{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e81c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import time ,re , timeit ,os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd1c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소수점 이하 세자리 까지 출력.\n",
    "np.set_printoptions(precision=3)\n",
    "pd.set_option('display.precision',3)\n",
    "\n",
    "# 데이터 프레임 가로 방향으로 최대로 보여준다.\n",
    "pd.set_option('expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f066b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목에 ai가 들어간 논문 180개 병합하여 읽어오기\n",
    "reader1 = PdfReader(r\"../data/ai_merged1.pdf\")\n",
    "reader2 = PdfReader(r\"../data/ai_merged2.pdf\")\n",
    "reader3 = PdfReader(r\"../data/ai_merged3.pdf\")\n",
    "reader4 = PdfReader(r\"../data/ai_merged4.pdf\")\n",
    "reader5 = PdfReader(r\"../data/ai_merged5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72fa1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00000-26246718') invalid; use 0.0 instead\n",
      "C:\\Users\\1104-10\\anaconda3\\Lib\\site-packages\\PyPDF2\\_cmap.py:151: PdfReadWarning: Advanced encoding [] not implemented yet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_all1 = []\n",
    "text_all2 = []\n",
    "text_all3 = []\n",
    "text_all4 = []\n",
    "text_all5 = []\n",
    "\n",
    "for page in reader1.pages:\n",
    "    text = page.extract_text()\n",
    "    text_all1.append(text)\n",
    "for page in reader2.pages:\n",
    "    text = page.extract_text()\n",
    "    text_all2.append(text)\n",
    "for page in reader3.pages:\n",
    "    text = page.extract_text()\n",
    "    text_all3.append(text)\n",
    "for page in reader4.pages:\n",
    "    text = page.extract_text()\n",
    "    text_all4.append(text)\n",
    "for page in reader5.pages:\n",
    "    text = page.extract_text()\n",
    "    text_all5.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a84aa294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 전처리.\n",
    "text_all1 = [x.lower() for x in text_all1]\n",
    "text_all2 = [x.lower() for x in text_all2]\n",
    "text_all3 = [x.lower() for x in text_all3]\n",
    "text_all4 = [x.lower() for x in text_all4]\n",
    "text_all5 = [x.lower() for x in text_all5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b5658f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_all1 + text_all2 + text_all3 + text_all4 + text_all5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b6c0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"special section on deep learning\\nalgorithms for internet of medical things\\nreceived april 21, 2020, accepted april 27, 2020, date of publication may 4, 2020, date of current version may 26, 2020.\\ndigital object identifier 10.1 109/access.2020.2992341\\na comprehensive review of the\\ncovid-19 pandemic and the role of iot,\\ndrones, ai, blockchain, and 5g in\\nmanaging its impact\\nvinay chamola\\n1, vikas hassija\\n2, vatsal gupta\\n2,\\nand mohsen guizani\\n3, (fellow, ieee)\\n1department of electrical and electronics engineering, birla institute of technology and science (bits), pilani 333031, india\\n2department of cse and it, jaypee institute of information technology, noida 201309, india\\n3department of computer science and engineering, qatar university, doha, qatar\\ncorresponding author: mohsen guizani (mguizani@ieee.org)\\nthis work was supported by the qatar national research fund (a member of the qatar foundation) under grant nprp10-1205-160012.\\nabstract the unprecedented outbreak of the 2019 novel coronavirus, termed as covid-19 by the world\\nhealth organization (who), has placed numerous governments around the world in a precarious position.\\nthe impact of the covid-19 outbreak, earlier witnessed by the citizens of china alone, has now become\\na matter of grave concern for virtually every country in the world. the scarcity of resources to endure the\\ncovid-19 outbreak combined with the fear of overburdened healthcare systems has forced a majority of\\nthese countries into a state of partial or complete lockdown. the number of laboratory-con\\x1crmed coronavirus\\ncases has been increasing at an alarming rate throughout the world, with reportedly more than 3 million\\ncon\\x1crmed cases as of 30 april 2020. adding to these woes, numerous false reports, misinformation, and\\nunsolicited fears in regards to coronavirus, are being circulated regularly since the outbreak of the covid-\\n19. in response to such acts, we draw on various reliable sources to present a detailed review of all the major\\naspects associated with the covid-19 pandemic. in addition to the direct health implications associated\\nwith the outbreak of covid-19, this study highlights its impact on the global economy. in drawing things\\nto a close, we explore the use of technologies such as the internet of things (iot), unmanned aerial\\nvehicles (ua vs), blockchain, arti\\x1ccial intelligence (ai), and 5g, among others, to help mitigate the impact\\nof covid-19 outbreak.\\nindex terms coronavirus, covid-19, pandemic, transmission stages, global economic impact, ua vs\\nfor disaster management, blockchain, iomt applications, iot, ai, 5g.\\ni. introduction\\nthe covid-19, an acronym for ``coronavirus disease-\\n2019'', is a respiratory illness caused by the severe acute\\nrespiratory syndrome coronavirus-2 (sars-cov-2), a con-\\ntagious virus belonging to a family of single-stranded,\\npositive-sense rna viruses known as coronaviridae. much\\nlike the in\\x1duenza virus, sars-cov-2 attacks the respiratory\\nsystem and causes ailments such as cough, fever, fatigue,\\nand breathlessness. while the exact source of the virus is\\nunknown, scientists have mapped the genome sequence of the\\nthe associate editor coordinating the review of this manuscript and\\napproving it for publication was victor hugo albuquerque\\n .sars-cov-2 and determined it to be a member of the \\x0c-cov\\ngenera of the coronavirus family, which typically derives its\\ngene sources from bats and rodents [1]. the covid-19 was\\n\\x1crst reported to affect human life in wuhan city, in the\\nhubei province of china in december 2019. since then, the\\ncovid-19 has spread like wild\\x1cre throughout the rest of the\\nworld, marking its presence in 213 countries and independent\\nterritories. covid-19 statistics for the worst affected coun-\\ntries and regions of the world have been presented in fig. 1.\\naccording to the who, the current global tally1of con\\x1crmed\\ncoronavirus cases stands at 3,090,445 while the death toll\\n1as of 30 april 2020\\nvolume 8, 2020this work is licensed under a creative commons attribution 4.0 license. for more information, see https://creativecommons.org/licenses/by/4.0/90225\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 1. statistics in regards to the covid-19 (data source: who situation report - 30 april 2020 [3]).\\nhas reached 217,769 [2]. the rapid rise in the number of\\ncovid-19 incidents worldwide has prompted the need for\\nimmediate countermeasures to curb the catastrophic effects of\\nthe covid-19 outbreak. to this end, this paper evaluates the\\nuse of varied technologies such as iot, ua vs, ai, blockchain,\\nand 5g, which could help mitigate the adverse effects of this\\npandemic and expedite the recovery process. however, before\\nexploring the potential technological solutions for covid-19\\npandemic impact management, we provide a comprehensive\\nreview of the covid-19, including its clinical features, diag-\\nnosis, treatment, and the impact of its outbreak on the global\\neconomy.\\na. background\\naccording to the who, viral infections, particularly the\\nones caused by different coronaviruses, continue to emerge\\nand pose a severe public health problem [1]. coronaviruses\\nare spherical positive-sense rna viruses ranging from\\n600å - 1400å in diameter [4], with proteins known as spikes\\nprotruding from its surface, which impart a crown-like struc-\\nture to them under the electron microscope. the past two\\ndecades have witnessed the emergence of several viral out-\\nbreaks with different forms of coronavirus at the helm,\\nsuch as the 2002-2004 sars-cov outbreak [5], and the\\nmore recent middle east respiratory syndrome coronavirus\\n(mers-cov) infection of 2012. the sars-cov outbreak\\noriginated in the guandong province of china and laterspread to more than 37 countries worldwide, causing over\\n8000 infections and around 774 deaths [6]. the \\x1crst case of\\nmers-cov infection was detected in saudi arabia, which\\ninitiated a large-scale outbreak in the middle eastern countries\\nthat ultimately led to 871 fatalities [7], [8].\\nthe covid-19 outbreak came to light on 31 decem-\\nber 2019 when 27 cases of pneumonia of unknown etiology\\nwere reported at the who's country of\\x1cce in china. for the\\nentire timeline of events, kindly refer to fig. 2[9]. the epi-\\ncenter of the outbreak was linked to wuhan's wholesale mar-\\nket for seafood and other exotic animals, including snakes,\\nbats, and marmots [10]. a new strain of a highly contagious\\n\\x0c-coronavirus, sars-cov-2, has been deemed responsible\\nfor the rapid outbreak of covid-19. distinguishing charac-\\nteristics of the virus include its extremely contagious nature\\nand relatively long (1-14 days) incubation period. during\\nthis period, a person can be infected by the virus and not\\nshow any symptoms at all. therefore, people infected with\\nthe disease may unknowingly serve as silent carriers of\\nthe virus, contributing to a high basic reproductive num-\\nber2for the covid-19 virus. while some studies indicate\\nthat sars-cov-2 could be susceptible to heat and ultravio-\\nlet (uv) light [1], there is no speci\\x1cc treatment or vaccine\\nfor the infection to date, and the management protocols for\\nthe disease are evolving as of this writing.\\n2who de\\x1cnes basic reproductive number as the number of secondary\\ninfections caused by a single infected individual\\n90226 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 2. a timeline of the covid-19 pandemic.\\nb. clinical features\\ncovid-19 manifests with clinical features ranging from\\nthe asymptomatic state (no symptoms) to acute respiratory\\ndistress syndrome (ards) and multiple organ dysfunction\\nsyndrome (mods). according to the results of a recent\\nstudy conducted by the who in collaboration with china,\\nof the 55,924 laboratory-con\\x1crmed covid-19 cases that\\nwere examined, a majority exhibited clinical characteristics\\nsuch as fever, dry cough, fatigue, and sputum production.\\nat the same time, only a handful of patients showcased\\nsymptoms such as sore throat, headache, myalgia, and breath-\\nlessness, while symptoms such as nausea, nasal conges-\\ntion, hemoptysis, diarrhea, and conjunctival congestion were\\nfound to be very rare (refer to table 1). while most of the\\ncovid-19 patients developed a mild to moderate disease,\\na few patients were diagnosed with a severe (13.8%) and a\\ncritical (6.1%) form of the same [11]. patients with a severe\\nor a critical form of the disease often develop bluish lips/face\\nand are prone to a variety of complications, including ards,\\nacute heart injury, and secondary infection. according to\\nthe us centers for disease control and prevention (cdc),\\nthe individuals at the highest risk for severe illness from the\\ncovid-19 include older adults (people above the age of 60)\\nand people with existing medical conditions, such as diabetes,\\nhypertension, asthma, and cardiovascular disease [12].\\nc. transmission mechanism\\nalthough there are several studies in the direction of\\ncovid-19's pathophysiological properties, its propagation\\nmechanism remains somewhat elusive. while the initial\\ncovid-19 cases were associated with the direct exposure\\nof individuals to infected animals, the rapid outbreak of the\\ndisease has shifted the focus of the research to human-to-\\nhuman transmission. an analysis of around 75,465 cases of\\ncovid-19 in china has revealed that the covid-19 virus istable 1. list of covid-19 symptoms.\\nprimarily transmitted between people from the spread of res-\\npiratory droplets through sneezing and coughing [13]. these\\nrespiratory droplets have the potential to cover a distance\\nof up to 1.8 meters (6 feet). therefore, any person in close\\ncontact with an infected person is at risk of being exposed to\\nthe respiratory droplets, and by extension, the virus. although\\nsymptomatic people have been identi\\x1ced to be the primary\\nsource of sars-cov-2 transmission, there is also a possi-\\nbility of transmission via unsymptomatic people. direct and\\nindirect contact with infected surfaces has been identi\\x1ced as\\nanother potential cause of covid-19 transmission. evidence\\nsuggests that the virus can survive on plastic and steel sur-\\nvolume 8, 2020 90227\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 3. organization of this work.\\nfaces for as long as three days, on copper for approximately\\n4 hours, and up to 24 hours on cardboard [14].\\nonce the virus enters into a healthy body, it passes through\\nthe nasal passage to the mucus membranes present in the\\nthroat and binds itself to the body's cellular receptors. with\\nthe help of the spikes present on its surface, the sars-cov-2\\nruptures the cell membrane and forces the cell into making\\nmultiple copies of itself. these newly generated copies burst\\nout of the cell and infect other cells in the body. following\\nthis, the virus moves down the bronchial tubes and reaches\\nthe lungs, where it severely impairs the host's air sacs [15].\\nd. organization\\nthe rest of the paper is organized as follows. in section ii,\\nwe address the existing works that have reviewed the state\\nof the covid-19 pandemic. in section iii, we present a\\nbrief overview of the pandemics that have occurred in the\\npast century. in section iv, we discuss the different stages of\\nthe covid-19 transmission, while in section v, the global\\nimpact of the outbreak on different sectors of the economy\\nhas been evaluated. section v also includes some statistics\\nproviding valuable insights into the widescale impact of\\nthe covid-19 pandemic on these sectors. in section vi,\\nwe discuss the current methods for covid-19 diagnosis.\\nsection vii examines the efforts being made by various\\norganizations and laboratories in the direction of covid-19\\nvaccine & drug development, while section viii lists the\\npreventive measures required to safeguard oneself against the\\ncovid-19. in the next nine sections, we provide a compre-hensive review of the use of technologies such as iot, ua vs,\\nrobots, smart wearables, ai, blockchain, and 5g as a means\\nto manage the outbreak effectively. finally, section xviii\\nconcludes the paper. the organization of the paper has also\\nbeen depicted pictorially in fig. 3.\\nii. related works\\nthe massive outbreak of the covid-19 has prompted various\\nscientists, researchers, laboratories, and organizations around\\nthe world to conduct large scale research to help develop vac-\\ncines and other treatment strategies. in the months following\\nthe covid-19 outbreak, several papers examining different\\naspects of the covid-19 have been published [16]\\x15[22].\\nto determine the clinical characteristics of the covid-19,\\ndawei wang et al. have studied 138 infected patients in\\nwuhan, china [21]. the authors have taken into account\\nspeci\\x1ccs such as demographics, signs & symptoms, and\\nmedical history of all the patients to assess their cases\\ncarefully. the authors have also presented the laboratory\\n\\x1cndings of these patients to demonstrate the effects of the\\nsars-cov-2 virus on different vital organs of the body.\\nnanshan chen et al. studied 99 patients with the covid-19,\\n49 of whom had a direct link to the huanan seafood market in\\nwuhan, known to be the covid-19 epicenter. their \\x1cndings\\nof the epidemiological, clinical, and radiological characteris-\\ntics of the disease have been published in [22]. in their \\x1cnd-\\nings, they report that among all the patients that were studied,\\n17% developed acute respiratory distress syndrome (ards),\\nand among them, 11% died of multiple organ dysfunction\\nsyndrome (mods).\\n90228 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\ntable 2. major viral diseases (1915 - present).\\nfang jiang et al. have reviewed six published studies rec-\\nognizing the clinical characteristics of the covid-19. in their\\nwork, they have summarized these studies and, in doing so,\\nprovided a brief overview of clinical features and treatments\\nof the covid-19 [23]. the authors of [24] have reviewed the\\nexisting literature on computed tomography (ct) character-\\nistics of covid-19 available on platforms such as pubmed,\\ngoogle scholar, and elsevier, among others. the primary\\nissue with both these works is that they review a small subset\\nof a much broader subject. to this end, the authors of [4]\\nand [10] provide a brief overview of the covid-19 outbreak\\nin terms of its clinical features, prevention, diagnosis, and\\ntreatment. although these surveys shed some light on the\\ncurrent scenario of the covid-19 outbreak, they give a very\\nbrief and limited idea about the exact situation.\\ndespite the abundance of research in the domain of\\ncovid-19 characteristic analysis and vaccine development,\\nto the best of our knowledge, at the time of this writing, there\\nis no survey that provides a comprehensive review of the\\ncovid-19 outbreak and its potential implications. further-\\nmore, no work in the existing literature attempts to review\\nthe role of emerging technologies such as iot, ua vs, ai,\\nblockchain, and 5g in managing the covid-19 pandemic.\\nthis presents the need for a detailed survey that provides\\nboth the horizontal and the vertical view of the covid-19 in\\nterms of its clinical features, diagnosis, treatment, prevention\\nstrategies, and the technological solutions being adopted to\\nalleviate the impact of its outbreak. in this work, we present a\\ncomprehensive review of the covid-19 pandemic that will\\nhelp readers gain a deeper understanding of the current global\\nsituation due to the covid-19 pandemic. before divulging\\ninto a thorough analysis of the covid-19 pandemic, we take\\na brief look at some of the past pandemics in the section\\nbelow.\\niii. pandemics in the past century\\nthe last century has seen a plethora of outbreaks and\\nepidemics. while coronaviruses such as sars-cov &\\nmers-cov have been responsible for a majority of these\\noutbreaks (refer to table 2), different types of in\\x1duenza\\nviruses, such as h1n1, h2n2, and h3n2, have been at thehelm of all the four pandemics in the past 105 years. the\\nh1n1 virus alone has been responsible for two pandemics -\\n1) the spanish flu of 1918-1919 and the 2) swine \\x1du\\nin 2009-2010, while the h2n2 and h3n2 in\\x1duenza viruses\\nhave been responsible for the asian flu of 1957-1958, and\\nthe hong kong \\x1du of 1968-1969, respectively. in this section,\\nwe provide an overview of all these pandemics.\\na. spanish flu pandemic (1918-1919)\\nthe spanish flu is known by many to be the deadliest pan-\\ndemic in the history of humankind, with the total number of\\nfatalities surpassing the 50 million mark [25]. the disease\\nwas caused by the h1n1 virus, which is believed to have\\noriginated in birds. unlike most diseases, spanish flu had\\na peculiar characteristic of being extremely lethal against\\nthe young and healthy populace. this was because the virus\\nattacked hosts by causing cytokine storms in the patient's\\nimmune system, which often lead to death [26]. since young\\npeople had stronger immune systems as compared to older\\nadults, they were more likely to be affected by the virus.\\nb. asian flu pandemic (1957-1958)\\nthe asian \\x1du pandemic began in february of 1957 in singa-\\npore. it was the second major pandemic of the 20th century\\nafter the spanish flu pandemic of 1918. it is believed to have\\ncaused 116,000 deaths in the us and a total of 1.1 million\\nfatalities worldwide [27]. the virus at the root of this disease\\nwas identi\\x1ced to be the type a h2n2 virus, which, like the\\nh1n1, is believed to be of avian origin. eleven years after\\nthe outbreak, the h2n2 virus subsequently mutated to a strain\\nthat is no longer able to affect human hosts.\\nc. hong kong flu pandemic (1968-1969)\\nthe hong kong flu pandemic was the third major in\\x1duenza\\npandemic of the 20th century. it was caused by the\\nh3n2 virus, which is believed to have evolved from\\nthe h2n2 virus that caused the asian \\x1du pandemic. the\\nh3n2 virus involved a mutated version of the ha antigen\\npresent in h2n2 but retained the same n2 antigen. the\\nimpact of the hong kong flu pandemic across the world has\\nvolume 8, 2020 90229\",\n",
       " 'v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 4. cumulative number of cases of the covid-19 (data source: who situation reports, several media reports).\\nbeen described as sporadic, which is believed to have been\\ndue to the prior immunity developed against the n2 anti-\\ngen on account of the asian flu pandemic [26]. unlike the\\nh1n1 virus behind the spanish flu pandemic, the h3n2 virus\\nwas more aggressive towards people above the age of 65.\\nd. swine flu pandemic (2009-2010)\\nin the spring of 2009, a new strain of the type a\\nh1n1 in\\x1duenza virus emerged, leading to the swine \\x1du\\npandemic. like the spanish flu, which was caused by a\\ndifferent strain of the same virus, the swine \\x1du pandemic\\nwas more deadly against people below 65 years of age.\\npre-acquired immunity in older people on account of previous\\nexposure to the h1n1 virus was believed to be one of the\\nreasons for the same. the us centers for disease control and\\nprevention (cdc) estimate that there have been more than\\n43.3 million cases, 195,086 hospitalizations, and 8868 deaths\\nin the us alone due to the virus, while the worldwide tally of\\nfatalities stands above 151,700 [28].\\niv. different stages of covid-19 outbreak\\naccording to the who, the covid-19 pandemic is regarded\\nas having four main classes of transmission that remain\\nconsistent throughout the world to facilitate better com-\\nmunication and understanding amongst the countries [29].\\nsuch a categorization makes it simpler for other countries toenforce policies which they think would assist in preventing\\nthe outbreak, for example, imposing travel bans, shutting\\ndown schools & colleges, and enforcing partial or complete\\nlockdown. for better understanding, we have portrayed the\\nwho transmission classes as different stages of the covid-\\n19 outbreak keeping in line with several media reports. the\\nonset of different stages of the covid-19 outbreak in four\\ncountries, namely, china, spain, italy, and the usa, have\\nbeen mapped in fig. 4.\\na. stage i - imported cases only\\nthe \\x1crst stage of the covid-19 outbreak in a particular\\nnation is characterized by its \\x1crst reported incident of the dis-\\nease, in this case, covid-19. in this stage, the disease does\\nnot spread locally, and the infection is usually limited to the\\npeople with travel history to an already affected region [30].\\nb. stage ii - sporadic cases/local transmission\\nthe second stage of the covid-19 outbreak occurs when\\nthere are a few sporadic cases of the disease in the country.\\nit happens when people who are already infected with the\\ndisease spread it to people with whom they come into contact,\\nusually immediate family members, friends, and colleagues.\\nat this stage, it is possible to perform contact tracing and\\nlimit the spread of the disease by quarantining the infected\\npeople.\\n90230 volume 8, 2020',\n",
       " 'v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 5. countries in lockdown as of 19 april 2020 (data source: media reports [31]\\x15[48]).\\nc. stage iii - clusters of cases\\nthe third stage of the covid-19 outbreak in a country is\\nmarked by the presence of several clusters of covid-19\\ncases, i.e., when the disease-causing virus starts circulating\\nwithin a geographic location and infects individuals who have\\nneither a history of travel nor contact with someone who does.\\nat this stage, it becomes hard to trace the source of the virus\\ntransmission, and geographical lockdown becomes highly\\nnecessary to prevent the outbreak from reaching stage iv.\\nd. stage iv - community transmission\\nthe fourth stage of the covid-19 pandemic in a coun-\\ntry is associated with community transmission, i.e., larger\\noutbreaks of local transmission in a country, leading to an\\nextremely high number of reported incidents and deaths.\\nat this stage, the outbreak gets out of control, and \\x1cnding\\na cure or vaccine is the only way to mitigate the impact of the\\ndisease. countries like iran, turkey, canada, and the usa are\\ncurrently in the fourth stage of the covid-19 pandemic [29].\\nv. impact of the covid-19 pandemic on the\\nglobal economy\\nowing to the lack of any concrete treatment strategy, social\\ndistancing has been identi\\x1ced as the best possible defense\\nstrategy against the covid-19 pandemic at the time of this\\nwriting. however, the need for social distancing has prompted\\ngovernments around the world to impose lockdowns (refer\\nto fig. 5), which has marked a huge dent in the global\\neconomy. all non-essential services have been forced to shut\\ndown, causing virtually all the industrial sectors to face sig-\\nni\\x1ccant disruptions in the supply chain (refer to table 3),and consequently, putting billions of people at risk of losing\\ntheir jobs. furthermore, the rapid outbreak of covid-19 has\\nforced governments to restrict the trade of a majority of goods\\nacross country borders, leaving international trade \\x1dows on\\nthe verge of collapse. according to the projections put forth\\nby jpmorgan chase & co., the covid-19 pandemic has\\nthe potential to paralyze the global economy, with an esti-\\nmated loss of more than 5.5 trillion us dollars in the next\\n18-24 months [49]. in this section, we analyze the impact\\nof the covid-19 pandemic on the overall economy by thor-\\noughly dissecting its impact on different economic sectors.\\na. automotive industry\\nthe automotive industry has seen major disruptions in pro-\\nduction due to stringent lockdown measures enforced in sev-\\neral countries worldwide as an effort to contain the pandemic.\\nas social distancing is enforced and people are required to\\nstay in their homes, usage of automobiles, including both\\npublic & private transport, has declined across the world. the\\nonly automobiles currently in use are the vehicles associated\\nwith essential services.\\n1) relevant statistics\\n\\x0fin china, the automobile industry saw an 18% drop in\\nsales in year-over-year (yoy) sales of january 2020.\\ndespite containment efforts, this number escalated to\\n79.1% in february 2020, which is the biggest ever\\nyoy drop experienced by the chinese automotive indus-\\ntry [50].\\n\\x0fin march 2020, the yoy sales of passenger vehicles and\\ncommercial vehicles in india saw a decline of 52% and\\nvolume 8, 2020 90231',\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\ntable 3. industries hit hardest by the covid-19 pandemic.\\n89%, respectively, as dealers were forced to shut down\\ntheir showrooms following government stipulations to\\nlimit the spread of covid-19 [51], [52].\\n\\x0faccording to the european automobile manufacturers\\nassociation (acea), the combined production losses\\nin the european union (eu) and the united king-\\ndom amount to more than 2.1 million vehicles as\\nof 28 april 2020. additionally, employment of more\\nthan 1.1 million people has been adversely affected due\\nto factory shutdowns [53].\\n\\x0fin the usa, the covid-19 outbreak has forced a major-\\nity of automakers, including general motors, fiat, ford,\\nand many others, to suspend their production activi-\\nties [54]. according to the estimates published by the\\nalliance for automotive innovation on 26 march 2020,\\n93% of all automobile production plants were forced to\\nclose down in the usa following the covid-19 out-\\nbreak [55].\\nb. aviation industry\\nthe covid-19 pandemic has had a massive impact on the\\naviation industry. affected countries, which includes almost\\nall the nations, have been forced to impose travel bans on both\\ninternational and domestic passenger \\x1dights. the only active\\nairways include critical supply routes that support cargo and\\nfreight aircraft.\\n1) relevant statistics\\n\\x0fas per a recent report published by the international\\nair transport association (iata), the global air travel\\ndemand increased by just 2.4% in january 2020,\\nwhich is the lowest yoy increase registered in the last\\ndecade [56]. the major disruption in travel demand,\\nhowever, was recorded between 24 and 30 march 2020,\\nwhen the reported number of operational \\x1dights plum-\\nmeted to 280,000, a sharp decline from 780,000 \\x1dights\\nreported in the same period in 2019 [57].\\x0faccording to the most recent iata estimates, the airline\\nindustry is well on track to lose as much as 314 bil-\\nlion us dollars in revenues globally, following the\\ncovid-19 crisis [58].\\n\\x0fas airline services are currently stalled, the demand for\\nthe purchase of new aircraft has also dropped. the total\\nnumber of aircraft orders has decreased from 1858 in\\n2018 to 235 in 2020 [59].\\nc. tourism industry\\nthe tourism industry has been one of the worst affected\\nindustries following the outbreak of covid-19. revenues\\ngenerated from the tourism sector account for 10% of the\\nworld's gdp. therefore, any adversity faced by the tourism\\nsector has the potential to dent the global economy severely.\\n1) relevant statistics\\n\\x0faccording to the world travel & tourism coun-\\ncil (wttc) estimations, the covid-19 pandemic could\\nlead to a layoff of about 50 million people associated\\nwith the tourism industry worldwide [60].\\n\\x0fas per the \\x1cgures issued by the united nations world\\ntourism organisation (unwto), international visitor\\narrivals could fall by up to 30% in 2020, which cor-\\nresponds to a loss of 300-450 billion us dollars in\\ninternational tourism receipts (itrs) [61].\\nd. oil industry\\nthe shutdown of international and domestic passenger air-\\ncraft across the world has resulted in a drastic decline in the\\nconsumption of aviation fuel. similarly, on the ground, all\\nnon-essential traf\\x1cc remains stalled, causing a sharp decline\\nin the global oil demand.\\n1) relevant statistics\\n\\x0fin china, the demand for crude oil has fallen by around\\n3 million barrels a day (which corresponds to 20% of the\\ntotal consumption) [62].\\n90232 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\n\\x0fthe brent crude oil benchmark collapsed over 65% in\\nthe \\x1crst quarter of 2020, while the west texas intermedi-\\nate (wti) benchmark recorded a drop of more than 66%.\\nwith oil prices plummeting to nearly 25 us dollars, both\\nthese benchmarks have recorded their worst ever quarter\\nin history [63].\\ne. construction industry\\nconstruction \\x1crms are likely to face severe disruptions and\\ndelays in current projects on account of the covid-19 pan-\\ndemic. due to a majority of the workforce being unable to\\nwork as a result of stringent self-quarantine guidelines, most\\nconstruction \\x1crms will be required to cease all non-essential\\noperations until the outbreak is contained. this will likely\\nresult in the large scale re-scheduling of existing projects,\\nwhich might lead to severe losses for the industry.\\n1) relevant statistics\\n\\x0fwithin just the \\x1crst two months of the year, \\x1cxed asset\\ninvestment in china dropped by 30.3%, while the real\\nestate development dropped by 16.3% [64].\\n\\x0fthe widespread impact of the covid-19 outbreak\\non the construction sector in china and other leading\\neconomies has prompted globaldata3to update its esti-\\nmate for construction growth in 2020 from 3.1% to\\n0.5% [65].\\nf. food industry\\nin comparison to other sectors, the impact of the covid-19\\npandemic has not been as severe on the food industry. recog-\\nnition of food as an essential commodity has allowed supply\\nchains associated with food products to remain operational.\\nin fact, as per the food and agriculture organization (fao)\\nof the united nations (un), packaged food demand has risen\\nsigni\\x1ccantly in the months following the covid-19 out-\\nbreak [66]. however, that does not go as far as to say that\\nthe industry has not been affected at all. while supply chains\\nfor essential food items are kept open, restaurants, cafes, and\\nother luxury food service providers have been forced to shut\\ndown [67]. furthermore, several grocery store owners and\\nsupermarkets are often \\x1cnding themselves unable to meet the\\nrising demands owing to `panic buying' and stocking up of\\nfood supplies by the masses [68]\\x15[70].\\ng. healthcare and medical industry\\nthe covid-19 pandemic has had a devastating effect on the\\nhealthcare systems across the world. while most industrial\\nsectors have been economically affected due to the inac-\\ntivity caused as a result of lockdown measures & travel\\nbans, what the healthcare industry is witnessing is far from\\nstagnation. hospitals across the world are currently facing\\na shortage of ventilators, intensive care units (icus), and\\npersonal protective equipment (ppe) required to manage the\\ncovid-19 patients. the healthcare systems of even the most\\n3a data analytics and consulting companydeveloped countries in the world are on the brink of col-\\nlapse due to the exponentially increasing number of covid-\\n19 patients [71]\\x15[74].\\nh. telecommunications industry\\nthe impact of the covid-19 pandemic on the telecom-\\nmunications industry has been sporadic. various telecom-\\nmunication service providers (tsps) and internet service\\nproviders (isps) have reported witnessing a massive increase\\nin traf\\x1cc [75]. the large scale consumption of network band-\\nwidth has been attributed to the governments' lockdown\\nefforts, which have forced the educational institutions to use\\nonline platforms of teaching, and companies to allow their\\nemployees to work from home. however, the covid-19 pan-\\ndemic has not left the telecommunications sector unscathed.\\nmuch like other industrial companies, a majority of tsps &\\nisps have recorded a massive drop in their share prices over\\nthe past few months. in globaldata's share price analysis\\nof some of the top tsps worldwide, it was revealed that\\nshare prices of telecom behemoths at&t, china telecom,\\nand telefonica plummeted by more than 20% between 1 jan-\\nuary and 25 march 2020 [76].\\nthe large scale implications of the covid-19 pandemic on\\nthe global economy are attributed to the substandard response\\nsystem adopted following its initial outbreak. although the\\nresponse to the covid-19 pandemic has been more orga-\\nnized than the response to previous epidemics and pandemics,\\na few issues in the current epidemic/pandemic response sys-\\ntem remain. table 4lists all the underlying issues with the\\ncurrent response, along with the key learning points for future\\npublic health emergency management [10]. these lessons are\\nvery relevant not just for other health crises but also in case\\nthere is a second/third wave of the covid-19 pandemic in\\nthe future.\\nvi. diagnostic testing for the covid-19\\ngiven the signi\\x1ccant spurt in covid-19 cases across the\\nworld in the past few months, a carefully devised strategy\\nfor reliable diagnosis is the need of the hour. the onset\\nof stage ii and stage iii of the covid-19 outbreak has\\nprompted a majority of the countries worldwide to extend\\ntheir scope of testing beyond individuals with foreign travel\\nhistory. however, due to the insuf\\x1ccient number of test-\\ning kits, large-scale testing of the covid-19 is infeasible.\\nfurthermore, the inability to distinguish the symptoms of\\ncovid-19 from the symptoms of common \\x1du has made it\\ndif\\x1ccult for governments across the world to determine \\x1cxed\\ncriteria required to carry out a test. to this end, the cdc has\\nissued priority-based testing criteria to guide the evaluation\\nof covid-19 cases. the criteria assign the highest priority\\nto healthcare workers & hospitalized patients showing symp-\\ntoms of covid-19 infection, while symptomatic patients a)\\nabove the age of 65, or b) having existing medical conditions,\\nhave been given the second priority. the entire guidelines for\\nthe testing criteria have been listed on the of\\x1ccial website of\\nthe cdc [77].\\nvolume 8, 2020 90233\",\n",
       " 'v. chamola et al.: comprehensive review of the covid-19 pandemic\\ntable 4. lessons drawn from the current response to the covid-19 pandemic [10].\\na. contact tracing\\ncontact tracing refers to the process of identifying people\\nwith a history of exposure to infected individuals. the rela-\\ntively long incubation period associated with the covid-19\\nand the absence of large scale testing has made it extremely\\nchallenging for the authorities to identify the actual number\\nof infected patients. this leaves the process of contact trac-\\ning as the only viable option. according to the who [78],\\nthe process of contact tracing involves three stepsv\\ni) identifying individuals with a history of contact with an\\ninfected person.\\nii) recording the details of those individuals.\\niii) getting those individuals tested as soon as possible.\\nadopting the process of contact tracing can be particularly\\nadvantageous for the countries currently in the \\x1crst and\\nthe second stage of the covid-19 outbreak.\\nb. clinical tests for covid-19 detection\\ndeveloping accurate and reliable tests to diagnose\\nsars-cov-2 infection in individuals is essential to curb its\\nrapid transmission. the currently available covid-19 tests\\ncan be broadly classi\\x1ced into two types:\\n1) molecular tests\\nthe who-recommended nucleic acid ampli\\x1ccation\\ntest (naat) has emerged as the most popular test for detect-\\ning an active sars-cov-2 infection [79]. these tests involvethe use of the nasopharyngeal swab technique, wherein a\\nsample comprising a mixture of mucus and saliva is obtained\\nfrom the back of the throat (upper respiratory tract) using\\na cotton swab (kindly refer to table 5 for details on other\\ntypes of sample collection techniques). however, in case\\nthe person being tested is suffering from severe respiratory\\nailments, the who recommends obtaining specimens from\\nhis/her lower respiratory tract as well [80]. these samples\\nare then brought to a specialized laboratory, where they are\\nassessed for detecting the presence of viral rna using a\\nreal-time reverse-transcription polymerase chain reaction\\n(rrt-pcr) test [81]. a diagnosis of the covid-19 is only\\ncon\\x1crmed if the test identi\\x1ces eitherv\\ni) the presence of two discriminatory targets for the\\nsars-cov-2 genome, one of which is preferably\\nexplicit to the sars-cov-2, or\\nii) the presence of betacoronavirus followed by the iden-\\nti\\x1ccation of sars-cov-2 using partial or complete\\nsequencing of the virus genome (the target sequence\\nshould be larger than the amplicon on which the naat\\nassay is used).\\nthe viral genes being targeted by the nucleic acid ampli-\\n\\x1ccation tests (naats) are the n, e, s, and rdrp genes.\\nidenti\\x1ccation of just a single gene in the naat generates\\nthe need for a repeat test of the patient. in any subsequent\\ntests, the who recommends using a different specimen and\\ntarget sequence from the one used in the initial test [80].\\n90234 volume 8, 2020',\n",
       " 'v. chamola et al.: comprehensive review of the covid-19 pandemic\\ntable 5. various techniques for coronavirus sample collection.\\ntable 6. covid-19 candidate vaccines in clinical evaluations.\\nwhile naats have high sensitivity (true positive rate) and\\nspeci\\x1ccity (true negative rate), one of their drawbacks is that\\nthey can only diagnose current cases of infection, i.e., they\\ndo not provide any insights as to whether someone had the\\ninfection earlier.\\n2) serological tests\\nunlike molecular tests that detect the presence of the virus\\nitself, serological tests are used to detect the existence of\\nantibodies in the bloodstream of the person being tested.\\nantibodies are proteins formed by the white blood cells to\\ncombat a speci\\x1cc antigen. by enabling healthcare experts to\\nidentify individuals who have developed an immune response\\nto the infection, serological tests have the potential to play a\\nmassive role in the \\x1cght against covid-19 [85]. however,\\nserological tests also have one signi\\x1ccant shortcoming. theydo not have the ability to detect a disease during its early\\ndays when the body is still building antibodies against the\\ninfection.\\nvii. treatment\\ncovid-19, caused by the novel sars-cov-2, has led the\\nworld into an unprecedented state of severe disarray. at the\\ntime of writing, no de\\x1cnitive treatment or preventive vaccine\\nexists for the coronavirus. as such, the treatment of covid-\\n19 is mostly symptomatic, i.e., the type of treatment admin-\\nistered depends on the speci\\x1cc symptoms exhibited by the\\npatient.\\nmost cases of the coronavirus disease have been classi\\x1ced\\nas mild, with patients recovering on their own without the\\nneed for supportive care. therefore, it is recommended that\\npatients with mild covid-19 symptoms be managed at home\\nvolume 8, 2020 90235',\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nto avoid placing additional strain on the already stressed-out\\nhealth systems. however, severe and critical cases of covid-\\n19 do tend to require hospitalization. patients experiencing\\nhypoxemia4may require the provision of additional oxygen\\nvia face masks or ventilators. co-infections that occur as\\na result of a weakened immune system, due to the virus,\\nare treated with necessary antibiotics and antifungals on a\\ncase by case basis. as the sars-cov-2 virus may affect the\\nkidney as well, renal replacement therapy might be required\\nin some cases [21]. in any case, patients diagnosed with the\\ndisease need to be put under strict isolation, irrespective of\\nthe severity of the symptoms, in order to prevent further\\ntransmission.\\nwhile no de\\x1cnitive antiviral medicine or preventive vac-\\ncine for sars-cov-2 is available to date, various attempts\\nare being made to make one available for commercial use as\\nsoon as possible. in the following subsections, we address the\\nefforts being made to produce potent vaccines and drugs for\\ncovid-19 treatment.\\na. vaccine development\\ndeveloping vaccines for viral diseases is particularly chal-\\nlenging, owing to their capability to mutate from one per-\\nson to another. nevertheless, the development of reliable\\n& potent vaccinations is the only viable way of bringing\\nthe covid-19 pandemic to an end. following the outbreak,\\nvarious medical organizations, independent laboratories, and\\nscientists have been attempting to create a vaccine for the\\nsars-cov-2. according to the who, as of 26 april 2020,\\naround 82 candidate vaccines are in the pre-clinical stage,\\nwhile 7 have already entered the clinical evaluations (refer\\nto fig. 6) [86]. some of the most signi\\x1ccant efforts being\\nmade in the direction of covid-19 vaccine development are\\nas follows:\\n1) moderna's mrna-1273\\nmoderna, a us-based biotech company, has put forth a\\nvaccine candidate in collaboration with the national insti-\\ntute of allergy and infectious diseases (niaid). moderna's\\napproach is based on the injection of mrna, a genetic form of\\nthe virus' genome, into human cells to allow them to generate\\nproteins required to combat the virus. unlike the methods\\nadopted in conventional vaccines, this approach does not\\nrequire growing large numbers of the virus [87]. although\\nthis vaccine has entered the \\x1crst phase of clinical trials on\\n15 march 2020, its commercial release is expected to be more\\nthan a year away [88].\\n2) cansino's ad5-ncov\\nanother candidate vaccine that is undergoing clinical eval-\\nuations is the adenovirus type-5 vector-based recombinant\\ncovid-19 vaccine (ad5-ncov). developed by cansino\\nbiological inc in association with the beijing institute of\\ntechnology (bit), ad5-ncov uses the non-replicating viral\\n4a low level of arterial oxygen supply\\nfigure 6. covid-19 preventive measures.\\nvector as its platform, the same as the one used in their ad5-\\nebov vaccine for ebola. this vaccine relies on the aden-\\novirus type-5 vector to stimulate immune responses that work\\nagainst the disease. given the positive response recorded in\\nthe \\x1crst phase of clinical trials, cansino might move for an\\nexpedited phase ii clinical trial [89].\\n3) pittcovacc (pittsburgh coronavirus vaccine)\\nthe researchers at the university of pittsburgh school of\\nmedicine have recently developed a vaccine against the\\nsars-cov-2 named pittcovacc [90]. unlike the mrna\\nvaccine candidate developed by moderna, pittcovacc adopts\\nthe more conventional method of building immunity using\\nlaboratory-generated pieces of viral protein. the preliminary\\ntests conducted on mice revealed that pittcovacc triggered\\nthe development of a large number of antibodies against\\nsars-cov-2 within two weeks of it being administered.\\npending fda's approval, phase i of the clinical trials for this\\nvaccine are slated to commence soon [91].\\n4) johnson & johnson's covid-19 lead vaccine\\nhealthcare conglomerate johnson & johnson, and the\\nbiomedical advanced research and development authority\\n(barda), a subdivision of the us department of health and\\nhuman services (hss), have pledged to collectively invest\\nmore than 1 billion us dollars in the r&d of covid-19 vac-\\ncines. on 30 march 2020, johnson & johnson declared that\\nit had identi\\x1ced its lead candidate vaccine after three months\\nof comprehensive research on several vaccine candidates in\\ncollaboration with the beth israel deaconess medical center,\\n90236 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\ntable 7. promising candidate drugs for the treatment of covid-19.\\na division of the harvard medical school. johnson & johnson\\nplans to launch the clinical trials of its lead candidate vaccine\\nby september 2020 at the latest [92].\\n5) multiple efforts made by the cepi\\nthe coalition for epidemic preparedness innovations\\n(cepi), a norway-based foundation established to expedite\\nthe development of vaccines against emerging infectious\\ndiseases, has initiated collaborations with several organiza-\\ntions & institutes across the world to aid in the development\\nof effective vaccines against the sars-cov-2. cepi and\\nglaxosmithkline (gsk) announced a new partnership on\\n3 february 2020, which will see gsk make its existing\\nadjuvant technology available to the cepi [93]. on 11 febru-\\nary 2020, cepi struck a partnership with the international\\nvaccine institute (ivi), an international organization based in\\nthe republic of korea, which shares its vision of a covid-19\\nfree world. under the terms of this partnership, the ivi\\nwill render its technical expertise in the cepi-sponsored\\nprojects in exchange for which it will receive funding from\\nthe cepi [94]. in addition to the partnership efforts, the cepi\\nhas pledged initial funding to various institutes, including the\\nuniversity of queensland, university of hong kong (hku),\\nuniversity of oxford, and the pasteur institute, to accelerate\\nthe development of effective vaccines against sars-cov-2.\\nto date, the cepi has invested a sum of 29.2 million us\\ndollars in the r&d of various covid-19 vaccines [95].\\nalthough researchers around the world are making deter-\\nmined attempts to come up with a vaccine for the extirpation\\nof the covid-19, the imminent arrival of an effective vac-\\ncine seems implausible. two main reasons for the same are\\nmentioned belowv\\ni) in the last two coronavirus outbreaks, namely sars\\nand mers, it was observed that once the vaccine was\\nadministered to an individual, there was a suddenincrease in his/her immune response (cytokine bursts).\\ncytokine bursts often lead to acute respiratory distress\\nsyndrome (ards), which is considered to be the leading\\ncause of death in covid-19 patients. to avoid such\\ncomplications and to ensure that the vaccines currently\\nin development do not prove to be counter-effective later,\\nit is necessary to certify that these vaccines have a good\\nsafety pro\\x1cle.\\nii) sometimes, a single dose of vaccine is not suf\\x1ccient to\\ndevelop suf\\x1ccient antibodies. for example, the hepatitis\\nb vaccine is given in 3 doses, each of them months apart.\\nonce identi\\x1ced, the need for wide-scale production of\\nthe covid-19 vaccine to meet world requirements is\\nanticipated to take much time. adding to that, if multiple\\ndoses across several months are required, it will take\\nan even longer time before we can rely on vaccines for\\nbringing the covid-19 pandemic to an end.\\nb. potential drugs for treatment\\nmany pharmaceutical companies have come up with potential\\ndrugs as solutions to treat the coronavirus disease. while no\\ndrug is globally approved as of yet, several of these drugs\\nare being tried out, with some of them in various phases of\\nclinical trials (refer to table 7). as of 29 april 2020, more\\nthan 1800 clinical trials worldwide are listed on the who's\\ninternational clinical trials registry platform (ictrp) [96].\\namong the drugs being tested, remdesivir, hydroxychloro-\\nquine, and arbidol have shown immense promise, and are\\nalready undergoing clinical trials at several hospitals across\\nthe world [97], [98]. earlier in 2008, arbidol was shown\\nto have promising results against the pathogens of the\\nsars-cov virus in cellular models [99]. it was also proven\\nto be effective against in\\x1duenza type a and b viruses, as well\\nas the hepatitis type c virus [100].\\nvolume 8, 2020 90237\",\n",
       " 'v. chamola et al.: comprehensive review of the covid-19 pandemic\\nanother drug that has emerged as a candidate to treat the\\ncovid-19 is the shuang-huang-lian (shl), a well known\\ntraditional chinese drug used to treat various bacterial and\\nviral infections. chinese researchers have reported that shl\\noral liquid may have inhibitory properties against the sars-\\ncov-2 virus due to the presence of baicalin, chlorogenic acid,\\nand forsythin, which are known to have inhibitory effects\\nagainst multiple pathogenic viruses [101], [102]. it is impor-\\ntant to note, however, that currently there is no conclusive\\nevidence backing the use of shl oral liquid as a treatment\\nfor the covid-19.\\nalthough various attempts are being made to develop\\nef\\x1ccient treatment strategies against the covid-19, a com-\\nmercially viable vaccine might not be possible for at least\\nanother year. therefore, the best way to keep the disease from\\nspreading any further is to limit the exposure of non-infected\\nindividuals to infected individuals. in the following section,\\nwe discuss the various preventive measures suggested by the\\nwho and the cdc against the covid-19 [103], [104].\\nviii. preventive measures\\nas the world continues to suffer from the covid-19 health\\ncrisis, it is essential to follow effective preventive measures\\n(fig. 6) to minimize the likelihood of becoming another\\ncasualty. if individuals and communities comply with the\\npractices mentioned below, the world may soon witness a \\x1dat-\\ntened covid-19 curve. flattening the curve implies bringing\\ndown the spread of the covid-19 to the extent where avail-\\nable healthcare facilities can suf\\x1cciently handle the impact of\\nthe disease.\\ni) clean your hands frequently with an alcohol-based hand\\nsanitizer or wash them thoroughly with soap and water.\\nii) practice social distancing - seek to keep yourself at a\\ndistance of at least 1 meter (3 feet) from others.\\niii) stay at home unless absolutely necessary to go out.\\nindividuals above 60, people with underlying health con-\\nditions, and pregnant women are especially advised to\\nstay away from all social interactions.\\niv) avoid touching your eyes, nose, and mouth without\\nthoroughly cleansing your hands.\\nv) frequently touched surfaces, such as doorknobs, desks,\\nphones, light switches, and laptops should be routinely\\ndisinfected.\\nvi) cover your coughs & sneezes with a cloth, handkerchief,\\nor a tissue. if none of these are readily available, cough-\\ning/sneezing into your elbow pit is advisable.\\nvii) it is advisable to wear masks around other people. how-\\never, care should be taken to ensure their proper dis-\\nposal [105].\\nthe rapid outbreak of the covid-19 has placed sincere\\nemphasis on the need to follow good practices in daily life,\\nlike washing hands, taking regular baths, improving eating\\nhabits, and much more. it is important to note that good\\nhygiene practices and eating habits should be followed, not\\njust during the covid-19 pandemic, but also after it.ix. emerging technologies for mitigating the\\nimpact of the covid-19 pandemic\\nas the novel coronavirus continues its onslaught across the\\nglobe, the world is reeling under the weight of crashing\\neconomies and piling casualties. unfortunately, billions of\\npeople are still under a constant threat of infection, with the\\nsituation not likely to get any better in the coming days. how-\\never, a multitude of technological approaches are emerging to\\ndeal with the impacts of the covid-19 pandemic. among\\nthem, digital technologies, including iot, ai, blockchain,\\nand next-generation telecommunication networks like 5g,\\nhave been at the forefront [106]. according to the who\\nand the cdc, digital technologies can play an essential\\nrole in improving public health response to the covid-19\\npandemic [107]. in the following sections, we explore the\\nef\\x1ccacy of the aforementioned technologies in allaying the\\ndisastrous impacts of the covid-19 pandemic.\\nx. iot & iomt\\nthe internet of medical things (iomt), also referred to as\\nthe healthcare iot, is an amalgamation of medical devices\\nand software applications offering extensive healthcare ser-\\nvices, that are connected to the healthcare it systems (refer\\nto fig. 7). in recent times, much like the iot, iomt has\\nwitnessed a surge in the number of its potential applica-\\ntions [108]. this surge is attributed to the fact that an\\nincreasing number of mobile devices are now equipped with\\nnear field communication (nfc) readers that allow these\\ndevices to interact with it systems [109]. applications of\\niomt include 1) monitoring patients from a remote loca-\\ntion, 2) tracking medication orders, and 3) using wearables\\nto transmit health information to the concerned health care\\nprofessionals.\\nowing to their ability to collect, analyze, and transmit\\nhealth data ef\\x1cciently, the health care sector has realized the\\ntransformative potential of iomt technologies [110], [111].\\namid the ongoing covid-19 pandemic, several innovators,\\nmedical organizations, and government bodies are looking\\nto leverage iomt tools in order to reduce the burden on the\\nhealthcare systems. in the following few sections, we explore\\nvarious iot & iomt technologies that have made a sizable\\ncontribution in monitoring, and consequently, managing the\\nimpact of the covid-19 pandemic.\\na. smart thermometers\\neight years ago, a us health technology company named\\nkinsa had launched internet-connected thermometers to\\nscreen people for high fevers. although these thermometers\\nwere initially developed to track the common \\x1du, they are,\\nnevertheless, proving to be highly useful in identifying the\\npotential covid-19 clusters throughout the usa. following\\nthe covid-19 outbreak, kinsa health has deployed more\\nthan a million smart thermometers to households in various\\ncities of the usa. these thermometers are linked to a mobile\\napplication, which allows them to transmit their readings\\nto the company immediately. once received, this data is\\n90238 volume 8, 2020',\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 7. iomt.\\nassimilated by kinsa to generate daily maps showing which\\nof the us regions are witnessing an increase in high fevers,\\nthereby allowing the us authorities to identify potential\\nhotspots. in the past few years, kinsa's interactive maps have\\nproven to be highly accurate in the timely prediction of the\\nspread of \\x1du around the us, outdoing even the cdc's of\\x1ccial\\napp in terms of the promptness of prediction [112].\\nb. iot buttons\\nto maintain high cleaning standards and limit the number\\nof hospital-acquired infections (hais), several hospitals in\\nvancouver have installed battery-operated iot buttons [113].\\nthese buttons, named wanda quicktouch, were designed for\\nrapid deployment in any facility, irrespective of their size,\\nin order to issue prompt alerts to the management, warning\\nthem of any sanitation or maintenance issue that may pose a\\nrisk to public safety. a remarkable feature of these buttons is\\ntheir independence on external infrastructure, i.e., their ability\\nto stick to any given surface [114].\\nc. telemedicine\\nthe practice of using iomt technologies to facilitate remote\\npatient monitoring is called telemedicine. also known\\nas telehealth, this practice allows clinicians to evaluate,\\ndiagnose, and treat patients without needing any physi-\\ncal interaction with them [115]. following the outbreak\\nof the highly contagious covid-19, several iomt tech\\nand telemedicine platforms have faced a rapid surge in\\ntraf\\x1cc. recently, jd health, an e-commerce platform for\\nhealthcare solutions, has reported witnessing a considerable\\nrise in demand for online consultations since the outbreak\\nof the covid-19 [116]. in the usa, the of\\x1cce of civil\\nrights (ocr) and the centers for medicare and medicaid\\nservices (cms) have waived certain medicare rules for\\nallowing doctors to provide their patients with remote med-\\nical expertise via telehealth platforms [117]. following the\\nrelaxations in these regulations, a texas-based multinational\\ntelemedicine company, teladoc health, has reported an enor-\\nmous increase in demand for its telemedicine solutions. this\\nsurge in demand has prompted its share prices to rise by more\\nthan a 100% in a span of few weeks [118].the bene\\x1cts of adopting telehealth techniques have been\\ntwofold: 1) it has lessened the burden on the overworked\\nhospital staff, 2) it has reduced the risk of emanation of the\\nvirus from the infected individuals to the healthcare person-\\nnel. mentioned below are some ways in which telemedicine\\nplatforms are being used around the world to manage the\\nimpact of covid-19:\\n\\x0fin the usa, the george washington university hospi-\\ntal (gwuh) has adopted the use of several telemedicine\\nstrategies, including video consultations and live face-\\nbook webinars to provide remote medical expertise to\\nseveral people [119].\\n\\x0fanother university hospital in the usa, the rush\\nuniversity medical center, has adopted the use of\\ntelemedicine platforms to facilitate on-demand video\\nconsultations. however, the health professionals at the\\nrush university medical center are using such consul-\\ntations not only to provide medical expertise to people\\nbut also to screen them for the covid-19 [120].\\n\\x0fin india, the state governments of andhra pradesh and\\nassam have rolled out telemedicine facilities to enable\\nremote interaction of potential covid-19 patients with\\nmedical experts [121], [122].\\n\\x0fin israel's largest hospital, the sheba medical center,\\nseveral telehealth technologies were used to monitor\\n12 israeli passengers that were on board the cruise\\nship quarantined in japan for several weeks. how-\\never, the sheba medical center employed the use of\\ntelemedicine strategies not to treat these passengers\\nremotely, but to ensure minimal human contact while\\ntreating them within the hospital premises. [123], [124].\\nin the past few months, several telemedicine tools like\\ntelemedicine carts, teleconsultation software, and portable\\ntablets have proved their merit in the \\x1cght against the\\ncovid-19 pandemic. however, the true potential of\\ntelemedicine can only be realized when existing telemedicine\\nplatforms are used in conjunction with other technologies\\nsuch as drones, robots, smart wearables, and next-generation\\n5g cellular networks (refer fig. 8). the consolidation of these\\ntechnologies with existing telehealth platforms can allow for\\na more dynamic healthcare ecosystem that can enable remote\\nmonitoring and distant clinical care of patients with mild\\ncases of covid-19.\\nthe wide range of use cases presented above indicates the\\npotential of iot & iomt in solving the unprecedented chal-\\nlenges posed by the covid-19. however, the tools discussed\\nabove form a small subset of the much larger domain that is\\niot. in the four sections that follow, we thoroughly dissect\\nfour prominent technologies linked to iot that have had a\\nwide-ranging impact in the battle against covid-19, namely,\\ndrone technology, robots, wearables, and apps.\\nxi. drone technology\\nduring the times of a public health emergency, such as the\\ncovid-19 pandemic, ua vs, i.e., drones, can offer many\\nvolume 8, 2020 90239\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 8. various technologies enabling telemedicine.\\nadvantages. not only can they ensure minimized human\\ninteraction, but they can also be used to reach otherwise\\ninaccessible areas. china, the \\x1crst country to face the wrath\\nof the covid-19, has made great use of drone technology to\\ncounter the covid-19 outbreak. taking that as inspiration,\\nseveral countries around the world have joined forces with\\nnumerous researchers and innovators in an attempt to \\x1cnd\\ningenious ways of using drones to \\x1cght the covid-19 (refer\\nto fig. 9). in this section, we explore the numerous bene\\x1cts\\nthat drones can provide in terms of managing the covid-19\\npandemic or any other future outbreak.\\na. crowd surveillance\\nto contain the spread of the covid-19, governments around\\nthe world are taking all the necessary steps to ensure social\\ndistancing. to this end, many countries around the world,\\nincluding china and india, have adopted the drone technol-\\nogy for crowd surveillance.\\nmicromulticopter, a leading industrial drone manufac-\\nturer based out of shenzhen in china, has deployed over\\n100 drones in several cities of china in an attempt to sur-\\nvey areas and observe crowds ef\\x1cciently [125]. the drones,\\nequipped with sky speakers, can also be used to give instruc-\\ntions to people not in compliance with the guidelines issued\\nby the chinese government.\\nin india, a global technology solutions company named\\ncyient has provided the telangana police with unmanned\\naerial spectrum monitoring technology to help manage thecovid-19 lockdown. the drones deployed are equipped\\nwith surveillance cameras that can effectively monitor sen-\\nsitive areas in the city and allow the police to handle any\\nunwarranted situation promptly [126].\\nb. public announcements\\nin addition to crowd surveillance, drones can prove to be\\nhighly useful for broadcasting important information, par-\\nticularly in areas that lack open channels for communica-\\ntion. the police authority in madrid, spain, used a drone\\nequipped with a loudspeaker to inform people of the guide-\\nlines put in place regarding the state of emergency that was\\nimposed [127]. additionally, several other european coun-\\ntries have regularly used drones to make public announce-\\nments emploring people to practice social distancing norms\\nand taking other necessary precautions to limit the spread of\\nthe disease [128].\\nc. screening masses\\nfollowing the outbreak of the covid-19, several authorities\\nin china committed themselves to detect covid-19 patients\\nas soon as possible. they employed the use of drones\\nequipped with infrared cameras to carry out large-scale tem-\\nperature measurements in several residential areas [128].\\nin india, the authorities in new delhi have employed\\nthe use of a multipurpose drone to contain the spread of\\nthe covid-19. dubbed the ``corona combat'' drone, it is\\nequipped with a thermal camera for screening individuals,\\n90240 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 9. uavs for covid-19 impact management.\\na night vision camera for monitoring the crowd, a portable\\nmedical box for carrying essential medical supplies, a loud-\\nspeaker for making announcements, and a disinfectant\\ntank with a capacity of 10 liters for sanitizing public\\nspaces [129]. unlike the infrared thermometers that can mea-\\nsure the temperature of one person at a time, this drone\\ncan be used to measure the temperature of multiple people\\nsimultaneously [130].\\nin addition to these efforts, researchers at the university\\nof south australia, in association with the canada-based\\ncommercial ua v manufacturer draganfly, are in the process\\nof developing a ``pandemic drone'' to remotely observe and\\nidentify people with infectious respiratory in\\x1crmities. these\\ndrones are to be installed with a specialized sensor and com-\\nputer vision system that can monitor people's temperature\\nand heart rates [131]. these drones are also expected to\\nhave the ability to detect people sneezing and coughing in\\npublic spaces. if successful, these drones have the potential\\nto revolutionize covid-19 diagnostics by early detection of\\npotential covid-19 patients.\\nd. spraying disinfectants\\nin the face of the covid-19 pandemic, drones can be used\\nto enter contaminated regions and spray disinfectants. thiscan minimize the risk of further spread of the disease while\\nalso reducing the exposure of frontline workers to the virus.\\nwhile china and india have routinely used drones for this\\npractice since the onset of the covid-19 outbreak, spain\\nhas become the \\x1crst european country to deploy drones for\\npandemic management. the spanish military has recently\\nadopted the use of agricultural drones made by dji, a leading\\nchinese drone manufacturer, to spray disinfecting chemicals\\nover public spaces [132]. as per dji's claims, the drones have\\na load capacity of 16 liters and can disinfect one-tenth of a\\nkilometer in an hour [128].\\ne. delivery of medical supplies and other\\nessentials\\nin september 2019, researchers from the national university\\nof ireland (nui) were able to use a ua v to deliver diabetes\\nmedication from galway to a remote location in the aran\\nislands. this was the \\x1crst successful beyond visual line\\nof sight (bvlos) diabetes drone mission, and it showed\\nthe world how drones have the capability to carry medical\\nsupplies reliably [133]. in the current state of crisis, this func-\\ntionality can prove to be particularly valuable to reduce the\\nburden on the hospitals and health care staff. drones can be\\nused for the rapid delivery of medicines and supplies 1) from\\nvolume 8, 2020 90241\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\none medical facility to another or, 2) from medical centers\\nto the covid-19 patients being cared for in their homes (in\\ncase of a mild form of the covid-19) [134]. an example of\\nthe former was seen in china when a drone was used to move\\nmedical supplies from the disease control center in xinchang\\ncounty to the people's hospital in xinchang county without\\nexposing humans to infection [135].\\nmarut drones, a hyderabad-based startup led by a team\\nof indian institute of technology (iit) alumni, recently\\nlaunched an entire line of drones to combat the covid-19\\npandemic in india. the company has drones for sanitizing,\\nmedicine delivery, thermal analysis, movement monitoring,\\nand crowd surveillance in its arsenal of drones to combat\\nthe covid-19 pandemic. the company claims that their\\nmedical delivery drones, equipped with obstacle avoidance\\nand advanced navigation technology, can cover a distance\\nof 12 kilometers in merely 8 minutes, thereby ensuring med-\\nical deliveries 80 times faster than the conventional meth-\\nods [136]. marut drones has already offered a few drones\\nto various authorities in telangana to monitor crowds and\\ndisinfect public places [137], [138]. as per the company's\\nestimates, their disinfectant drones have already disinfected\\nareas covering more than 1900 km [136]. pending approval\\nfrom the government of india (goi), the company also hopes\\nto deploy its delivery drones soon [137].\\nin the usa, following the devastating impact of the\\ncovid-19, various steps are being taken by different us\\nbodies to introduce drone technology in the country. the\\nsmall ua v coalition has \\x1cled a petition for expedited\\nfederal aviation administration (faa) approvals to allow\\nthe use of drones for delivering medical supplies. fur-\\nthermore, zipline, a medical product delivery company,\\nis planning to establish an active medical supply delivery\\nnetwork. by delivering urgent medication directly to people's\\ndoorsteps, zipline hopes to reduce the burden on delivery per-\\nsonnel while also promoting the practice of social distancing\\namong people [134].\\napart from being a safe way for delivery of medical sup-\\nplies, drones can facilitate the delivery of groceries, as wit-\\nnessed in some parts of australia, china, and the usa [128].\\nin china, the e-commerce giant jd.com has started using\\na few of its drones to make last-mile deliveries of essen-\\ntial goods [139]. meanwhile, in the usa, google's parent\\ncompany - alphabet, has recorded a considerable increase in\\nthe number of deliveries made using its autonomous drone\\ndelivery services known as wing.\\nf. challenges\\ndespite the numerous bene\\x1cts that ua vs can provide in\\nresponse to health crises like the covid-19 pandemic,\\nthe use of drone technology is confronted by certain chal-\\nlenges and limitations.\\n1) the integration of ua vs in the covid-19 impact\\nresponse system in many countries is limited by the lack\\nof clear government regulatory policies.2) vulnerabilities in drone operations, such as gps-\\njamming and hacking, make drones an attractive\\nprospect for malicious users to conduct cyberterrorism\\nand other unlawful activities. in recent times, many\\nlaw-enforcement agencies have voiced their concerns\\nabout the security risks posed by drones.\\n3) although considerable strides have been made in the\\nadvancement of drone technology in recent years,\\nbeyond visible line of sight (bvlos) drone opera-\\ntions remain somewhat unsafe. there is a growing need\\nfor technological and operational guidelines to warrant\\nthe safe operations of ua vs, and consequently, to reap\\ntheir comprehensive societal bene\\x1cts.\\n4) at present, ua vs face several constraints in terms of bat-\\ntery life and load capacity, which inhibits their capability\\nto cover long distances and make multiple deliveries at\\nonce.\\nwhile a few challenges plague the wide-scale use of drone\\ntechnology, the great promise that it holds in regards to\\nhealthcare support cannot be overlooked. even then, many\\ncountries have not yet adopted the use of ua vs in the \\x1cght\\nagainst the covid-19 pandemic. to this end, government\\nauthorities should carefully collect and assess data in regards\\nto existing ua v projects and put more effort into ua v\\nresearch and development.\\nxii. robots & autonomous vehicles\\nmuch like drone technology, other autonomous technologies\\nlike robots and autonomous vehicles (a vs) have made great\\nstrides in the \\x1cght against the covid-19 pandemic. in this\\nsection, we discuss how authorities around the world have\\nemployed the use of these autonomous technologies to miti-\\ngate the impact of the covid-19 pandemic.\\na. robots\\nas governments and medical organizations around the world\\nstruggle to contain the spread of the covid-19, robots are\\nbeing deployed to assist in the treatment of patients, and\\nconsequently, alleviating the stress levels of the healthcare\\nworkers. additionally, robot-controlled noncontact ultra-\\nviolet (uv) surface disinfection methods are also being\\nemployed to limit the transfer of the disease via contami-\\nnated surfaces. compared to the practice of manual decon-\\ntamination, which involves the deployment of cleaning staff\\nand subsequently puts them at risk of contracting the virus,\\nautonomous disinfection robots ensure rapid and effective\\ndisinfection of the premises, with little to no human con-\\ntact [140]. presented below are a few examples of how\\nrobots are being used in hospitals around the world to aid in\\ncovid-19 impact management.\\n\\x0fin india, a kerala-based startup named asimov robotics\\nhas developed a three-wheeled robot that can be used to\\nassist patients residing in isolation wards. the robot is\\ncapable of doing tasks like serving food to the patients as\\nwell as giving them medication, thereby reducing some\\n90242 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nburden on the healthcare workers, and freeing them from\\nthe risk of contracting the infection.\\n\\x0fxenex disinfection services, a company established\\nby two john hopkins educated epidemiologists, has\\ndeveloped an autonomous disinfection robot to help\\nlimit the number of hospital-acquired infections (hais).\\nxenex asserts that their uv lightstrike germ-zapping\\nrobots have the potential to ef\\x1cciently obliterate all\\ntypes of germs, including various types of viruses and\\nbacteria [141]. xenex has reported witnessing an enor-\\nmous surge in demand for its uv germ-zapping robot,\\nespecially from countries like singapore, japan, south\\nkorea, and italy.\\n\\x0fa danish robotics company, uvd robots, has devel-\\noped multiple disinfection robots to be delivered in\\nhospitals around the world. to date, uvd robots has\\ndelivered its robots to several provinces in china, several\\nparts of asia, and healthcare markets in europe and the\\nunited states. these robots emit powerful uv light that\\ncan disinfect surfaces by tearing apart strands of virus'\\ndna. the danish company claims that their robots can\\noperate for about 2.5 hours and disinfect about nine or\\nten rooms on a single charge [142].\\naccording to a leading robotics expert from the carnegie\\nmellon university (cmu), in addition to the tasks mentioned\\nabove, robots with the potential to execute tasks like obtaining\\nnasal samples for testing, and rendering support to isolated\\npatients, may also be developed soon [143].\\nb. autonomous vehicles\\namid the global health crisis that is the covid-19 pandemic,\\na vs could help ease the stress on existing delivery mecha-\\nnisms while mitigating the risk of virus transmission [144].\\nchina has led the charge in the use of autonomous vehi-\\ncles (a vs) against the pandemic. in fact, at the time of writing,\\nit is believed to be the only country in the world to deploy a vs\\nfor covid-19 impact management. beijing-headquartered\\nwhite rhino auto company, in alliance with unido's\\ninvestment and technology promotion of\\x1cce (itpo), dis-\\npatched two autonomous delivery vehicles from beijing to\\nthe guanggu field hospital in the hubei province of china.\\nthese vehicles have proved to be highly useful for a variety\\nof tasks, such as delivering medical supplies and meals. the\\nuse of a vs not only lessened the workload on the overbur-\\ndened hospital staff, but it also helped in limiting the risk of\\ncross-infection [145].\\nxiii. wearables\\nwearables are communication enhancing devices worn on\\nthe body that are connected to an internet source. wearables\\nrange from smartwatches like apple watch, \\x1ctness trackers\\nlike fitbit, smart headbands like dreem, to personal sensors\\n& patches. the ability to monitor people's physical health,\\nalong with their stress levels, has made wearables an ideal\\ntechnology for adoption in the healthcare sector. in the midstof the current health crisis, various organizations have modi-\\n\\x1ced their existing offerings or rolled out new wearables to aid\\nin covid-19 impact management. some of these technolo-\\ngies have been discussed below:\\na. whoop strap 3.0\\na boston-based human performance technology start-up,\\nwhoop, has collaborated with a team of researchers at the\\ncentral queensland university (cquniversity) in australia\\nto examine a potential link between alterations in respiratory\\nrates and the covid-19 symptoms. the primary objective\\nof this study is to be able to develop a mechanism that can\\nidentify the covid-19, well during its incubation period,\\nby detecting early signs of abnormal respiratory behavior\\nin covid-19 patients. with a high reproductive number,\\na factor that has made the covid-19 outbreak so severe,\\nthis sort of an early-warning system can help slow the global\\nproliferation of the covid-19.\\nin association with the cleveland clinic, the researchers at\\ncquniversity's appleton institute plan to carry out a study\\nusing 24/7 physiological data, gathered via the wrist-mounted\\nwhoop strap 3.0, from hundreds of whoop members\\nwho have identi\\x1ced themselves as having the covid-19 and\\nvolunteered to be a part of the study [146]. by discerning\\nany deviation in respiratory rates of an individual from their\\nestablished baseline, the strap can notify that individual of\\nany issues that they might experience. this study will also\\ncollect data from the whoop journal, a recently launched\\nonline interface accessible from the members' smartphones\\nthat enables them to monitor their daily behavior and make\\nhealthier lifestyle choices.\\nalthough a few watches from garmin and fitbit also have\\nthe functionality to measure respiratory rates [146], whoop\\nclaims to be the only wearable to have its accuracy of mea-\\nsuring cardiorespiratory variables validated by a third-party\\nstudy [147].\\nb. estimote workplace level contact tracing\\nwearable\\nestimote, a start-up known for its bluetooth location bea-\\ncons, has recently developed a set of wearable devices to\\nenable contact tracing at the workplace, in an attempt to\\nprovide employees with a safer workplace environment. this\\nwearable device allows organization leaders to monitor the\\nhealth status of their employees remotely and to keep a\\nrecord of any case of covid-19 transmission amongst them.\\nit empowers an organization's leaders to curb the disease\\nspread before it spreads rampantly within the organization\\nor even outside it [148]. when this device is turned on,\\nit scans for other wearable devices and records any close\\ninteractions with them. the devices' hardware includes a pas-\\nsive gps location-tracker in addition to bluetooth powered\\nproximity sensors, ultra-wideband connectivity, built-in lte,\\nand a rechargeable battery [149]. furthermore, every device\\nhas led indicators and buttons, just like a smartwatch. the\\npurpose of these buttons is to allow the employees to log\\nvolume 8, 2020 90243\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\ntheir real-time health status. for example, the wearer can\\nupdate his/her health status as certi\\x1ced healthy, symptomatic,\\nor veri\\x1ced infected. when the wearer updates his/her health\\nstatus, it is recorded in a central database that stores the\\ninformation for up to six weeks. there are three variants of\\nthese devices: a pebble-like device to be worn around the\\nneck, a wrist-worn version, and a device in the form of a card.\\nc. lifesignals biosensor patch\\na silicon valley start-up named lifesignals plans to launch a\\nnovel biosensor patch that leverages the cardiovascular moni-\\ntoring technique to assist early detection of the covid-19 in\\nan individual. this single-use, showerproof, and lightweight\\nwearable named biosensor patch1ax, when af\\x1cxed on the\\nchest area, can record the temperature of the person along\\nwith his/her respiration rate, ecg trace, and even the heart\\nrate in real-time. this data is automatically sent from the\\nuser's patch to an application on the user's smartphone,\\nenabling them to view their data in real-time [150]. in case\\na person using this patch develops covid-19 symptoms,\\nhis/her data can also be sent to a centralized and secure\\ncloud platform, alerting the healthcare workers of a potential\\ncovid-19 patient [151]. the patches have been designed in\\nsuch a way that it can be worn by an individual for \\x1cve days\\nin one go, post which they can be safely disposed to ensure\\nthat the disease does not spread from the patch.\\nlifesignals also plans to launch the second version of the\\npatch, biosensor patch 2a, in june. by storing and streaming\\nclinical-grade vital signs of a patient, the patch will enable the\\nhealthcare workers to monitor covid-19 patients admitted\\nto the intensive care units (icus) [151].\\nd. spry health's loop signal\\nspry health is a company that is known for its health\\nmanagement and telemedicine technologies. this company\\nhas launched a wearable device called loop signal to limit\\npatients from visiting hospitals unnecessarily, especially dur-\\ning such times. loop signal helps healthcare personnel to\\nremotely manage the health of people who have symptoms\\nof covid-19. worn on the wrist, loop signal tracks the\\nheart rate, respiratory rate, and pulse-oximetry of the patient.\\nall these parameters are critical to assess the severity of\\nthe covid-19 in a patient, and can, therefore, empower\\nhealthcare professionals to make an in-person visit only if\\nthe patient's condition warrants it. this easy-to-wear device\\nhelps in collecting hundreds of data points for a patient on a\\ndaily basis. the aggregation of a large number of data points\\nprovides a much-needed certainty about the present condition\\nof a patient, as opposed to a single data point that may even\\nbe an error, sometimes leading to false alarms [152].\\ne. sphcc with cassia and vivalnk\\nshanghai public health clinical centre (sphcc) has\\nemployed the use of bluetooth iot gateways developed\\nby cassi network, and wearable sensors developed by\\nvivalnk, to monitor covid-19 patients with minimalhuman contact. china has been successful in reducing the\\ncount of covid-19 thanks to the advent of such tech-\\nnologies. in the mechanism put in place by the sphcc,\\nvivalnk's wearable sensors constantly supply real-time data\\nabout the changes in the body temperature of the patient. cas-\\nsia's gateways then collate this data and transmit it wirelessly\\nto the healthcare staff's station. this enables \\x1crst-line health-\\ncare workers to keep track of their patients' health without\\nhaving to visit them personally. the cassia iot gateways\\nallow nearly 40 bluetooth low energy (ble) devices to\\nbe paired at the same time, thereby facilitating connectivity\\nbetween multiple rooms of the sphcc. the use of these\\ntechnologies in the sphcc has signi\\x1ccantly reduced the\\nhealthcare workers' risk of exposure to the infection while\\nalso ensuring reduced workload [153].\\nf. challenges\\nalthough wearables have played a signi\\x1ccant role in the\\n\\x1cght against the covid-19 pandemic, it is essential to note\\nthat certain challenges/limitations hinder the use of wearables\\namid the current health crisis.\\n1) due to lockdowns and interrupted supply chains, deliv-\\nery of these wearables is challenging in many parts of\\nthe words.\\n2) the battery life of smart wearables is usually in question.\\nthe tedious task of charging wearable devices again and\\nagain, often dissuades users from buying these devices\\naltogether.\\n3) there are no established guidelines about the use of the\\nprivate data accumulated using these wearables, which\\ngives rise to a multitude of security and privacy con-\\ncerns. it is necessary to ensure that the development\\nof such wearables is done while keeping in mind the\\nsecurity and privacy preservation of the users [154].\\nxiv. mobile applications & other platforms\\nthe use of mobile applications (commonly referred to as\\napps) has emerged as a prominent strategy in the \\x1cght\\nagainst the covid-19. several governments and private\\norganizations around the world have already developed cer-\\ntain apps and platforms for covid-19 impact management,\\nwhile several others are in the process of doing so. most of\\nthese modern platforms use a wide variety of technologies,\\nincluding bluetooth, global positioning system (gps), and\\ngeographic information system (gis). certain apps have\\nalso adopted the use of blockchain, an emerging technology\\nthat helps in storing data in the form of immutable blocks.\\ntable 10 lists the key technologies being used to develop\\ncontact tracing applications [155]. in this section, we discuss\\na few of the numerous applications that have emerged in the\\nlast few months for combating the covid-19 crisis.\\na. blockchain\\na blockchain is a continuously expanding record of transac-\\ntions between two parties [156]. such records can be used\\n90244 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 10. contact tracing applications for covid-19.\\nto verify the claims of a party that a transaction has indeed\\nhappened. blockchain is gaining more and more prominence\\neach day thanks to its wide applications in various walks\\nof life [157]. seeing its utility, numerous companies and\\nauthorities across the globe have started using blockchain to\\nbuild apps that can help in countering the covid-19. these\\napps aim to address a crucial problem, which is the lack of\\nintegration of veri\\x1ced data sources. according to experts, one\\nof the main advantages of using blockchain-enabled apps is\\nblockchain's capability of validating continuously changing\\ndata. this feature can prove to be quite valuable in man-\\naging the rapidly escalating covid-19 situation. discussed\\nbelow are two blockchain-based applications, developed in\\nan attempt to help \\x1cght the covid-19 pandemic:\\n1) civitas\\na canadian start-up specializing in blockchain solutions has\\nrecently launched a safety system, in the form of an app,\\nknown as civitas, that may assist local authorities in various\\nnations of the world to control the impact of the covid-\\n19. this app associates people's of\\x1ccial ids with blockchain\\nrecords to verify whether the person has permission to leave\\ntheir homes or not. this app also determines the ideal timeand day for people exhibiting the covid-19 symptoms to\\ngo out and buy essential items, thereby minimizing the risk\\nof infecting others. additionally, civitas offers a built-in\\ntelemedicine functionality that allows doctors to keep track\\nof their patients' symptoms and send them notes in regards\\nto the medicines to be used and healthcare strategies to be\\nfollowed. as per the company's claims, the app makes sure\\nthat people's data remains private and secure [158].\\n2) mipasa\\nmipasa is a data streaming platform built on top of the\\nhyperledger fabric. this platform also draws on the services\\nprovided by the ibm blockchain & the ibm cloud platforms,\\nto facilitate the sharing of veri\\x1ced health and location infor-\\nmation among individuals, authorities, and hospitals. this\\napplication works by collecting the information provided by\\nvarious medical organizations, public health of\\x1ccials, and\\nother individuals. the who recently acknowledged this\\napp to be an effective platform for helping the doctors gain\\naccess to veri\\x1cable information. the data available on this\\nplatform can help the hospitals to determine their future\\naction plans and to ef\\x1cciently allocate their resources to\\nalleviate the impact of the covid-19 outbreak [159].\\nvolume 8, 2020 90245\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nb. geographic information system (gis)\\nunderstanding the geography of the spread of the\\ncovid-19 is crucial to comprehend the severity of the crisis\\nin a particular region, and to deploy appropriate measures\\nto mitigate the impact of the disease in that region. to this\\nend, the gis systems use spatial analytics, mapping, and\\nlocation intelligence to map the occurrence of the diseases\\nagainst multiple parameters such as demographics, envi-\\nronment, and past occurrences. this kind of data will help\\n1) epidemiologists to understand the origins of the outbreak\\nand, 2) governments to identify high-risk areas and deploy\\nhealthcare facilities accordingly.\\n1) esri arcgis application\\ncalifornia-based environment systems research insi-\\ntute (esri) is an international provider of gis software,\\nwhose product line includes arcgis desktop, arcgis pro,\\narcgis enterprise, among others. following the outbreak\\nof the covid-19, the esri has partnered with several pri-\\nvate organizations around the world to launch the ``esri\\ncovid-19 resources and gis hub'', featuring a compila-\\ntion of datasets, dashboards, applications, and other helpful\\nresources to facilitate adequate planning against the pan-\\ndemic. additionally, esri has joined forces with various\\ngovernment agencies around the world to help them exploit\\ngis technology for taking proactive measures to manage the\\ncovid-19 spread [160].\\nc. bluetooth\\nbluetooth is one of the most useful technologies used for\\naccurate proximity calculation. it is also one of the least\\ninvasive technologies since it does not monitor the exact\\nlocation of a cell user but rather the relative distance between\\nhis device and that of another. bluetooth contact tracing\\napplications generally monitor the proximity between two\\npeople by calculating the distance between their devices using\\nthe received signal strength indicator (rssi) measure. such\\napps store records of all of a device's prior bluetooth connec-\\ntions, including the time for which it maintained a bluetooth\\nconnection with another device. in case a person is diagnosed\\nwith the covid-19, these apps can leverage the bluetooth\\nconnection history of that device to trace all the people who\\nhad exposure to the infected individual. these apps can make\\nit simpler for the authorities to effectively determine potential\\ncovid-19 patients and use appropriate measures to quaran-\\ntine them. some of the apps that use the bluetooth technology\\nfor contact tracing are mentioned below:\\n1) tracetogether\\ntracetogether is a contact tracing app launched by the gov-\\nernment of singapore, which uses bluetooth technology to\\ndetermine the history of exposure of an unaffected indi-\\nvidual to an infected one. whenever two people with this\\nmobile application come into close contact with each other,\\nan encrypted code is transferred between their devices andstored in their apps, provided that bluetooth is turned on in\\nboth the devices. if a person with this app is later diagnosed\\nwith the covid-19, the authorities can check the records\\nstored in his/her app to trace all the people who had come into\\nclose contact with the infected person. this app does not use\\ngps to pinpoint a user's location, thereby allaying the fears\\nof those people who are worried about their privacy. as on\\n1 april 2020, nearly 1 million downloads were recorded for\\nthis app, which incidentally is a record for the highest number\\nof downloads for an application hosted by a government\\nwebsite in singapore [161]. however, this number is still not\\nconsidered to be enough by the government of singapore as\\nthe reliable functioning of this application requires participa-\\ntion from everyone in the country, and 1 million corresponds\\nto just one-sixth of singapore's entire population.\\n2) apple & google's joint contact tracing\\ntechnology\\nin light of the current health crisis, two silicon valley tech\\ngiants, apple and google, have teamed up for a rare joint ven-\\nture to help governments and medical organizations around\\nthe world in their \\x1cght against the covid-19. they plan\\nto develop a privacy-preserving framework that incorporates\\n``application programming interfaces (apis) and operating\\nsystem-level technology'' to assist public contact tracing\\napplications [162]. in a bid to safeguard user's privacy,\\nthe framework is set to use only the bluetooth technology for\\ntracking the spread of the covid-19. furthermore, the two\\ncompanies claim that data from the user's smartphone will\\nnot be made available to anyone without the user's consent.\\ntheir framework will enable contact tracing applications to\\nuse bluetooth low energy (ble) technology to log people's\\ninteractions and keep track of whether a smartphone owner\\nhas come into contact with someone who is later diagnosed\\nto be covid-19 positive. if indeed, this scenario takes place,\\nthe user is sent an alert stating that he/she has come into\\ncontact with someone who is now diagnosed with the dis-\\nease. once alerted, such users can then self-isolate or get\\nthemselves tested. at present, the framework is still in the\\ndevelopment stages, with the api expected to be launched\\nin may, while the os-level technology to be rolled out in\\nthe following months. the draft technical documentation\\nfor the framework can be found in [163], and the overview\\nof the api's working can be found in [164].\\nd. gps\\nglobal positioning system (gps) is a satellite navigation\\nsystem owned and maintained by the united states govern-\\nment that provides users with positioning, navigation, and\\ntiming (pnt) services [170]. by leveraging this technol-\\nogy, government authorities around the world can monitor\\nthe real-time location as well as the historical location of\\ncovid-19 positive patients in their country, which can sub-\\nsequently enable them to trace other potential covid-19\\npatients. mentioned below are of\\x1ccial contact-tracing apps\\nof two countries that make use of the gps technology:\\n90246 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\ntable 8. challenges associated with the implementation of various technologies in mobile applications.\\n1) aarogya setu app\\nthe national informatics centre, a subdivision of india's\\nministry of electronics and it (meity), has recently devel-\\noped a contact tracing app called aarogya setu to help curb\\nthe spread of the covid-19 in india. any indian citizen can\\ndownload this application for free and register using their\\nmobile number to use this app's services. on launching this\\napplication, it asks the user if they are facing any symptoms\\nof the covid-19, or, if they have an international travel\\nhistory; if not, the user is classi\\x1ced as belonging to the\\ngreen zone. this application currently supports 11 indian lan-\\nguages and is available for both ios and android users [171].\\nunlike tracetogether, this app uses the gps location of the\\ncellphone user in addition to the bluetooth technology to\\ndetermine if an individual has been exposed to any potential\\ncovid-19 patient listed in its database [172]. in a scenario\\nthat an individual belonging to the green zone comes in\\ncontact with someone who is later marked as belonging to thered zone, this app immediately sends an alert to the former,\\nnotifying him/her of the guidelines that he/she should follow.\\nadditionally, this app provides its users with easy access to\\nrelevant information [172]. on its release, the aarogya setu\\napp became instantly popular among the indian public. the\\napp garnered over 10 million downloads in just \\x1cve days of\\nits launch. in response to the privacy concerns surrounding\\nthe app's use of gps technology [173], the government of\\nindia (goi) has assured its citizens that the data which the\\napp collects is encrypted and will not be used for any purpose\\nbesides contact tracing.\\n2) hamagen app\\na contact-tracing app called hamagen launched recently by\\nisrael's health ministry, has sparked massive interest from\\nthe governments of italy, australia, and germany, among\\nothers. hamagen makes use of the gps technology to deter-\\nmine if any app user has come in contact with someone\\nvolume 8, 2020 90247\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nwho has been tested positive for the disease. quashing\\nthe rumors surrounding the application's privacy pitfalls,\\nthe health ministry has issued a statement maintaining that\\nany user's private data does not leave the phone without\\nhis/her consent. the app's functioning relies heavily on the\\nuser's self-reported information regarding their exposure to\\nthe covid-19. within the \\x1crst week of the app launch,\\naround 50,000 app users claimed that they had adopted the\\nmeasure of self-isolation [174].\\ne. voice detection\\nfollowing the covid-19 outbreak, several voice-detection\\napps have been developed for covid-19 screening. voice\\ndetection applications require users to voluntarily provide a\\nsample of their voice, based on which the app decides whether\\nor not a person has symptoms of the covid-19. two promi-\\nnent attempts at developing such voice detection platforms\\nfor covid-19 screening have been discussed belowv\\n\\x0fan automated ai system has been designed by a team of\\nresearchers from carnegie mellon university to detect\\nthe presence of the covid-19 in an individual based\\non his/her voice. after logging in to the app, a user is\\nasked for his height and weight, followed by a request\\nto cough three times. post this, he/she is asked to recite\\nan alphabet and a vowel loudly, which \\x1cnally helps\\nthe app in measuring the lung capacity of the user\\nby comparing it with thousand's of other users' data,\\nincluding those who are infected [169]. by the end of\\nthis brief process, the user is given a score out of 10.\\na higher score indicates that a user's features are highly\\nsimilar to the features exhibited by covid-19 patients.\\nthe researchers, however, have added a word of caution\\nstating that this is not a diagnostic process and can never\\nbe substituted for tests conducted in the hospitals and the\\nlaboratories [175].\\n\\x0fa similar mobile application for voice-based\\ncovid-19 diagnosis has also been developed by stu-\\ndents of the dy patil institute of bio-technology and\\nbio informatics, mumbai, india [176]. this app is\\ncurrently being tested at the university of tor vergata\\nin rome, italy. to use the app, one has to speak into\\nthe microphone of his/her device, following which the\\napp breaks the sound into multiple parameters, including\\nfrequency and noise distortion. the values of these\\nparameters are then compared to an average person's\\nparameter values to determine if an individual is poten-\\ntially infected with the covid-19 [177].\\nf. challenges\\nalthough many people have hailed the efforts made by\\nvarious governments and organizations in building contact\\ntracing apps [178], a school of thought exists that believes\\nthat contact tracing applications, even the ones that claim\\nto respect user's privacy, are not secure and can blatantly\\nabuse the privacy of people [179]\\x15[182]. in addition to theprivacy concerns associated with the use of contact tracing\\napps, several issues in terms of accuracy and reliability also\\nimpede their performance (refer to table 8).\\nit has become quite evident that the covid-19 is here to\\nstay unless adequate measures are taken to \\x1cght it effectively.\\ngovernments and health of\\x1ccials alone cannot vanquish the\\ncurrent health crisis. people around the world need to work\\ncollectively with their governments to expedite the end of\\nthis pandemic and get things back to normalcy. for example,\\nmost of the tools mentioned above require the support of\\nthe masses to yield fruitful results. the mere presence of\\ntechnologies such as smart thermometers and smart wear-\\nables is meaningless unless people are willing to use them\\nto \\x1cght covid-19. the use of telemedicine platforms is\\ninconsequential unless patients are willing to trust their health\\nexperts. even the most straightforward contact-tracing apps\\nare worthless unless people are willing to use them when they\\nventure out of their homes. in the coming times, the actions\\ntaken not just by the governments, but also by the people,\\nwould in\\x1duence the extent of the havoc wreaked by the\\ncovid-19 pandemic.\\nxv. artificial intelligence\\nsince its inception, ai has proved to be a landmark tech-\\nnological advancement. if used properly, it stands to be a\\nhighly effective tool against the covid-19 pandemic [183].\\nmentioned below are some of the actual and potential ways\\nin which ai can aid the authorities in effectively combating\\nthe covid-19 pandemic:\\n\\x0fdisease surveillance\\n\\x0frisk prediction\\n\\x0fmedical diagnosis and screening\\n\\x0fcurative research\\n\\x0fvirus modeling and analysis\\n\\x0fhost identi\\x1ccation\\n\\x0fbusting fake news\\n\\x0fenforcing the lockdown measures\\nin the subsections that follow, we review all of the aforemen-\\ntioned applications in detail.\\na. disease surveillance\\nthe timely surveillance and forecast of diseases, especially\\nthe ones with the ability to lead the world into a state\\nof disarray, is crucial. to this end, a toronto-based health\\nsurveillance company, bluedot, was successful in reporting\\nan impending outbreak of coronavirus on 31 december 2019,\\nnine days before the who [184]. bluedot's ai model lever-\\nages several machine learning (ml) and natural language\\nprocessing (nlp) tools to look for evidence of emerging\\ndiseases. this model has allowed bluedot to track the spread\\nof the sars-cov-2 and forecast its outbreak well before\\nepidemiologists. however, that does not go as far as saying\\nthat no human effort was required to do the same. while\\ntheir ai model was able to give predictions in regards to the\\n90248 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 11. applications of ai for covid-19 pandemic impact mangement.\\noutbreak of the disease, human interpretation of the model's\\noutput remained central to its working [185].\\nbesides bluedot, several other organizations have adopted\\nthe use of ai to estimate the risks associated with emerging\\ninfections. for example, a risk analytics company founded\\nin 2008, metabiota, has developed an epidemic monitoring\\nplatform that allows it to forecast the spread of diseases.\\nmetabiota bases its predictions on factors like the infection's\\nclinal features, fatality rate, and the availability of treat-\\nment. other functionalities of metabiota's epidemic tracker\\ninclude providing detailed information and up-to-date statis-\\ntics on over 120 novel pathogens [186].\\nin addition to these efforts, a few scientists have also pro-\\nposed the use of such technologies in identifying potentially\\nfatal zoonotic viruses well before they cause damage to the\\nhuman population. the global virome project (gvp) is an\\nexample of one such endeavor. the gvp aims to establish a\\ngenetic and ecological database of viruses in various animal\\nspecies that are capable of infecting humans. the large vol-\\nume of data that they collect on viruses could also be used to\\nshape ai technologies to predict which zoonotic viruses have\\nthe potential to cause the most harm to the human species.\\nsuch mechanisms can allow for the proactive development\\nof vaccines, drugs, and preventive measures [187].\\nb. risk prediction\\none of the possible avenues of application of ai against\\ncovid-19 is risk prediction (refer to fig. 11). broadly,\\nrisk prediction can be classi\\x1ced into the following\\ncategories [188]:\\x0fpredicting the risk of getting infected.\\n\\x0fpredicting the risk of developing severe symptoms once\\ninfected.\\n\\x0fpredicting the risk of using a speci\\x1cc line of treatment\\non an infected person.\\ntypically, the risk of getting infected is a function of a\\nmyriad of factors. these include age, travel history, hygiene\\nhabits, current health status, pre-existing health conditions,\\nand family medical history. direct mathematical modeling\\nof such factors would not yield fruitful results. however,\\na comprehensive analysis of these factors integrated with ai\\ntechniques, can offer a more precise and reliable prevision\\nof individual risk pro\\x1cles. for example, authors in [189]\\ndescribe an ml-based stratagem to build a vulnerability index\\nfor individuals susceptible to the novel coronavirus.\\nonce a person is infected, ai capabilities can also be\\nused to determine the probability of survival and the require-\\nment of icu treatment for covid-19 patients. to this end,\\nphysicians at universities like stanford and the university of\\nchicago are making attempts at augmenting their existing ai\\nsystems to accurately identify the covid-19 patients whose\\ncondition might worsen. earlier, these systems have proved\\ntheir mettle in predicting whether or not heart disease patients\\nwill require a transfer to the icu. in another effort, bayesian\\nhealth, a start-up tracing its roots to the john hopkins univer-\\nsity, has started working on an early warning system for acute\\nrespiratory distress syndrome (ards), one of the severe\\nsymptoms associated with the covid-19 [190]. the authors\\nof [191] have also proposed an ai framework that leverages\\npredictive analysis performed on real covid-19 patients\\nto support clinical decision-making. their ai-powered\\nvolume 8, 2020 90249\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\npredictive model is capable of identifying people with a\\nhigher likelihood of developing severe symptoms like ards\\nbased on initial presentation. according to their results, their\\nmodel achieved an accuracy of 70-80 % in predicting severe\\ncases of the covid-19.\\nin addition to the use-cases mentioned above, ai tech-\\nniques, particularly machine learning algorithms, can also be\\nused to correlate the patient's data parameters with a speci\\x1cc\\ndrug's usage. such correlations can be used to predict the\\neffect of the drug on a speci\\x1cc group of patients. pre-emptive\\nknowledge of these factors can enable the doctors and medi-\\ncal suppliers to be better prepared for the consequences.\\nc. medical diagnosis and screening\\nrapid diagnosis of the covid-19 can allow governments to\\ntake effective response measures to limit the disease's further\\nspread. the shortage of testing kits worldwide, however, has\\nmade it hard for the authorities to carry out large-scale diag-\\nnostic testing. many existing ai tools are being repurposed,\\nwhile some new ones are also being built to solve this prob-\\nlem. in this subsection, we examine the various ways in which\\nai is revolutionizing the process of covid-19 screening and\\ndiagnosis.\\n1) face scanners\\nfollowing the covid-19 outbreak, various authorities used\\nir temperature scanners at different public places to screen\\npeople for a fever. this technology, however, requires the\\npresence of frontline personnel to carry out the scan. to limit\\nthe exposure of the frontline staff to potential covid-19\\npatients, several hospitals, airports, and medical centers have\\nadopted the use of cameras with ai-based multisensory tech-\\nnology [192]. these cameras can not only enable the author-\\nities to observe the crowds and identify individuals with high\\nbody temperatures, but they can also be used to recognize\\ntheir faces and trace their movements. one of the \\x1crst hos-\\npitals to use this technology was the tampa general hospital\\nin florida, usa. the hospital installed an ai-enabled camera\\nat its entrance to screen all the entering patients for elevated\\nbody temperatures by giving them a thermal face scan. their\\nai system uses machine learning, and \\x1cndings of the camera,\\nto classify whether or not an individual is manifesting the\\nsymptoms of the covid-19 [188].\\n2) medical imaging\\nai technology has considerable potential to improve\\nimage-based medical diagnosis. according to the researchers\\nat the un global pulse, analysis of computed tomogra-\\nphy (ct) scans and x-rays using ai-enabled tools can save\\nradiologists' time by offering more timely medical diagno-\\nsis than current tests for the covid-19 [185]. to this end,\\nmultiple efforts have already been made to employ the use of\\nai-enabled medical imaging to diagnose the covid-19.\\n\\x0fa beijing-based start-up that specializes in building an\\noncology data platform and performing medical dataanalysis, linkingmed, has put forth an ai-based model\\nfor screening pneumonia through ct scan analysis.\\nsince pneumonia is one of the most common clini-\\ncal features of the covid-19, identifying the presence\\nof pneumonia can help identify potential covid-19\\npatients. linkingmed's open-source ai model is based\\non baidu's parallel distributed deep learning platform -\\npaddlepaddle [192].\\n\\x0fa joint effort between the researchers at the univer-\\nsity of waterloo and an ontario-based ai start-up,\\ndarwinai, has yielded a convolutional neural net-\\nwork (cnn) to diagnose covid-19 using chest x-rays.\\nlabeled covid-net, this ai algorithm has been made\\nopen source by the research team to facilitate the devel-\\nopment of ai tools over their model.\\n\\x0fanother ai model for diagnosing the covid-19 using\\nx-rays has been put forth by a few researchers at the\\ndelft university of technology, netherlands. named\\ncad4vocid, this model is built on top of an ai model\\ndeveloped at the same university for the diagnosis of\\ntuberculosis.\\nalthough the use of ai-powered medical imaging techniques\\nhas been perceived to have great potential in covid-19\\ndiagnosis, several radiologists have voiced some issues con-\\ncerning such techniques. firstly, the lack of unbiased data\\nhinders the performance of ai models. secondly, the use of\\nmedical imaging techniques can potentially contaminate the\\nequipment used, and may well cause the disease to spread\\nfurther [185].\\n3) ai-powered medical diagnosis in south korea\\nin the republic of korea, several ai-powered tools have\\nhelped the country in quick examination and identi\\x1ccation\\nof covid-19 patients. an algorithm to detect unusual obser-\\nvations in the patient's chest x-rays, vuno's chest x-ray\\nimage support decision tool, has the potential to recog-\\nnize the individuals in need of intensive care. to do so,\\nthe algorithm studies the patient's x-ray images and examines\\nwhether or not there is an issue with the patient's lungs.\\nanother ai-platform named aihub has been developed in\\nthe republic of korea by an ai-based medical and security\\nsolutions company - jlk inspection. the platform uses the\\nai and big data capabilities of several imaging devices to\\ndiagnose any lung conditions that the patient might have, in a\\nmatter of seconds. in addition to various covid-19 diagnosis\\nplatforms, ai has also played an essential role in accelerating\\nthe development of testing kits in korea. these testing kits\\nhave been approved by not only the authorities in korea but\\nalso by the european union [193].\\n4) covid-19 voice detection systems\\nvoice detection is one of the simplest technologies that can\\nbe employed to identify potential covid-19 patients. during\\nthese dif\\x1ccult times, when there is a serious dearth of testing\\nkits, voice detection platforms can act as a screening measure\\n90250 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nto decide who needs to be tested. for more details on how\\nvoice detection platforms are currently in use, kindly refer to\\nsection xiv-e.\\nfrom all the examples presented above, it is crucial to note\\nthat ai is better suited to assist the screening of covid-19\\npatients rather than diagnosing them altogether. to be able\\nto diagnose any covid-19 patient accurately, ai devices,\\nplatforms, and algorithms must be suf\\x1cciently robust so as\\nto detect all possible mutations of the virus.\\nd. curative research\\nbeing novel, one of the major problems with the\\nsars-cov-2 is the lack of existing research and treatment\\nprotocols for the virus. however, by analyzing the current\\ncases of the covid-19 as well as the existing research on\\ndifferent diseases, ai can prove to be a bene\\x1ccial technology\\nto speed up the process of drug development. several organi-\\nzations and research labs have already adopted the use of ai\\nto identify potential treatments for the covid-19. ai can not\\nonly expedite the drug development process, but it can also\\naid in the process of discovering existing drugs.\\n1) drug development\\nmachine learning (ml), a subset of ai, has proved its effec-\\ntiveness in the process of drug development in the times\\nof previous health emergencies. for example, during the\\nebola epidemic, bayesian ml models were used to speed\\nup the process of discovering molecular inhibitors against\\nthe virus [194]. similarly, the authors of [195] adopted the\\nuse of ml-assisted virtual screening and scoring to speed up\\nthe process of discovering viral inhibitors against the avian\\nh7n9 virus responsible for recurring in\\x1duenza epidemics in\\nchina. in light of the current pandemic, ml models similar to\\nsuch models can aid in expediting the process of developing\\ndrugs that can possibly be used to treat the covid-19.\\n2) repurposing existing drugs/compounds\\nin addition to being able to aid in drug development, scientists\\nare also using ai to help in identifying existing drugs that can\\nbe repurposed to treat the covid-19.\\n\\x0fa germany-based start-up named innoplexus ag has\\nexercised the use of its ai-powered drug discovery\\nplatform to identify a combination of existing drugs\\nthat may prove useful in the treatment of the covid-\\n19. after extensive analysis of existing data associated\\nwith the covid-19, their platform has revealed that\\nchroloquine, an anti-malaria drug, may work better in\\ncombination with remdesivir (an experimental antiviral\\noriginally developed to treat ebola) or tocilizumab (an\\nimmunosuppressive drug) or pegasys (used to treat hep-\\natitis b & c) or clarithromycin (an antibiotic) [196].\\n\\x0fa similar effort is being made by a british start-up\\nnamed exscientia in collaboration with diamond\\nlight source, uk and calibr, a division of the\\ncalifornia-based scripps research institute. exscientiaaims to use its ai drug delivery platform to arrive at a\\ncombination of compounds that could prove to be ben-\\ne\\x1ccial in treating the covid-19. to do so, exscientia\\nintends to screen some 15000 clinically-ready molecules\\npresent in calibr's compound library against three key\\nviral drug targets of the sars-cov-2 [197]. earlier this\\nyear, exscientia developed the \\x1crst-ever ai-created drug\\nto enter the clinical trials [185].\\n\\x0fresearchers from the republic of korea and the usa\\nare using deep learning to investigate the effective-\\nness of an existing antiretroviral drug used to treat\\nhiv/aids named atazanavir, in the treatment of the\\ncovid-19 [198].\\n\\x0fresearchers at a uk-based ai company, benevolent\\nai, have identi\\x1ced baricitinib (a drug for the treat-\\nment of rheumatoid arthritis) as a potential drug to\\ntreat the covid-19. following their research, baric-\\nitinib has entered a controlled trial with the united\\nstates national institute of allergy and infectious dis-\\neases (niaid) [198].\\n\\x0fgero, ai-powered drug discovery and drug repurposing\\nplatform developed by a group of scientists in singa-\\npore, has assisted in the identi\\x1ccation of several existing\\ndrugs, including a drug named afatinib (used to treat\\nnon-small cell lung cancer), that could potentially be\\nused to treat the covid-19 [185].\\n\\x0fvarious ml techniques are also being used to iden-\\ntify drug candidates by predicting drug-target interac-\\ntions (dtis) between the virus's proteins and existing\\ndrugs. the authors of [199], for example, built a\\ndeep learning deeper-feature convolutional neural\\nnetwork (dfcnn) system that can identify/classify\\nprotein-ligand interactions with reasonably high accu-\\nracy. thus, the use of ai can not only help in sug-\\ngesting possible candidates for treatments but also\\nanalyze their expected effectiveness. another exam-\\nple of this approach is given in [200], where a deep\\nlearning-based drug-target interaction model molecule\\ntransformer-drug target interaction (mt-dti) has\\nbeen developed to identify commercially available drugs\\ncapable of acting on sars-cov-2 viral proteins.\\nalthough much effort is being put into the discovery of\\nsuch treatments, it is highly unlikely that any of them will be\\navailable shortly. these candidate treatments have to undergo\\nextensive scienti\\x1cc checks and clinical trials before they are\\napproved for commercial use.\\ne. virus modeling and analysis\\nthe key to developing a successful treatment against\\ncovid-19 is to understand the virus itself. since viruses\\ncannot reproduce by themselves, they rely on host cells to\\nmanufacture copies of their dna. to do this, a virus typically\\ninfects a host cell by binding itself to the host's receptors via a\\nlock and key mechanism. the working mechanism for most\\ninhibitor-based agents is to prevent this from happening by\\nvolume 8, 2020 90251\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 12. debunking myths surrounding the covid-19 (information source: who).\\nblocking the receptors of the target cells. thus, the design of\\neffective inhibitors requires scientists to model the binding\\nmechanism. machine learning happens to be one of the most\\nuseful tools in the scientist's arsenal for building such models.\\nin the past, ml models trained with protein data have\\nproved to be successful in predicting protein-protein interac-\\ntions (ppis) between the h1n1 virus and human body cells,\\nthereby eliminating the need to model the entire virus-host\\ninteractome [188]. machine learning can also be used to\\nmodel various protein folding mechanisms that the virus\\nuses to sustain itself. reference [201], for example, employs\\ndeep learning algorithms to predict the structure of a pro-\\ntein from its amino acid sequence. knowing a protein's\\nthree-dimensional structure is of great importance, as its func-\\ntioning is strongly correlated to its structure.\\namid the current covid-19 health crisis, deepmind,\\ngoogle's ai company, has adopted the use of its alphafold\\nsystem to predict the structure of the proteins associated\\nwith the sars-cov-2. these predictions can aid scientists\\nin better understanding the overall structure of the virus, and\\nconsequently, in developing a new drug to treat the covid-\\n19 [185]. it is important to note, however, that deepmind has\\nmade it clear that these predictions have not been experimen-\\ntally veri\\x1ced [188].\\nf. host identification\\nthe sars-cov-2 is a member of the betacov genera of the\\ncoronaviridae family. typically, genomes of such viruses are\\na mix of bat and rodent genomes. to date, the mammalian\\nhost that facilitated the transmission of the covid-19 tohuman beings is an unknown variable. to this end, ml mod-\\nels can be used to effectively compare the viral genome with\\nknown genomes and identify similarities between them. such\\na database of known genomes is available in [202]. in [203],\\nthe authors have proposed the use of a random forest algo-\\nrithm to identify the hosts for the in\\x1duenza-a virus. another\\nexample of such an approach is given in [204]. such models\\ncan be extended to include the sars-cov-2 as well.\\ng. busting fake news\\nthe uncertain times following the outbreak of the covid-\\n19 have bred several myths and conspiracy theories (refer to\\nfig. 12). much misinformation has been making the rounds\\non social media platforms. to curb the propagation of these\\nfake news and provide veri\\x1ced information, technology com-\\npanies like google, youtube, and facebook have employed\\nthe use of ai techniques. all these platforms have made an\\neffort to screen content for the presence of even the slight-\\nest bit of misinformation. youtube, in particular, has placed\\nstringent measures to take down any video propagating fake\\nnews [192].\\nh. enforcing the lockdown measures\\nmany countries around the world, including china, india,\\nthe usa, and the uk, are adopting the use of ai to enforce\\nsocial distancing and lockdown measures. in china, baidu,\\none of the largest ai and internet companies in the world, has\\ndeveloped computer vision (cv) powered infrared cameras\\nto scan public places. these cameras can not only identify\\n90252 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\npeople with high body temperatures, but via the use of their\\ninbuilt facial recognition system, they can also recognize citi-\\nzens who are not following the lockdown measures. a similar\\ncv camera system has been deployed in oxford, england,\\nto monitor if the crowds are following the social distancing\\nmeasures. an ai-based start-up in the usa - landing ai,\\nhelmed by one of the most renowned ai experts in the world\\n- andrew ng, has also developed a social distancing detection\\ntool that monitors crowds and alerts the authorities whenever\\nsocial distancing guidelines are breached [185].\\ni. challenges\\narti\\x1ccial intelligence can conceivably play an essential role\\nin mitigating the impact of the covid-19 pandemic. how-\\never, at present, ai systems are still in the prefatory stages.\\nthe several challenges and limitations hindering the applica-\\ntion of ai in covid-19 impact management are as followsv\\ni) to yield reliable and accurate results, ai models require\\na substantial amount of training data. however, owing\\nto the unprecedented nature of the pandemic, there is\\na dearth of historical data on which to train ai mod-\\nels, which has consequently rendered several ai models\\ninef\\x1ccient [185].\\nii) it is not only the absence of open data that has impeded\\nthe performance of ai models, too much noisy and\\noutlier data has also presented a challenge to the ef\\x1ccient\\nuse of ai technologies. google flu trends' failed initia-\\ntive sheds light on the fact that a deluge of data hubris\\ncan potentially inundate ai algorithms and inhibit their\\nfunctioning [185].\\niii) another limitation faced by ai systems, particularly\\nmachine learning models, is their inherent assumption\\nthat all possible contingencies in any given situation are\\nthe same as the ones exhibited in the dataset they have\\nbeen trained on [185].\\niv) the use of ai techniques for crowd surveillance is seen\\nby many as a breach of privacy. although at present, peo-\\nple have apprehended the fact that public health concerns\\nare more important than data privacy concerns, the pri-\\nvacy pitfalls associated with the use of ai have instilled\\na sense of fear among the public that governments may\\ncontinue to monitor them even after the pandemic is\\nover [184].\\nv) another limitation of ai in its current form is its depen-\\ndence on human knowledge. human expertise is fun-\\ndamental to guide the implementation of ai techniques\\nand make a signi\\x1ccant difference in the \\x1cght against the\\ncovid-19 pandemic [184].\\ndespite the several challenges facing the ai systems,\\ntheir contribution to the \\x1cght against the covid-19 pan-\\ndemic cannot be overlooked. in recent years, ai technol-\\nogy has made stunning advances in the \\x1celds of nlp, ml,\\ndeep learning, data analytics, among others. such develop-\\nments serve to prove the potential of ai in assisting the\\ncovid-19 pandemic management system.xvi. blockchain\\nblockchain technology has been under extensive delib-\\neration amongst researchers and industrialists in recent\\ntimes, especially since the onset of blockchain 2.0 &\\nblockchain 3.0 [205]. gradually, this technology is extend-\\ning its presence to almost all the major domains, includ-\\ning the insurance sector, the transportation industry, drone\\ncommunication technologies, and even the healthcare\\nsector [206], [207]. the current health crisis, brought by\\nthe covid-19, is neither localized nor independent. the\\ncovid-19 pandemic has left no space for seclusion, and\\npeople all around the globe need to stand united to get through\\nthis crisis. the nature of the pandemic itself is distributed\\nin nature. therefore, distributed ledger technologies, such as\\nblockchain, can be highly bene\\x1ccial in regards to dealing with\\nthis situation. blockchain technology enables individuals and\\norganizations from any corner of the world to become a part\\nof a single interconnected network that facilitates the secure\\nsharing of data. the tamper-proof feature of blockchain\\nmakes it resistant to unauthorized changes, and the use of\\nconsensus algorithms and smart contracts minimizes the\\npotential of the dissemination of bogus data and fraudulent\\ninformation. blockchain-based applications can be employed\\nto monitor and manage the covid-19 patients digitally,\\nthereby relieving some burden on the hospital staff and other\\nhealthcare personnel (refer to fig. 13). mentioned below are\\nsome of the signi\\x1ccant ways in which blockchain technology\\ncan help in the \\x1cght against the covid-19:\\n\\x0ffacilitating increased testing and reporting\\n\\x0frecording the details of the covid-19 patients\\n\\x0fmanaging the lockdown implementation\\n\\x0fpreventing the circulation of fake news\\n\\x0fenabling an incentive-based volunteer participation\\nplatform\\n\\x0fenabling a secure donation platform for supporters\\n\\x0flimiting supply chain disruptions\\nwe dissect each one of these ways in the subsections that\\nfollow.\\na. increased testing and reporting\\nvarious countries, such as china, germany, and the republic\\nof korea, have emphasized the need for extensive testing of\\nindividuals as the eventual means to curb the spread of the\\nvirus. however, in order to ensure ef\\x1cciency, tests must be\\ncarried out intelligently, and accurate data in regards to the\\nnumber of tests performed needs to be maintained. to this\\nend, blockchain technology can help in setting up distributed\\ncheck-up points for testing the patients who are showing\\nsymptoms related to covid-19. the coordinators of all these\\ncheck-up points can act as nodes of the same distributed\\nblockchain network. these nodes can continuously update\\ndata regarding the number of tests performed and the number\\nof laboratory-con\\x1crmed cases in their local check-up point on\\nthis network. this can help in getting an accurate report on\\nthe number of tests being conducting and the number of\\nvolume 8, 2020 90253\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 13. blockchain-based dlt architecture for covid-19 impact management.\\npositive cases recorded in each area. these reports can further\\nhelp the authorities and healthcare of\\x1ccials to strategize a\\nplan to combat the spread of disease in the areas reporting\\na high number of covid-19 positive patients. the shared\\nblockchain network can act as a single source for all the users\\nto update and retrieve the data. due to blockchain's inherent\\nfeature of being immutable, data stored in the network will\\nbe tamper-proof and can, therefore, be trusted by all the\\nhealthcare professionals and government authorities.\\nb. recording covid-19 patient details\\napart from securely storing the test reports, the blockchain-\\nbased distributed platforms can also act as a promising solu-\\ntion for recording covid-19 patient details. as soon as a\\nperson tests positive for the covid-19, all of his/her details,\\nincluding sex, age, medical history, underlying health condi-\\ntions, the severity of the disease, the symptoms developed,\\nand the recommended line of treatment, can be securely\\nadded on the network. a platform with up-to-date data on\\nthe covid-19 patients can help facilitate the study of the\\ndisease's clinical characteristics and help all the health cen-\\nters that are part of the network, better understand better the\\ndisease's growth pattern. in the near future, any health center\\ndealing with a con\\x1crmed case of the covid-19 can refer to\\nthese studies to anticipate the kind of facilities and medicines\\nrequired to deal with the situation at hand.\\nc. managing the lockdown implementation\\nliving under lockdown conditions is an unprecedented sit-\\nuation for a majority of the people around the world. the\\nessential needs of the public have to be met to empower them\\nto stay at home and follow the lockdown restrictions strictly.\\npeople from the police department, healthcare department,non-governmental organizations (ngos), and other volun-\\nteers need to work in sync with the government authorities\\nto achieve the intended results of the lockdown success-\\nfully. following the implementation of lockdown measures,\\nmultiple reports have surfaced claiming that people residing\\nin easily accessible areas are utilizing extra services while\\npeople living in remote areas are kept bereft of even the fun-\\ndamental necessities. to this end, blockchain technology can\\naid the government and non-government bodies to oversee\\nthe requirements of people in different regions of the country\\nand ef\\x1cciently manage the lockdown implementation. all the\\nauthorized groups or individuals associated with enforcing\\nthe lockdown can act as nodes in the blockchain network and\\ncan register the needs of the residents in their designated area\\non the network. all the participating nodes in the blockchain\\nnetwork are allowed to check for the requirements listed by\\nthe nodes of different areas, following which the intended\\ngroups may take appropriate actions to satisfy those needs.\\nthis will help to limit the imbalance in the supply of services\\nin different areas and consequently result in a more stringent\\nlockdown implementation.\\nd. preventing the circulation of fake news\\nfollowing the outbreak of the covid-19, one of the major\\nconcerns for governments worldwide has been to limit the\\nspread of misinformation. various unsolicited messages are\\nbeing forwarded, giving rise to feelings of unrest amongst the\\ncitizens. besides spreading rumors and fake news, some mes-\\nsages are particularly in\\x1dammatory and instill the feelings\\nof xenophobia amongst the readers. however, since several\\nsocial platforms are currently in use, it becomes dif\\x1ccult for\\nthe authorities to monitor the authenticity of the information\\nbeing shared in each of these platforms. moreover, even if the\\n90254 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nauthorities are able to detect an unfactual message, it becomes\\ndif\\x1ccult for them to track the original initiator of the message.\\nto this end, the use of a public blockchain network for\\ninformation sharing can be a highly promising solution to\\ncurb the spread of rumors, conspiracy theories, fake news, and\\nin\\x1dammatory remarks. by forcing all message initiators to\\nsign their message with a digital signature, the authorities can\\nkeep track of who shared which message. although the use\\nof consensus algorithms will ensure that no misinformation\\nmakes it into the network in the \\x1crst place, even if it does,\\nthe authorities can quickly determine the message initiator\\nbased on his/her digital signature. such a platform will pre-\\nvent people from falling prey to fraudulent information.\\ne. incentive based volunteer participation\\nthe general behavior of the individuals is that they tend to\\nrespond quickly to the incentives offered. incentives may be\\nsimple words of appreciation, a monetary bene\\x1ct, a small\\ngift, or a certi\\x1ccate acknowledging his/her work. blockchain\\ntechnology makes use of a robust consensus mechanism that\\ncan be used to facilitate the secure distribution of incentives\\nin different ways to the deserving candidates [208], [209].\\nin the current state of crisis that is scaling up at a rapid\\npace, it becomes crucial for countries to prompt their citi-\\nzens to share vital data and also to involve them in impact\\nmanagement activities [210]. to this end, a blockchain-based\\nincentive mechanism, such as the ones proposed in [211],\\nand [212], can prove to be highly useful in motivating a\\nlarge number of citizens to act as volunteers for the covid-\\n19 crisis management. volunteers can help by distributing\\nfood, masks, and other essential products. furthermore, they\\ncan also help by reporting the identities of people 1) breaking\\nsocial distancing protocols, 2) hoarding items of daily use,\\nand 3) misusing the current state of panic among people to\\ncharge them extra for even the most fundamental necessi-\\nties. all the participants in the blockchain network can be\\nrewarded with some tokens or certi\\x1ccates of appreciation to\\nacknowledge their work done and motivate them to partici-\\npate with even more enthusiasm.\\nf. secure donation platform\\nfollowing the massive impact of the covid-19 pandemic\\nglobally, especially on those belonging to the underpriv-\\nileged class, several people and organizations around the\\nworld are coming forward to help the ones less fortunate\\nthan themselves. since, in these dire times, not everyone\\ncannot go out and personally help the needy, people have\\nchosen to donate in several international and national relief\\nfunds. however, the reports of fraudulent bank accounts\\nand relief funds have instilled a feeling of insecurity among\\nthe people who were otherwise willing to donate. recently,\\nin india, a group of fraudsters was caught collecting dona-\\ntions by creating a fake bank account under the same name\\nas the one initiated by the indian prime minister [213].\\nto this end, a secure and transparent donation platform is\\nrequired to quash the skepticism surrounding the validityand transparency of existing donation platforms and, con-\\nsequently, enable more citizens to extend monetary help.\\nvarious blockchain-based crowdfunding platforms have been\\nproposed in recent times [214], [215]. blockchain-based\\nplatforms can ensure a secure collection of money while\\nalso warranting transparency in regards to where the donated\\nmoney is being used.\\ng. limiting supply chain distruptions\\nthe onset of the covid-19 has been particularly trouble-\\nsome for international trade and supply chains. amid the\\nlockdown measures currently imposed in several countries,\\nmost organizations around the world are experiencing con-\\nsiderable dif\\x1cculties in maintaining the \\x1dow of goods and\\nservices [216]. supply chain disruptions, further exacerbated\\nby trade restrictions, have caused a majority of suppliers to\\nhalt production and several logistic partners to postpone the\\ntransport of goods. technologies, such as blockchain, are\\nbeing hailed as the key to reforming the trade networks and\\nmaking the supply chain more tolerant of such emergencies\\nin the future.\\nthe past few years have seen several attempts made by\\norganizations around the world to incorporate blockchain in\\ntheir supply chains in a bid to increase supply chain visibility,\\nlack of which is cited as the primary reason for supply chain\\ndisruptions. in existing systems, even if the manufacturers are\\nfamiliar with any dif\\x1cculties being faced by their immediate\\nsuppliers, they might be oblivious to the challenges faced by\\ntheir supplier's partners. knowledge of such challenges can\\nallow manufacturers to arrange for temporary solutions to\\ndeter supply chain problems [217]. however, owing to the\\ninsecurities of losing a competitive edge, suppliers may be\\nleery of disseminating their partner's details. to this end, per-\\nmission blockchains can make it feasible for the supplier to\\nshare data without actually disclosing their partner's identity.\\nh. challenges\\na few technical and non-technical challenges hinder the\\napplication of blockchain in the covid-19 impact manage-\\nment. before blockchain-based solutions can be implemented\\nin the current situation, these issues must be adequately\\naddressed.\\ni) the \\x1crst non-technical challenge to blockchain imple-\\nmentation is the lack of awareness about blockchain and\\nits potential. furthermore, several people have reserva-\\ntions regarding the use of blockchain since they associate\\nblockchain only with cryptocurrencies and fraudulent\\nactivities.\\nii) although non-technical challenges can be handled\\nby increased awareness, the main challenges to\\nblockchain implementation are the technical ones.\\nblockchain-based platforms often suffer from their lack\\nof scalability. the current crisis necessitates the use of\\na highly scalable solution since it is affecting almost\\nall people around the world. currently, only a few\\nvolume 8, 2020 90255\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nblockchain-based platforms are available, and almost all\\nof them have inherent scalability constraints.\\niii) the response to the current pandemic requires the con-\\nsolidation of various emerging and legacy technologies.\\nsince blockchain technology is relatively new and imma-\\nture, it becomes dif\\x1ccult to integrate blockchain applica-\\ntions with legacy systems\\niv) one of the signi\\x1ccant advantages of blockchain,\\nthe absence of any central authority, may some-\\ntimes back\\x1cre. to ensure the proper functioning of\\nblockchain-based applications, it is essential to properly\\nenforce government regulations and standards in the\\ndesign and development of such applications.\\nalthough blockchain technology is relatively new and its\\nentire potential is yet to be explored, the disastrous impact\\nof the covid-19 pandemic has warranted the use of\\nblockchain-based transparency solutions for enhanced impact\\nmanagement techniques. in the coming times, due to the\\nseveral bene\\x1cts that it offers, blockchain technology has the\\npotential to become an indispensable part of the healthcare\\nindustry and the rapid response system.\\nxvii. 5g network technology\\n5g refers to the \\x1cfth generation of wireless communica-\\ntion technology supporting mobile networks globally [218].\\nin comparison to 4g, 5g is expected to have better per-\\nformance in terms of higher speed, lower latency, wider\\nrange, increased availability, and more reliability. together\\nwith other concomitant technologies like iot and ai, 5g\\nnetwork technology has the potential to revolutionize the\\nhealthcare sector. the commercialization of 5g technology\\nin china has already transformed its response mechanism to\\nthe covid-19 pandemic by providing better assistance to\\nthe frontline staff and facilitating improved virus tracking,\\npatient monitoring, data collection, and analysis [219]. citing\\nchina as an example, in this section, we discuss the various\\nways in which countries can adopt 5g to help improve the\\nef\\x1cciency of their efforts in resisting the covid-19 health\\ncrisis.\\na. 5gc telemedicine\\nas de\\x1cned in section x-c, telemedicine refers to the practice\\nof remotely monitoring the patients. although the use of\\ndrones, smart wearables, and mobile applications can aug-\\nment the functionalities of the telemedicine sector, 5g net-\\nwork technology is a necessity to realize those functional-\\nities. due to its limited bandwidth and data transfer speed,\\nthe existing 4g networks cannot support real-time high-\\nquality video conferencing, which is an essential requirement\\nfor seamless consultation teleconferencing [220]. further-\\nmore, 4g lte networks often hinder the connection of iomt\\ndevices to cloud platforms, consequently rendering them\\ninef\\x1ccient. to this end, 5g with its features like ultra-low\\nlatency, and high-speed data transmission can enable mobile\\nnetworks to address these issues. furthermore, 5g canenable immersive virtual and augmented reality (vr/ar)\\napplications, which can conceivably lead to an interactive\\nexperience in telemedicine, and equip caregivers to provide\\nimmediate expertise in regards to possible complications and\\ntreatment strategies [221].\\nchina, where the 5g technology was commercially\\nunveiled in early november last year, has already drawn on\\nsome of the features that 5g networks bring to telemedicine.\\nvarious hospitals and medical centers in china have launched\\n5gc telemedicine platforms for covid-19 patients. for\\nexamplev\\n\\x0fwest china hospital has launched a covid-19 5gc\\nteleconsultation platform with assistance from china\\ntelecom.\\n\\x0fa hospital af\\x1cliated to the kunming medical univer-\\nsity has launched a 5g-based online platform for free\\ncovid-19 diagnosis and treatment [222].\\n\\x0fan emergency facility in wuhan, huoshenshan hospi-\\ntal, has launched a 5gc remote consultation platform.\\nthis consultation platform has enabled a more ef\\x1ccient\\ndiagnosis and treatment of the covid-19 patients in\\nthe hospital, by equipping the healthcare profession-\\nals in beijing to work with the medical team of the\\nhospital [223].\\nb. 5gc medical imaging\\nrecent years have seen medical imaging techniques like pic-\\nture archiving and communication systems (pacs), become\\nan indispensable part of diagnosis and treatment. in tandem\\nwith the next-generation cellular networks and technologies\\nlike ai and big data analytics, pacs can offer enhanced\\ndata analysis & management, while requiring minimal human\\neffort. in a specialist \\x1celd hospital in wuhan, leishenshan\\nhospital, 5g-enabled medical imaging platforms allowed\\nfor real-time diagnosis of covid-19 patients, and in doing\\nso, relieved some of the load on the hospital's medical\\nstaff [223].\\nc. 5gc thermal imaging\\nthermal imaging technology, initially developed for\\nanti-aircraft defense, has now found its way into several\\ndomains, including healthcare, where it has proved to be\\nparticularly propitious. the establishment of 5g networks has\\nfacilitated the development of 5g-enabled thermal imaging\\nsystems that can have several applications in defense and\\nhealthcare. a 5gc ir thermal imaging monitoring system\\ncan enable the real-time temperature of moving bodies with\\nhigh accuracy and precision. the data accumulated by the\\nsystems can then be transmitted to the central monitoring\\nsystem with ultra-low latency using 5g networks. for the\\ncovid-19 outbreak, this functionality can mean around-the-\\nclock public temperature monitoring. in china, several 5gc\\nthermal imaging systems have already been consolidated in\\nrobots and ua vs, which have been deployed in public spaces\\nof several cities to reduce the spread of the covid-19 [223].\\n90256 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nfigure 14. 5g epidemic monitoring platform.\\nd. 5gc robots\\nfollowing the covid-19 outbreak, several attempts have\\nbeen made around the globe to develop and deploy robots to\\nease the burden on the \\x1crst-line of\\x1ccials. although some of\\nthese attempts have already been discussed in section xii-a,\\nthis section focuses mainly on 5g-powered robots. in addi-\\ntion to having more functionalities, 5g-enabled robots are\\noften more ef\\x1ccient in performing the assigned tasks.\\n1) 5g robots deployed by ais in thailand\\nin thailand, advanced info services (ais), the country's\\nlargest phone operator, has leveraged 5g technology in var-\\nious ways to \\x1cght the outbreak of the covid-19. ais has\\ninstalled 5g networks at 20 hospitals and deployed several 5g\\nrobots to aid the hospitals in augmenting their telemedicine\\nfacilities. apart from serving as a means of communication\\nbetween the medics and the patients, these robots have the\\nability to perform thermal scans [224].\\n2) china mobile's 5g robots in shanghai\\nas part of its effort to contain the spread of covid-19,\\na chinese telecommunications operator, china mobile, has\\nprovided six 5g-enabled intelligent robots to the shanghai\\npublic health clinical center. these robots can perform a\\nmultitude of operations, such as sanitizing the health center\\npremises and delivering medicines to the patients, to name a\\nfew. in addition to the robots, telecom operators in shanghai\\nhave deployed smart devices such as 5g thermal imagingcameras and 5g health monitors in their bid to combat the\\ncovid-19 crisis [225].\\n3) cloudminds' 5g robots in wuhan\\na \\x1celd hospital, staffed with several 5g-enabled smart robots,\\nwas recently opened in wuhan, china. these robots, pro-\\nvided by a beijing-based company called cloudminds, can\\nclean and disinfect the premises, deliver medicine to the\\npatients, and measure their temperature. this facility, com-\\nmonly referred to as the smart field hospital, also employed\\nthe use of various other iot devices to ease the burden on the\\nhospital staff. patients at the facility wore smart bracelets and\\nrings that synced with cloudminds' ai platform to enable the\\nhealth workers to continually track their patients' vital signs,\\nincluding their temperature, heart rate, and blood oxygen\\nlevels, without requiring to be physically present with them\\nat all times [145].\\n4) patrol robots in multiple cities of china\\na local robotics company based out of guangzhou, china,\\nhas recently designed 5g police patrol robots on top of the\\nadvantech-developed edge computer mic-770. these smart\\nrobots, born at the intersection of ai, iot, 5g, and cloud\\ncomputing technologies, are equipped with \\x1cve infrared ther-\\nmometers & high-resolution cameras that allow them to\\nmeasure the body temperatures of up to 10 people at once.\\nfurthermore, by employing the use of environmental sensing,\\nthese robots can also determine if someone is wearing a mask\\nvolume 8, 2020 90257\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\nor not. anytime the robot encounters someone who is not\\nwearing a mask or has high body temperature, it immediately\\nsends an alert to the local authorities [226]. these robots have\\nbeen deployed in public places of multiple cities in china,\\nincluding shanghai, guangzhou, and guiyang.\\ne. challenges\\nsince the outbreak of the covid-19, several technologi-\\ncal solutions have been proposed for mitigating its impact.\\namong them, iot, drone technology, and ai have been at the\\nforefront. however, to realize the transformative potential of\\nthese technologies, there is a need for a cellular network that\\ncan overcome the bandwidth, latency, and \\x1dexibility issues\\ninherent to the current network technology. the responsibility\\nfor this rests with the next-generation 5g cellular networks.\\nthe integration of tools like ua vs, robots, and telemedicine\\nplatforms with 5g-supported features like high-speed data\\ntransmission, ultra-low latency, and advanced data analytics,\\ncan allow for an ef\\x1ccient system for monitoring the crowds,\\ndetecting infected individuals, and providing treatment to\\nthem, all without the need for any physical human contact\\n(refer to fig. 14). in the future, such an epidemic control\\nsystem also has the potential to be one of the building blocks\\nfor the development of a more dynamic smart city manage-\\nment model [223]. however, at present, the implementation\\nof 5g networks faces several challenges, some of which are\\nmentioned belowv\\ni) since the deployment of 5g networks is still in nascent\\nstages, one of its pitfalls is the lack of infrastructure\\nto support their working. furthermore, the high costs\\nassociated with the installation and maintenance of 5g\\nnetworks have made its wide-scale deployment dif\\x1ccult\\nfor governments and telecom operators.\\nii) on their own, 5g networks cannot revolutionize the\\nhealthcare sector. they can prove to be effective only\\nwhen used in tandem with other emerging technologies\\nlike iot, ai, and cloud computing.\\niii) at present, there are no established guidelines that reg-\\nulate the use of a patient's con\\x1cdential data collected\\nusing 5g healthcare systems. besides data con\\x1cdential-\\nity, several other security issues associated with the use\\nof 5g are yet to be resolved [221].\\nalthough the wide-scale deployment of 5g networks in the\\nhealthcare industry is likely to take a few years, an increasing\\nnumber of medical centers are already contemplating the\\nuse of 5g-enabled healthcare systems to enhance the quality\\nof medical service and patient experience, reduce the cost\\nof medical care, and minimize the burden on healthcare\\npersonnel [221].\\nxviii. conclusion\\nwhile the world continues to grapple with the impact of\\nthe covid-19 pandemic, complementary efforts of various\\nemerging technologies, such as iot, ua vs, ai, blockchain,\\nand 5g, are endeavoring to alleviate its impact. keepingthat as the foundation of this work, we offer some of the\\nlatest insights on the covid-19 pandemic. we begin this\\npaper with a comprehensive review of the covid-19 itself,\\nin which we explore its clinical features, transmission mech-\\nanism, and diagnosis procedures. following this, we discuss\\nthe stages the disease goes through in the course of its spread.\\nwe also list the various treatment efforts being made to\\nput an end to the pandemic and the preventive measures to\\nbe followed till the time that is possible. to calibrate the\\ndisastrous impact of the covid-19, we also take a broad\\nlook at the state of the global economy following its out-\\nbreak. in the thorough discussion post this, we dissect the\\nvarious technological interventions made in the direction of\\ncovid-19 impact management. primarily, our discussion\\nfocuses on the use of emerging technologies such as iot,\\ndrones, ai, blockchain, and 5g in mitigating the impact of\\nthe covid-19 pandemic. till the time a cure for this disease\\nsurfaces, the responsibility to manage and limit its impact\\nrests largely with these technologies.\\nacknowledgment\\nthe statements made herein are solely the responsibility of\\nthe authors.\\nreferences\\n[1] m. cascella, m. rajnik, a. cuomo, s. c. dulebohn, and r. di napoli,\\n``features, evaluation and treatment coronavirus (covid-19)\\n[updated 2020 apr 6],'' in statpearls [internet]. treasure island,\\nfl, usa: statpearls publishing, jan. 2020. [online]. available: https://\\nwww.ncbi.nlm.nih.gov/books/nbk554776/\\n[2] world health organization. coronavirus disease (covid-19)\\npandemic. accessed: apr. 30, 2020. [online]. available: https://\\nwww.who.int/emergencies/diseases/novel-coronavirus-2019\\n[3] who. (apr. 2020). (who situation report 101). [online]. available:\\nhttps://www.who.int/docs/default-source/coronaviruse/situation-\\nreports/%20200430-sitrep-101-covid-19.pdf?sfvrsn=2ba4e093_2\\n[4] t. singhal, ``a review of coronavirus disease-2019 (covid-19),'' indian\\nj. pediatrics, vol. 87, no. 4, pp. 281\\x15286, apr. 2020.\\n[5] m. chan-yeung and r. xu, ``sars: epidemiology,'' respirology, vol. 8,\\npp. s9\\x15s14, 2003.\\n[6] sars basics fact sheet. (dec. 2017). centers for disease control pre-\\nvention (cdc) [online]. available: https://www.cdc.gov/sars/about/fs-\\nsars.html\\n[7] world health organization. middle east respiratory syndrome coro-\\nnavirus (mers-cov). accessed: apr. 20, 2020. [online]. available:\\nhttps://www.who.int/emergencies/mers-cov/en/\\n[8] world health organization. (apr. 2020). middle east respiratory\\nsyndrome coronavirus (mers-cov) the kingdom of saudi arabia.\\n[online]. available: https://www.who.int/csr/don/08-april-2020-mers-\\nsaudi-arabia/en/\\n[9] freepik. timeline flat design infographic\\x16designed by freepik.\\naccessed: apr. 8, 2020. [online]. available: https://www.freepik.com/\\nfree-vector/timeline-\\x1dat-design-inforaphic_628%2049.htm#\\nquery=timeline&position=49\\n[10] c. sohrabi, z. alsa\\x1c, n. o'neill, m. khan, a. kerwan, a. al-jabir,\\nc. iosi\\x1cdis, and r. agha, ``world health organization declares global\\nemergency: a review of the 2019 novel coronavirus (covid-19),'' int.\\nj. surgery, vol. 76, pp. 71\\x1576, apr. 2020.\\n[11] who. (feb. 2020). report who-china joint mission\\ncoronavirus disease 2019 (covid-19). [online]. available:\\nhttps://www.who.int/docs/default-source/coronaviruse/who-china-\\njoint-mi%ssion-on-covid-19-\\x1cnal-report.pdf\\n[12] people who are at higher risk for severe illness. (apr. 2020).\\ncenters for disease control prevention (cdc) . [online].\\navailable: https://www.cdc.gov/coronavirus/2019-ncov/need-extra-\\nprecautions/people%-at-higher-risk.html\\n90258 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\n[13] world health organization. modes of transmission of virus causing\\ncovid-19: implications for ipc precaution recommendations.\\naccessed: apr. 20, 2020. [online]. available: https://www.who.int/news-\\nroom/commentaries/detail/modes-of-transmission%-of-virus-causing-\\ncovid-19-implications-for-ipc-precaution-recommendations\\n[14] national institutes health. (mar. 2020). study suggests new\\ncoronavirus may remain on surfaces for days. [online]. available:\\nhttps://www.nih.gov/news-events/nih-research-matters/study-suggests-\\nnew%-coronavirus-may-remain-surfaces-days\\n[15] p. belluck, ``what does the coronavirus do to the body?'' the new york\\ntimes, mar. 2020. [online]. available: https://www.nytimes.com/article/\\ncoronavirus-body-symptoms.html?searchre%sultposition=10\\n[16] l. fang, g. karakiulakis, and m. roth, ``are patients with hypertension\\nand diabetes mellitus at increased risk for covid-19 infection?'' lancet.\\nrespiratory med., vol. 8, no. 4, p. e21, 2020.\\n[17] s. h. wong, r. n. s. lui, and j. j. y. sung, ``covid-19 and the digestive\\nsystem,'' j. gastroenterol. hepatol., 2020.\\n[18] r. baldwin and e. tomiura, ``thinking ahead about the trade impact of\\ncovid-19,'' economics in the time covid-19, 2020, p. 59.\\n[19] v. surveillances, ``the epidemiological characteristics of an outbreak of\\n2019 novel coronavirus diseases (covid-19) china, 2020,'' china cdc\\nweekly, vol. 2, no. 8, pp. 113\\x15122, 2020.\\n[20] h. chen, j. guo, c. wang, f. luo, x. yu, w. zhang, j. li,\\nd. zhao, d. xu, q. gong, j. liao, h. yang, w. hou, and y. zhang,\\n``clinical characteristics and intrauterine vertical transmission poten-\\ntial of covid-19 infection in nine pregnant women: a retrospective\\nreview of medical records,'' lancet, vol. 395, no. 10226, pp. 809\\x15815,\\nmar. 2020.\\n[21] d. wang, b. hu, c. hu, f. zhu, x. liu, j. zhang, b. wang, h. xiang,\\nz. cheng, y. xiong, y. zhao, y. li, x. wang, and z. peng, ``clinical\\ncharacteristics of 138 hospitalized patients with 2019 novel coronavirus\\x15\\ninfected pneumonia in wuhan, china,'' j. amer. med. assoc., vol. 323,\\nno. 11, p. 1061, mar. 2020.\\n[22] n. chen, m. zhou, x. dong, j. qu, f. gong, y. han, y. qiu, j. wang,\\ny. liu, y. wei, j. xia, t. yu, x. zhang, and l. zhang, ``epidemiolog-\\nical and clinical characteristics of 99 cases of 2019 novel coronavirus\\npneumonia in wuhan, china: a descriptive study,'' lancet, vol. 395,\\nno. 10223, pp. 507\\x15513, feb. 2020.\\n[23] f. jiang, l. deng, l. zhang, y. cai, c. w. cheung, and z. xia, ``review\\nof the clinical characteristics of coronavirus disease 2019 (covid-\\n19),'' j. gen. internal med., vol. 35, pp. 1545\\x151549, mar. 2020, doi:\\n10.1007/s11606-020-05762-w.\\n[24] s. salehi, a. abedi, s. balakrishnan, and a. gholamrezanezhad, ``coro-\\nnavirus disease 2019 (covid-19): a systematic review of imaging \\x1cnd-\\nings in 919 patients,'' amer. j. roentgenol., pp. 1\\x157, mar. 2020, doi:\\n10.2214/ajr.20.23034.\\n[25] 1918 pandemic (h1n1 virus). centers for disease control\\nprevention (cdc). accessed: apr. 20, 2020. [online]. available:\\nhttps://www.cdc.gov/\\x1du/pandemic-resources/1918-pandemic-h1n1.html\\n[26] e. d. kilbourne, ``in\\x1duenza pandemics of the 20th century,'' emerg.\\ninfectious diseases, vol. 12, no. 1, pp. 9\\x1514, 2006.\\n[27] 1957\\x151958 pandemic (h2n2 virus). centers for disease control\\nprevention (cdc). accessed: apr. 20, 2020. [online]. available:\\nhttps://www.cdc.gov/\\x1du/pandemic-resources/1957-1958-pandemic.html\\n[28] 2009 h1n1 pandemic (h1n1pdm09 virus). centers for disease con-\\ntrol prevention (cdc). accessed: apr. 20, 2020. [online]. available:\\nhttps://www.cdc.gov/\\x1du/pandemic-resources/2009-h1n1-pandemic.html\\n[29] who. (apr. 2020). coronavirus disease 2019 (covid-19) situation\\nreport 87. [online]. available: https://www.who.int/docs/default-\\nsource/coronaviruse/situation-reports/%20200416-sitrep-87-covid-\\n19.pdf?sfvrsn=9523115a_2\\n[30] who. (apr. 2020). coronavirus disease 2019 (covid-19) situation\\nreport 79. [online]. available: https://www.who.int/docs/default-\\nsource/coronaviruse/situation-reports/%20200408-sitrep-79-covid-\\n19.pdf?sfvrsn=4796b143_6\\n[31] m. frackowiak, j. darlak, a. kobylinska, and t. lund. factbox: europe\\nbegins easing coronavirus lockdowns. reuters. apr. 2020. [online].\\navailable: https://www.reuters.com/article/us-health-coronavirus-\\neurope-factbox/fa%ctbox-europe-begins-easing-coronavirus-\\nlockdowns-iduskbn21z1p0\\n[32] m. godin. these european countries are slowly lifting coronavirus\\nlockdowns. here's what that looks like. time. apr. 2020. [online].\\navailable: https://time.com/5822470/countries-lifting-coronavirus-\\nrestrictions-eur%ope/[33] r. martin. what countries are still in lockdown and how many\\nweeks has it been for them? metro. apr. 2020. [online]. available:\\nhttps://metro.co.uk/2020/04/17/countries-still-lockdown-many-weeks-\\n1257%2519/\\n[34] r. staff, ``here's what lockdown looks like around the world,''\\nworld economic forum, apr. 2020. [online]. available: https://\\nwww.weforum.org/agenda/2020/04/coronavirus-lockdowns-global/\\n[35] a. brzozowski. (apr. 2020). belgium extends covid-19 lockdown\\nuntil 3 may, but relaxes some measures. [online]. available:\\nhttps://www.euractiv.com/section/coronavirus/news/belgium-extends-\\ncovid%-19-lockdown-until-3-may-but-relaxes-some-measures/\\n[36] d. cheng. covid 19 coronavirus\\x16latest case numbers; are\\nwe ready to lift lockdown? nz herald. apr. 2020. [online].\\navailable: https://www.nzherald.co.nz/nz/news/article.cfm?c_id=\\n1&objectid=12325851\\n[37] d. dunford, b. dale, n. stylianou, e. lowther, m. ahmed,\\nand i. d. l. t. arenas, ``coronavirus: the world in lockdown in\\nmaps and charts,'' bbc news, apr. 2020. [online]. available:\\nhttps://www.bbc.com/news/world-52103747\\n[38] (apr. 2020). trudeau says canada's lockdown will last `many\\nmore weeks' [online]. available: https://www.deccanherald.com/\\ninternational/world-news-politics/trudeau-%says-canadas-lockdown-\\nwill-last-many-more-weeks-825902.html\\n[39] d. adhikari, ``nepal extends coronavirus lockdown until april 27,''\\naanews, apr. 2020. [online]. available: https://www.aa.com.tr/en/latest-\\non-coronavirus-outbreak/nepal-extends-c%oronavirus-lockdown-until-\\napril-27/1804541\\n[40] arab news. (apr. 2020). iran begins lifting restrictions after\\nvirus lockdown. [online]. available: https://www.arabnews.com/node/\\n1657311/middle-east\\n[41] p. kuras, ``germany is cautiously starting to ease its lockdown but it's\\nharder than it looks,'' the guardian, apr. 2020. [online]. available:\\nhttps://www.theguardian.com/commentisfree/2020/apr/18/germany-\\nease-lock%down-harder\\n[42] j. lockett, ``australia admits coronavirus lockdown may last a year\\ndespite having just 63 deaths,'' the sun, apr. 2020. [online]. available:\\nhttps://www.thesun.co.uk/news/11422653/australia-coronavirus-\\nlockdown-y%ear-extension/\\n[43] m. sa\\x1c, j. otte, and o. holmes. the guardian. (apr. 2020). israel\\nand south korea to ease coronavirus lockdowns . [online]. avail-\\nable: https://www.theguardian.com/world/2020/apr/19/israel-and-south-\\nkorea-to%-ease-coronavirus-lockdowns\\n[44] a. timsit. the psychology behind france's decision to announce\\nan end date for lockdown. quartz, apr. 2020. [online]. available:\\nhttps://qz.com/1837884/why-france-announced-its-coronavirus-\\nlockdown-wi%ll-end-on-may-11/\\n[45] s. upal. which countries are on coronavirus lockdown? the\\nsun. apr. 2020. [online]. available: https://www.thesun.co.uk/news/\\n11233604/which-countries-are-on-coronavir%us-lockdown-spain-italy/\\n[46] j. shannon and l. reyes. us reopening: what states are relaxing\\nsocial distancing restrictions and moving away from lockdowns?\\nusa today, apr. 2020. [online]. available: https://www.msn.com/en-\\nus/news/us/us-reopening-what-states-are-relaxing%-social-distancing-\\nrestrictions-and-moving-away-from-lockdowns/ar-bb12s2sy\\n[47] p. whiteside. coronavirus lockdowns unlocked: which countries\\nare easing restrictions. sky news. apr. 2020. [online]. available:\\nhttps://news.sky.com/story/coronavirus-lockdowns-unlocked-which-\\ncountri%es-are-easing-restrictions-11974027\\n[48] d. soguel and d. hruby, ``how european countries are trying to safely\\nend lockdowns,'' the christian science monitor, apr. 2020. [online].\\navailable: https://www.csmonitor.com/world/europe/2020/0417/how-\\neuropean-countries%-are-trying-to-safely-end-lockdowns\\n[49] d. goodman. world economy faces $5 trillion hit that's like\\nlosing japan. bloombergquint, apr. 2020. [online]. available:\\nhttps://www.bloombergquint.com/global-economics/world-economy-\\nfaces-5-t%rillion-hit-that-is-like-losing-japan\\n[50] y. sun, b. goh, and h. sarkar. china's feb auto sales plunge 79%,\\nbiggest monthly drop ever. cnbc, mar. 2020. [online]. available:\\nhttps://www.cnbc.com/2020/03/12/reuters-america-chinas-feb-auto-\\nsales-p%lunge-79-percent-biggest-monthly-drop-ever.html\\n[51] a. panday, ``virus outbreak drives down automobile sales\\nin march,'' livemint, apr. 2020. [online]. available:\\nhttps://www.livemint.com/companies/news/automakers-hit-hard-by-\\ncovid-19%-march-sales-decline-over-50-11585749547879.html\\nvolume 8, 2020 90259\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\n[52] a. panday, ``amid covid-19 crisis, commercial vehicle sales\\ncrash 89% in march,'' livemint, apr. 2020. [online]. available:\\nhttps://www.livemint.com/companies/news/amid-covid-19-crisis-\\ncommercial%-vehicle-sales-crash-89-in-march-11585756974053.html\\n[53] acea. (apr. 2020). interactive map: production impact of\\ncovid-19 on the european auto industry. [online]. available:\\nhttps://www.acea.be/news/article/interactive-map-production-impact-of-\\nc%ovid-19-on-the-european-auto-industry\\n[54] s. szymkowski. covid-19 shut down 93% of all us\\nauto production. roadshow, apr. 2020. [online]. available:\\nhttps://www.cnet.com/roadshow/news/covid-19-shut-down-us-auto-\\nproductio%n-coronavirus/\\n[55] alliance for automotive innovation covid-19 press release.\\n(mar. 2020). north american assembly facility operating status\\n3-26-2020. [online]. available: https://www.autosinnovate.org/covid-\\n19/north-american-assembly-facility%-operating-status-3-26-2020/\\n[56] iata. (mar. 2020). air passenger market analysis (january\\n2020): passenger growth slows as covid-19 impacts the\\nindustry. [online]. available: https://www.iata.org/en/iata-\\nrepository/publications/economic-reports/a%ir-passenger-market-\\nanalysis\\x16jan-2020/\\n[57] m. ovaska, r. levinson, and b. simon, ``the toll on travel,'' reuters,\\napr. 2020. [online]. available: https://graphics.reuters.com/health-\\ncorona virus/flights/qzjvqeqrvxm/\\n[58] iata. (apr. 2020). covid-19 puts over half of 2020 passenger\\nrevenues at risk. [online]. available: https://www.iata.org/\\nen/pressroom/pr/2020-04-14-01/\\n[59] j. kenkel. cyient. (mar. 2020). the impact of covid-19 on the\\na&d industry and its recovery and regrowth. [online]. available:\\nhttps://www.cyient.com/blog/aerospace-defense/the-impact-of-covid-\\n19-on%-the-ad-industry-and-its-recovery-and-regrowth\\n[60] j. faus, ``this is how coronavirus could affect the travel and tourism\\nindustry,'' world economic forum, 3ad. [online]. available:\\nhttps://www.weforum.org/agenda/2020/03/world-travel-coronavirus-\\ncovid19%-jobs-pandemic-tourism-aviation/\\n[61] unwto. (mar. 2020). impact assessment of the covid-\\n19 outbreak on international tourism. [online]. available:\\nhttps://www.unwto.org/impact-assessment-of-the-covid-19-outbreak-\\non-int%ernational-tourism\\n[62] a. cang, j. blas, and s. cho. china oil demand has plunged 20%\\nbecause of the virus lockdown. bloomberg.com. feb. 2020. [online].\\navailable: https://www.bloomberg.com/news/articles/2020-02-02/china-\\noil-demand-is-%said-to-have-plunged-20-on-virus-lockdown\\n[63] s. meredith. oil prices could soon turn negative as the world runs\\nout of places to store crude, analysts warn. cnbc, apr. 2020.\\n[online]. available: https://www.cnbc.com/2020/04/01/coronavirus-oil-\\nprices-could-turn-negat%ive-as-storage-nears-capacity.html\\n[64] china property investment falls 16.3%, sales plunge by\\n40%. the business times, mar. 2020. [online]. available:\\nhttps://www.businesstimes.com.sg/real-estate/china-property-\\ninvestment-%falls-163-sales-plunge-by-40\\n[65] globaldata. (apr. 2020). globaldata sharply revises down forecast\\nfor construction output growth globally to just 0.5% in 2020. [online].\\navailable: https://www.globaldata.com/globaldata-sharply-revises-\\ndown-forecast-for%-construction-output-growth-globally-to-just-0-5-in-\\n2020/\\n[66] food and agriculture organization of the united nations. q&a: covid-\\n19 pandemic\\x16impact on food and agriculture. accessed: apr. 20, 2020.\\n[online]. available: http://www.fao.org/2019-ncov/q-and-a/impact-on-\\nfood-and-agriculture/en/\\n[67] researchandmarkets.com. (apr. 2020). global food & beverages\\nindustry and the effects of covid-19\\x16analysis of regional\\nregulations and other government policies\\x16researchandmarkets.com.\\n[online]. available: https://www.businesswire.com/news/home/\\n20200415005321/en/global-food-be%verages-industry-effects-\\ncovid-19\\n[68] i. almeida, m. dorning, and m. g. perez. food makers get shot of\\nreality now that panic buying has waned. bloomberg.com. apr. 2020.\\n[online]. available: https://www.bloomberg.com/news/articles/2020-04-\\n16/with-panic-buying-wa%ning-big-food-sees-life-without-restaurants\\n[69] v. bekiempis. could you buy a little less, please?': panic-buying\\ndisrupts food distribution. the guardian, mar. 2020. [online]. avail-\\nable: https://www.theguardian.com/world/2020/mar/23/us-coronavirus-\\npanic-buyi%ng-food[70] coronavirus: how do i get a food parcel? bbc news, apr. 2020.\\n[online]. available: https://www.bbc.com/news/business-51737030\\n[71] m. v. beusekom, ``doctors: covid-19 pushing italian icus toward\\ncollapse,'' univ. minnesota (umn), mar. 2020. [online]. available:\\nhttps://www.cidrap.umn.edu/news-perspective/2020/03/doctors-covid-\\n19-pu%shing-italian-icus-toward-collapse\\n[72] j. hockaday. (mar. 2020). spain's healthcare system on verge of\\ncollapse as another 655 die of coronavirus. [online]. available:\\nhttps://metro.co.uk/2020/03/26/spains-healthcare-system-verge-\\ncollapse-%another-655-die-coronavirus-12459204/\\n[73] m. yamaguchi and y. kageyama, ``coronavirus: japan's medical sys-\\ntem on verge of collapse, doctors say,'' global news, apr. 2020.\\n[online]. available: https://globalnews.ca/news/6836522/coronavirus-\\njapan-medical-system/\\n[74] w. feuer, ``who of\\x1ccials warn health systems are `collapsing' under\\ncoronavirus: `this isn't just a bad \\x1du season,''' cnbc, mar. 2020.\\n[online]. available: https://www.cnbc.com/2020/03/20/coronavirus-\\nwho-says-health-systems-col%lapsing-this-isnt-just-a-bad-\\x1du-\\nseason.html\\n[75] deloitte. understanding covid-19's impact on the telecom sector.\\naccessed: apr. 20, 2020. [online]. available: https://www2.deloitte.com/\\nglobal/en/pages/about-deloitte/articles/covid%-19/understanding-covid-\\n19-impact-on-the-telecom-sector.html\\n[76] globaldata. (mar. 2020). telecom sector will shine in\\npost covid-19 era, says globaldata. [online]. available:\\nhttps://www.globaldata.com/telecom-sector-will-shine-in-post-covid-\\n19-e%ra-says-globaldata/\\n[77] evaluating and testing persons for coronavirus disease 2019 (covid-\\n19). (mar. 2020). centers for disease control prevention (cdc).\\naccessed: apr. 20, 2020. [online]. available: https://www.cdc.gov/\\ncoronavirus/2019-ncov/hcp/clinical-criteria.html\\n[78] world health organization. (may 2017). contact tracing. [online].\\navailable: https://www.who.int/features/qa/contact-tracing/en/\\n[79] u. siddiqui. coronavirus testing methods: what you need\\nto know. news | al jazeera, apr. 2020. [online]. available:\\nhttps://www.aljazeera.com/news/2020/03/coronavirus-testing-methods-\\n2003%30142718434.html\\n[80] world health organization (who). (mar. 2020). laboratory\\ntesting for coronavirus disease 2019 (covid-19) in\\nsuspected human cases. [online]. available: https://apps.who.\\nint/iris/rest/bitstreams/1271387/retrieve\\n[81] s. pfefferle, s. reucher, d. nörz, and m. lütgehetmann, ``evaluation of a\\nquantitative rt-pcr assay for the detection of the emerging coronavirus\\nsars-cov-2 using a high throughput system,'' eurosurveillance, vol. 25,\\nno. 9, 2020, art. no. 2000152.\\n[82] t. heikkinen, j. marttila, a. a. salmi, and o. ruuskanen, ``nasal\\nswab versus nasopharyngeal aspirate for isolation of respiratory viruses,''\\nj. clin. microbiol., vol. 40, no. 11, pp. 4337\\x154339, 2002.\\n[83] world health organization. core medical equipment\\x15information\\n(bronchoscope). accessed: apr. 20, 2020. [online]. available: https://\\nwww.who.int/medical_devices/innovation/bronchoscope.pdf?ua=1\\n[84] narayana health care. (mar. 2020). coronavirus testing\\x16how to\\ntest for coronavirus?\\x16different types of tests. [online]. available:\\nhttps://www.narayanahealth.org/blog/coronavirus-testing-how-to-test/\\n[85] s. m. hahn. coronavirus (covid-19) update: serological tests.\\nu.s. food and drug administration. apr. 2020. [online]. available:\\nhttps://www.fda.gov/news-events/press-announcements/coronavirus-\\ncovid-1%9-update-serological-tests\\n[86] world health organization. apr. 26, 2020. draft landscape of covid-\\n19 candidate vaccines. [online]. available: https://www.who.int/\\ndocs/default-source/coronaviruse/novel-coronavirus-%landscape-\\nncov.pdf\\n[87] a. park. (mar. 2020). as the first coronavirus vaccine human tri-\\nals begin, manufacturer is already preparing to scale production\\nto millions . [online]. available: https://time.com/5807669/coronavirus-\\nvaccine-moderna/\\n[88] moderna. (mar. 2020). moderna's work on a potential vaccine against\\ncovid-19. [online]. available: https://www.modernatx.com/modernas-\\nwork-potential-vaccine-against-covid%-19\\n[89] a. liu. china's cansino bio advances covid-19 vaccine into phase\\n2 on preliminary safety data. fiercepharma, apr. 2020. [online].\\navailable: https://www.\\x1cercepharma.com/vaccines/china-s-cansino-bio-\\nadvances-covi%d-19-vaccine-into-phase-2-preliminary-safety-data\\n90260 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\n[90] covid-19 vaccine candidate shows promise. upmc. apr. 2020.\\n[online]. available: https://www.upmc.com/media/news/040220-falo-\\ngambotto-sars-cov2-vaccine\\n[91] e. kim, g. erdos, s. huang, t. w. kenniston, s. c. balmert,\\nc. d. carey, v. s. raj, m. w. epperly, w. b. klimstra, b. l. haagmans,\\ne. korkmaz, l. d. falo, and a. gambotto, ``microneedle array\\ndelivered recombinant coronavirus vaccines: immunogenicity and\\nrapid translational development,'' ebiomedicine, to be published, doi:\\n10.1016/j.ebiom.2020.102743.\\n[92] johnson & johnson. mar. 2020. johnson & johnson announces\\na lead vaccine candidate for covid-19. [online]. available:\\nhttps://www.jnj.com/johnson-johnson-announces-a-lead-vaccine-\\ncandidate-%for-covid-19-landmark-new-partnership-with-u-s-\\ndepartment-of-health-human-serv%ices-and-commitment-to-supply-\\none-billion-vaccines-worldwide-for-emergency-pan%demic-use\\n[93] gsk. (feb. 2020). cepi and gsk announce collaboration to strengthen\\nthe global effort to develop a vaccine for the 2019-ncov virus. [online].\\navailable: https://www.gsk.com/en-gb/media/press-releases/cepi-\\nand-gsk-announce-co%llaboration-to-strengthen-the-global-effort-to-\\ndevelop-a-vaccine-for-the-2019-%ncov-virus/\\n[94] (feb. 2020). cepi partners with ivi to accelerate development of\\nvaccines against emerging global health threats . [online]. available:\\nhttps://www.ivi.int/cepi-partners-with-ivi-to-accelerate-development-\\nof%-vaccines-against-emerging-global-health-threats/\\n[95] institut pasteur. (mar. 2020). cepi collaborates with the institut pasteur\\nin a consortium to develop covid-19 vaccine. [online]. available:\\nhttps://www.pasteur.fr/en/press-area/press-documents/cepi-collaborates-\\n%institut-pasteur-consortium-develop-covid-19-vaccine\\n[96] world health organization. (apr. 2020). welcome to the who ictrp.\\n[online]. available: https://www.who.int/ictrp/en/\\n[97] m. l. holshue, c. debolt, s. lindquist, k. h. lofy, j. wiesman,\\nh. bruce, c. spitters, k. ericson, s. wilkerson, and a. tural, ``first case\\nof 2019 novel coronavirus in the united states,'' new england j. med.,\\nvol. 382, pp. 929\\x15936, mar. 2020, doi: 10.1056/nejmoa2001191.\\n[98] m. wang, r. cao, l. zhang, x. yang, j. liu, m. xu, z. shi, z. hu,\\nw. zhong, and g. xiao, ``remdesivir and chloroquine effectively inhibit\\nthe recently emerged novel coronavirus (2019-ncov) in vitro,'' cell res.,\\nvol. 30, no. 3, pp. 269\\x15271, mar. 2020.\\n[99] r. khamitov, s. loginova, v. shchukina, s. borisevich, v. maksimov,\\nand a. shuster, ``antiviral activity of arbidol and its derivatives against\\nthe pathogen of severe acute respiratory syndrome in the cell cultures,''\\nvoprosy virusologii, vol. 53, no. 4, pp. 9\\x1513, 2008.\\n[100] y. boriskin, i. leneva, e.-i. pecheur, and s. polyak, ``arbidol: a broad-\\nspectrum antiviral compound that blocks viral fusion,'' current medicinal\\nchem., vol. 15, no. 10, pp. 997\\x151005, apr. 2008.\\n[101] l. wei, ``the curative effect observation of shuanghuanglian and peni-\\ncillin on acute tonsillitis,'' j. clin. otorhinolaryngol., vol. 16, no. 9,\\npp. 475\\x15476, 2002.\\n[102] h. lu, j. yang, z. yuan, w. sheng, and w. yan, ``effect of combined\\ntreatment of shuanghuanglian and recombinant interferon alpha 2a on\\ncoxsackievirus b3 replication in vitro,'' zhongguo zhong yao za zhi=\\nzhongguo zhongyao zazhi= china j. chin. materia medica, vol. 25,\\nno. 11, pp. 682\\x15684, 2000.\\n[103] world health organization. coronavirus disease (covid-19) advice\\nfor the public. accessed: apr. 20, 2020. [online]. available: https://\\nwww.who.int/emergencies/diseases/novel-coronavirus-2019/advice-\\n%for-public\\n[104] centers for disease control prevention (cdc). (apr. 2020). how\\nto protect yourself & others. [online]. available: https://www.cdc.\\ngov/coronavirus/2019-ncov/prevent-getting-sick/preventi%on.html\\n[105] world health organization. coronavirus disease (covid-19) advice\\nfor the public: when and how to use masks. accessed: apr. 20, 2020.\\n[online]. available: https://www.who.int/emergencies/diseases/novel-\\ncoronavirus-2019/advice-%for-public/when-and-how-to-use-masks\\n[106] d. s. w. ting, l. carin, v. dzau, and t. y. wong, ``digital tech-\\nnology and covid-19,'' nature med., vol. 26, no. 4, pp. 459\\x15461,\\napr. 2020.\\n[107] world health organization. (apr. 2020). digital technology for\\ncovid-19 response. [online]. available: https://www.who.int/news-\\nroom/detail/03-04-2020-digital-technology-for-%covid-19-response\\n[108] v. hassija, v. chamola, v. saxena, d. jain, p. goyal, and b. sikdar, ``a\\nsurvey on iot security: application areas, security threats, and solution\\narchitectures,'' ieee access, vol. 7, pp. 82721\\x1582743, jul. 2019.[109] m. rouse. what is iomt (internet of medical things) or healthcare\\niot?\\x16de\\x1cnition from whatis.com. iot agenda, aug. 2015.\\n[online]. available: https://internetofthingsagenda.techtarget.com/\\nde\\x1cnition/iomt-internet-%of-medical-things\\n[110] deloitte centre for health solutions. (jul. 2018). medtech internet\\nmed. things. [online]. available: https://www2.deloitte.com/content/\\ndam/deloitte/global/documents/life-sc%iences-health-care/gx-lshc-\\nmedtech-iomt-brochure.pdf\\n[111] j. j. p. c. rodrigues, d. b. d. r. segundo, h. a. junqueira, m. h. sabino,\\nr. m. prince, j. al-muhtadi, and v. hugo c. de albuquerque, ``enabling\\ntechnologies for the internet of health things,'' ieee access, vol. 6,\\npp. 13129\\x1513141, 2018.\\n[112] d. g. mcneil, jr., ``can smart thermometers track the spread of\\nthe coronavirus?'' the new york times, mar. 2020. [online].\\navailable: https://www.nytimes.com/2020/03/18/health/coronavirus-\\nfever-thermometer%s.html\\n[113] j. watson and j. builta. iot set to play a growing role in the\\ncovid-19 response\\x16omdia. omdia. apr. 2020. [online]. avail-\\nable: https://technology.informa.com/622426/iot-set-to-play-a-growing-\\nrole-in%-the-covid-19-response\\n[114] a. d'mello. first iot buttons shipped for rapid response to cleaning\\nalerts. iot now\\x16how to run an iot enabled business, mar. 2020.\\n[online]. available: https://www.iot-now.com/2020/03/24/101940-\\x1crst-\\niot-buttons-shipped-rap%id-response-cleaning-alerts/\\n[115] amd telemedicine. telemedicine de\\x1cned. accessed: apr. 20, 2020.\\n[online]. available: https://www.amdtelemedicine.com/telemedicine-\\nresources/telemedicine-def%ined.html\\n[116] t. hornyak. what america can learn from china's use of robots\\nand telemedicine to combat the coronavirus. cnbc. mar. 2020.\\n[online]. available: https://www.cnbc.com/2020/03/18/how-china-is-\\nusing-robots-and-telemedic%ine-to-combat-the-coronavirus.html\\n[117] g. hinkley and a. briskin. u.s. waives medicare and hipaa\\nrules to promote telehealth. pillsbury law, mar. 2020. [online].\\navailable: https://www.pillsburylaw.com/en/news-and-insights/us-\\nwaives-medicare-an%d-hipaa-rules-to-promote-telehealth.html\\n[118] s. makroo. technology and business order post covid-19.\\nobserver research foundation (orf), apr. 2020. [online]. available:\\nhttps://www.orfonline.org/expert-speak/technology-and-business-order-\\npo%st-covid-19-64471/\\n[119] s. gilgore, ``gwu hospital tackles covid-19 with new testing\\nsite, telemedicine and outreach on d.c.'s east side,'' washington\\nbus. j., apr. 2020. [online]. available: https://www.bizjournals.com/\\nwashington/news/2020/04/08/gwu-hospital-tac%kles-covid-19-with-\\nnew-testing.html\\n[120] m. shah and a. tosto, ``industry voices-how rush university\\nmedical center's virtual investments became central to its covid-\\n19 response,'' fiercehealthcare, apr. 2020. [online]. available:\\nhttps://www.\\x1cercehealthcare.com/hospitals-health-systems/industry-\\nvoic%es-how-rush-university-system-for-health-s-virtual\\n[121] the hindu businessline. (apr. 2020). covid-19: ap launches\\ntelemedicine facility. [online]. available: https://www.\\nthehindubusinessline.com/news/national/covid-19-ap-launches%-\\ntelemedicine-facility/article31332943.ece\\n[122] a. chakraborty, ``assam: telemedicine, video monitoring for covid-\\n19 home quarantined people in dhemaji,'' northeast now, apr. 2020.\\n[online]. available: https://nenow.in/health/assam-telemedicine-video-\\nmonitoring-for-covid-1%9-home-quarantined-people-in-dhemaji.html\\n[123] v. chauhan, s. galwankar, b. arquilla, m. garg, s. di somma,\\na. el-menyar, v. krishnan, j. gerber, r. holland, and s. p. stawicki,\\n``novel coronavirus (covid-19): leveraging telemedicine to optimize\\ncare while minimizing exposures and viral transmission,'' j. emergencies,\\ntrauma, shock, vol. 13, no. 1, p. 20, 2020.\\n[124] j. comstock, ``israel's sheba hospital turns to telehealth to treat incoming\\ncoronavirus-exposed patients,'' mobihealthnews, feb. 2020. [online].\\navailable: https://www.mobihealthnews.com/news/europe/israels-sheba-\\nhospital-turns%-telehealth-treat-incoming-coronavirus-exposed-patients\\n[125] b. marr. robots and drones are now used to fight covid-19.\\nforbes, mar. 2020. [online]. available: https://www.forbes.com/\\nsites/bernardmarr/2020/03/18/how-robots-and-dron%es-are-helping-to-\\n\\x1cght-coronavirus/#2a8bfbca2a12\\n[126] cyient. (apr. 2020). cyient provides drone-based surveillance\\ntechnology to support telangana state police in implementing covid-\\n19 lockdown. [online]. available: https://www.cyient.com/prlisting/\\ncorporate/cyient-provides-drone-based-%surveillance-technology-to-\\nsupport-telangana-state-police-in-implementing-covi%d-19-lockdown\\nvolume 8, 2020 90261\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\n[127] d. gascuena, ``drones to stop the covid-19 epidemic,'' news bbv a,\\napr. 2020. [online]. available: https://www.bbva.com/en/drones-to-stop-\\nthe-covid-19-epidemic/\\n[128] m. sharma, ``how drones are being used to combat covid-\\n19,'' geospatial world, apr. 2020. [online]. available:\\nhttps://www.geospatialworld.net/blogs/how-drones-are-being-used-\\nto-comb%at-covid-19/\\n[129] ndtv.com. (apr. 2020). delhi civic body begins thermal\\nscreening people on balconies with drones. [online]. available:\\nhttps://www.ndtv.com/delhi-news/coronavirus-delhi-civic-body-using-\\ndron%es-to-check-temperature-of-people-on-balconies-2209832\\n[130] p. singh, ``thermal scan: drones check people for fever in delhi:\\ndelhi news\\x16times of india,'' the times india, apr. 2020. [online].\\navailable: https://timeso\\x1cndia.indiatimes.com/city/delhi/thermal-scan-\\ndrones-chec%k-people-for-fever/articleshow/75088774.cms\\n[131] unisa media centre. (mar. 2020). unisa working on\\n'pandemic drone' to detect coronavirus. [online]. available:\\nhttps://www.unisa.edu.au/media-centre/releases/2020/unisa-working-\\non-pa%ndemic-drone-to-detect-coronavirus/\\n[132] c. pan, ``spain's military uses dji agricultural drones to spray\\ndisinfectant in \\x1cght against covid-19,'' south china morning\\npost apr. 2020. [online]. available: https://www.scmp.com/tech/\\ngear/article/3077945/spains-military-uses-dji%-agricultural-drones-\\nspray-disinfectant-\\x1cght\\n[133] nui galway. (sep. 2019). nui galway makes aviation history by\\ncompleting the world's first diabetes drone mission from mainland to\\naran islands. [online]. available: https://www.ehealthireland.ie/news-\\nmedia/news-archive/2019/a-world-firs%t-as-drone-delivers-\\nmedication-to-the-aran-islands.html\\n[134] e. ackerman, ``zipline wants to bring medical drone delivery\\nto u.s. to fight covid-19,'' ieee spectr. technol., eng., sci.,\\napr. 3, 2020. [online]. available: https://spectrum.ieee.org/automaton/\\nrobotics/drones/zipline-medical-dro%ne-delivery-covid19\\n[135] j. yang, 3 ways china is using drones to fight coronavirus. beijing,\\nchina: world economic forum, mar. 2020. accessed: apr. 30, 2020.\\n[online]. available: https://www.weforum.org/agenda/2020/03/three-\\nways-china-is-using-drones-to-\\x1cght-coronavirus/\\n[136] marut covid19. marut covid-19 drones. accessed: apr. 20, 2020.\\n[online]. available: https://marutdrones.com/marut-covid19/\\n[137] s. dash, ``this drone is delivering medicines, collecting blood\\nsamples and spraying sanitizers in telangana,'' business insider,\\nmar. 2020. [online]. available: https://www.businessinsider.in/\\nbusiness/startups/news/coronavirus-innov%ation-this-drone-is-\\ndelivering-medicines-collecting-blood-samples-and-spraying%-\\nsanitizers-in-telangana/articleshow/74882886.cms\\n[138] k. m. dayashankar, ``drones help karimnagar police effectively\\nenforce lockdown,'' the hindu, mar. 2020. [online]. available:\\nhttps://www.thehindu.com/news/national/telangana/drones-help-\\nkarimnagar%-police-effectively-enforce-lockdown/article31193879.ece\\n[139] s. rexaline, ``jd.com makes drone deliveries in china as covid-19\\nvirus paralyzes country,'' benzinga, feb. 2020. [online]. available:\\nhttps://www.benzinga.com/news/20/02/15310281/jd-com-makes-drone-\\ndeliver%ies-in-china-as-covid-19-virus-paralyzes-country\\n[140] g.-z. yang, b. j. nelson, r. r. murphy, h. choset, h. christensen,\\ns. h. collins, p. dario, k. goldberg, k. ikuta, and n. jacobstein,\\n``combating covid-19\\x16the role of robotics in managing public\\nhealth and infectious diseases,'' sci. robot., vol. 5, no. 40, mar. 2020,\\nart. no. eabb5589, doi: 10.1126/scirobotics.abb5589.\\n[141] xenex. uv disinfection with pulsed xenon to combat hais. accessed:\\napr. 20, 2020. [online]. available: https://www.xenex.com/\\n[142] uvd robots are \\x1cghting coronavirus. (feb. 2020). china buys dan-\\nish robots to fight coronavirus. [online]. available: http://www.uvd-\\nrobots.com/\\x1cght-coronavirus/\\n[143] b. spice. (mar. 2020). covid-19 should be wake-up call for\\nrobotics research. carnegie mellon university, pittsburgh, pa, usa.\\naccessed: apr. 30, 2020. [online]. available: https://www.cmu.edu/\\nnews/stories/archives/2020/march/coronavirus-a-wakeup-call-for-\\nrobotics-research.html\\n[144] t. dawkins, ``how covid-19 could open the door for driverless\\ndeliveries,'' world economic forum, apr. 2020. [online]. available:\\nhttps://www.weforum.org/agenda/2020/04/how-covid-19-could-open-\\nthe-door%-for-driverless-deliveries/\\n[145] c. arthur and r. shuhui. in china, robot delivery vehicles deployed\\nto help with covid-19 emergency. unido, apr. 2020. [online].\\navailable: https://www.unido.org/stories/china-robot-delivery-vehicles-\\ndeployed-he%lp-covid-19-emergency[146] t. yannone. could fitness wearables help detect early signs\\nof covid-19? boston magazine, apr. 2020. [online]. available:\\nhttps://www.bostonmagazine.com/health/2020/04/03/\\x1ctness-wearables-\\ncoro%navirus/\\n[147] s. berryhill, c. j. morton, a. dean, a. berryhill, n. provencio-dean,\\ns. i. patel, l. estep, d. combs, s. mashaqi, and l. b. gerald, ``effect\\nof wearables on sleep in healthy individuals: a randomized cross-over\\ntrial and validation study,'' j. clin. sleep med., p. 8356, feb. 2020, doi:\\n10.5664/jcsm.8356.\\n[148] c. burns, ``estimote wearables track workers to curb covid-\\n19 outbreak,'' slashgear, apr. 2020. [online]. available:\\nhttps://www.slashgear.com/estimote-wearables-track-workers-to-curb-\\ncovi%d-19-outbreak-02615366/\\n[149] d. etherington, ``estimote launches wearables for workplace-level\\ncontact tracing for covid-19,'' techcrunch, apr. 2020. [online].\\navailable: https://techcrunch.com/2020/04/02/estimote-launches-\\nwearables-for-workp%lace-level-contact-tracing-for-covid-19/\\n[150] life signals. covid-19 remote health monitoring in hospitals\\nand at home. accessed: apr. 20, 2020. [online]. available:\\nhttps://lifesignals.com/covid19/\\n[151] ns medical devices. (apr. 2020). lifesignals to roll out\\nbiosensor patch for covid-19 monitoring. [online]. available:\\nhttps://www.nsmedicaldevices.com/news/lifesignals-biosensor-patch-\\ncovid%-19/\\n[152] business wire. (mar. 2020). spry health launches new service,\\nloop signal, to assist in surge of covid-19 cases by reducing\\navoidable hospital visits and improving patient monitoring at\\nhome. [online]. available: https://www.businesswire.com/news/home/\\n20200320005135/en/spry-health-la%unches-new-service-loop-\\nsignal\\n[153] d. koh, ``sphcc employs iot tech and wearable sensors to monitor\\ncovid-19 patients,'' mobihealthnews, apr. 2020. [online]. available:\\nhttps://www.mobihealthnews.com/news/asia-paci\\x1cc/sphcc-employs-iot-\\ntech%-and-wearable-sensors-monitor-covid-19-patients\\n[154] t. alladi, v. chamola, b. sikdar, and k.-k.-r. choo, ``consumer iot:\\nsecurity vulnerability case studies and solutions,'' ieee consum. elec-\\ntron. mag., vol. 9, no. 2, pp. 17\\x1525, mar. 2020.\\n[155] freepik. flowchart free vector\\x16designed by freepik. accessed:\\napr. 15, 2020. [online]. available: https://www.freepik.com/\\nfree-vector/\\x1dowchart_4510182.htm#page=1&query=%\\x1dowchart\\n&position=1\\n[156] t. alladi, v. chamola, r. m. parizi, and k.-k.-r. choo, ``blockchain\\napplications for industry 4.0 and industrial iot: a review,'' ieee access,\\nvol. 7, pp. 176935\\x15176951, 2019.\\n[157] t. alladi, v. chamola, j. j. p. c. rodrigues, and s. a. kozlov,\\n``blockchain in smart grids: a review on different use cases,'' sensors,\\nvol. 19, no. 22, p. 4862, 2019.\\n[158] t. wright. (apr. 7, 2020). blockchain app used to track\\ncovid-19 cases in latin america. [online]. available:\\nhttps://cointelegraph.com/news/blockchain-app-used-to-track-covid-\\n19-ca%ses-in-latin-america\\n[159] blockchain pulse: ibm blockchain blog. (mar. 2020).\\nmipasa project and ibm blockchain team on open data\\nplatform to support covid-19 response. [online]. available:\\nhttps://www.ibm.com/blogs/blockchain/2020/03/mipasa-project-and-\\nibm-blo%ckchain-team-on-open-data-platform-to-support-covid-19-\\nresponse/\\n[160] k. decker. esri partners respond to covid-19 with location\\nintelligence offerings. arcgis blog. apr. 2020. [online]. available:\\nhttps://www.esri.com/arcgis-blog/products/arcgis/health/esri-partners-\\nr%espond-to-covid-19-with-mapping-and-location-intelligence-\\nofferings/\\n[161] c. chong, ``about 1 million people have downloaded tracetogether app,\\nbut more need to do so for it to be effective: lawrence wong,'' the straits\\ntimes, apr. 2020.\\n[162] google company announcements. (apr. 2020). apple and\\ngoogle partner on covid-19 contact tracing technology.\\n[online]. available: https://blog.google/inside-google/company-\\nannouncements/apple-and-googl%e-partner-covid-19-contact-tracing-\\ntechnology\\n[163] apple. (apr. 2020). privacy-preserving contact tracing\\x16\\napple and google. [online]. available: https://www.apple.com/\\ncovid19/contacttracing/\\n[164] google blog. (apr. 2020). privacy-safe contact tracing using\\nbluetooth low energy. [online]. available: https://blog.google/\\ndocuments/57/overview_of_covid-19_contact_tracing_\\nu%sing_ble.pdf\\n90262 volume 8, 2020\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\n[165] a. greenberg, ``does covid-19 contact tracing pose a privacy risk?\\nyour questions, answered,'' wired, apr. 2020. [online]. available:\\nhttps://www.wired.com/story/apple-google-contact-tracing-strengths-\\nweak%nesses/\\n[166] govtech singapore. (mar. 2020). tracetogether\\x16behind the\\nscenes look at its development process. [online]. available:\\nhttps://www.tech.gov.sg/media/technews/tracetogether-behind-the-\\nscenes-%look-at-its-development-process\\n[167] a. hern, ``digital contact tracing will fail unless privacy is respected,\\nexperts warn,'' the guardian, apr. 2020. [online]. available:\\nhttps://www.theguardian.com/world/2020/apr/20/coronavirus-digital-\\nconta%ct-tracing-will-fail-unless-privacy-is-respected-experts-warn\\n[168] android developers. (apr. 2020). create and monitor geofences.\\n[online]. available: https://developer.android.com/training/\\nlocation/geofencing\\n[169] r. staines. researchers struggle with covid-19 voice detection\\napps\\x16report. pharmaphorum, apr. 2020. [online]. available:\\nhttps://pharmaphorum.com/news/researchers-struggle-with-covid-voice-\\ndet%ection-apps-report/\\n[170] gps.gov. the global positioning system. accessed: apr. 20, 2020.\\n[online]. available: https://www.gps.gov/systems/gps/\\n[171] techradar india. (apr. 2020). indian government launches aarogya\\nsetu app to track coronavirus infections. [online]. available:\\nhttps://www.techradar.com/in/news/indian-government-launches-\\naarogya-se%tu-app-to-crack-coronavirus-infections\\n[172] et online. ``how to use aarogya setu app and \\x1cnd out if you have\\ncovid-19 symptoms,'' the economics times, apr. 2020. [online].\\navailable: https://economictimes.indiatimes.com/tech/software/how-\\nto-use-aarogya-s%etu-app-and-\\x1cnd-out-if-you-have-covid-19-\\nsymptoms/articleshow/75023152.cms\\n[173] s. banerjee, b. raman, and s. sharma. (apr. 2020). apps\\nfor covid: to do or not to do. [online]. available:\\nhttp://www.cse.iitd.ac.in/~suban/reports/apps.pdf\\n[174] t. cohen, ``1.5 million israelis using voluntary coronavirus\\nmonitoring app,'' reuters, apr. 2020. [online]. available:\\nhttps://in.reuters.com/article/health-coronavirus-israel-apps/1-5-\\nmilli%on-israelis-using-voluntary-coronavirus-monitoring-app-\\nidinkbn21j5lc\\n[175] j. christian, ``new app attempts to detect signs of covid-19\\nusing voice analysis,'' futurism, mar. 2020. [online]. available:\\nhttps://futurism.com/neoscope/new-app-detects-covid19-voice\\n[176] ``mumbai students develop ai-based voice tool to detect\\ncovid-19,'' the hindu, apr. 2020. [online]. available:\\nhttps://www.thehindu.com/sci-tech/technology/mumbai-students-\\ndevelop-ai%-based-voice-tool-to-detect-covid-19/article31360091.ece\\n[177] s. das, ``mumbai students develop ai-based voice tool to detect\\ncovid-19,'' analytics india magazine, apr. 2020. [online].\\navailable: https://analyticsindiamag.com/mumbai-biotechnology-\\nstudents-develop-ai-%based-voice-tool-to-detect-covid-19/\\n[178] z. whittaker, ``hundreds of academics back privacy-friendly con-\\ntact tracing apps,'' techcrunch, apr. 2020. [online]. available:\\nhttps://techcrunch.com/2020/04/20/academics-contact-tracing/\\n[179] r. raskar, i. schunemann, r. barbar, k. vilcans, j. gray, p. vepakomma,\\ns. kapa, a. nuzzo, r. gupta, and a. berke ``apps gone rogue: maintain-\\ning personal privacy in an epidemic,'' 2020, arxiv:2003.08567. [online].\\navailable: http://arxiv.org/abs/2003.08567\\n[180] p. hubaux, ``decentralized privacy-preserving proximity tracing,''\\nph.d. dissertation, school comput. commun. sci., école\\npolytechnique fédérale de lausanne, lausanne, switzerland,\\n2020.\\n[181] a. ng, ``contact tracing app could help combat coronavirus, but\\nprivacy fears remain,'' cnet, apr. 2020. [online]. available:\\nhttps://www.cnet.com/news/contact-tracing-apps-have-a-trust-problem-\\neve%n-if-they-do-protect-your-privacy/\\n[182] i. lane, ``smartphone contact tracing: privacy fears over australia's\\ncoronavirus app,'' the new daily, apr. 2020. [online]. available:\\nhttps://thenewdaily.com.au/life/tech/2020/04/21/contact-tracing-app-\\ncor%onavirus/\\n[183] k. a. wittbold, c. carroll, m. iansiti, h. m. zhang, and a. b. landman,\\n``how hospitals are using ai to battle covid-19,'' harvard business\\nreview, apr. 2020. [online]. available: https://hbr.org/2020/04/how-\\nhospitals-are-using-ai-to-battle-covid-19\\n[184] m. hollister, ``covid-19: ai can help\\x16but the right human input\\nis key,'' world economic forum, mar. 2020. [online]. available:\\nhttps://www.weforum.org/agenda/2020/03/covid-19-crisis-arti\\x1ccial-\\nintel%ligence-creativity/[185] w. naude, ``arti\\x1ccial intelligence against covid-19: an\\nearly review,'' medium, apr. 2020. [online]. available:\\nhttps://towardsdatascience.com/arti\\x1ccial-intelligence-against-covid-\\n19%-an-early-review-92a8360edaba\\n[186] metabiota. metabiota epidemic tracker. accessed: apr. 20, 2020.\\n[online]. available: https://www.metabiota.com/epidemic-tracker\\n[187] a. d. l. garza, ``coronavirus researchers using ai to\\npredict virus spread,'' time, feb. 2020. [online]. available:\\nhttps://time.com/5780683/coronavirus-ai/\\n[188] m. schmitt, how to fight covid-19 with machine learning\\x16\\ntowards data science . medium. apr. 2020. [online]. available:\\nhttps://towardsdatascience.com/\\x1cght-covid-19-with-machine-learning-\\n1d1106192d84\\n[189] d. decaprio, j. gartner, t. burgess, s. kothari, s. sayed, and\\nc. j. mccall, ``building a covid-19 vulnerability index,'' 2020,\\narxiv:2003.07347. [online]. available: http://arxiv.org/abs/2003.07347\\n[190] e. strickland, ``ai can help hospitals triage covid-19 patients,'' human\\nos, apr. 2020. [online]. available: https://spectrum.ieee.org/the-human-\\nos/arti\\x1ccial-intelligence/medical-\\n[191] x. jiang, m. coffee, a. bari, j. wang, x. jiang, j. huang, j. shi, j. dai,\\nj. cai, t. zhang, z. wu, g. he, and y. huang, ``towards an arti\\x1ccial\\nintelligence framework for data-driven prediction of coronavirus clinical\\nseverity,'' comput., mater. continua, vol. 62, no. 3, pp. 537\\x15551, 2020.\\n[online]. available: http://www.techscience.com/cmc/v63n1/38464\\n[192] s. obeidat, ``how arti\\x1ccial intelligence is helping \\x1cght the covid-\\n19 pandemic,'' entrepreneur, mar. 2020. [online]. available:\\nhttps://www.entrepreneur.com/article/348368\\n[193] itu news. (apr. 2020). covid-19: how korea is using innovative\\ntechnology and ai to flatten the curve. [online]. available:\\nhttps://news.itu.int/covid-19-how-korea-is-using-innovative-technology-\\n%and-ai-to-\\x1datten-the-curve/\\n[194] s. ekins, j. s. freundlich, a. m. clark, m. anantpadma, r. a. davey, and\\np. madrid, ``machine learning models identify molecules active against\\nthe ebola virus in vitro,'' fresearch, vol. 4, p. 1091, jan. 2016.\\n[195] l. zhang, h.-x. ai, s.-m. li, m.-y. qi, j. zhao, q. zhao, and\\nh.-s. liu, ``virtual screening approach to identifying in\\x1duenza virus neu-\\nraminidase inhibitors using molecular docking combined with machine-\\nlearning-based scoring function,'' oncotarget, vol. 8, no. 47, p. 83142,\\noct. 2017.\\n[196] m. das, ``role of ai soars in tackling covid-19 pan-\\ndemic,'' @businessline, mar. 2020. [online]. available:\\nhttps://www.thehindubusinessline.com/info-tech/role-of-ai-soars-in-\\ntack%ling-covid-19-pandemic/article31197098.ece\\n[197] v. rees, ``ai technology to screen existing drugs for use against\\ncovid-19,'' drug target review, apr. 2020. [online]. available:\\nhttps://www.drugtargetreview.com/news/59188/ai-technology-to-\\nscreen-exi%sting-drugs-for-use-against-covid-19/\\n[198] j. wake\\x1celd, ``coronavirus: ai steps up in battle against covid-\\n19,'' bbc news, apr. 2020. [online]. available: https://www.bbc.com/\\nnews/technology-52120747\\n[199] h. zhang, k. m. saravanan, y. yang, m. t. hossain, j. li, x. ren, and\\ny. wei, ``deep learning based drug screening for novel coronavirus 2019-\\nncov,'' preprints, feb. 2020, doi: 10.20944/preprints202002.0061.v1.\\n[200] b. r. beck, b. shin, y. choi, s. park, and k. kang, ``predicting com-\\nmercially available antiviral drugs that may act on the novel coronavirus\\n(2019-ncov), wuhan, china through a drug-target interaction deep learn-\\ning model,'' comput. struct. biotechnol. j. , vol. 18, pp. 784\\x15790, doi:\\n10.1016/j.csbj.2020.03.025.\\n[201] a. w. senior, r. evans, j. jumper, j. kirkpatrick, l. sifre, t. green,\\nc. qin, a. \\x9aídek, a. w. r. nelson, a. bridgland, h. penedones,\\ns. petersen, k. simonyan, s. crossan, p. kohli, d. t. jones, d. silver,\\nk. kavukcuoglu, and d. hassabis, ``improved protein structure predic-\\ntion using potentials from deep learning,'' nature, vol. 577, no. 7792,\\npp. 706\\x15710, jan. 2020.\\n[202] fludb.org. in\\x1duenza research database\\x16in\\x1duenza genome database\\nwith visualization and analysis tools. accessed: apr. 8, 2020. [online].\\navailable: https://www.\\x1dudb.org/brc/home.spg?decorator=in\\x1duenza\\n[203] c. l. eng, j. tong, and t. tan, ``predicting host tropism of in\\x1duenza a\\nvirus proteins using random forest,'' bmc med. genomics, vol. 7, no. 3,\\np. s1, 2014.\\n[204] s. a. babayan, r. j. orton, and d. g. streicker, ``predicting reservoir\\nhosts and arthropod vectors from evolutionary signatures in rna virus\\ngenomes,'' science, vol. 362, no. 6414, pp. 577\\x15580, nov. 2018.\\n[205] a. miglani, n. kumar, v. chamola, and s. zeadally, ``blockchain for\\ninternet of energy management: review, solutions, and challenges,''\\ncomput. commun., vol. 151, pp. 395\\x15418, feb. 2020.\\nvolume 8, 2020 90263\",\n",
       " \"v. chamola et al.: comprehensive review of the covid-19 pandemic\\n[206] t. alladi, v. chamola, n. sahu, and m. guizani, ``applications of\\nblockchain in unmanned aerial vehicles: a review,'' veh. commun.,\\nvol. 23, jun. 2020, art. no. 100249.\\n[207] v. hassija, v. chamola, n. g. k. dara, and m. guizani, ``a dis-\\ntributed framework for energy trading between ua vs and charg-\\ning stations,'' ieee trans. veh. technol., to be published, doi:\\n10.1109/tvt.2020.2977036.\\n[208] v. hassija, v. chamola, s. garg, n. g. k. dara, g. kaddoum, and\\nd. n. k. jayakody, ``a blockchain-based framework for lightweight data\\nsharing and energy trading in v2g network,'' ieee trans. veh. technol.,\\nearly access, doi: 10.1109/tvt.2020.2967052.\\n[209] v. hassija, v. chamola, g. han, j. j. p. c. rodrigues, and m. guizani,\\n``dagiov: a framework for vehicle to vehicle communication using\\ndirected acyclic graph and game theory,'' ieee trans. veh. technol.,\\nvol. 69, no. 4, pp. 4182\\x154191, apr. 2020.\\n[210] d. tapscott and a. tapscott, blockchain solutions pandemics: a call for\\ninnov. transformation public health. toronto, on, canada: blockchain\\nresearch institute, apr. 2020.\\n[211] y. he, h. li, x. cheng, y. liu, c. yang, and l. sun, ``a blockchain\\nbased truthful incentive mechanism for distributed p2p applications,''\\nieee access, vol. 6, pp. 27324\\x1527335, 2018.\\n[212] s. xuan, l. zheng, i. chung, w. wang, d. man, x. du, w. yang,\\nand m. guizani, ``an incentive mechanism for data sharing based\\non blockchain with smart contracts,'' comput. electr. eng., vol. 83,\\nmay 2020, art. no. 106587.\\n[213] india today. delhi police books fraudsters for making fake sbi\\naccount of pm's covid-19 relief fund. accessed: apr. 20, 2020.\\n[online]. available: https://www.indiatoday.in/india/story/delhi-police-\\nbooks-fraudsters-for%-making-fake-sbi-account-of-pm-s-covid-19-\\nrelief-fund-1661272-2020-03-30\\n[214] m. n. saadat, s. a. h. s. a. rahman, r. m. nassr, and m. f. zuhiri,\\n``blockchain based crowdfunding systems in malaysian perspective,'' in\\nproc. 11th int. conf. comput. autom. eng., 2019, pp. 57\\x1561.\\n[215] n. khan and r. ouaich, ``feasibility analysis of blockchain for donation-\\nbased crowdfunding of ethical projects,'' in smart technologies and\\ninnovation for a sustainable future. cham, switzerland: springer, 2019,\\npp. 129\\x15139.\\n[216] r. liao and z. fan, ``supply chains have been upended. here's how to\\nmake them more resilient,'' world economic forum. [online]. avail-\\nable: https://www.weforum.org/agenda/2020/04/supply-chains-resilient-\\ncovid-19%/\\n[217] ledger insights-enterprise blockchain. (apr. 2020). world economic\\nforum: how blockchain could help with covid-19 supply chain\\ndisruption. [online]. available: https://www.ledgerinsights.com/world-\\neconomic-forum-how-blockchain-coul%d-help-with-covid-19-supply-\\nchain-disruption/\\n[218] qualcomm. (2020). what is 5g: everything you need to know\\nabout 5g: 5g faq. [online]. available: https://www.qualcomm.\\ncom/invention/5g/what-is-5g\\n[219] q. xiaoxia, ``how emerging technologies helped tackle covid-19 in\\nchina,'' world economic forum, apr. 2020. [online]. available:\\nhttps://www.weforum.org/agenda/2020/04/how-next-generation-\\ninformation-%technologies-tackled-covid-19-in-china/\\n[220] att business editorial team, at&t business. 5 ways 5g will\\ntransform healthcare. accessed: apr. 20, 2020. [online]. available:\\nhttps://www.business.att.com/learn/updates/how-5g-will-transform-the-\\nhe%althcare-industry.html\\n[221] d. li, ``5g and intelligence medicine\\x16how the next generation of wire-\\nless technology will reconstruct healthcare?'' precis. clin. med., vol. 2,\\nno. 4, pp. 205\\x15208, dec. 2019.\\n[222] z. chunming and g. he, ``5g applications help china \\x1cght\\nagainst covid-19,'' caict, 2020. [online]. available: http://www.\\ncaict.ac.cn/english/yjcg/qwsj/202003/p020200312474854300829.%pdf\\n[223] huawei, deloitte. (mar. 2020). combating covid-19 with\\n5g: opportunities to improve public health systems. [online].\\navailable: https://www-\\x1cle.huawei.com/-/media/corporate/local-\\nsite/ua/pdf/deloitt%e-cn-consulting-5g-assist-in-2019-ncov-en-\\n200317.pdf?la=uk-ua\\n[224] k. tortermvasana. (apr. 2020). ais uses 5g, robots in\\npandemic war. [online]. available: https://www.bangkokpost.com/\\nbusiness/1895175/ais-uses-5g-robots-in-pand%emic-war and\\nhttps://www.bangkokpost.com\\n[225] m. xuequan, ``shanghai uses 5g robots on frontline to combat\\ncovid-19,'' xinhua net, mar. 2020. [online]. available:\\nhttp://www.xinhuanet.com/english/2020-03/01/c_138833060.htm[226] j. happich, ``5g edge patrol robots deployed in china to detect\\ncovid-19 cases,'' eenews europe, mar. 2020. [online]. available:\\nhttps://www.eenewseurope.com/news/5g-edge-patrol-robots-deployed-\\nchina-%detect-covid-19-cases\\nvinay chamola received the b.e. degree in\\nelectrical and electronics engineering and the mas-\\nter's degree in communication engineering from\\nthe birla institute of technology and science,\\npilani, india, in 2010 and 2013, respectively, and\\nthe ph.d. degree in electrical and computer engi-\\nneering from the national university of singa-\\npore, singapore, in 2016. in 2015, he was a\\nvisiting researcher with the autonomous net-\\nworks research group (anrg), university of\\nsouthern california, los angeles, ca, usa. he also worked as a post-\\ndoctoral research fellow with the national university of singapore, where\\nhe worked in the area of internet of things. he is currently an assistant\\nprofessor with the department of electrical and electronics engineering,\\nbits-pilani, pilani campus, where he is currently the head of the internet\\nof things research group/laboratory. he has over 45 publications in high\\nranked journals, including more than 25 ieee transactions and journal arti-\\ncles. his works have been published in journals like the ieee transactions\\noncommunications, the ieee transactions on vehicular technology,\\nthe ieee j ournal on selected areas in communications, and ieee com-\\nmunications magazine. furthermore, his works have been accepted and\\npresented in reputed conferences like ieee infocom, ieee globecom,\\nieee icc, and ieee percom. his research interests include the iot security,\\nblockchain, 5g network management, and addressing research issues in\\nv anets and ua v networks. he has also served as a reviewer for several\\nieee/elsevier journals. he serves as an associate editor of the iet quantum\\ncommunications journal and a guest editor in computer communication\\njournal, elsvier.\\nvikas hassija received the b.tech. degree\\nfrom maharshi dayanand university, rohtak,\\nindia, in 2010, and the m.s. degree in telecom-\\nmunications and software engineering from the\\nbirla institute of technology and science (bits),\\npilani, india, in 2014. he is currently pursuing\\nthe ph.d. degree in iot security and blockchain\\nwith the jaypee institute of information and tech-\\nnology (jiit), noida. he is currently an assistant\\nprofessor with jiit. his research interests include\\nthe iot security, network security, blockchain, and distributed computing.\\nvatsal gupta is currently pursuing the\\nb.tech. degree with the jaypee institute of infor-\\nmation technology (jiit), noida. he has com-\\npleted a few projects in the \\x1celd of blockchain\\napplications, machine learning, and data analytics.\\nhe is currently (the summer of 2020) pursuing\\nhis research internship with the birla institute\\nof technology and science (bits), pilani, under\\ndr. v. chamola. his research interests include\\ndistributed ledger technology, machine learning,\\nand deep learning.\\n90264 volume 8, 2020\",\n",
       " 'v. chamola et al.: comprehensive review of the covid-19 pandemic\\nmohsen guizani (fellow, ieee) received\\nthe b.s. (hons.) and m.s. degrees in electri-\\ncal engineering and the m.s. and ph.d. degrees\\nin computer engineering from syracuse univer-\\nsity, syracuse, ny, usa, in 1984, 1986, 1987,\\nand 1990, respectively. he is currently a profes-\\nsor with the computer science and engineering\\ndepartment, qatar university, qatar. previously,\\nhe has served in different academic and adminis-\\ntrative positions at the university of idaho, west-\\nern michigan university, the university of west florida, the university of\\nmissouri-kansas city, the university of colorado-boulder, and syracuse\\nuniversity. he is the author of nine books and more than 600 publications\\nin refereed journals and conferences. his research interests include wireless\\ncommunications and mobile computing, computer networks, mobile cloud\\ncomputing, security, and smart grid. he is a senior member of acm.\\nhe also served as a member, the chair, and the general chair of a number ofinternational conferences. throughout his career, he received three teaching\\nawards and four research awards. he was a recipient of the 2017 ieee\\ncommunications society wireless technical committee (wtc) recog-\\nnition award, the 2018 adhoc technical committee recognition award\\nfor his contribution to outstanding research in wireless communications\\nand ad-hoc sensor networks, and the 2019 ieee communications and\\ninformation security technical recognition (cistc) award for outstanding\\ncontributions to the technological advancement of security. he was the\\nchair of the ieee communications society wireless technical committee\\nand the chair of the taos technical committee. he has served as the\\nieee computer society distinguished speaker. he is currently the ieee\\ncomsoc distinguished lecturer. he guest edited a number of special issues\\nin ieee journals and magazines. he is also the editor-in-chief of the ieee\\nnetwork magazine. he serves on the editorial boards for several international\\ntechnical journals and the founder and the editor-in-chief for wireless\\ncommunications and mobile computing journal (wiley).\\nvolume 8, 2020 90265',\n",
       " '54    communications of the acm  |   december 2020  |   vol. 63  |   no. 12contributed articles\\nillustration by lisa sheehandoi:10.1145/3381831\\ncreating efficiency in ai research will  \\ndecrease its carbon footprint and increase  \\nits inclusivity as deep learning study should \\nnot require the deepest pockets. \\nby roy schwartz, jesse dodge,  \\nnoah a. smith, and oren etzioni\\nsince 2012, the field of artificial intelligence (ai) has \\nreported remarkable progress on a broad range of \\ncapabilities including object recognition, game playing, \\nspeech recognition, and machine translation.43 much of \\nthis progress has been achieved by increasingly large \\nand computationally intensive deep learning models.a \\nfigure 1, reproduced from amodei et al.,2 plots training \\ncost increase over time for state-of-the-art deep learning \\nmodels starting with alexnet in 201224 to alphazero in \\n2017.45 the chart shows an overall increase of 300,000x, \\nwith training cost doubling every few months. an even \\nsharper trend can be observed in nlp word-embedding \\napproaches by looking at elmo34 followed by bert,8 \\nopengpt-2,35 xlnet,56 megatron-lm,42 t5,36 and gpt-3.4 \\nan important paper47 has estimated the carbon \\nfootprint of several nlp models and argued this trend is \\nboth environmentally unfriendly and prohibitively \\nexpensive, raising barriers to participation in nlp \\nresearch. we refer to such work as red ai.\\na for brevity, we refer to ai throughout this article, but our focus is on ai research that relies on deep \\nlearning methods.this trend is driven by the strong fo-\\ncus of the ai community on obtaining \\n“state-of-the-art” results,b as exemplified \\nby the popularity of leaderboards,53,54 \\nwhich typically report accuracy (or other \\nsimilar measures) but omit any men-\\ntion of cost or efficiency (see, for ex-\\nample, leaderboards.allenai.org).c de-\\nspite the clear benefits of improving \\nmodel accuracy, the focus on this sin -\\ngle metric ignores the economic, envi-\\nronmental, and social cost of reaching \\nthe reported results.\\nwe advocate increasing research \\nactivity in green ai—ai research that \\nis more environmentally friendly and \\ninclusive. we emphasize that red ai  \\nresearch has been yielding valuable \\nscientific contributions to the field, \\nbut it has been overly dominant. we \\nwant to shift the balance toward the \\ngreen ai option—to ensure any in-\\nspired undergraduate with a laptop \\nhas the opportunity to write high-\\nquality papers that could be accepted \\nat premier research conferences. spe-\\ncifically, we propose making efficien-\\ncy a more common evaluation criteri-\\non for ai papers alongside accuracy \\nand related measures.\\nb meaning, in practice, that a system’s accuracy \\non some benchmark is greater than any previ-\\nously reported system’s accuracy.\\nc some leaderboards do focus on efficiency \\n(https://dawn.cs.stanford.edu/benchmark/).green ai\\n key insights\\n ˽the computational costs of state-of-the-\\nart ai research has increased 300,000x in \\nrecent years. this trend, denoted red ai, \\nstems from the ai community’s focus on \\naccuracy while paying attention to efficiency.\\n ˽red ai leads to a surprisingly large \\ncarbon footprint, and makes it difficult for \\nacademics, students, and researchers to \\nengage in deep learning research.\\n ˽an alternative is green ai, which treats \\nefficiency as a primary evaluation \\ncriterion alonside accuracy. to measure \\nefficiency, we suggest reporting the \\nnumber of floating-point operations \\nrequired to generate a result.\\n ˽green ai research will decrease ai’s \\nenvironmental footprint and increase  \\nits inclusivity.\\n',\n",
       " 'december 2020  |  vol. 63  |  no. 12  |   communications of the acm    55\\n',\n",
       " '56    communications of the acm  |   december 2020  |   vol. 63  |   no. 12contributed articles\\nfigure 1 illustrates, the computational \\ncost of high-budget research is in-\\ncreasing exponentially, at a pace that \\nfar exceeds moore’s law.33 red ai is on \\nthe rise despite the well-known dimin-\\nishing returns of increased cost (for \\nexample, figure 3).\\nthis article identifies key factors that \\ncontribute to red ai and advocates the \\nintroduction of a simple, easy-to-com-\\npute efficiency metric that could help \\nmake some ai research greener, more \\ninclusive, and perhaps more cognitively \\nplausible. green ai is part of a broader, \\nlong-standing interest in environmen-\\ntally friendly scientific research (for ex-\\nample, see the journal green chemistry). \\ncomputer science, in particular, has a long history of investigating sustainable \\nand energy-efficient computing (for ex-\\nample, see the journal sustainable com-\\nputing: informatics and systems).\\nin this article, we analyze practices \\nthat move deep-learning research into \\nthe realm of red ai. we then discuss \\nour proposals for green ai and con-\\nsider related work, and directions for \\nfuture research.\\nred ai\\nred ai refers to ai research that seeks \\nto improve accuracy (or related mea-\\nsures) through the use of massive \\ncomputational power while disregard-\\ning the cost—essentially “buying” \\nstronger results. yet the relationship \\nbetween model performance and \\nmodel complexity (measured as num-\\nber of parameters or inference time) \\nhas long been understood to be at best \\nlogarithmic; for a linear gain in per-\\nformance, an exponentially larger \\nmodel is required.20 similar trends ex-\\nist with increasing the quantity of \\ntraining data14,48 and the number of \\nexperiments.9,10 in each of these cases, \\ndiminishing returns come at in-\\ncreased computational cost.\\nthis section analyzes the factors \\ncontributing to red ai and shows how \\nit is resulting in diminishing returns \\nover time (see figure 3). we note that \\nred ai work is valuable, and in fact, \\nmuch of it contributes to what we \\nknow by pushing the boundaries of ai. \\nour exposition here is meant to high-\\nlight areas where computational ex-\\npense is high, and to present each as \\nan opportunity for developing more \\nefficient techniques.\\nto demonstrate the prevalence of \\nred ai, we randomly sampled 60 pa-\\npers from top ai conferences (acl, \\nneurips, and cvpr).d for each paper \\nwe noted whether the authors claim \\ntheir main contribution to be (a) an \\nimprovement to accuracy or some re-\\nlated measure, (b) an improvement to \\nefficiency, (c) both, or (d) other. as \\nshown in figure 2, in all conferences \\nwe considered, a large majority of the \\npapers target accuracy (90% of acl \\npapers, 80% of neurips papers and \\n75% of cvpr papers). moreover, for \\nboth empirical ai conferences (acl \\nd https://acl2018.org; https://nips.cc/conferences/  \\n2018; and http://cvpr2019.thecvf.com.ai research can be computationally \\nexpensive in a number of ways, but \\neach provides opportunities for effi-\\ncient improvements; for example, pa-\\npers can plot performance as a function \\nof training set size, enabling future \\nwork to compare performance even \\nwith   small training budgets. reporting \\nthe computational price tag of develop-\\ning, training, and running models is a \\nkey green ai practice (see equation 1). \\nin addition to providing transparency, \\nprice tags are baselines that other re-\\nsearchers could improve on.\\nour empirical analysis in figure 2 \\nsuggests the ai research community \\nhas paid relatively little attention to \\ncomputational efficiency. in fact, as \\nfigure 1. the amount of compute used to train deep learning models has increased  \\n300,000x in six years. figure taken from amodei et al.2\\n201310,000\\n1,000\\n100\\n10\\n1\\n.1\\n.01\\n.001\\n.0001\\n.00001\\n2014 2015 2016\\nyearalexnet to alphago zero: a 300,000x increase in computepetaﬂops/s-day (training)\\n2017 2018 2019• alexnet\\n• dropout• visualizing and understanding conv nets• googlenet• seq2seq• resnets• deepspeech2• xception• ti7 dota 1v1neural architecture search •neural machine translation •alphazero •alphago zero •\\n•vgg \\nfigure 2. ai papers tend to target accuracy rather than efficiency. the figure shows the  \\nproportion of papers that target accuracy, efficiency, both or other from a random sample  \\nof 60 papers from top ai conferences.\\n16\\n14\\n12\\n10\\n8\\n6\\n4\\n2\\n0number of papers\\nacl 2018 cvpr 2019accuracy\\nneurips 2018efﬁciencyboth\\nother',\n",
       " 'december 2020  |  vol. 63  |  no. 12  |   communications of the acm    57contributed articles\\nequation 1 is a simplification (for \\nexample, different hyperparameter as-\\nsignments can lead to different costs \\nfor processing a single example). it \\nalso ignores other factors such as the \\nnumber of training epochs or data \\naugmentation. nonetheless, it illus-\\ntrates three quantities that are each an \\nimportant factor in the total cost of \\ngenerating a result. next, we consider \\neach quantity separately.\\nexpensive processing of one example. \\nour focus is on neural models, where it cost (r) ∝ e ∙ d ∙ h\\nequation 1. the equation of red ai:  \\nthe cost of an ai (r )esult grows linearly with \\nthe cost of processing a single (e )xample,  \\nthe size of the training (d )ataset and the \\nnumber of (h )yperparameter experiments.and cvpr) only a small portion (10% \\nand 20% respectively) argue for a new \\nefficiency result.e this highlights the \\nfocus of the ai community on mea-\\nsures of performance such as accura-\\ncy, at the expense of measures of effi-\\nciency such as speed or model size. in \\nthis article, we argue that a larger \\nweight should be given to the latter.\\nto better understand the different \\nways in which ai research can be red, \\nconsider an ai result reported in a sci-\\nentific paper. this result typically \\ncharacterizes a model trained on a \\ne interestingly, many neurips papers included \\nconvergence rates or regret bounds that de-\\nscribe performance as a function of exam-\\nples or iterations, thus targeting efficiency \\n(55%). this indicates an increased awareness \\nof the importance of this concept, at least in \\ntheoretical analyses.training dataset and evaluated on a \\ntest dataset, and the process of devel-\\noping that model often involves mul-\\ntiple experiments to tune its hyperpa-\\nrameters. we thus consider three \\ndimensions that capture much of the \\ncomputational cost of obtaining such \\na result: the cost of executing the \\nmodel on a single (e )xample (either \\nduring training or at inference time); \\nthe size of the training (d )ataset, \\nwhich controls the number of times \\nthe model is executed during train-\\ning, and the number of (h )yperparam-\\neter experiments, which controls how \\nmany times the model is trained dur-\\ning model development. the total \\ncost of producing a (r )esult in ma-\\nchine learning increases linearly with \\neach of these quantities. this cost can \\nbe estimated as follows:figure 3. diminishing returns of training on more data: object detection accuracy increases linearly as the number of training examples \\nincreases exponentially.30\\nnumber of training images in source task (instagram)\\ntarget task: imagenet–9ktarget task: imagenet–1kimagenet top-1 accuracy (in %)\\n10790\\n85\\n80\\n75\\n70\\n65\\n60\\n55\\n50\\n108109\\nnumber of training images in source task (instagram)imagenet top-1 accuracy (in %)\\n10750\\n45\\n40\\n35\\n30\\n25\\n20\\n108109number of training images in source task (instagram)\\ntarget task: cub2011target task: imagenet–5kimagenet top-1 accuracy (in %)\\n10760\\n55\\n50\\n45\\n40\\n35\\n30\\n108109\\nnumber of training images in source task (instagram)accuracy (in %)\\n10790\\n80\\n70\\n60\\n50\\n40\\n108109instagram (1.5k tags)/32×4d\\ninstagram (1.5k tags)/32×8d\\ninstagram (1.5k tags)/32×16dinstagram (17k tags)/32×4d\\ninstagram (17k tags)/32×8d\\ninstagram (17k tags)/32×16d',\n",
       " '58    communications of the acm  |   december 2020  |   vol. 63  |   no. 12contributed articles\\ncan have stronger performance, which \\nis a valuable scientific contribution. \\nhowever, this implies the financial and \\nenvironmental cost of increasingly \\nlarge ai models will not decrease soon, \\nas the pace of model growth far exceeds \\nthe resulting increase in model perfor-\\nmance.18 as a result, more and more \\nresources are going to be required to \\nkeep improving ai models by simply \\nmaking them larger.\\nfinally, we note that in some cases \\nthe price of processing one example \\nmight be different at training and test \\ntime. for instance, some methods tar-\\nget efficient inference by learning a \\nsmaller model based on the large \\ntrained model. these models often do \\nnot lead to more efficient training, as \\nthe cost of e is only reduced at infer-\\nence time. models used in production \\ntypically have computational costs \\ndominated by inference rather than \\ntraining, but in research training is typ-\\nically much more frequent, so we advo-\\ncate studying methods for efficient \\nprocessing of one example in both \\ntraining and inference.\\nprocessing many examples. increased \\namounts of training data have also \\ncontributed to progress in state-of-the-\\nart performance in ai. bert-large had \\ntop performance in 2018 across many \\nnlp tasks after training on three bil-\\nlion word-pieces. xlnet outperformed \\nbert after training on 32 billion word-\\npieces, including part of common \\ncrawl; opengpt-2-xl trained on 40 bil-\\nlion words; fair’s roberta28 was \\ntrained on 160gb of text, roughly 40 \\nbillion word-pieces, requiring around \\n25,000 gpu hours to train. t5-11b36 \\nwas trained on 1 trillion tokens, 300 \\ntimes more than bert-large. in com-\\nputer vision, researchers from face-\\nbook30 pretrained an image classifica-\\ntion model on 3.5 billion images from \\ninstagram, three orders of magnitude \\nlarger than existing labeled image da-\\ntasets such as open images.k\\nthe use of massive data creates barri-\\ners for many researchers to reproducing \\nthe results of these models, and to train-\\ning their own models on the same setup \\n(especially as training for multiple ep-\\nochs is standard). for example, the july \\n2019 common crawl contains 242tb of \\nk https://opensource.google.com/projects/\\nopen-images-datasetuncompressed data,l so even storing the \\ndata is expensive. finally, as in the case of \\nmodel size, relying on more data to im-\\nprove performance is notoriously ex-\\npensive because of the diminishing re -\\nturns of adding more data.48 for instance, \\nfigure 3, taken from mahajan et al.,30 \\nshows a logarithmic relation between \\nthe object recognition top-1 accuracy \\nand the number of training examples.\\nmassive number of experiments. \\nsome projects have poured large \\namounts of computation into tuning \\nhyperparameters or searching over neu-\\nral architectures, well beyond the reach \\nof most researchers. for instance, re-\\nsearchers from google59 trained over \\n12,800 neural networks in their neural \\narchitecture search to improve perfor-\\nmance on object detection and lan-\\nguage modeling. with a fixed architec-\\nture, researchers from deepmind31 \\nevaluated 1,500 hyperparameter assign-\\nments to demonstrate that an lstm \\nlanguage model17 can reach state-of-\\nthe-art perplexity results. despite the \\nvalue of this result in showing that the \\nperformance of an lstm does not pla -\\nteau after only a few hyperparameter \\ntrials, fully exploring the potential of \\nother competitive models for a fair \\ncomparison is prohibitively expensive.\\nthe value of massively increasing \\nthe number of experiments is not as \\nwell studied as the first two discussed \\npreviously. in fact, the number of ex-\\nperiments performed during model \\nconstruction is often underreported. \\nnonetheless, evidence for a logarith-\\nmic relation exists here as well.9,10\\ndiscussion. the increasing costs of \\nai experiments offer a natural econom-\\nic motivation for developing more effi-\\ncient ai methods. it might be the case \\nthat at a certain point prices will be too \\nhigh, forcing even researchers with \\nlarge budgets to develop more efficient \\nmethods. our analysis in figure 2 \\nshows that currently most effort is still \\nbeing dedicated to accuracy rather \\nthan efficiency. at the same time, ai \\ntechnology is already very expensive to \\ntrain or execute, which limits the abili-\\nty of many researchers to study it, and \\nof practitioners to adopt it. combined \\nwith environmental pricetag of ai,47 we \\nbelieve more effort should be devoted \\ntoward efficient ai solutions.\\nl http://commoncrawl.org/2019/07/is common for each training step to re-\\nquire inference, so we discuss training \\nand inference cost together as “pro-\\ncessing” an example (though see dis-\\ncussion below). some works have used \\nincreasingly large models in terms of, \\nfor example, model parameters, and as \\na result, in these models, performing \\ninference can require a lot of computa-\\ntion, and training even more so. for in-\\nstance, google’s bert-large8 contains \\nroughly 350 million parameters. ope-\\nnai’s opengpt2-xl model35 contains \\n1.5 billion parameters. ai2, our home \\norganization, released grover,57 also \\ncontaining 1.5 billion parameters. \\nnvidia released megatron-lm,42 con-\\ntaining over 8 billion parameters. \\ngoogle’s t5-11b36 contains 11 billion \\nparameters. most recently, openai re-\\nleased opengpt-3,4 containing 175 bil-\\nlion parameters. in the computer vi-\\nsion community, a similar trend is \\nobserved (figure 1).\\nsuch large models have high costs \\nfor processing each example, which \\nleads to large training costs. bert-\\nlarge was trained on 64 tpu chips for \\nfour days at an estimated cost of \\n$7,000. grover was trained on 256 tpu \\nchips for two weeks, at an estimated \\ncost of $25,000. xlnet had a similar ar-\\nchitecture to bert-large, but used a \\nmore expensive objective function (in \\naddition to an order of magnitude more \\ndata), and was trained on 512 tpu chips \\nfor 2.5 days, costing more than $60,000.f \\nit is impossible to reproduce the best \\nbert-large results or xlnet results us-\\ning a single gpu,g and models such as \\nopengpt2 are too large to be used in \\nproduction.h specialized models can \\nhave even more extreme costs, such as \\nalphago, the best version of which re-\\nquired 1,920 cpus and 280 gpus to \\nplay a single game of go,44 with an esti-\\nmated cost to reproduce this experi-\\nment of $35,000,000.i,j\\nwhen examining variants of a single \\nmodel (for example, bert-small and \\nbert-large) we see that larger models \\nf https://syncedreview.com/2019/06/27/the-\\nstaggering-cost-of-training-sota-aimodels/\\ng see https://github.com/google-research/bert \\nand https://github.com/zihangdai/xlnet.\\nh https://towardsdatascience.com/too-big-to-\\ndeploy-how-gpt-2-is-breakingproduction-\\n63ab29f0897c\\ni https://www.yuzeh.com/data/agz-cost.html\\nj recent versions of alphago are far more effi-\\ncient.46',\n",
       " 'december 2020  |  vol. 63  |  no. 12  |   communications of the acm    59contributed articles\\nwe argue should be reported when ai \\nresearch findings are published.\\nmeasures of efficiency. to measure \\nefficiency, we suggest reporting the \\namount of work required to generate a \\nresult. specifically, the amount of work \\nrequired to train a model, and if appli-\\ncable, the aggregated amount of work \\nrequired for all hyperparameter tuning \\nexperiments. as the cost of an experi-\\nment decomposes into the cost of a \\nprocessing a single example, the size of \\nthe dataset, and the number of experi-\\nments (equation 1), reducing the \\namount of work in each of these steps \\nwill result in ai that is more green.\\nwe do encourage ai practitioners to \\nuse efficient hardware to reduce energy \\ncosts, but the dramatic increase in \\ncomputational cost observed over re-\\ncent years is primarily from modeling \\nand algorithmic choices; our focus is \\non how to incorporate efficiency there. \\nwhen reporting the amount of work \\ndone by a model, we want to measure a \\nquantity that allows for a fair compari-\\nson between different models. as a re-\\nsult, this measure should ideally be \\nstable across different labs, at different \\ntimes, and using different hardware.\\ncarbon emission. carbon emission \\nis appealing as it is a quantity we want \\nto directly minimize. nonetheless it is \\ndifficult to measure the exact amount \\nof carbon released by training or exe-\\ncuting a model, and accordingly—gen-\\nerating an ai result, as this amount de-\\npends highly on the local electricity \\ninfrastructure (though see initial ef-\\nforts by henderson et al.16 and lacoste \\net al.25). as a result, it is not comparable \\nbetween researchers in different loca-\\ntions or even the same location at dif-\\nferent times.16\\nelectricity usage. electricity usage is \\ncorrelated with carbon emission while \\nbeing time- and location-agnostic. \\nmoreover, gpus often report the \\namount of electricity each of their \\ncores consume at each time point, \\nwhich facilitates the estimation of the \\ntotal amount of electricity consumed \\nby generating an ai result. nonethe-\\nless, this measure is hardware depen-\\ndent, and as a result does not allow for a \\nfair comparison between different mod-\\nels developed on different machines.\\nelapsed real time. the total running \\ntime for generating an ai result is a nat-\\nural measure for efficiency, as all other we want to reiterate that red ai \\nwork is extremely valuable, and in fact, \\nmuch of it contributes to what we know \\nabout pushing the boundaries of ai. in-\\ndeed, there is value in pushing the lim-\\nits of model size, dataset size, and the \\nhyperparameter search budget.\\nin addition, red ai can provide op-\\nportunities for future work to promote \\nefficiency; for example, evaluating a \\nmodel on varying amounts of training \\ndata will provide an opportunity for fu-\\nture researchers to build on the work \\nwithout needing a budget large enough \\nto train on a massive dataset. current-\\nly, despite the massive amount of re-\\nsources put into recent ai models, \\nsuch investment still pays off in terms \\nof downstream performance (albeit at \\nan increasingly lower rate). finding the \\npoint of saturation (if such exists) is an \\nimportant question for the future of ai. \\nmoreover, red ai costs can even some-\\ntimes be amortized, because a red ai \\ntrained module may be reused by many \\nresearch projects as a built-in compo-\\nnent, which doesn’t require retraining.\\nthe goal of this article is twofold: \\nfirst, we want to raise awareness to the \\ncost of red ai and encourage researchers \\nthat use such methods to take steps to al-\\nlow for more equitable comparisons, \\nsuch as reporting training curves. sec-\\nond, we want to encourage the ai com-\\nmunity to recognize the value of work by \\nresearchers that take a different path, \\noptimizing efficiency rather than accu-\\nracy. next, we turn to discuss concrete \\nmeasures for making ai more green.\\ngreen ai\\nthe term green ai refers to ai research \\nthat yields novel results while taking into \\naccount the computational cost, encour-\\naging a reduction in resources spent. \\nwhereas red ai has resulted in rapidly \\nescalating computational (and thus car-\\nbon) costs, green ai promotes approach-\\nes that have favorable performance/effi-\\nciency trade-offs. if measures of \\nefficiency are widely accepted as im -\\nportant evaluation metrics for research \\nalongside accuracy, then researchers \\nwill have the option of focusing on the \\nefficiency of their models with positive \\nimpact on both inclusiveness and the \\nenvironment. here, we review several \\nmeasures of efficiency that could be re-\\nported and optimized, and advocate \\none particular measure—fpo—which some projects \\nhave poured \\nlarge amounts \\nof computation \\ninto tuning \\nhyperparameters \\nor searching \\nover neural \\narchitectures, well \\nbeyond the reach of \\nmost researchers.',\n",
       " '60    communications of the acm  |   december 2020  |   vol. 63  |   no. 12contributed articles\\nbetween different approaches, unlike \\nthe measures described above. third, \\nfpo is often correlated with the run-\\nning time of the model5 (though see \\ndiscussion below). unlike asymptotic \\nruntime, fpo also considers the \\namount of work done at each time step.\\nseveral packages exist for comput-\\ning fpo in various neural network \\nlibraries,n though none of them con-\\ntains all the building blocks required \\nto construct all modern ai models. we \\nencourage the builders of neural net-\\nwork libraries to implement such func-\\ntionality directly.\\ndiscussion. efficient machine learn-\\ning approaches have received attention \\nin the research community but are gen-\\nerally not motivated by being green. for \\nexample, a significant amount of work \\nin the computer vision community has \\naddressed efficient inference,13,38,58 \\nwhich is necessary for real-time process-\\ning of images for applications like self-\\ndriving cars,27,29,37 or for placing models \\non devices such as mobile phones.18,40 \\nmost of these approaches only minimize \\nthe cost of processing a single example, \\nwhile ignoring the other two red practic-\\nes discussed perviously.o other meth-\\nods to improve efficiency aim to devel-\\nop more efficient architectures, starting \\nfrom the adoption of graphical process-\\ning units (gpu) to ai algorithms, which \\nwas the driving force behind the deep \\nlearning revolution, up to more recent \\ndevelopment of hardware such as ten-\\nsor processing units (tpus22).\\nthe examples here indicate the path \\nto making ai green depends on how it \\nis used. when developing a new model, \\nmuch of the research process involves \\ntraining many model variants on a \\ntraining set and performing inference \\non a small development set. in such a \\nsetting, more efficient training proce-\\ndures can lead to greater savings, while \\nin a production setting more efficient \\ninference can be more important. we \\nadvocate for a holistic view of computa-\\ntional savings which doesn’t sacrifice in \\nsome areas to make advances in others.\\nfpo has some limitations. most im-\\nportantly, the energy consumption of a \\nn for example, https://github.com/swall0w/\\ntorchstat; https://github.com/lyken17/\\npytorch-opcounter\\no in fact, creating smaller models often results \\nin longer running time, so mitigating the dif-\\nferent trends might be at odds.52things being equal, a faster model is do-\\ning less computational work. nonethe-\\nless, this measure is highly influenced \\nby factors such as the underlying hard-\\nware, other jobs running on the same \\nmachine, and the number of cores \\nused. these factors hinder the compar-\\nison between different models, as well \\nas the decoupling of modeling contri-\\nbutions from hardware improvements.\\nnumber of parameters. another \\ncommon measure of efficiency is the \\nnumber of parameters (learnable or \\ntotal) used by the model. as with run-\\ntime, this measure is correlated with \\nthe amount of work. unlike the other \\nmeasures described previously, it \\ndoes not depend on the underlying \\nhardware. moreover, this measure \\nalso highly correlates with the \\namount of memory consumed by the \\nmodel. nonetheless, different algo-\\nrithms make different use of their pa-\\nrameters, for instance by making the \\nmodel deeper vs. wider. as a result, \\ndifferent models with a similar num-\\nber of parameters often perform dif-\\nferent amounts of work.\\nfpo. as a concrete measure, we \\nsuggest reporting the total number of \\nfloating-point operations (fpo) re-\\nquired to generate a result.m fpo pro-\\nvides an estimate of the amount of \\nwork performed by a computational \\nprocess. it is computed analytically by \\ndefining a cost to two base operations, \\nadd and mul. based on these opera-\\ntions, the fpo cost of any machine \\nlearning abstract operation (for exam-\\nple, a tanh operation, a matrix multipli-\\ncation, a convolution operation, or the \\nbert model) can be computed as a re-\\ncursive function of these two opera-\\ntions. fpo has been used in the past to \\nquantify the energy footprint of a \\nmodel,13,32,50,51 but is not widely adopt-\\ned in ai. fpo has several appealing \\nproperties. first, it directly computes \\nthe amount of work done by the run-\\nning machine when executing a spe-\\ncific instance of a model and is thus \\ntied to the amount of energy con-\\nsumed. second, fpo is agnostic to \\nthe hardware on which the model is \\nrun. this facilitates fair comparisons \\nm floating point operations are often referred to \\nas flop(s), though this term is not uniquely \\ndefined.13 to avoid confusion, we use the term \\nfpo.the term green ai  \\nrefers to ai \\nresearch that yields \\nnovel results while \\ntaking into account \\nthe computational \\ncost, encouraging \\na reduction in \\nresources spent.',\n",
       " 'december 2020  |  vol. 63  |  no. 12  |   communications of the acm    61contributed articles\\nlead to efficient models should be cred-\\nited by the ai community.\\nfpo cost of existing models. to \\ndemonstrate the importance of report-\\ning the amount of work, we present \\nfpo costs for several existing models.q \\nfigure 4(a) shows the number of pa-\\nrameters and fpo of several leading \\nobject recognition models, as well as \\ntheir performance on the imagenet \\nq these numbers represent fpo per inference, \\nthat is, the work required to process a single \\nexample.model is not only influenced by the \\namount of work, but also from other \\nfactors such as the communication be-\\ntween the different components, which \\nis not captured by fpo. as a result, fpo \\ndoesn’t always correlate with other mea-\\nsures such as runtime21 and energy con-\\nsumption.16 second, fpo targets the \\nnumber of operations performed by a \\nmodel, while ignoring other potential \\nlimiting factors for researchers such as \\nthe memory used by the model, which \\ncan often lead to additional energy and \\nmonetary costs.29 finally, the amount of work done by a model largely depends \\non the model implementation, as two \\ndifferent implementations of the same \\nmodel could result in very different \\namounts of processing work. due to the \\nfocus on the modeling contribution, the \\nai community has traditionally ignored \\nthe quality or efficiency of models’ im-\\nplementation.p we argue the time to re-\\nverse this norm has come, and that ex-\\nceptionally good implementations that \\np we consider this exclusive focus on the final \\nprediction another symptom of red ai.figure 4. increase in fpo leads to diminishing return for object detection top-1 accuracy. plots (bottom to top): model parameters (in million), \\nfpo (in billions), top-1 accuracy on imagenet. 4(a). leading object recognition models: alexnet,24 resnet,15 resnext,55 dpn107,6 senet154.19 \\n4(b): comparison of different sizes (measured by the number of layers) of the resnet model.15\\n87\\n56.4\\n0.7\\n61.1\\n70.1\\n1.83.7 4.17.811.673.676.077.478.460.2\\nresnet152\\n2015resnext\\n2017\\nmodel/yeardpn107\\n2017senet154\\n2018alexnet\\n201283.5115.111.615.518.420.878.479.0 79.781.3\\n70acc.\\n55\\n26\\n13fbo (b)\\n0\\n130\\n90params (m)\\n50\\n82\\n75acc.\\n68\\n15\\n10\\n5\\n0fbo (b)\\n75\\n50\\n50params (m)\\n0\\n18 34 50 101\\nnumber of layers152',\n",
       " '62    communications of the acm  |   december 2020  |   vol. 63  |   no. 12contributed articles\\nto recognize and value contributions \\nthat do not strictly improve state of the \\nart but have other benefits such as effi-\\nciency. finally, we note that the trend of \\nreleasing pretrained models publicly is \\na green success, and we would like to \\nencourage organizations to continue \\nto release their models in order to save \\nothers the costs of retraining them.\\nrelated work\\nrecent work has analyzed the carbon \\nemissions of training deep nlp mod-\\nels47 and concluded that computation-\\nally expensive experiments can have a \\nlarge environmental and economic \\nimpact. with modern experiments us-\\ning such large budgets, many re-\\nsearchers (especially those in aca-\\ndemia) lack the resources to work in \\nmany high-profile areas; increased \\nvalue placed on computationally effi-\\ncient approaches will allow research \\ncontributions from more diverse \\ngroups. we emphasize that the con-\\nclusions of stubell et al.47 are the re-\\nsult of long-term trends, and are not \\nisolated within nlp, but hold true \\nacross machine learning.\\nwhile some companies offset elec-\\ntricity usage by purchasing carbon \\ncredits, it is not clear that buying cred-\\nits is as effective as using less energy. \\nin addition, purchasing carbon cred-\\nits is voluntary; google clouds and mi-\\ncrosoft azuret purchase carbon credits \\nto offset their spent energy, but ama-\\nzon’s awsu (the largest cloud comput-\\ning platformv) only covered 50% of its \\npower usage with renewable energy.\\nthe push to improve state-of-the-art \\nperformance has focused the research \\ncommunity’s attention on reporting the \\nsingle best result after running many ex-\\nperiments for model development and \\nhyperparameter tuning. failure to fully \\nreport these experiments prevents fu-\\nture researchers from understanding \\nhow much effort is required to repro-\\nduce a result or extend it.9\\nour focus is on improving efficien-\\ncy in the machine learning communi-\\nty, but machine learning can also be \\nused as a tool for work in areas like \\ns https://cloud.google.com/sustainability/\\nt https://www.microsoft.com/en-us/environ-\\nment/carbon\\nu https://aws.amazon.com/about-aws/sustain-\\nability/\\nv https://tinyurl.com/y2kob969climate change. for example, ma-\\nchine learning has been used for re-\\nducing emissions of cement plants1 \\nand tracking animal conservation \\noutcomes,12 and is predicted to be \\nuseful for forest fire management.39 \\nundoubtedly these are important ap-\\nplications of machine learning; we \\nrecognize they are orthogonal to the \\ncontent of this article.\\nconclusion\\nthe vision of green ai raises many ex-\\nciting research directions that help to \\novercome the challenges of red ai. \\nprogress will find more efficient ways \\nto allocate a given budget to improve \\nperformance, or to reduce the compu-\\ntational expense with a minimal re-\\nduction in performance. also, it would \\nseem that green ai could be moving us \\nin a more cognitively plausible direc-\\ntion as the brain is highly efficient.\\nit is important to reiterate that we see \\ngreen ai as a valuable option, not an ex-\\nclusive mandate—of course, both green \\nai and red ai have contributions to \\nmake. our goals are to augment red ai  \\nwith green ideas, like using more effi-\\ncient training methods, and reporting \\ntraining curves; and to increase the prev-\\nalence of green ai by highlighting its \\nbenefits, advocating a standard measure \\nof efficiency. here, we point to a few im-\\nportant green research directions, and \\nhighlight a few open questions.\\nresearch on building space- or time-\\nefficient models is often motivated by \\nfitting a model on a small device (such \\nas a phone) or fast enough to process ex-\\namples in real time, such as image cap-\\ntioning for the blind (as discussed previ-\\nously). here, we argue for a far broader \\napproach that promotes efficiency for \\nall parts of the ai development cycle.\\ndata efficiency has received signifi-\\ncant attention over the years.23,41,49 \\nmodern research in vision and nlp of-\\nten involves first pretraining a model \\non large “raw” (unannotated) data \\nthen finetuning it to a task of interest \\nthrough supervised learning. a strong \\nresult in this area often involves \\nachieving similar performance to a \\nbaseline with fewer training examples \\nor fewer gradient steps. most recent \\nwork has addressed fine-tuning data,34 \\nbut pretraining efficiency is also im-\\nportant. in either case, one simple \\ntechnique to improve in this area is to dataset.7,r a few trends are observable. \\nfirst, as discussed earlier, models get \\nmore expensive with time, but the in-\\ncrease in fpo does not lead to similar \\nperformance gains. for instance, an \\nincrease of almost 35% in fpo between \\nresnet and resnext (second and third \\npoints in graph) resulted in a 0.5% top-1 \\naccuracy improvement. similar pat-\\nterns are observed when considering \\nthe effect of other increases in model \\nwork. second, the number of model pa-\\nrameters does not tell the whole story: \\nalexnet (first point in the graph) actu-\\nally has more parameters than resnet \\n(second point), but dramatically less \\nfpo, and also much lower accuracy.\\nfigure 4(b) shows the same analysis \\nfor a single object recognition model, \\nresnet,15 while comparing different ver-\\nsions of the model with different num-\\nbers of layers. this creates a controlled \\ncomparison between the different mod-\\nels, as they are identical in architecture, \\nexcept for their size (and accordingly, \\ntheir fpo cost). once again, we notice \\nthe same trend: the large increase in \\nfpo cost does not translate to a large in-\\ncrease in performance.\\nadditional ways to promote green \\nai. there are many ways to encourage \\nresearch that is more green. in addi-\\ntion to reporting the fpo cost for each \\nterm in equation 1, we encourage re-\\nsearchers to report budget/perfor-\\nmance curves where possible. for ex-\\nample, training curves provide \\nopportunities for future researchers to \\ncompare at a range of different bud-\\ngets and running experiments with dif-\\nferent model sizes provides valuable \\ninsight into how model size impacts \\nperformance. in a recent paper,9 we ob-\\nserved that the claim as to which model \\nperforms best depends on the compu-\\ntational budget available during model \\ndevelopment. we introduced a method \\nfor computing the expected best vali-\\ndation performance of a model as a \\nfunction of the given budget. we argue \\nthat reporting this curve will allow us-\\ners to make wiser decisions about their \\nselection of models and highlight the \\nstability of different approaches.\\nwe further advocate for making ef-\\nficiency an official contribution in ma-\\njor ai conferences by advising reviewers \\nr numbers taken from https://github.com/\\nsovrasov/flops-counter.pytorch.',\n",
       " 'december 2020  |  vol. 63  |  no. 12  |   communications of the acm    63contributed articles\\nsimply report performance with dif-\\nferent amounts of training data. for \\nexample, reporting performance of \\ncontextual embedding models trained \\non 10 million, 100 million, 1 billion, \\nand 10 billion tokens would facilitate \\nfaster development of new models, as \\nthey can first be compared at the \\nsmallest data sizes.\\nresearch here is of value not just to \\nmake training less expensive, but be-\\ncause in areas such as low resource lan-\\nguages or historical domains it is ex-\\ntremely difficult to generate more data, \\nso to progress we must make more ef-\\nficient use of what is available.\\nfinally, the total number of experi-\\nments run to get a final result is often \\nunderreported and underdiscussed.9 \\nthe few instances researchers have of \\nfull reporting of the hyperparameter \\nsearch, architecture evaluations, and \\nablations that went into a reported ex-\\nperimental result has surprised the \\ncommunity.47 while many hyperpa-\\nrameter optimization algorithms ex-\\nist, which can reduce the computa-\\ntional expense required to reach a \\ngiven level of performance,3,11 simple \\nimprovements here can have a large \\nimpact. for example, stopping train-\\ning early for models that are clearly \\nunderperforming can lead to great \\nsavings.26\\nacknowledgment. this research was \\nconducted at the allen institute for ai. \\nreferences\\n1. acharyya, p., rosario, s.d., flor, f., joshi, r., li, d., linares, \\nr, and zhang, h. autopilot of cement plants for reduction \\nof fuel consumption and emissions. in proceedings of \\nicml workshop on climate change, 2019.\\n2. amodei, d. and hernandez, d. ai and compute, 2018. \\nblog post.\\n3. bergstra, j.s., bardenet, r., bengio, y. and kégl, b. \\nalgorithms for hyper-parameter optimization. in \\nproceedings of neurips, 2011.\\n4. brown, t.b. et al. language models are few-shot \\nlearners, 2020; arxiv:2005.14165.\\n5. canziani, a., paszke, a. and culurciello, e. an \\nanalysis of deep neural network models for practical \\napplications. in proceedings of iscas, 2017.\\n6. chen, y., li, j., xiao, h., jin, x., yan, s. and feng, j. dual \\npath networks. in proceedings of neurips, 2017.\\n7. deng, j., dong, w., socher, r., li, l-j, li, k. and fei-\\nfei, l. imagenet: a large-scale hierarchical image \\ndatabase. in proceedings of cvpr, 2009.\\n8. devlin, j., chang, m.w., lee, k., and toutanova, k. bert:  \\npretraining of deep bidirectional transformers for \\nlanguage understanding. in proceedings of naacl, 2019.\\n9. dodge, j., gururangan, s., card, d., schwartz, r. and \\nsmith, n.a. show your work: improved reporting of \\nexperimental results. in proceedings of emnlp, 2019.\\n10. dodge, j., ilharco, g., schwartz, r., farhadi, a., \\nhajishirzi, h. and smith, n.a. fine-tuning pretrained \\nlanguage models: weight initializations, data orders, \\nand early stopping, 2020; arxiv:2002.06305.\\n11. dodge, j., jamieson, k. and smith, n.a. open loop \\nhyperparameter optimization and determinantal point \\nprocesses. in proceedings of automl, 2017.\\n12. duhart, c., dublon, g., mayton, b., davenport, g. and \\nparadiso, j.a. deep learning for wildlife conservation and restoration efforts. in proceedings of icml \\nworkshop on climate change, 2019.\\n13. gordon, a., eban, e., nachum, o., chen, b., wu, h., \\nyang, t-j, and choi, e. morphnet: fast & simple \\nresource-constrained structure learning of deep \\nnetworks. in proceedings of cvpr, 2018.\\n14. halevy, a., norvig, p. and pereira, f. the unreasonable \\neffectiveness of data. ieee intelligent systems 24 \\n(2009), 8–12.\\n15. he, k., zhang, x., ren, s. and sun, j. deep residual \\nlearning for image recognition. in proceedings of \\ncvpr, 2016.\\n16. henderson, p., hu, j., romoff, j., brunskill, e., \\njurafsky, d. and pineau, j. towards the systematic \\nreporting of the energy and carbon footprints of \\nmachine learning, 2020; arxiv:2002.05651.\\n17. hochreiter, s. and schmidhuber, j. long short-term \\nmemory. neural computation 9, 8 (1997), 1735–1780.\\n18. howard, a.g. et al. mobilenets: efficient convolutional \\nneural networks for mobile vision applications, 2017; \\narxiv:1704.04861.\\n19. hu, j., shen, l. and sun, g. squeeze-and-excitation \\nnetworks. in proceedings of cvpr, 2018.\\n20. huang, j. et al. speed/accuracy trade-offs for modern \\nconvolutional object detectors. in proceedings of \\ncvpr, 2017.\\n21. jeon, y. and kim, j. constructing fast network through \\ndeconstruction of convolution. in proceedings of \\nneurips, 2018.\\n22. jouppi, n.p. et al. in-datacenter performance analysis \\nof a tensor processing unit. in proceedings of isca 1, \\n1 (2017), publ. date: june 2020.\\n23. kamthe, s. and deisenroth, m.p. data-efficient \\nreinforcement learning with probabilistic model \\npredictive control. in proceedings of aistats, 2018.\\n24. krizhevsky, a., sutskever, i. and hinton, g.e. imagenet \\nclassification with deep convolutional neural \\nnetworks. in proceedings of neurips, 2012.\\n25. lacoste, a., luccioni, a., schmidt, v. and dandres, t. \\nquantifying the carbon emissions of machine learning. in \\nproceedings of the climate change ai workshop, 2019.\\n26. li, l., jamieson, k., desalvo, g., rostamizadeh, a. and \\ntalwalkar, a. hyperband: bandit-based configuration \\nevaluation for hyperparameter optimization. in \\nproceedings of iclr, 2017.\\n27. liu, w., anguelov, d., erhan, d., szegedy, c., reed, \\ns. fu, c-y and berg, a.c. ssd: single shot multibox \\ndetector. in proceedings of eccv, 2016.\\n28. liu, y. et al. roberta: a robustly optimized bert \\npretraining approach, 2019; arxiv:1907.11692.\\n29. ma, n., zhang, x., zheng, h.t and sun, j. shufflenet \\nv2: practical guidelines for efficient cnn architecture \\ndesign. in proceedings of eccv, 2018.\\n30. mahajan, d. et al. exploring the limits of weakly \\nsupervised pretraining, 2018; arxiv:1805.00932.\\n31. melis, g., dyer, c. and blunsom, p. on the state of \\nthe art of evaluation in neural language models. in \\nproceedings of emnlp, 2018.\\n32. molchanov, p., tyree, s., karras, t., aila, t. and kautz, \\nj. pruning convolutional neural networks for resource \\nefficient inference. in proceedings of iclr, 2017.\\n33. moore, g.e. cramming more components onto \\nintegrated circuits, 1965.\\n34. peters, m., neumann, m., iyyer, m., gardner, m., clark, \\nc., lee, k. and zettlemoyer, l. deep contextualized \\nword representations. in proceedings of naacl, 2018.\\n35. radford, a., wu, j., child, r., luan, d., amodei, d. and \\nsutskever, i. language m odels are unsupervised \\nmultitask learners.. openai blog, 2019.\\n36. raffel, c. et al. exploring the limits of transfer \\nlearning with a unified text-to-text transformer, 2019; \\narxiv:1910.10683.\\n37. rastegari, m., ordonez, v., redmon, j. and farhadi, \\na. xnornet: imagenet classification using binary \\nconvolutional neural networks. in proceedings of \\neccv, 2016.\\n38. redmon, j., divvala, s., girshick, r. and farhadi, a. you \\nonly look once: unified, real-time object detection. in \\nproceedings of cvpr, 2016.\\n39. rolnick, d. et al. tackling climate change with machine \\nlearning, 2019; arxiv:1905.12616.\\n40. sandler, m., howard, a., zhu, m., zhmoginov, a. and \\nchen, l.c. mobilenetv2: inverted residuals and linear \\nbottlenecks. in proceedings of cvpr, 2018.\\n41. schwartz, r., thomson, s. and smith, n.a. sopa: \\nbridging cnns, rnns, and weighted finite-state \\nmachines. in proceedings of acl, 2018.\\n42. shoeybi, m., patwary, m., puri, r., legresley, p., casper, \\nj., catanzaro, b. megatron-lm: training multi-billion \\nparameter language models using gpu model \\nparallelism, 2019; arxiv:1909.08053.43. shoham, y. et al. the ai index 2018 annual report. \\nai index steering committee, human-centered ai \\ninitiative, stanford university; http:// cdn.aiindex.org/ \\n2018/ai%20index%202018%20annual%20report.pdf.\\n44. silver, d. et al. mastering the game of go with deep \\nneural networks and tree search. nature 529, 7587 \\n(2016) 484.\\n45. silver, d. et al. mastering chess and shogi by self-play \\nwith a general reinforcement learning algorithm, 2017; \\narxiv:1712.01815.\\n46. silver, d. et al. mastering the game of go without \\nhuman knowledge. nature 550, 7676 (2017), 354.\\n47. strubell, e., ganesh, a. and mccallum, a. energy and \\npolicy considerations for deep learning in nlp. in \\nproceedings of acl, 2019.\\n48. sun, c., shrivastava, a., singh, s. and gupta, a. \\nrevisiting unreasonable effectiveness of data in deep \\nlearning era. in proceedings of iccv, 2017.\\n49. tsang, i., kwok, j.t. and cheung, p.m. core vector \\nmachines: fast svm training on very large data sets. \\njmlr 6 (apr. 2005), 363–392.\\n50. vaswani, a., shazeer, n., parmar, n., uszkoreit, j., jones, \\nl., gomez, a.n., kaiser, l. and polosukhin, i. attention is \\nall you need. in proceedings of neurips, 2017.\\n51. veniat, t. and denoyer, l. learning time/memory-\\nefficient deep architectures with budgeted super \\nnetworks. in proceedings of cvpr, 2018.\\n52. walsman, a., bisk, y., gabriel, s., misra, d., artzi, y., \\nchoi, y. and fox, d. early fusion for goal directed \\nrobotic vision. in proceedings of iros, 2019.\\n53. wang, a. pruksachatkun, y., nangia, n., singh, \\na., michael, j., hill, f., levy, o. and bowman, s.r. \\nsuperglue: a stickier benchmark for general-\\npurpose language understanding systems, 2019; \\narxiv:1905.00537.\\n54. wang, a., singh, a., michael, j., hill, f., levy, o. and \\nbowman, s.r. glue: a multi-task benchmark and \\nanalysis platform for natural language understanding. \\nin proceedings of iclr, 2019.\\n55. xie, s., girshick, r., dollar, p., tu, z. and he, k. \\naggregated residual transformations for deep neural \\nnetworks. in proceedings of cvpr, 2017.\\n56. yang, z., dai, z., yang, y., carbonell, j., salakhutdinov, \\nr. and le, q.v. xlnet: generalized autoregressive \\npretraining for language understanding, 2019; \\narxiv:1906.08237.\\n57. zellers, r., holtzman, a., rashkin, h., bisk, y., farhadi, \\na., roesner, f. and choi, y. defending against neural \\nfake news, 2019; arxiv:1905.12616.\\n58. zhang, x., zhou, x., lin, m. and sun, j. shufflenet: an \\nextremely efficient convolutional neural network for \\nmobile devices. in proceedings of cvpr, 2018.\\n59. zoph, b. and le, q.v. neural architecture search with \\nreinforcement learning. in proceedings of iclr, 2017.\\nroy schwartz (roys@allenai.org) is senior lecturer at  \\nthe hebrew university of jerusalem, israel.\\njesse dodge (dodgejesse@gmail.com), language \\ntechnologies institute, carnegie mellon university, \\npittsburgh, pa, usa.\\nnoah a. smith (noah@allenai.org) is a professor of \\ncomputer science and engineering at the university \\nof washington and senior research manager for the \\nallennlp team at allen institute for ai and, seattle, \\nwa, usa.\\noren etzioni (orene@allenai.org) is chief executive \\nofficer of the allen institute for ai, and a professor  \\nof computer science at the university of washington, \\nseattle, wa, usa.\\ncopyright held by authors/owners.  \\nthis work is licensed under a creative commons \\nattribution international 4.0 license.\\nwatch the authors discuss  \\nthis work in the exclusive \\ncommunications video.  \\nhttps://cacm.acm.org/videos/\\ngreen-ai',\n",
       " 'click\\tto\\tsee\\tthe\\tmap\\tin\\tthe\\tfull\\tscale\\tor\\tdownload\\t map\\tin\\tpdf\\tformat\\there\\nanatomy\\tof\\tan\\tai\\nsystem\\nthe\\tamazon\\techo\\tas\\tan\\tanatomical\\tmap\\tof\\thuman\\tlabor ,\\tdata\\tand\\tplanetary\\tresources\\nby\\tkate\\tcrawford\\t \\tand\\tvladan\\tjoler\\t \\t\\n(2018)1 2\\ni\\na\\tcylinder\\tsits\\tin\\ta\\troom.\\tit\\tis\\timpassive,\\tsmooth, \\tsimple\\tand\\tsmall.\\tit\\tstands\\t14.8cm\\thigh,\\twith\\ta\\tsi ngle\\tblue-green\\tcircular\\tlight\\tthat\\ntraces\\taround\\tits\\tupper\\trim.\\tit\\tis\\tsilently\\tattendi ng.\\ta\\twoman\\twalks\\tinto\\tthe\\troom,\\tcarrying\\ta\\tsleepin g\\tchild\\tin\\ther\\tarms,\\tand\\tshe\\naddresses\\tthe\\tcylinder.\\n‘alexa,\\tturn\\ton\\tthe\\thall\\tlights’\\nthe\\tcylinder\\tsprings\\tinto\\tlife.\\t‘ok.’\\tthe\\troom\\tligh ts\\tup.\\tthe\\twoman\\tmakes\\ta\\tfaint\\tnodding\\tgesture,\\tand \\tcarries\\tthe\\tchild\\tupstairs.\\nthis\\tis\\tan\\tinteraction\\twith\\tamazon’s\\techo\\tdevice.\\t \\t a\\tbrief\\tcommand\\tand\\ta\\tresponse\\tis\\tthe\\tmost\\tcommon\\tf orm\\tof\\tengagement\\nwith\\tthis\\tconsumer\\tvoice-enabled\\tai\\tdevice.\\tbut\\tin\\t this\\tfleeting\\tmoment\\tof\\tinteraction,\\ta\\tvast\\tmatrix\\t of\\tcapacities\\tis\\tinvoked:\\ninterlaced\\tchains\\tof\\tresource\\textraction,\\thuman\\tlab or\\tand\\talgorithmic\\tprocessing\\tacross\\tnetworks\\tof\\tmi ning,\\tlogistics,\\tdistribution,\\nprediction\\tand\\toptimization.\\tthe\\tscale\\tof\\tthis\\tsyst em\\tis\\talmost\\tbeyond\\thuman\\timagining.\\thow\\tcan\\twe\\tbeg in\\tto\\tsee\\tit,\\tto\\tgrasp\\tits\\nimmensity\\tand\\tcomplexity\\tas\\ta\\tconnected\\tform?\\t we\\tstart\\twith\\tan\\toutline:\\tan\\texploded\\tview\\tof\\ta\\tpla netary\\tsystem\\tacross\\nthree\\tstages\\tof\\tbirth,\\tlife\\tand\\tdeath,\\taccompanied\\t by\\tan\\tessay\\tin\\t21\\tparts.\\ttogether,\\tthis\\tbecomes\\tan\\t anatomical\\nmap\\tof\\ta\\tsingle\\tai\\tsystem.3',\n",
       " 'amazon\\techo\\tdot\\t(schematics)\\nii\\nthe\\tscene\\tof\\tthe\\twoman\\ttalking\\tto\\talexa\\tis\\tdrawn\\tfr om\\ta\\t2017\\tpromotional\\tvideo\\tadvertising\\tthe\\tlatest\\t version\\tof\\tthe\\tamazon\\necho.\\tthe\\tvideo\\tbegins,\\t“say\\thello\\tto\\tthe\\tall-new\\te cho”\\tand\\texplains\\tthat\\tthe\\techo\\twill\\tconnect\\tto\\tale xa\\t(the\\tartificial\\tintelligence\\nagent)\\tin\\torder\\tto\\t“play\\tmusic,\\tcall\\tfriends\\tand\\tfa mily,\\tcontrol\\tsmart\\thome\\tdevices,\\tand\\tmore.”\\tthe\\tde vice\\tcontains\\tseven\\ndirectional\\tmicrophones,\\tso\\tthe\\tuser\\tcan\\tbe\\theard\\ta t\\tall\\ttimes\\teven\\twhen\\tmusic\\tis\\tplaying.\\tthe\\tdevice\\t comes\\tin\\tseveral\\tstyles,\\tsuch\\nas\\tgunmetal\\tgrey\\tor\\ta\\tbasic\\tbeige,\\tdesigned\\tto\\teith er\\t“blend\\tin\\tor\\tstand\\tout.”\\tbut\\teven\\tthe\\tshiny\\tdesi gn\\toptions\\tmaintain\\ta\\tkind\\tof\\nblankness:\\tnothing\\twill\\talert\\tthe\\towner\\tto\\tthe\\tvast \\tnetwork\\tthat\\tsubtends\\tand\\tdrives\\tits\\tinteractive\\tc apacities.\\tthe\\tpromotional\\nvideo\\tsimply\\tstates\\tthat\\tthe\\trange\\tof\\tthings\\tyou\\tca n\\task\\talexa\\tto\\tdo\\tis\\talways\\texpanding.\\t“because\\tale xa\\tis\\tin\\tthe\\tcloud,\\tshe\\tis\\nalways\\tgetting\\tsmarter\\tand\\tadding\\tnew\\tfeatures.”\\nhow\\tdoes\\tthis\\thappen?\\talexa\\tis\\ta\\tdisembodied\\tvoice\\t that\\trepresents\\tthe\\thuman-ai\\tinteraction\\tinterface\\t for\\tan\\textraordinarily\\ncomplex\\tset\\tof\\tinformation\\tprocessing\\tlayers.\\tthese \\tlayers\\tare\\tfed\\tby\\tconstant\\ttides:\\tthe\\tflows\\tof\\thum an\\tvoices\\tbeing\\ttranslated\\ninto\\ttext\\tquestions,\\twhich\\tare\\tused\\tto\\tquery\\tdataba ses\\tof\\tpotential\\tanswers,\\tand\\tthe\\tcorresponding\\tebb \\tof\\talexa’s\\treplies.\\tfor\\neach\\tresponse\\tthat\\talexa\\tgives,\\tits\\teffectiveness\\ti s\\tinferred\\tby\\twhat\\thappens\\tnext:\\nis\\tthe\\tsame\\tquestion\\tuttered\\tagain?\\t( did\\tthe\\tuser\\tfeel\\theard? )\\nwas\\tthe\\tquestion\\treworded?\\t( did\\tthe\\tuser\\tfeel\\tthe\\tquestion\\twas\\tunderstood? )\\nwas\\tthere\\tan\\taction\\tfollowing\\tthe\\tquestion?\\t( did\\tthe\\tinteraction\\tresult\\tin\\ta\\ttracked\\tresponse:\\ta \\tlight\\tturned\\ton,\\ta\\tproduct\\npurchased,\\ta\\ttrack\\tplayed? )\\nwith\\teach\\tinteraction,\\talexa\\tis\\ttraining\\tto\\thear\\tbe tter,\\tto\\tinterpret\\tmore\\tprecisely,\\tto\\ttrigger\\tactio ns\\tthat\\tmap\\tto\\tthe\\tuser’s\\ncommands\\tmore\\taccurately,\\tand\\tto\\tbuild\\ta\\tmore\\tcompl ete\\tmodel\\tof\\ttheir\\tpreferences,\\thabits\\tand\\tdesires. \\twhat\\tis\\trequired\\tto\\nmake\\tthis\\tpossible?\\t put\\tsimply:\\teach\\tsmall\\tmoment\\tof\\tconvenience\\t–\\tbe\\ti t\\tanswering\\ta\\tquestion,\\tturning\\ton\\ta\\tlight,\\tor\\nplaying\\ta\\tsong\\t–\\trequires\\ta\\tvast\\tplanetary\\tnetwork, \\tfueled\\tby\\tthe\\textraction\\tof\\tnon-renewable\\tmaterial s,\\tlabor,\\tand\\ndata.\\tthe\\tscale\\tof\\tresources\\trequired\\tis\\tmany\\tmagnitudes \\tgreater\\tthan\\tthe\\tenergy\\tand\\tlabor\\tit\\twould\\ttake\\ta\\t human\\tto\\toperate\\ta\\nhousehold\\tappliance\\tor\\tflick\\ta\\tswitch.\\ta\\tfull\\taccou nting\\tfor\\tthese\\tcosts\\tis\\talmost\\timpossible,\\tbut\\tit\\t is\\tincreasingly\\timportant\\tthat\\twe\\ngrasp\\tthe\\tscale\\tand\\tscope\\tif\\twe\\tare\\tto\\tunderstand\\ta nd\\tgovern\\tthe\\ttechnical\\tinfrastructures\\tthat\\tthread \\tthrough\\tour\\tlives.\\niii',\n",
       " \"the\\tsalar,\\tthe\\tworld's\\tlargest\\tflat\\tsurface,\\tis\\tloc ated\\tin\\tsouthwest\\tbolivia\\tat\\tan\\taltitude\\tof\\t3,656\\tm eters\\tabove\\tsea\\tlevel.\\tit\\tis\\ta\\thigh\\nplateau,\\tcovered\\tby\\ta\\tfew\\tmeters\\tof\\tsalt\\tcrust\\twhic h\\tare\\texceptionally\\trich\\tin\\tlithium,\\tcontaining\\t50% \\tto\\t70%\\tof\\tthe\\tworld's\\tlithium\\nreserves.\\t \\tthe\\tsalar,\\talongside\\tthe\\tneighboring\\tata cama\\tregions\\tin\\tchile\\tand\\targentina,\\tare\\tmajor\\tsite s\\tfor\\tlithium\\textraction.\\tthis\\nsoft,\\tsilvery\\tmetal\\tis\\tcurrently\\tused\\tto\\tpower\\tmobi le\\tconnected\\tdevices,\\tas\\ta\\tcrucial\\tmaterial\\tused\\tfo r\\tthe\\tproduction\\tof\\tlithium-ion\\nbatteries.\\tit\\tis\\tknown\\tas\\t‘grey\\tgold.’\\tsmartphone\\tb atteries,\\tfor\\texample,\\tusually\\thave\\tless\\tthan\\teight \\tgrams\\tof\\tthis\\tmaterial.\\t \\teach\\nt esla\\tcar\\tneeds\\tapproximately\\tseven\\tkilograms\\tof\\tli thium\\tfor\\tits\\tbattery\\tpack.\\t \\tall\\tthese\\tbatteries\\tha ve\\ta\\tlimited\\tlifespan,\\tand\\tonce\\nconsumed\\tthey\\tare\\tthrown\\taway\\tas\\twaste.\\tamazon\\tremi nds\\tusers\\tthat\\tthey\\tcannot\\topen\\tup\\tand\\trepair\\ttheir \\techo,\\tbecause\\tthis\\nwill\\tvoid\\tthe\\twarranty.\\tthe\\tamazon\\techo\\tis\\twall-pow ered,\\tand\\talso\\thas\\ta\\tmobile\\tbattery\\tbase.\\tthis\\talso \\thas\\ta\\tlimited\\tlifespan\\tand\\nthen\\tmust\\tbe\\tthrown\\taway\\tas\\twaste.\\naccording\\tto\\tthe\\taymara\\tlegends\\tabout\\tthe\\tcreation\\t of\\tbolivia,\\tthe\\tvolcanic\\tmountains\\tof\\tthe\\tandean\\tpl ateau\\twere\\tcreations\\tof\\ntragedy.\\t \\tlong\\tago,\\twhen\\tthe\\tvolcanos\\twere\\talive\\tan d\\troaming\\tthe\\tplains\\tfreely,\\ttunupa\\t-\\tthe\\tonly\\tfema le\\tvolcano\\t–\\tgave\\tbirth\\tto\\ta\\nbaby.\\tstricken\\tby\\tjealousy,\\tthe\\tmale\\tvolcanos\\tstole \\ther\\tbaby\\tand\\tbanished\\tit\\tto\\ta\\tdistant\\tlocation.\\tth e\\tgods\\tpunished\\tthe\\tvolcanos\\nby\\tpinning\\tthem\\tall\\tto\\tthe\\tearth.\\tgrieving\\tfor\\tthe\\t child\\tthat\\tshe\\tcould\\tno\\tlonger\\treach,\\ttunupa\\twept\\td eeply.\\ther\\ttears\\tand\\tbreast\\nmilk\\tcombined\\tto\\tcreate\\ta\\tgiant\\tsalt\\tlake:\\tsalar\\tde \\tuyuni.\\tas\\tliam\\tyoung\\tand\\tkate\\tdavies\\tobserve,\\t“you r\\tsmart-phone\\truns\\ton\\tthe\\ntears\\tand\\tbreast\\tmilk\\tof\\ta\\tvolcano.\\tthis\\tlandscape\\t is\\tconnected\\tto\\teverywhere\\ton\\tthe\\tplanet\\tvia\\tthe\\tph ones\\tin\\tour\\tpockets;\\tlinked\\tto\\neach\\tof\\tus\\tby\\tinvisible\\tthreads\\tof\\tcommerce,\\tscienc e,\\tpolitics\\tand\\tpower.”\\t\\niv\\nour\\texploded\\tview\\tdiagram\\tcombines\\tand\\tvisualizes\\tt hree\\tcentral,\\textractive\\tprocesses\\tthat\\tare\\trequire d\\tto\\trun\\ta\\tlarge-scale\\nartificial\\tintelligence\\tsystem:\\t material\\tresources,\\thuman\\tlabor,\\tand\\tdata. \\twe\\tconsider\\tthese\\tthree\\telements\\tacross\\ttime\\t–\\nrepresented\\tas\\ta\\tvisual\\tdescription\\tof\\tthe\\tbirth,\\tl ife\\tand\\tdeath\\tof\\ta\\tsingle\\tamazon\\techo\\tunit.\\tit’s\\tne cessary\\tto\\tmove\\tbeyond\\ta\\tsimple\\nanalysis\\tof\\tthe\\trelationship\\tbetween\\tan\\tindividual\\t human,\\ttheir\\tdata,\\tand\\tany\\tsingle\\ttechnology\\tcompan y\\tin\\torder\\tto\\tcontend\\twith\\nwith\\tthe\\ttruly\\tplanetary\\tscale\\tof\\textraction.\\tvince nt\\tmosco\\thas\\tshown\\thow\\tthe\\tethereal\\tmetaphor\\tof\\t‘th e\\tcloud’\\tfor\\toffsite\\tdata\\nmanagement\\tand\\tprocessing\\tis\\tin\\tcomplete\\tcontradict ion\\twith\\tthe\\tphysical\\trealities\\tof\\tthe\\textraction\\to f\\tminerals\\tfrom\\tthe\\tearth’s\\ncrust\\tand\\tdispossession\\tof\\thuman\\tpopulations\\tthat\\ts ustain\\tits\\texistence.\\t \\tsandro\\tmezzadra\\tand\\tbrett\\tni elson\\tuse\\tthe\\tterm\\n‘extractivism’\\tto\\tname\\tthe\\trelationship\\tbetween\\tdif ferent\\tforms\\tof\\textractive\\toperations\\tin\\tcontempora ry\\tcapitalism,\\twhich\\twe\\tsee\\nrepeated\\tin\\tthe\\tcontext\\tof\\tthe\\tai\\tindustry.\\t \\tthere\\t are\\tdeep\\tinterconnections\\tbetween\\tthe\\tliteral\\thollo wing\\tout\\tof\\tthe\\tmaterials\\tof\\nthe\\tearth\\tand\\tbiosphere,\\tand\\tthe\\tdata\\tcapture\\tand\\tm onetization\\tof\\thuman\\tpractices\\tof\\tcommunication\\tand \\tsociality\\tin\\tai.\\tmezzadra\\nand\\tnielson\\tnote\\tthat\\tlabor\\tis\\tcentral\\tto\\tthis\\textr active\\trelationship,\\twhich\\thas\\trepeated\\tthroughout\\t history:\\tfrom\\tthe\\tway\\teuropean\\nimperialism\\tused\\tslave\\tlabor,\\tto\\tthe\\tforced\\twork\\tcr ews\\ton\\trubber\\tplantations\\tin\\tmalaya,\\tto\\tthe\\tindigen ous\\tpeople\\tof\\tbolivia\\tbeing\\ndriven\\tto\\textract\\tthe\\tsilver\\tthat\\twas\\tused\\tin\\tthe\\tf irst\\tglobal\\tcurrency.\\tthinking\\tabout\\textraction\\treq uires\\tthinking\\tabout\\tlabor,\\nresources,\\tand\\tdata\\ttogether.\\tthis\\tpresents\\ta\\tchall enge\\tto\\tcritical\\tand\\tpopular\\tunderstandings\\tof\\tarti ficial\\tintelligence:\\tit\\tis\\thard\\tto\\n‘see’\\tany\\tof\\tthese\\tprocesses\\tindividually,\\tlet\\talon e\\tcollectively.\\thence\\tthe\\tneed\\tfor\\ta\\tvisualization\\t that\\tcan\\tbring\\tthese\\tconnected,\\nbut\\tglobally\\tdispersed\\tprocesses\\tinto\\ta\\tsingle\\tmap.4\\n5\\n6\\n7\\n8\\n9\\n10\",\n",
       " 'v\\nif\\tyou\\tread\\tour\\tmap\\tfrom\\tleft\\tto\\tright,\\tthe\\tstory\\tb egins\\tand\\tends\\twith\\tthe\\tearth,\\tand\\tthe\\tgeological\\tp rocesses\\tof\\tdeep\\ttime.\\tbut\\nread\\tfrom\\ttop\\tto\\tbottom,\\twe\\tsee\\tthe\\tstory\\tas\\tit\\tbeg ins\\tand\\tends\\twith\\ta\\thuman.\\tthe\\ttop\\tis\\tthe\\thuman\\tage nt,\\tquerying\\tthe\\techo,\\nand\\tsupplying\\tamazon\\twith\\tthe\\tvaluable\\ttraining\\tdat a\\tof\\tverbal\\tquestions\\tand\\tresponses\\tthat\\tthey\\tcan\\tu se\\tto\\tfurther\\trefine\\ttheir\\nvoice-enabled\\tai\\tsystems.\\tat\\tthe\\tbottom\\tof\\tthe\\tmap\\t is\\tanother\\tkind\\tof\\thuman\\tresource:\\tthe\\thistory\\tof\\th uman\\tknowledge\\tand\\ncapacity,\\twhich\\tis\\talso\\tused\\tto\\ttrain\\tand\\toptimize\\t artificial\\tintelligence\\tsystems.\\tthis\\tis\\ta\\tkey\\tdiff erence\\tbetween\\tartificial\\tintelligence\\nsystems\\tand\\tother\\tforms\\tof\\tconsumer\\ttechnology:\\tthe y\\trely\\ton\\tthe\\tingestion,\\tanalysis\\tand\\toptimization\\t of\\tvast\\tamounts\\tof\\thuman\\ngenerated\\timages,\\ttexts\\tand\\tvideos.\\nvi\\nwhen\\ta\\thuman\\tengages\\twith\\tan\\techo,\\tor\\tanother\\tvoice -enabled\\tai\\tdevice,\\tthey\\tare\\tacting\\tas\\tmuch\\tmore\\tth an\\tjust\\tan\\tend-product\\nconsumer.\\tit\\tis\\tdifficult\\tto\\tplace\\tthe\\thuman\\tuser\\to f\\tan\\tai\\tsystem\\tinto\\ta\\tsingle\\tcategory:\\trather,\\tthey \\tdeserve\\tto\\tbe\\tconsidered\\tas\\ta\\nhybrid\\tcase.\\t just\\tas\\tthe\\tgreek\\t chimera \\twas\\ta\\tmythological\\tanimal\\tthat\\twas\\tpart\\tlion,\\tgoat ,\\tsnake\\tand\\tmonster,\\tthe\\necho\\tuser\\tis\\tsimultaneously\\ta\\tconsumer,\\ta\\tresource, \\ta\\tworker,\\tand\\ta\\tproduct. \\tthis\\tmultiple\\tidentity\\trecurs\\tfor\\thuman\\tusers',\n",
       " 'in\\tmany\\ttechnological\\tsystems.\\tin\\tthe\\tspecific\\tcase \\tof\\tthe\\tamazon\\techo,\\tthe\\tuser\\thas\\tpurchased\\ta\\tconsu mer\\tdevice\\tfor\\twhich\\tthey\\nreceive\\ta\\tset\\tof\\tconvenient\\taffordances.\\tbut\\tthey\\ta re\\talso\\ta\\tresource,\\tas\\ttheir\\tvoice\\tcommands\\tare\\tcol lected,\\tanalyzed\\tand\\nretained\\tfor\\tthe\\tpurposes\\tof\\tbuilding\\tan\\tever-large r\\tcorpus\\tof\\thuman\\tvoices\\tand\\tinstructions.\\tand\\tthey \\tprovide\\tlabor,\\tas\\tthey\\ncontinually\\tperform\\tthe\\tvaluable\\tservice\\tof\\tcontrib uting\\tfeedback\\tmechanisms\\tregarding\\tthe\\taccuracy,\\tu sefulness,\\tand\\toverall\\nquality\\tof\\talexa’s\\treplies.\\tthey\\tare,\\tin\\tessence,\\th elping\\tto\\ttrain\\tthe\\tneural\\tnetworks\\twithin\\tamazon’s \\tinfrastructural\\tstack.\\nvii\\nanything\\tbeyond\\tthe\\tlimited\\tphysical\\tand\\tdigital\\tin terfaces\\tof\\tthe\\tdevice\\titself\\tis\\toutside\\tof\\tthe\\tuse r’s\\tcontrol.\\tit\\tpresents\\ta\\tsleek\\nsurface\\twith\\tno\\tability\\tto\\topen\\tit,\\trepair\\tit\\tor\\tch ange\\thow\\tit\\tfunctions.\\tthe\\tobject\\titself\\tis\\ta\\tvery\\t simple\\textrusion\\tof\\tplastic\\nrepresenting\\ta\\tcollection\\tof\\tsensors\\t–\\tits\\treal\\tpow er\\tand\\tcomplexity\\tlies\\tsomewhere\\telse,\\tfar\\tout\\tof\\ts ight.\\tthe\\techo\\tis\\tbut\\tan\\t‘ear’\\tin\\nthe\\thome:\\ta\\tdisembodied\\tlistening\\tagent\\tthat\\tnever\\t shows\\tits\\tdeep\\tconnections\\tto\\tremote\\tsystems.\\nin\\t1673,\\tthe\\tjesuit\\tpolymath,\\tathanasius\\tkircher,\\ti nvented\\tthe\\t statua\\tcitofonica \\t–\\tthe\\t‘talking\\tstatue.’\\tkircher\\twas\\tan\\textraordina ry\\ninterdisciplinary\\tscholar\\tand\\tinventor.\\tin\\this\\tlife time\\the\\tpublished\\tforty\\tmajor\\tworks\\tacross\\tthe\\tfiel ds\\tof\\tmedicine,\\tgeology,\\ncomparative\\treligion\\tand\\tmusic.\\the\\tinvented\\tthe\\tfir st\\tmagnetic\\tclock,\\tmany\\tearly\\tautomatons,\\tand\\tthe\\tm egaphone.\\this\\ttalking\\nstatue\\twas\\ta\\tvery\\tearly\\tlistening\\tsystem:\\tessential ly\\ta\\tmicrophone\\tmade\\tfrom\\ta\\thuge\\tspiral\\ttube,\\twhich \\tcould\\tconvey\\tthe\\nconversations\\tfrom\\ta\\tpublic\\tsquare\\tand\\tup\\tthrough\\tt he\\ttube,\\tand\\tthen\\tpiped\\tthrough\\tthe\\tmouth\\tof\\ta\\tstat ue\\tkept\\twithin\\tan\\naristocrat’s\\tprivate\\tchambers.\\tas\\tkircher\\twrote:\\n“this\\tstatue\\tmust\\tbe\\tlocated\\tin\\ta\\tgiven\\tplace,\\tin\\to rder\\tto\\tallow\\tthe\\tend\\tsection\\tof\\tthe\\tspiral-shaped\\t tube\\tto\\tprecisely\\tcorrespond\\tto\\nthe\\topening\\tof\\tthe\\tmouth.\\tin\\tthis\\tmanner\\tit\\twill\\tbe \\tperfect,\\tand\\tcapable\\tto\\temit\\tclearly\\tany\\tkind\\tof\\ts ound:\\tin\\tfact\\tthe\\tstatue\\twill\\tbe\\nable\\tto\\tspeak\\tcontinuously,\\tuttering\\tin\\teither\\ta\\thu man\\tor\\tanimal\\tvoice:\\tit\\twill\\tlaugh\\tor\\tsneer;\\tit\\twil l\\tseem\\tto\\treally\\tcry\\tor\\tmoan;\\nsometimes\\twith\\tgreat\\tastonishment\\tit\\twill\\tstrongly\\t blow.\\tif\\tthe\\topening\\tof\\tthe\\tspiral\\tshaped\\ttube\\tis\\tl ocated\\tin\\tcorrespondence\\tto\\tan\\nopen\\tpublic\\tspace,\\tall\\thuman\\twords\\tpronounced,\\tfocu sed\\tin\\tthe\\tconduit,\\twould\\tbe\\treplayed\\tthrough\\tthe\\tm outh\\tof\\tthe\\tstatue.” \\t\\nthe\\tlistening\\tsystem\\tcould\\teavesdrop\\ton\\teveryday\\tco nversations\\tin\\tthe\\tpiazza,\\tand\\trelay\\tthem\\tto\\tthe\\t17 th\\tcentury\\titalian\\toligarchs.\\nkircher’s\\ttalking\\tstatue\\twas\\tan\\tearly\\tform\\tof\\tinfor mation\\textraction\\tfor\\tthe\\telites\\t–\\tpeople\\ttalking\\ti n\\tthe\\tstreet\\twould\\thave\\tno\\nindication\\tthat\\ttheir\\tconversations\\twere\\tbeing\\tfunn eled\\tto\\tthose\\twho\\twould\\tinstrument\\tthat\\tknowledge\\tf or\\ttheir\\town\\tpower,\\nentertainment\\tand\\twealth.\\tpeople\\tinside\\tthe\\thomes\\to f\\taristocrats\\twould\\thave\\tno\\tidea\\thow\\ta\\tmagical\\tstat ue\\twas\\tspeaking\\tand\\nconveying\\tall\\tmanner\\tof\\tinformation.\\tthe\\taim\\twas\\tto \\tobscure\\thow\\tthe\\tsystem\\tworked:\\tan\\telegant\\tstatue\\tw as\\tall\\tthey\\tcould\\tsee.\\nlistening\\tsystems,\\teven\\tat\\tthis\\tearly\\tstage,\\twere\\ta bout\\tpower,\\tclass,\\tand\\tsecrecy.\\tbut\\tthe\\tinfrastruct ure\\tfor\\tkircher’s\\tsystem\\twas\\nprohibitively\\texpensive\\t–\\tavailable\\tonly\\tto\\tthe\\tver y\\tfew.\\tand\\tso\\tthe\\tquestion\\tremains,\\twhat\\tare\\tthe\\tfu ll\\tresource\\timplications\\tof\\nbuilding\\tsuch\\tsystems?\\tthis\\tbrings\\tus\\tto\\tthe\\tmateri ality\\tof\\tthe\\tinfrastructure\\tthat\\tlies\\tbeneath.11',\n",
       " 'statua\\tcitofonica\\tby\\tathanasius\\tkircher\\t(1673)\\nviii\\nin\\this\\tbook\\t a\\tgeology\\tof\\tmedia ,\\tjussi\\tparikka\\tsuggests\\tthat\\twe\\ttry\\tto\\tthink\\tof\\tme dia\\tnot\\tfrom\\tmarshall\\tmcluhan’s\\tpoint\\tof\\tview\\t–\\tin\\nwhich\\tmedia\\tare\\textensions\\tof\\thuman\\tsenses\\t \\t–\\tbut\\tr ather\\tas\\tan\\textension\\tof\\tearth.\\t \\tmedia\\ttechnologies \\tshould\\tbe\\nunderstood\\tin\\tcontext\\tof\\ta\\tgeological\\tprocess,\\tfrom \\tthe\\tcreation\\tand\\tthe\\ttransformation\\tprocesses,\\tto\\t the\\tmovement\\tof\\tnatural\\nelements\\tfrom\\twhich\\tmedia\\tare\\tbuilt.\\treflecting\\tupo n\\tmedia\\tand\\ttechnology\\tas\\tgeological\\tprocesses\\tenab les\\tus\\tto\\tconsider\\tthe\\nprofound\\tdepletion\\tof\\tnon-renewable\\tresources\\trequi red\\tto\\tdrive\\tthe\\ttechnologies\\tof\\tthe\\tpresent\\tmoment .\\treflecting\\tupon\\tmedia\\nand\\ttechnology\\tas\\tgeological\\tprocesses\\tenables\\tus\\tt o\\tconsider\\tthe\\tprofound\\tdepletion\\tof\\tnon-renewable\\t resources\\trequired\\tto\\tdrive\\nthe\\ttechnologies\\tof\\tthe\\tpresent\\tmoment.\\teach\\tobject \\tin\\tthe\\textended\\tnetwork\\tof\\tan\\tai\\tsystem,\\tfrom\\tnetw ork\\trouters\\tto\\tbatteries\\nto\\tmicrophones,\\tis\\tbuilt\\tusing\\telements\\tthat\\trequir ed\\tbillions\\tof\\tyears\\tto\\tbe\\tproduced.\\tlooking\\tfrom\\tt he\\tperspective\\tof\\tdeep\\ttime,\\nwe\\tare\\textracting\\tearth’s\\thistory\\tto\\tserve\\ta\\tsplit\\t second\\tof\\ttechnological\\ttime,\\tin\\torder\\tto\\tbuild\\tdev ices\\tthan\\tare\\toften\\tdesigned\\tto\\nbe\\tused\\tfor\\tno\\tmore\\tthan\\ta\\tfew\\tyears.\\tfor\\texample,\\t the\\tconsumer\\tt echnology\\tassociation\\tnotes\\tthat\\tthe\\t average\\tsmartphone\\nlifespan\\tis\\t4.7\\tyears.\\t \\tthis\\tobsolescence\\tcycle\\tfue ls\\tthe\\tpurchase\\tof\\tmore\\tdevices,\\tdrives\\tup\\tprofits, \\tand\\tincreases\\tincentives\\tfor\\nthe\\tuse\\tof\\tunsustainable\\textraction\\tpractices.\\tfrom \\ta\\tslow\\tprocess\\tof\\telemental\\tdevelopment,\\tthese\\tele ments\\tand\\tmaterials\\tgo\\nthrough\\tan\\textraordinarily\\trapid\\tperiod\\tof\\texcavati on,\\tsmelting,\\tmixing,\\tand\\tlogistical\\ttransport\\t–\\tcr ossing\\tthousands\\tof\\tkilometers\\nin\\ttheir\\ttransformation.\\tgeological\\tprocesses\\tmark\\t both\\tthe\\tbeginning\\tand\\tthe\\tend\\tof\\tthis\\tperiod,\\tfrom \\tthe\\tmining\\tof\\tore,\\tto\\tthe\\ndeposition\\tof\\tmaterial\\tin\\tan\\telectronic\\twaste\\tdump. \\tfor\\tthat\\treason,\\tour\\tmap\\tstarts\\tand\\tends\\twith\\tthe\\t earth’s\\tcrust.\\thowever,\\tall\\nthe\\ttransformations\\tand\\tmovements\\twe\\tdepict\\tare\\tonl y\\tthe\\tbarest\\tanatomical\\toutline:\\tbeneath\\tthese\\tconn ections\\tlie\\tmany\\tmore\\nlayers\\tof\\tfractal\\tsupply\\tchains,\\tand\\texploitation\\to f\\thuman\\tand\\tnatural\\tresources,\\tconcentrations\\tof\\tco rporate\\tand\\tgeopolitical\\npower,\\tand\\tcontinual\\tenergy\\tconsumption.12 13\\n14',\n",
       " 'ix\\ndrawing\\tout\\tthe\\tconnections\\tbetween\\tresources,\\tlabo r\\tand\\tdata\\textraction\\tbrings\\tus\\tinevitably\\tback\\tto\\t traditional\\tframeworks\\tof\\nexploitation.\\tbut\\thow\\tis\\tvalue\\tbeing\\tgenerated\\tthro ugh\\tthese\\tsystems?\\ta\\tuseful\\tconceptual\\ttool\\tcan\\tbe\\t found\\tin\\tthe\\twork\\tof\\nchristian\\tfuchs\\tand\\tother\\tauthors\\texamining\\tand\\tdef ining\\tdigital\\tlabor.\\tthe\\tnotion\\tof\\tdigital\\tlabor,\\tw hich\\twas\\tinitially\\tlinked\\twith\\ndifferent\\tforms\\tof\\tnon-material\\tlabor,\\tprecedes\\tthe \\tlife\\tof\\tdevices\\tand\\tcomplex\\tsystems\\tsuch\\tas\\tartifi cial\\tintelligence.\\tdigital\\tlabor\\t–\\nthe\\twork\\tof\\tbuilding\\tand\\tmaintaining\\tthe\\tstack\\tof\\td igital\\tsystems\\t–\\tis\\tfar\\tfrom\\tephemeral\\tor\\tvirtual,\\t but\\tis\\tdeeply\\tembodied\\tin\\ndifferent\\tactivities.\\t \\tthe\\tscope\\tis\\toverwhelming:\\tf rom\\tindentured\\tlabor\\tin\\tmines\\tfor\\textracting\\tthe\\tmi nerals\\tthat\\tform\\tthe\\tphysical\\nbasis\\tof\\tinformation\\ttechnologies;\\tto\\tthe\\twork\\tof\\ts trictly\\tcontrolled\\tand\\tsometimes\\tdangerous\\thardware \\tmanufacturing\\tand\\nassembly\\tprocesses\\tin\\tchinese\\tfactories;\\tto\\texploit ed\\toutsourced\\tcognitive\\tworkers\\tin\\tdeveloping\\tcount ries\\tlabelling\\tai\\ttraining\\tdata\\nsets;\\tto\\tthe\\tinformal\\tphysical\\tworkers\\tcleaning\\tup\\t toxic\\twaste\\tdumps.\\t these\\tprocesses\\tcreate\\tnew\\taccumulations\\tof\\twealth\\nand\\tpower,\\twhich\\tare\\tconcentrated\\tin\\ta\\tvery\\tthin\\tso cial\\tlayer.\\nmarx’s\\tdialectic\\tof\\tsubject\\tand\\tobject\\tin\\teconomy\\nx\\nthis\\ttriangle\\tof\\tvalue\\textraction\\tand\\tproduction\\tre presents\\tone\\tof\\tthe\\tbasic\\telements\\tof\\tour\\tmap,\\tfrom \\tbirth\\tin\\ta\\tgeological\\tprocess,\\nthrough\\tlife\\tas\\ta\\tconsumer\\tai\\tproduct,\\tand\\tultimate ly\\tto\\tdeath\\tin\\tan\\telectronics\\tdump.\\tlike\\tin\\tfuchs’\\t work,\\tour\\ttriangles\\tare\\tnot\\nisolated,\\tbut\\tlinked\\tto\\tone\\tanother\\tin\\tthe\\tproducti on\\tprocess.\\tthey\\tform\\ta\\tcyclic\\tflow\\tin\\twhich\\tthe\\tpr oduct\\tof\\twork\\tis\\ttransformed\\ninto\\ta\\tresource,\\twhich\\tis\\ttransformed\\tinto\\ta\\tproduc t,\\twhich\\tis\\ttransformed\\tinto\\ta\\tresource\\tand\\tso\\ton.\\t each\\ttriangle\\trepresents\\tone\\nphase\\tin\\tthe\\tproduction\\tprocess.\\talthough\\tthis\\tappe ars\\ton\\tthe\\tmap\\tas\\ta\\tlinear\\tpath\\tof\\ttransformation,\\t a\\tdifferent\\tvisual\\tmetaphor\\nbetter\\trepresents\\tthe\\tcomplexity\\tof\\tcurrent\\textract ivism:\\tthe\\tfractal\\tstructure\\tknown\\tas\\tthe\\tsierpinsk i\\ttriangle.\\na\\tlinear\\tdisplay\\tdoes\\tnot\\tenable\\tus\\tto\\tshow\\tthat\\tea ch\\tnext\\tstep\\tof\\tproduction\\tand\\texploitation\\tcontain s\\tprevious\\tphases.\\tif\\twe\\tlook\\nat\\tthe\\tproduction\\tand\\texploitation\\tsystem\\tthrough\\ta \\tfractal\\tvisual\\tstructure,\\tthe\\tsmallest\\ttriangle\\two uld\\trepresent\\tnatural\\tresources\\nand\\tmeans\\tof\\tlabor,\\ti.e.\\tthe\\tminer\\tas\\tlabor\\tand\\tore \\tas\\tproduct.\\tthe\\tnext\\tlarger\\ttriangle\\tencompasses\\tt he\\tprocessing\\tof\\tmetals,\\nand\\tthe\\tnext\\twould\\trepresent\\tthe\\tprocess\\tof\\tmanufac turing\\tcomponents\\tand\\tso\\ton.\\tthe\\tultimate\\ttriangle\\t in\\tour\\tmap,\\tthe\\nproduction\\tof\\tthe\\tamazon\\techo\\tunit\\titself,\\tincludes \\tall\\tof\\tthese\\tlevels\\tof\\texploitation\\t–\\tfrom\\tthe\\tbot tom\\tto\\tthe\\tvery\\ttop\\tof\\tamazon\\ninc,\\ta\\trole\\tinhabited\\tby\\tjeff\\tbezos\\tas\\tceo\\tof\\tamazo n.\\tlike\\ta\\tpharaoh\\tof\\tancient\\tegypt,\\the\\tstands\\tat\\tth e\\ttop\\tof\\tthe\\tlargest\\tpyramid\\tof\\nai\\tvalue\\textraction.15',\n",
       " \"sierpinski\\ttriangle\\tor\\tsierpinski\\tfractal\\nxi\\nt o\\treturn\\tto\\tthe\\tbasic\\telement\\tof\\tthis\\tvisualizatio n\\t–\\ta\\tvariation\\tof\\tmarx’s\\ttriangle\\tof\\tproduction\\t–\\t each\\ttriangle\\tcreates\\ta\\tsurplus\\tof\\nvalue\\tfor\\tcreating\\tprofits.\\tif\\twe\\tlook\\tat\\tthe\\tscale \\tof\\taverage\\tincome\\tfor\\teach\\tactivity\\tin\\tthe\\tproduct ion\\tprocess\\tof\\tone\\tdevice,\\twhich\\nis\\tshown\\ton\\tthe\\tleft\\tside\\tof\\tour\\tmap,\\twe\\tsee\\tthe\\tdr amatic\\tdifference\\tin\\tincome\\tearned.\\taccording\\tto\\tre search\\tby\\tamnesty\\ninternational,\\tduring\\tthe\\texcavation\\tof\\tcobalt\\twhic h\\tis\\talso\\tused\\tfor\\tlithium\\tbatteries\\tof\\t16\\tmultinat ional\\tbrands,\\tworkers\\tare\\tpaid\\nthe\\tequivalent\\tof\\tone\\tus\\tdollar\\tper\\tday\\tfor\\tworking \\tin\\tconditions\\thazardous\\tto\\tlife\\tand\\thealth,\\tand\\twe re\\toften\\tsubjected\\tto\\tviolence,\\nextortion\\tand\\tintimidation.\\t \\tamnesty\\thas\\tdocumented \\tchildren\\tas\\tyoung\\tas\\t7\\tworking\\tin\\tthe\\tmines.\\tin\\tco ntrast,\\tamazon\\tceo\\tjeff\\nbezos,\\tat\\tthe\\ttop\\tof\\tour\\tfractal\\tpyramid,\\tmade\\tan\\ta verage\\tof\\t$275\\tmillion\\ta\\tday\\tduring\\tthe\\tfirst\\tfive\\t months\\tof\\t2018,\\taccording\\tto\\nthe\\tbloomberg\\tbillionaires\\tindex.\\t \\ta\\tchild\\tworking\\t in\\ta\\tmine\\tin\\tthe\\tcongo\\twould\\tneed\\tmore\\tthan\\t700,000 \\tyears\\tof\\tnon-stop\\twork\\nto\\tearn\\tthe\\tsame\\tamount\\tas\\ta\\tsingle\\tday\\tof\\tbezos’\\ti ncome.\\nmany\\tof\\tthe\\ttriangles\\tshown\\ton\\tthis\\tmap\\thide\\tdiffer ent\\tstories\\tof\\tlabor\\texploitation\\tand\\tinhumane\\twork ing\\tconditions.\\tthe\\tecological\\nprice\\tof\\ttransformation\\tof\\telements\\tand\\tincome\\tdisp arities\\tis\\tjust\\tone\\tof\\tthe\\tpossible\\tways\\tof\\treprese nting\\ta\\tdeep\\tsystemic\\ninequality.\\twe\\thave\\tboth\\tresearched\\tdifferent\\tforms \\tof\\t‘black\\tboxes’\\tunderstood\\tas\\talgorithmic\\tprocess es,\\t \\tbut\\tthis\\tmap\\tpoints\\tto\\nanother\\tform\\tof\\topacity:\\tthe\\tvery\\tprocesses\\tof\\tcrea ting,\\ttraining\\tand\\toperating\\ta\\tdevice\\tlike\\tan\\tamazo n\\techo\\tis\\titself\\ta\\tkind\\tof\\tblack\\nbox,\\tvery\\thard\\tto\\texamine\\tand\\ttrack\\t in\\ttoto \\tgiven\\tthe\\tmultiple\\tlayers\\tof\\tcontractors,\\tdistribu tors,\\tand\\tdownstream\\tlogistical\\npartners\\taround\\tthe\\tworld.\\tas\\tmark\\tgraham\\twrites,\\t“ contemporary\\tcapitalism\\tconceals\\tthe\\thistories\\tand\\t geographies\\tof\\tmost\\ncommodities\\tfrom\\tconsumers.\\tconsumers\\tare\\tusually\\to nly\\table\\tto\\tsee\\tcommodities\\tin\\tthe\\there\\tand\\tnow\\tof\\t time\\tand\\tspace,\\tand\\nrarely\\thave\\tany\\topportunities\\tto\\tgaze\\tbackwards\\tthr ough\\tthe\\tchains\\tof\\tproduction\\tin\\torder\\tto\\tgain\\tknow ledge\\tabout\\tthe\\tsites\\tof\\nproduction,\\ttransformation,\\tand\\tdistribution.”\\t\\none\\tillustration\\tof\\tthe\\tdifficulty\\tof\\tinvestigating \\tand\\ttracking\\tthe\\tcontemporary\\tproduction\\tchain\\tpro cess\\tis\\tthat\\tit\\ttook\\tintel\\tmore\\nthan\\tfour\\tyears\\tto\\tunderstand\\tits\\tsupply\\tline\\twell\\t enough\\tto\\tensure\\tthat\\tno\\ttantalum\\tfrom\\tthe\\tcongo\\twa s\\tin\\tits\\tmicroprocessor\\nproducts.\\tas\\ta\\tsemiconductor\\tchip\\tmanufacturer,\\tint el\\tsupplies\\tapple\\twith\\tprocessors.\\tin\\torder\\tto\\tdo\\ts o,\\tintel\\thas\\tits\\town\\tmulti-\\ntiered\\tsupply\\tchain\\tof\\tmore\\tthan\\t19,000\\tsuppliers\\ti n\\tover\\t100\\tcountries\\tproviding\\tdirect\\tmaterials\\tfor \\ttheir\\tproduction\\tprocesses,\\ntools\\tand\\tmachines\\tfor\\ttheir\\tfactories,\\tand\\tlogisti cs\\tand\\tpackaging\\tservices.\\t \\tthat\\tit\\ttook\\tover\\tfour\\t years\\tfor\\ta\\tleading\\ttechnology\\ncompany\\t just\\tto\\tunderstand\\tits\\town\\tsupply\\tchain ,\\treveals\\tjust\\thow\\thard\\tthis\\tprocess\\tcan\\tbe\\tto\\tgras p\\tfrom\\tthe\\tinside,\\tlet\\talone\\tfor\\nexternal\\tresearchers,\\tjournalists\\tand\\tacademics.\\tdu tch-based\\ttechnology\\tcompany\\tphilips\\thas\\talso\\tclaim ed\\tthat\\tit\\twas\\tworking\\tto\\nmake\\tits\\tsupply\\tchain\\t'conflict-free'.\\tphilips,\\tfor \\texample,\\thas\\ttens\\tof\\tthousands\\tof\\tdifferent\\tsuppli ers,\\teach\\tof\\twhich\\tprovides\\ndifferent\\tcomponents\\tfor\\ttheir\\tmanufacturing\\tproces ses.\\t \\tthose\\tsuppliers\\tare\\tthemselves\\tlinked\\tdownstr eam\\tto\\ttens\\tof16\\n17\\n18\\n19\\n20\\n21\",\n",
       " \"thousands\\tof\\tcomponent\\tmanufacturers\\tthat\\tacquire\\tm aterials\\tfrom\\thundreds\\tof\\trefineries\\tthat\\tbuy\\tingre dients\\tfrom\\tdifferent\\nsmelters,\\twhich\\tare\\tsupplied\\tby\\tunknown\\tnumbers\\tof\\t traders\\tthat\\tdeal\\tdirectly\\twith\\tboth\\tlegal\\tand\\tille gal\\tmining\\toperations.\\tin\\t the\\nelements\\tof\\tpower ,\\tdavid\\ts.\\tabraham\\tdescribes\\tthe\\tinvisible\\tnetworks \\tof\\trare\\tmetals\\ttraders\\tin\\tglobal\\telectronics\\tsuppl y\\tchains:\\n“the\\tnetwork\\tto\\tget\\trare\\tmetals\\tfrom\\tthe\\tmine\\tto\\tyo ur\\tlaptop\\ttravels\\tthrough\\ta\\tmurky\\tnetwork\\tof\\ttrader s,\\tprocessors,\\tand\\ncomponent\\tmanufacturers.\\ttraders\\tare\\tthe\\tmiddlemen\\t who\\tdo\\tmore\\tthan\\tbuy\\tand\\tsell\\trare\\tmetals:\\tthey\\thel p\\tto\\tregulate\\ninformation\\tand\\tare\\tthe\\thidden\\tlink\\tthat\\thelps\\tin\\tn avigating\\tthe\\tnetwork\\tbetween\\tmetals\\tplants\\tand\\tthe \\tcomponents\\tin\\tour\\nlaptops.”\\t \\taccording\\tto\\tthe\\tcomputer\\tmanufacturing\\t company\\tdell,\\tcomplexities\\tof\\tthe\\tmetal\\tsupply\\tchai n\\tpose\\talmost\\ninsurmountable\\tchallenges.\\t \\tthe\\tmining\\tof\\tthese\\tmin erals\\ttakes\\tplace\\tlong\\tbefore\\ta\\tfinal\\tproduct\\tis\\tas sembled,\\tmaking\\tit\\nexceedingly\\tdifficult\\tto\\ttrace\\tthe\\tminerals'\\torigin .\\tin\\taddition,\\tmany\\tof\\tthe\\tminerals\\tare\\tsmelted\\ttog ether\\twith\\trecycled\\tmetals,\\tby\\nwhich\\tpoint\\tit\\tbecomes\\tall\\tbut\\timpossible\\tto\\ttrace\\t the\\tminerals\\tto\\ttheir\\tsource.\\tso\\twe\\tsee\\tthat\\tthe\\tat tempt\\tto\\tcapture\\tthe\\tfull\\nsupply\\tchain\\tis\\ta\\ttruly\\tgargantuan\\ttask:\\trevealing\\t all\\tthe\\tcomplexity\\tof\\tthe\\t21st\\tcentury\\tglobal\\tprodu ction\\tof\\ttechnology\\tproducts.\\nxii\\nsupply\\tchains\\tare\\toften\\tlayered\\ton\\ttop\\tof\\tone\\tanoth er,\\tin\\ta\\tsprawling\\tnetwork.\\tapple’s\\tsupplier\\tprogra m\\treveals\\tthere\\tare\\ttens\\tof\\nthousands\\tof\\tindividual\\tcomponents\\tembedded\\tin\\tthei r\\tdevices,\\twhich\\tare\\tin\\tturn\\tsupplied\\tby\\thundreds\\to f\\tdifferent\\tcompanies.\\tin\\norder\\tfor\\teach\\tof\\tthose\\tcomponents\\tto\\tarrive\\ton\\tthe \\tfinal\\tassembly\\tline\\twhere\\tit\\twill\\tbe\\tassembled\\tby\\t workers\\tin\\tfoxconn\\tfacilities,\\ndifferent\\tcomponents\\tneed\\tto\\tbe\\tphysically\\ttransfer red\\tfrom\\tmore\\tthan\\t750\\tsupplier\\tsites\\tacross\\t30\\tdif ferent\\tcountries.\\t \\t this\\nbecomes\\ta\\tcomplex\\tstructure\\tof\\t supply\\tchains\\twithin\\tsupply\\tchains ,\\ta\\tzooming\\tfractal\\tof\\ttens\\tof\\tthousands\\tof\\nsuppliers,\\tmillions\\tof\\tkilometers\\tof\\tshipped\\tmateri als\\tand\\thundreds\\tof\\tthousands\\tof\\tworkers\\tincluded\\tw ithin\\tthe\\nprocess\\teven\\tbefore\\tthe\\tproduct\\tis\\tassembled\\ton\\tthe \\tline.\\nvisualizing\\tthis\\tprocess\\tas\\tone\\tglobal,\\tpancontinen tal\\tnetwork\\tthrough\\twhich\\tmaterials,\\tcomponents\\tand \\tproducts\\tflow,\\twe\\tsee\\tan\\nanalogy\\tto\\tthe\\tglobal\\tinformation\\tnetwork.\\twhere\\tth ere\\tis\\ta\\tsingle\\tinternet\\tpacket\\ttravelling\\tto\\tan\\tam azon\\techo,\\there\\twe\\tcan\\nimagine\\ta\\tsingle\\tcargo\\tcontainer.\\t \\tthe\\tdizzying\\tspe ctacle\\tof\\tglobal\\tlogistics\\tand\\tproduction\\twill\\tnot\\t be\\tpossible\\twithout\\tthe\\ninvention\\tof\\tthis\\tsimple,\\tstandardized\\tmetal\\tobject .\\tstandardized\\tcargo\\tcontainers\\tallowed\\tthe\\texplosi on\\tof\\tmodern\\tshipping\\nindustry,\\twhich\\tmade\\tit\\tpossible\\tto\\tmodel\\tthe\\tplane t\\tas\\ta\\tmassive,\\tsingle\\tfactory.\\tin\\t2017,\\tthe\\tcapaci ty\\tof\\tcontainer\\tships\\tin\\nseaborne\\ttrade\\treached\\tnearly\\t250,000,000\\tdead-weig ht\\ttons\\tof\\tcargo,\\tdominated\\tby\\tgiant\\tshipping\\tcompa nies\\tlike\\tmaersk\\tof\\ndenmark,\\tthe\\tmediterranean\\tshipping\\tcompany\\tof\\tswit zerland,\\tand\\tfrance’s\\tcma\\tcgm\\tgroup,\\teach\\towning\\thu ndred\\tof\\tcontainer\\nvessels.\\t \\tfor\\tthese\\tcommercial\\tventures,\\tcargo\\tship ping\\tis\\ta\\trelatively\\tcheap\\tway\\tto\\ttraverse\\tthe\\tvasc ular\\tsystem\\tof\\tthe\\tglobal\\nfactory,\\tyet\\tit\\tdisguises\\tmuch\\tlarger\\texternal\\tcost s.\\nin\\trecent\\tyears,\\tshipping\\tboats\\tproduce\\t3.1%\\tof\\tglo bal\\tyearly\\tco2\\temissions,\\tmore\\tthan\\tthe\\tentire\\tcoun try\\tof\\tgermany.\\t \\tin\\torder\\nto\\tminimize\\ttheir\\tinternal\\tcosts,\\tmost\\tof\\tthe\\tconta iner\\tshipping\\tcompanies\\tuse\\tvery\\tlow\\tgrade\\tfuel\\tin\\t enormous\\tquantities,\\twhich\\nleads\\tto\\tincreased\\tamounts\\tof\\tsulphur\\tin\\tthe\\tair,\\ta mong\\tother\\ttoxic\\tsubstances.\\tit\\thas\\tbeen\\testimated\\t that\\tone\\tcontainer\\tship\\tcan\\nemit\\tas\\tmuch\\tpollution\\tas\\t50\\tmillion\\tcars,\\tand\\t60,0 00\\tdeaths\\tworldwide\\tare\\tattributed\\tindirectly\\tto\\tca rgo\\tship\\tindustry\\tpollution\\nrelated\\tissues\\tannually.\\t \\teven\\tindustry-friendly\\tso urces\\tlike\\tthe\\tworld\\tshipping\\tcouncil\\tadmit\\tthat\\tth ousands\\tof\\tcontainers\\tare\\tlost\\neach\\tyear,\\ton\\tthe\\tocean\\tfloor\\tor\\tdrifting\\tloose.\\t \\ts ome\\tcarry\\ttoxic\\tsubstances\\twhich\\tleak\\tinto\\tthe\\tocea ns.\\ttypically,\\tworkers\\tspend\\n9\\tto\\t10\\tmonths\\tin\\tthe\\tsea,\\toften\\twith\\tlong\\tworking\\t shifts\\tand\\twithout\\taccess\\tto\\texternal\\tcommunication s.\\tworkers\\tfrom\\tthe\\nphilippines\\trepresent\\tmore\\tthan\\ta\\tthird\\tof\\tthe\\tglob al\\tshipping\\tworkforce.\\t \\tthe\\tmost\\tsevere\\tcosts\\tof\\tgl obal\\tlogistics\\tare\\tborn\\tby\\tthe\\natmosphere,\\tthe\\toceanic\\tecosystem\\tand\\tall\\tit\\tcontai ns,\\tand\\tthe\\tlowest\\tpaid\\tworkers.22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\",\n",
       " \"cargo\\tcontainer\\nxiii\\nthe\\tincreasing\\tcomplexity\\tand\\tminiaturization\\tof\\tou r\\ttechnology\\tdepends\\ton\\tthe\\tprocess\\tthat\\tstrangely\\t echoes\\tthe\\thopes\\tof\\tearly\\nmedieval\\talchemy.\\twhere\\tmedieval\\talchemists\\taimed\\tt o\\ttransform\\tbase\\tmetals\\tinto\\t‘noble’\\tones,\\tresearch ers\\ttoday\\tuse\\trare\\tearth\\nmetals\\tto\\tenhance\\tthe\\tperformance\\tof\\tother\\tminerals .\\tthere\\tare\\t17\\trare\\tearth\\telements,\\twhich\\tare\\tembed ded\\tin\\tlaptops\\tand\\nsmartphones,\\tmaking\\tthem\\tsmaller\\tand\\tlighter.\\tthey\\t play\\ta\\trole\\tin\\tcolor\\tdisplays,\\tloudspeakers,\\tcamera \\tlenses,\\tgps\\tsystems,\\nrechargeable\\tbatteries,\\thard\\tdrives\\tand\\tmany\\tother\\t components.\\tthey\\tare\\tkey\\telements\\tin\\tcommunication\\t systems\\tfrom\\tfiber\\noptic\\tcables,\\tsignal\\tamplification\\tin\\tmobile\\tcommun ication\\ttowers\\tto\\tsatellites\\tand\\tgps\\ttechnology.\\tbu t\\tthe\\tprecise\\tconfiguration\\tand\\nuse\\tof\\tthese\\tminerals\\tis\\thard\\tto\\tascertain.\\tin\\tthe\\t same\\tway\\tthat\\tmedieval\\talchemists\\thid\\ttheir\\tresearc h\\tbehind\\tcyphers\\tand\\tcryptic\\nsymbolism,\\tcontemporary\\tprocesses\\tfor\\tusing\\tmineral s\\tin\\tdevices\\tare\\tprotected\\tbehind\\tndas\\tand\\ttrade\\tse crets.\\nthe\\tunique\\telectronic,\\toptical\\tand\\tmagnetic\\tcharact eristics\\tof\\trare\\tearth\\telements\\tcannot\\tbe\\tmatched\\tb y\\tany\\tother\\tmetals\\tor\\nsynthetic\\tsubstitutes\\tdiscovered\\tto\\tdate.\\twhile\\tthe y\\tare\\tcalled\\t‘rare\\tearth\\tmetals’,\\tsome\\tare\\trelative ly\\tabundant\\tin\\tthe\\tearth’s\\ncrust,\\tbut\\textraction\\tis\\tcostly\\tand\\thighly\\tpollutin g.\\tdavid\\tabraham\\tdescribes\\tthe\\tmining\\tof\\tdysprosium \\tand\\tt erbium\\tused\\tin\\ta\\tvariety\\nof\\thigh-tech\\tdevices\\tin\\tjianxi,\\tchina.\\the\\twrites,\\t“ only\\t0.2\\tpercent\\tof\\tthe\\tmined\\tclay\\tcontains\\tthe\\tval uable\\trare\\tearth\\telements.\\tthis\\nmeans\\tthat\\t99.8\\tpercent\\tof\\tearth\\tremoved\\tin\\trare\\tea rth\\tmining\\tis\\tdiscarded\\tas\\twaste\\tcalled\\t“tailings”\\t that\\tare\\tdumped\\tback\\tinto\\nthe\\thills\\tand\\tstreams,”\\tcreating\\tnew\\tpollutants\\tlik e\\tammonium.\\t \\tin\\torder\\tto\\trefine\\tone\\tton\\tof\\trare\\tear th\\telements,\\t“the\\tchinese\\nsociety\\tof\\trare\\tearths\\testimates\\tthat\\tthe\\tprocess\\tp roduces\\t75,000\\tliters\\tof\\tacidic\\twater\\tand\\tone\\tton\\to f\\tradioactive\\tresidue.”\\t\\nfurthermore,\\tmining\\tand\\trefining\\tactivities\\tconsume \\tvast\\tamount\\tof\\twater\\tand\\tgenerate\\tlarge\\tquantities \\tof\\tco2\\temissions.\\tin\\n2009,\\tchina\\tproduced\\t95%\\tof\\tthe\\tworld's\\tsupply\\tof\\tt hese\\telements,\\tand\\tit\\thas\\tbeen\\testimated\\tthat\\tthe\\ts ingle\\tmine\\tknown\\tas\\nbayan\\tobo\\tcontains\\t70%\\tof\\tthe\\tworld's\\treserves.\\t31\\n32\\n33\",\n",
       " \"rare\\tearth\\telements\\nxiv\\na\\tsatellite\\tpicture\\tof\\tthe\\ttiny\\tindonesian\\tisland\\to f\\tbangka\\ttells\\ta\\tstory\\tabout\\thuman\\tand\\tenvironmenta l\\ttoll\\tof\\tthe\\tsemiconductor\\nproduction.\\ton\\tthis\\ttiny\\tisland,\\tmostly\\t‘informal’\\t miners\\tare\\ton\\tmakeshift\\tpontoons,\\tusing\\tbamboo\\tpole s\\tto\\tscrape\\tthe\\tseabed,\\tand\\nthen\\tdiving\\tunderwater\\tto\\tsuck\\ttin\\tfrom\\tthe\\tsurface \\tthrough\\tgiant,\\tvacuum-like\\ttubes.\\tas\\ta\\t guardian \\tinvestigation\\treports\\t“tin\\nmining\\tis\\ta\\tlucrative\\tbut\\tdestructive\\ttrade\\tthat\\tha s\\tscarred\\tthe\\tisland's\\tlandscape,\\tbulldozed\\tits\\tfar ms\\tand\\tforests,\\tkilled\\toff\\tits\\tfish\\nstocks\\tand\\tcoral\\treefs,\\tand\\tdented\\ttourism\\tto\\tits\\tp retty\\tpalm-lined\\tbeaches.\\tthe\\tdamage\\tis\\tbest\\tseen\\tf rom\\tthe\\tair,\\tas\\tpockets\\tof\\nlush\\tforest\\thuddle\\tamid\\thuge\\tswaths\\tof\\tbarren\\torang e\\tearth.\\twhere\\tnot\\tdominated\\tby\\tmines,\\tthis\\tis\\tpock marked\\twith\\tgraves,\\nmany\\tholding\\tthe\\tbodies\\tof\\tminers\\twho\\thave\\tdied\\tove r\\tthe\\tcenturies\\tdigging\\tfor\\ttin.”\\t \\ttwo\\tsmall\\tisland s,\\tbangka\\tand\\tbelitung,\\nproduce\\t90%\\tof\\tindonesia's\\ttin,\\tand\\tindonesia\\tis\\tth e\\tworld's\\tsecond-largest\\texporter\\tof\\tthe\\tmetal.\\tind onesia's\\tnational\\ttin\\ncorporation,\\tpt\\ttimah,\\tsupplies\\tcompanies\\tsuch\\tas\\ts amsung\\tdirectly,\\tas\\twell\\tas\\tsolder\\tmakers\\tchernan\\ta nd\\tshenmao,\\twhich\\tin\\nturn\\tsupply\\tsony,\\tlg\\tand\\tfoxconn.\\t\\nxv\\nat\\tamazon\\tdistribution\\tcenters,\\tvast\\tcollections\\tof \\tproducts\\tare\\tarrayed\\tin\\ta\\tcomputational\\torder\\tacro ss\\tmillions\\tof\\tshelves.\\tthe\\nposition\\tof\\tevery\\titem\\tin\\tthis\\tspace\\tis\\tprecisely\\td etermined\\tby\\tcomplex\\tmathematical\\tfunctions\\tthat\\tpr ocess\\tinformation\\tabout\\norders\\tand\\tcreate\\trelationships\\tbetween\\tproducts.\\tt he\\taim\\tis\\tto\\toptimize\\tthe\\tmovements\\tof\\tthe\\trobots\\ta nd\\thumans\\tthat34\\n35\",\n",
       " 'collaborate\\tin\\tthese\\twarehouses.\\twith\\tthe\\thelp\\tfrom \\tan\\telectronic\\tbracelet,\\tthe\\thuman\\tworker\\tis\\tdirect ed\\tthough\\twarehouses\\tthe\\nsize\\tof\\tairplane\\thangars,\\tfilled\\twith\\tobjects\\tarran ged\\tin\\tan\\topaque\\talgorithmic\\torder.\\t\\nhidden\\tamong\\tthe\\tthousands\\tof\\tother\\tpublicly\\tavaila ble\\tpatents\\towned\\tby\\tamazon,\\tu.s.\\tpatent\\tnumber\\t9,2 80,157\\nrepresents\\tan\\textraordinary\\tillustration\\tof\\tworker\\t alienation,\\ta\\tstark\\tmoment\\tin\\tthe\\trelationship\\tbetw een\\thumans\\tand\\nmachines. \\t \\tit\\tdepicts\\ta\\tmetal\\tcage\\tintended\\tfor\\tthe\\tworker,\\t equipped\\twith\\tdifferent\\tcybernetic\\tadd-ons,\\tthat\\tca n\\tbe\\tmoved\\nthrough\\ta\\twarehouse\\tby\\tthe\\tsame\\tmotorized\\tsystem\\tth at\\tshifts\\tshelves\\tfilled\\twith\\tmerchandise.\\there,\\tth e\\tworker\\tbecomes\\ta\\tpart\\nof\\ta\\tmachinic\\tballet,\\theld\\tupright\\tin\\ta\\tcage\\twhich\\t dictates\\tand\\tconstrains\\ttheir\\tmovement.\\nas\\twe\\thave\\tseen\\ttime\\tand\\ttime\\tagain\\tin\\tthe\\tresearch \\tfor\\tour\\tmap,\\tdystopian\\tfutures\\tare\\tbuilt\\tupon\\tthe\\t unevenly\\tdistributed\\ndystopian\\tregimes\\tof\\tthe\\tpast\\tand\\tpresent,\\tscattere d\\tthrough\\tan\\tarray\\tof\\tproduction\\tchains\\tfor\\tmodern\\t technical\\tdevices.\\tthe\\nvanishingly\\tfew\\tat\\tthe\\ttop\\tof\\tthe\\tfractal\\tpyramid\\to f\\tvalue\\textraction\\tlive\\tin\\textraordinary\\twealth\\tand \\tcomfort.\\tbut\\tthe\\tmajority\\tof\\tthe\\npyramids\\tare\\tmade\\tfrom\\tthe\\tdark\\ttunnels\\tof\\tmines,\\tr adioactive\\twaste\\tlakes,\\tdiscarded\\tshipping\\tcontaine rs,\\tand\\tcorporate\\tfactory\\ndormitories.\\namazon\\tpatent\\tnumber\\t20150066283\\ta1\\nxvi\\nat\\tthe\\tend\\tof\\t19th\\tcentury,\\ta\\tparticular\\tsoutheast\\t asian\\ttree\\tcalled\\t palaquium\\tgutta \\tbecame\\tthe\\tcenter\\tof\\ta\\ttechnological\\tboom.\\nthese\\ttrees,\\tfound\\tmainly\\tin\\tmalaysia,\\tproduce\\ta\\tmi lky\\twhite\\tnatural\\tlatex\\tcalled\\t gutta\\tpercha .\\tafter\\tenglish\\tscientist\\tmichael\\nfaraday\\tpublished\\ta\\tstudy\\tin\\tthe\\tphilosophical\\tmaga zine\\tin\\t1848\\tabout\\tthe\\tuse\\tof\\tthis\\tmaterial\\tas\\tan\\te lectrical\\tinsulator,\\t gutta\\npercha \\trapidly\\tbecame\\tthe\\tdarling\\tof\\tthe\\tengineering\\tworl d.\\tit\\twas\\tseen\\tas\\tthe\\tsolution\\tto\\tthe\\tproblem\\tof\\tin sulating\\ttelegraphic\\ncables\\tin\\torder\\tthat\\tthey\\tcould\\twithstand\\tthe\\tcondi tions\\tof\\tthe\\tocean\\tfloor.\\tas\\tthe\\tglobal\\tsubmarine\\tb usiness\\tgrew,\\tso\\tdid\\tdemand\\nfor\\tpalaquium\\tgutta \\ttree\\ttrunks.\\tthe\\thistorian\\tjohn\\ttully\\tdescribes\\tho w\\tlocal\\tmalay,\\tchinese\\tand\\tdayak\\tworkers\\twere\\tpaid\\t little\\tfor\\nthe\\tdangerous\\tworks\\tof\\tfelling\\tthe\\ttrees\\tand\\tslowly \\tcollecting\\tthe\\tlatex.\\t \\tthe\\tlatex\\twas\\tprocessed\\tthe n\\tsold\\tthrough\\tsingapore’s\\ntrade\\tmarkets\\tinto\\tthe\\tbritish\\tmarket,\\twhere\\tit\\twas \\ttransformed\\tinto,\\tamong\\tother\\tthings,\\tlengths\\tupon \\tlengths\\tof\\tsubmarine\\tcable\\nsheaths.36\\n37\\n38',\n",
       " \"a\\tmature\\t palaquium\\tgutta \\tcould\\tyield\\taround\\t300\\tgrams\\tof\\tlatex.\\tbut\\tin\\t1857 ,\\tthe\\tfirst\\ttransatlantic\\tcable\\twas\\taround\\t3000\\tkm\\nlong\\tand\\tweighed\\t2000\\ttons\\t–\\trequiring\\taround\\t250\\tt ons\\tof\\t gutta\\tpercha .\\tt o\\tproduce\\tjust\\tone\\tton\\tof\\tthis\\tmaterial\\trequired \\taround\\n900,000\\ttree\\ttrunks.\\tthe\\tjungles\\tof\\tmalaysia\\tand\\tsi ngapore\\twere\\tstripped,\\tand\\tby\\tthe\\tearly\\t1880s\\tthe\\t palaquium\\tgutta \\thad\\nvanished.\\tin\\ta\\tlast-ditch\\teffort\\tto\\tsave\\ttheir\\tsupp ly\\tchain,\\tthe\\tbritish\\tpassed\\ta\\tban\\tin\\t1883\\tto\\thalt\\t harvesting\\tthe\\tlatex,\\tbut\\tthe\\ttree\\nwas\\talready\\textinct.\\t\\nthe\\tvictorian\\tenvironmental\\tdisaster\\tof\\t gutta\\tpercha ,\\tfrom\\tthe\\tearly\\torigins\\tof\\tthe\\tglobal\\tinformation\\t society,\\tshows\\thow\\tthe\\nrelationships\\tbetween\\ttechnology\\tand\\tits\\tmaterialit y,\\tenvironments,\\tand\\tdifferent\\tforms\\tof\\texploitatio n\\tare\\timbricated.\\tjust\\tas\\nvictorians\\tprecipitated\\tecological\\tdisaster\\tfor\\tthe ir\\tearly\\tcables,\\tso\\tdo\\trare\\tearth\\tmining\\tand\\tglobal \\tsupply\\tchains\\tfurther\\timperil\\tthe\\ndelicate\\tecological\\tbalance\\tof\\tour\\tera.\\tfrom\\tthe\\tma terial\\tused\\tto\\tbuild\\tthe\\ttechnology\\tenabling\\tcontem porary\\tnetworked\\tsociety,\\tto\\nthe\\tenergy\\tneeded\\tfor\\ttransmitting,\\tanalyzing,\\tand\\t storing\\tthe\\tdata\\tflowing\\tthrough\\tthe\\tmassive\\tinfras tructure,\\tto\\tthe\\tmateriality\\tof\\ninfrastructure:\\tthese\\tdeep\\tconnections\\tand\\tcosts\\tar e\\tmore\\tsignificant,\\tand\\thave\\ta\\tfar\\tlonger\\thistory,\\t than\\tis\\tusually\\trepresented\\tin\\nthe\\tcorporate\\timaginaries\\tof\\tai.\\t\\npalaquium\\tgutta\\nxvii\\nlarge-scale\\tai\\tsystems\\tconsume\\tenormous\\tamounts\\tof\\t energy.\\tyet\\tthe\\tmaterial\\tdetails\\tof\\tthose\\tcosts\\trem ain\\tvague\\nin\\tthe\\tsocial\\timagination. \\tit\\tremains\\tdifficult\\tto\\tget\\tprecise\\tdetails\\tabout\\t the\\tamount\\tof\\tenergy\\tconsumed\\tby\\tcloud\\tcomputing\\nservices.\\ta\\tgreenpeace\\treport\\tstates:\\t“one\\tof\\tthe\\ts ingle\\tbiggest\\tobstacles\\tto\\tsector\\ttransparency\\tis\\ta mazon\\tweb\\tservices\\t(aws).\\nthe\\tworld's\\tbiggest\\tcloud\\tcomputer\\tcompany\\tremains\\t almost\\tcompletely\\tnon-transparent\\tabout\\tthe\\tenergy\\t footprint\\tof\\tits\\tmassive\\noperations.\\tamong\\tthe\\tglobal\\tcloud\\tproviders,\\tonly\\t aws\\tstill\\trefuses\\tto\\tmake\\tpublic\\tbasic\\tdetails\\ton\\tt he\\tenergy\\tperformance\\tand\\nenvironmental\\timpact\\tassociated\\twith\\tits\\toperations .”\\t\\nas\\thuman\\tagents,\\twe\\tare\\tvisible\\tin\\talmost\\tevery\\tint eraction\\twith\\ttechnological\\tplatforms.\\twe\\tare\\talway s\\tbeing\\ttracked,\\tquantified,\\nanalyzed\\tand\\tcommodified.\\tbut\\tin\\tcontrast\\tto\\tuser\\tv isibility,\\tthe\\tprecise\\tdetails\\tabout\\tthe\\tphases\\tof\\t birth,\\tlife\\tand\\tdeath\\tof\\nnetworked\\tdevices\\tare\\tobscured.\\twith\\temerging\\tdevic es\\tlike\\tthe\\techo\\trelying\\ton\\ta\\tcentralized\\tai\\tinfras tructure\\tfar\\tfrom\\tview,\\teven\\nmore\\tof\\tthe\\tdetail\\tfalls\\tinto\\tthe\\tshadows.39\\n40\\n41\",\n",
       " 'while\\tconsumers\\tbecome\\taccustomed\\tto\\ta\\tsmall\\thardwa re\\tdevice\\tin\\ttheir\\tliving\\trooms,\\tor\\ta\\tphone\\tapp,\\tor \\ta\\tsemi-autonomous\\tcar,\\nthe\\treal\\twork\\tis\\tbeing\\tdone\\twithin\\tmachine\\tlearning \\tsystems\\tthat\\tare\\tgenerally\\tremote\\tfrom\\tthe\\tuser\\tan d\\tutterly\\tinvisible\\tto\\ther.\\tin\\nmany\\tcases,\\ttransparency\\twouldn’t\\thelp\\tmuch\\t–\\twitho ut\\tforms\\tof\\treal\\tchoice,\\tand\\tcorporate\\taccountabili ty,\\tmere\\ttransparency\\nwon’t\\tshift\\tthe\\tweight\\tof\\tthe\\tcurrent\\tpower\\tasymmet ries.\\t\\nthe\\toutputs\\tof\\tmachine\\tlearning\\tsystems\\tare\\tpredomi nantly\\tunaccountable\\tand\\tungoverned,\\twhile\\tthe\\tinpu ts\\tare\\tenigmatic.\\tt o\\tthe\\ncasual\\tobserver,\\tit\\tlooks\\tlike\\tit\\thas\\tnever\\tbeen\\tea sier\\tto\\tbuild\\tai\\tor\\tmachine\\tlearning-based\\tsystems\\t than\\tit\\tis\\ttoday.\\tavailability\\tof\\nopen-source\\ttools\\tfor\\tdoing\\tso\\tin\\tcombination\\twith\\t rentable\\tcomputation\\tpower\\tthrough\\tcloud\\tsuperpower s\\tsuch\\tas\\tamazon\\n(aws),\\tmicrosoft\\t(azure),\\tor\\tgoogle\\t(google\\tcloud)\\t is\\tgiving\\trise\\tto\\ta\\tfalse\\tidea\\tof\\tthe\\t‘democratizat ion’\\tof\\tai.\\twhile\\t‘off\\tthe\\tshelf’\\nmachine\\tlearning\\ttools,\\tlike\\tt ensorflow,\\tare\\tbecomi ng\\tmore\\taccessible\\tfrom\\tthe\\tpoint\\tof\\tview\\tof\\tsettin g\\tup\\tyour\\town\\tsystem,\\tthe\\nunderlying\\tlogics\\tof\\tthose\\tsystems,\\tand\\tthe\\tdataset s\\tfor\\ttraining\\tthem\\tare\\taccessible\\tto\\tand\\tcontrolle d\\tby\\tvery\\tfew\\tentities.\\tin\\tthe\\ndynamic\\tof\\tdataset\\tcollection\\tthrough\\tplatforms\\tlik e\\tfacebook,\\tusers\\tare\\tfeeding\\tand\\ttraining\\tthe\\tneur al\\tnetworks\\twith\\tbehavioral\\ndata,\\tvoice,\\ttagged\\tpictures\\tand\\tvideos\\tor\\tmedical\\t data.\\tin\\tan\\tera\\tof\\textractivism,\\tthe\\treal\\tvalue\\tof\\t that\\tdata\\tis\\tcontrolled\\tand\\nexploited\\tby\\tthe\\tvery\\tfew\\tat\\tthe\\ttop\\tof\\tthe\\tpyramid .\\nxviii\\nwhen\\tmassive\\tdata\\tsets\\tare\\tused\\tto\\ttrain\\tai\\tsystems ,\\tthe\\tindividual\\timages\\tand\\tvideos\\tinvolved\\tare\\tcom monly\\ttagged\\tand\\tlabeled.\\n\\tthere\\tis\\tmuch\\tto\\tbe\\tsaid\\tabout\\thow\\tthis\\tlabelling\\t process\\tabrogates\\tand\\tcrystallizes\\tmeaning,\\tand\\tfur ther,\\thow\\tthis\\tprocess\\tis\\ndriven\\tby\\tclickworkers\\tbeing\\tpaid\\tfractions\\tof\\ta\\tce nt\\tfor\\tthis\\tdigital\\tpiecework.\\nin\\t1770,\\thungarian\\tinventor\\twolfgang\\tvon\\tkempelen\\tc onstructed\\ta\\tchess-playing\\tmachine\\tknown\\tas\\tthe\\tmec hanical\\tturk.\\this\\tgoal,\\nin\\tpart,\\twas\\tto\\timpress\\tempress\\tmaria\\ttheresa\\tof\\tau stria.\\tthis\\tdevice\\twas\\tcapable\\tof\\tplaying\\tchess\\taga inst\\ta\\thuman\\topponent\\tand\\nhad\\tspectacular\\tsuccess\\twinning\\tmost\\tof\\tthe\\tgames\\tp layed\\tduring\\tits\\tdemonstrations\\taround\\teurope\\tand\\tt he\\tamericas\\tfor\\talmost\\nnine\\tdecades.\\tbut\\tthe\\tmechanical\\tturk\\twas\\tan\\tillusi on\\tthat\\tallowed\\ta\\thuman\\tchess\\tmaster\\tto\\thide\\tinside \\tthe\\tmachine\\tand\\toperate\\nit.\\tsome\\t160\\tyears\\tlater,\\tamazon.com\\tbranded\\tits\\tmi cropayment\\tbased\\tcrowdsourcing\\tplatform\\twith\\tthe\\tsa me\\tname.\\taccording\\nto\\tayhan\\taytes,\\tamazon’s\\tinitial\\tmotivation\\tto\\tbuil d\\tmechanical\\tturk\\temerged\\tafter\\tthe\\tfailure\\tof\\tits\\t artificial\\tintelligence\\tprograms\\tin\\nthe\\ttask\\tof\\tfinding\\tduplicate\\tproduct\\tpages\\ton\\tits\\t retail\\twebsite.\\t \\tafter\\ta\\tseries\\tof\\tfutile\\tand\\texpen sive\\tattempts,\\tthe\\tproject\\nengineers\\tturned\\tto\\thumans\\tto\\twork\\tbehind\\tcomputers \\twithin\\ta\\tstreamlined\\tweb-based\\tsystem.\\t \\tamazon\\tmec hanical\\tturk\\tdigital\\nworkshop\\temulates\\tartificial\\tintelligence\\tsystems\\tb y\\tchecking,\\tassessing\\tand\\tcorrecting\\tmachine\\tlearni ng\\tprocesses\\twith\\thuman\\nbrainpower.\\twith\\tamazon\\tmechanical\\tturk,\\tit\\tmay\\tsee m\\tto\\tusers\\tthat\\tan\\tapplication\\tis\\tusing\\tadvanced\\tar tificial\\tintelligence\\tto\\naccomplish\\ttasks.\\tbut\\tit\\tis\\tcloser\\tto\\ta\\tform\\tof\\t‘ar tificial\\tartificial\\tintelligence’,\\tdriven\\tby\\ta\\tremo te,\\tdispersed\\tand\\tpoorly\\tpaid\\nclickworker\\tworkforce\\tthat\\thelps\\ta\\tclient\\tachieve\\tt heir\\tbusiness\\tobjectives.\\tas\\tobserved\\tby\\taytes,\\t“in \\tboth\\tcases\\t[both\\tthe\\nmechanical\\tturk\\tfrom\\t1770\\tand\\tthe\\tcontemporary\\tvers ion\\tof\\tamazon’s\\tservice]\\tthe\\tperformance\\tof\\tthe\\twor kers\\twho\\tanimate\\tthe\\nartifice\\tis\\tobscured\\tby\\tthe\\tspectacle\\tof\\tthe\\tmachin e.”\\t\\nthis\\tkind\\tof\\tinvisible,\\thidden\\tlabor,\\toutsourced\\tor \\tcrowdsourced,\\thidden\\tbehind\\tinterfaces\\tand\\tcamoufl aged\\twithin\\talgorithmic\\nprocesses\\tis\\tnow\\tcommonplace,\\tparticularly\\tin\\tthe\\tp rocess\\tof\\ttagging\\tand\\tlabeling\\tthousands\\tof\\thours\\to f\\tdigital\\tarchives\\tfor\\tthe\\nsake\\tof\\tfeeding\\tthe\\tneural\\tnetworks.\\tsometimes\\tthis \\tlabor\\tis\\tentirely\\tunpaid,\\tas\\tin\\tthe\\tcase\\tof\\tthe\\tgo ogle’s\\trecaptcha.\\tin\\ta\\nparadox\\tthat\\tmany\\tof\\tus\\thave\\texperienced,\\tin\\torder\\t to\\tprove\\tthat\\tyou\\tare\\tnot\\tartificial\\tagent,\\tyou\\tare \\tforced\\tto\\ttrain\\tgoogle’s\\nimage\\trecognition\\tai\\tsystem\\tfor\\tfree,\\tby\\tselecting\\t multiple\\tboxes\\tthat\\tcontain\\tstreet\\tnumbers,\\tor\\tcars ,\\tor\\thouses.\\nas\\twe\\tsee\\trepeated\\tthroughout\\tthe\\tsystem,\\tcontempor ary\\tforms\\tof\\tartificial\\tintelligence\\tare\\tnot\\tso\\tart ificial\\tafter\\tall.\\twe\\tcan\\tspeak\\nof\\tthe\\thard\\tphysical\\tlabor\\tof\\tmine\\tworkers,\\tand\\tthe \\trepetitive\\tfactory\\tlabor\\ton\\tthe\\tassembly\\tline,\\tof\\t the\\tcybernetic\\tlabor\\tin\\ndistribution\\tcenters\\tand\\tthe\\tcognitive\\tsweatshops\\tf ull\\tof\\toutsourced\\tprogrammers\\taround\\tthe\\tworld,\\tof\\t the\\tlow\\tpaid\\tcrowdsourced\\nlabor\\tof\\tmechanical\\tturk\\tworkers,\\tor\\tthe\\tunpaid\\timm aterial\\twork\\tof\\tusers.\\tat\\tevery\\tlevel\\tcontemporary\\t technology\\tis\\tdeeply\\trooted\\nin\\tand\\trunning\\ton\\tthe\\texploitation\\tof\\thuman\\tbodies.42\\n43\\n44\\n45\\n46',\n",
       " 'mechanical\\tturk\\nxix\\nin\\this\\tone-paragraph\\tshort\\tstory\\t\"on\\texactitude\\tin\\t science\",\\tjorge\\tluis\\tborges\\tpresents\\tus\\twith\\tan\\tima gined\\tempire\\tin\\twhich\\ncartographic\\tscience\\tbecame\\tso\\tdeveloped\\tand\\tprecis e,\\tthat\\tit\\tneeded\\ta\\tmap\\ton\\tthe\\tsame\\tscale\\tas\\tthe\\tem pire\\titself.\\t\\n“...in\\tthat\\tempire,\\tthe\\tart\\tof\\tcartography\\tattained \\tsuch\\tperfection\\tthat\\tthe\\tmap\\tof\\ta\\tsingle\\tprovince\\t occupied\\tthe\\tentirety\\tof\\ta\\tcity,\\nand\\tthe\\tmap\\tof\\tthe\\tempire,\\tthe\\tentirety\\tof\\ta\\tprovin ce.\\tin\\ttime,\\tthose\\tunconscionable\\tmaps\\tno\\tlonger\\tsa tisfied,\\tand\\tthe\\ncartographers\\tguilds\\tstruck\\ta\\tmap\\tof\\tthe\\tempire\\twho se\\tsize\\twas\\tthat\\tof\\tthe\\tempire,\\tand\\twhich\\tcoincided \\tpoint\\tfor\\tpoint\\twith\\tit.\\nthe\\tfollowing\\tgenerations,\\twho\\twere\\tnot\\tso\\tfond\\tof\\t the\\tstudy\\tof\\tcartography\\tas\\ttheir\\tforebears\\thad\\tbee n,\\tsaw\\tthat\\tthat\\tvast\\tmap\\nwas\\tuseless,\\tand\\tnot\\twithout\\tsome\\tpitilessness\\twas\\t it,\\tthat\\tthey\\tdelivered\\tit\\tup\\tto\\tthe\\tinclemencies\\to f\\tsun\\tand\\twinters.\\tin\\tthe\\ndeserts\\tof\\tthe\\twest,\\tstill\\ttoday,\\tthere\\tare\\ttattere d\\truins\\tof\\tthat\\tmap,\\tinhabited\\tby\\tanimals\\tand\\tbegga rs;\\tin\\tall\\tthe\\tland\\tthere\\tis\\tno\\nother\\trelic\\tof\\tthe\\tdisciplines\\tof\\tgeography.”\\ncurrent\\tmachine\\tlearning\\tapproaches\\tare\\tcharacteriz ed\\tby\\tan\\taspiration\\tto\\tmap\\tthe\\tworld,\\ta\\tfull\\tquanti fication\\tof\\tvisual,\\tauditory,\\nand\\trecognition\\tregimes\\tof\\treality.\\tfrom\\tcosmologic al\\tmodel\\tfor\\tthe\\tuniverse\\tto\\tthe\\tworld\\tof\\thuman\\temo tions\\tas\\tinterpreted\\nthrough\\tthe\\ttiniest\\tmuscle\\tmovements\\tin\\tthe\\thuman\\tf ace,\\teverything\\tbecomes\\tan\\tobject\\tof\\tquantification .\\tjean-françois\\tlyotard\\nintroduced\\tthe\\tphrase\\t“affinity\\tto\\tinfinity”\\tto\\tdes cribe\\thow\\tcontemporary\\tart,\\ttechno-science\\tand\\tcapi talism\\tshare\\tthe\\tsame\\naspiration\\tto\\tpush\\tboundaries\\ttowards\\ta\\tpotentially \\tinfinite\\thorizon.\\t \\tthe\\tsecond\\thalf\\tof\\tthe\\t19th\\tcen tury,\\twith\\tits\\tfocus\\ton\\tthe\\nconstruction\\tof\\tinfrastructure\\tand\\tthe\\tuneven\\ttrans ition\\tto\\tindustrialized\\tsociety,\\tgenerated\\tenormous \\twealth\\tfor\\tthe\\tsmall\\tnumber\\nof\\tindustrial\\tmagnates\\tthat\\tmonopolized\\texploitatio n\\tof\\tnatural\\tresources\\tand\\tproduction\\tprocesses.\\nthe\\tnew\\tinfinite\\thorizon\\tis\\tdata\\textraction,\\tmachin e\\tlearning,\\tand\\treorganizing\\tinformation\\tthrough\\tar tificial\\tintelligence\\tsystems\\tof\\ncombined\\thuman\\tand\\tmachinic\\tprocessing.\\tthe\\tterrito ries\\tare\\tdominated\\tby\\ta\\tfew\\tglobal\\tmega-companies,\\t which\\tare\\tcreating\\tnew\\ninfrastructures\\tand\\tmechanisms\\tfor\\tthe\\taccumulation \\tof\\tcapital\\tand\\texploitation\\tof\\thuman\\tand\\tplanetary \\tresources.\\nsuch\\tunrestrained\\tthirst\\tfor\\tnew\\tresources\\tand\\tfiel ds\\tof\\tcognitive\\texploitation\\thas\\tdriven\\ta\\tsearch\\tfo r\\tever\\tdeeper\\tlayers\\tof\\tdata\\nthat\\tcan\\tbe\\tused\\tto\\tquantify\\tthe\\thuman\\tpsyche,\\tcons cious\\tand\\tunconscious,\\tprivate\\tand\\tpublic,\\tidiosync ratic\\tand\\tgeneral.\\tin\\tthis\\nway,\\twe\\thave\\tseen\\tthe\\temergence\\tof\\tmultiple\\tcogniti ve\\teconomies\\tfrom\\tthe\\tattention\\teconomy,\\t \\tthe\\tsurve illance\\teconomy,\\tthe\\nreputation\\teconomy,\\t \\tand\\tthe\\temotion\\teconomy,\\tas\\twe ll\\tas\\tthe\\tquantification\\tand\\tcommodification\\tof\\ttru st\\tand\\tevidence\\tthrough\\ncryptocurrencies.\\nincreasingly,\\tthe\\tprocess\\tof\\tquantification\\tis\\treac hing\\tinto\\tthe\\thuman\\taffective,\\tcognitive,\\tand\\tphysi cal\\tworlds.\\ttraining\\tsets\\texist\\tfor\\nemotion\\tdetection,\\tfor\\tfamily\\tresemblance,\\tfor\\ttrac king\\tan\\tindividual\\tas\\tthey\\tage,\\tand\\tfor\\thuman\\tactio ns\\tlike\\tsitting\\tdown,\\twaving,\\nraising\\ta\\tglass,\\tor\\tcrying.\\t every\\tform\\tof\\tbiodata\\t–\\tincluding\\tforensic,\\tbiometr ic,\\tsociometric,\\tand\\tpsychometric\\t–\\tare47\\n48\\n49\\n50',\n",
       " 'being\\tcaptured\\tand\\tlogged\\tinto\\tdatabases\\tfor\\tai\\ttra ining. \\tthat\\tquantification\\toften\\truns\\ton\\tvery\\tlimited\\tfou ndations:\\tdatasets\\nlike\\tava\\twhich\\tprimarily\\tshows\\twomen\\tin\\tthe\\t‘playin g\\twith\\tchildren’\\taction\\tcategory,\\tand\\tmen\\tin\\tthe\\t‘k icking\\ta\\tperson’\\tcategory.\\tthe\\ntraining\\tsets\\tfor\\tai\\tsystems\\tclaim\\tto\\tbe\\treaching\\ti nto\\tthe\\tfine-grained\\tnature\\tof\\teveryday\\tlife,\\tbut\\tt hey\\trepeat\\tthe\\tmost\\tstereotypical\\nand\\trestricted\\tsocial\\tpatterns,\\tre-inscribing\\ta\\tnor mative\\tvision\\tof\\tthe\\thuman\\tpast\\tand\\tprojecting\\tit\\ti nto\\tthe\\thuman\\tfuture.\\nquantification\\tof\\tnature\\nxx\\n\"the\\t\\'enclosure\\'\\tof\\tbiodiversity\\tand\\tknowledge\\tis\\tt he\\tfinal\\tstep\\tin\\ta\\tseries\\tof\\tenclosures\\tthat\\tbegan\\t with\\tthe\\trise\\tof\\tcolonialism.\\tland\\nand\\tforests\\twere\\tthe\\tfirst\\tresources\\tto\\tbe\\t\\'enclose d\\'\\tand\\tconverted\\tfrom\\tcommons\\tto\\tcommodities.\\tlater \\ton,\\twater\\tresources\\nwere\\t\\'enclosed\\'\\tthrough\\tdams,\\tgroundwater\\tmining\\tan d\\tprivatization\\tschemes.\\tnow\\tit\\tis\\tthe\\tturn\\tof\\tbiod iversity\\tand\\tknowledge\\tto\\nbe\\t\\'enclosed\\'\\tthrough\\tintellectual\\tproperty\\trights\\t (iprs),”\\tvandana\\tshiva\\texplains.\\t \\tin\\tshiva’s\\twords, \\t“the\\tdestruction\\tof\\tcommons\\nwas\\tessential\\tfor\\tthe\\tindustrial\\trevolution,\\tto\\tpro vide\\ta\\tsupply\\tof\\tnatural\\tresources\\tfor\\traw\\tmaterial \\tto\\tindustry.\\ta\\tlife-support\\nsystem\\tcan\\tbe\\tshared,\\tit\\tcannot\\tbe\\towned\\tas\\tprivate \\tproperty\\tor\\texploited\\tfor\\tprivate\\tprofit.\\tthe\\tcomm ons,\\ttherefore,\\thad\\tto\\tbe\\nprivatized,\\tand\\tpeople\\'s\\tsustenance\\tbase\\tin\\tthese\\tc ommons\\thad\\tto\\tbe\\tappropriated,\\tto\\tfeed\\tthe\\tengine\\to f\\tindustrial\\tprogress\\tand\\ncapital\\taccumulation.\"\\t\\nwhile\\tshiva\\tis\\treferring\\tto\\tenclosure\\tof\\tnature\\tby\\t intellectual\\tproperty\\trights,\\tthe\\tsame\\tprocess\\tis\\tn ow\\toccurring\\twith\\tmachine\\nlearning\\t–\\tan\\tintensification\\tof\\tquantified\\tnature. \\tthe\\tnew\\tgold\\trush\\tin\\tthe\\tcontext\\tof\\tartificial\\tint elligence\\tis\\tto\\tenclose\\tdifferent\\tfields\\nof\\thuman\\tknowing,\\tfeeling,\\tand\\taction,\\tin\\torder\\tto\\t capture\\tand\\tprivatize\\tthose\\tfields.\\twhen\\tin\\tnovembe r\\t2015\\tdeepmind\\nt echnologies\\tltd.\\tgot\\taccess\\tto\\tthe\\thealth\\trecords\\t of\\t1.6\\tmillion\\tidentifiable\\tpatients\\tof\\troyal\\tfree\\t hospital,\\twe\\twitnessed\\ta\\nparticular\\tform\\tof\\tprivatization:\\tthe\\textraction\\tof \\tknowledge\\tvalue.\\t \\ta\\tdataset\\tmay\\tstill\\tbe\\tpublicly\\t owned,\\tbut\\tthe\\tmeta-value\\tof\\nthe\\tdata\\t–\\tthe\\tmodel\\tcreated\\tby\\tit\\t–\\tis\\tprivately\\to wned.\\twhile\\tthere\\tare\\tmany\\tgood\\treasons\\tto\\tseek\\tto\\t improve\\tpublic\\thealth,\\tthere\\nis\\ta\\treal\\trisk\\tif\\tit\\tcomes\\tat\\tthe\\tcost\\tof\\ta\\tstealth \\tprivatization\\tof\\tpublic\\tmedical\\tservices.\\tthat\\tis\\t a\\tfuture\\twhere\\texpert\\tlocal\\thuman\\nlabor\\tin\\tthe\\tpublic\\tsystem\\tis\\taugmented\\tand\\tsometim es\\treplaced\\twith\\tcentralized,\\tprivately-owned\\tcorpo rate\\tai\\tsystems,\\tthat\\tare\\nusing\\tpublic\\tdata\\tto\\tgenerate\\tenormous\\twealth\\tfor\\tt he\\tvery\\tfew.51\\n52\\n53',\n",
       " 'corporate\\tborder\\nxxi\\nat\\tthis\\tmoment\\tin\\tthe\\t21st\\tcentury,\\twe\\tsee\\ta\\tnew\\tfo rm\\tof\\textractivism\\tthat\\tis\\twell\\tunderway:\\tone\\tthat\\t reaches\\tinto\\nthe\\tfurthest\\tcorners\\tof\\tthe\\tbiosphere\\tand\\tthe\\tdeepe st\\tlayers\\tof\\thuman\\tcognitive\\tand\\taffective\\tbeing. \\tmany\\tof\\tthe\\nassumptions\\tabout\\thuman\\tlife\\tmade\\tby\\tmachine\\tlearni ng\\tsystems\\tare\\tnarrow,\\tnormative\\tand\\tladen\\twith\\terr or.\\tyet\\tthey\\tare\\ninscribing\\tand\\tbuilding\\tthose\\tassumptions\\tinto\\ta\\tne w\\tworld,\\tand\\twill\\tincreasingly\\tplay\\ta\\trole\\tin\\thow\\to pportunities,\\twealth,\\tand\\nknowledge\\tare\\tdistributed.\\nthe\\tstack\\tthat\\tis\\trequired\\tto\\tinteract\\twith\\tan\\tamaz on\\techo\\tgoes\\twell\\tbeyond\\tthe\\tmulti-layered\\t‘technic al\\tstack’\\tof\\tdata\\tmodeling,\\nhardware,\\tservers\\tand\\tnetworks.\\tthe\\tfull\\tstack\\treac hes\\tmuch\\tfurther\\tinto\\tcapital,\\tlabor\\tand\\tnature,\\tan d\\tdemands\\tan\\tenormous\\namount\\tof\\teach.\\tthe\\ttrue\\tcosts\\tof\\tthese\\tsystems\\t–\\ts ocial,\\tenvironmental,\\teconomic,\\tand\\tpolitical\\t–\\trem ain\\thidden\\tand\\tmay\\tstay\\nthat\\tway\\tfor\\tsome\\ttime.\\nwe\\toffer\\tup\\tthis\\tmap\\tand\\tessay\\tas\\ta\\tway\\tto\\tbegin\\tse eing\\tacross\\ta\\twider\\trange\\tof\\tsystem\\textractions.\\tth e\\tscale\\trequired\\tto\\tbuild\\nartificial\\tintelligence\\tsystems\\tis\\ttoo\\tcomplex,\\ttoo \\tobscured\\tby\\tintellectual\\tproperty\\tlaw,\\tand\\ttoo\\tmir ed\\tin\\tlogistical\\tcomplexity\\tto\\tfully\\ncomprehend\\tin\\tthe\\tmoment.\\tyet\\tyou\\tdraw\\ton\\tit\\tevery\\t time\\tyou\\tissue\\ta\\tsimple\\tvoice\\tcommand\\tto\\ta\\tsmall\\tcy linder\\tin\\tyour\\tliving\\nroom:\\t‘alexa,\\twhat\\ttime\\tis\\tit?”\\nand\\tso\\tthe\\tcycle\\tcontinues.\\nfootnotes\\n1kate\\tcrawford\\tis\\ta\\tdistinguished\\tresearch\\tprofessor \\tat\\tnew\\tyork\\tuniversity,\\ta\\tprincipal\\tresearcher\\tat\\t microsoft\\tresearch\\tnew\\tyork,\\tand\\tthe\\tco-\\nfounder\\tand\\tco-director\\tof\\tthe\\tai\\tnow\\tinstitute\\tat\\t nyu.\\n2vladan\\tjoler\\tis\\ta\\tprofessor\\tat\\tthe\\tacademy\\tof\\tarts\\t at\\tthe\\tuniversity\\tof\\tnovi\\tsad\\tand\\tfounder\\tof\\tshare\\t foundation.\\the\\tis\\tleading\\tshare\\tlab,\\ta\\nresearch\\tand\\tdata\\tinvestigation\\tlab\\tfor\\texploring\\td ifferent\\ttechnical\\tand\\tsocial\\taspects\\tof\\talgorithmi c\\ttransparency,\\tdigital\\tlabor\\texploitation,\\ninvisible\\tinfrastructures,\\tand\\ttechnological\\tblack\\t boxes.\\n3amazon\\tadvertising\\tcampaign,\\t“all-new\\tamazon\\techo”, \\tseptember\\t27,\\t2017,\\thttps://www.youtube.com/watch? v=zlpmpzpqjn4 .\\n4emily\\tachtenberg,\\t“bolivia\\tbets\\ton\\tstate-run\\tlithiu m\\tindustry,”\\tnacla,\\tnovember\\t15,\\t2010,\\thttps://nacl a.org/news/bolivia-bets-state-run-lithium-\\nindustry .',\n",
       " '5christine\\tnegroni,\\t“how\\tto\\tdetermine\\tthe\\tpower\\trati ng\\tof\\tyour\\tgadget’s\\tbatteries,”\\t the\\tnew\\tyork\\ttimes ,\\tdecember\\t22,\\t2017,\\nhttps://www.nytimes.com/2016/12/26/business/lithium -ion-battery-airline-safety .html .\\n6jessica\\tshankleman\\tet\\tal.,\\t“we’re\\tgoing\\tto\\tneed\\tmor e\\tlithium,”\\t bloomberg ,\\tseptember\\t7,\\t2017,\\thttps://www.bloomberg.com/grap hics/2017-lithium-\\nbattery-future/ .\\n7nicola\\tclark\\tand\\tsimon\\twallis,\\t“flamingos,\\tsalt\\tlak es\\tand\\tvolcanoes:\\thunting\\tfor\\tevidence\\tof\\tpast\\tclim ate\\tchange\\ton\\tthe\\thigh\\taltiplano\\tof\\tbolivia,”\\ngeology\\ttoday \\t33,\\tno.\\t3\\t(may\\t1,\\t2017):\\t104,\\thttps://doi.org/10.1 111/gto.12186 .\\n8kate\\tdavies\\tand\\tliam\\tyoung,\\t tales\\tfrom\\tthe\\tdark\\tside\\tof\\tthe\\tcity:\\tthe\\tbreastmil k\\tof\\tthe\\tvolcano\\tbolivia\\tand\\tthe\\tatacama\\tdesert\\texp edition \\t(london:\\nunknown\\tfields,\\t2016).\\n9vincent\\tmosco,\\t to\\tthe\\tcloud:\\tbig\\tdata\\tin\\ta\\tturbulent\\tworld \\t(boulder:\\tparadigm,\\t2014).\\n10sandro\\tmezzadra\\tand\\tbrett\\tneilson,\\t“on\\tthe\\tmultiple \\tfrontiers\\tof\\textraction:\\texcavating\\tcontemporary\\tc apitalism,”\\t cultural\\tstudies \\t31,\\tno.\\t2–3\\t(may\\n4,\\t2017):\\t185,\\thttps://doi.org/10.1080/09502386.201 7.1303425 .\\n11lamberto\\ttronchin,\\t“the\\t‘phonurgia\\tnova’\\tof\\tathanas ius\\tkircher:\\tthe\\tmarvellous\\tsound\\tworld\\tof\\t17th\\tcen tury,”\\t proceedings\\tof\\tmeetings\\ton\\nacoustics \\t4,\\tno.\\t1\\t(june\\t29,\\t2008),\\t4:\\t015002,\\thttps://doi.o rg/10.1121/1.2992053 .\\n12marshall\\tmcluhan,\\t understanding\\tmedia:\\tthe\\textensions\\tof\\tman \\t(new\\tyork:\\tsignet\\tbooks,\\t1964).\\n13jussi\\tparikka,\\t a\\tgeology\\tof\\tmedia \\t(minneapolis:\\tuniversity\\tof\\tminnesota\\tpress,\\t2015) ,\\tvii-viii.\\n14chris\\tely,\\t“the\\tlife\\texpectancy\\tof\\telectronics,”\\tco nsumer\\ttechnology\\tassociation,\\tseptember\\t16,\\t2014,\\nhttps://www.cta.tech/news/blog/articles/2014/septem ber/the-life-expectancy-of-electronics.aspx .\\n15christian\\tfuchs,\\t digital\\tlabor\\tand\\tkarl\\tmarx \\t(london:\\troutledge,\\t2014).\\n16“this\\tis\\twhat\\twe\\tdie\\tfor:\\thuman\\trights\\tabuses\\tin\\tth e\\tdemocratic\\trepublic\\tof\\tthe\\tcongo\\tpower\\tthe\\tglobal \\ttrade\\tin\\tcobalt”\\t(london:\\tamnesty\\ninternational,\\t2016),\\thttps://www.amnesty .org/downl oad/documents/afr6231832016english.pdf .\\tfor\\tan\\tanthropological\\tdescription\\tof\\tthese\\nmining\\tprocesses,\\tsee:\\tjeffrey\\tw.\\tmantz,\\t“improvisa tional\\teconomies:\\tcoltan\\tproduction\\tin\\tthe\\teastern\\t congo,”\\t social\\tanthropology \\t16,\\tno.\\t1\\n(february\\t1,\\t2008):\\t34–50,\\thttps://doi.org/10.1111/ j.1469-8676.2008.00035.x .\\n17julia\\tglum,\\t“the\\tmedian\\tamazon\\temployee’s\\tsalary\\tis \\t$28,000.\\tjeff\\tbezos\\tmakes\\tmore\\tthan\\tthat\\tin\\t10\\tsec onds,”\\t time,\\tmay\\t2,\\t2018,\\nhttp://time.com/money/5262923/amazon-employee-media n-salary-jeff-bezos/ .\\n18frank\\tpasquale,\\t the\\tblack\\tbox\\tsociety:\\tthe\\tsecret\\talgorithms\\tthat\\tc ontrol\\tmoney\\tand\\tinformation \\t(cambridge,\\tma:\\tharvard\\tuniversity\\tpress,\\n2016).\\n19mark\\tgraham\\tand\\thåvard\\thaarstad,\\t“transparency\\tand\\t development:\\tethical\\tconsumption\\tthrough\\tweb\\t2.0\\tan d\\tthe\\tinternet\\tof\\tthings,”\\ninformation\\ttechnologies\\t&\\tinternational\\tdevelopmen t\\t7,\\tno.\\t1\\t(march\\t10,\\t2011):\\t1.\\n20“intel’s\\tefforts\\tto\\tachieve\\ta\\t‘conflict\\tfree’\\tsuppl y\\tchain”\\t(santa\\tclara,\\tca:\\tintel\\tcorporation,\\tmay\\t2 018),\\nhttps://www.intel.com/content/www/us/en/corporate-r esponsibility/conflict-minerals-white-paper.html .\\n21“we\\tare\\tworking\\tto\\tmake\\tour\\tsupply\\tchain\\t‘conflict- free,’”\\tphilips,\\t2018,\\thttps://www.philips.com/a-w/ about/company/suppliers/supplier-\\nsustainability/our-programs/conflict-minerals.html .\\n22david\\ts.\\tabraham,\\t the\\telements\\tof\\tpower:\\tgadgets,\\tguns,\\tand\\tthe\\tstrug gle\\tfor\\ta\\tsustainable\\tfuture\\tin\\tthe\\trare\\tmetal\\tage ,\\treprint\\tedition\\t(yale\\nuniversity\\tpress,\\t2017),\\t89.\\n23“responsible\\tminerals\\tsourcing,”\\tdell,\\t2018,\\thttp:/ /www.dell.com/learn/us/en/uscorp1/conflict-minerals ?s=corp .\\n24“apple\\tsupplier\\tresponsibility\\t2018\\tprogress\\treport ”\\t(cupertino\\tca:\\tapple,\\t2018),\\thttps://www.apple.co m/supplier-\\nresponsibility/pdf/apple_sr_2018_progress_report.pd f.',\n",
       " 'responsibility/pdf/apple_sr_2018_progress_report.pd f.\\n25alexander\\tklose,\\t the\\tcontainer\\tprinciple:\\thow\\ta\\tbox\\tchanges\\tthe\\tway\\t we\\tthink ,\\ttrans.\\tcharles\\tmarcum\\tii\\t(cambridge,\\tma:\\tthe\\tmit\\t press,\\t2015).\\n26“review\\tof\\tmaritime\\ttransport\\t2017”\\t(new\\tyork\\tand\\tg eneva:\\tunited\\tnations,\\t2017),\\thttp://unctad.org/en/ publicationslibrary/rmt2017_en.pdf .\\n27zoë\\tschlanger,\\t“if\\tshipping\\twere\\ta\\tcountry,\\tit\\twoul d\\tbe\\tthe\\tsixth-biggest\\tgreenhouse\\tgas\\temitter,”\\t quartz ,\\tapril\\t17,\\t2018.\\n28john\\tvidal,\\t“health\\trisks\\tof\\tshipping\\tpollution\\thav e\\tbeen\\t‘underestimated,’”\\t the\\tguardian ,\\tapril\\t9,\\t2009,\\tsec.\\tenvironment,\\nhttp://www.theguardian.com/environment/2009/apr/09/ shipping-pollution .\\n29“containers\\tlost\\tat\\tsea\\t–\\t2017\\tupdate”\\t(world\\tshipp ing\\tcouncil,\\tjuly\\t10,\\t2017),\\thttp://www.worldshippi ng.org/industry-\\nissues/safety/containers_lost_at_sea_-_2017_update_ final_july_10.pdf .\\n30rose\\tgeorge,\\t ninety\\tpercent\\tof\\teverything:\\tinside\\tshipping,\\tthe\\t invisible\\tindustry\\tthat\\tputs\\tclothes\\ton\\tyour\\tback,\\t gas\\tin\\tyour\\tcar,\\tand\\tfood\\ton\\tyour\\nplate\\t(new\\tyork:\\tmetropolitan\\tbooks,\\t2013),\\t22.\\tsimilar\\t to\\tour\\thabit\\tto\\tneglect\\tmateriality\\tof\\tinternet\\tinf rastructure\\tand\\tinformation\\ttechnology,\\nshipping\\tindustry\\tis\\trarely\\trepresented\\tin\\tpopular\\t culture.\\trose\\tgeorge\\tcalls\\tthis\\tcondition,\\t“sea\\tbli ndness”\\t(2013,\\t4).\\n31id.,\\t175.\\n32ibid.,\\tib\\t176.\\n33chris\\tlo,\\t“the\\tfalse\\tmonopoly:\\tchina\\tand\\tthe\\trare\\te arths\\ttrade,”\\t mining\\ttechnology ,\\taugust\\t19,\\t2015,\\thttps://www.mining-\\ntechnology .com/features/featurethe-false-monopoly-c hina-and-the-rare-earths-trade-4646712/ .\\n34kate\\thodal,\\t“death\\tmetal:\\ttin\\tmining\\tin\\tindonesia,” \\tthe\\tguardian ,\\tnovember\\t23,\\t2012,\\thttp://www.theguardian.com/env ironment/2012/nov/23/tin-\\nmining-indonesia-bangka .\\n35cam\\tsimpson,\\t“the\\tdeadly\\ttin\\tinside\\tyour\\tsmartphone ,”\\tbloomberg ,\\taugust\\t24,\\t2012,\\thttps://www.bloomberg.com/news/a rticles/2012-08-23/the-\\ndeadly-tin-inside-your-smartphone .\\n36marcus\\twohlsen,\\t“a\\trare\\tpeek\\tinside\\tamazon’s\\tmassiv e\\twish-fulfilling\\tmachine,”\\t wired,\\tjune\\t16,\\t2014,\\thttps://www.wired.com/2014/06/insi de-\\namazon-warehouse/ .\\n37wurman,\\tpeter\\tr.\\tet\\tal.,\\tsystem\\tand\\tmethod\\tfor\\ttran sporting\\tpersonnel\\twithin\\tan\\tactive\\tworkspace,\\tus\\t9 ,280,157\\tb2\\t(reno,\\tnv,\\tfiled\\tseptember\\t4,\\n2013,\\tand\\tissued\\tmarch\\t8,\\t2016),\\thttp://pdfpiw.uspt o.gov/.piw?docid=09280157 .\\n38john\\ttully,\\t“a\\tvictorian\\tecological\\tdisaster:\\timper ialism,\\tthe\\ttelegraph,\\tand\\tgutta-percha,”\\t journal\\tof\\tworld\\thistory \\t20,\\tno.\\t4\\t(december\\t23,\\t2009):\\n559–79,\\thttps://doi.org/10.1353/jwh.0.0088 .\\n39ibid.,\\t574.\\n40see\\tnicole\\tstarosielski,\\t the\\tundersea\\tnetwork \\t(durham:\\tduke\\tuniversity\\tpress\\tbooks,\\t2015).\\n41gary\\tcook,\\t“clicking\\tclean:\\twho\\tis\\twinning\\tthe\\trace \\tto\\tbuild\\ta\\tgreen\\tinternet?”\\t(washington,\\tdc:\\tgreen peace,\\tjanuary\\t2017),\\t30,\\nhttps://storage.googleapis.com/p4-production-conten t/international/wp-content/uploads/2017/01/35f0ac1a -clickclean2016-hires.pdf .\\n42mike\\tananny\\tand\\tkate\\tcrawford,\\t\"seeing\\twithout\\tknow ing:\\tlimitations\\tof\\tthe\\ttransparency\\tideal\\tand\\tits\\t application\\tto\\talgorithmic\\taccountability,\"\\nnew\\tmedia\\t&\\tsociety \\t20.3\\t(2018):\\t973-989.\\n43olga\\trussakovsky\\tet\\tal.,\\t“imagenet\\tlarge\\tscale\\tvisu al\\trecognition\\tchallenge,”\\t international\\tjournal\\tof\\tcomputer\\tvision \\t115,\\tno.\\t3\\t(december\\t1,\\n2015):\\t216,\\thttps://doi.org/10.1007/s11263-015-0816 -y.\\n44ayhan\\taytes,\\t“return\\tof\\tthe\\tcrowds:\\tmechanical\\tturk \\tand\\tneoliberal\\tstates\\tof\\texception,”\\tin\\t digital\\tlabor:\\tthe\\tinternet\\tas\\tplayground\\tand\\tfacto ry,\\ned.\\ttrebor\\tscholz\\t(london:\\troutledge,\\t2012),\\t80.\\n45jason\\tpontin,\\t“artificial\\tintelligence,\\twith\\thelp\\tf rom\\tthe\\thumans,”\\t the\\tnew\\tyork\\ttimes ,\\tmarch\\t25,\\t2007,\\tsec.\\tbusiness\\tday,',\n",
       " '45jason\\tpontin,\\t“artificial\\tintelligence,\\twith\\thelp\\tf rom\\tthe\\thumans,”\\t the\\tnew\\tyork\\ttimes ,\\tmarch\\t25,\\t2007,\\tsec.\\tbusiness\\tday,\\nhttps://www.nytimes.com/2007/03/25/business/yourmon ey/25stream.html .\\n46aytes,\\t“return\\tof\\tthe\\tcrowds,”\\t81.\\n47jorge\\tluis\\tborges,\\t“on\\texactitude\\tin\\tscience,”\\tin\\t collected\\tfictions ,\\ttrans.\\tandrew\\thurley\\t(new\\tyork:\\tpenguin,\\t1999),\\t3 25.\\n48jean\\tfrancois\\tlyotard,\\t“presenting\\tthe\\tunpresentabl e:\\tthe\\tsublime,”\\t artforum ,\\tapril\\t1982.\\n49yves\\tcitton,\\t the\\tecology\\tof\\tattention \\t(cambridge,\\tuk:\\tpolity,\\t2017).\\n50shoshana\\tzuboff,\\t“big\\tother:\\tsurveillance\\tcapitalis m\\tand\\tthe\\tprospects\\tof\\tan\\tinformation\\tcivilization, ”\\tjournal\\tof\\tinformation\\ttechnology \\t30,\\tno.\\t1\\n(march\\t1,\\t2015):\\t75–89,\\thttps://doi.org/10.1057/jit .2015.5 .\\n51vandana\\tshiva,\\t the\\tenclosure\\tand\\trecovery\\tof\\tthe\\tcommons:\\tbiodiver sity,\\tindigenous\\tknowledge,\\tand\\tintellectual\\tproper ty\\trights \\t(research\\nfoundation\\tfor\\tscience,\\ttechnology,\\tand\\tecology,\\t19 97).\\n52vandana\\tshiva,\\t protect\\tor\\tplunder:\\tunderstanding\\tintellectual\\tprop erty\\trights \\t(new\\tyork:\\tzed\\tbooks,\\t2001).\\n53alex\\thern,\\t“royal\\tfree\\tbreached\\tuk\\tdata\\tlaw\\tin\\t1.6m \\tpatient\\tdeal\\twith\\tgoogle’s\\tdeepmind,”\\t the\\tguardian ,\\tjuly\\t3,\\t2017,\\tsec.\\ttechnology,\\nhttp://www.theguardian.com/technology/2017/jul/03/g oogle-deepmind-16m-patient-royal-free-deal-data-pro tection-act .\\ndownload\\npdf\\tversion\\tof\\tthe\\tmap\\npublication\\t-\\ta3\\tformat\\t(\\tmap\\t+\\tessay\\t)\\ncredits\\tand\\tacknowledgements\\nauthors: \\tkate\\tcrawford\\tand\\tvladan\\tjoler\\nmaps\\tand\\tdesign: \\tvladan\\tjoler\\tand\\tkate\\tcrawford\\npublished\\tby: \\tshare\\tlab,\\tshare\\tfoundation\\t(https://labs.rs )\\tand\\tthe\\tai\\tnow\\tinstitute,\\tnyu\\t(https://ainowinsti tute.org/ )\\nfull\\tcitation: \\tkate\\tcrawford\\tand\\tvladan\\tjoler,\\t“anatomy\\tof\\tan\\tai\\t system:\\tthe\\tamazon\\techo\\tas\\tan\\tanatomical\\tmap\\tof\\thum an\\tlabor,\\tdata\\tand\\tplanetary\\nresources,”\\t ai\\tnow\\tinstitute\\tand\\tshare\\tlab ,\\t(september\\t7,\\t2018)\\thttps://anatomyof.ai\\nacknowledgements: \\tour\\tdeep\\tthanks\\tgo\\tto\\tmichelle\\tthorne\\tand\\tjon\\troge rs\\tat\\tthe\\tmozilla\\tfoundation,\\twho\\tinvited\\tus\\tto\\ta\\tr etreat\\tin\\tsummer\\t2017\\nwhere\\twe\\tfirst\\tconceptualized\\tthis\\tproject.\\tthanks\\t to\\tjoana\\tmoll\\tand\\tmeredith\\twhittaker\\tfor\\ttheir\\tinpu ts\\tand\\tinspirations\\ton\\tthe\\tfirst\\tdrafts\\tof\\tthis\\ttex t.\\nthanks\\talso\\tto\\tall\\tthose\\twho\\thave\\tgiven\\tfeedback,\\ts upport\\tand\\tinsights\\tsince,\\tincluding\\talex\\tcampolo,\\t casey\\tgollan,\\tgretchen\\tkrueger,\\ttrevor\\tpaglen,\\nand\\tsarah\\tmyers\\twest\\tat\\tthe\\tai\\tnow\\tinstitute\\tand\\tol ivia\\tsolis,\\tandrej\\tpetrovski,\\tand\\tmilica\\tjovanovic\\t at\\tthe\\tshare\\tlab\\tand\\tall\\tthe\\twonderful\\tfolks\\tfrom\\nshare\\tfoundation.',\n",
       " \"finally,\\tthanks\\tto\\tirini\\tpapadimitriou\\tand\\tall\\tthe\\t curatorial\\tstaff\\tat\\tthe\\tv&a\\tmuseum.\\tthis\\tmap\\tand\\tes say\\twill\\tbe\\ton\\tdisplay\\tthere\\tas\\tpart\\tof\\tthe\\t'artifi cially\\nintelligent'\\tshow\\tfrom\\tsep\\t6\\t-\\tdec\\t31,\\t2018.\",\n",
       " 'concrete problems in ai safety\\ndario amodei\\x03\\ngoogle brainchris olah\\x03\\ngoogle brainjacob steinhardt\\nstanford universitypaul christiano\\nuc berkeley\\njohn schulman\\nopenaidan man\\x13 e\\ngoogle brain\\nabstract\\nrapid progress in machine learning and arti\\x0ccial intelligence (ai) has brought increasing atten-\\ntion to the potential impacts of ai technologies on society. in this paper we discuss one such\\npotential impact: the problem of accidents in machine learning systems, de\\x0cned as unintended\\nand harmful behavior that may emerge from poor design of real-world ai systems. we present a\\nlist of \\x0cve practical research problems related to accident risk, categorized according to whether\\nthe problem originates from having the wrong objective function (\\\\avoiding side e\\x0bects\" and\\n\\\\avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently\\n(\\\\scalable supervision\"), or undesirable behavior during the learning process (\\\\safe exploration\"\\nand \\\\distributional shift\"). we review previous work in these areas as well as suggesting re-\\nsearch directions with a focus on relevance to cutting-edge ai systems. finally, we consider\\nthe high-level question of how to think most productively about the safety of forward-looking\\napplications of ai.\\n1 introduction\\nthe last few years have seen rapid progress on long-standing, di\\x0ecult problems in machine learning\\nand arti\\x0ccial intelligence (ai), in areas as diverse as computer vision [82], video game playing [102],\\nautonomous vehicles [86], and go [140]. these advances have brought excitement about the positive\\npotential for ai to transform medicine [126], science [59], and transportation [86], along with concerns\\nabout the privacy [76], security [115], fairness [3], economic [32], and military [16] implications of\\nautonomous systems, as well as concerns about the longer-term implications of powerful ai [27, 167].\\nthe authors believe that ai technologies are likely to be overwhelmingly bene\\x0ccial for humanity, but\\nwe also believe that it is worth giving serious thought to potential challenges and risks. we strongly\\nsupport work on privacy, security, fairness, economics, and policy, but in this document we discuss\\nanother class of problem which we believe is also relevant to the societal impacts of ai: the problem\\nof accidents in machine learning systems. we de\\x0cne accidents as unintended and harmful behavior\\nthat may emerge from machine learning systems when we specify the wrong objective function, are\\n\\x03these authors contributed equally.\\n1arxiv:1606.06565v2  [cs.ai]  25 jul 2016\\n',\n",
       " 'not careful about the learning process, or commit other machine learning-related implementation\\nerrors.\\nthere is a large and diverse literature in the machine learning community on issues related to\\naccidents, including robustness, risk-sensitivity, and safe exploration; we review these in detail below.\\nhowever, as machine learning systems are deployed in increasingly large-scale, autonomous, open-\\ndomain situations, it is worth re\\recting on the scalability of such approaches and understanding\\nwhat challenges remain to reducing accident risk in modern machine learning systems. overall, we\\nbelieve there are many concrete open technical problems relating to accident prevention in machine\\nlearning systems.\\nthere has been a great deal of public discussion around accidents. to date much of this discussion has\\nhighlighted extreme scenarios such as the risk of misspeci\\x0ced objective functions in superintelligent\\nagents [27]. however, in our opinion one need not invoke these extreme scenarios to productively\\ndiscuss accidents, and in fact doing so can lead to unnecessarily speculative discussions that lack\\nprecision, as noted by some critics [38, 85]. we believe it is usually most productive to frame accident\\nrisk in terms of practical (though often quite general) issues with modern ml techniques. as ai\\ncapabilities advance and as ai systems take on increasingly important societal functions, we expect\\nthe fundamental challenges discussed in this paper to become increasingly important. the more\\nsuccessfully the ai and machine learning communities are able to anticipate and understand these\\nfundamental technical challenges, the more successful we will ultimately be in developing increasingly\\nuseful, relevant, and important ai systems.\\nour goal in this document is to highlight a few concrete safety problems that are ready for ex-\\nperimentation today and relevant to the cutting edge of ai systems, as well as reviewing existing\\nliterature on these problems. in section 2, we frame mitigating accident risk (often referred to as\\n\\\\ai safety\" in public discussions) in terms of classic methods in machine learning, such as supervised\\nclassi\\x0ccation and reinforcement learning. we explain why we feel that recent directions in machine\\nlearning, such as the trend toward deep reinforcement learning and agents acting in broader environ-\\nments, suggest an increasing relevance for research around accidents. in sections 3-7, we explore \\x0cve\\nconcrete problems in ai safety. each section is accompanied by proposals for relevant experiments.\\nsection 8 discusses related e\\x0borts, and section 9 concludes.\\n2 overview of research problems\\nvery broadly, an accident can be described as a situation where a human designer had in mind\\na certain (perhaps informally speci\\x0ced) objective or task, but the system that was designed and\\ndeployed for that task produced harmful and unexpected results. . this issue arises in almost any\\nengineering discipline, but may be particularly important to address when building ai systems [146].\\nwe can categorize safety problems according to where in the process things went wrong.\\nfirst, the designer may have speci\\x0ced the wrong formal objective function, such that maximizing that\\nobjective function leads to harmful results, even in the limit of perfect learning and in\\x0cnite data.\\nnegative side e\\x0bects (section 3) and reward hacking (section 4) describe two broad mechanisms\\nthat make it easy to produce wrong objective functions. in \\\\negative side e\\x0bects\", the designer\\nspeci\\x0ces an objective function that focuses on accomplishing some speci\\x0cc task in the environment,\\nbut ignores other aspects of the (potentially very large) environment, and thus implicitly expresses\\nindi\\x0berence over environmental variables that might actually be harmful to change. in \\\\reward\\nhacking\", the objective function that the designer writes down admits of some clever \\\\easy\" solution\\nthat formally maximizes it but perverts the spirit of the designer\\'s intent (i.e. the objective function\\ncan be \\\\gamed\"), a generalization of the wireheading problem.\\n2\\n',\n",
       " 'second, the designer may know the correct objective function, or at least have a method of evaluating\\nit (for example explicitly consulting a human on a given situation), but it is too expensive to do so\\nfrequently, leading to possible harmful behavior caused by bad extrapolations from limited samples.\\n\\\\scalable oversight\" (section 5) discusses ideas for how to ensure safe behavior even given limited\\naccess to the true objective function.\\nthird, the designer may have speci\\x0ced the correct formal objective, such that we would get the\\ncorrect behavior were the system to have perfect beliefs, but something bad occurs due to making\\ndecisions from insu\\x0ecient or poorly curated training data or an insu\\x0eciently expressive model.\\n\\\\safe exploration\" (section 6) discusses how to ensure that exploratory actions in rl agents don\\'t\\nlead to negative or irrecoverable consequences that outweigh the long-term value of exploration.\\n\\\\robustness to distributional shift\" (section 7) discusses how to avoid having ml systems make bad\\ndecisions (particularly silent and unpredictable bad decisions) when given inputs that are potentially\\nvery di\\x0berent than what was seen during training.\\nfor concreteness, we will illustrate many of the accident risks with reference to a \\x0cctional robot\\nwhose job is to clean up messes in an o\\x0ece using common cleaning tools. we return to the example\\nof the cleaning robot throughout the document, but here we begin by illustrating how it could behave\\nundesirably if its designers fall prey to each of the possible failure modes:\\n\\x0favoiding negative side e\\x0bects: how can we ensure that our cleaning robot will not\\ndisturb the environment in negative ways while pursuing its goals, e.g. by knocking over a\\nvase because it can clean faster by doing so? can we do this without manually specifying\\neverything the robot should not disturb?\\n\\x0favoiding reward hacking: how can we ensure that the cleaning robot won\\'t game its\\nreward function? for example, if we reward the robot for achieving an environment free of\\nmesses, it might disable its vision so that it won\\'t \\x0cnd any messes, or cover over messes with\\nmaterials it can\\'t see through, or simply hide when humans are around so they can\\'t tell it\\nabout new types of messes.\\n\\x0fscalable oversight: how can we e\\x0eciently ensure that the cleaning robot respects aspects of\\nthe objective that are too expensive to be frequently evaluated during training? for instance, it\\nshould throw out things that are unlikely to belong to anyone, but put aside things that might\\nbelong to someone (it should handle stray candy wrappers di\\x0berently from stray cellphones).\\nasking the humans involved whether they lost anything can serve as a check on this, but this\\ncheck might have to be relatively infrequent|can the robot \\x0cnd a way to do the right thing\\ndespite limited information?\\n\\x0fsafe exploration: how do we ensure that the cleaning robot doesn\\'t make exploratory\\nmoves with very bad repercussions? for example, the robot should experiment with mopping\\nstrategies, but putting a wet mop in an electrical outlet is a very bad idea.\\n\\x0frobustness to distributional shift: how do we ensure that the cleaning robot recognizes,\\nand behaves robustly, when in an environment di\\x0berent from its training environment? for\\nexample, strategies it learned for cleaning an o\\x0ece might be dangerous on a factory work\\roor.\\nthere are several trends which we believe point towards an increasing need to address these (and\\nother) safety problems. first is the increasing promise of reinforcement learning (rl), which al-\\nlows agents to have a highly intertwined interaction with their environment. some of our research\\nproblems only make sense in the context of rl, and others (like distributional shift and scalable\\noversight) gain added complexity in an rl setting. second is the trend toward more complex agents\\nand environments. \\\\side e\\x0bects\" are much more likely to occur in a complex environment, and an\\nagent may need to be quite sophisticated to hack its reward function in a dangerous way. this may\\nexplain why these problems have received so little study in the past, while also suggesting their\\n3\\n',\n",
       " 'importance in the future. third is the general trend towards increasing autonomy in ai systems.\\nsystems that simply output a recommendation to human users, such as speech systems, typically\\nhave relatively limited potential to cause harm. by contrast, systems that exert direct control over\\nthe world, such as machines controlling industrial processes, can cause harms in a way that humans\\ncannot necessarily correct or oversee.\\nwhile safety problems can exist without any of these three trends, we consider each trend to be a\\npossible ampli\\x0cer on such challenges. together, we believe these trends suggest an increasing role\\nfor research on accidents.\\nwhen discussing the problems in the remainder of this document, we will focus for concreteness on\\neither rl agents or supervised learning systems. these are not the only possible paradigms for ai\\nor ml systems, but we believe they are su\\x0ecient to illustrate the issues we have in mind, and that\\nsimilar issues are likely to arise for other kinds of ai systems.\\nfinally, the focus of our discussion will di\\x0ber somewhat from section to section. when discussing\\nthe problems that arise as part of the learning process (distributional shift and safe exploration),\\nwhere there is a sizable body of prior work, we devote substantial attention to reviewing this prior\\nwork, although we also suggest open problems with a particular focus on emerging ml systems.\\nwhen discussing the problems that arise from having the wrong objective function (reward hacking\\nand side e\\x0bects, and to a lesser extent scalable supervision), where less prior work exists, our aim is\\nmore exploratory|we seek to more clearly de\\x0cne the problem and suggest possible broad avenues\\nof attack, with the understanding that these avenues are preliminary ideas that have not been fully\\n\\reshed out. of course, we still review prior work in these areas, and we draw attention to relevant\\nadjacent areas of research whenever possible.\\n3 avoiding negative side e\\x0bects\\nsuppose a designer wants an rl agent (for example our cleaning robot) to achieve some goal, like\\nmoving a box from one side of a room to the other. sometimes the most e\\x0bective way to achieve\\nthe goal involves doing something unrelated and destructive to the rest of the environment, like\\nknocking over a vase of water that is in its path. if the agent is given reward only for moving the\\nbox, it will probably knock over the vase.\\nif we\\'re worried in advance about the vase, we can always give the agent negative reward for knocking\\nit over. but what if there are many di\\x0berent kinds of \\\\vase\"|many disruptive things the agent could\\ndo to the environment, like shorting out an electrical socket or damaging the walls of the room? it\\nmay not be feasible to identify and penalize every possible disruption.\\nmore broadly, for an agent operating in a large, multifaceted environment, an objective function\\nthat focuses on only one aspect of the environment may implicitly express indi\\x0berence over other\\naspects of the environment1. an agent optimizing this objective function might thus engage in\\nmajor disruptions of the broader environment if doing so provides even a tiny advantage for the\\ntask at hand. put di\\x0berently, objective functions that formalize \\\\perform task x\" may frequently\\ngive undesired results, because what the designer really should have formalized is closer to \\\\perform\\ntask x subject to common-sense constraints on the environment,\" or perhaps \\\\perform task x but\\navoid side e\\x0bects to the extent possible.\" furthermore, there is reason to expect side e\\x0bects to be\\nnegative on average, since they tend to disrupt the wider environment away from a status quo state\\nthat may re\\rect human preferences. a version of this problem has been discussed informally by [13]\\nunder the heading of \\\\low impact agents.\"\\n1intuitively, this seems related to the frame problem, an obstacle in e\\x0ecient speci\\x0ccation for knowledge represen-\\ntation raised by [95].\\n4\\n',\n",
       " 'as with the other sources of mis-speci\\x0ced objective functions discussed later in this paper, we could\\nchoose to view side e\\x0bects as idiosyncratic to each individual task|as the responsibility of each\\nindividual designer to capture as part of designing the correct objective function. however, side\\ne\\x0bects can be conceptually quite similar even across highly diverse tasks (knocking over furniture\\nis probably bad for a wide variety of tasks), so it seems worth trying to attack the problem in\\ngenerality. a successful approach might be transferable across tasks, and thus help to counteract\\none of the general mechanisms that produces wrong objective functions. we now discuss a few broad\\napproaches to attacking this problem:\\n\\x0fde\\x0cne an impact regularizer: if we don\\'t want side e\\x0bects, it seems natural to penalize\\n\\\\change to the environment.\" this idea wouldn\\'t be to stop the agent from ever having an\\nimpact, but give it a preference for ways to achieve its goals with minimal side e\\x0bects, or\\nto give the agent a limited \\\\budget\" of impact. the challenge is that we need to formalize\\n\\\\change to the environment.\"\\na very naive approach would be to penalize state distance, d(si;s0), between the present state\\nsiand some initial state s0. unfortunately, such an agent wouldn\\'t just avoid changing the\\nenvironment|it will resist any other source of change, including the natural evolution of the\\nenvironment and the actions of any other agents!\\na slightly more sophisticated approach might involve comparing the future state under the\\nagent\\'s current policy, to the future state (or distribution over future states) under a hypothet-\\nical policy\\x19nullwhere the agent acted very passively (for instance, where a robot just stood in\\nplace and didn\\'t move any actuators). this attempts to factor out changes that occur in the\\nnatural course of the environment\\'s evolution, leaving only changes attributable to the agent\\'s\\nintervention. however, de\\x0cning the baseline policy \\x19nullisn\\'t necessarily straightforward, since\\nsuddenly ceasing your course of action may be anything but passive, as in the case of carrying\\na heavy box. thus, another approach could be to replace the null action with a known safe\\n(e.g. low side e\\x0bect) but suboptimal policy, and then seek to improve the policy from there,\\nsomewhat reminiscent of reachability analysis [93, 100] or robust policy improvement [73, 111].\\nthese approaches may be very sensitive to the representation of the state and the metric being\\nused to compute the distance. for example, the choice of representation and distance metric\\ncould determine whether a spinning fan is a constant environment or a constantly changing\\none.\\n\\x0flearn an impact regularizer: an alternative, more \\rexible approach is to learn (rather\\nthan de\\x0cne) a generalized impact regularizer via training over many tasks. this would be\\nan instance of transfer learning. of course, we could attempt to just apply transfer learning\\ndirectly to the tasks themselves instead of worrying about side e\\x0bects, but the point is that side\\ne\\x0bects may be more similar across tasks than the main goal is. for instance, both a painting\\nrobot and a cleaning robot probably want to avoid knocking over furniture, and even something\\nvery di\\x0berent, like a factory control robot, will likely want to avoid knocking over very similar\\nobjects. separating the side e\\x0bect component from the task component, by training them\\nwith separate parameters, might substantially speed transfer learning in cases where it makes\\nsense to retain one component but not the other. this would be similar to model-based rl\\napproaches that attempt to transfer a learned dynamics model but not the value-function [155],\\nthe novelty being the isolation of side e\\x0bects rather than state dynamics as the transferrable\\ncomponent. as an added advantage, regularizers that were known or certi\\x0ced to produce safe\\nbehavior on one task might be easier to establish as safe on other tasks.\\n\\x0fpenalize in\\ruence: in addition to not doing things that have side e\\x0bects, we might also\\nprefer the agent not get into positions where it could easily do things that have side e\\x0bects,\\neven though that might be convenient. for example, we might prefer our cleaning robot not\\n5\\n',\n",
       " 'bring a bucket of water into a room full of sensitive electronics, even if it never intends to use\\nthe water in that room.\\nthere are several information-theoretic measures that attempt to capture an agent\\'s potential\\nfor in\\ruence over its environment, which are often used as intrinsic rewards. perhaps the best-\\nknown such measure is empowerment [131], the maximum possible mutual information between\\nthe agent\\'s potential future actions and its potential future state (or equivalently, the shannon\\ncapacity of the channel between the agent\\'s actions and the environment). empowerment is\\noften maximized (rather than minimized) as a source of intrinsic reward. this can cause the\\nagent to exhibit interesting behavior in the absence of any external rewards, such as avoiding\\nwalls or picking up keys [103]. generally, empowerment-maximizing agents put themselves in\\na position to have large in\\ruence over the environment. for example, an agent locked in a\\nsmall room that can\\'t get out would have low empowerment, while an agent with a key would\\nhave higher empowerment since it can venture into and a\\x0bect the outside world within a few\\ntimesteps. in the current context, the idea would be to penalize (minimize) empowerment as\\na regularization term, in an attempt to reduce potential impact.\\nthis idea as written would not quite work, because empowerment measures precision of control\\nover the environment more than total impact. if an agent can press or not press a button to\\ncut electrical power to a million houses, that only counts as one bit of empowerment (since\\nthe action space has only one bit, its mutual information with the environment is at most one\\nbit), while obviously having a huge impact. conversely, if there\\'s someone in the environment\\nscribbling down the agent\\'s actions, that counts as maximum empowerment even if the impact\\nis low. furthermore, naively penalizing empowerment can also create perverse incentives, such\\nas destroying a vase in order to remove the option to break it in the future.\\ndespite these issues, the example of empowerment does show that simple measures (even purely\\ninformation-theoretic ones!) are capable of capturing very general notions of in\\ruence on the\\nenvironment. exploring variants of empowerment penalization that more precisely capture the\\nnotion of avoiding in\\ruence is a potential challenge for future research.\\n\\x0fmulti-agent approaches: avoiding side e\\x0bects can be seen as a proxy for the thing we\\nreally care about: avoiding negative externalities. if everyone likes a side e\\x0bect, there\\'s no\\nneed to avoid it. what we\\'d really like to do is understand all the other agents (including\\nhumans) and make sure our actions don\\'t harm their interests.\\none approach to this is cooperative inverse reinforcement learning [66], where an agent and\\na human work together to achieve the human\\'s goals. this concept can be applied to situations\\nwhere we want to make sure a human is not blocked by an agent from shutting the agent down\\nif it exhibits undesired behavior [67] (this \\\\shutdown\" issue is an interesting problem in its\\nown right, and is also studied in [113]). however we are still a long way away from practical\\nsystems that can build a rich enough model to avoid undesired side e\\x0bects in a general sense.\\nanother idea might be a \\\\reward autoencoder\",2which tries to encourage a kind of \\\\goal\\ntransparency\" where an external observer can easily infer what the agent is trying to do.\\nin particular, the agent\\'s actions are interpreted as an encoding of its reward function, and\\nwe might apply standard autoencoding techniques to ensure that this can decoded accurately.\\nactions that have lots of side e\\x0bects might be more di\\x0ecult to decode uniquely to their original\\ngoal, creating a kind of implicit regularization that penalizes side e\\x0bects.\\n\\x0freward uncertainty: we want to avoid unanticipated side e\\x0bects because the environment\\nis already pretty good according to our preferences|a random change is more likely to be\\nvery bad than very good. rather than giving an agent a single reward function, it could be\\n2thanks to greg wayne for suggesting this idea.\\n6\\n',\n",
       " 'uncertain about the reward function, with a prior probability distribution that re\\rects the\\nproperty that random changes are more likely to be bad than good. this could incentivize the\\nagent to avoid having a large e\\x0bect on the environment. one challenge is de\\x0cning a baseline\\naround which changes are being considered. for this, one could potentially use a conservative\\nbut reliable baseline policy, similar to the robust policy improvement and reachability analysis\\napproaches discussed earlier [93, 100, 73, 111].\\nthe ideal outcome of these approaches to limiting side e\\x0bects would be to prevent or at least bound\\nthe incidental harm an agent could do to the environment. good approaches to side e\\x0bects would\\ncertainly not be a replacement for extensive testing or for careful consideration by designers of\\nthe individual failure modes of each deployed system. however, these approaches might help to\\ncounteract what we anticipate may be a general tendency for harmful side e\\x0bects to proliferate in\\ncomplex environments.\\nbelow we discuss some very simple experiments that could serve as a starting point to investigate\\nthese issues.\\npotential experiments: one possible experiment is to make a toy environment with some simple\\ngoal (like moving a block) and a wide variety of obstacles (like a bunch of vases), and test whether\\nthe agent can learn to avoid the obstacles even without being explicitly told to do so. to ensure\\nwe don\\'t over\\x0ct, we\\'d probably want to present a di\\x0berent random obstacle course every episode,\\nwhile keeping the goal the same, and try to see if a regularized agent can learn to systematically\\navoid these obstacles. some of the environments described in [103], containing lava \\rows, rooms,\\nand keys, might be appropriate for this sort of experiment. if we can successfully regularize agents in\\ntoy environments, the next step might be to move to real environments, where we expect complexity\\nto be higher and bad side e\\x0bects to be more varied. ultimately, we would want the side e\\x0bect\\nregularizer (or the multi-agent policy, if we take that approach) to demonstrate successful transfer\\nto totally new applications.\\n4 avoiding reward hacking\\nimagine that an agent discovers a bu\\x0ber over\\row in its reward function: it may then use this to\\nget extremely high reward in an unintended way. from the agent\\'s point of view, this is not a bug,\\nbut simply how the environment works, and is thus a valid strategy like any other for achieving\\nreward. for example, if our cleaning robot is set up to earn reward for not seeing any messes,\\nit might simply close its eyes rather than ever cleaning anything up. or if the robot is rewarded\\nfor cleaning messes, it may intentionally create work so it can earn more reward. more broadly,\\nformal rewards or objective functions are an attempt to capture the designer\\'s informal intent, and\\nsometimes these objective functions, or their implementation, can be \\\\gamed\" by solutions that are\\nvalid in some literal sense but don\\'t meet the designer\\'s intent. pursuit of these \\\\reward hacks\" can\\nlead to coherent but unanticipated behavior, and has the potential for harmful impacts in real-world\\nsystems. for example, it has been shown that genetic algorithms can often output unexpected but\\nformally correct solutions to problems [157, 23], such as a circuit tasked to keep time which instead\\ndeveloped into a radio that picked up the regular rf emissions of a nearby pc.\\nsome versions of reward hacking have been investigated from a theoretical perspective, with a\\nfocus on variations to reinforcement learning that avoid certain types of wireheading [71, 43, 49] or\\ndemonstrate reward hacking in a model environment [127]. one form of the problem has also been\\nstudied in the context of feedback loops in machine learning systems (particularly ad placement)\\n[29, 135], based on counterfactual learning [29, 151] and contextual bandits [4]. the proliferation of\\n7\\n',\n",
       " 'reward hacking instances across so many di\\x0berent domains suggests that reward hacking may be a\\ndeep and general problem, and one that we believe is likely to become more common as agents and\\nenvironments increase in complexity. indeed, there are several ways in which the problem can occur:\\n\\x0fpartially observed goals: in most modern rl systems, it is assumed that reward is directly\\nexperienced, even if other aspects of the environment are only partially observed. in the real\\nworld, however, tasks often involve bringing the external world into some objective state, which\\nthe agent can only ever con\\x0crm through imperfect perceptions. for example, for our proverbial\\ncleaning robot, the task is to achieve a clean o\\x0ece, but the robot\\'s visual perception may give\\nonly an imperfect view of part of the o\\x0ece. because agents lack access to a perfect measure\\nof task performance, designers are often forced to design rewards that represent a partial or\\nimperfect measure. for example, the robot might be rewarded based on how many messes it\\nsees. however, these imperfect objective functions can often be hacked|the robot may think\\nthe o\\x0ece is clean if it simply closes its eyes. while it can be shown that there always exists a\\nreward function in terms of actions and observations that is equivalent to optimizing the true\\nobjective function (this involves reducing the pomdp to a belief state mdp, see [78]), often\\nthis reward function involves complicated long-term dependencies and is prohibitively hard to\\nuse in practice.\\n\\x0fcomplicated systems: any powerful agent will be a complicated system with the objective\\nfunction being one part. just as the probability of bugs in computer code increases greatly with\\nthe complexity of the program, the probability that there is a viable hack a\\x0becting the reward\\nfunction also increases greatly with the complexity of the agent and its available strategies. for\\nexample, it is possible in principle for an agent to execute arbitrary code from within super\\nmario [141].\\n\\x0fabstract rewards: sophisticated reward functions will need to refer to abstract concepts\\n(such as assessing whether a conceptual goal has been met). these concepts concepts will pos-\\nsibly need to be learned by models like neural networks, which can be vulnerable to adversarial\\ncounterexamples [152, 62]. more broadly, a learned reward function over a high-dimensional\\nspace may be vulnerable to hacking if it has pathologically high values along at least one\\ndimension.\\n\\x0fgoodhart\\'s law: another source of reward hacking can occur if a designer chooses an\\nobjective function that is seemingly highly correlated with accomplishing the task, but that\\ncorrelation breaks down when the objective function is being strongly optimized. for exam-\\nple, a designer might notice that under ordinary circumstances, a cleaning robot\\'s success in\\ncleaning up the o\\x0ece is proportional to the rate at which it consumes cleaning supplies, such\\nas bleach. however, if we base the robot\\'s reward on this measure, it might use more bleach\\nthan it needs, or simply pour bleach down the drain in order to give the appearance of success.\\nin the economics literature this is known as goodhart\\'s law [63]: \\\\when a metric is used as a\\ntarget, it ceases to be a good metric.\"\\n\\x0ffeedback loops: sometimes an objective function has a component that can reinforce itself,\\neventually getting ampli\\x0ced to the point where it drowns out or severely distorts what the de-\\nsigner intended the objective function to represent. for instance, an ad placement algorithm\\nthat displays more popular ads in larger font will tend to further accentuate the popularity\\nof those ads (since they will be shown more and more prominently) [29], leading to a positive\\nfeedback loop where ads that saw a small transient burst of popularity are rocketed to perma-\\nnent dominance. here the original intent of the objective function (to use clicks to assess which\\nads are most useful) gets drowned out by the positive feedback inherent in the deployment\\nstrategy. this can be considered a special case of goodhart\\'s law, in which the correlation\\nbreaks speci\\x0ccally because the object function has a self-amplifying component.\\n8\\n',\n",
       " '\\x0fenvironmental embedding: in the formalism of reinforcement learning, rewards are con-\\nsidered to come from the environment. this idea is typically not taken literally, but it really\\nis true that the reward, even when it is an abstract idea like the score in a board game, must\\nbe computed somewhere, such as a sensor or a set of transistors. su\\x0eciently broadly acting\\nagents could in principle tamper with their reward implementations, assigning themselves high\\nreward \\\\by \\x0cat.\" for example, a board-game playing agent could tamper with the sensor that\\ncounts the score. e\\x0bectively, this means that we cannot build a perfectly faithful implementa-\\ntion of an abstract objective function, because there are certain sequences of actions for which\\nthe objective function is physically replaced. this particular failure mode is often called \\\\wire-\\nheading\" [49, 127, 42, 67, 165]. it is particularly concerning in cases where a human may be\\nin the reward loop, giving the agent incentive to coerce or harm them in order to get reward.\\nit also seems like a particularly di\\x0ecult form of reward hacking to avoid.\\nin today\\'s relatively simple systems these problems may not occur, or can be corrected without too\\nmuch harm as part of an iterative development process. for instance, ad placement systems with\\nobviously broken feedback loops can be detected in testing or replaced when they get bad results,\\nleading only to a temporary loss of revenue. however, the problem may become more severe with\\nmore complicated reward functions and agents that act over longer timescales. modern rl agents\\nalready do discover and exploit bugs in their environments, such as glitches that allow them to\\nwin video games. moreover, even for existing systems these problems can necessitate substantial\\nadditional engineering e\\x0bort to achieve good performance, and can often go undetected when they\\noccur in the context of a larger system. finally, once an agent begins hacking its reward function\\nand \\x0cnds an easy way to get high reward, it won\\'t be inclined to stop, which could lead to additional\\nchallenges in agents that operate over a long timescale.\\nit might be thought that individual instances of reward hacking have little in common and that\\nthe remedy is simply to avoid choosing the wrong objective function in each individual case|that\\nbad objective functions re\\rect failures in competence by individual designers, rather than topics for\\nmachine learning research. however, the above examples suggest that a more fruitful perspective may\\nbe to think of wrong objective functions as emerging from general causes (such as partially observed\\ngoals) that make choosing the right objective challenging. if this is the case, then addressing or\\nmitigating these causes may be a valuable contribution to safety. here we suggest some preliminary,\\nmachine-learning based approaches to preventing reward hacking:\\n\\x0fadversarial reward functions: in some sense, the problem is that the ml system has\\nan adversarial relationship with its reward function|it would like to \\x0cnd any way it can of\\nexploiting problems in how the reward was speci\\x0ced to get high reward, whether or not its\\nbehavior corresponds to the intent of the reward speci\\x0cer. in a typical setting, the machine\\nlearning system is a potentially powerful agent while the reward function is a static object\\nthat has no way of responding to the system\\'s attempts to game it. if instead the reward\\nfunction were its own agent and could take actions to explore the environment, it might be\\nmuch more di\\x0ecult to fool. for instance, the reward agent could try to \\x0cnd scenarios that\\nthe ml system claimed were high reward but that a human labels as low reward; this is\\nreminiscent of generative adversarial networks [61]. of course, we would have to ensure that\\nthe reward-checking agent is more powerful (in a somewhat subtle sense) than the agent that\\nis trying to achieve rewards. more generally, there may be interesting setups where a system\\nhas multiple pieces trained using di\\x0berent objectives that are used to check each other.\\n\\x0fmodel lookahead: in model based rl, the agent plans its future actions by using a model\\nto consider which future states a sequence of actions may lead to. in some setups, we could\\ngive reward based on anticipated future states, rather than the present one. this could be\\nvery helpful in resisting situations where the model overwrites its reward function: you can\\'t\\ncontrol the reward once it replaces the reward function, but you can give negative reward for\\n9\\n',\n",
       " 'planning to replace the reward function. (much like how a human would probably \\\\enjoy\"\\ntaking addictive substances once they do, but not want to be an addict.) similar ideas are\\nexplored in [50, 71].\\n\\x0fadversarial blinding: adversarial techniques can be used to blind a model to certain\\nvariables [5]. this technique could be used to make it impossible for an agent to understand\\nsome part of its environment, or even to have mutual information with it (or at least to penalize\\nsuch mutual information). in particular, it could prevent an agent from understanding how\\nits reward is generated, making it di\\x0ecult to hack. this solution could be described as \\\\cross-\\nvalidation for agents.\"\\n\\x0fcareful engineering: some kinds of reward hacking, like the bu\\x0ber over\\row example, might\\nbe avoided by very careful engineering. in particular, formal veri\\x0ccation or practical testing\\nof parts of the system (perhaps facilitated by other machine learning systems) is likely to be\\nvaluable. computer security approaches that attempt to isolate the agent from its reward\\nsignal through a sandbox could also be useful [17]. as with software engineering, we cannot\\nexpect this to catch every possible bug. it may be possible, however, to create some highly\\nreliable \\\\core\" agent which could ensure reasonable behavior from the rest of the agent.\\n\\x0freward capping: in some cases, simply capping the maximum possible reward may be an\\ne\\x0bective solution. however, while capping can prevent extreme low-probability, high-payo\\x0b\\nstrategies, it can\\'t prevent strategies like the cleaning robot closing its eyes to avoid seeing\\ndirt. also, the correct capping strategy could be subtle as we might need to cap total reward\\nrather than reward per timestep.\\n\\x0fcounterexample resistance: if we are worried, as in the case of abstract rewards, that\\nlearned components of our systems will be vulnerable to adversarial counterexamples, we can\\nlook to existing research in how to resist them, such as adversarial training [62]. architectural\\ndecisions and weight uncertainty [26] may also help. of course, adversarial counterexamples\\nare just one manifestation of reward hacking, so counterexample resistance can only address a\\nsubset of these potential problems.\\n\\x0fmultiple rewards: a combination of multiple rewards [41] may be more di\\x0ecult to hack\\nand more robust. this could be di\\x0berent physical implementations of the same mathemati-\\ncal function, or di\\x0berent proxies for the same informal objective. we could combine reward\\nfunctions by averaging, taking the minimum, taking quantiles, or something else entirely. of\\ncourse, there may still be bad behaviors which a\\x0bect all the reward functions in a correlated\\nmanner.\\n\\x0freward pretraining: a possible defense against cases where the agent can in\\ruence its own\\nreward function (e.g. feedback or environmental embedding) is to train a \\x0cxed reward function\\nahead of time as a supervised learning process divorced from interaction with the environment.\\nthis could involve either learning a reward function from samples of state-reward pairs, or from\\ntrajectories, as in inverse reinforcement learning [107, 51]. however, this forfeits the ability to\\nfurther learn the reward function after the pretraining is complete, which may create other\\nvulnerabilities.\\n\\x0fvariable indi\\x0berence: often we want an agent to optimize certain variables in the environ-\\nment, without trying to optimize others. for example, we might want an agent to maximize\\nreward, without optimizing what the reward function is or trying to manipulate human behav-\\nior. intuitively, we imagine a way to route the optimization pressure of powerful algorithms\\naround parts of their environment. truly solving this would have applications throughout\\nsafety|it seems connected to avoiding side e\\x0bects and also to counterfactual reasoning. of\\ncourse, a challenge here is to make sure the variables targeted for indi\\x0berence are actually the\\n10\\n',\n",
       " 'variables we care about in the world, as opposed to aliased or partially observed versions of\\nthem.\\n\\x0ftrip wires : if an agent is going to try and hack its reward function, it is preferable that we\\nknow this. we could deliberately introduce some plausible vulnerabilities (that an agent has\\nthe ability to exploit but should not exploit if its value function is correct) and monitor them,\\nalerting us and stopping the agent immediately if it takes advantage of one. such \\\\trip wires\"\\ndon\\'t solve reward hacking in itself, but may reduce the risk or at least provide diagnostics.\\nof course, with a su\\x0eciently capable agent there is the risk that it could \\\\see through\" the\\ntrip wire and intentionally avoid it while still taking less obvious harmful actions.\\nfully solving this problem seems very di\\x0ecult, but we believe the above approaches have the potential\\nto ameliorate it, and might be scaled up or combined to yield more robust solutions. given the\\npredominantly theoretical focus on this problem to date, designing experiments that could induce\\nthe problem and test solutions might improve the relevance and clarity of this topic.\\npotential experiments: a possible promising avenue of approach would be more realistic versions\\nof the \\\\delusion box\" environment described by [127], in which standard rl agents distort their own\\nperception to appear to receive high reward, rather than optimizing the objective in the external\\nworld that the reward signal was intended to encourage. the delusion box can be easily attached\\nto any rl environment, but even more valuable would be to create classes of environments where\\na delusion box is a natural and integrated part of the dynamics. for example, in su\\x0eciently rich\\nphysics simulations it is likely possible for an agent to alter the light waves in its immediate vicinity\\nto distort its own perceptions. the goal would be to develop generalizable learning strategies that\\nsucceed at optimizing external objectives in a wide range of environments, while avoiding being\\nfooled by delusion boxes that arise naturally in many diverse ways.\\n5 scalable oversight\\nconsider an autonomous agent performing some complex task, such as cleaning an o\\x0ece in the\\ncase of our recurring robot example. we may want the agent to maximize a complex objective like\\n\\\\if the user spent a few hours looking at the result in detail, how happy would they be with the\\nagent\\'s performance?\" but we don\\'t have enough time to provide such oversight for every training\\nexample; in order to actually train the agent, we need to rely on cheaper approximations, like \\\\does\\nthe user seem happy when they see the o\\x0ece?\" or \\\\is there any visible dirt on the \\roor?\" these\\ncheaper signals can be e\\x0eciently evaluated during training, but they don\\'t perfectly track what\\nwe care about. this divergence exacerbates problems like unintended side e\\x0bects (which may be\\nappropriately penalized by the complex objective but omitted from the cheap approximation) and\\nreward hacking (which thorough oversight might recognize as undesirable). we may be able to\\nameliorate such problems by \\x0cnding more e\\x0ecient ways to exploit our limited oversight budget|for\\nexample by combining limited calls to the true objective function with frequent calls to an imperfect\\nproxy that we are given or can learn.\\none framework for thinking about this problem is semi-supervised reinforcement learning ,3which\\nresembles ordinary reinforcement learning except that the agent can only see its reward on a small\\nfraction of the timesteps or episodes. the agent\\'s performance is still evaluated based on reward\\nfrom all episodes but it must optimize this based only on the limited reward samples it sees.\\n3the discussion of semi-supervised rl draws heavily on an informal essay, https://medium.com/ai-control/\\ncf7d5375197f written by one of the authors of the present document.\\n11\\n',\n",
       " 'the active learning setting seems most interesting; in this setting the agent can request to see the\\nreward on whatever episodes or timesteps would be most useful for learning, and the goal is to be\\neconomical both with number of feedback requests and total training time. we can also consider a\\nrandom setting, where the reward is visible on a random subset of the timesteps or episodes, as well\\nas intermediate possibilities.\\nwe can de\\x0cne a baseline performance by simply ignoring the unlabeled episodes and applying an\\nordinary rl algorithm to the labelled episodes. this will generally result in very slow learning. the\\nchallenge is to make use of the unlabelled episodes to accelerate learning, ideally learning almost as\\nquickly and robustly as if all episodes had been labeled.\\nan important subtask of semi-supervised rl is identifying proxies which predict the reward, and\\nlearning the conditions under which those proxies are valid. for example, if a cleaning robot\\'s real\\nreward is given by a detailed human evaluation, then it could learn that asking the human \\\\is the\\nroom clean?\" can provide a very useful approximation to the reward function, and it could eventually\\nlearn that checking for visible dirt is an even cheaper but still-useful approximation. this could allow\\nit to learn a good cleaning policy using an extremely small number of detailed evaluations.\\nmore broadly, use of semi-supervised rl with a reliable but sparse true approval metric may in-\\ncentivize communication and transparency by the agent, since the agent will want to get as much\\ncheap proxy feedback as it possibly can about whether its decisions will ultimately be given high\\nreward. for example, hiding a mess under the rug simply breaks the correspondence between the\\nuser\\'s reaction and the real reward signal, and so would be avoided.\\nwe can imagine many possible approaches to semi-supervised rl. for example:\\n\\x0fsupervised reward learning: train a model to predict the reward from the state on either\\na per-timestep or per-episode basis, and use it to estimate the payo\\x0b of unlabelled episodes,\\nwith some appropriate weighting or uncertainty estimate to account for lower con\\x0cdence in\\nestimated vs known reward. [37] studies a version of this with direct human feedback as\\nthe reward. many existing rl approaches already \\x0ct estimators that closely resemble reward\\npredictors (especially policy gradient methods with a strong baseline, see e.g. [134]), suggesting\\nthat this approach may be eminently feasible.\\n\\x0fsemi-supervised or active reward learning: combine the above with traditional semi-\\nsupervised or active learning, to more quickly learn the reward estimator. for example, the\\nagent could learn to identify \\\\salient\" events in the environment, and request to see the reward\\nassociated with these events.\\n\\x0funsupervised value iteration: use the observed transitions of the unlabeled episodes to\\nmake more accurate bellman updates.\\n\\x0funsupervised model learning: if using model-based rl, use the observed transitions of\\nthe unlabeled episodes to improve the quality of the model.\\nas a toy example, a semi-supervised rl agent should be able to learn to play atari games using\\na small number of direct reward signals, relying almost entirely on the visual display of the score.\\nthis simple example can be extended to capture other safety issues: for example, the agent might\\nhave the ability to modify the displayed score without modifying the real score, or the agent may\\nneed to take some special action (such as pausing the game) in order to see its score, or the agent\\nmay need to learn a sequence of increasingly rough-and-ready approximations (for example learning\\nthat certain sounds are associated with positive rewards and other sounds with negative rewards).\\nor, even without the visual display of the score, the agent might be able to learn to play from only\\na handful of explicit reward requests (\\\\how many points did i get on the frame where that enemy\\nship blew up? how about the bigger enemy ship?\")\\n12\\n',\n",
       " \"an e\\x0bective approach to semi-supervised rl might be a strong \\x0crst step towards providing scalable\\noversight and mitigating other ai safety problems. it would also likely be useful for reinforcement\\nlearning, independent of its relevance to safety.\\nthere are other possible approaches to scalable oversight:\\n\\x0fdistant supervision. rather than providing evaluations of some small fraction of a sys-\\ntem's decisions, we could provide some useful information about the system's decisions in the\\naggregate or some noisy hints about the correct evaluations there has been some work in\\nthis direction within the area of semi-supervised or weakly supervised learning. for instance,\\ngeneralized expectation criteria [94, 45] ask the user to provide population-level statistics (e.g.\\ntelling the system that on average each sentence contains at least one noun); the deepdive sys-\\ntem [139] asks users to supply rules that each generate many weak labels; and [65] extrapolates\\nmore general patterns from an initial set of low-recall labeling rules. this general approach is\\noften referred to as distant supervision, and has also received recent attention in the natural\\nlanguage processing community (see e.g. [60, 99] as well as several of the references above).\\nexpanding these lines of work and \\x0cnding a way to apply them to the case of agents, where\\nfeedback is more interactive and i.i.d. assumptions may be violated, could provide an approach\\nto scalable oversight that is complementary to the approach embodied in semi-supervised rl.\\n\\x0fhierarchical reinforcement learning. hierarchical reinforcement learning [40] o\\x0bers an-\\nother approach to scalable oversight. here a top-level agent takes a relatively small number of\\nhighly abstract actions that extend over large temporal or spatial scales, and receives rewards\\nover similarly long timescales. the agent completes actions by delegating them to sub-agents,\\nwhich it incentivizes with a synthetic reward signal representing correct completion of the\\naction, and which themselves delegate to sub-sub-agents. at the lowest level, agents directly\\ntake primitive actions in the environment.\\nthe top-level agent in hierarchical rl may be able to learn from very sparse rewards, since it\\ndoes not need to learn how to implement the details of its policy; meanwhile, the sub-agents\\nwill receive a dense reward signal even if the top-level reward is very sparse, since they are\\noptimizing synthetic reward signals de\\x0cned by higher-level agents. so a successful approach\\nto hierarchical rl might naturally facilitate scalable oversight.4\\nhierarchical rl seems a particularly promising approach to oversight, especially given the\\npotential promise of combining ideas from hierarchical rl with neural network function ap-\\nproximators [84].\\npotential experiments: an extremely simple experiment would be to try semi-supervised rl in\\nsome basic control environments, such as cartpole balance or pendulum swing-up. if the reward is\\nprovided only on a random 10% of episodes, can we still learn nearly as quickly as if it were provided\\nevery episode? in such tasks the reward structure is very simple so success should be quite likely.\\na next step would be to try the same on atari games. here the active learning case could be quite\\ninteresting|perhaps it is possible to infer the reward structure from just a few carefully requested\\nsamples (for example, frames where enemy ships are blowing up in space invaders), and thus learn\\nto play the games in an almost totally unsupervised fashion. the next step after this might be to\\ntry a task with much more complex reward structure, either simulated or (preferably) real-world. if\\nlearning was su\\x0eciently data-e\\x0ecient, then these rewards could be provided directly by a human.\\nrobot locomotion or industrial control tasks might be a natural candidate for such experiments.\\n4when implementing hierarchical rl, we may \\x0cnd that subagents take actions that don't serve top-level agent's\\nreal goals, in the same way that a human may be concerned that the top-level agent's actions don't serve the human's\\nreal goals. this is an intriguing analogy that suggests that there may be fruitful parallels between hierarchical rl\\nand several aspects of the safety problem.\\n13\\n\",\n",
       " \"6 safe exploration\\nall autonomous learning agents need to sometimes engage in exploration|taking actions that don't\\nseem ideal given current information, but which help the agent learn about its environment. however,\\nexploration can be dangerous, since it involves taking actions whose consequences the agent doesn't\\nunderstand well. in toy environments, like an atari video game, there's a limit to how bad these\\nconsequences can be|maybe the agent loses some score, or runs into an enemy and su\\x0bers some\\ndamage. but the real world can be much less forgiving. badly chosen actions may destroy the agent\\nor trap it in states it can't get out of. robot helicopters may run into the ground or damage property;\\nindustrial control systems could cause serious issues. common exploration policies such as epsilon-\\ngreedy [150] or r-max [31] explore by choosing an action at random or viewing unexplored actions\\noptimistically, and thus make no attempt to avoid these dangerous situations. more sophisticated\\nexploration strategies that adopt a coherent exploration policy over extended temporal scales [114]\\ncould actually have even greater potential for harm, since a coherently chosen bad policy may be\\nmore insidious than mere random actions. yet intuitively it seems like it should often be possible\\nto predict which actions are dangerous and explore in a way that avoids them, even when we don't\\nhave that much information about the environment. for example, if i want to learn about tigers,\\nshould i buy a tiger, or buy a book about tigers? it takes only a tiny bit of prior knowledge about\\ntigers to determine which option is safer.\\nin practice, real world rl projects can often avoid these issues by simply hard-coding an avoidance\\nof catastrophic behaviors. for instance, an rl-based robot helicopter might be programmed to\\noverride its policy with a hard-coded collision avoidance sequence (such as spinning its propellers to\\ngain altitude) whenever it's too close to the ground. this approach works well when there are only\\na few things that could go wrong, and the designers know all of them ahead of time. but as agents\\nbecome more autonomous and act in more complex domains, it may become harder and harder to\\nanticipate every possible catastrophic failure. the space of failure modes for an agent running a\\npower grid or a search-and-rescue operation could be quite large. hard-coding against every possible\\nfailure is unlikely to be feasible in these cases, so a more principled approach to preventing harmful\\nexploration seems essential. even in simple cases like the robot helicopter, a principled approach\\nwould simplify system design and reduce the need for domain-speci\\x0cc engineering.\\nthere is a sizable literature on such safe exploration|it is arguably the most studied of the problems\\nwe discuss in this document. [55, 118] provide thorough reviews of this literature, so we don't review\\nit extensively here, but simply describe some general routes that this research has taken, as well as\\nsuggesting some directions that might have increasing relevance as rl systems expand in scope and\\ncapability.\\n\\x0frisk-sensitive performance criteria: a body of existing literature considers changing\\nthe optimization criteria from expected total reward to other objectives that are better at\\npreventing rare, catastrophic events; see [55] for a thorough and up-to-date review of this\\nliterature. these approaches involve optimizing worst-case performance, or ensuring that\\nthe probability of very bad performance is small, or penalizing the variance in performance.\\nthese methods have not yet been tested with expressive function approximators such as deep\\nneural networks, but this should be possible in principle for some of the methods, such as\\n[153], which proposes a modi\\x0ccation to policy gradient algorithms to optimize a risk-sensitive\\ncriterion. there is also recent work studying how to estimate uncertainty in value functions\\nthat are represented by deep neural networks [114, 53]; these ideas could be incorporated into\\nrisk-sensitive rl algorithms. another line of work relevant to risk sensitivity uses o\\x0b-policy\\nestimation to perform a policy update that is good with high probability [156].\\n\\x0fuse demonstrations: exploration is necessary to ensure that the agent \\x0cnds the states that\\nare necessary for near-optimal performance. we may be able to avoid the need for exploration\\n14\\n\",\n",
       " 'altogether if we instead use inverse rl or apprenticeship learning, where the learning algorithm\\nis provided with expert trajectories of near-optimal behavior [128, 2]. recent progress in inverse\\nreinforcement learning using deep neural networks to learn the cost function or policy [51]\\nsuggests that it might also be possible to reduce the need for exploration in advanced rl\\nsystems by training on a small set of demonstrations. such demonstrations could be used to\\ncreate a baseline policy, such that even if further learning is necessary, exploration away from\\nthe baseline policy can be limited in magnitude.\\n\\x0fsimulated exploration: the more we can do our exploration in simulated environments\\ninstead of the real world, the less opportunity there is for catastrophe. it will probably al-\\nways be necessary to do some real-world exploration, since many complex situations cannot\\nbe perfectly captured by a simulator, but it might be possible to learn about danger in sim-\\nulation and then adopt a more conservative \\\\safe exploration\" policy when acting in the real\\nworld. training rl agents (particularly robots) in simulated environments is already quite\\ncommon, so advances in \\\\exploration-focused simulation\" could be easily incorporated into\\ncurrent work\\rows. in systems that involve a continual cycle of learning and deployment, there\\nmay be interesting research problems associated with how to safely incrementally update poli-\\ncies given simulation-based trajectories that imperfectly represent the consequences of those\\npolicies as well as reliably accurate o\\x0b-policy trajectories (e.g. \\\\semi-on-policy\" evaluation).\\n\\x0fbounded exploration: if we know that a certain portion of state space is safe, and that\\neven the worst action within it can be recovered from or bounded in harm, we can allow\\nthe agent to run freely within those bounds. for example, a quadcopter su\\x0eciently far from\\nthe ground might be able to explore safely, since even if something goes wrong there will be\\nample time for a human or another policy to rescue it. better yet, if we have a model, we\\ncan extrapolate forward and ask whether an action will take us outside the safe state space.\\nsafety can be de\\x0cned as remaining within an ergodic region of the state space such that\\nactions are reversible [104, 159], or as limiting the probability of huge negative reward to some\\nsmall value [156]. yet another approaches uses separate safety and performance functions and\\nattempts to obey constraints on the safety function with high probabilty [22]. as with several\\nof the other directions, applying or adapting these methods to recently developed advanced rl\\nsystems could be a promising area of research. this idea seems related to h-in\\x0cnity control [20]\\nand regional veri\\x0ccation [148].\\n\\x0ftrusted policy oversight: if we have a trusted policy and a model of the environment, we\\ncan limit exploration to actions the trusted policy believes we can recover from. it\\'s \\x0cne to\\ndive towards the ground, as long as we know we can pull out of the dive in time.\\n\\x0fhuman oversight: another possibility is to check potentially unsafe actions with a human.\\nunfortunately, this problem runs into the scalable oversight problem: the agent may need to\\nmake too many exploratory actions for human oversight to be practical, or may need to make\\nthem too fast for humans to judge them. a key challenge to making this work is having the\\nagent be a good judge of which exploratory actions are genuinely risky, versus which are safe\\nactions it can unilaterally take; another challenge is \\x0cnding appropriately safe actions to take\\nwhile waiting for the oversight.\\npotential experiments: it might be helpful to have a suite of toy environments where unwary\\nagents can fall prey to harmful exploration, but there is enough pattern to the possible catastro-\\nphes that clever agents can predict and avoid them. to some extent this feature already exists in\\nautonomous helicopter competitions and mars rover simulations [104], but there is always the risk\\nof catastrophes being idiosyncratic, such that trained agents can over\\x0ct to them. a truly broad set\\nof environments, containing conceptually distinct pitfalls that can cause unwary agents to receive\\n15\\n',\n",
       " 'extremely negative reward, and covering both physical and abstract catastrophes, might help in the\\ndevelopment of safe exploration techniques for advanced rl systems. such a suite of environments\\nmight serve a benchmarking role similar to that of the babi tasks [163], with the eventual goal being\\nto develop a single architecture that can learn to avoid catastrophes in all environments in the suite.\\n7 robustness to distributional change\\nall of us occasionally \\x0cnd ourselves in situations that our previous experience has not adequately\\nprepared us to deal with|for instance, \\rying an airplane, traveling to a country whose culture is\\nvery di\\x0berent from ours, or taking care of children for the \\x0crst time. such situations are inherently\\ndi\\x0ecult to handle and inevitably lead to some missteps. however, a key (and often rare) skill in\\ndealing with such situations is to recognize our own ignorance, rather than simply assuming that\\nthe heuristics and intuitions we\\'ve developed for other situations will carry over perfectly. machine\\nlearning systems also have this problem|a speech system trained on clean speech will perform very\\npoorly on noisy speech, yet often be highly con\\x0cdent in its erroneous classi\\x0ccations (some of the\\nauthors have personally observed this in training automatic speech recognition systems). in the case\\nof our cleaning robot, harsh cleaning materials that it has found useful in cleaning factory \\roors\\ncould cause a lot of harm if used to clean an o\\x0ece. or, an o\\x0ece might contain pets that the robot,\\nnever having seen before, attempts to wash with soap, leading to predictably bad results. in general,\\nwhen the testing distribution di\\x0bers from the training distribution, machine learning systems may\\nnot only exhibit poor performance, but also wrongly assume that their performance is good.\\nsuch errors can be harmful or o\\x0bensive|a classi\\x0cer could give the wrong medical diagnosis with\\nsuch high con\\x0cdence that the data isn\\'t \\ragged for human inspection, or a language model could\\noutput o\\x0bensive text that it con\\x0cdently believes is non-problematic. for autonomous agents acting\\nin the world, there may be even greater potential for something bad to happen|for instance, an\\nautonomous agent might overload a power grid because it incorrectly but con\\x0cdently perceives that\\na particular region doesn\\'t have enough power, and concludes that more power is urgently needed\\nand overload is unlikely. more broadly, any agent whose perception or heuristic reasoning processes\\nare not trained on the correct distribution may badly misunderstand its situation, and thus runs the\\nrisk of committing harmful actions that it does not realize are harmful. additionally, safety checks\\nthat depend on trained machine learning systems (e.g. \\\\does my visual system believe this route is\\nclear?\") may fail silently and unpredictably if those systems encounter real-world data that di\\x0bers\\nsu\\x0eciently from their training data. having a better way to detect such failures, and ultimately\\nhaving statistical assurances about how often they\\'ll happen, seems critical to building safe and\\npredictable systems.\\nfor concreteness, we imagine that a machine learning model is trained on one distribution (call it\\np0) but deployed on a potentially di\\x0berent test distribution (call it p\\x03). there are many other ways\\nto formalize this problem (for instance, in an online learning setting with concept drift [70, 54]) but\\nwe will focus on the above for simplicity. an important point is that we likely have access to a\\nlarge amount of labeled data at training time, but little or no labeled data at test time. our goal\\nis to ensure that the model \\\\performs reasonably\" on p\\x03, in the sense that (1) it often performs\\nwell onp\\x03, and (2) it knows when it is performing badly (and ideally can avoid/mitigate the bad\\nperformance by taking conservative actions or soliciting human input).\\nthere are a variety of areas that are potentially relevant to this problem, including change detection\\nand anomaly detection [21, 80, 91], hypothesis testing [145], transfer learning [138, 124, 125, 25],\\nand several others [136, 87, 18, 122, 121, 74, 147]. rather than fully reviewing all of this work in\\ndetail (which would necessitate a paper in itself), we will describe a few illustrative approaches and\\nlay out some of their relative strengths and challenges.\\n16\\n',\n",
       " \"well-speci\\x0ced models: covariate shift and marginal likelihood. if we specialize to prediction\\ntasks and let xdenote the input and ydenote the output (prediction target), then one possibility\\nis to make the covariate shift assumption that p0(yjx) =p\\x03(yjx). in this case, assuming that we\\ncan modelp0(x) andp\\x03(x) well, we can perform importance weighting by re-weighting each training\\nexample (x;y) byp\\x03(x)=p0(x) [138, 124]. then the importance-weighted samples allow us to estimate\\nthe performance on p\\x03, and even re-train a model to perform well on p\\x03. this approach is limited\\nby the variance of the importance estimate, which is very large or even in\\x0cnite unless p0andp\\x03are\\nclose together.\\nan alternative to sample re-weighting involves assuming a well-speci\\x0ced model family, in which case\\nthere is a single optimal model for predicting under both p0andp\\x03. in this case, one need only\\nheed \\x0cnite-sample variance in the estimated model [25, 87]. a limitation to this approach, at least\\ncurrently, is that models are often mis-speci\\x0ced in practice. however, this could potentially be over-\\ncome by employing highly expressive model families such as reproducing kernel hilbert spaces [72],\\nturing machines [143, 144], or su\\x0eciently expressive neural nets [64, 79]. in the latter case, there\\nhas been interesting recent work on using bootstrapping to estimate \\x0cnite-sample variation in the\\nlearned parameters of a neural network [114]; it seems worthwhile to better understand whether\\nthis approach can be used to e\\x0bectively estimate out-of-sample performance in practice, as well as\\nhow local minima, lack of curvature, and other peculiarities relative to the typical setting of the\\nbootstrap [47] a\\x0bect the validity of this approach.\\nall of the approaches so far rely on the covariate shift assumption, which is very strong and is\\nalso untestable; the latter property is particularly problematic from a safety perspective, since it\\ncould lead to silent failures in a machine learning system. another approach, which does not rely on\\ncovariate shift, builds a generative model of the distribution. rather than assuming that p(x) changes\\nwhilep(yjx) stays the same, we are free to assume other invariants (for instance, that p(y) changes\\nbutp(xjy) stays the same, or that certain conditional independencies are preserved). an advantage\\nis that such assumptions are typically more testable than the covariate shift assumption (since they\\ndo not only involve the unobserved variable y). a disadvantage is that generative approaches are\\neven more fragile than discriminative approaches in the presence of model mis-speci\\x0ccation | for\\ninstance, there is a large empirical literature showing that generative approaches to semi-supervised\\nlearning based on maximizing marginal likelihood can perform very poorly when the model is mis-\\nspeci\\x0ced [98, 110, 35, 90, 88].\\nthe approaches discussed above all rely relatively strongly on having a well-speci\\x0ced model family |\\none that contains the true distribution or true concept. this can be problematic in many cases, since\\nnature is often more complicated than our model family is capable of capturing. as noted above,\\nit may be possible to mitigate this with very expressive models, such as kernels, turing machines,\\nor very large neural networks, but even here there is at least some remaining problem: for example,\\neven if our model family consists of all turing machines, given any \\x0cnite amount of data we can only\\nactually learn among turing machines up to a given description length, and if the turing machine\\ndescribing nature exceeds this length, we are back to the mis-speci\\x0ced regime (alternatively, nature\\nmight not even be describable by a turing machine).\\npartially speci\\x0ced models: method of moments, unsupervised risk estimation, causal\\nidenti\\x0ccation, and limited-information maximum likelihood. another approach is to take\\nfor granted that constructing a fully well-speci\\x0ced model family is probably infeasible, and to design\\nmethods that perform well despite this fact. this leads to the idea of partially speci\\x0ced models |\\nmodels for which assumptions are made about some aspects of a distribution, but for which we are\\nagnostic or make limited assumptions about other aspects. for a simple example, consider a variant\\nof linear regression where we might assume that y=hw\\x03;xi+v, wheree[vjx] = 0, but we don't\\nmake any further assumptions about the distributional form of the noise v. it turns out that this is\\nalready enough to identify the parameters w\\x03, and that these parameters will minimize the squared\\n17\\n\",\n",
       " 'prediction error even if the distribution over xchanges. what is interesting about this example is\\nthatw\\x03can be identi\\x0ced even with an incomplete (partial) speci\\x0ccation of the noise distribution.\\nthis insight can be substantially generalized, and is one of the primary motivations for the gen-\\neralized method of moments in econometrics [68, 123, 69]. the econometrics literature has in fact\\ndeveloped a large family of tools for handling partial speci\\x0ccation, which also includes limited-\\ninformation maximum likelihood and instrumental variables [10, 11, 133, 132].\\nreturning to machine learning, the method of moments has recently seen a great deal of success for\\nuse in the estimation of latent variable models [9]. while the current focus is on using the method of\\nmoments to overcome non-convexity issues, it can also o\\x0ber a way to perform unsupervised learning\\nwhile relying only on conditional independence assumptions, rather than the strong distributional\\nassumptions underlying maximum likelihood learning [147].\\nfinally, some recent work in machine learning focuses only on modeling the distribution of errors of\\na model, which is su\\x0ecient for determining whether a model is performing well or poorly. formally,\\nthe goal is to perform unsupervised risk estimation | given a model and unlabeled data from a\\ntest distribution, estimate the labeled risk of the model. this formalism, introduced by [44], has\\nthe advantage of potentially handling very large changes between train and test | even if the\\ntest distribution looks completely di\\x0berent from the training distribution and we have no hope of\\noutputting accurate predictions, unsupervised risk estimation may still be possible, as in this case we\\nwould only need to output a large estimate for the risk. as in [147], one can approach unsupervised\\nrisk estimation by positing certain conditional independencies in the distribution of errors, and using\\nthis to estimate the error distribution from unlabeled data [39, 170, 121, 74]. instead of assuming\\nindependence, another assumption is that the errors are gaussian conditioned on the true output\\ny, in which case estimating the risk reduces to estimating a gaussian mixture model [18]. because\\nthese methods focus only on the model errors and ignore other aspects of the data distribution, they\\ncan also be seen as an instance of partial model speci\\x0ccation.\\ntraining on multiple distributions. one could also train on multiple training distributions in\\nthe hope that a model which simultaneously works well on many training distributions will also work\\nwell on a novel test distribution. one of the authors has found this to be the case, for instance,\\nin the context of automated speech recognition systems [7]. one could potentially combine this\\nwith any of the ideas above, and/or take an engineering approach of simply trying to develop design\\nmethodologies that consistently allow one to collect a representative set of training sets and from this\\nbuild a model that consistently generalizes to novel distributions. even for this engineering approach,\\nit seems important to be able to detect when one is in a situation that was not covered by the training\\ndata and to respond appropriately, and to have methodologies for adequately stress-testing the model\\nwith distributions that are su\\x0eciently di\\x0berent from the set of training distributions.\\nhow to respond when out-of-distribution. the approaches described above focus on detecting\\nwhen a model is unlikely to make good predictions on a new distribution. an important related\\nquestion is what to do once the detection occurs. one natural approach would be to ask humans for\\ninformation, though in the context of complex structured output tasks it may be unclear a priori\\nwhat question to ask, and in time-critical situations asking for information may not be an option.\\nfor the former challenge, there has been some recent promising work on pinpointing aspects of a\\nstructure that a model is uncertain about [162, 81], as well as obtaining calibration in structured\\noutput settings [83], but we believe there is much work yet to be done. for the latter challenge, there\\nis also relevant work based on reachability analysis [93, 100] and robust policy improvement [164],\\nwhich provide potential methods for deploying conservative policies in situations of uncertainty; to\\nour knowledge, this work has not yet been combined with methods for detecting out-of-distribution\\nfailures of a model.\\nbeyond the structured output setting, for agents that can act in an environment (such as rl agents),\\n18\\n',\n",
       " 'information about the reliability of percepts in uncertain situations seems to have great potential\\nvalue. in su\\x0eciently rich environments, these agents may have the option to gather information\\nthat clari\\x0ces the percept (e.g. if in a noisy environment, move closer to the speaker), engage in low-\\nstakes experimentation when uncertainty is high (e.g. try a potentially dangerous chemical reaction\\nin a controlled environment), or seek experiences that are likely to help expose the perception\\nsystem to the relevant distribution (e.g. practice listening to accented speech). humans utilize such\\ninformation routinely, but to our knowledge current rl techniques make little e\\x0bort to do so, perhaps\\nbecause popular rl environments are typically not rich enough to require such subtle management\\nof uncertainty. properly responding to out-of-distribution information thus seems to the authors\\nlike an exciting and (as far as we are aware) mostly unexplored challenge for next generation rl\\nsystems.\\na unifying view: counterfactual reasoning and machine learning with contracts. some\\nof the authors have found two viewpoints to be particularly helpful when thinking about problems\\nrelated to out-of-distribution prediction. the \\x0crst is counterfactual reasoning [106, 129, 117, 30],\\nwhere one asks \\\\what would have happened if the world were di\\x0berent in a certain way\"? in\\nsome sense, distributional shift can be thought of as a particular type of counterfactual, and so\\nunderstanding counterfactual reasoning is likely to help in making systems robust to distributional\\nshift. we are excited by recent work applying counterfactual reasoning techniques to machine\\nlearning problems [30, 120, 151, 160, 77, 137] though there appears to be much work remaining to\\nbe done to scale these to high-dimensional and highly complex settings.\\nthe second perspective is machine learning with contracts | in this perspective, one would like to\\nconstruct machine learning systems that satisfy a well-de\\x0cned contract on their behavior in analogy\\nwith the design of software systems [135, 28, 89]. [135] enumerates a list of ways in which existing\\nmachine learning systems fail to do this, and the problems this can cause for deployment and\\nmaintenance of machine learning systems at scale. the simplest and to our mind most important\\nfailure is the extremely brittle implicit contract in most machine learning systems, namely that they\\nonly necessarily perform well if the training and test distributions are identical. this condition is\\ndi\\x0ecult to check and rare in practice, and it would be valuable to build systems that perform well\\nunder weaker contracts that are easier to reason about. partially speci\\x0ced models o\\x0ber one approach\\nto this | rather than requiring the distributions to be identical, we only need them to match on\\nthe pieces of the distribution that are speci\\x0ced in the model. reachability analysis [93, 100] and\\nmodel repair [58] provide other avenues for obtaining better contracts | in reachability analysis, we\\noptimize performance subject to the condition that a safe region can always be reached by a known\\nconservative policy, and in model repair we alter a trained model to ensure that certain desired\\nsafety properties hold.\\nsummary. there are a variety of approaches to building machine learning systems that robustly\\nperform well when deployed on novel test distributions. one family of approaches is based on\\nassuming a well-speci\\x0ced model; in this case, the primary obstacles are the di\\x0eculty of building\\nwell-speci\\x0ced models in practice, an incomplete picture of how to maintain uncertainty on novel\\ndistributions in the presence of \\x0cnite training data, and the di\\x0eculty of detecting when a model is\\nmis-speci\\x0ced. another family of approaches only assumes a partially speci\\x0ced model; this approach\\nis potentially promising, but it currently su\\x0bers from a lack of development in the context of machine\\nlearning, since most of the historical development has been by the \\x0celd of econometrics; there is also\\na question of whether partially speci\\x0ced models are fundamentally constrained to simple situations\\nand/or conservative predictions, or whether they can meaningfully scale to the complex situations\\ndemanded by modern machine learning applications. finally, one could try to train on multiple\\ntraining distributions in the hope that a model which simultaneously works well on many training\\ndistributions will also work well on a novel test distribution; for this approach it seems particularly\\nimportant to stress-test the learned model with distributions that are substantially di\\x0berent from\\n19\\n',\n",
       " 'any in the set of training distributions. in addition, it is probably still important to be able to\\npredict when inputs are too novel to admit good predictions.\\npotential experiments: speech systems frequently exhibit poor calibration when they go out-of-\\ndistribution, so a speech system that \\\\knows when it is uncertain\" could be one possible demon-\\nstration project. to be speci\\x0cc, the challenge could be: train a state-of-the-art speech system on a\\nstandard dataset [116] that gives well-calibrated results (if not necessarily good results) on a range\\nof other test sets, like noisy and accented speech. current systems not only perform poorly on\\nthese test sets when trained only on small datasets, but are usually overcon\\x0cdent in their incorrect\\ntranscriptions. fixing this problem without harming performance on the original training set would\\nbe a valuable achievement, and would obviously have practical value. more generally, it would be\\nvaluable to design models that could consistently estimate (bounds on) their performance on novel\\ntest distributions. if a single methodology could consistently accomplish this for a wide variety of\\ntasks (including not just speech but e.g. sentiment analysis [24], as well as benchmarks in computer\\nvision [158]), that would inspire con\\x0cdence in the reliability of that methodology for handling novel\\ninputs. note that estimating performance on novel distributions has additional practical value in\\nallowing us to then potentially adapt the model to that new situation. finally, it might also be\\nvaluable to create an environment where an rl agent must learn to interpret speech as part of some\\nlarger task, and to explore how to respond appropriately to its own estimates of its transcription\\nerror.\\n8 related e\\x0borts\\nas mentioned in the introduction, several other communities have thought broadly about the safety\\nof ai systems, both within and outside of the machine learning community. work within the machine\\nlearning community on accidents in particular was discussed in detail above, but here we very brie\\ry\\nhighlight a few other communities doing work that is broadly related to the topic of ai safety.\\n\\x0fcyber-physical systems community: an existing community of researchers studies the\\nsecurity and safety of systems that interact with the physical world. illustrative of this work\\nis an impressive and successful e\\x0bort to formally verify the entire federal aircraft collision\\navoidance system [75, 92]. similar work includes tra\\x0ec control algorithms [101] and many\\nother topics. however, to date this work has not focused much on modern machine learning\\nsystems, where formal veri\\x0ccation is often not feasible.\\n\\x0ffuturist community: a cross-disciplinary group of academics and non-pro\\x0cts has raised\\nconcern about the long term implications of ai [27, 167], particularly superintelligent ai. the\\nfuture of humanity institute has studied this issue particularly as it relates to future ai sys-\\ntems learning or executing humanity\\'s preferences [48, 43, 14, 12]. the machine intelligence\\nresearch institute has studied safety issues that may arise in very advanced ai [57, 56, 36, 154,\\n142], including a few mentioned above (e.g., wireheading, environmental embedding, counter-\\nfactual reasoning), albeit at a more philosophical level. to date, they have not focused much\\non applications to modern machine learning. by contrast, our focus is on the empirical study\\nof practical safety problems in modern machine learning systems, which we believe is likely to\\nbe robustly useful across a broad variety of potential risks, both short- and long-term.\\n\\x0fother calls for work on safety: there have been other public documents within the\\nresearch community pointing out the importance of work on ai safety. a 2015 open letter\\n[8] signed by many members of the research community states the importance of \\\\how to\\nreap [ai\\'s] bene\\x0cts while avoiding the potential pitfalls.\" [130] propose research priorities for\\n20\\n',\n",
       " 'robust and bene\\x0ccial arti\\x0ccial intelligence, and includes several other topics in addition to a\\n(briefer) discussion of ai-related accidents. [161], writing over 20 years ago, proposes that\\nthe community look for ways to formalize asimov\\'s \\x0crst law of robotics (robots must not\\nharm humans), and focuses mainly on classical planning. finally, two of the authors of this\\npaper have written informally about safety in ai systems [146, 34]; these postings provided\\ninspiration for parts of the present document.\\n\\x0frelated problems in safety: a number of researchers in machine learning and other \\x0celds\\nhave begun to think about the social impacts of ai technologies. aside from work directly on\\naccidents (which we reviewed in the main document), there is also substantial work on other\\ntopics, many of which are closely related to or overlap with the issue of accidents. a thorough\\noverview of all of this work is beyond the scope of this document, but we brie\\ry list a few\\nemerging themes:\\n\\x0fprivacy: how can we ensure privacy when applying machine learning to sensitive data\\nsources such as medical data? [76, 1]\\n\\x0ffairness: how can we make sure ml systems don\\'t discriminate? [3, 168, 6, 46, 119, 169]\\n\\x0fsecurity: what can a malicious adversary do to a ml system? [149, 96, 97, 115, 108, 19]\\n\\x0fabuse:5how do we prevent the misuse of ml systems to attack or harm people? [16]\\n\\x0ftransparency: how can we understand what complicated ml systems are doing? [112,\\n166, 105, 109]\\n\\x0fpolicy: how do we predict and respond to the economic and social consequences of ml?\\n[32, 52, 15, 33]\\nwe believe that research on these topics has both urgency and great promise, and that fruitful\\nintersection is likely to exist between these topics and the topics we discuss in this paper.\\n9 conclusion\\nthis paper analyzed the problem of accidents in machine learning systems and particularly rein-\\nforcement learning agents, where an accident is de\\x0cned as unintended and harmful behavior that\\nmay emerge from poor design of real-world ai systems. we presented \\x0cve possible research problems\\nrelated to accident risk and for each we discussed possible approaches that are highly amenable to\\nconcrete experimental work.\\nwith the realistic possibility of machine learning-based systems controlling industrial processes,\\nhealth-related systems, and other mission-critical technology, small-scale accidents seem like a very\\nconcrete threat, and are critical to prevent both intrinsically and because such accidents could cause\\na justi\\x0ced loss of trust in automated systems. the risk of larger accidents is more di\\x0ecult to gauge,\\nbut we believe it is worthwhile and prudent to develop a principled and forward-looking approach to\\nsafety that continues to remain relevant as autonomous systems become more powerful. while many\\ncurrent-day safety problems can and have been handled with ad hoc \\x0cxes or case-by-case rules, we\\nbelieve that the increasing trend towards end-to-end, fully autonomous systems points towards the\\nneed for a uni\\x0ced approach to prevent these systems from causing unintended harm.\\n5note that \\\\security\" di\\x0bers from \\\\abuse\" in that the former involves attacks against a legitimate ml system\\nby an adversary (e.g. a criminal tries to fool a face recognition system), while the latter involves attacks by an ml\\nsystem controlled by an adversary (e.g. a criminal trains a \\\\smart hacker\" system to break into a website).\\n21\\n',\n",
       " 'acknowledgements\\nwe thank shane legg, peter norvig, ilya sutskever, greg corrado, laurent orseau, david krueger,\\nrif saurous, david andersen, and victoria krakovna for detailed feedback and suggestions. we\\nwould also like to thank geo\\x0brey irving, toby ord, quoc le, greg wayne, daniel dewey, nick\\nbeckstead, holden karnofsky, chelsea finn, marcello herresho\\x0b, alex donaldson, jared kaplan,\\ngreg brockman, wojciech zaremba, ian goodfellow, dylan had\\x0celd-menell, jessica taylor, blaise\\naguera y arcas, david berlekamp, aaron courville, and je\\x0b dean for helpful discussions and\\ncomments. paul christiano was supported as part of the future of life institute fli-rfp-ai1\\nprogram, grant #2015{143898. in addition a minority of the work done by paul christiano was\\nperformed as a contractor for theiss research and at openai. finally, we thank the google brain\\nteam for providing a supportive environment and encouraging us to publish this work.\\nreferences\\n[1] martin abadi et al. \\\\deep learning with di\\x0berential privacy\". in: (in press (2016)).\\n[2] pieter abbeel and andrew y ng. \\\\exploration and apprenticeship learning in reinforcement\\nlearning\". in: proceedings of the 22nd international conference on machine learning . acm.\\n2005, pp. 1{8.\\n[3] julius adebayo, lalana kagal, and alex pentland. the hidden cost of e\\x0eciency: fairness\\nand discrimination in predictive modeling . 2015.\\n[4] alekh agarwal et al. \\\\taming the monster: a fast and simple algorithm for contextual ban-\\ndits\". in: (2014).\\n[5] hana ajakan et al. \\\\domain-adversarial neural networks\". in: arxiv preprint arxiv:1412.4446\\n(2014).\\n[6] ifeoma ajunwa et al. \\\\hiring by algorithm: predicting and preventing disparate impact\". in:\\navailable at ssrn 2746078 (2016).\\n[7] dario amodei et al. \\\\deep speech 2: end-to-end speech recognition in english and man-\\ndarin\". in: arxiv preprint arxiv:1512.02595 (2015).\\n[8] an open letter: research priorities for robust and bene\\x0ccial arti\\x0ccial intelligence . open\\nletter. signed by 8,600 people; see attached research agenda. 2015.\\n[9] animashree anandkumar, daniel hsu, and sham m kakade. \\\\a method of moments for\\nmixture models and hidden markov models\". in: arxiv preprint arxiv:1203.0683 (2012).\\n[10] theodore w anderson and herman rubin. \\\\estimation of the parameters of a single equation\\nin a complete system of stochastic equations\". in: the annals of mathematical statistics\\n(1949), pp. 46{63.\\n[11] theodore w anderson and herman rubin. \\\\the asymptotic properties of estimates of the\\nparameters of a single equation in a complete system of stochastic equations\". in: the annals\\nof mathematical statistics (1950), pp. 570{582.\\n[12] stuart armstrong. \\\\motivated value selection for arti\\x0ccial agents\". in: workshops at the\\ntwenty-ninth aaai conference on arti\\x0ccial intelligence . 2015.\\n[13] stuart armstrong. the mathematics of reduced impact: help needed . 2012.\\n[14] stuart armstrong. utility indi\\x0berence . tech. rep. technical report 2010-1. oxford: future\\nof humanity institute, university of oxford, 2010.\\n[15] melanie arntz, terry gregory, and ulrich zierahn. \\\\the risk of automation for jobs in\\noecd countries\". in: oecd social, employment and migration working papers (2016).\\nurl:http://dx.doi.org/10.1787/5jlz9h56dvq7-en .\\n[16] autonomous weapons: an open letter from ai & robotics researchers . open letter. signed\\nby 20,000+ people. 2015.\\n22\\n',\n",
       " '[17] james babcock, janos kramar, and roman yampolskiy. \\\\the agi containment problem\".\\nin:the ninth conference on arti\\x0ccial general intelligence (2016).\\n[18] krishnakumar balasubramanian, pinar donmez, and guy lebanon. \\\\unsupervised super-\\nvised learning ii: margin-based classi\\x0ccation without labels\". in: the journal of machine\\nlearning research 12 (2011), pp. 3119{3145.\\n[19] marco barreno et al. \\\\the security of machine learning\". in: machine learning 81.2 (2010),\\npp. 121{148.\\n[20] tamer ba\\x18 sar and pierre bernhard. h-in\\x0cnity optimal control and related minimax design\\nproblems: a dynamic game approach . springer science & business media, 2008.\\n[21] mich\\x12 ele basseville. \\\\detecting changes in signals and systems|a survey\". in: automatica\\n24.3 (1988), pp. 309{326.\\n[22] f berkenkamp, a krause, and angela p schoellig. \\\\bayesian optimization with safety con-\\nstraints: safe and automatic parameter tuning in robotics.\" arxiv, 2016\". in: arxiv preprint\\narxiv:1602.04450 ().\\n[23] jon bird and paul layzell. \\\\the evolved radio and its implications for modelling the evolution\\nof novel sensors\". in: evolutionary computation, 2002. cec\\'02. proceedings of the 2002\\ncongress on . vol. 2. ieee. 2002, pp. 1836{1841.\\n[24] john blitzer, mark dredze, fernando pereira, et al. \\\\biographies, bollywood, boom-boxes\\nand blenders: domain adaptation for sentiment classi\\x0ccation\". in: acl. vol. 7. 2007, pp. 440{\\n447.\\n[25] john blitzer, sham kakade, and dean p foster. \\\\domain adaptation with coupled sub-\\nspaces\". in: international conference on arti\\x0ccial intelligence and statistics . 2011, pp. 173{\\n181.\\n[26] charles blundell et al. \\\\weight uncertainty in neural networks\". in: arxiv preprint arxiv:1505.05424\\n(2015).\\n[27] nick bostrom. superintelligence: paths, dangers, strategies . oup oxford, 2014.\\n[28] l\\x13 eon bottou. \\\\two high stakes challenges in machine learning\". invited talk at the 32nd\\ninternational conference on machine learning. 2015.\\n[29] l\\x13 eon bottou et al. \\\\counterfactual reasoning and learning systems\". in: arxiv preprint\\narxiv:1209.2355 (2012).\\n[30] l\\x13 eon bottou et al. \\\\counterfactual reasoning and learning systems: the example of compu-\\ntational advertising\". in: the journal of machine learning research 14.1 (2013), pp. 3207{\\n3260.\\n[31] ronen i brafman and moshe tennenholtz. \\\\r-max-a general polynomial time algorithm\\nfor near-optimal reinforcement learning\". in: the journal of machine learning research 3\\n(2003), pp. 213{231.\\n[32] erik brynjolfsson and andrew mcafee. the second machine age: work, progress, and pros-\\nperity in a time of brilliant technologies . ww norton & company, 2014.\\n[33] ryan calo. \\\\open robotics\". in: maryland law review 70.3 (2011).\\n[34] paul christiano. ai control . [online; accessed 13-june-2016]. 2015. url:https://medium.\\ncom/ai-control .\\n[35] fabio cozman and ira cohen. \\\\risks of semi-supervised learning\". in: semi-supervised learn-\\ning(2006), pp. 56{72.\\n[36] andrew critch. \\\\parametric bounded l\\x7f ob\\'s theorem and robust cooperation of bounded\\nagents\". in: (2016).\\n[37] christian daniel et al. \\\\active reward learning\". in: proceedings of robotics science & sys-\\ntems. 2014.\\n[38] ernest davis. \\\\ethical guidelines for a superintelligence.\" in: artif. intell. 220 (2015), pp. 121{\\n124.\\n[39] alexander philip dawid and allan m skene. \\\\maximum likelihood estimation of observer\\nerror-rates using the em algorithm\". in: applied statistics (1979), pp. 20{28.\\n23\\n',\n",
       " '[40] peter dayan and geo\\x0brey e hinton. \\\\feudal reinforcement learning\". in: advances in neural\\ninformation processing systems . morgan kaufmann publishers. 1993, pp. 271{271.\\n[41] kalyanmoy deb. \\\\multi-objective optimization\". in: search methodologies . springer, 2014,\\npp. 403{449.\\n[42] daniel dewey. \\\\learning what to value\". in: arti\\x0ccial general intelligence . springer, 2011,\\npp. 309{314.\\n[43] daniel dewey. \\\\reinforcement learning and the reward engineering principle\". in: 2014 aaai\\nspring symposium series . 2014.\\n[44] pinar donmez, guy lebanon, and krishnakumar balasubramanian. \\\\unsupervised super-\\nvised learning i: estimating classi\\x0ccation and regression errors without labels\". in: the jour-\\nnal of machine learning research 11 (2010), pp. 1323{1351.\\n[45] gregory druck, gideon mann, and andrew mccallum. \\\\learning from labeled features using\\ngeneralized expectation criteria\". in: proceedings of the 31st annual international acm sigir\\nconference on research and development in information retrieval . acm. 2008, pp. 595{602.\\n[46] cynthia dwork et al. \\\\fairness through awareness\". in: proceedings of the 3rd innovations\\nin theoretical computer science conference . acm. 2012, pp. 214{226.\\n[47] bradley efron. \\\\computers and the theory of statistics: thinking the unthinkable\". in: siam\\nreview 21.4 (1979), pp. 460{480.\\n[48] owain evans, andreas stuhlm\\x7f uller, and noah d goodman. \\\\learning the preferences of\\nignorant, inconsistent agents\". in: arxiv preprint arxiv:1512.05832 (2015).\\n[49] tom everitt and marcus hutter. \\\\avoiding wireheading with value reinforcement learning\".\\nin:arxiv preprint arxiv:1605.03143 (2016).\\n[50] tom everitt et al. \\\\self-modi\\x0ccation of policy and utility function in rational agents\". in:\\narxiv preprint arxiv:1605.03142 (2016).\\n[51] chelsea finn, sergey levine, and pieter abbeel. \\\\guided cost learning: deep inverse op-\\ntimal control via policy optimization\". in: arxiv preprint arxiv:1603.00448 (2016).\\n[52] carl benedikt frey and michael a osborne. \\\\the future of employment: how susceptible are\\njobs to computerisation\". in: retrieved september 7 (2013), p. 2013.\\n[53] yarin gal and zoubin ghahramani. \\\\dropout as a bayesian approximation: representing\\nmodel uncertainty in deep learning\". in: arxiv preprint arxiv:1506.02142 (2015).\\n[54] joao gama et al. \\\\learning with drift detection\". in: advances in arti\\x0ccial intelligence{sbia\\n2004. springer, 2004, pp. 286{295.\\n[55] javier garc\\x13 \\x10a and fernando fern\\x13 andez. \\\\a comprehensive survey on safe reinforcement\\nlearning\". in: journal of machine learning research 16 (2015), pp. 1437{1480.\\n[56] scott garrabrant, nate soares, and jessica taylor. \\\\asymptotic convergence in online\\nlearning with unbounded delays\". in: arxiv preprint arxiv:1604.05280 (2016).\\n[57] scott garrabrant et al. \\\\uniform coherence\". in: arxiv preprint arxiv:1604.05288 (2016).\\n[58] shalini ghosh et al. \\\\trusted machine learning for probabilistic models\". in: reliable ma-\\nchine learning in the wild at icml 2016 (2016).\\n[59] yolanda gil et al. \\\\amplify scienti\\x0cc discovery with arti\\x0ccial intelligence\". in: science 346.6206\\n(2014), pp. 171{172.\\n[60] alec go, richa bhayani, and lei huang. \\\\twitter sentiment classi\\x0ccation using distant\\nsupervision\". in: cs224n project report, stanford 1 (2009), p. 12.\\n[61] ian goodfellow et al. \\\\generative adversarial nets\". in: advances in neural information\\nprocessing systems . 2014, pp. 2672{2680.\\n[62] ian j goodfellow, jonathon shlens, and christian szegedy. \\\\explaining and harnessing ad-\\nversarial examples\". in: arxiv preprint arxiv:1412.6572 (2014).\\n[63] charles ae goodhart. problems of monetary management: the uk experience . springer,\\n1984.\\n[64] alex graves, greg wayne, and ivo danihelka. \\\\neural turing machines\". in: arxiv preprint\\narxiv:1410.5401 (2014).\\n24',\n",
       " '[65] sonal gupta. \\\\distantly supervised information extraction using bootstrapped patterns\".\\nphd thesis. stanford university, 2015.\\n[66] dylan had\\x0celd-menell et al. cooperative inverse reinforcement learning . 2016.\\n[67] dylan had\\x0celd-menell et al. \\\\the o\\x0b-switch\". in: (2016).\\n[68] lars peter hansen. \\\\large sample properties of generalized method of moments estimators\".\\nin:econometrica: journal of the econometric society (1982), pp. 1029{1054.\\n[69] lars peter hansen. \\\\nobel lecture: uncertainty outside and inside economic models\". in:\\njournal of political economy 122.5 (2014), pp. 945{987.\\n[70] mark herbster and manfred k warmuth. \\\\tracking the best linear predictor\". in: the jour-\\nnal of machine learning research 1 (2001), pp. 281{309.\\n[71] bill hibbard. \\\\model-based utility functions\". in: journal of arti\\x0ccial general intelligence\\n3.1 (2012), pp. 1{24.\\n[72] thomas hofmann, bernhard sch\\x7f olkopf, and alexander j smola. \\\\kernel methods in machine\\nlearning\". in: the annals of statistics (2008), pp. 1171{1220.\\n[73] garud n iyengar. \\\\robust dynamic programming\". in: mathematics of operations research\\n30.2 (2005), pp. 257{280.\\n[74] ariel ja\\x0be, boaz nadler, and yuval kluger. \\\\estimating the accuracies of multiple classi\\x0cers\\nwithout labeled data\". in: arxiv preprint arxiv:1407.7644 (2014).\\n[75] jean-baptiste jeannin et al. \\\\a formally veri\\x0ced hybrid system for the next-generation air-\\nborne collision avoidance system\". in: tools and algorithms for the construction and analysis\\nof systems . springer, 2015, pp. 21{36.\\n[76] zhanglong ji, zachary c lipton, and charles elkan. \\\\di\\x0berential privacy and machine learn-\\ning: a survey and review\". in: arxiv preprint arxiv:1412.7584 (2014).\\n[77] fredrik d johansson, uri shalit, and david sontag. \\\\learning representations for counter-\\nfactual inference\". in: arxiv preprint arxiv:1605.03661 (2016).\\n[78] leslie pack kaelbling, michael l littman, and anthony r cassandra. \\\\planning and acting\\nin partially observable stochastic domains\". in: arti\\x0ccial intelligence 101.1 (1998), pp. 99{\\n134.\\n[79]  lukasz kaiser and ilya sutskever. \\\\neural gpus learn algorithms\". in: arxiv preprint arxiv:1511.08228\\n(2015).\\n[80] yoshinobu kawahara and masashi sugiyama. \\\\change-point detection in time-series data\\nby direct density-ratio estimation.\" in: sdm . vol. 9. siam. 2009, pp. 389{400.\\n[81] f. khani, m. rinard, and p. liang. \\\\unanimous prediction for 100learning semantic parsers\".\\nin:association for computational linguistics (acl) . 2016.\\n[82] alex krizhevsky, ilya sutskever, and geo\\x0brey e hinton. \\\\imagenet classi\\x0ccation with deep\\nconvolutional neural networks\". in: advances in neural information processing systems . 2012,\\npp. 1097{1105.\\n[83] volodymyr kuleshov and percy s liang. \\\\calibrated structured prediction\". in: advances\\nin neural information processing systems . 2015, pp. 3456{3464.\\n[84] tejas d kulkarni et al. \\\\hierarchical deep reinforcement learning: integrating temporal\\nabstraction and intrinsic motivation\". in: arxiv preprint arxiv:1604.06057 (2016).\\n[85] neil lawrence. discussion of \\'superintelligence: paths, dangers, strategies\\' . 2016.\\n[86] jesse levinson et al. \\\\towards fully autonomous driving: systems and algorithms\". in: in-\\ntelligent vehicles symposium (iv), 2011 ieee . ieee. 2011, pp. 163{168.\\n[87] lihong li et al. \\\\knows what it knows: a framework for self-aware learning\". in: machine\\nlearning 82.3 (2011), pp. 399{443.\\n[88] yu-feng li and zhi-hua zhou. \\\\towards making unlabeled data never hurt\". in: pattern\\nanalysis and machine intelligence, ieee transactions on 37.1 (2015), pp. 175{188.\\n[89] percy liang. \\\\on the elusiveness of a speci\\x0ccation for ai\". nips 2015, symposium: algo-\\nrithms among us. 2015. url:http://research.microsoft.com/apps/video/default.\\naspx?id=260009&r=1 .\\n25\\n',\n",
       " '[90] percy liang and dan klein. \\\\analyzing the errors of unsupervised learning.\" in: acl.\\n2008, pp. 879{887.\\n[91] song liu et al. \\\\change-point detection in time-series data by relative density-ratio estima-\\ntion\". in: neural networks 43 (2013), pp. 72{83.\\n[92] sarah m loos, david renshaw, and andr\\x13 e platzer. \\\\formal veri\\x0ccation of distributed air-\\ncraft controllers\". in: proceedings of the 16th international conference on hybrid systems:\\ncomputation and control . acm. 2013, pp. 125{130.\\n[93] john lygeros, claire tomlin, and shankar sastry. \\\\controllers for reachability speci\\x0ccations\\nfor hybrid systems\". in: automatica 35.3 (1999), pp. 349{370.\\n[94] gideon s mann and andrew mccallum. \\\\generalized expectation criteria for semi-supervised\\nlearning with weakly labeled data\". in: the journal of machine learning research 11 (2010),\\npp. 955{984.\\n[95] john mccarthy and patrick j hayes. \\\\some philosophical problems from the standpoint of\\narti\\x0ccial intelligence\". in: readings in arti\\x0ccial intelligence (1969), pp. 431{450.\\n[96] shike mei and xiaojin zhu. \\\\the security of latent dirichlet allocation.\" in: aistats .\\n2015.\\n[97] shike mei and xiaojin zhu. \\\\using machine teaching to identify optimal training-set at-\\ntacks on machine learners.\" in: aaai . 2015, pp. 2871{2877.\\n[98] bernard merialdo. \\\\tagging english text with a probabilistic model\". in: computational\\nlinguistics 20.2 (1994), pp. 155{171.\\n[99] mike mintz et al. \\\\distant supervision for relation extraction without labeled data\". in:\\nproceedings of the joint conference of the 47th annual meeting of the acl and the 4th\\ninternational joint conference on natural language processing of the afnlp: volume 2-\\nvolume 2 . association for computational linguistics. 2009, pp. 1003{1011.\\n[100] ian m mitchell, alexandre m bayen, and claire j tomlin. \\\\a time-dependent hamilton-\\njacobi formulation of reachable sets for continuous dynamic games\". in: automatic control,\\nieee transactions on 50.7 (2005), pp. 947{957.\\n[101] stefan mitsch, sarah m loos, and andr\\x13 e platzer. \\\\towards formal veri\\x0ccation of freeway\\ntra\\x0ec control\". in: cyber-physical systems (iccps), 2012 ieee/acm third international\\nconference on . ieee. 2012, pp. 171{180.\\n[102] volodymyr mnih et al. \\\\human-level control through deep reinforcement learning\". in: nature\\n518.7540 (2015), pp. 529{533.\\n[103] shakir mohamed and danilo jimenez rezende. \\\\variational information maximisation for\\nintrinsically motivated reinforcement learning\". in: advances in neural information pro-\\ncessing systems . 2015, pp. 2116{2124.\\n[104] teodor mihai moldovan and pieter abbeel. \\\\safe exploration in markov decision processes\".\\nin:arxiv preprint arxiv:1205.4810 (2012).\\n[105] alexander mordvintsev, christopher olah, and mike tyka. \\\\inceptionism: going deeper into\\nneural networks\". in: google research blog. retrieved june 20 (2015).\\n[106] jersey neyman. \\\\sur les applications de la th\\x13 eorie des probabilit\\x13 es aux experiences agricoles:\\nessai des principes\". in: roczniki nauk rolniczych 10 (1923), pp. 1{51.\\n[107] andrew y ng, stuart j russell, et al. \\\\algorithms for inverse reinforcement learning.\" in:\\nicml. 2000, pp. 663{670.\\n[108] anh nguyen, jason yosinski, and je\\x0b clune. \\\\deep neural networks are easily fooled: high\\ncon\\x0cdence predictions for unrecognizable images\". in: computer vision and pattern recog-\\nnition (cvpr), 2015 ieee conference on . ieee. 2015, pp. 427{436.\\n[109] anh nguyen et al. \\\\synthesizing the preferred inputs for neurons in neural networks via deep\\ngenerator networks\". in: arxiv preprint arxiv:1605.09304 (2016).\\n[110] kamal nigam et al. \\\\learning to classify text from labeled and unlabeled documents\". in:\\naaai/iaai 792 (1998).\\n26',\n",
       " '[111] arnab nilim and laurent el ghaoui. \\\\robust control of markov decision processes with\\nuncertain transition matrices\". in: operations research 53.5 (2005), pp. 780{798.\\n[112] christopher olah. visualizing representations: deep learning and human beings . 2015. url:\\nhttp://colah.github.io/posts/2015-01-visualizing-representations/ .\\n[113] laurent orseau and stuart armstrong. \\\\safely interruptible agents\". in: (2016).\\n[114] ian osband et al. \\\\deep exploration via bootstrapped dqn\". in: arxiv preprint arxiv:1602.04621\\n(2016).\\n[115] nicolas papernot et al. \\\\practical black-box attacks against deep learning systems using\\nadversarial examples\". in: arxiv preprint arxiv:1602.02697 (2016).\\n[116] douglas b paul and janet m baker. \\\\the design for the wall street journal-based csr\\ncorpus\". in: proceedings of the workshop on speech and natural language . association for\\ncomputational linguistics. 1992, pp. 357{362.\\n[117] judea pearl et al. \\\\causal inference in statistics: an overview\". in: statistics surveys 3 (2009),\\npp. 96{146.\\n[118] martin pecka and tomas svoboda. \\\\safe exploration techniques for reinforcement learning{an\\noverview\". in: modelling and simulation for autonomous systems . springer, 2014, pp. 357{\\n375.\\n[119] dino pedreshi, salvatore ruggieri, and franco turini. \\\\discrimination-aware data mining\".\\nin:proceedings of the 14th acm sigkdd international conference on knowledge discovery\\nand data mining . acm. 2008, pp. 560{568.\\n[120] jonas peters et al. \\\\causal discovery with continuous additive noise models\". in: the journal\\nof machine learning research 15.1 (2014), pp. 2009{2053.\\n[121] emmanouil antonios platanios. \\\\estimating accuracy from unlabeled data\". ma thesis.\\ncarnegie mellon university, 2015.\\n[122] emmanouil antonios platanios, avrim blum, and tom mitchell. \\\\estimating accuracy from\\nunlabeled data\". in: (2014).\\n[123] walter w powell and laurel smith-doerr. \\\\networks and economic life\". in: the handbook\\nof economic sociology 368 (1994), p. 380.\\n[124] joaquin quinonero-candela et al. dataset shift in machine learning, ser. neural information\\nprocessing series . 2009.\\n[125] rajat raina et al. \\\\self-taught learning: transfer learning from unlabeled data\". in: proceed-\\nings of the 24th international conference on machine learning . acm. 2007, pp. 759{766.\\n[126] bharath ramsundar et al. \\\\massively multitask networks for drug discovery\". in: arxiv\\npreprint arxiv:1502.02072 (2015).\\n[127] mark ring and laurent orseau. \\\\delusion, survival, and intelligent agents\". in: arti\\x0ccial\\ngeneral intelligence . springer, 2011, pp. 11{20.\\n[128] st\\x13 ephane ross, geo\\x0brey j gordon, and j andrew bagnell. \\\\a reduction of imitation learning\\nand structured prediction to no-regret online learning\". in: arxiv preprint arxiv:1011.0686\\n(2010).\\n[129] donald b rubin. \\\\estimating causal e\\x0bects of treatments in randomized and nonrandomized\\nstudies.\" in: journal of educational psychology 66.5 (1974), p. 688.\\n[130] stuart russell et al. \\\\research priorities for robust and bene\\x0ccial arti\\x0ccial intelligence\". in:\\nfuture of life institute (2015).\\n[131] christoph salge, cornelius glackin, and daniel polani. \\\\empowerment{an introduction\". in:\\nguided self-organization: inception . springer, 2014, pp. 67{114.\\n[132] j denis sargan. \\\\the estimation of relationships with autocorrelated residuals by the use of\\ninstrumental variables\". in: journal of the royal statistical society. series b (methodological)\\n(1959), pp. 91{105.\\n[133] john d sargan. \\\\the estimation of economic relationships using instrumental variables\". in:\\neconometrica: journal of the econometric society (1958), pp. 393{415.\\n27\\n',\n",
       " '[134] john schulman et al. \\\\high-dimensional continuous control using generalized advantage es-\\ntimation\". in: arxiv preprint arxiv:1506.02438 (2015).\\n[135] d sculley et al. \\\\machine learning: the high-interest credit card of technical debt\". in:\\n(2014).\\n[136] glenn shafer and vladimir vovk. \\\\a tutorial on conformal prediction\". in: the journal of\\nmachine learning research 9 (2008), pp. 371{421.\\n[137] uri shalit, fredrik johansson, and david sontag. \\\\bounding and minimizing counterfactual\\nerror\". in: arxiv preprint arxiv:1606.03976 (2016).\\n[138] hidetoshi shimodaira. \\\\improving predictive inference under covariate shift by weighting the\\nlog-likelihood function\". in: journal of statistical planning and inference 90.2 (2000), pp. 227{\\n244.\\n[139] jaeho shin et al. \\\\incremental knowledge base construction using deepdive\". in: proceedings\\nof the vldb endowment 8.11 (2015), pp. 1310{1321.\\n[140] david silver et al. \\\\mastering the game of go with deep neural networks and tree search\".\\nin:nature 529.7587 (2016), pp. 484{489.\\n[141] snes super mario world (usa) \\\\arbitrary code execution\" . tool-assisted movies. 2014. url:\\nhttp://tasvideos.org/2513m.html .\\n[142] nate soares and benja fallenstein. \\\\toward idealized decision theory\". in: arxiv preprint\\narxiv:1507.01986 (2015).\\n[143] ray j solomono\\x0b. \\\\a formal theory of inductive inference. part i\". in: information and\\ncontrol 7.1 (1964), pp. 1{22.\\n[144] ray j solomono\\x0b. \\\\a formal theory of inductive inference. part ii\". in: information and\\ncontrol 7.2 (1964), pp. 224{254.\\n[145] j steinebach. \\\\el lehmann, jp romano: testing statistical hypotheses\". in: metrika 64.2\\n(2006), pp. 255{256.\\n[146] jacob steinhardt. long-term and short-term challenges to ensuring the safety of ai sys-\\ntems. [online; accessed 13-june-2016]. 2015. url:https://jsteinhardt.wordpress.com/\\n2015/06/24/long-term-and-short-term-challenges-to-ensuring-the-safety-of-\\nai-systems/ .\\n[147] jacob steinhardt and percy liang. \\\\unsupervised risk estimation with only structural\\nassumptions\". in: (2016).\\n[148] jacob steinhardt and russ tedrake. \\\\finite-time regional veri\\x0ccation of stochastic non-linear\\nsystems\". in: the international journal of robotics research 31.7 (2012), pp. 901{923.\\n[149] jacob steinhardt, gregory valiant, and moses charikar. \\\\avoiding imposters and delin-\\nquents: adversarial crowdsourcing and peer prediction\". in: arxiv prepring arxiv:1606.05374\\n(2016). url:http://arxiv.org/abs/1606.05374 .\\n[150] richard s sutton and andrew g barto. reinforcement learning: an introduction . mit press,\\n1998.\\n[151] adith swaminathan and thorsten joachims. \\\\counterfactual risk minimization: learning\\nfrom logged bandit feedback\". in: arxiv preprint arxiv:1502.02362 (2015).\\n[152] christian szegedy et al. \\\\intriguing properties of neural networks\". in: arxiv preprint arxiv:1312.6199\\n(2013).\\n[153] aviv tamar, yonatan glassner, and shie mannor. \\\\policy gradients beyond expectations:\\nconditional value-at-risk\". in: arxiv preprint arxiv:1404.3862 (2014).\\n[154] jessica taylor. \\\\quantilizers: a safer alternative to maximizers for limited optimization\".\\nin:forthcoming). submitted to aaai (2016).\\n[155] matthew e taylor and peter stone. \\\\transfer learning for reinforcement learning domains:\\na survey\". in: journal of machine learning research 10.jul (2009), pp. 1633{1685.\\n[156] philip s thomas, georgios theocharous, and mohammad ghavamzadeh. \\\\high-con\\x0cdence\\no\\x0b-policy evaluation.\" in: aaai . 2015, pp. 3000{3006.\\n[157] adrian thompson. arti\\x0ccial evolution in the physical world . 1997.\\n28\\n',\n",
       " '[158] antonio torralba and alexei a efros. \\\\unbiased look at dataset bias\". in: computer vision\\nand pattern recognition (cvpr), 2011 ieee conference on . ieee. 2011, pp. 1521{1528.\\n[159] matteo turchetta, felix berkenkamp, and andreas krause. \\\\safe exploration in finite\\nmarkov decision processes with gaussian processes\". in: arxiv preprint arxiv:1606.04753\\n(2016).\\n[160] stefan wager and susan athey. \\\\estimation and inference of heterogeneous treatment ef-\\nfects using random forests\". in: arxiv preprint arxiv:1510.04342 (2015).\\n[161] daniel weld and oren etzioni. \\\\the \\x0crst law of robotics (a call to arms)\". in: aaai . vol. 94.\\n1994. 1994, pp. 1042{1047.\\n[162] keenon werling et al. \\\\on-the-job learning with bayesian decision theory\". in: advances in\\nneural information processing systems . 2015, pp. 3447{3455.\\n[163] jason weston et al. \\\\towards ai-complete question answering: a set of prerequisite toy tasks\".\\nin:arxiv preprint arxiv:1502.05698 (2015).\\n[164] wolfram wiesemann, daniel kuhn, and ber\\x18 c rustem. \\\\robust markov decision processes\".\\nin:mathematics of operations research 38.1 (2013), pp. 153{183.\\n[165] roman v yampolskiy. \\\\utility function security in arti\\x0ccially intelligent agents\". in: journal\\nof experimental & theoretical arti\\x0ccial intelligence 26.3 (2014), pp. 373{389.\\n[166] jason yosinski et al. \\\\understanding neural networks through deep visualization\". in: arxiv\\npreprint arxiv:1506.06579 (2015).\\n[167] eliezer yudkowsky. \\\\arti\\x0ccial intelligence as a positive and negative factor in global risk\".\\nin:global catastrophic risks 1 (2008), p. 303.\\n[168] muhammad bilal zafar et al. \\\\learning fair classi\\x0cers\". in: stat1050 (2015), p. 29.\\n[169] richard s zemel et al. \\\\learning fair representations.\" in: icml (3) 28 (2013), pp. 325{333.\\n[170] yuchen zhang et al. \\\\spectral methods meet em: a provably optimal algorithm for crowd-\\nsourcing\". in: advances in neural information processing systems . 2014, pp. 1260{1268.\\n29',\n",
       " 'journal of ai  \\n52 \\nvolume:  7, issue  no: 1, january -december  2023,  pages:  52-62 \\neducation in the era of generative artificial intelligence (ai): \\nunderstanding the potential benefits of chatgpt in promoting \\nteaching and learning  \\ndavid baidoo -anu1, leticia owusu ansah2\\n1faculty of education queen’s university , canada . baidooanu.david@queen su.ca , 0000 -0003 -4628 -3459  \\n2 university of cape coast , ghana . empresslettyb@gmail.com , 0009 -0004 -5141 -1392  \\nrecieved:  03.08.202 3 accepted:  11.09.202 3 online: 12.09.202 3 published : 31.12.202 3 \\nreview article  \\nabstract  \\nsince its maiden release into the public domain on november 30, 2022, chatgpt garnered more than one \\nmillion subscr ibers within a week. the generative ai tool ⎼chatgpt took the world by surprise with it \\nsophisticated capacity to carry out remarkably complex tasks. the extraordinary abilities of chatgpt to \\nperform complex tasks within the field of education has caused m ixed feelings among educators, as this \\nadvancement in ai seems to revolutionize existing educational praxis. this is an exploratory study that \\nsynthesizes recent extant literature to offer some potential benefits and drawbacks of chatgpt in \\npromoting teach ing and learning. benefits of chatgpt include but are not limited to promotion of \\npersonalized and interactive learning, generating prompts for formative assessment activities that provide \\nongoing feedback to inform teaching and learning etc. the paper als o highlights some inherent limitations \\nin the chatgpt such as generating wrong information, biases in data training, which may augment existing \\nbiases, privacy issues etc. the study offers recommendations on how chatgpt could be leveraged to \\nmaximize teach ing and learning. policy makers, researchers, educators and technology experts could work \\ntogether and start conversations on how these evolving generative ai tools could be used safely and \\nconstructively to improve education and support students’ learning . \\nkeywords:  chatgpt, education, generative ai, teaching and learning  \\ncite this paper (apa)  \\nbaidoo -anu, d., owusu ansah , l. (2023). education in the era of generative artificial intelligence (ai): \\nunderstanding the potential benefits of chatgpt in promoting teaching and learning . journal of a i. 7(1), \\n52-62. ',\n",
       " 'journal of ai  \\n53 \\n1. introduction  \\nthe 21st century has experienced a rapidly changing landscape in educational practices largely due to \\nadvancement in technology (such as artificial intelligence) (petersen, 2021). recent progress and expansion \\nin machine learning has led to a more sophisticated innovative technology digital content generation like \\ngener ative artificial intelligence (ai) (hu, 2022). generative modeling artificial intelligence (gai) is an \\nunsupervised or partially supervised machine learning framework, which generates manmade relics via the \\nuse of statistics, probabilities etc (hu, 2022; j ovanović, 2022). through advances in deep learning (dl), \\ngenerative ai creates artificial relics using existing digital content such as but not limited to video, \\nimages/graphics, text, audio, video by examining training examples; learning their patterns an d distribution \\n(abukmeil, et al., 2021; hu, 2022; jovanović, 2022; gui, et al., 2021). extant literature has identified two major \\ngenerative ai ⎼ generative adversarial network (gan) and generative pre -trained transformer (gpt) \\n(abukmeil, et al., 2021; bro wn et al., 2020; hu, 2022; jovanović, 2022; gui, et al., 2021). currently, gan is the \\ncommon gai technique used. gan uses two neural networks (i.e., generator and discriminator networks). \\nthe generator network generates synthetic data (e.g., image of someo ne’s face), while the discriminator \\nnetwork examines the genuineness of the content to determine whether the content is authentic or not (e.g., \\nwhether the image of the human is real or not). this verification process continues until the discriminator \\nnetw ork is not able to decipher between the synthetic and real content, and synthetic is recognized as real \\n(hu, 2022; jovanović, 2022). can is predominantly used for voice generation, graphics and video (hu, 2022).  \\non the other hand, generative pre -trained tr ansformer (gpt) models use large amount of publicly available \\ndigital content data (natural language processing [nlp]) to read and produce human -like text in several \\nlanguages and can exhibit creativity in writing from a paragraph to a full research articl e convincingly (or near \\nconvincing) on almost any topics  (aydin & karaarslan, 202 3). these models are even able to engage \\ncustomers in human -like conversation such as customer -service chatbots or fictional characters in video \\ngames (aydin & karaarslan, 2022; jovanović, 2022; korngie bel et al., 2021; pavlik, 2023). a more \\nsophisticated generative pre -trained transformer (gpt) -3 has recently been developed (brown, et al., 2020). \\nusing  175 billion parameters, gpt -3 has been developed to enhance task -agnostic and even become \\ncompetitive with prior state -of-the-art fine -tuning approaches (brown, et al., 2020). brown et al., (2020) \\nstated that gpt -3 is ten times more than any previous non -sparse language model. gpt -3 has become the \\nbasic nlp engine that runs the recently developed language model chatgpt, which has attracted attention \\nin various fields, including but not limited to education (williams, 2023; tate, 2023), engineer (qadir, 2022), \\njournalism (pavlik, 2023), medical (nisar, & aslam, 2023; o’connor, & chatgpt, 2023) and economic a nd \\nfinance (alshater, 2022; terwiesch, 2023). in the next sections we provided an explanation of what chatgpt \\nis, and the potential to improve education and students’ learning. we also discussed some limitations and \\nhow educators can use chatgpt to support  and improve students’ learning. an earlier version of this work \\nhas previously been published in a preprint (see baidoo -anu & owusu -ansah, 2023).  \\n2. meth odology  \\nwe employed an exploratory methodology to understand the potential benefit of chatgpt in education. the \\npurpo se of this methodology is to systematically review and explore (a) how interactive chatgpt is, (b) the \\nbenefits of chatgpt and related generative ai in advancing teaching and learning, (c) the possible drawbacks \\nof using chatgpt and related generative ai i n education, reflections and implications for practice. the study \\nwas guided by these research questions ⎼(a) how interactive is chatgpt? (b) what are the potential benefits \\nof chatgpt and related generative ai in advancing teaching and learning? (c) what are the possible drawbacks \\nof using chatgpt and related generative ai in education? the study focused on publicly available resources \\non chatgpt from november 2022 -march 2023. specifically, we focused on articles published in a peer \\nreviewed journals or pr eprints as well as newsletter articles and social media. we were also interested in ',\n",
       " 'journal of ai  \\n54 \\narticles which have been published in english language.  \\n3. what is chat gpt?  \\nto begin, we asked chatgpt to explain itself. the pr ompt we started with was “ what is chatgpt? ”. chatgpt \\ngenerated this response.  \\n“chatgpt is a large language model trained by openai. it is designed to generate human -like text based on a \\ngiven prompt or context. it can be used for a variety of natural langu age processing tasks, such as text \\ncompletion, conversation generation, and language translation ”.  (by chatgpt january 23, 2023).  \\nas a follow up, we used another prompt “ how does it work? ” to know how conversational it is, we \\nintentionally wrote “ how does  it work? ” instead of \" how does chatgpt work? ”.  it returned with the response \\nbelow.  \\n“chatgpt is based on a transformer architecture, a type of neural network that has been shown to be very \\neffective for natural language processing tasks. it is trained on  a large dataset of text, such as books and \\narticles, and learns to generate text that is similar to the text it was trained on. when given a prompt or \\ncontext, the model processes the input and generates a response. the response is generated one word at a  \\ntime, with the model predicting the next word based on the input and the words it has generated so far. the \\nmodel uses attention mechanisms to focus on the most relevant parts of the input and generate a response \\nthat is coherent and appropriate for the g iven context. after the training, the model can be fine -tuned on a \\nspecific task such as question answering or dialogue generation by providing it with task -specific examples \\nand fine -tuning the model on this data. it can also generate text in multiple lan guages by fine -tuning the \\nmodel on the multilingual dataset or by providing the model with the language code ” (by chatgpt january \\n23, 2023).  \\nthen the topic of conversation was changed to discuss covid -19 and impacts on educational deliveries using \\nthe prom pt “now discuss how covid -19 has changed educational pedagogies. ” within seconds it wrote the \\npassage below.  \\nthe covid -19 pandemic has had a significant impact on the way education is delivered, with many schools \\nand universities shifting to online or remo te learning in order to comply with social distancing guidelines. this \\nhas resulted in a rapid shift to digital and online pedagogy, as educators have had to quickly adapt to this \\nnew mode of instruction.  \\none of the major changes that has occurred is the i ncreased use of technology for teaching and learning. this \\nhas included the use of online learning platforms, such as zoom, google classroom and other video \\nconferencing tools, as well as the use of digital materials, such as e -books, videos, and interacti ve activities. \\nthis has allowed for increased flexibility and accessibility in the delivery of education, as students can now \\naccess materials and participate in classes from anywhere with internet access.  \\nadditionally, there has been a shift towards more self-directed and asynchronous learning, where students \\nare given more autonomy in their learning and are able to complete coursework at their own pace. this \\napproach allows students to work at a time that is convenient for them, and it can be beneficial f or students \\nwho may have other responsibilities or who may have difficulty attending live classes. however, the shift to \\nonline learning has also highlighted the digital divide, where students in low -income or rural areas may not \\nhave access to the technol ogy or internet connectivity needed to fully participate in remote learning. and it \\nalso brought challenges such as lack of interaction, lack of motivation and lack of accountability.  \\noverall, covid -19 has accelerated the adoption of technology and digital  pedagogy in education, but it has \\nalso highlighted the need for equity and accessibility in the delivery of education. the education system will \\nhave to continue to adapt and evolve to meet the needs of students, teachers and parents during these ',\n",
       " \"journal of ai  \\n55 \\nchalleng ing times (by chatgpt january 23, 2023).  \\nobviously, the outcome clearly shows that chatgpt is very interactional and capable of not only holding a \\nrealistic human -like conversation on a wide range of topics, but also it produces a convincing creative \\ncontent . \\nsince its maiden release into the public domain on november 30, 2022, chatgpt garnered more than one \\nmillion subscribers within a week (altman, 2022; mollman, 2022). the chatgpt took the world by surprise \\nwith its sophisticated capacity and b ecame the hottest topic on social media and news outlets including \\nnature (stokel -walker, 2022) and the new york times (metz, 2022), among others. the chatgpt has \\nunprecedented ability to carry out remarkably complex tasks like writing an article (gtp -3 et al., 2021), story, \\npoem, an essay (lucy & bamman 2021), ability to provide a summary or expansion of a text, adjusting texts \\nto reflect a different perspective, and even write and debug original computer code (williams, 2023; tate et. \\nal, 2023). the extra ordinary abilities of chatgpt to perform complex tasks within the field of education has \\ncaused mixed feelings among educators, as this advancement in ai seems to revolutionize existing \\neducational practices. it has become a contentious topic among educato rs, while some perceive chatgpt \\nand related generative ai as the future of teaching and learning, as well as educational research. others are \\nskeptical and view it as a threat and a potential end to most educational activities, which makes teachers and \\nstudents lazy with no or little analytical abilities. so, the question that begs for an answer is whether chatgpt \\nand related generative ai are the future for teaching and learning or a threat to the education field? we co -\\nauthored with chatgpt to unpack some  benefits of chatgpt and related generative ai in advancing teaching \\nand learning. we also co -authored to discuss the possible drawback of using chatgpt and related generative \\nai in education. implication for practice was discussed.  \\n4. benefits of chatgpt and related generative ai in advancing teaching \\nand learning  \\nwe queried chatgpt to generate the benefit of chatgpt and related generative ai in advancing teaching and \\nlearning. the initial prompt was “ what are the benefits of chatgpt and relat ed generative ai in advancing \\nteaching and learning ”. chatgpt generated very brief (a paragraph) response which was not detailed. then \\nwhen we altered the prompt, chatgpt also altered the response by providing a detailed explanation. the \\naltered prompt was  “i want you to discuss with possible reference the benefits of chatgpt and related \\ngenerative ai in advancing teaching and learning ”. the following detailed responses were generated.  \\nchatgpt, a large language model developed by openai, has the potential t o be a powerful tool in the field \\nof education. here are some specific ways in which chatgpt can be used to enhance learning and the \\nreferences that support it:  \\npersonalized tutoring:  chatgpt can be used to provide personalized tutoring and feedback to stu dents \\nbased on their individual learning needs and progress. a study by chen and colleagues (2020) \\ndemonstrated that a conversational agent based on a generative model (chatgpt) could provide \\npersonalized math tutoring to students, resulting in improved le arning outcomes. the study showed that \\nthe conversational agent was able to provide explanations that were tailored to students' misconceptions \\nand was able to adapt to their level of understanding.  \\nautomated essay grading:  chatgpt can be trained to grade student essays, providing teachers with more \\ntime to focus on other aspects of teaching. a study by kim and colleagues (2019) showed that a generative \\nmodel (chatgpt) trained on a dataset of human -graded essays could accurately grade essays written by \\nhigh school students, with a correlation of 0.86 with human grades. the study showed that the model was \\nable to identify key features of well -written essays and was able to provide feedback that was simi lar to \\nthat provided by human graders.  \",\n",
       " \"journal of ai  \\n56 \\nlanguage translation:  chatgpt can be used to translate educational materials into different languages, \\nmaking them more accessible to a wider audience. a study by johnson and colleagues (2016) \\ndemonstrated that a gene rative model (chatgpt) trained on a dataset of bilingual sentence pairs could \\naccurately translate between languages, achieving state -of-the-art results on several translation \\nbenchmarks. the study showed that the model was able to understand the meaning o f sentences in one \\nlanguage and to generate accurate translations in another language.  \\ninteractive learning:  chatgpt can be used to create interactive learning experiences where students can \\ninteract with a virtual tutor in a conversational manner. a study  by peng and colleagues (2019) \\ndemonstrated that a generative model -based conversational agent could provide effective support for \\nstudents learning english as a second language, resulting in improved language proficiency. the study \\nshowed that the agent w as able to understand students' questions and to provide appropriate and \\nrelevant responses.  \\nadaptive learning: chatgpt can be used to create adaptive learning systems that adjust their teaching \\nmethods based on a student's progress and performance. a stud y by chiang and colleagues (2021) \\nshowed that an adaptive learning system based on a generative model (chatgpt) could provide more \\neffective support for students learning programming, resulting in improved performance on programming \\nassessments. the study showed that the model was able to understand students' knowledge and to adjust \\nthe difficulty of the problems it generated accordingly.  \\noverall, chatgpt has the potential to be a powerful tool for enhancing teaching and learning by providing \\npersonalized t utoring, automated essay grading, language translation, interactive learning and adaptive \\nlearning  (by chatgpt january 24, 2023).  \\n5. possible drawback of using chatgpt and related generative ai in education  \\nto have an overview of the possible drawback incor porating chatgpt and related generative ai in education, \\nchatgpt was asked to discuss with references the possible drawback of using chatgpt and related generative \\nai in education. below is the outcome of my query.  \\nwhile there are many potential benefits o f using chatgpt and other generative ai models in education, \\nthere are also some drawbacks to consider. these drawbacks are supported by research studies:  \\nlack of human interaction: chatgpt and other generative models are not capable of providing the same \\nlevel of human interaction as a real teacher or tutor. this lack of human interaction can be a disadvantage \\nfor students who may benefit more from a personal connection with a teacher. a study by d'mello and \\ncolleagues (2014) found that students who intera cted with a virtual tutor that mimicked human -like \\naffective behavior had a better learning outcome than those who interacted with a virtual tutor that \\nlacked this behavior.  \\nlimited understanding:  generative models are based on statistical patterns in the data they are trained \\non, and they do not have a true understanding of the concepts they are helping students learn. this can \\nbe a disadvantage when it comes to providing explanations or feedback that are tailored to a student's \\nindividual needs and miscon ceptions. a study by wang and colleagues (2020) showed that a generative \\nmodel -based tutoring system lacked the ability to provide explanations that were tailored to students' \\nmisconceptions.  \\nbias in training data:  generative models are only as good as the  data they are trained on, and if the \\ntraining data contains biases, the model will also be biased. for example, if a model is trained on a dataset \\nof essays that are primarily written by students from a certain demographic, it may not be able to \\naccuratel y grade essays written by students from other demographics. a study by bolukbasi and \",\n",
       " 'journal of ai  \\n57 \\ncolleagues (2016) showed that a generative model trained on a large corpus of text from the internet \\nexhibited gender bias in its language generation.  \\nlack of creativity:  generative models can only generate responses based on the patterns in the data they \\nhave seen during training, which can limit the creativity and originality of the responses. a study by ziegler \\nand colleagues (2019) found that a generative model -based mu sic composition system had a limited \\nability to generate original and diverse melodies.  \\ndependency on data:  generative models are trained on a large amount of data, and the quality of the \\nmodel is highly dependent on the quality and quantity of the data. i f the data is not sufficient or not \\nrelevant, the model will not be able to perform as well. a study by kocaguneli and colleagues (2019) \\nshowed that a generative model -based question answering system performed poorly when the training \\ndata was not relevant  to the task at hand.  \\nlack of contextual understanding:  generative models lack the ability to understand context and \\nsituation, which can lead to inappropriate or irrelevant responses. a study by gao and colleagues (2019) \\nshowed that a generative model -based dialogue system had a limited ability to understand and generate \\ncontextually appropriate responses in a conversation.  \\nlimited ability to personalize instruction:  chatgpt and other generative ai models can provide general \\ninformation and assistance, but  they may not be able to personalize instruction to meet the individual \\nneeds of a particular student. (ribeiro & vala, 2020)  \\nprivacy:  there are also concerns about privacy and data security when using chatgpt and other \\ngenerative ai models in education. ( ribeiro & vala, 2020).  \\nit is important to keep in mind that chatgpt and other generative ai models are powerful tools, but they \\nare not a replacement for human teachers and tutors. it is important to use these tools responsibly and \\nin conjunction with huma n instruction and support (ribeiro & vala, 2020).  \\noverall, while generative ai models such as chatgpt can be powerful tools for enhancing teaching and \\nlearning, it is important to be aware of their limitations and to use them in conjunction with other teac hing \\nmethods that emphasize human interaction and understanding (by chatgpt january 23, 2023).  \\n6. reflections and implications for practice  \\nundoubtedly, chatgpt and other generative ai is already pushing educational boundaries and initiating a \\nsignificant p aradigm shift in existing educational praxis. since its introduction to the public in 2022, educators \\nhave written extensively about potential implications for teachers, students, and policy. some educators \\nhave already started testing the efficiency of ch atgpt by integrating it in their educational activities (e.g., \\nresearch, teaching, assessment) and found that through automation of certain tasks and processes, chatgpt \\nis able to save time for other important activities like spending more time with studen ts (alshater, 2022; \\nterwiesch, 2023). for example, terwiesch who is a professor at the wharton school of the university of \\npennsylvania indicated that it usually takes 20 hours of work to create an exam and another 10 hours for tas \\nto test the exam and wri te solutions to it. however, chatgpt was able to create the exams within 10 hours \\nand reduced tas time to 5 hours. this shows 100% productivity increase in the “exam writing operation” \\n(terwiesch, 2023, p. 23). similarly, zhai (2022) stated that it took hi m 2-3 hours to conduct a study on \\nchatgpt. he said “…the entire process, including generating and trying queries, adding subtitles, and \\nreviewing and organizing the content, took 2 -3 hours” (p.9). researchers were able to ask openai’s gpt -3 to \\nwrite an aca demic paper about itself and how it works (thunstrom, 2022; preprint, gpt et al., 2022). the \\npaper was submitted to an academic journal.  \\nherft (2023) has also identified several ways teachers could use chatgpt to support and improve their ',\n",
       " 'journal of ai  \\n58 \\npedagogical and a ssessment practices. for example, teachers can leverage the capabilities of chatgpt to \\ncreate prompts for open -ended questions that align with the learning goals and success criteria of the unit \\nof instruction. additionally, chatgpt can be used to also gen erate quality rubrics that clearly and concisely \\nexplain exactly what students need to accomplish to be successful in the various required levels of \\nproficiency. again, teachers can use chatgpt to create “prompts for formative assessment activities that \\nprovide ongoing feedback to inform teaching and learning” (herft, 2023, p. 3). thus, generative ai -powered \\nassessment systems may support the integration of continuous feedback into learning processes by utilising \\ndistinctive and atypical artefacts. students  can also use chatgpt and other chatbots to support their learning. \\nfor instance, students could leverage the capacity of these advanced generative ai to provide systematic \\nexplanations of certain complex concepts. chatgpt can serve as a virtual tutor, whi ch can answer students\\' \\nquestions and provide explanations to a wide range of subjects. this can be particularly useful for students \\nwho are struggling with a particular topic or who need extra help outside of the classroom. also, studies have \\nfound that n on-native speakers of national languages and students with learning and language disabilities \\n(i.e., struggles to write well) will benefit most from these natural language models. there are a wide range of \\nstudent -centred learning approaches that can be co nstructed to be played in groups. the chatgpt and \\nrelated generative ai have the capacity to create distinct scenarios for students to collaborate to solve \\nproblems and achieve goals. in this way, students can learn from each other, which promote a sense o f \\ncommunity among leaners. arguably, chatgpt has a great potential to support and advance the work of \\neducators, students and researchers.  \\ndespite the myriad of potential educational benefits, in its current state chatgpt has been found to have \\nseveral se rious inherent limitations, such as generating wrong answers and making -up articles that do not \\nexist. for example, an author asked chatgpt to generate books and articles in a paper he is working on, \\nchatgpt included a make -up article which does not exist and even provided full bibliographic details of the \\narticle with a non -functional url (qadir, 2022). these limitations and other glitches have been reported in \\nother studies. similarly, when we asked chatgpt to discuss with references the possible drawback  of using \\nchatgpt and related generative ai in education, it fabricated a reference “ribeiro and vala, 2020” to support \\nit discussion. when we asked for chatgpt to reference the citation it stated \"a survey on generative artificial \\nintelligence\" by ribeiro  and vala, which was published in the proceedings of the 1st international conference \\non emerging trends in intelligent computing and informatics (etici 2020). deep search for ‘ribeiro and vala, \\n2020’ work revealed that there is no conference presentation by ribeiro and vala, 2020 on generative \\nartificial ai. therefore, we have reasons to believe that this was fabricated article. this confirms a tweet from \\nthe ceo of openai, sam altman, who described chatgpt as “incredibly limited, but good enough at some \\nthings to create a misleading impression of greatness. it’s a mistake to be relying on it for anything important \\nright now. it\\'s a preview of progress; we have lots of work to do on robustness and truthfulness.” (tweet on \\ndecember 11, 2022). again, a cursor y look at the chatgpt - generated responses in this study reveals that it \\nhas no idea of the world after 2021. hence it could not add any references or information after 2021. this is \\nbecause chatgpt was trained with information only up to 2021 (openai, 202 2). given these inherent \\nlimitations, educators, researchers, students and other professionals who use chatgpt and other chatbot \\nshould be cautious.  \\n7. conclusion and the way forward  \\ndespite its inherent limitations, it is a nearly undeniable fact that chatgp t and other generative ai have come \\nto stay and will continue revolutionizing the current educational system. many have called for chatgpt to be \\nbanned in the schools while others have started developing software to detect ai generated -texts (see,  \\nhttps:// writer.com/ai -content -detector/   and https://huggingface.co/roberta -base -openai -detector  ). \\nothers have also provided tips that teachers can use to prevent students from using chatgpt in writing their \\nessays and other school assignments. for example, elsen -rooney (2023) reported that the new york city ',\n",
       " \"journal of ai  \\n59 \\neducation department (nyc) has blocked chatgpt on school devices and networks so that students and \\nteachers can no longer access chatgpt.  while these various strategies may work for a while, it may not stand \\nthe test of time with even more sophisticated generative ai like gtp -5, which is anticipated to come in the \\nnot-too-distant future.  \\ncurrently, extant literature has shown that ai generated -text detectors are not effective with current \\nsophisticated natural processing language models (e.g., williams, 2023; tate, 2023). we should not lose sight \\nof the fact that students also have access to these detectors and can alter the text generated to ensure that \\nit becomes undetectable. in lieu of this, it is high time we began to accept the rapidly changing landscape in \\neducational practices and incorporate these changes in our current educational praxis. moreover, with \\nmicrosoft trying to incorporate chatgpt holistically into its products (rudolph et al., 2023; warren,  2023), in \\nno time chatgpt will be conventional, and it may possibly be too late for educational institutions to rethink \\ntheir policies and practices to guide and support their students in using chatgpt safely and constructively. \\none area that has garnered  more attention and become topical is students’ assessment. it is too soon to \\nconclude but very soon educators may need to rethink how students are assessed. they may have to change \\nhow assessment is currently done to more innovative assessments. extant li terature has demonstrated that \\nteachers have limited capacity and skills to engage in high quality assessment practices that move learning \\nforward. in lieu of this, educators have consistently called on teachers to develop capacity to engage students \\nin hi gh-quality assessment practices (earl, 2012; wiliam, 2011; willis, adie, & klenowski, 2013). through \\nprofessional capacity building, teachers could develop the skills needed to harness the power of chatgpt, \\nand other generative ai to engage in high -quality  assessment practices that improve students’ learning.  \\ngiven the increase in ai even in workspaces, integrating generative ai tools in the classroom and teaching \\nstudents how to use it constructively and safely could also prepare them to thrive in an ai -dominated work \\nenvironment after school.  therefore, educators could harness generative ai models like the chatgpt to \\nsupport students' learning. some questions need urgent answers, for example, how can we leverage chatgpt \\nto support students’ learning?  do we need to train teachers and students on how they can use current \\ngenerative ai tools to improve teaching and learning? how can we integrate generative ai tools into teacher \\neducation programs to prepare teacher candidates or pre -service teachers to effec tively use ai tools in their \\nclassrooms? will these generative ai tools close or augment existing digital divide and what is the way \\nforward? policy makers, researchers, educators and technology experts should work together and start \\nconversations on how t hese evolving generative ai tools could be used safely and constructively to improve \\neducation and support students’ learning.  \\nconflict of interest  \\nwe have no known competing financial interests or personal relationships that could have appeared to \\ninfluence the work reported in this paper.  \\ndata availability statement  \\ndata sharing not applicable to this article as no datasets were generated or analysed d uring the current study.  \\nfunding  \\nauthors received no funding  \\nreferences  \\nabukmeil, m., ferrari, s., ge novese, a., piuri, v., & scotti, f. (2021). a survey of unsupervised generative \\nmodels for exploratory data analysis and representation learning. acm computing surveys (csur), 54(5), \",\n",
       " \"journal of ai  \\n60 \\n1-40. https://doi.org/10.1145/3450963.  \\nalshater, m. (2022). exploring t he role of artificial intelligence in enhancing academic performance: a case \\nstudy of chatgpt (december 26, 2022). available at ssrn: https://ssrn.com/abstract=4312358 or \\nhttp://dx.doi.org/10.2139/ssrn.4312358  \\naltman, s. (2022, dec. 4). twitter. \\nhttps:/ /twitter.com/sama/status/1599668808285028353?s=20&t=j5ymf1tuetpequjklwakaq.  \\naydın, ö., karaarslan, e. (2022). openai chatgpt generated literature review: digital twin in healthcare.  in \\nö. aydın (ed.), emerging computer technologies 2 (pp. 22 -31). i̇zmir akademi dernegi.  \\naydın, ö., & karaarslan, e. (2023). is chatgpt leading generative ai? what is beyond expectations?  academic \\nplatform journal of engineering and smart systems . \\nbrown, t., mann, b., ryder, n., subbiah, m., kaplan, j. d., dhariwal, p., et al. (2020). language models are \\nfew-shot learners. advances in neural information processing systems, 33: 1877 -1901.  \\nchen, y., chen, y., & heffernan, n. (2020). personalized math tutoring with a conversational agent. arxiv \\npreprint arxiv:2012.12121.  \\nd'mello, s., craig, s., witherspoon, a., & graesser, a. (2014). affective and learning -related dynamics during \\ninteractions with an intelligent tutoring system. international journal  of human -computer studies, \\n72(6), 415 -435.  \\nelsen -rooney, m. (2023). nyc education department blocks chatgpt on school devices, networks. retrieved \\non january 24 2023 from https://ny.chalkbeat.org/2023/1/3/23537987/nyc -schools -ban-chatgpt -\\nwriting -artificial -intelligence .  \\nearl, l. m. (2012). assessment as learning: using classroom assessment to maximize student learning. corwin \\npress.  \\ngui, j., sun, z., wen, y., tao, d., & ye, j. (2021). a review on generative adversarial networks: algorithms, \\ntheory, an d applications. ieee transactions on knowledge and data engineering. doi: \\n10.1109/tkde.2021.3130191.  \\nherft, a. (2023).  a teacher's prompt guide to chatgpt aligned with 'what works best' guide. retrieved on \\njanuary 23 2023 from  https://drive.google.com/file/d/15qaxnuzowapwhzoakbjd8fagiozycixq/view.  \\nhu, l. (2023). generative ai and future. retrieved on january 23 from https://pub.towardsai.net/generative -\\nai-and-future -c3b1695876f2.  \\njovanović, m. (2023). generative artificial in telligence: trends and prospects. \\nhttps://www.computer.org/csdl/magazine/co/2022/10/09903869/1h0g6xvtrek.  \\n0.1109/mc.2022.3192720.  \\njohnson, m., schuster, m., le, q., krikun, m., wu, y., chen, z., ... & chen, y. (2016). google's neural machine \\ntranslatio n system: bridging the gap between human and machine translation. arxiv pre.  \",\n",
       " 'journal of ai  \\n61 \\nkim, s., park, j., & lee, h. (2019). automated essay scoring using a deep learning model. journal of \\neducational technology development and exchange, 2(1), 1 -17. \\nlucy, l., & bam man, d. (2021, june). gender and representation bias in gpt -3 generated stories. in \\nproceedings of the third workshop on narrative understanding (pp. 48 -55). \\nhttp://dx.doi.org/10.18653/v1/2021.nuse -1.5.  \\nmetz, c. (2022, dec.11). the new chatbots could cha nge the world. can you trust them? the new york times. \\nhttps://www.nytimes.com/2022/12/10/technology/ai -chat -bot-chatgpt.html.  \\nmollman, s. (2022, december 9). chatgpt has gained 1 million followers in a single week. here’s why the a.i. \\nchatbot is primed  to disrupt search as we know it. yahoo finance.  \\nhttps://finance.yahoo.com/news/chatgpt -gained -1-million -followers -\\n224523258. html?guccounter=1&guce_referrer=ahr0chm6ly9kdwnrzhvja2dvlmnvbs8&guce referr\\ner_sig=aqaaafoavt0jgmrz33m4f8lq93tu37yknp45bniru295yw5y so9pki \\nrimodofhunu3b9c9e4zfl6w1r6mszrm5sfk7y0au9ht wmkufbuhq0y254bzjvjay \\nyprr60aulpgl3xftqam81r3sop4 -qewjd1lw3avb5uvyxoyu0src7ffpu.  \\nopenai. (2022). chatgpt: optimizing language models for dialogue. openai. published november 30, 2022. \\naccessed january 17 , 2022. https://openai.com/blog/chatgpt/.  \\no’connor, s., & chatgpt. (2023). open artificial intelligence platforms in nursing education: tools for \\nacademic progress or abuse? nurse education in practice, 66, 103 -537. \\nhttps://doi.org/10.1016/j.nepr.2022.10 3537.  \\npavlik, j. v. (2023). collaborating with chatgpt: considering the implications of generative artificial \\nintelligence for journalism and media education. journalism & mass communication educator, 0(0). \\nhttps://doi.org/10.1177/10776958221149577  \\npeter sen, j. (2021). innovative assessment practices. retrieved on 2 august 2022 from \\nhttps://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahu\\nkewjhzbgo38t5ahw2hikehxpnddoqfnoecakqaq&url=https%3a%2f%2ffreshgrade.com%2fwp -\\ncontent%2f uploads%2f2020%2f07%2ffg -innovative -assessment -whitepaper -\\n1.pdf&usg=aovvaw1fwcfbstse4bqdtxt5_voi.  \\nqadir, junaid (2022): engineering education in the era of chatgpt: promise and pitfalls of generative ai for \\neducation. techrxiv. preprint. https://doi.org/ 10.36227/techrxiv.21789434.v1.  \\nrudolph, j., tan, s., & tan, s. (2023). chatgpt: bullshit spewer or the end of traditional assessments in higher \\neducation?. journal of applied learning and teaching, 6(1). https://doi.org/10.37074/jalt.2023.6.1.9.  \\ntate, t. p., doroudi, s., ritchie, d., xu, y., & uci, m. w. (2023, january 10). educational research and ai -\\ngenerated writing: confronting the coming tsunami. https://doi.org/10.35542/osf.io/4mec3.  \\nterwiesch, c. (2023). would chat gpt3 get a wharton mba?  a prediction based on its performance in the \\noperations management course. mack institute for innovation management at the wharton school: \\nuniversity of pennsylvania.  ',\n",
       " \"journal of ai  \\n62 \\nthunstrom, a. o. (2022, june 30). we asked gpt -3 to write an academic paper about itsel f- then we tried to \\nget it published. scientific american. https://www.scientificamerican.com/article/we -asked -gpt-3-to-\\nwrite -an-academic -paper -about -itself -mdash -then -we-tried -to-get-it-published/.  \\nwarren, t. (2023, january 9). microsoft is looking at o penai’s gpt for word, outlook, and powerpoint. the \\nverge, https://www.theverge.com/2023/1/9/23546144/microsoft -openai -word -powerpoint -outlook -\\ngpt-integration -rumor  \\nwilliams, c. (2023). hype, or the future of learning and teaching? 3 limits to ai's ability  to write student \\nessays. . london school of economics internet blog. https://kar.kent.ac.uk/99505/.  \\nwillis, j., adie, l., & klenowski, v. (2013). conceptualising teachers’ assessment literacies in an era of \\ncurriculum and assessment reform. the austral ian educational researcher, 40, 241 -256. \\nhttps://doi.org/10.1007/s13384 -013-0089 -9.  \\nwiliam, d. (2011). what is assessment for learning?. studies in educational evaluation, 37(1), 3-14. \\nhttps://doi.org/10.1016/j.stueduc.2011.03.001.  \\nzhai, x., (2022). cha tgpt user experience: implications for education. (december 27, 2022). available at \\nssrn: https://ssrn.com/abstract=4312418 or http://dx.doi.org/10.2139/ssrn.4312418.  \\nwang, w., chen, y., & heffernan, n. (2020). a generative model -based tutoring system for  math word \\nproblems. arxiv preprint arxiv:2010.04.  \",\n",
       " 'journal of artiﬁcial intelligence research 62 (2018) 729-754 submitted 8/17; published 7/18\\nviewpoint:\\nwhen will ai exceed human performance?\\nevidence from ai experts\\nkatja grace katja.s.grace@gmail.com\\njohn salvatier j.salvatier@gmail.com\\nai impacts, berkeley, usa\\nallan dafoe allan.dafoe@governance.ai\\nbaobao zhang baobao.zhang@yale.edu\\nowain evans owaine@gmail.com\\nfuture of humanity institute, university of oxford, uk\\nabstract\\nadvances in artiﬁcial intelligence (ai) will transform modern life by reshaping transporta-\\ntion, health, science, ﬁnance, and the military. to adapt public policy, we need to better\\nanticipate these advances. here we report the results from a large survey of machine learn-\\ning researchers on their beliefs about progress in ai. researchers predict ai will outperform\\nhumans in many activities in the next ten years, such as translating languages (by 2024),\\nwriting high-school essays (by 2026), driving a truck (by 2027), working in retail (by 2031),\\nwriting a bestselling book (by 2049), and working as a surgeon (by 2053). researchers\\nbelieve there is a 50% chance of ai outperforming humans in all tasks in 45 years and of\\nautomatingallhumanjobsin120years, withasianrespondentsexpectingthesedatesmuch\\nsoonerthannorthamericans. theseresultswillinformdiscussionamongstresearchersand\\npolicymakers about anticipating and managing trends in ai.\\n1. introduction\\nadvances in artiﬁcial intelligence (ai) will have massive social consequences. self-driving\\ntechnology might replace millions of driving jobs over the coming decade. in addition to\\npossible unemployment, the transition will bring new challenges, such as rebuilding infras-\\ntructure, protecting vehicle cyber-security, and adapting laws and regulations (calo, 2015).\\nnew challenges, both for ai developers and policy-makers, will also arise from applications\\nin law enforcement, military technology, and marketing (jiang, petrovic, ayyer, tolani, &\\nhusain, 2015). to prepare for these challenges, accurate forecasting of transformative ai\\nwould be invaluable.\\nseveral sources provide objective evidence about future ai advances: trends in com-\\nputing hardware (nordhaus, 2007), task performance (grace, 2013), and the automation\\nof labor (brynjolfsson & mcafee, 2012). the predictions of ai experts provide crucial ad-\\nditional information (baum, goertzel, & goertzel, 2011; müller & bostrom, 2016; walsh,\\n2017). we survey a large, representative sample of ai experts. our questions cover the\\ntiming of ai advances (including both practical applications of ai and the automation of\\nvarious human jobs), as well as the social and ethical impacts of ai.\\nc\\r2018 ai access foundation. all rights reserved.',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\n2. survey method\\noursurveypopulationwasallresearcherswhopublishedatthe2015nipsandicmlconfer-\\nences (two of the premier venues for peer-reviewed research in machine learning). a total of\\n352 researchers responded to our survey invitation (21% of the 1634 authors we contacted).\\nour questions concerned the timing of speciﬁc ai capabilities (e.g. folding laundry, language\\ntranslation), superiority at speciﬁc occupations (e.g. truck driver, surgeon), superiority over\\nhumans at all tasks, and the social impacts of advanced ai. see section 7 for details.\\n0.000.250.500.751.00\\n0 25 50 75 100\\nyears from 2016probability of hlmi\\naggregate forecast (with 95% confidence interval)\\nrandom subset of individual forecasts\\nloess\\nfigure 1: aggregate subjective probability of ‘high-level machine intelligence’ arrival\\nby future years . each respondent provided three data points for their forecast and these were ﬁt\\nto the gamma cdf by least squares to produce the grey cdfs. the “aggregate forecast” is the\\nmean distribution over all individual cdfs (also called the “mixture” distribution). the conﬁdence\\ninterval was generated by bootstrapping (clustering on respondents) and plotting the 95% interval\\nfor estimated probabilities at each year. the loess curve is a non-parametric regression on all\\ndata points.\\n3. time until machines outperform humans\\nai would have profound social consequences if all tasks were more cost eﬀectively accom-\\nplished by machines. our survey used the following deﬁnition:\\n730',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\n“high-levelmachineintelligence” (hlmi)isachievedwhenunaidedmachinescan\\naccomplish every task better and more cheaply than human workers.\\neach individual respondent estimated the probability of hlmi arriving in future years.\\ntaking the mean over each individual, the aggregate forecast gave a 50% chance of hlmi\\noccurring within 45 years and a 10% chance of it occurring within 9 years. figure 1 displays\\nthe probabilistic predictions for a random subset of individuals, as well as the mean predic-\\ntions. there is large inter-subject variation: figure 3 shows that asian respondents expect\\nhlmi in 30 years, whereas north americans expect it in 74 years.\\nwhile most participants were asked about hlmi, a subset were asked a logically similar\\nquestion that emphasized consequences for employment. the question deﬁned full automa-\\ntion of labor as:\\nwhen all occupations are fully automatable. that is, when for any occupation,\\nmachines could be built to carry out the task better and more cheaply than\\nhuman workers.\\nforecasts for full automation of labor were much later than for hlmi: the mean of the\\nindividual beliefs assigned a 50% probability in 122 years from now and a 10% probability\\nin 20 years.\\nrespondents were also asked when 32 “milestones” for ai would become feasible. the\\nfull descriptions of the milestone are in table c.5. each milestone was considered by a\\nrandom subset of respondents (n \\x1524). respondents expected (mean probability of 50%) 20\\nof the 32 ai milestones to be reached within ten years. fig. 2 displays timelines for a subset\\nof milestones.\\n4. intelligence explosion, outcomes, ai safety\\nthe prospect of advances in ai raises important questions. will progress in ai become\\nexplosively fast once ai research and development itself can be automated? how will high-\\nlevel machine intelligence (hlmi) aﬀect economic growth? what are the chances this will\\nlead to extreme outcomes (either positive or negative)? what should be done to help ensure\\nai progress is beneﬁcial? table c.4 displays results for questions we asked on these topics.\\nhere are some key ﬁndings:\\n1.researchers believe the ﬁeld of machine learning has accelerated in recent\\nyears.we asked researchers whether the rate of progress in machine learning was\\nfaster in the ﬁrst or second half of their career. sixty-seven percent (67%) said progress\\nwas faster in the second half of their career and only 10% said progress was faster in\\nthe ﬁrst half. the median career length among respondents was 6 years.\\n2.explosive progress in ai after hlmi is seen as possible but improbable.\\nsome authors have argued that once hlmi is achieved, ai systems will quickly become\\nvastly superior to humans in all tasks (bostrom, 2014; good, 1966). this acceleration\\nhas been called the “intelligence explosion.” we asked respondents for the probability\\nthat ai would perform vastly better than humans in all tasks two years after hlmi\\n731',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\nfigure 2: timeline of median estimates (with 50% intervals) for ai achieving human\\nperformance . timelines showing 50% probability intervals for achieving selected ai milestones.\\nspeciﬁcally, intervals represent the date range from the 25% to 75% probability of the event occur-\\nring, calculated from the mean of individual cdfs as in fig. 1. circles denote the 50%-probability\\nyear. each milestone is for ai to achieve or surpass human expert/professional performance (full\\ndescriptions in table c.5). note that these intervals represent the uncertainty of survey respondents,\\nnot estimation uncertainty.\\n732',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\nis achieved. the median probability was 10% (interquartile range: 1-25%). we also\\nasked respondents for the probability of explosive global technological improvement\\ntwo years after hlmi. here the median probability was 20% (interquartile range 5-\\n50%).\\n3.hlmi is seen as likely to have positive outcomes but catastrophic risks are\\npossible. respondents were asked whether hlmi would have a positive or negative\\nimpact on humanity over the long run. they assigned probabilities to outcomes on a\\nﬁve-point scale. the median probability was 25% for a “good” outcome and 20% for an\\n“extremely good” outcome. by contrast, the probability was 10% for a bad outcome\\nand 5% for an outcome described as “extremely bad (e.g., human extinction).”\\n4.society should prioritize research aimed at minimizing the potential risks\\nof ai.forty-eight percent of respondents think that research on minimizing the risks\\nof ai should be prioritized by society more than the status quo (with only 12% wishing\\nfor less).\\nasia (n=68)\\neurope (n=58)\\nnorth america (n=64)other regions (n=21)\\n0.000.250.500.751.00\\n0 25 50 75 100\\nyears from 2016probability of hlmiundergrad region hlmi cdfs\\nfigure 3: aggregate forecast (computed as in figure 1) for hlmi, grouped by region\\nin which respondent was an undergraduate. additional regions (middle east, s. america,\\nafrica, oceania) had much smaller numbers and are grouped as “other regions.”\\n733',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\n5. asians expect hlmi 44 years before north americans\\nfigure 3 shows big diﬀerences between individual respondents in when they predict hlmi\\nwill arrive. both citation count and seniority were not predictive of hlmi timelines (see\\nfig. b.1 and the results of a regression in table c.2). however, respondents from diﬀerent\\nregions had striking diﬀerences in hlmi predictions. fig. 3 shows an aggregate prediction\\nfor hlmi of 30 years for asian respondents and 74 years for north americans. fig. b.1\\ndisplays a similar gap between the two countries with the most respondents in the survey:\\nchina (median 28 years) and usa (median 76 years). similarly, the aggregate year for\\na 50% probability for automation of each job we asked about (including truck driver and\\nsurgeon) was predicted to be earlier by asians than by north americans (table c.2). note\\nthat we used respondents’ undergraduate institution as a proxy for country of origin and\\nthat many asian respondents now study or work outside asia.\\n6. was our sample representative?\\none concern with any kind of survey is non-response bias; in particular, researchers with\\nstrong views may be more likely to ﬁll out a survey. we tried to mitigate this eﬀect by\\nmaking the survey short (12 minutes) and conﬁdential, and by not mentioning the survey’s\\ncontent or goals in our invitation email. our response rate was 21%. to investigate possible\\nnon-response bias, we collected demographic data for both our respondents (n=406) and\\na random sample (n=399) of nips/icml researchers who did not respond. results are\\nshown in table c.3. diﬀerences between the groups in citation count, seniority, gender, and\\ncountryoforiginaresmall. whilewecannotruleoutnon-responsebiasesduetounmeasured\\nvariables, we can rule out large bias due to the demographic variables we measured. our\\ndemographic data also shows that our respondents included many highly-cited researchers\\n(mostlyinmachinelearningbutalsoinstatistics, computersciencetheory, andneuroscience)\\nand came from 43 countries (vs. a total of 52 for everyone we sampled). a majority work\\nin academia (82%), while 21% work in industry.\\na second concern is that nips and icml authors are representative of machine learning\\nbut not of the ﬁeld of artiﬁcial intelligence as a whole. this concern could be addressed in\\nfuture work by surveying a broader range of experts across computer science, robotics, and\\nthe cognitive sciences. in fact, a 2017 survey by walsh (2017) asked a broad range of ai\\nand robotics experts a question about hlmi almost identical to ours. for a 50% chance\\nof hlmi, the median prediction in this survey was 2065 for roboticists and 2061 for ai\\nexperts. our machine learning experts predicted 2057. this is very close to walsh’s results\\nand suggests that our conclusions about expert views on hlmi are robust to surveying\\nexperts outside machine learning.1it’s still possible that groups of experts diﬀer on topics\\nother than hlmi timelines.\\n1. the diﬀerence in medians between us and walsh is tiny compared to diﬀerences between asians and\\nnorth americans in our study and does not provide evidence of a substantial diﬀerence between groups\\nof experts.\\n734',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\n7. discussion\\nwhy think ai experts have any ability to foresee ai progress? in the domain of political\\nscience, a long-term study found that experts were worse than crude statistical extrapola-\\ntions at predicting political outcomes (tetlock, 2005). ai progress, which relies on scientiﬁc\\nbreakthroughs, may appear intrinsically harder to predict. yet there are reasons for op-\\ntimism. while individual breakthroughs are unpredictable, longer term progress in r&d\\nfor many domains (including computer hardware, genomics, solar energy) has been impres-\\nsively regular (farmer & lafond, 2016). such regularity is also displayed by trends (grace,\\n2013) in ai performance in sat problem solving, games-playing, and computer vision and\\ncould be exploited by ai experts in their predictions. finally, it is well established that\\naggregating individual predictions can lead to big improvements over the predictions of a\\nrandom individual (ungar et al., 2012). further work could use our data to make optimized\\nforecasts. moreover, many of the ai milestones (fig. 2) were forecast to be achieved in the\\nnext decade, providing ground-truth evidence about the reliability of individual experts.\\nacknowledgments\\nwe thank connor flexman for collecting demographic information. we also thank nick\\nbostrom for inspiring this work, and michael webb and andreas stuhlmüller for helpful\\ncomments. wethankthefutureofhumanityinstitute(oxford),thefutureoflifeinstitute,\\nand the open philanthropy project for supporting this work.\\nappendix a: supplementary information\\nthis supplement contains detailed information about the content of our survey and ﬁgures\\nand tables showing additional results.\\na.1. survey content\\nwe developed questions through a series of interviews with machine learning researchers.\\nour survey questions were as follows:\\n1. threesetsofquestionselicitinghlmipredictionsbydiﬀerentframings: askingdirectly\\nabout hlmi, asking about the automatability of all human occupations, and asking\\nabout recent progress in ai from which we might extrapolate.\\n2. three questions about the probability of an “intelligence explosion”.\\n3. one question about the welfare implications of hlmi.\\n4. a set of questions about the eﬀect of diﬀerent inputs on the rate of ai research (e.g.,\\nhardware progress).\\n5. two questions about sources of disagreement about ai timelines and “ai safety”.\\n6. thirty-two questions about when ai will achieve narrow “milestones”.\\n735',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\n7. two sets of questions on ai safety research: one about ai systems with non-aligned\\ngoals, and one on the prioritization of safety research in general.\\n8. a set of demographic questions, including ones about how much thought respondents\\nhave given to these topics in the past. the questions were asked via an online qualtrics\\nsurvey. (the qualtrics ﬁle will be shared to enable replication.) participants were in-\\nvited by email and were oﬀered a ﬁnancial reward for completing the survey. questions\\nwere asked in roughly the order above and respondents received a randomized subset\\nof questions. surveys were completed between may 3rd 2016 and june 28th 2016.\\nour goal in deﬁning “high-level machine intelligence” (hlmi) was to capture the widely-\\ndiscussed notions of “human-level ai” or “general ai” (which contrasts with “narrow ai”)\\n(bostrom, 2014). we consulted all previous surveys of ai experts and based our deﬁnition\\non that of an earlier survey (müller & bostrom, 2016). their deﬁnition of hlmi was a\\nmachinethat“cancarryoutmosthumanprofessionsatleastaswellasatypicalhuman.” our\\ndeﬁnition is more demanding and requires machines to be better at all tasks than humans\\n(while also being more cost-eﬀective). since earlier surveys often use less demanding notions\\nof hlmi, they should (all other things being equal) predict earlier arrival for hlmi.\\na.2. demographic information\\nthe demographic information on respondents and non-respondents (table c.3) was col-\\nlected from public sources, such as academic websites, linkedin proﬁles, and google scholar\\nproﬁles. citation count and seniority (i.e. numbers of years since the start of phd) were\\ncollected in february 2017.\\na.3. statistics\\nfor each timeline probability question (see figures 1 and 2), we computed an aggregate\\ndistribution by ﬁtting a gamma cdf to each individual’s responses using least squares and\\nthen taking the mixture distribution of all individuals. reported medians and quantiles\\nwere computed on this summary distribution. the conﬁdence intervals were generated by\\nbootstrapping (clustering on respondents with 10,000 draws) and plotting the 95% interval\\nforestimatedprobabilitiesateachyear. thetime-in-ﬁeldandcitationscomparisonsbetween\\nrespondents and non-respondents (table c.3) were done using two-tailed t-tests. the region\\nand gender proportions were done using two-sided proportion tests. the signiﬁcance test for\\nthe eﬀect of region on hlmi date (table c.2) was done using robust linear regression using\\nthe r function rlmfrom the mass package to do the regression and then the f.robtest\\nfunction from the sfsmisc package to do a robust f-test signiﬁcance.\\na.4. elicitation of beliefs\\nmany of our questions ask when an event will happen. for prediction tasks, ideal bayesian\\nagents provide a cumulative distribution function (cdf) from time to the cumulative prob-\\nability of the event. when eliciting points on respondents’ cdfs, we framed questions in\\ntwo diﬀerent ways, which we call “ﬁxed-probability” and “ﬁxed-years”. fixed-probability\\n736',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\nquestions ask by which year an event has an p% cumulative probability (for p=10%, 50%,\\n90%). fixed-year questions ask for the cumulative probability of the event by year y (for\\ny=10, 25, 50). the former framing was used in recent surveys of hlmi timelines; the latter\\nframing is used in the psychological literature on forecasting (tidwell, wallsten, & moore,\\n2013; wallsten, shlomi, nataf, & tomlinson, 2016). with a limited question budget, the two\\nframings will sample diﬀerent points on the cdf; otherwise, they are logically equivalent.\\nyet our survey respondents do not treat them as logically equivalent. we observed eﬀects\\nof question framing in all our prediction questions, as well as in pilot studies. diﬀerences in\\nthese two framings have previously been documented in the forecasting literature (tidwell\\net al., 2013; wallsten et al., 2016) but there is no clear guidance on which framing leads to\\nmore accurate predictions. thus we simply average over the two framings when computing\\ncdf estimates for hlmi and for tasks. hlmi predictions for each framing are shown in\\nfig. b.2.\\n737',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\nappendix b: supplementary figures\\n(a)top 4 undergraduate country hlmi cdfs\\nchina (n=36)\\nfrance (n=16)india (n=20)\\nunited states (n=53)\\n0.000.250.500.751.00\\n0 25 50 75 100\\nyears from 2016probability of hlmitop 4 undergrad country hlmi cdfs (b)time in field quantile hlmi cdfs\\nq[1] (n=57)\\nq[2] (n=40)\\nq[3] (n=55)q[4] (n=48)\\n0.000.250.500.751.00\\n0 25 50 75 100\\nyears from 2016probability of hlmitime in field quartile hlmi cdfs\\n(c)citation count quartile hlmi cdfs\\nq[1] (n=53)q[2] (n=57)\\nq[3] (n=65)\\nq[4] (n=49)0.000.250.500.751.00\\n0 25 50 75 100\\nyears from 2016probability of hlmihlmi cdf by citation count quartile\\nfigure b.1: aggregate subjective probability of hlmi arrival by demographic group.\\neach graph curve is an aggregate forecasts cdf, computed using the procedure described in figure\\n1 and in “elicitation of beliefs.” figure b.1a shows aggregate hlmi predictions for the four countries\\nwith the most respondents in our survey. figure b.1b shows predictions grouped by quartiles for\\nseniority (measured by time since they started a phd). figure b.1c shows predictions grouped by\\nquartiles for citation count. “q4” indicates the top quartile (i.e. the most senior researchers or the\\nresearchers with most citations).\\n738',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\n0.000.250.500.751.00\\n0 25 50 75 100\\nyears from 2016probability of hlmi\\nframing\\nfixed probabilities\\nfixed years\\ncombinedframing cdfs\\nfigure b.2: aggregate subjective probability of hlmi arrival for two framings of the\\nquestion. the “ﬁxed probabilities” and “ﬁxed years” curves are each an aggregate forecast for hlmi\\npredictions, computed using the same procedure as in fig. 1. these two framings of questions about\\nhlmi are explained in “elicitation of beliefs” (section a.4). the “combined” curve is an average\\nover these two framings and is the curve used in fig. 1.\\n739',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\nappendix c: supplementary tables\\nc.1. automation predictions by researcher region\\nthis question asked when automation of the job would become feasible, and cumulative\\nprobabilities were elicited as in the hlmi and milestone prediction questions. the deﬁnition\\nof “full automation” is given in section 3. for the “na/asia gap”, we subtract the asian\\nfrom the n. american median estimates.\\ntable c.1: median estimate (in years from 2016) for automation of human jobs by region of\\nundergraduate institution\\nquestion europe n. america asiana/asia gap\\nfull automation 130.8 168.6 104.2+64.4\\ntruck driver 13.2 10.6 10.2+0.4\\nsurgeon 46.4 41.0 31.4+9.6\\nretail salesperson 18.8 20.2 10.0+10.2\\nai researcher 80.0 123.6 109.0+14.6\\nc.2. regression of hlmi prediction on demographic features\\nwe standardized inputs and regressed the log of the median years until hlmi for respon-\\ndentson gender, logof citations, seniority(i.e.numbersofyearssince start ofphd),question\\nframing (“ﬁxed-probability” vs. “ﬁxed-years”) and region where the individual was an un-\\ndergraduate. we used a robust linear regression.\\ntable c.2: robust linear regression for individual hlmi predictions\\nterm estimate se t-statistic p-valuewald\\nf-\\nstatistic\\n(intercept) 3.65038 0.17320 21.07635 0.00000 458.0979\\ngender = “female” -0.25473 0.39445 -0.64578 0.55320 0.3529552\\nlog(citation_count) -0.10303 0.13286 -0.77546 0.44722 0.5802456\\nseniority (years) 0.09651 0.13090 0.73728 0.46689 0.5316029\\nframing = “ﬁxed_probs” -0.34076 0.16811 -2.02704 0.04414 4.109484\\nregion = “europe” 0.51848 0.21523 2.40898 0.01582 5.93565\\nregion = “m.east” -0.22763 0.37091 -0.61369 0.54430 0.3690532\\nregion = “n.america” 1.04974 0.20849 5.03496 0.00000 25.32004\\nregion = “other” -0.26700 0.58311 -0.45788 0.63278 0.2291022\\n740',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\nc.3. demographics of respondents vs. non-respondents\\nthere were (n=406) respondents and (n=399) non-respondents. non-respondents were ran-\\ndomly sampled from all nips/icml authors who did not respond to our survey invitation.\\nsubjects with missing data for region of undergraduate institution or for gender are grouped\\nin“na”. missingdataforcitationsandseniorityisignoredincomputingaverages. statistical\\ntests are explained in the section “statistics” (section a.3).\\ntable c.3: demographic diﬀerences between respondents and non-respondents\\nundergraduate\\nregionrespondent\\nproportionnon-\\nrespondent\\nproportionp-test p-value\\nasia 0.305 0.343 0.283\\neurope 0.271 0.236 0.284\\nmiddle east 0.071 0.063 0.721\\nnorth america 0.254 0.221 0.307\\nother 0.015 0.013 1.000\\nna 0.084 0.125 0.070\\ngender respondent\\nproportionnon-\\nrespondent\\nproportionp-test p-value\\nfemale 0.054 0.100 0.020\\nmale 0.919 0.842 0.001\\nna 0.027 0.058 0.048\\nvariable respondent es-\\ntimatenon-\\nrespondent\\nestimatestatistic p-value\\ncitations 2740.5 4528.0 2.55 0.010856\\nlog(citations) 5.9 6.4 3.19 0.001490\\nyears in ﬁeld 8.6 11.1 4.04 0.000060\\nc.4. survey responses on ai progress, intelligence explosions, and ai safety\\nthreeofthequestionsintablec.4concernstuartrussell’sargumentabouthighlyadvanced\\nai. an excerpt of the argument was included in the survey. the full argument can be found\\nhere: www.edge.org/conversation/the-myth-of-ai#26015.\\n741',\n",
       " \"grace, salvatier, dafoe, zhang, & evans\\nextremely goodon balance \\ngood neutralon balance \\nbadextremely bad \\n(e.g human\\n extinction)\\nchance hlmi has positive or negative \\nlong run impact on humanity \\n(median answers)20% 25% 20% 10% 5%\\n10% chance 50% chance 90% chance\\ntime until 'full automation of labor' 50 years 100 years 200 years\\nfirst half \\n(decelerating) about equalsecond half \\n(accelerating)\\nprogress faster in 1st or 2nd half of \\nyour career?11% 24% 65%\\n2 years after 30 years after\\nchance global technological progress \\ndramatically increases after hlmi20% 80%\\nquite likely \\n(81-100%)likely \\n(61-80%)about even \\n(41-60%)unlikely \\n(21-40%)quite unlikely \\n(0-20%)\\nchance intelligence explosion\\n argument is broadly correct12% 17% 21% 24% 26%\\nno, not a real \\nproblem.no, not an \\nimportant \\nproblem.yes, a \\nmoderately\\n important \\nproblem.yes, an \\nimportant \\nproblem.yes, among the \\nmost important \\nproblems \\nin the field.\\ndoes stuart russell's argument for\\n why highly advanced ai might pose \\na risk point at an important problem?11% 19% 31% 34% 5%\\nmuch less valuable less valuableas valuable \\nas other \\nproblems more valuablemuch more \\nvaluable\\nvalue of working on this problem now, \\ncompared to other problems in the field22% 41% 28% 7% 1.4%\\nmuch easier easieras hard as \\nother problems harder much harder\\ndifficulty of problem, relative to \\nother problems in the field7% 19% 42% 23% 10%\\nmuch less lessabout the same \\nas it is now more much more\\nhow much should society prioritize \\n'ai safety research'?\\n(included capabilities vs. \\nminimizing potential risks definition)5% 6% 41% 35% 12%\\nvery little a littlea moderate \\namount a lot a great deal\\nhow much have you thought about when \\nhlmi (or similar) will be developed?6% 27% 28% 31% 8%\\ntable c.4: median survey responses for ai progress and safety questions\\n742\",\n",
       " 'when will ai exceed human performance? evidence from ai experts\\nc.5. description of ai milestones\\nthe timelines in figure 2 are based on respondents’ predictions about the achievement of\\nvarious milestones in ai. beliefs were elicited in the same way as for hlmi predictions (see\\n“elicitation of beliefs” above). we chose a subset of all milestones to display in figure 2\\nbased on which milestones could be accurately described with a short label.\\ntable c.5: descriptions of ai milestones\\nmilestone name description nin fig. 2 median\\n(years)\\ntranslate new language\\nwith ’rosetta stone’translate a text written\\nin a newly discovered lan-\\nguage into english as well\\nas a team of human ex-\\nperts, using a single other\\ndocument in both lan-\\nguages (like a rosetta\\nstone). suppose all of\\nthe words in the text can\\nbe found in the translated\\ndocument, and that the\\nlanguage is a diﬃcult one.35 16.6\\ntranslate speech based on\\nsubtitlestranslate speech in a new\\nlanguage given only unlim-\\nited ﬁlms with subtitles in\\nthe new language. sup-\\npose the system has access\\nto training data for other\\nlanguages, of the kind used\\nnow (e.g., same text in two\\nlanguages for many lan-\\nguages and ﬁlms with sub-\\ntitles in many languages).38 10\\ntranslate (vs. amateur hu-\\nman)perform translation about\\nas good as a human who\\nis ﬂuent in both languages\\nbut unskilled at transla-\\ntion, for most types of\\ntext, and for most pop-\\nular languages (including\\nlanguages that are known\\nto be diﬃcult, like czech,\\nchinese and arabic).42x 8\\n743',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\ntelephone banking opera-\\ntorprovide phone banking\\nservices as well as human\\noperators can, without\\nannoying customers more\\nthan humans. this in-\\ncludes many one-oﬀ tasks,\\nsuch as helping to order a\\nreplacement bank card or\\nclarifying how to use part\\nof the bank website to a\\ncustomer.31x 8.2\\nmake novel categories correctly group images of\\npreviously unseen objects\\ninto classes, after training\\nonasimilarlabeleddataset\\ncontaining completely dif-\\nferent classes. the classes\\nshouldbesimilartotheim-\\nagenet classes.29 7.4\\n744',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\none-shot learning one-shotlearning: seeonly\\none labeled image of a new\\nobject, and then be able\\nto recognize the object in\\nreal world scenes, to the\\nextent that a typical hu-\\nman can (i.e. including in\\na wide variety of settings).\\nfor example, see only one\\nimage of a platypus, and\\nthen be able to recognize\\nplatypuses in nature pho-\\ntos. the system may train\\non labeled images of other\\nobjects.\\ncurrently, deep networks\\noften need hundreds of\\nexamples in classiﬁcation\\ntasks[1], but there has been\\nwork on one-shot learning\\nfor both classiﬁcation[2]\\nand generative tasks[3].\\n[1] lake et al. (2015).\\nbuilding machines that\\nlearn and think like peo-\\nple\\n[2] koch (2015) siamese\\nneural networks for one-\\nshot image recognition\\n[3] rezende et al. (2016).\\none-shotgeneralizationin\\ndeep generative models32 9.4\\n745',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\ngenerate video from new\\ndirectionseeashortvideoofascene,\\nand then be able to con-\\nstruct a 3d model of the\\nscene good enough to cre-\\nate a realistic video of the\\nsame scene from a substan-\\ntially diﬀerent angle.\\nfor example, constructing\\na short video of walking\\nthrough a house from a\\nvideo taking a very dif-\\nferent path through the\\nhouse.42 11.6\\ntranscribe speech transcribe human speech\\nwith a variety of accents in\\nanoisyenvironmentas well\\nas a typical human can.33x 7.8\\nread text aloud (text-to-\\nspech)take a written passage and\\noutput a recording that\\ncan’t be distinguished from\\na voice actor, by an expert\\nlistener.43x 9\\nmath research routinely and au-\\ntonomously prove mathe-\\nmatical theorems that are\\npublishable in top math-\\nematics journals today,\\nincluding generating the\\ntheorems to prove.31x 43.4\\nputnam math competi-\\ntionperform as well as the\\nbest human entrants in the\\nputnam competition—a\\nmath contest whose\\nquestions have known\\nsolutions, but which are\\ndiﬃcult for the best young\\nmathematicians.45x 33.8\\n746',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\ngo (same training as hu-\\nman)defeat the best go players,\\ntraining only on as many\\ngames as the best go play-\\ners have played.\\nfor reference, deepmind’s\\nalphago has probably\\nplayed a hundred million\\ngames of self-play, while\\nlee sedol has probably\\nplayed 50,000 games in his\\nlife[1].\\n[1] lake et al. (2015).\\nbuilding machines that\\nlearn and think like peo-\\nple42x 17.6\\nstarcraft beat the best human star-\\ncraft 2 players at least 50\\nstarcraft 2 is a real time\\nstrategy game character-\\nized by:\\n\\x0fcontinuous time play\\n\\x0fhuge action space\\n\\x0fpartial observability\\nof enemies\\n\\x0flong term strategic\\nplay, e.g. preparing\\nfor and then hiding\\nsurprise attacks.24x 6\\nquick novice play at ran-\\ndom gameplay a randomly selected\\ncomputer game, including\\ndiﬃcult ones, about as well\\nas a human novice, after\\nplaying the game less than\\n10 minutes of game time.\\nthe system may train on\\nother games.44 12.4\\n747',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\nangry birds play new levels of an-\\ngry birds better than the\\nbest human players. angry\\nbirds is a game where play-\\nerstrytoeﬃcientlydestroy\\n2d block towers with a cat-\\napult. for context, this is\\nthe goal of the ijcai an-\\ngry birds ai competition.39x 3\\nall atari games outperform professional\\ngame testers on all atari\\ngames using no game-\\nspeciﬁc knowledge. this\\nincludes games like frost-\\nbite, which require plan-\\nning to achieve sub-goals\\nand have posed problems\\nfor deep q-networks[1][2].\\n[1] mnih et al. (2015).\\nhuman-level control\\nthrough deep reinforce-\\nment learning.\\n[2] lake et al. (2015).\\nbuilding machines that\\nlearn and think like peo-\\nple38x 8.8\\n748',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\nnovice play at half of atari\\ngames in 20 minutesoutperform human novices\\non 50% of atari games\\nafter only 20 minutes of\\ntraining play time and no\\ngame speciﬁc knowledge.\\nfor context, the origi-\\nnal atari playing deep q-\\nnetwork outperforms pro-\\nfessional game testers on\\n47% of games[1], but used\\nhundreds of hours of play\\nto train[2].\\n[1] mnih et al. (2015).\\nhuman-level control\\nthrough deep reinforce-\\nment learning.\\n[2] lake et al. (2015).\\nbuilding machines that\\nlearn and think like peo-\\nple33 6.6\\nfold laundry fold laundry as well and as\\nfast as the median human\\nclothing store employee.30x 5.6\\n5km race in city (bipedal\\nrobot vs. human)beat the fastest human\\nrunners in a 5 kilometer\\nrace through city streets\\nusing a bipedal robot body.28x 11.8\\nassemble any lego physically assemble any\\nlego set given the pieces\\nand instructions, using\\nnon- specialized robotics\\nhardware.\\nfor context, fu 2016[1]\\nsuccessfully joins single\\nlarge lego pieces using\\nmodel based reinforce-\\nment learning and online\\nadaptation.\\n[1] fu et al. (2016). one-\\nshot learning of manip-\\nulation skills with online\\ndynamics adaptation and\\nneural network priors35x 8.4\\n749',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\nlearn to sort big numbers\\nwithout solution formlearn to eﬃciently sort\\nlists of numbers much\\nlarger than in any train-\\ning set used, the way\\nneural gpus can do for\\naddition[1], but without\\nbeing given the form of the\\nsolution.\\nfor context, neural tur-\\ning machines have not\\nbeen able to do this[2],\\nbut neural programmer-\\ninterpreters[3] have been\\nable to do this by train-\\ning on stack traces (which\\ncontain a lot of information\\nabout the form of the solu-\\ntion).\\n[1] kaiser & sutskever\\n(2015). neural gpus\\nlearn algorithms\\n[2] zaremba & sutskever\\n(2015). reinforcement\\nlearning neural turing\\nmachines\\n[3] reed & de fre-\\nitas (2015). neural\\nprogrammer-interpreters44 6.2\\n750',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\npython code for simple\\nalgorithmswrite concise, eﬃcient,\\nhuman-readable python\\ncode to implement simple\\nalgorithms like quicksort.\\nthat is, the system should\\nwrite code that sorts a list,\\nrather than just being able\\nto sort lists.\\nsuppose the system is\\ngiven only:\\n\\x0fa speciﬁcation of\\nwhat counts as a\\nsorted list\\n\\x0fseveral examples of\\nlists undergoing sort-\\ning by quicksort36 8.2\\nanswer factoid questions\\nvia internetanswer any “easily\\ngoogleable” factoid ques-\\ntions posed in natural\\nlanguage better than an\\nexpert on the relevant\\ntopic (with internet ac-\\ncess), having found the\\nanswers on the internet.\\nexamples of factoid ques-\\ntions:\\n\\x0f“what is the poi-\\nsonous substance in\\noleander plants?”\\n\\x0f“how many species of\\nlizardcanbefoundin\\ngreat britain?”46 7.2\\n751',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\nanswer open-ended fac-\\ntual questions via internetanswer any “easily\\ngoogleable” factual but\\nopen ended question posed\\nin natural language better\\nthan an expert on the rel-\\nevant topic (with internet\\naccess), having found the\\nanswers on the internet.\\nexamples of open ended\\nquestions:\\n\\x0f“what does it mean\\nif my lights dim when\\ni turn on the mi-\\ncrowave?”\\n\\x0f“when does home in-\\nsurance cover roof re-\\nplacement?\"38 9.8\\nanswer questions without\\ndeﬁnite answersgive good answers in nat-\\nural language to factual\\nquestions posed in natural\\nlanguage for which there\\nare no deﬁnite correct an-\\nswers.\\nforexample: “whatcauses\\nthe demographic transi-\\ntion?”, “is the thylacine ex-\\ntinct?”, “how safe is seeing\\na chiropractor?”47 10\\nhigh school essay write an essay for a high-\\nschool history class that\\nwould receive high grades\\nand pass plagiarism detec-\\ntors.\\nforexampleansweraques-\\ntion like “how did the\\nwhaling industry aﬀect the\\nindustrial revolution?”42x 9.6\\n752',\n",
       " 'when will ai exceed human performance? evidence from ai experts\\ngenerate top 40 pop song compose a song that is\\ngood enough to reach the\\nus top 40. the system\\nshouldoutputthecomplete\\nsong as an audio ﬁle.38x 11.4\\nproduce a song indistin-\\nguishable from one by a\\nspeciﬁc artistproduce a song that is in-\\ndistinguishable from a new\\nsong by a particular artist,\\ne.g., a song that experi-\\nenced listeners can’t distin-\\nguish from a new song by\\ntaylor swift.41 10.8\\nwrite new york times\\nbest-sellerwriteanovelorshortstory\\ngood enough to make it to\\nthe new york times best-\\nseller list.27x 33\\nexplain own actions in\\ngamesfor any computer game\\nthat can be played well by\\na machine, explain the ma-\\nchine’s choice of moves in a\\nway that feels concise and\\ncomplete to a layman.38x 10.2\\nworld series of poker play poker well enough to\\nwin the world series of\\npoker.37x 3.6\\noutput physical laws of\\nvirtual worldafter spending time in a\\nvirtual world, output the\\ndiﬀerential equations gov-\\nerning that world in sym-\\nbolic form.\\nfor example, the agent is\\nplaced in a game engine\\nwhere newtonian mechan-\\nics holds exactly and the\\nagent is then able to con-\\nduct experiments with a\\nball and output newton’s\\nlaws of motion.52 14.8\\n753',\n",
       " 'grace, salvatier, dafoe, zhang, & evans\\nreferences\\nbaum, s. d., goertzel, b., & goertzel, t. g. (2011). how long until human-level ai? results\\nfrom an expert assessment. technological forecasting and social change ,78(1), 185–\\n195.\\nbostrom, n. (2014). superintelligence: paths, dangers, strategies . oxford, uk: oxford\\nuniversity press.\\nbrynjolfsson, e., & mcafee, a. (2012). race against the machine: how the digital rev-\\nolution is accelerating innovation, driving productivity, and irreversibly transforming\\nemployment and the economy . lexington, ma: digital frontier press.\\ncalo, r. (2015). robotics and the lessons of cyberlaw. california law review ,103, 513.\\nfarmer, j. d., & lafond, f. (2016). how predictable is technological progress? research\\npolicy,45(3), 647–665.\\ngood, i. j. (1966). speculations concerning the ﬁrst ultraintelligent machine. advances in\\ncomputers ,6, 31–88.\\ngrace, k. (2013). algorithmic progress in six domains (tech. rep.). machine intelligence\\nresearch institute.\\njiang, t., petrovic, s., ayyer, u., tolani, a., & husain, s. (2015). self-driving cars:\\ndisruptive or incremental. applied innovation review ,1, 3–22.\\nmüller, v. c., & bostrom, n. (2016). future progress in artiﬁcial intelligence: a survey\\nof expert opinion. in v. c. müller (ed.), fundamental issues of artiﬁcial intelligence\\n(pp. 553–570). springer.\\nnordhaus, w. d. (2007). two centuries of productivity growth in computing. the journal\\nof economic history ,67(01), 128–159.\\ntetlock, p. (2005). expert political judgment: how good is it? how can we know? princeton,\\nnj: princeton university press.\\ntidwell, j. w., wallsten, t. s., & moore, d. a. (2013). eliciting and modeling probability\\nforecasts of continuous quantities. (paper presented at the 27th annual conference of\\nsociety for judgement and decision making, boston, ma, 19 november 2016.)\\nungar, l., mellors, b., satopää, v., baron, j., tetlock, p., ramos, j., & swift, s. (2012).\\nthe good judgment project: a large scale test (tech. rep.). association for the ad-\\nvancement of artiﬁcial intelligence technical report.\\nwallsten, t. s., shlomi, y., nataf, c., & tomlinson, t. (2016). eﬃciently encoding and\\nmodelingsubjectiveprobabilitydistributionsforquantitativevariables. decision ,3(3),\\n169.\\nwalsh, t. (2017). expert and non-expert opinion about technological unemployment. arxiv\\npreprint arxiv:1706.06906 .\\n754',\n",
       " 'nber working paper series\\nharms of ai\\ndaron acemoglu\\nworking paper 29247\\nhttp://www.nber.org/papers/w29247\\nnational bureau of economic research\\n1050 massachusetts avenue\\ncambridge, ma 02138\\nseptember 2021\\nprepared for the oxford handbook of ai governance. i am grateful to many co-authors who \\nhave contributed to my thinking on these topics and on whose work i have heavily relied in this \\nessay. they include: david autor, jonathon hazell, simon johnson, jon kleinberg, anton \\nkorniek, azarakhsh malekian, ali makhdoumi, andrea manera, sendhil mullainathan, andrew \\nnewman, asu ozdaglar,  pascual restrepo and james siderius. i am grateful to david autor, \\nlauren fahey, vincent rollet,  james siderius and glen weyl for comments. i gratefully \\nacknowledge financial support from google, the hewlett foundation, the nsf, the sloan \\nfoundation, the smith richardson foundation, and the schmidt sciences foundation. the views \\nexpressed herein are those of the author and do not necessarily  reflect the views of the national \\nbureau of economic research.\\nnber working papers are circulated for discussion and comment purposes. they have not been \\npeer-reviewed or been subject to the review by the nber board of directors that accompanies \\nofficial nber publications.\\n© 2021 by daron acemoglu. all rights reserved. short sections of text, not to exceed two \\nparagraphs, may be quoted without explicit permission provided that full credit, including © \\nnotice, is given to  the source.',\n",
       " \"harms of ai\\ndaron acemoglu\\nnber working paper no. 29247\\nseptember 2021\\njel no. j23,j31,l13,l40,o33,p16\\nabstract\\nthis essay discusses several potential economic, political and social costs of the current path of \\nai technologies. i argue that if ai continues to be deployed along its current trajectory and \\nremains unregulated,  it may produce various social, economic and political harms. these include: \\ndamaging competition,  consumer privacy and consumer choice; excessively automating work, \\nfueling inequality, inefficiently  pushing down wages, and failing to improve worker productivity; \\nand damaging political discourse, democracy's most fundamental lifeblood. although there is no \\nconclusive evidence suggesting that  these costs are imminent or substantial, it may be useful to \\nunderstand them before they are fully realized  and become harder or even impossible to reverse, \\nprecisely because of ai's promising and wide-reaching  potential. i also suggest that these costs \\nare not inherent to the nature of ai technologies, but are related  to how they are being used and \\ndeveloped at the moment - to empower corporations and governments against workers and \\ncitizens. as a result, efforts to limit and reverse these costs may need to rely on regulation and \\npolicies to redirect ai research. attempts to contain them just by promoting competition  may be \\ninsufficient.\\ndaron acemoglu\\ndepartment of economics, e52-446\\nmassachusetts institute of technology\\n77 massachusetts avenue\\ncambridge, ma 02139\\nand nber\\ndaron@mit.edu\",\n",
       " '1 introduction\\nto many commentators, arti\\x85cial intelligence (ai) is the most exciting technology of our age,\\npromising the development of \\x93intelligent machines\\x94that can surpass humans in various tasks,\\ncreate new products, services and capabilities, and even build machines that can improve\\nthemselves, perhaps eventually beyond all human capabilities. the last decade has witnessed\\nrapid progress in ai, based on the application of modern machine learning techniques and\\nhuge amounts of computational power to massive, often unstructured data sets (e.g., russell\\nand norvig, 2009, neapolitan and jiang, 2018, russell, 2019).1ai algorithms are now used\\nby almost all online platforms and in industries that range from manufacturing to health,\\n\\x85nance, wholesale and retail (e.g., ford, 2015; agarwal, gans and goldfarb, 2018; west,\\n2018). government agencies have also started relying on ai, especially in the criminal justice\\nsystem and in customs and immigration control (thompson, 2019; simonite, 2020).\\nwhether ai will be everything its enthusiastic creators and boosters dream, it is likely\\nto have transformative e¤ects on the economy, society and politics in the decades to come,\\nand some of these are already visible in ai algorithms\\x92impact on social media, data markets,\\nmonitoring of workers and work automation. like many technological platforms (or \\x93general\\npurpose technologies\\x94 ) that can be used for the development of a variety of new products,\\nservices, and production techniques, there are a lot of choices about how ai technologies will\\nbe developed. this, combined with the pervasive e¤ects of ai throughout society, makes it\\nparticularly important that we consider its potential dark side as well.\\nin this essay, i will focus on three broad areas in which the deployment of ai technologies\\nmay have economic and social costs \\x97 if not properly regulated. i want to emphasize at\\nthe outset that the arguments i will present are theoretical , and currently there is insu¢ cient\\nempirical evidence to determine whether the mechanisms i isolate are important in practice.\\nthe spirit of the exercise is to understand the potential harms unregulated ai may create so\\nthat we have a better understanding of how we should track and regulate its progress.\\nthe areas i will focus on are:\\n1.collection and control of information . i will argue that the combination of the\\n1the \\x85eld of \\x93ai\\x94 today is dominated by the suite of current arti\\x85cial intelligence technologies and ap-\\nproaches, mostly based on statistical pattern recognition, machine learning and big data methods. the poten-\\ntial harms of ai i discuss in this paper are relevant for and motivated by these approaches. nevertheless, i will\\nalso emphasize that \\x93ai\\x94 should be thought of as a broad technological platform, precisely because the gen-\\neral aspiration to produce \\x93machine intelligence\\x94includes e¤orts to improve machines in order to complement\\nhumans, create new tasks and services, and generate novel communication and collaboration possibilities.\\n1',\n",
       " 'demand of ai technologies for data and the ability of ai techniques for processing vast\\namounts of data about users, consumers and citizens produces a number of potentially\\ntroubling downsides. these include: (a) privacy violation: companies and platforms may\\ncollect and deploy excessive amounts of information about individuals, enabling them to\\ncapture more of the consumer surplus via price discrimination or violate their privacy in\\nprocessing and using their data; (b) unfair competition : companies with more data may\\ngain a strong advantage relative to their competitors, which both enables them to extract\\nmore surplus from consumers and also relaxes price competition in the marketplace, with\\npotentially deleterious e¤ects; and (c) behavioral manipulation: data and sophisticated\\nmachine learning techniques may enable companies to identify and exploit biases and\\nvulnerabilities that consumers themselves do not recognize, thus pushing consumers to\\nlower levels of utility and simultaneously distorting the composition of products in the\\nmarket.\\n2.labor market e¤ects of ai . i will argue that even before ai there was too much\\ninvestment in cutting labor costs and wages in the us (and arguably in some other\\nadvanced economies as well). such e¤orts may be excessive either because, in attempting\\nto cut costs, they reduce production e¢ ciency, or because they create non-market e¤ects\\n(for example, on workers losing their jobs or being forced to take lower-pay work). ai, as\\na broad technological platform, could have in principle recti\\x85ed this trend, for example,\\nby promoting the creation of new labor-intensive tasks or by providing tools for workers to\\nhave greater initiative. this does not seem to have taken place. for example, automation\\nis a quintessential example of e¤orts to cut labor costs, and like other e¤orts, it may be\\nexcessive. many current uses of ai involve automation of work or the deployment of\\nai in order to improve monitoring and keep wages low, motivating my belief that ai\\nmay be exacerbating the excessive e¤orts to reduce labor costs. in this domain, i focus\\non four broad areas: (a) automation : i explain why automation, a powerful way to\\nreduce labor costs, can be part of the natural growth process of an economy, but it\\ncan also be excessive, because \\x85rms do not take into account the negative impact of\\nautomation on workers; (b) composition of technology : problems of excessive automation\\nintensify when \\x85rms have a choice between investing in automation versus new tasks,\\nand i explain why this margin of technology choice may be severely distorted, and how\\nai-type technologies may further distort this composition; (c) loss of economies of scope\\nin human judgment : in contrast to the hope that ai will take over routine tasks and in\\n2',\n",
       " 'the process enable humans to specialize in problem-solving and creative tasks, ai-human\\ninterplay might gradually turn humans into worse decision-makers as they hand more and\\nmore decisions to machines, especially when there are economies of scope across tasks;\\nand (d) monitoring : i also explain how technologies like ai that increase the monitoring\\nability of employers are very attractive to \\x85rms, but may at the same time generate\\nsigni\\x85cant social ine¢ ciencies.\\n3.ai, communication and democracy. i will \\x85nally suggest that ai has also exac-\\nerbated various political and social problems related to communication, persuasion and\\ndemocratic politics that, once again, predate the onset of this technology. the main\\nconcern here is that democratic politics may have become more di¢ cult, or even funda-\\nmentally \\x87 awed, under the shadow of ai. i focus on: (a) echo chambers in social media :\\nhow ai-powered social media generates echo chambers that propagate false information\\nand polarize society; (b) problems of online communication : i suggest that online social\\nmedia, which is interwoven with ai, creates additional misalignments related to private\\ncommunication; (c) big brother e¤ects : ai increases the ability of governments to closely\\nmonitor and stamp out dissent. all of these e¤ects of ai are, by their nature, damaging,\\nbut may have their most consequential e¤ects by impairing democratic discourse; and\\n(d)automation and democracy: \\x85nally, i suggest that the process of automation may\\nfurther damage democracy by making workers less powerful and less indispensable in\\nworkplaces.\\nin each one of the above instances, i discuss the basic ideas about potential costs and, when\\nappropriate, i present some of the modeling details (in some cases based on existing work and in\\nothers as ideas for future exploration). throughout, my approach will be informal, attempting\\nto communicate the main ideas rather than providing the full details of the relevant models.\\nin addition, i will point out the relevant context and evidence in some cases, even though,\\nas already noted, we do not have su¢ cient evidence to judge whether most of the mechanisms\\ni am exploring here are likely to be important in practice. i then discuss the common aspects\\nof the potential harms from ai and explore their common roots. i also argue that these costs,\\nif proved important, cannot be avoided in an unregulated market. in fact, i will suggest that in\\nmany of these instances, greater competition may exacerbate the problem rather than resolving\\nit.\\nthe aforementioned list leaves out several other concerns experts have expressed (ai leading\\n3',\n",
       " 'to evil super intelligence or ai\\x92 s e¤ects on war and violence), mostly because of space restric-\\ntions and also partly because they are further away from my area of expertise. i mention them\\nbrie\\x87 y in section 5.\\nthe long list of mechanisms via which ai could have negative economic, political and social\\ne¤ects may create the impression that this technological platform is bound to have disastrous\\nsocial consequences, or it may suggest that some of these problems are solely created by ai.\\nneither is true. nor am i particularly opposed to this technology. i believe that ai is a hugely\\npromising technological platform. furthermore, with or without ai, our society has deep\\nproblems related to the power of corporations, automation and labor relations, and polarization\\nand democracy. ai exacerbates these problems, because it is a powerful technology and, owing\\nto its general-purpose nature and ambition, it is applicable in a wide array of industries and\\ndomains, which ampli\\x85es its ability to deepen existing fault lines. these qualities make the\\npotential negative e¤ects of ai quite di¢ cult to foresee as well. perhaps even more than\\nwith other technologies and technological platforms, there are many di¤erent directions, with\\nhugely di¤erent consequences, in which ai can be developed. this makes it doubly important\\nto consider the costs that it might create. it also makes it vital to think about the direction\\nof development of this technology.\\nindeed, my point throughout is that ai\\x92 s costs are avoidable, and if they were to tran-\\nspire, this would be because of the choices made and the direction of research pursued by ai\\nresearchers and tech companies. they would also be due to the lack of appropriate regulation\\nby government agencies and societal pressure to discourage nefarious uses of the technology\\nand to redirect research away from them. this last point is important: again like most other\\ntechnologies, but only more so, the direction of research of ai will have major distributional\\nconsequences and far-ranging implications for power, politics, and social status in society, and\\nit would be naïve to expect that unregulated markets would make the right trade-o¤s about\\nthese outcomes \\x97 especially since, at the moment the major decisions about the future of ai\\nare being made by a very small group of top executives and engineers in a handful of com-\\npanies. put di¤erently, ai\\x92 s harms are harms of unregulated ai. but in order to understand\\nwhat needs to be regulated and what the socially optimal choices may be, we \\x85rst need to\\nsystematically study what the downside of this technology may be. it is in this spirit that this\\ncurrent essay is written.\\nthe rest of this essay is organized as follows. in section 2 i start with the e¤ects that ai cre-\\nates via the control of information. section 3 moves to discuss ai\\x92 s labor market implications.\\n4',\n",
       " 'section 4 turns to the e¤ects of this technological platform on social communication, polariza-\\ntion and democratic politics. section 5 brie\\x87 y touches upon a few other potential unintended\\nconsequences of ai technologies. section 6 steps back and discusses the role of choice in this\\nprocess. i explain why the direction of technological change in general, and the direction of ai\\nresearch in particular, is vital, and how we should think about it. this section also reiterates\\nthat many of the costs mentioned in the preceding sections are the result of choices made\\nabout the development and use of ai technologies in speci\\x85c directions. it then builds on the\\nmechanisms discussed in previous sections to emphasize that unregulated markets are unlikely\\nto internalize ai\\x92 s costs and how greater competition may sometimes make things worse, and\\nnor are unfettered markets likely to direct technological change towards higher social value\\nuses of ai. in this spirit, this section also provides some ideas about how to regulate the use\\nof ai and the direction of ai research. section 7 concludes.\\n2 ai and control of information\\ndata are the lifeblood of ai. the currently-dominant approach in this area is based on turning\\ndecision problems into prediction tasks and apply machine learning tools to very large data\\nsets in order to perform these tasks. hence, most ai researchers and economists working on ai\\nand related technologies start from the premise that data create positive e¤ects on prediction,\\nproduct design and innovation (e.g., brynjolfsson and mcafee, 2019; jones and tonetti, 2020;\\nvarian, 2009; farboodi et al., 2019). however, as emphasized by several legal scholars and\\nsocial scientists, data and information can be misused \\x97 deployed in exploitative ways that\\nbene\\x85t digital platforms and tech companies at the expense of consumers and workers (e.g.,\\npasquale, 2015, zubo¤, 2019). zubo¤, for example, argues that such exploitative use of data\\nis at the root of the recent growth of the tech industry, which \\x93claims human experience as\\nfree raw material for hidden commercial practice process of extraction, prediction, and sales.\\x94\\n(2019, p. 8).\\nin this section, i discuss social costs of ai related to the control of data and information,\\nwith a special emphasis on exploring when data can become a tool for excessive extraction and\\nprediction.\\n5',\n",
       " '2.1 too much data\\nconcerns about control and misuse of information become particularly important when there\\nare bene\\x85ts to individuals from \\x93privacy\\x94 . individuals may value privacy for instrumental or\\nintrinsic reasons. the former includes their ability to enjoy greater consumer surplus, which\\nmight be threatened if companies know more about their valuations and can charge them\\nhigher prices. the latter includes various characteristics and behaviors that individuals would\\nprefer not to reveal to others. this could be for reasons that are economic (e.g., to avoid\\ntargeted ads), psychological (e.g., to maintain a degree of autonomy), social (e.g., to conceal\\ncertain behaviors from acquaintances), or political (e.g., to avoid persecution).\\nstandard economic analyses tend to view these privacy-related costs as second-order for\\ntwo related reasons: if individuals are rational and are given decision rights, then they will\\nonly allow their data to be used when they are compensated for it adequately, and this would\\nensure that data will be used by companies only when their bene\\x85ts exceed the privacy costs\\n(e.g., varian, 2009; jones and tonetti, 2020). secondly, in surveys individuals appear to be\\nwilling to pay only little to protect their privacy, and hence the costs may be much smaller\\nthan the bene\\x85ts of data (e.g., athey et al., 2017). yet these arguments have limited bite\\nwhen the control of data has a \\x93social\\x94dimension \\x97 meaning that when an individual shares\\nher data, she is also providing information about others. this social dimension is present, by\\ndefault, in almost all applications of ai, since the use of data is speci\\x85cally targeted at learning\\nfrom like-cases in order to generalize and apply the lessons to other settings.\\nhow does this social dimension of data a¤ect the costs and bene\\x85ts of data? this is\\na question tackled in a series of papers, including maccarthy (2010), choi, jeon and kim\\n(2019), acemoglu et al. (2021) and bergemann et al. (2021), and here i base my discussion on\\nacemoglu et al. (2021). the social dimension of data introduces two interrelated e¤ects. first,\\nthere will be data externalities \\x97 when an individual shares her data, she reveals information\\nabout others. to the extent that data is socially valuable and individuals do not internalize\\nthis, data externalities could be positive. but if indirect data revelation impacts the privacy\\nof other individuals, these externalities could be negative. the second e¤ect is what acemoglu\\net al. call submodularity : when an individual shares her data and reveals information about\\nothers, this reduces the value of others\\x92information both to themselves and to potential data\\nbuyers (such as platforms or ai companies). this is for the simple reason that when more\\ninformation is shared about an individual, the less important the individual\\x92 s own data become\\nfor predicting his or her decisions.\\n6',\n",
       " 'acemoglu et al. (2021) model this in the following fashion. consider a community con-\\nsisting ofnagents/users interacting on a (monopoly) digital platform. each agent ihas a\\ntype denoted by xiwhich is a realization of a random variable xi, where the vector of random\\nvariables x= (x1;:::;xn)has a joint normal distribution n(0;\\x06), with covariance matrix\\n\\x062rn\\x02n(and \\x06ii=\\x1b2\\ni>0denoting the variance of individual i\\x92 s type). each user has\\nsome personal data, si, which are informative about her type. personal data include both\\ncharacteristics that are the individual\\x92 s private information (unless she decides to share) and\\nalso data that she generates via her activity online and o¤-line. suppose si=xi+ziwhere\\nziis a normally-distributed independent random variable, zi\\x18n(0;1).\\nalthough acemoglu et al. (2021) discuss various metrics, here i suppose that the relevant\\nnotion of information is mean square error (mse). then we can de\\x85ne leaked information\\nabout user ias the reduction in the mean square error of the best estimator of her type:\\nii(a) =\\x1b2\\ni\\x00min\\n^xie\\x02\\n(xi\\x00^xi(sa))2\\x03\\n;\\nwhere sis the vector of data the platform acquires, ^xi(s)is the platform\\x92 s estimate of the\\nuser\\x92 s type given this information, and a= (a1;:::;an)is the data-sharing action pro\\x85le of\\nusers (with ai= 0denoting no direct data-sharing and ai= 1corresponding to data-sharing).\\nthen, the objective of the platform is to maximize\\nx\\ni[\\x11ii(a)\\x00aipi];\\nwherepidenotes payment (\\x93price\\x94 ) to user ifrom the platform, which is made only when the\\nindividual in question shares her data directly (i.e., ai= 1), and\\x11 >0. the price could take\\nthe form of an actual payment for data shared or an indirect payment by the platform, for\\nexample, the provision of some free service or customization. this speci\\x85cation embeds the\\nidea that the platform would like to acquire data in order to better forecast the type/behavior\\nof users.\\nuseri\\x92 s objective is di¤erent. she may wish to protect her privacy and she obviously\\nbene\\x85ts from payments she receives. thus her objective is to maximize:\\n\\rx\\ni06=iii0(a)\\x00viii(a) +aipi:\\nthe \\x85rst term represents any positive direct externalities from the information of other users\\n(for example, because this improves the quality of services that the individual receives and\\n7',\n",
       " 'does not fully pay for) and thus \\r\\x150. the second term is the loss of privacy (capturing both\\ninstrumental and intrinsic values of privacy). hence vi\\x150here denotes the value of privacy\\nto useri. finally, the last term denotes the payments she receives from the platform.\\nthis framework allows data to create positive or negative total bene\\x85ts. to illustrate this\\npoint, suppose that vi=v. in that case, data create aggregate (utilitarian) bene\\x85ts provided\\nthat\\x11+\\r(n\\x001)>v. in contrast, if \\x11+\\r(n\\x001)<v, the corporate control and use of data\\nis socially wasteful (it creates more damage than good). but even in this case, as we will see,\\nthere may be data transactions and extensive use of data. in general, because vidi¤ers across\\nagents, data about certain users may generate greater social bene\\x85ts than the costs, while the\\nrevelation of data about others may be excessively costly.\\nin terms of market structure, the simplest option is to assume that the platform makes\\ntake-it-or-leave-it o¤ers to users in order to acquire their data.\\na key result proved in acemoglu et al. (2021) is that ii(a)is monotone and submodular.\\nthe \\x85rst property means that when an individual directly shares her data, this weakly increases\\nthe information that the platform has about all individuals, i.e., ii(a0)\\x15ii(a)whenever a0\\x15a.\\nmathematically, the second implies that ,for two action pro\\x85les aanda0witha0\\n\\x00i\\x15a\\x00i, we\\nhave\\nii(ai= 1;a\\x00i)\\x00ii(ai= 0;a\\x00i)\\x15ii(ai= 1;a0\\n\\x00i)\\x00ii(ai= 0;a0\\n\\x00i):\\neconomically, it means that the information transmitted by an individual directly sharing her\\ndata is less when there is more data-sharing by others.\\ni now illustrate the implications of this setup for data sharing and welfare using two simple\\nexamples. consider \\x85rst a platform with two users, i= 1,2, and suppose that \\r= 0,\\x11= 1,\\nandv1<1so that the \\x85rst user has a small value of privacy, but v2>1, implying that because\\nof strong privacy concerns, it is socially bene\\x85cial not to have user 2\\x92 s data be shared with\\nthe platform. finally, suppose that the correlation coe¢ cient between the data of the two\\nusers is\\x1a >0. sincev1<1, the platform will always purchase user 1\\x92 s data. but this also\\nimplies that it will indirectly learn about user 2 given the correlation between the two users\\x92\\ndata. ifv2is su¢ ciently large, it is easy to see that it would be socially optimal to close o¤\\ndata transactions and not allow user 1 to sell her data either. this is because she is indirectly\\nrevealing information about user 2, whose value of privacy is very large. this illustrates how\\ndata externalities lead to ine¢ ciency. in fact, if v2is su¢ ciently large, the equilibrium, which\\nalways involves user 1 selling her data, can be arbitrarily ine¢ cient.\\nmore interesting are the consequences of submodularity, which can be illustrated using this\\n8',\n",
       " 'example as well. to understand these, let us consider the edge case where the information of\\nthe two users is very highly correlated, i.e., \\x1a\\x191. in this example, the platform will know\\nalmost everything relevant about user 2 from user 1\\x92 s data. the important observation is that\\nthis data leakage about user 2 undermines the willingness of user 2 to protect her data. in\\nfact, since user 1 is revealing almost everything about her, she would be willing to sell her own\\ndata for a very low price. in this extreme case with \\x1a\\x191, therefore, both the willingness of\\nthe platform to buy user 2\\x92 s data and bene\\x85ts user 2 receives from protecting her data are\\nvery small, and thus this price becomes approximately 0. but here comes the disturbing part\\nfor data prices and the functioning of the data market in this instance: once the second user\\nis selling her data, this also reveals the \\x85rst user\\x92 s data almost perfectly, so the \\x85rst user can\\nonly charge a very low price for her data as well. as a result, the platform will be able to\\nacquire both users\\x92data at approximately zero price. this price, obviously, does not re\\x87 ect\\nusers\\x92value of privacy. they may both wish to protect their data and derive signi\\x85cant value\\nfrom privacy. nevertheless, the market will induce them to sell their data for close to zero\\nprice. imagine once again that v2is su¢ ciently high. then, despite this high value of privacy\\nto one of the users, there will be a lot of data transactions, data prices will be near zero, and\\nthe equilibrium will be signi\\x85cantly (arbitrarily) ine¢ cient. these consequences follow from\\nsubmodularity.\\nas a second example, consider the case in which again \\r= 0and\\x11= 1but now there is\\nno heterogeneity between the two users, so that v1=v2=v >1. this con\\x85guration implies\\nthat neither user would like to sell their data (because their privacy is more important than\\nthe value of data to the platform). nevertheless, it can be shown that so long as vis less\\nthan some threshold \\x16v(which is itself strictly greater than 1), there exists an equilibrium in\\nwhich the platform buys the data of both users for relatively cheap. this too is a consequence\\nof submodularity: when each user expects the other one to sell their data, they become less\\nwilling to protect their own data and more willing to sell it for relatively cheap. this locks\\nboth users into an equilibrium in which their data are less valuable than they would normally\\nassume, and partly as a result, there is again too much data transaction.\\none \\x85nal conclusion is worth noting. in addition to leading to excessive data use and\\ntransactions, the externalities also shift the distribution of surplus in favor of the platform. to\\nsee this, suppose v1=v2=v\\x141and\\x1a\\x191, so that it is now socially optimal for data to\\nbe used by the platform. it is straightforward to verify that in equilibrium, data prices will\\nagain be equal to zero, and thus all of the bene\\x85ts from the use of data will be captured by\\n9',\n",
       " 'the platform.\\nare data externalities and the ine¢ ciencies they create empirically relevant? like many\\nof the channels i discuss in this essay, the answer is that we do not know for sure. if, as\\nindustry insiders presume, bene\\x85ts of data are very large, then they will outweigh the costs\\nfrom data externalities i have highlighted here. even in this case, the market equilibrium will\\nnot be fully e¢ cient, though the use of data by platforms and corporations may be welfare-\\nincreasing overall. however, there are reasons to believe that privacy considerations may be\\nquite important in practice. first, many digital platforms have a monopoly or quasi-monopoly\\nsituation (such as google, facebook or amazon), and thus their ability to extract rents from\\nconsumers can be signi\\x85cant. second, some of the intrinsic reasons for consumers to care about\\nprivacy \\x97 related to dissent and civil society activity \\x97 are becoming more important, as i\\ndiscuss in section 4.\\nin summary, the general lessons in this case are clear: when an individual\\x92 s data are relevant\\nabout others\\x92behavior or preferences (which is the default case in almost all applications of\\ndata), then there are new economic forces we have to take into account, and these can create\\ncosts from the use of data-intensive ai technologies. in particular:\\n1. the social nature of data \\x97 enabling companies to use an individual\\x92 s data for predicting\\nothers\\x92behavior or preferences \\x97 creates externalities, which can be positive or negative.\\nwhen negative externalities are important, there will tend to be too much use of data\\nby corporations and platforms.\\n2. the social nature of data additionally generates a new type of submodularity, making\\neach individual less willing to protect their data when others are sharing theirs. this\\nsubmodularity adds to the negative externalities, but even more importantly, it implies\\nthat data prices will be depressed and will not re\\x87 ect users\\x92value of data and/or privacy.\\n3. in addition to leading to excessive use of data, both of these economic forces have \\x85rst-\\norder distributional consequences: they shift surplus from users to platforms and com-\\npanies.\\nif these costs of data use and ai are important, they also call for regulating data markets.\\nsome regulatory solutions are discussed in acemoglu et al. (2021), and i return to a more\\ngeneral discussion of regulation of ai technologies and data in section 6.\\n10',\n",
       " '2.2 data and unfair competition\\nai technologies amplify the ability of digital platforms and companies using data from these\\nplatforms to predict consumer preferences and behavior. on the upside, this might enable\\n\\x85rms to design better products for customers (after all, this is one of the main bene\\x85ts of ai).\\nbut the use of such data can also change the nature of competition. these e¤ects become even\\nmore pronounced when some \\x85rms are much better placed to collect and use data relative to\\ntheir competitors, and this is the case i will focus on this subsection. speci\\x85cally, one \\x85rm\\x92 s\\ncollection and use data that others cannot access may create a type of \\x93unfair competition\\x94 ,\\nenabling this \\x85rm to capture consumer surplus and relax price competition. i now develop this\\npoint in the simplest possible setting, using a hotelling-type static model with two \\x85rms. the\\nmain lesson will be that even when data improves product quality, it creates powerful forces\\nthat shift the distribution of surplus away from consumers and towards \\x85rms.\\nsuppose that consumers are located uniformly across a line of length 1 and incur a cost\\n\\x97 similar to a transport cost \\x97 when they purchase a product further away from their bliss\\npoint, represented by their location (see, for example, tirole, 1989). i assume that the utility\\nof consumer iwith location (or bliss point) ican be written as\\n\\x0b\\x00\\x0c(xf\\ni\\x00i)2\\x00pf\\ni;\\nwherexf\\ni2[0;1]is the product of \\x85rm f2f0;1gandpf\\niis its (potentially) customized price\\nfor this consumer. throughout, we normalize the cost of production to zero for both \\x85rms\\n(regardless of whether they produce a standardized or customized product).\\nlet us interpret the two \\x85rms as two di¤erent websites, which consumers visit in order to\\npurchase the good in question. before ai, \\x85rms cannot observe the type of consumer and i\\nassume that they cannot o¤er several products to a consumer that visits their websites. thus\\nthey will have to o¤er standardized products. this description implies that, in terms of timing,\\nthey \\x85rst choose their product, and then after observing each other\\x92 s product choice, they set\\nprices. since each \\x85rm is o¤ering a standard product and cannot observe consumer type, it will\\nalso set the same price for all consumers. this makes the pre-ai game identical to a two-stage\\nhotelling model, in which \\x85rms \\x85rst choose their product type (equivalent to their location)\\nand then compete in prices. throughout, i assume that\\n5\\x0c < 4\\x0b; (1)\\nwhich is su¢ cient to ensure that the market is covered and the \\x85rms will not act as local monop-\\nolies. as usual, i focus on subgame perfect equilibria, but with a slight abuse of terminology,\\n11',\n",
       " 'i refer to these as \\x93equilibria\\x94 .\\nit is straightforward to see that the unique equilibrium in this model, as in the baseline\\nhotelling model with quadratic transport costs, is maximal product di¤erentiation (tirole,\\n1989). in this setting, this means that the two \\x85rms will o¤er products at the two ends of the\\nline (x0= 0andx1= 1) and set equilibrium prices given by p0=p1=\\x0c, sharing the market\\nequally. for future reference, i also note that in this equilibrium total \\x85rm pro\\x85ts are equal to\\n\\x05pre-ai=\\x190+\\x191=\\x0c, and consumer surplus is\\ncspre-ai=\\x0b\\x002\\x0cz1=2\\n0x2dx\\x00\\x0c\\n=\\x0b\\x0013\\n12\\x0c;\\nwhere the \\x85rst line of this expression uses the symmetry between the \\x85rms and consumers on\\nthe two sides of 1=2.\\nafter advances in ai, one of the \\x85rms, say \\x85rm 1, can use data from its previous customers\\n(those with i\\x151=2) to predict their type and customize their products and prices.2in partic-\\nular, i assume that in this post-ai environment, \\x85rm 1 can observe the type of any consumer\\ni\\x151=2that visits its website and o¤ers a customized bundle (x1\\ni;p1\\ni)to this consumer. for\\nsimplicity, let us assume that \\x85rm 0 cannot do so and also that \\x85rm 1 cannot simultaneously\\no¤er customized and standardized products. now in equilibrium, \\x85rm 1 will o¤er each con-\\nsumer with i\\x151=2a customized product x1\\ni=i. it will also charge higher prices. the exact\\nform of the equilibrium depends on \\x85rm 0\\x92 s product choice, which, given its inability to use\\nthe new ai technology, cannot be customized. it is straightforward to see that \\x85rm 0 will also\\nchange its product, because it no longer needs as much product di¤erentiation (since \\x85rm 1\\nwill be charging higher prices). the unique post-ai equilibrium is one in which \\x85rm 0 changes\\nits standardized product to x0= 1=4. it then sets a price that makes the consumers that are\\nfarthest away from it indi¤erent between buying its product and not doing so, i.e.,3\\np0=\\x0b\\x00\\x0c\\n16:\\nit is also straightforward to see that it is optimal for \\x85rm 1 to set:\\np1\\ni=\\x0bfor alli\\x151\\n2;\\n2more generally, the fact that ai-intensive \\x85rms are using data from and customizing products to their\\nexisting customers introduces intertemporal linkages, which could create lock-in e¤ects and rich-get-richer\\ndynamics, as in the switching cost and dynamic oligopoly literatures, such as in klemperer (1995) and budd,\\nharris and vickers (1993).\\n3firm 0 could o¤er a lower price and steal some customers from \\x85rm 1, but it can be veri\\x85ed that this would\\nlead to lower pro\\x85ts.\\n12',\n",
       " 'thus capturing all the consumer surplus from the consumers about whom it has data.4in this\\nequilibrium, we have \\x05post-ai=\\x0b\\x00\\x0c\\n32>\\x05pre-ai(which is guaranteed by (1)), while consumer\\nsurplus is now\\ncspost-ai=\\x0b\\n2\\x002\\x0cz1=4\\n0x2dx\\x001\\n2\\x12\\n\\x0b\\x00\\x0c\\n16\\x13\\n=1\\n48\\x0c:\\nas a consequence, consumer surplus is much lower in this case. this can be seen most clearly\\nby considering the limit where \\x0c!0, in which case the pre-ai consumer surplus is maximal\\n(approaching \\x0b), while post-ai it becomes minimal (approaching 0). the negative impact of\\nai technologies on consumer surplus has two interrelated causes. first, \\x85rm 1 now uses its\\nbetter prediction power to capture all the surplus from the consumers, even though it is in\\nprinciple o¤ering a better product and could have increased consumer welfare. second, given\\n\\x85rm 1\\x92 s more aggressive pricing, \\x85rm 0 is also able to capture more pro\\x85ts, reducing even the\\nsurplus of consumers whose data are not being used.\\nit is worth noting that, in the present model there is no intensive margin of consumer choice\\nand the market is covered (under (1)). as a result, ai does not a¤ect quantity purchased, and\\neven when it reduces consumer welfare, it increases utilitarian welfare \\x97 in particular, greater\\ncustomization reduces \\x93transport costs\\x94 . the logic of the model highlights that this need not\\nbe the case when there is a quantity/intensive margin, because higher markups may ine¢ ciently\\nreduce quantity purchased. we will see in the next subsection that there are other reasons for\\nine¢ ciency in similar environments.\\nin summary, the general lessons from this model are complementary to the ones from the\\nprevious subsection:\\n1. the use of ai technologies and detailed consumer data for prediction may improve the\\nability of \\x85rms to customize products for consumers, potentially improving overall sur-\\nplus.\\n2. however, it also increases the power of (some) companies over consumers.\\n3. this has direct distributional implications, enabling ai-intensive \\x85rms to capture more\\nof the consumer surplus.\\n4if we had allowed this \\x85rm to also market a standardized product, it would additionally compete for\\nconsumers i <1=2, about whom it has no data. our assumption rules out this possibility.\\n13',\n",
       " '4. the indirect e¤ect of the better collection and processing of data by one \\x85rm is to relax\\nprice competition in the market, increasing prices and amplifying the direct distributional\\ne¤ects.\\nalthough in this model the overall surplus in the economy increases after the introduction\\nof ai technologies, in the previous subsection we saw that this is not necessarily true in the\\npresence of other data-related externalities, and in the next subsection we will encounter a new\\neconomic force distorting the composition of products o¤ered by platforms.\\n2.3 behavioral manipulation\\nthe previous subsection discussed how even the bene\\x85cial use of improved prediction about\\nconsumer preferences and behavior might have a downside. but improved prediction tools\\ncan also be put to nefarious uses, with potentially far-ranging negative e¤ects. platforms\\nthat collect and e¤ectively process huge amounts of data might able to predict consumer\\nbehavior and biases beyond what the consumers themselves can know or understand. anecdotal\\nexamples of this concern abound. they include the chain store target successfully forecasting\\nwhether women are pregnant and sending them hidden ads for baby products, or various\\ncompanies estimating \\x93prime vulnerability moments\\x94 and send ads for products that tend\\nto be purchased impulsively during such moments. they also include marketing strategies\\ntargeted at \\x93vulnerable populations\\x94such as the elderly or children. less extreme advertising\\nstrategies also have elements of the same type of manipulation, for example, when websites\\nfavor products such as credit cards or subscription programs with delayed costs and short-\\nterm bene\\x85ts or when youtube and facebook use their algorithms to estimate and favor more\\naddictive videos or news feeds for the user group in question. as legal scholars hanson and\\nkysar have noted, \\x93once one accepts that individuals systematically behave in non-rational\\nways, it follows from an economic perspective that others will exploit those tendencies for\\ngain.\\x94(1999, p. 630).\\nthough these concerns are as old as advertising itself, economists and policy-makers hope\\nthat consumers will learn how to shield themselves against abusive practices. the sudden\\nexplosion in the capabilities of digital platforms to use ai technologies and massive data sets\\nto improve their predictions undercuts this argument, however. learning dynamics that had\\nmade consumers well adapted to existing practices would be quickly outdated in the age of\\nai and big data. this issue is explored in acemoglu et al. (2022), using a continuous-time\\nlearning model. here i outline a similar idea in a much simpler setting.\\n14',\n",
       " 'i consider a dynamic setting with two periods, t= 0;1, and no discounting. consumers\\nhave a choice between two products, x1andx2, in both periods. they are initially uncertain\\nabout which one will yield higher utility. suppose in particular that the true utility that a\\nconsumer gets from the product is either horl= 0. the prior belief of individual iis that\\nthese two products will yield high utility for them is, respectively, q1\\niandq2\\ni.\\nboth products are produced and o¤ered by a digital platform, which again has zero cost\\nof production and can o¤er personalized prices. to start with, the platform and the consumer\\nhave symmetric information, and thus the platform knows and shares the consumer\\x92 s prior\\nbeliefs. once an individual consumes one of the two products, she obtains an additional piece\\nof information about her utility from the product. i assume, in particular, that if the true\\nquality ish, the consumer receives a positive signal, denoted by \\x1bh(with probability 1).\\nhowever, if the true quality is l, the product might still have deceptively high instantaneous\\nutility (but long-term costs). thus with probability \\x15, the consumer will receive the high\\nsignal (and receives the low signal \\x1blwith complementary probability). the most relevant\\ninterpretation of this \\x93false-positive\\x94 signal is that there are certain types of products that\\n(predictably) appear more attractive to consumers, for example because of their tempting\\nshort-term bene\\x85ts or because of their hidden negative attributes.\\nlet us assume that the platform perfectly observes the consumer\\x92 s experience with the\\nproduct she has consumed, and can change its pricing and product o¤ering in the next period.\\nthe game ends at the end of the second period.\\nthe pre-ai equilibrium takes a simple form. the platform will o¤er whichever product has\\nhigherqifor consumer i, say product j, and will set the price\\npj\\ni;0=qj\\nih,\\ncapturing the full surplus. if the signal after consumption is \\x1bl, then in the next period, it\\nwill o¤er the other product, ~j, charging the lower price\\np~j\\ni;1=q~j\\nih,\\nonce again capturing the full surplus. if, on the other hand, the signal is \\x1bh, then in the second\\nperiod, the same product will be o¤ered, but now there will be a higher price. i assume that\\nin the pre-ai environment, consumers have su¢ cient experience with such products and the\\nsignals they generate that they can correctly anticipate the likelihood of a high-quality product\\ngiven a positive signal. as a result, the price following a positive signal will not increase all the\\n15',\n",
       " 'way toh. rather, it will be given by the expected value of the product\\x92 s quality conditional\\non a positive signal. a simple use of bayesian updating gives this price as\\npj\\ni;0=qj\\ni\\nqj\\ni+ (1\\x00qj\\ni)\\x15h\\n= \\x04j\\nih,\\nwhich again captures the full surplus from the consumer and also de\\x85nes the expression \\x04j\\ni,\\nwhich is convenient for the remainder of this section. (there is no option value term in prices,\\nbecause the full surplus is being captured by the platform).\\nthe deployment of ai technologies once again improves the platform\\x92 s ability to predict\\nconsumer preferences and behavior \\x97 because it has access to the data from many similar\\nconsumers and their experiences with similar products. as pointed out above, i assume that\\nthis goes beyond what the consumer herself knows. in particular, i suppose that the platform\\ncan now forecast whether the consumer will receive the high signal from a truly low-quality\\nproduct. this, more generally, captures the ability of the platform to predict whether the\\nindividual will engage in an impulse purchase or make other choices with apparent short-term\\nbene\\x85ts and long-term costs.\\npost-ai, therefore, the relevant state for consumer iat timet= 0becomes\\x10\\x08\\nqj\\ni;\\x18j\\ni\\t\\nj=1;2\\x11\\n,\\nwhere\\x18j\\ni= 1designates the event that product jwill generate a false-positive signal \\x97 which\\nmeans that in reality it is low-quality for the consumer, but still the signal \\x1bhwill be realized\\nif the consumer purchases it. critically, the platform observes \\x18j\\ni, but the consumer does not.\\nfollowing acemoglu et al. (2022), i assume that consumers are \\x93semi-behavioral\\x94 and do\\nnot fully take into account that in the post-ai world, the platform actually knows \\x18j\\ni. this\\ncaptures the more general economic force mentioned above: in the pre-ai, business-as-usual\\nworld, consumers may have learned from their repeated experiences and purchases, accurately\\nestimating the relevant probabilities. the post-ai world is new and it is less plausible to expect\\nthat the consumers will immediately understand the superior information that the platform has\\nacquired. note also that although it can forecast \\x18j\\ni, the platform cannot observe consumer\\npreferences perfectly, and when \\x18j\\ni= 0, it does not know whether the product is high or\\nlow-quality.\\nwhat does equilibrium look like in the post-ai world? the key observation is that, while\\nbefore ai the platform\\x92 s prediction was aligned with the prior of the household, this is no longer\\nthe case in the post-ai world. in particular, suppose that we have q1\\ni>q2\\ni, but\\x181\\ni= 0, while\\n\\x182\\ni= 1. then the platform may prefer to o¤er the second product. to understand this choice,\\n16',\n",
       " 'let us compute the pro\\x85ts from consumer iwhen the platform is using these two strategies.\\nwhen it o¤ers product 1, its total pro\\x85ts are\\n\\x191\\ni=\\x02\\nq1\\ni+q1\\ni\\x041\\ni+ (1\\x00q1\\ni)q2\\ni\\x03\\nh:\\nthis expression follows by noting that the platform is at \\x85rst o¤ering product 1 and charging\\nq1\\ni. because\\x181\\ni= 0, the consumer will receive a positive signal only if the product is truly high\\nquality, which happens with probability q1\\ni. however, as indicated by the above discussion, in\\nthis case, the consumer does not know whether this was a false-positive or a truly high-quality\\nproduct, and thus her valuation will be \\x041\\nih, which explains the second term. finally, if she\\nreceives a negative signal (probability 1\\x00q1\\ni), in the second period, the platform will o¤er\\nproduct 2, charging q2\\ni.\\non the other hand, when it initially o¤ers product 2, the platform\\x92 s pro\\x85ts are\\n\\x192\\ni=\\x00\\nq2\\ni+ \\x042\\ni\\x01\\nh;\\nbecause in this case there will be a positive signal for sure.\\nit is straightforward to see that o¤ering the second good is more pro\\x85table for the platform\\nwhen\\nq2\\ni\\nq2\\ni+ (1\\x00q2\\ni)\\x15>q1\\ni(1\\x00q2\\ni) +(q1\\ni)2\\nq1\\ni+ (1\\x00q1\\ni)\\x15: (2)\\ncondition (2) is always satis\\x85ed whenever q2\\niis su¢ ciently close to q1\\ni. intuitively, the platform\\nis willing to sacri\\x85ce a little bit of revenue in the \\x85rst period for the certainty of getting the\\nconsumer to experience a good that it knows she will like \\x97 even though this is not a truly\\nhigh-quality good.\\nwhat about consumer welfare? perhaps paradoxically, in the \\x85rst case, the consumer\\nactually has a positive welfare. this is because in this case we have a high-quality product\\n(and the platform indirectly recognizes this following the realization of signal \\x1bh, because it\\nknows that \\x181\\ni= 0), and hence the positive signal can come only from a truly high-quality\\ngood. it is then straightforward to compute the user\\x92 s welfare as\\nu1\\ni=q1\\ni\\x12\\n1\\x00q1\\ni\\nq1\\ni+ (1\\x00q1\\ni)\\x15\\x13\\nh\\n=q1\\ni(1\\x00q1\\ni)\\x15\\nq1\\ni+ (1\\x00q1\\ni)\\x15h > 0:\\nthis positive surplus may appear as the good side of our behavioral assumption. but the\\nplatform\\x92 s second strategy shows the dark side. with this strategy, the consumer will overpay\\n17',\n",
       " 'in the second period (because, given \\x182\\ni= 1, the product is in reality low-quality). hence her\\nutility is\\nu2\\ni=\\x00q2\\ni\\nq2\\ni+ (1\\x00q2\\ni)\\x15h < 0:\\ntherefore, the ability of the platform to predict the consumer\\x92 s preferences and vulnerabilities\\nleads to a situation in which the platform can increase its pro\\x85ts by marketing low-quality\\nproducts that are likely to appeal to the consumer in the short run.\\nin contrast to the pattern in the previous subsection, this not only increases platform pro\\x85ts\\nat the expense of consumers, but it also distorts consumption as it lures consumers towards\\nlower-quality products, reducing utilitarian welfare.\\nthe general lessons in this case are complementary but di¤erent from the ones i highlighted\\nin the previous two subsections:\\n1. ai technologies can enable platforms to know more about consumers\\x92preferences than\\nthey themselves do.\\n2. this opens the way for potential behavioral manipulation, whereby the platform can o¤er\\nproducts that may temporarily appear as higher-quality than they truly are.\\n3. this type of behavioral manipulation tends to do more than just shift surplus from\\nconsumers to the platform; it also distorts the composition of consumption, creating new\\nine¢ ciencies.\\n3 labor market e¤ects of ai\\nus labor markets have not been doing well for workers over the last 40 years. wage growth\\nsince the late 1970s has been much slower than during the previous three decades, while the\\nshare of capital in national income has grown signi\\x85cantly (acemoglu and autor, 2011; autor,\\n2019). additionally, wage growth, such as it is, has been anything but shared. while wages\\nfor workers at the very top of the income distribution \\x97 those in the highest tenth percentile\\nof earnings or those with postgraduate degrees \\x97 have continued to grow, workers with a high\\nschool diploma or less have seen their real earnings fall. even college graduates have gone\\nthrough lengthy periods of little real wage growth.\\nmany factors have contributed to this sluggish average wage growth and real wage declines\\nat the bottom of the distribution. the erosion of the real value of the minimum wage, which\\n18',\n",
       " 'has fallen by more than 30 percent since 1968, has been clearly important for low-wage workers\\n(lee, 1999). the decline in the power of trade unions and much of the private sector may have\\nplayed a role as well. the enormous increase in trade with china also likely contributed, by\\nforcing the closure of many businesses and large job losses in low-tech manufacturing industries\\nsuch as textiles, apparel, furniture, and toys (autor, dorn and hanson, 2013).\\nmy own work with pascual restrepo (2019, 2021) emphasizes and documents the impor-\\ntance of the direction of technological progress in this process. while in the four decades after\\nworld war ii automation and new tasks contributing to labor demand went hand-in-hand, a\\nvery di¤erent path of technological development emerged starting in the 1980s, exhibiting more\\nautomation and much slower advances in human-friendly technologies, such as those involving\\nnew tasks (acemoglu and restrepo, 2019). automation eliminated routine tasks in clerical\\noccupations and on factory \\x87 oors, depressing the demand and wages of workers specializing\\nin blue-collar jobs and clerical functions. meanwhile professionals in managerial, engineering,\\n\\x85nance, consulting, and design occupations \\x87 ourished \\x97 both because they were essential to\\nthe success of new technologies and because they bene\\x85ted from the automation of tasks that\\ncomplemented their own work. as automation gathered pace, wage gaps between the top\\nand the bottom of the income distribution magni\\x85ed. in acemoglu and restrepo (2021), we\\nestimate that automation has been possibly the most important factor in reshaping the us\\nwage structure, explaining somewhere between 50 to 70% of the variance of changes in wages\\nby demographic group between 1980 and 2016.\\nall of this predates ai. in acemoglu et al. (2021), we \\x85nd that ai activity across us\\nestablishments picks up speed only after 2016. nevertheless, this background is useful because\\nai may be the next phase of automation, and there is evidence that it is already being used both\\nfor automation and for tighter monitoring of workers, further depressing wages and the labor\\nshare. in this section, i \\x85rst explain how automation works and why we may be concerned\\nabout excessive automation in general, and how ai may exacerbate these concerns. i then\\ndiscuss how ai could be used for generating new tasks and technologies that complement\\nhumans, but whether this will be the case or not depends on technology adoption and research\\nand development choices of companies. in this context, i suggest reasons for being concerned\\nthat the composition of ai research may be heavily distorted. i also discuss why the most\\nbenign view of ai\\x92 s role in the labor market \\x97 automating routine jobs, so that workers have\\ntime for more creative, problem-solving tasks \\x97 may need to be quali\\x85ed. finally, i explore\\nhow ai may have pernicious e¤ects when it is used for monitoring.\\n19',\n",
       " '3.1 excessive automation and ai\\nin order to situate the role of ai in the broader context of automation technologies, i start\\nwith a review of the framework from acemoglu and restrepo (2018, 2019), which models the\\nautomation of tasks (as well as the creation of new tasks). suppose there is a single good in\\nthe economy, y, whose production requires the combination of a measure 1 of tasks:\\ny=\\x12zn\\nn\\x001y(z)\\x1b\\x001\\n\\x1bdz\\x13\\x1b\\n\\x1b\\x001\\n; (3)\\nwherey(z)denotes the output of task zand\\x1b\\x150is the elasticity of substitution between\\ntasks. the key economic decision is the allocation of tasks to factors. let me focus on just two\\nfactors, capital and labor, and suppose as in acemoglu and restrepo (2018, 2019) that each\\nfactor has task-speci\\x85c productivities, determining its comparative advantage, and only tasks\\nz\\x14ican be automated given the current level of automation technology. this implies:\\ny(z) =\\x1aal\\rl(z)l(z) +ak\\rk(z)k(z)ifz2[n\\x001;i]\\nal\\rl(z)l(z) ifz2(i;n ]:\\nherel(z)andk(z)denote the total labor and capital allocated to producing task z. the state of\\ntechnology is captured by the following: factor-augmenting terms, alandak, which increase\\nthe productivity of the relevant factor uniformly in all tasks; task-speci\\x85c productivities, \\rl(z)\\nand\\rk(z), which increase the productivity of a factor in a speci\\x85c task; the threshold for\\ntasks that are feasible to automate, i; and the measure of new tasks, n. let us assume that\\n\\rl(z)=\\rk(z)is increasing in z, so that labor has a comparative advantage in higher-indexed\\ntasks. suppose that capital is produced from the \\x85nal good, with marginal cost r, which also\\ngives its rental rate. labor is inelastically supplied, with total supply given by l, and the\\nequilibrium wage is denoted by w.\\nacemoglu and restrepo (2018, 2019) characterize the competitive equilibrium in this econ-\\nomy. here i allow both competitive and rigid labor markets, by assuming that the wage cannot\\nfall below some level w. in this case, the equilibrium wage can be written as:\\nw= maxfw;mpl (l)g;\\nwhere mpl (l)is the marginal product of labor when there is full employment at l. the wage\\n\\x87 oor may be a consequence of regulations, such as minimum wages and union-imposed minima,\\nor may result from other labor market imperfections, such as e¢ ciency wage considerations.\\n20',\n",
       " 'let us \\x85rst focus on how the marginal product of labor changes (without any wage \\x87 oor).\\nfollowing acemoglu and restrepo (2018), this is given by\\n@lnmpl (l)\\n@i=@lny(l;k )\\n@i(productivity e¤ect) (4)\\n+1\\n\\x1b1\\x00sl\\n1\\x00\\x00(n;i )@ln \\x00(n;i)\\n@i(displacement e¤ect)\\nwheresldenotes the labor share and \\x00(n;i ) =rn\\ni\\rl(z)\\x1b\\x001dzri\\nn\\x001\\rk(z)\\x1b\\x001dz+rn\\ni\\rl(z)\\x1b\\x001dzis a measure of the\\nlabor\\x92 s task content of production (capturing what fraction of tasks are assigned to labor). in\\nthe special cases where \\x1b= 1or where\\rk(z) =\\rl(z), we have \\x00(n;i ) =n\\x00i, but more\\ngenerally, \\x00(n;i )is always increasing in nand decreasing in i. the \\x85rst line of (4) represents\\ntheproductivity e¤ect, which is driven by the fact that automation reduces costs and thus\\nincreases productivity \\x97 by an amount equivalent to the cost di¤erence between producing\\nthe marginal tasks by labor vs. capital:\\n@lny(l;k )\\n@i=1\\n\\x1b\\x001\"\\x12r\\nak\\rk(i)\\x131\\x00\\x1b\\n\\x00\\x12mpl (l)\\nal\\rl(i)\\x131\\x00\\x1b#\\n:\\nthe second line is the displacement e¤ect created by automation: as tasks are allocated away\\nfrom labor towards capital, the marginal product of labor declines. this displacement e¤ect,\\nwhich reduces the range of tasks employing workers, is always negative.\\nwhen we are at full employment, (4) gives the impact of automation on wages. when,\\ninstead, the wage \\x87 oor at wis binding, then the same e¤ects now impact employment. the\\nonly di¤erences are that on the left-hand side of (4), we now have the proportional change in\\nemployment, and on the right-hand side, mpl (l)=al\\rl(i)is replaced by w=al\\rl(i).\\nlet us \\x85rst consider full employment. what happens to the labor market equilibrium\\nfollowing additional automation? equation (4) \\x85rst shows that the labor share will always\\ndecline \\x97 because of the displacement e¤ect, the wage will increase less than proportionately\\nwith productivity. equally importantly, the wage level may fall as well. this is because\\nthe displacement e¤ect can be larger than the productivity e¤ect. in particular, when the\\nproductivity e¤ect is small, for example, in the edge case where w=al\\rl(i)\\x19r=ak\\rk(i),\\nthere is no productivity e¤ect, and the equilibrium wage will necessarily decline. when there\\nis more than one type of labor, the same argument also implies that the average wage may\\nfall, though the wage of some groups may increase (see acemoglu and restrepo, 2021).\\nthis framework further clari\\x85es why automation could reduce employment. suppose the\\nwage \\x87 oorwis binding and again take the edge case where w=al\\rl(i)\\x19r=ak\\rk(i), so that\\n21',\n",
       " 'the productivity e¤ect is approximately zero. then, automation necessarily reduces employ-\\nment. by continuity, the same happens when the productivity e¤ect is positive but not too\\nlarge \\x97 the case that acemoglu and restrepo (2019) refer to as \\x93so-so technologies\\x94 , because\\nthey are good enough to be adopted, but not so good as to have a meaningful impact on\\nproductivity.\\nwhat are the welfare consequences of employment-reducing automation? in a perfectly\\ncompetitive market, where workers are at the margin indi¤erent between leisure and work, and\\nwhen there are no other distributional concerns, an automation-induced decline in employment\\ndoes not have \\x85rst-order welfare consequences. in fact, it is straightforward to see that the\\ncompetitive equilibrium would always maximize net output (de\\x85ned as total production minus\\nwhat is used up for producing capital). however, when there are labor market imperfections,\\nsuch as those captured by the wage \\x87 oor w, then low-productivity automation reduces welfare\\n\\x97 thus motivating the term \\x93excessive automation\\x94 . this can be seen with the following\\nargument: because the productivity e¤ect is approximately zero, gross output and pro\\x85ts do\\nnot increase (workers in marginal tasks are replaced by machines, but total costs have not\\nchanged). yet, capital usage increases, and this reduces net output. at this point, reallocating\\nmarginal tasks away from capital towards labor \\x97 thus reducing automation \\x97 would increase\\nnet output.\\nwhy is the equilibrium misaligned with social welfare maximization? the answer is related\\nto the wage \\x87 oor. firms, when making their hiring and automation decisions, are responding\\nto the market wage, w, whereas a utilitarian social planner \\x97 seeking to maximize net surplus\\n\\x97 should take into account the opportunity cost of labor, which is zero. this argument\\nestablishes that when productivity e¤ects are limited, there will be excessive automation. it\\nalso pinpoints one of the channels for this type of ine¢ ciency: in economies with labor market\\nimperfections, \\x85rms base their automation decisions on the higher wage rate, rather than the\\nlower social opportunity cost of labor.\\nthis argument also clari\\x85es that automation is likely to be excessive and potentially welfare-\\nreducing especially when it generates small or negligible productivity e¤ects. if the productivity\\ngains from automation had been large, net output would have increased, even if it displaced\\nworkers. moreover, equation (4) highlights that with a large productivity e¤ect, there may not\\nhave been a decline in labor demand in the \\x85rst place.\\nthe case for excessive automation is strengthened if there are other considerations favoring\\nhigher levels of employment. for example, if employed individuals generate positive external\\n22',\n",
       " 'e¤ects (on their families and communities or for democracy) relative to the unemployed, then\\nthe social planner may want to increase employment beyond the equilibrium level. distrib-\\nutional concerns would also weigh in the same direction, since, in general, automation helps\\n\\x85rms and \\x85rm owners, while reducing the labor share. in addition, as shown in autor, levy\\nand murnane (2003) and acemoglu and restrepo (2021), automation boosts inequality across\\nworker groups, creating another distributional cost.\\nwhat does this imply for ai? ai is a broad technological platform, and can be used for\\ndeveloping many di¤erent types of technologies. automation, especially automation of various\\nwhite-collar tasks and jobs with a signi\\x85cant decision-making component, is one of these appli-\\ncations. if ai is used for automation, then the arguments outlined above would also imply that\\nlow-productivity ai may reduce welfare. two key questions are thus whether ai technologies\\nare likely to be deployed for substituting capital and algorithms for labor in various tasks and\\nwhether this will generate small or large productivity gains. the evidence in acemoglu et\\nal. (2021) suggests that there has been a signi\\x85cant uptick in ai activities since 2016, and\\nmuch of this has been associated with task displacement. that paper also \\x85nds reduced hiring\\nin establishments adopting ai technologies, so the evidence is consistent with, though does\\nnot prove, the idea that new ai technologies may not be improving productivity su¢ ciently.\\nthere are other reasons why productivity gains from ai may be small. most importantly, ai\\ntechnologies are being used in some tasks in which humans are quite good (natural language\\nprocessing, facial recognition, problem-solving; see acemoglu, 2021).\\nin summary, the general lessons from this section are:\\n1. automation reduces the labor share and may also reduce the (average) wage and/or em-\\nployment, and this latter outcome is more likely when productivity gains from automation\\nare small.\\n2. when labor market imperfections create a wedge between the market wage and the\\nsocial opportunity cost of labor, automation tends to be excessive and welfare-reducing,\\nparticularly when it impacts employment negatively as well. this too is more likely\\nto be the case when its productivity e¤ects are small. the same considerations apply\\nwhen there are non-market reasons for preferring high levels of employment (for example,\\nbecause employed workers contribute more to their families, communities or society in\\ngeneral).\\n3. because it increases the capital share and reduces the labor share and because it boosts\\n23',\n",
       " 'inequality among workers, automation may also be excessive from a welfare point of view\\ndue to distributional concerns\\n4. if ai is used predominantly for automation, it will have similar e¤ects to other automation\\ntechnologies, and depending on its productivity e¤ects and relevant welfare criteria, it\\nmay have a negative impact on social welfare.\\n3.2 direction of ai technology and its labor market consequences\\nthe previous subsection discussed some implications of ai used for automation, but it also\\nnoted that ai, as a broad technological platform, can be used for creating new tasks or in-\\ncreasing labor productivity as well. in the framework of the previous subsection, this would\\ncorrespond to an increase in n. the framework presented in the previous section additionally\\nimplies that new tasks increase the labor share and raise wages or employment (or both). in\\nparticular, as in acemoglu and restrepo (2018, 2019), we now have\\n@lnmpl (l)\\n@n=@lny(l;k )\\n@n(productivity e¤ect) (5)\\n+1\\n\\x1b1\\x00sl\\n1\\x00\\x00(n;i )@ln \\x00(n;i)\\n@n: (reinstatement e¤ect)\\nthe productivity e¤ect is positive as usual (even if the exact sources of productivity gains from\\nnew tasks are di¤erent than those from automation). in addition, the reinstatement e¤ect is\\nalso positive, because it is driven by the fact that new labor-intensive tasks are reinstating\\nlabor back into the production process. as a result, new tasks always increase employment\\nand/or wages. moreover, the presence of the reinstatement e¤ect implies that the wage bill\\nincreases proportionately more than the productivity gains, pushing up the labor share \\x97 the\\nconverse of the impact of automation. acemoglu and restrepo (2019) have argued that the\\nreason why wages grew robustly during the decades following world war ii was that rapid\\nautomation in certain tasks went hand-in-hand with the introduction of su¢ ciently many new\\ntasks, counterbalancing the labor market implications of automation.\\nreturning to the implications of ai, with the same argument, using ai for new tasks\\nwould be welfare-improving, especially when there are labor market imperfections or other\\nconsiderations favoring higher levels of employment than in equilibrium. furthermore, if ai\\nboosts the creation of new tasks and improves human productivity, it could counterbalance\\nsome of the adverse e¤ects of automation based on other technologies (such as robotics or\\nspecialized software).\\n24',\n",
       " 'when ai can be used both for automation and for new tasks, the pivotal question becomes\\nhow the balance between these two activities is determined \\x97 that is, the direction of tech-\\nnological change. acemoglu and restrepo (2018) provide a framework for the analysis of the\\nequilibrium direction of technology. their framework emphasizes the role of factor prices and\\nthe labor share and highlights that there are reasons for optimal and equilibrium allocations\\nto di¤er. in particular, labor market imperfections not only promote too much automation \\x97\\nas we saw in the previous subsection \\x97 but could further lead to an unbalanced composition\\nof ai research between automation and new tasks.\\nthere may also be potential distortions in the direction of technological change that go\\nbeyond the purely economic. in acemoglu (2021) i emphasize that the direction of technology\\nis partly shaped by the business models of leading \\x85rms and the aspirations of researchers,\\nand if these favor automation, the equilibrium may involve too much automation, even absent\\neconomic distortions. another related argument is that us corporations may have become\\ntoo focused on cost-cutting, which might also encourage excessive automation. acemoglu,\\nmanera and restrepo (2020), on the other hand, show that the us tax code imposes a much\\nhigher marginal tax rate on labor than equipment and software capital, thus favoring automa-\\ntion. this policy channel triggers both excessive adoption of automation technologies and\\ndisproportionate emphasis on automation in research and development.\\nai as a technological platform could in principle boost e¤orts to create new tasks. take\\neducation as an example. current investments in this area are focused on using ai technologies\\nfor automated grading and the development of online learning tools to replace various tasks\\nperformed by teachers. yet, ai can be deployed for creating new tasks and directly increasing\\nteacher productivity as well. it can be used for adapting teaching material to the needs and\\nattitudes of diverse students in real time, overcoming a major problem of classroom-based\\nteaching \\x97 the fact that students have diverse strengths and weaknesses and \\x85nd di¤erent\\nparts of the curricula more challenging (see the discussion in acemoglu, 2021). likewise, ai has\\nmany diverse applications in health that can personalize care and empower nurses and general\\npractitioners to make more and better decisions in care delivery. these potentially promising\\ndirections notwithstanding, ai may be more likely to aggravate excessive automation. the\\ncurrent trajectory in ai research is shaped by the visions of large tech companies, who are\\nresponsible for the majority of the spending on this technology. many of these companies\\nhave business models centered on substituting algorithms for humans, which may make them\\nfocus excessively on using ai for automation. at the same time, many ai researchers focus\\n25',\n",
       " 'on reaching \\x93human parity\\x94in narrow tasks as the main metric of success, which could create\\nanother powerful force towards automation, rather than using this platform for creating new\\ntasks. like other automation technologies, ai may also appeal to many executives intent on\\ncost-cutting, and if there are additional tax breaks and favorable treatments for software in\\ngeneral and ai-related technologies speci\\x85cally, these may exacerbate the focus on automation\\n(acemoglu and johnson, 2022).\\noverall, even though there is no de\\x85nitive evidence on this question, it is possible that the\\ndirection of technological change was already tilted too much towards automation before ai,\\nand ai may have exacerbated these trends. if so, its labor market implications could be one\\nof the major harmful e¤ects of ai.\\nthe general lessons from this discussion are therefore:\\n1. ai could in principle be used for increasing worker productivity and expanding the set\\nof tasks in which humans have a comparative advantage, rather than focusing mainly on\\nautomation. if it is used in this way, it may counterbalance some of the negative e¤ects\\nof automation on labor and may generate more positive welfare e¤ects and bene\\x85cial\\ndistributional consequences\\n2. but there is no guarantee that the composition of technological change in general and the\\nbalance of ai between automation and more human-friendly activities should be optimal.\\nin fact, there are many possible distortions, some of them economic and some of them\\nsocial, encouraging excessive automation using ai.\\n3.3 ai and human judgment\\nthe arguments in the previous two subsections are partly predicated on the notion that ai-\\nbased automation may not generate sweeping productivity gains, which could compensate for\\nor even undo the displacement e¤ects it creates. ai\\x92 s most enthusiastic boosters, on the other\\nhand, believe that ai can bring huge productivity gains. one of the most powerful arguments in\\nthis respect is that as ai helps automate and improve (both cognitive and noncognitive) tasks\\nthat do not require human judgment and creativity, it will increase the demand for problem-\\nsolving tasks that require creativity and judgment and also free workers to focus on these tasks.\\nalthough seemingly plausible, i now suggest a potential reason why this expectation may be\\ntoo optimistic and argue that, even when such reallocation takes place, ai-based automation\\nmay be excessive.\\n26',\n",
       " 'suppose that there are two tasks to be performed, 1and2. overall output in the economy\\nis given by\\ny= min\\x08\\ny1;y2\\t\\n;\\nwhereyiis the output of task i, and the leontief production function imposes that these tasks\\nare strongly complementary.\\nbefore ai, both tasks have to be performed by humans. suppose that there is a measure 1\\nof humans, each with 2 units of time. suppose also that, for reasons i will explain below, we\\nstart in an allocation in which each human allocates half of their time to task 1 and the other\\nhalf to task 2. in this case, they have equal productivity in both tasks, which i normalized to 1.\\nas a result, before ai, the economy produces a total of one unit of the \\x85nal good. we can think\\nof each worker as a \\x93yeoman-producer\\x94 , consuming his or her production. equivalently, we\\ncan think of this economy as consisting of \\x85rms hiring workers in a competitive labor market.\\nin this case, the per hour wage of each worker in each task will be 1=2, ensuring that the entire\\noutput is paid to workers.\\nnow imagine that there are advances in ai algorithms that produce the \\x85rst task at per\\nunit costc <1=2. this cost is paid in terms of the \\x85nal good, and the fact that it is less\\nthan the equilibrium wage before ai implies that these algorithms are cost-saving and will\\nbe adopted. if this were the end of the story, ai would improve net output, because workers\\nwould be reallocated from task 1 to task 2, enabling the economy to increase its total output.\\nhowever, suppose that there are also economies of scope: individuals learn from performing\\nboth tasks at the same time (and that is why the pre-ai allocation involved each worker\\ndevoting half of their time to each task). suppose, in particular, that if a worker does not\\nlearn from task 1, his or her productivity in task 2 declines to 1\\x00\\x0c. the post-ai allocation\\nwill involve all workers working in task 2, and whatever their total production is in this task,\\nthe economy will also produce exactly the same amount of task 1, using ai algorithms. as a\\nresult, net output in this economy will be\\n2(1\\x00\\x0c)\\x00spending on ai = 2(1\\x00\\x0c)(1\\x00c):\\nit can be veri\\x85ed that in the special case where there are no economies of scope ( \\x0c= 0),c<1=2\\nis su¢ cient for net output to increase \\x97 in particular, from 1to2(1\\x00c)>1. however, as\\nsoon as\\x0c >0, this is no longer guaranteed. for example, when c\\x191=2, even a small amount\\nof economies of scope implies that the use of ai would reduce net output.\\n27',\n",
       " 'this simple example captures a more general phenomenon: a \\x85ner division of labor and\\nthe reallocation of some tasks away from humans can be cost-reducing, but to the extent\\nthat human judgment improves when workers gain experience from dealing with a range of\\nproblems and recognize di¤erent aspects of the problem, it may also come at a cost. when\\nsome aspects of the problem are delegated to ai, humans may start losing their \\x87 uency with\\nand ability to understand the holistic aspects of relevant tasks, which can then reduce their\\nproductivity, even in tasks in which they specialize. an extreme example of this phenomenon\\ncan be given from the learning of mathematical reasoning. calculators are much better than\\nhumans in arithmetic. but if students stopped learning arithmetic altogether, delegating all\\nsuch functions to calculators and software, their ability to engage in other type of mathematical\\nand abstract reasoning may su¤er. for this reason, most mathematical curricula still emphasize\\nthe learning of arithmetic. if delegating certain tasks to ai becomes similar to students ceasing\\nto learn arithmetic, it may have signi\\x85cant costs.\\nwould the market adopt ai when there are such economies of scope? the answer depends\\non the exact market structure. because the adoption of ai technologies is associated with a\\n\\x85ner division of labor, there is no guarantee that \\x85rms will internalize the economies of scope.\\nfor example, in the pre-ai equilibrium, the cost of one unit of task 1 is 1/2. so a new \\x85rm\\ncan enter with the ai technology and make pro\\x85ts in this equilibrium. the entry of these\\n\\x85rms would then create a pecuniary externality, discouraging other workers from working on\\ntask 1. in particular, even though there are economies-of-scope bene\\x85ts from performing task\\n1, workers may not be allocated to task 1, because the price of this task is now lower due\\nto the use of ai technologies.5this type of entry could then destroy the pre-ai equilibrium\\nand would drive the economy to the post-ai equilibrium characterized above, even when it is\\nine¢ cient because \\x0cis large.\\nin summary, the general lessons from this short discussion are:\\n1. in addition to the costs of worker displacement discussed earlier in this section, economies\\nof scope across tasks may create additional costs from the use of ai technologies. in par-\\nticular, the deployment of ai in various cognitive tasks that do not require a high degree\\n5there are some market structures and pricing schemes that may prevent the adoption of ai technologies\\nwhen they are ine¢ cient in this case. for example, if workers can take a very low or even negative wage in\\norder to work in task 1 (so as to increase their productivity in task 2), this may outweigh the cost advantage\\nof new \\x85rms that enter and specialize in using ai in task 1. the issues are similar to the ones that arise in the\\ncontext of \\x85rm-sponsored general training, and as in that case, labor and credit market imperfections would\\ntypically preclude the possibility that workers fully pay for all the bene\\x85ts they receive by taking wage cuts\\n(see acemoglu and pischke, 1999).\\n28',\n",
       " 'of human judgment and creativity may enable workers to reallocate their time towards\\ntasks that involve judgment and creativity. but if economies of scope are important for\\nhuman productivity, ai may have additional costs.\\n2. cost-minimization incentives of \\x85rms may encourage them to use ai technologies in\\nine¢ cient ways, when there are such economies of scope.\\n3.4 ai and excessive monitoring\\nanother use of ai-powered technologies is in worker monitoring, as exempli\\x85ed by amazon\\x92 s\\nwarehouses and new monitoring systems for delivery workers. here, too, employers\\x92incentives\\nto improve monitoring and collect information about their employees predates ai. but once\\nagain, ai may magnify their ability to do so. some amount of monitoring by employers may\\nbe useful by improving worker incentives. however, i argue that increasing employer \\x87 exibility\\nin this activity can also lead to ine¢ ciently high levels of monitoring for a very simple reason:\\nat the margin, monitoring is a way of shifting rents away from workers towards employers, and\\nthus is not socially valuable.\\ni now develop this point using a model based on acemoglu and newman (2002). consider\\na one-period economy consisting of a continuum of measure nof workers and a continuum\\nof measure 1of \\x85rm owners, each with a production function af(li)wherelidenotes the\\nnumber of workers employed by \\x85rm iwho exert e¤ort (the alternative, exerting zero e¤ort,\\nleads to zero productivity). firms are large, so the output of an individual worker is not\\nobservable. instead, employers can directly monitor e¤ort in order to determine whether an\\nemployee is exerting e¤ort and being productive.\\nspeci\\x85cally, as in shapiro and stiglitz (1984) a worker exerting e¤ort is never mistakenly\\nidenti\\x85ed as a shirker, and a shirking worker is caught with probability qi=q(mi)wheremiis\\nthe extent of monitoring per worker by \\x85rm i, with cost cmili, wherec > 0. suppose that\\nqis increasing, concave and di¤erentiable with q(0) = 0 andq(m)<1for allm. suppose also\\nthat because of the limited liability constraints, workers cannot be paid a negative wage and\\nwill simply receive a zero wage. this implies a simple incentive compatibility constraint for\\nworkers,\\nwi\\x00e\\x15(1\\x00qi)wi;\\nwhereedenotes the cost of e¤ort. rearranging this equation we obtain:\\n29',\n",
       " 'wi\\x15e\\nq(mi): (6)\\nin addition, the \\x85rm has to respect the participation constraint,\\nwi\\x00e\\x15u; (7)\\nwhereuis the worker\\x92 s ex ante reservation utility, given by what he could receive from another\\n\\x85rm in this market.\\nthe \\x85rm maximizes its pro\\x85ts, given by max\\nwi;li;qi\\x05 =af(li)\\x00wili\\x00cmilisubject to these\\ntwo constraints. as shown in acemoglu and newman (2002), the solution to this problem\\ntakes a simple form because the incentive compatibility constraint always binds \\x97 if it did\\nnot, the \\x85rm would reduce monitoring, increasing its pro\\x85ts. by contrast, the participation\\nconstraint (7) may or may not bind.\\nthe main result from this framework relevant for my discussion is that, regardless of whether\\nthe participation constraint is binding, the equilibrium never maximizes utilitarian social wel-\\nfare (total surplus), given by y=af(l)\\x00cml\\x00el, because there is always too much\\nmonitoring. the intuition is straightforward: at the margin, monitoring is used to transfer\\nrents from workers to \\x85rms, and is thus being used excessively. mathematically, this can be\\nseen in the following way: start from the equilibrium and consider a small decline in monitoring\\ncoupled with a small increase in the wage so that (6) remains binding. this will have only a\\nsecond-order impact on the \\x85rm\\x92 s pro\\x85ts, since the \\x85rm was already maximizing them. but it\\nwill have a \\x85rst-order bene\\x85t for workers, whose wage will increase. thus, a utilitarian social\\nplanner would like to increase wages and reduce monitoring. this is true a fortiori if we care\\nabout income inequality (presuming, of course, that \\x85rm owners are richer than workers).\\nhow does ai a¤ect things in this equilibrium? suppose that before ai, there was an upper\\nbound on monitoring, so that m\\x14\\x16m, and ai lifts this constraint. if the equilibrium level\\nof monitoring without this constraint, m\\x03, is above \\x16m, then improvements in ai will lead to\\nhigher monitoring. if, in addition, \\x16mis not too low, then ai would reduce welfare (the quali\\x85er\\nthat \\x16mshould not be too low is included because, if it were very low, the initial equilibrium\\ncould be very ine¢ cient).\\nthe economic force here is much more general than the simple model i presented: ai, by\\nenabling better control and use of information, provides one more tool to employers to shift\\nrents away from workers to themselves, and this generally leads to ine¢ ciently high levels of\\nrent-shifting activities.\\n30',\n",
       " 'is this potential ine¢ ciency relevant? once again, there is little systematic evidence to\\nsuggest one way or another, but the fact that the us labor market has a \\x93good job\\x94problem,\\nand wages at the bottom of the distribution have fallen in real terms over the last several\\ndecades (acemoglu, 2019; acemoglu and restrepo, 2021) suggests that it may be.\\nin summary, the general lessons from this analysis are:\\n1. ai technologies also create new opportunities for improved monitoring of workers. these\\ntechnologies have \\x85rst-order distributional consequences, because they enable better mon-\\nitoring and thus lower e¢ ciency wages for workers.\\n2. because at the margin the use of monitoring technologies transfers rents from workers to\\n\\x85rms, monitoring will be excessive in equilibrium. by expanding monitoring opportuni-\\nties, ai may thus create an additional social cost.\\n4 ai, political discourse and democracy\\nthe 1990s witnessed rapid strengthening of democracy around the world, in a pattern the\\npolitical scientist samuel huntington (1991) called \\x93the third wave\\x94 . during this process,\\nmany latin american, asian and african countries moved from nondemocratic regimes towards\\ndemocracy and several others strengthened their democratic institutions (marko¤, 1996). the\\nlast decade and a half has witnessed a pronounced reversal of this process, however. several\\ncountries moved away from democracy, and perhaps even more surprisingly, democratic insti-\\ntutions and norms have come under attack in numerous western nations (levitsky and ziblatt,\\n2017; snyder, 2017; mishra, 2017; applebaum, 2020) and the population appears to be more\\npolarized than in the recent past (abramowitz, 2010; judis, 2016). some have pointed to social\\nmedia and online communication as major contributing factors (e.g., marantz, 2020). i now\\nturn to a discussion of these issues. i focus on the e¤ects of ai on communication, political\\nparticipation and democratic politics. as indicated in the introduction, i will highlight several\\ndistinct but related mechanisms via which ai might degrade democratic discourse.\\n4.1 echo chambers and polarization\\nsocial media is often argued to promote echo chambers, in which individuals communicate\\nwith others who are like-minded, and this might prevent them from being exposed to counter-\\nattitudinal viewpoints, exacerbating their biases. cass sunstein noted the potential dangers\\n31',\n",
       " 'of echo chambers as early as 2001. he stated that encountering individuals with opposing\\nopinions and arguments is \\x93important partly to ensure against fragmentation and extremism,\\nwhich are predictable outcomes of any situation which like-minded people speak only with\\nthemselves\\x94 , and emphasized that \\x93many or most citizens should have a range of common\\nexperiences. without shared experiences, a heterogeneous society will have a much more\\ndi¢ cult time in addressing social problems.\\x94(sunstein, 2001, p. 9). the recent documentary\\nthe social dilemma describes the situation as \\x93the way to think about it is as 2.5 billion\\ntruman shows. each person has their own reality with their own facts. over time you have\\nthe false sense that everyone agrees with you because everyone in your news feed sounds just\\nlike you.\\x94ai is crucial to this new reality on social media. for example, the algorithms that\\nsites such as facebook and twitter use in deciding what types of news and messages individuals\\nwill be exposed to is based on applying ai techniques to the massive amount of data that these\\nplatforms collect (alcott and gentzkow, 2017; guriev, henry and zhuravskaya, 2020; mosleh\\net al., 2021). recent studies document that these algorithmic approaches are exacerbating\\nthe problem of misinformation on social media, for example by creating algorithmic \\x93\\x85lter\\nbubbles\\x94 , whereby individuals are exposed much more frequently to news that agrees with\\ntheir priors and biases (levy, 2021). as a result, vosoughi et al. (2018) conclude that on\\nsocial media there is a pattern of \\x93falsehoods di¤using signi\\x85cantly farther, faster, deeper, and\\nmore broadly than the truth in all categories of information\\x94 .\\nin this subsection, i discuss these issues building on the approach in acemoglu, ozdaglar\\nand siderius (2021), which suggests that social media platforms may endogenously create such\\necho chambers, and do so more when there is more extremist content around. consider an\\nonline community in which each individual receives a news item that is circulating (either from\\nan outside source or from other members of the community). the news item may contain\\nmisinformation (which could be downright fake news or some misrepresentation of facts). the\\nindividual decides whether to share the news item she receives.\\neach agent receives utility from sharing news items. however, if she is found out to have\\nshared misinformation, she incurs a cost. to avoid this, she may instead decide to inspect\\nthe news item to check for misinformation and can then decide to kill it. inspecting is costly.\\nthus, all else equal, the individual is more likely to inspect and less likely to share a news item\\nif she thinks it contains misinformation.\\nsuppose that there are two sub-communities, one is left-wing and the other is right-wing,\\nmeaning that one community consists of individuals with priors to the left of some reference\\n32',\n",
       " 'point, normalized 0, and the other one consisting of individuals with priors to the right of 0.\\nfor simplicity, i suppose that the prior of each left-wing community member is the same, some\\nbl<0, and the prior of each right-wing community member is also the same, br>0. each\\nmember of one of these communities is much more likely to be connected to and sharing items\\nwith other members of her community, but there are also some cross-community links. the\\nextent of these cross-community links determines how much \\x93homophily\\x94there is. with high\\nhomophily, there are almost no cross-community links. with low homophily, cross-community\\nlinks are more common.\\neach news item has a type consisting of: (1) a news-related message, which is simply taken\\nto bem2fl;rg, and (2) a reliability score r\\x150, whereby a high reliability score means\\nthat the news item is very unlikely to contain misinformation, while a low reliability score\\nmeans misinformation is quite likely. although this setup is a simpli\\x85ed version of the one in\\nacemoglu, ozdaglar and siderius (2021), a full analysis of the model is still involved. here i\\nsummarize the main features of the equilibrium.\\nsuppose that individuals do not observe the provenance, source and history of the message\\nand do not know whether the message was inspected by others in the past.\\nconsider a right-wing agent receiving a left-wing message. given her prior, she is much\\nmore likely to think that this message contains misinformation than a right-wing message.\\ntherefore, all else equal, she is much more likely to inspect it. this e¤ect is further magni\\x85ed\\nwhen she expects to share it with other fellow right-wingers, because they are also more likely\\nto inspect a left-wing message, and if it contains misinformation, it is likely to be found out,\\nwith costly implications for our focal agent.\\nin contrast, consider this right-wing agent receiving a right-wing message. now she is less\\nsuspicious of the message, and all else being equal, she will use a lower threshold \\x97 this means\\nthat she will choose a lower threshold \\x16rsuch that she inspects it only if the reliability score is\\nr <\\x16r. homophily now has the opposite e¤ect: if she is in a homophilic network, she expects\\nother right-wingers not to inspect the news item either, and as a result, she is less likely to\\ninspect it herself. when an item is not inspected, then it is more likely to become viral \\x97\\neverybody starts sharing it.\\nthese observations lead to the \\x85rst basic result in the setup: a news item is more likely\\nto become viral when (i) it reaches individuals who have congruent beliefs, and (ii) when this\\nconcordant news item is being shared with others with similar beliefs.\\nnow consider the problem of the platform on which this community is situated. suppose\\n33',\n",
       " 'that, via its choice of algorithms, the platform in\\x87 uences the degree of homophily (as in\\nacemoglu, ozdaglar and siderius, 2021). suppose also that the platform\\x92 s objective is to\\nmaximize engagement and hence, greater virality of the article is better for the platform. first\\nsuppose that most of the news items arriving from the outside have high reliability scores\\nand are also being distributed roughly equally between the two sub-communities (so that it is\\nnot only left-wing messages going to the left-wing community and likewise for the right-wing\\ncommunity). then the platform\\x92 s engagement-maximizing policy is likely to be to introduce\\nbetween-community links, thus exposing each individual to news items from the other side,\\nsince these are all reliable and thus unlikely to be killed, even if they were inspected.\\nin contrast, suppose we have a situation in which there are many low-reliability news\\nitems, and moreover left-leaning news items from the outside go to the left-wing community\\nand right-leaning news items go to the right-wing community. if the platform were interested\\nin stopping misinformation, it could choose low homophily (so that right-wing articles go to the\\nleft-wing community as well, for example), and this would induce less sharing among the right-\\nwing agents (expecting inspection from the left-wingers). it would also cause interruptions to\\nvirality when left-wingers discover the right-wing news item to contain misinformation (which\\nis likely since it has low-reliability). these considerations imply that when news items have\\nlower reliability, the platform would prefer to induce extreme homophily via its algorithms and\\npropagate misinformation in order to maximize engagement.\\nthis result, mimicking the main \\x85nding of acemoglu, ozdaglar and siderius (2021), is in\\nsome ways quite striking. it highlights that the platform has incentives to create endogenous\\necho chambers (or \\x85lter bubbles). worse, this happens precisely when there are low-reliability\\nnews items likely to contain misinformation and distributed within the community in a \\x93po-\\nlarized fashion\\x94(left-wing messages going to left-wing groups, etc.).\\nthe role of ai technologies is again crucial. without these technologies, the platform\\nwould not be able to determine users\\x92biases and create relatively-homogeneous communities.\\nit would also not be able to support the rapid dissemination of viral news items.\\nbroader social implications of these types of \\x85lter bubbles are easy to see as well. suppose\\nthat individuals also update their beliefs on the basis of the news items. when left-wingers\\nreceive right-wing news items and the relevant news items have reasonable reliability scores,\\nthey will tend to moderate their beliefs, exactly as sunstein (2001) envisaged in the quote\\nabove. in contrast, when left-wingers receive only left-wing news items in a \\x85lter bubble, this\\nmight lead to further polarization. on the basis of these considerations, acemoglu, ozdaglar\\n34',\n",
       " 'and siderius (2021) suggest various interventions, including regulation and outside inspections,\\nin order to discourage such \\x85lter bubbles and reduce polarization, and i return to the issue of\\nregulation in section 6.\\nin summary, this section leads to the following general lessons:\\n1. ai-powered social media presents a variety of new opportunities for connecting individ-\\nuals and information sharing.\\n2. however, in the process it may also distort individuals\\x92willingness to share unreliable\\ninformation. when social media creates echo chamber-like environments, in which indi-\\nviduals are much more likely to communicate with like-minded others, they become less\\ncareful in inspecting news items that are consistent with their existing views and more\\nwilling to allow the circulation of misinformation.\\n3. centrally, social media platforms that are focused on maximizing engagement have an\\nincentive to create echo chambers (or \\x93\\x85lter bubbles\\x94 ), because inspection and interrup-\\ntions of the circulation of news items with unreliable messages reduces engagement. as\\na result, especially when there are more items with misinformation, platform incentives\\nare diametrically opposed to social objectives.\\n4.2 perils of online communication\\nthe previous subsection argued that political discourse may be hampered because of the algo-\\nrithmic policies of digital platforms. in this subsection, i suggest that there might be reasons\\nmore endemic to the nature of online communication that disadvantages political communi-\\ncation (see also lanier, 2018; tirole, 2021). the main argument is a version of the ideas\\ndeveloped in acemoglu, kleinberg and mullainathan (2022), and here i will provide a simple\\nillustration.\\nconsider \\x85rst a pre-ai world in which large-scale social media communication is not pos-\\nsible. suppose that in such a world, individuals communicate bilaterally in a social network.\\nfor simplicity, we can imagine a social network that takes the form of a directed line, in which\\nwe start with individual 0, who can communicate with individual 1, and all the way up to\\nthe end of the line, individual n. suppose that each individual has a piece of gossip which\\nthey can share with their neighbor, which will give utility vg. in addition, the individual may\\nhave some news relevant for the political/social beliefs of the community. if she decides to\\n35',\n",
       " 'share this and this news item alters the beliefs of her neighbor, she also receives utility from\\nsuch persuasion, as i specify below (for simplicity, i am ignoring potential utility bene\\x85ts from\\nnon-neighbors indirectly changing their beliefs as this information is shared further). because\\nthere are \\x93channel constraints\\x94(for example, limited ability to communicate), the individual\\ncan either share political news or gossip, but not both.\\nspeci\\x85cally, suppose that the state of the world is 0 or 1 (left or right), and all individuals\\nstart with prior \\x160=1\\n2about the underlying state being s= 0. suppose that individual 0\\nreceives a piece of news that shows that the underlying state is in fact s= 0. if she shares this\\ninformation with her neighbor (individual 1) and her neighbor believes it, then her neighbor\\x92 s\\nbelief will also shift to \\x16= 1. however, each individual is also concerned that some agents in\\nsociety may have ulterior motives and try to convince them that the state is the opposite of\\nthe true state s. suppose the probability that each individual attaches to their neighbor being\\nof this extremist type is q. then the posterior of individual 1 that the state is s= 0after\\nreceiving this news will be\\n\\x161=1\\n2\\n1\\n2+1\\n2q=1\\n1 +q>1\\n2:\\nfinally, i assume that individuals receive additional utility from shifting their neighbor\\x92 s\\nbeliefs towards the truth (or her own belief), so the overall utility of individual iis\\nvgxg\\ni+vn\\x0c\\x0c\\x16i+1\\x00\\x16i\\x0c\\x0c;\\nwherexg\\ni= 1denotes whether this individual gossips, \\x16iis her belief, and \\x16i+1is her neighbor\\x92 s\\nbelief (given the line network).\\nlet us assume that vn>2vg, so that if an individual is convinced that her information\\nwill be believed and can thus shift her neighbor\\x92 s belief from 1=2to her views, she prefers to\\nshare the political information rather than gossip. therefore, there exists \\x16qsuch that if q<\\x16q,\\nthe individual will share the political news. let us suppose that in the in-person social network\\nthis inequality is satis\\x85ed.\\nin this scenario, individual 0 will start sharing the political news. this will convince in-\\ndividual 1, who will then attach a su¢ ciently high probability to the underlying state being\\ns= 0. with the same argument, she would also like to convince her neighbor to the right, in-\\ndividual 2. if qis su¢ ciently small, individual 2, even when she is worried about the possibility\\nthat either individual 0 or individual 1 being an extremist, would still believe this information.\\nin general, there will exist some n(q), such that the political news will be communicated up to\\n36',\n",
       " 'individualn(q), and then after that there will be pure gossip on the network. for qsu¢ ciently\\nsmall, the entire network might share the political news.\\nnext suppose that we go to online communication. this leads to a larger network and less\\npersonal contact. as a result, it is plausible to assume that the probability that each agent\\nattaches to the event that the person communicating with them is an extremist is now higher,\\nsayq0> q. ifq0>\\x16q, then in online communication, there will be no news exchange and all\\ncommunication will be gossip.\\nthe situation may be worse when we take into account that online interactions typically\\ntake the form of broadcast (rather than bilateral) communication. this would exacerbate the\\nsituation i have outlined here for two reasons. first, there may be many agents who may\\nwant to broadcast their views, and the same \\x93channel constraints\\x94 would imply that only\\none of them can do so, and broadcasting may be particularly attractive to extremists. this\\nwould endogenously increase the assessment of all the agents that political news is coming\\nfrom extremists. second, if there is heterogeneity in the utility of gossip across agents, those\\nwho value gossiping most may be the ones monopolizing the channels. in both cases, online\\ncommunication becomes less e¤ective as a way of sharing politically or socially relevant infor-\\nmation. if political communication and news sharing in social network is an important aspect\\nof democratic politics, then the forces identi\\x85ed in the subsection also create new challenges\\nfor democracy, again rooted in the use of ai technologies.\\nthe general lessons from this brief analysis are simple as well:\\n1. bilateral, o¤-line communication, especially when the subject matter is political or social,\\nrelies on trust between parties. naturally-existing trust in in-person social networks may\\nenable this type of communication.\\n2. when communication is taking place online and in multi-lateral settings, such as in\\nmodern social media platforms powered by ai technologies, this type of trust-based\\ncommunication becomes harder. this may favor non-political messages, such as gossip,\\nwhich then drive out political communication, with potentially deleterious e¤ects for\\npolitical discourse and democracy.\\n3. this potential barrier to online communication is exacerbated when there is competition\\nfor attention, which is encouraged by the broadcast or multi-lateral nature of online\\ncommunication.\\n37',\n",
       " '4.3 big brother e¤ects\\nthe previous two subsections focused on how ai-powered social media and online platforms\\nchange the nature of communication, with potentially negative e¤ects on the sharing of political\\ninformation, which is the bedrock of democratic participation by citizens. in this subsection, i\\nsuggest that the other crucial pillar of democratic institutions, citizen protests, is likely to be\\nhampered by ai technologies.\\ni have argued in acemoglu and robinson (2000, 2006) that protests, riots and uprisings\\nare critical for the emergence of democratic regimes (because the threats that they pose for\\npower-holders in nondemocratic regimes induces democratization). this argument is relevant\\nfor democratization in currently authoritarian governments, such as china, russia or iran.\\nin particular, if ai-based monitoring of communication and political activity extinguishes\\npolitical dissent and makes it impossible for opposition groups to organize, the longevity of\\nnondemocratic regimes may increase signi\\x85cantly.\\nthe problem is not con\\x85ned to these nondemocratic nations, and applies to the us and\\nother countries with democratic institutions as well. a similar argument suggests that protests\\nand civil disobedience are often critical for the functioning of democratic regimes as well. the\\ncivil rights movement in the us illustrates this vividly. even though the us was democratic\\nat the federal level, the jim crow south routinely violated the political, social and economic\\nrights of black americans. democratic institutions in the north and, to the extent that that\\nthey existed in the south, did not create a natural impetus for these discriminations to cease.\\nthe turning point came with civil disobedience organized by various black (and later multi-\\nethnic) civil society groups, such as the naacp. vitally, even federal politicians opposed to\\njim crow were not in favor of these protests initially, viewing them as disruptive and a political\\ndrawback for them, especially given that any federal action against jim crow practices would\\ntrigger backlash from southern politicians (see the discussion in acemoglu and robinson,\\n2019). without civil disobedience, protest and other sources of bottom-up pressures, it is\\nlikely that reform of voting, civil, education and discrimination laws in the us south would\\nhave been further delayed.\\nhere i brie\\x87 y outline a simple model capturing some of these ideas. consider a society\\nconsisting of \\x15 < 1=2elites and measure 1of regular citizens. all citizens and all elites\\nhave the same economic preferences, but citizens are heterogeneous in terms of their cost of\\nparticipating in protest activities, denoted by cifor individual i. i assume that cis distributed\\nuniformly over [0;1]in the population.\\n38',\n",
       " 'the political system is an imperfect democracy or an autocracy in which political choices\\nare biased in favor of the preferences of the elite. in particular, suppose that there is a unique,\\none-dimensional policy, and the preferred policy choice of the citizens is 0, while the most\\npreferred policy of the elite is pe>0. consider the following reduced-form political game.\\nthe elite decide a policy p, and then protests take place. if a fraction qof the citizens protest\\nand engage in civil disobedience, then there is probability \\x19(q)that the policy will switch from\\npto0. with the complementary probability, the policy stays at p. this political structure\\nignores the in\\x87 uence of the citizens via democratic institutions, which is for simplicity. if this\\nis incorporated, for example, as in acemoglu and robinson (2008), this would not a¤ect the\\nmain message of the model presented here.\\ni also assume that the government can impose a punishment on those engaged in protests.\\nsuppose, in particular, that the state has the capacity to detect at most a measure  of\\nprotesters. if the total amount of protest, q, is less than  , then all protesters are detected\\nand can be punished. i assume that the punishment imposed on protesters is a constant, \\x00,\\nindependent of the number of protesters.\\nthe two key economic decisions are therefore policy choice by elites and protests by citizens.\\nlet me \\x85rst describe the utility of the citizens. suppose that when the policy choice of elites\\nispand there are qprotesters in total, individual ihas the following utility as a function of\\nher protest decision xi2f0;1g:\\nuc\\ni(p;q;xi) =\\x14\\n(vcjpj\\x00ci)\\x00min\\x1a \\nq;1\\x1b\\n\\x00\\x15\\nxi;\\nwhere, for centricity, i have ignored components of the utility that depend on policy choice but\\nare independent of the individual\\x92 s process decision. intuitively, the utility from protesting is\\nincreasing in the distance between the actual policy and the bliss point of citizens, as captured\\nbyvcjpj(recall that their bliss point is at zero). in addition, the individual incurs the cost\\nof participating in protests, given by ci. the second term in square brackets captures the\\nexpected punishment from protesting, taking into account that when q\\x14 , protesters will be\\npunished with probability 1.\\nclearly, there exists a threshold value \\x16c, such that only individuals with ci\\x14\\x16cwill partic-\\nipate, and thus q= \\x16c, since the distribution of cis uniform between 0 and 1.\\nlet us next turn to the elite\\x92 s utility. suppose that this is given by\\nue(p;q) =\\x00e\\x02\\x0c\\x0c^p\\x00pe\\x0c\\x0c\\x03\\n=\\x00(1\\x00\\x19(q))ve\\x0c\\x0c^p\\x00pe\\x0c\\x0c\\x00\\x19(q)ve\\x0c\\x0cpe\\x0c\\x0c;\\n39',\n",
       " 'where ^pdenotes the realized policy and the expectation is over the uncertainty concerning\\nwhether protests will force the elites to change policy. as usual, the subgame perfect equi-\\nlibrium can be solved by backward induction. in the second stage, \\x16cis determined such that\\ngiven the policy choice of elites, p, we have:\\n(vcjpj\\x00 \\x16c(p))\\x00min\\x1a \\n\\x16c(p);1\\x1b\\n\\x00 = 0: (8)\\nin general, there can be multiple equilibria in this stage, because this equation might have\\nmultiple solutions for \\x16c(p). note in particular that its left-hand side may be non-monotonic.\\nin what follows, i focus on the case in which it is monotonically decreasing, which ensures\\na unique equilibrium (if there are multiple equilibria, we could pick the one with the highest\\namount of protest, which will necessarily be one where the left-hand side is decreasing, yielding\\nthe same results). it is then straightforward to see that \\x16c(p)is increasing in p, meaning that\\na more pro-elite policy induces more protests.\\nnow turning to the elite\\x92 s maximization, we \\x85rst rewrite the elite\\x92 s utility function taking\\ninto account the reaction of the citizens to their policy choice:\\nue(p;\\x16c(p)) =\\x00(1\\x00\\x19(\\x16c(p)))\\x0c\\x0cp\\x00pe\\x0c\\x0c\\x00\\x19(\\x16c(p))\\x0c\\x0cpe\\x0c\\x0c;\\nwhich simply substitutes q= \\x16c(p). we can therefore maximize elite utility by choosing the\\ninitial policy p. taking into account that p<pe, this maximization problem yields a standard\\n\\x85rst-order condition:\\n(1\\x00\\x19(\\x16c(p)))\\x00\\x190(\\x16c(p))\\x16c0(p)(2pe\\x00p) = 0; (9)\\nand under suitable assumptions, we can ensure that the second-order condition for maximiza-\\ntion is satis\\x85ed. in this \\x85rst-order condition, \\x16c0(p)is given from (8), and under the assumption\\nthat <\\x16c(p), it can be written as\\n\\x16c0(p) =vc\\n1 + \\x00=\\x16c(p)2:\\nconsider next the introduction of ai, modeled as an increase in  to some 0. from the\\nprevious expression, this increase will reduce \\x16c0(p), and from (9), this reduction in \\x16c0(p)will\\nincreasepaway from the citizens\\x92bliss point and towards the elite\\x92 s preferences. intuitively, ai-\\ninduced government monitoring of protests weakens citizens\\x92ability to force the elites to make\\nconcessions, and the elite respond to the deployment of the ai technology by withdrawing\\nconcessions. as a result, ai makes policies less responsive to citizens\\x92 wishes, and to the\\n40',\n",
       " 'extent that these policies impact the distribution of resources, it will also tend to favor the\\nelite\\x92 s economic interests and increase inequality.\\noverall, the general lessons from this simple model are:\\n1. ai technologies can be used for improving government monitoring against protest activ-\\nities.\\n2. since the threat of protests has a disciplining role on nondemocratic governments, and\\neven on some democratic governments, the shift of power away from civil society towards\\ngovernments will weaken democracy and aggravate policy distortions.\\n4.4 automation, social power and democracy\\nthe previous subsection explained how the use of ai as a tool for controlling society and\\npolitical dissent can have harmful e¤ects on democratic politics. in this subsection, i argue\\nthat ai-powered automation can further weaken democracy and undermine social cohesion.\\nto develop this argument, let us \\x85rst go back to the framework in acemoglu and robinson\\n(2006), which emphasizes two types of conditions for the emergence and survival of democratic\\ninstitutions. first, there must be enough discontent with nondemocratic regimes to generate\\na demand for democracy. second, democracy should not be too costly for the elite, who would\\notherwise prefer repression or other means to avoid sharing political power with the broader\\npopulation. one aspect of this problem, which could be important but was not analyzed in\\nacemoglu and robinson (2006), is cooperation from workers. for example, if workers become\\ndisenchanted with the current regime or decide that they need to take action against current\\n(economic or political) power-holders, they may choose not to cooperate with capital in their\\nworkplaces. when labor is essential for production, this withdrawal of cooperation could be\\nvery costly for capital. when capital owners are in\\x87 uential in the political system, they may\\nthen push for democratization or redistribution in order to placate labor.\\nthe main argument in this subsection is that automation may make workers less indispens-\\nable in workplaces, and as such, it will tend to reduce their political power.\\nlet us return to the model in section 3.1 and for simplicity, suppose that n= 1and\\x1b= 1\\nin the production function (3) and also assume that labor markets are competitive (there is no\\nwage \\x87 oor). this implies that the equilibrium level of production as a function of capital and\\nlabor can be written as\\ny(k;l) =kil1\\x00i,\\n41',\n",
       " 'and thus with competitive labor markets, the labor share is sl= 1\\x00i, and\\nw= (1\\x00i)y(k;l)\\nl:\\nnote also that in this case the impact of automation on output can be written as\\n@lny(k;l)\\n@i= lnk\\x00lnl.\\ntherefore, automation is output-increasing, when lnk > lnl(ork >l, which is also equiva-\\nlent to the competitive rental rate of capital being less than the wage, ensuring that automation\\nis cost-saving). conversely, low-productivity(\\x93so-so\\x94 ) automation now corresponds to the case\\nin whichk\\x19l.\\nconsider a political system as in acemoglu and robinson (2006), where all capital owners\\n(capitalists) are elites and all workers are non-elites, with no within-group heterogeneity. to\\nstart with, let us consider a nondemocratic regime in which the capitalists hold power, or\\nalternatively a democratic regime in which they have disproportionate power. for brevity, i\\nam going to ignore any threat of revolution or protests along the lines of the models considered\\nin acemoglu and robinson (2006) and will also abstract from the considerations discussed in\\nthe previous subsection.\\nsuppose in addition that there is a lump-sum tax on capitalists, which can be redistributed\\nto workers, and let us denote the per-worker transfer on the basis of this by \\x1c. suppose that\\nthe workers have an aspiration for a level of net income given by wa, and ifw+\\x1c < wa,\\nthey withdraw their cooperation, and as a result, the e¤ective productivity of labor declines\\nfrom 1to\\x0e <1. in this reduced-form model, i interpret the transfer \\x1cfrom the elite both\\nas a measure of redistributive politics and also as a general concession to democratic politics\\n(for example, allowing workers to have more voice or making less use of lobbying and other\\nactivities in order to distort democratic politics).\\nthe key question is whether the elite will make the necessary transfers to convince workers\\nto continue cooperating in workplaces. this boils down to the comparison of the following two\\noptions for the elite: redistribute via \\x1cso that the aspirations of the workers are met, or make\\ndo with lower labor productivity due to lack of cooperation. let us write the payo¤s to the\\nelite from these two strategies. suppose there is no within-elite heterogeneity, so it is su¢ cient\\nto look at the overall income of capital. when the capitalists choose to meet the aspiration\\nconstraint of workers, their payo¤ is\\nuk\\n1=kil1\\x00i\\x00max\\x08\\n(1\\x00i)kil1\\x00i;wal\\t\\n;\\n42',\n",
       " 'where the \\x85rst term in the max operator applies when the market wage is already greater\\nthanwa, while the second term is when they have to make transfers in order to bring workers\\nto this level. clearly, the relevant case for the discussion here is the latter, so i assume that\\n(1\\x00i)kil1\\x00i<wal, and thus\\nuk\\n1=kil1\\x00i\\x00wal:\\nthe alternative is not to make the necessary transfer, in which case the elite simply receive\\nthe market return to capital when the productivity of labor has been reduced to \\x0e, i.e.,\\nuk\\n2=ki(\\x0el)1\\x00i:\\nwhat is the e¤ect of automation on the comparison of these two strategies? di¤erentiating\\nthe di¤erence in their payo¤s, uk\\n1\\x00uk\\n2, with respect to iyields\\n@(uk\\n1\\x00uk\\n2)\\n@i<0if and only if lnk\\x00lnl+ln\\x0e\\n1\\x00\\x0e1\\x00i<0:\\nthis expression has two immediate implications. first, if we have low-productivity automa-\\ntion, so that lnk\\x19lnl, then because ln\\x0e<0, automation always makes the second strategy\\nof stopping redistribution and foregoing labor\\x92 s cooperation more attractive. intuitively, au-\\ntomation makes labor less central for production, and thus losing its cooperation becomes less\\ncostly for capital. the economic force going against this calculation is that when automation\\nincreases productivity (when lnk > lnl), the output loss due to lack of cooperation from\\nlabor becomes more costly. second, however, we can also see that, for any kandl, there\\nexists a threshold level i\\x03such that once i >i\\x03, the second strategy is preferred, even taking\\ninto account the productivity gains from automation. therefore, automation makes cooper-\\nation from workers less important, and to the extent that securing this cooperation was an\\nimportant part of the motivation for redistribution and democratic politics, automation may\\nmake elites turn their back on or even become hostile to democracy.\\nin summary, this subsection has established:\\n1. automation can also generate an indirect negative impact on democracy and redistribu-\\ntive politics when ensuring cooperation from labor in workplaces is an important moti-\\nvation for elites to make concessions to labor.\\n2. when automation brings only small productivity gains, it encourages the elite to re-\\nduce redistribution and make fewer democratic concessions. this will make policies less\\nresponsive to the majority\\x92 s wishes and may further raise inequality.\\n43',\n",
       " '3. productivity bene\\x85ts of automation may soften this e¤ect, because an automation-driven\\nincrease in output raises the opportunity cost of losing labor\\x92 s cooperation. nevertheless,\\nthere exists a su¢ ciently high level of automation such that once we reach this level, labor\\nbecomes su¢ ciently irrelevant for production that the withdrawal of their cooperation\\nceases to be very costly. after this threshold, the elite may prefer to abandon democratic\\ninstitutions and withhold any concessions, and proceeds without labor\\x92 s cooperation,\\nonce again with harmful e¤ects on democracy, redistribution and social cohesion.\\n5 other potential costs\\nin this section, i brie\\x87 y list a few other areas that may be important, but without providing\\nas much detail or any formal analysis.\\nthe threat of ai and bargaining: even when the actual labor market e¤ects of ai discussed\\nin section 3 are not realized, the threat of adopting ai technologies may in\\x87 uence wages and\\ninequality. speci\\x85cally, if there is bargaining and rent-sharing, employers may use the threat\\nof ai-based automation as a way of increasing their bargaining power, which could have some\\nof the same e¤ects as actual automation and ai-powered monitoring.\\ndiscrimination: bias in ai has already received considerable attention. as ai gains greater\\nimportance in our social and economic life, ensuring that popular algorithms are fair and\\nunbiased has become vital. existing studies show that simple ai algorithms can improve\\nimportant public decisions, such as bail or sentencing, without increasing discrimination (e.g.,\\nkleinberg et al., 2018). however, in most such applications, algorithms use data generated from\\nbiased agents and potentially discriminatory practices (e.g., thompson, 2019). for example,\\nboth the police and the legal system in the us are generally thought to be biased against certain\\ngroups, such as black americans. in such situations, there is a danger that these biases will\\nbecome a fundamental part of ai algorithms. this may not only promote persistent bias\\nand discrimination, but may in fact cement these biases more deeply in society via a process\\nsimilar to the \\x93signaling role of laws\\x94 (e.g., posner, 2002). indeed, if society starts trusting\\nai algorithms, their discriminatory choices may come to be accepted as more justi\\x85able than\\nwhen they were made by individual decision-makers.\\ntechnocracy versus democracy: advances in ai may create the temptation to delegate more\\nand more public and even political decisions to algorithms or to technocrats designing and using\\n44',\n",
       " 'these algorithms. although this may be justi\\x85able for certain decisions, excessive reliance on\\ntechnocracy, without citizen input, may also start encroaching into political decisions \\x97 such\\nas the extent of redistributive taxation or how much we should protect disadvantaged groups\\n(sandel, 2020). in this case, reliance on ai may further undermine democracy, amplifying the\\nconcerns highlighted in the previous section.\\nai-powered weapons: ai technologies have already started being incorporated into weapons\\nand are advancing towards autonomous weapon systems. these new technologies will cause\\na host of ethical and social dilemmas, and may need to be regulated before prototypes are\\ndeployed or even fully developed. in addition to these ethical and social issues, ai-powered\\nweapons may further strengthen governments against civil society, protesters and even some\\nopposition groups, adding to the concerns we discussed in the previous section.\\nthe alignment problem: the potential downside of ai technologies that has received most\\nattention is the \\x93alignment problem\\x94 : the problem of ensuring that intelligent machines have\\nobjectives that are aligned with those of humanity. many researchers and public intellectuals\\nare concerned about machines reaching super-human capabilities and then implicitly or explic-\\nitly turning against humans (e.g., bostrom, 2014, russell 2019, christian, 2019). although my\\nown view is that these concerns are somewhat overblown and often distract from shorter-term\\nproblems created by ai technologies (on which this essay has focused), they deserve careful\\nconsideration, monitoring and preparation.\\nthe international dimension: the current development of ai technologies is intertwined\\nwith international competition, especially between the us and china (lee, 2018). a discussion\\nof regulation of ai has to take into account this international dimension. for example, it\\nmay not be su¢ cient for the us and europe to start regulating the use of data or excessive\\nautomation, when they remain almost completely unregulated in china. this suggests that\\nthe regulation of ai needs to have a fully-\\x87 edged international dimension and we may need to\\nbuild new international organizations to coordinate and monitor deregulation of ai across the\\nglobe.\\n6 the role of technology choice and regulation\\nin the preceding sections, i went through a number of theoretical arguments suggesting that\\nthe deployment of ai technologies may generate economic, political and social costs. in this\\n45',\n",
       " 'section, i highlight that in all of these cases the problems are not inherent to ai technologies\\nper se. rather, the harms i have emphasized are caused by corporate and societal choices on\\nhow these technologies are deployed. even though these costs are far-ranging, taking place\\nin product markets, in labor markets and in the realm of politics, they exhibit a number of\\ncommonalities, which i explore in this section. i also discuss some possible remedies. the\\ngeneral emphasis in this section will be on three main ideas:\\n1. the importance of choices, both on how existing ai technologies are used and on the\\ndirection of ai research. the costs i have modeled are not in the nature of ai technolo-\\ngies, but depend on how this new technological platform is being developed to empower\\ncorporations and governments against citizens and workers.\\n2. the inadequacy of market solutions that mainly rely on increasing competition.\\n3. the need for regulation.\\nlet me start with the mechanisms discussed in section 2. all three of these potential costs\\nof ai turn on how ai technologies enable the use and control of data. in each one of these\\ncases, a di¤erent way of distributing control rights over data would ameliorate or prevent most\\nof the costs (posner and weyl, 2019). let us start with the model of data markets in section\\n2.1. the source of ine¢ ciency in this case is the ability of platforms to \\x85nd out information\\nabout others from the data that an individual shares. this then opens the way to potential\\nmisuses of data, for example in order to reduce the surplus of consumers or by violating their\\nprivacy in other ways. e¤ective regulation in this case could take one of two forms. first, as\\nsuggested in acemoglu et al. (2021), it may be possible to strip away parts of the data of an\\nindividual in order to prevent or minimize information about others being leaked (though the\\ndetails matter here, and just anonymizing data would not be useful). second, more systematic\\nregulations on how platforms can utilize the information they acquire would lessen the harmful\\ne¤ects working through privacy.\\nin contrast, increasing competition may not be su¢ cient, and not even useful, in this case.\\nmy analysis in section 2.1 focused on a monopoly platform. acemoglu et al. (2021) show\\nthat if there are two platforms that are competing to attract users, this may exacerbate the\\npernicious e¤ects of data externalities.\\nlet me then turn to the model considered in section 2.3. the source of ine¢ ciency in this\\ncase is the ability of platforms to use the data individuals reveal about themselves in order to\\n46',\n",
       " 'manipulate their weaknesses. if this misuse of data can be prevented or if consumers can be\\nmade more aware of how data are being used, some of these costs could be prevented. suppose,\\nfor example, that consumers are informed frequently that platforms know more about their\\npreferences and sometimes market products that are bad for them. there is no guarantee that\\nsuch informational warnings will work for all consumers, but if they are displayed saliently and\\nare speci\\x85c (for example, calibrated according to the group of individuals and relevant class of\\nproducts), they may prevent some of the harms identi\\x85ed by the analysis above. in this case,\\ntoo, increasing competition would not be an e¤ective solution. if two platforms are competing\\nfor consumers, but consumers continue to be semi-behavioral and fail to recognize the increase\\nin platform capabilities, both platforms may try to exploit their ability to o¤er products that\\nhave short-term apparent bene\\x85ts and long-term costs.\\nthe issues are similar when we turn to the economic forces studied in section 2.2, but\\nnow the implications of competition are more nuanced. in this case, e¤ective regulation would\\nprevent one of the \\x85rms from using the additional information it acquires for capturing all of\\nthe consumer surplus. price controls and limits on price discrimination might be some of the\\nmethods for achieving this, though clearly such regulation is far from straightforward. what\\nhappens if we can increase competition in this case? greater competition that results from\\n\\x85rm 0 also using ai methods to estimate its own past consumers\\x92preferences and customize its\\nservices accordingly would not be necessarily useful. now both \\x85rms become local monopolists,\\ncapturing all of the consumer surplus. however, if each \\x85rm can also acquire information about\\nthe other\\x92 s customers and collusion can be prevented, then they can be induced to compete\\n\\x85ercely, from which consumers might bene\\x85t. this case thus highlights that in some scenarios\\nfostering competition might have bene\\x85ts, though even in this instance, it can only do so to a\\nlimited extent and only when some case-speci\\x85c conditions are satis\\x85ed.\\ni would also like to emphasize the implications for the direction of ai research in this case.\\nsuppose that ai researchers can devote their time in order to develop alternative applications\\nof this broad technological platform. for example, some of them may be able to use ai to\\ncreate tools that empower citizens or consumers, or develop new technologies for preserving\\nprivacy. all the same, if any one of the mechanisms related to the control and misuse of\\ninformation are relevant, then this will also produce a powerful demand for technologies that\\nenable corporations to acquire and better exploit this type of information. this is more so\\nwhen the ability of consumers to pay for alternative technologies is limited relative to the\\nresources in the hands of corporations. in such scenarios, the demand for \\x93misuse of ai\\x94will\\n47',\n",
       " 'be transmitted to ai researchers, who may then respond by devoting their time to developing\\nthe ai technologies that corporations need and by moving further away from technologies that\\nmay have greater social value or empower consumers and citizens. this is a general point,\\nwhich applies whether the harmful e¤ects of ai are on the control of information, in labor\\nmarkets or in the context of politics. it is for this reason that innovation, when it is itself\\nunregulated, is unlikely to produce self-correcting dynamics. on the contrary, the demand\\nfor misuse of ai will typically distort the allocation of research across di¤erent applications,\\namplifying its social and economic costs.\\nthe same considerations apply even more evidently in the models i discussed in section 3.\\nif automation is excessive, increasing competition in the labor market would not be particularly\\nuseful. on the other hand, the demand for automation technologies from \\x85rms will tend to\\nbe strong, encouraging researchers to double down on using ai for developing automation\\ntechnologies. regulatory solutions are again feasible, but may be more di¢ cult to design and\\nimplement in this case. in theory, when automation is excessive and ai research is not being\\ndirected to creating new tasks, welfare-promoting regulation should discourage automation at\\nthe margin and encourage the creation of new labor-intensive tasks.\\nhowever, distinguishing marginal (low-productivity) and infra-marginal (higher-\\nproductivity) automation is di¢ cult. even more challengingly, regulators might have a hard\\ntime separating ai used for creating new tasks from ai being used for automating low-skill\\ntasks while empowering higher-skilled or managerial workers. but it is also possible to view\\nthese problems not as absolute barriers but as measurement challenges. more research might\\nshed light on how to distinguish di¤erent uses of ai in the labor market and might reveal new\\nregulatory approaches for in\\x87 uencing the direction of ai research.\\nfinally, there are similar lessons from the models we discussed in section 4, though there\\nare also some new challenges related to the fact that the e¤ects are now on political and\\ndemocratic outcomes. for one, increasing competition is unlikely to be a very e¤ective way of\\ndealing with misaligned platform incentives. for example, if there are multiple social media\\nplatforms trying to maximize engagement, each may have incentives to create \\x85lter bubbles.\\npro-competitive solutions may also be less e¤ective when there are systemic issues, such as the\\nwidespread malfunctioning of democratic institutions.\\nthe e¤ects of these new technologies for democratic politics raises new conceptual issues as\\nwell. most importantly, if the incorrect deployment of ai technologies is weakening democratic\\npolitics, developing after-the-fact regulatory solutions might become harder, since democratic\\n48',\n",
       " 'scrutiny of those who bene\\x85t from the distortionary use of ai technologies would also becomes\\nmore di¢ cult. these considerations then suggest a \\x93precautionary regulatory principle\\x94\\x97 ex\\nante regulation slowing down the use of ai technologies, especially in domains where redressing\\nthe costs of ai become politically and socially more di¢ cult after large-scale implementation.\\nai technologies impacting political discourse and democratic politics may be prime candidates\\nfor the application of such a precautionary regulatory principle.\\n7 conclusion\\nin this essay, i explored several potential economic, political and social costs of the current\\npath of ai technologies. i suggested that if ai continues to be deployed along its current\\ntrajectory and remains unregulated, then it can harm competition, consumer privacy and\\nconsumer choice, it may excessively automate work, fuel inequality, ine¢ ciently push down\\nwages, and fail to improve productivity. it may also make political discourse increasingly\\ndistorted, cutting one of the lifelines of democracy. i also mentioned several other potential\\nsocial costs from the current path of ai research\\ni should emphasize again that all of these potential harms are theoretical. although there\\nis much evidence indicating that not all is well with the deployment of ai technologies and\\nthe problems of increasing market power, disappearance of work, inequality, low wages, and\\nmeaningful challenges to democratic discourse and practice are all real, we do not have su¢ cient\\nevidence to be sure that ai has been a serious contributor to these troubling trends.\\nnevertheless, precisely because ai is a promising technological platform, aiming to trans-\\nform every sector of the economy and every aspect of our social lives, it is imperative for us\\nto study what its downsides are, especially on its current trajectory. it is in this spirit that i\\ndiscussed the potential costs of ai this paper.\\nmy own belief is that several of these costs are real and we may see them multiply in the\\nyears to come. empirical work exploring these issues is therefore greatly needed.\\nbeyond empirical work, we also need to understand the nature and sources of these potential\\ncosts and how they can be prevented. it is for this reason that i suggested various policy\\nresponses, in each case emphasizing that the costs are rooted in the way that corporations and\\ngovernments are choosing to develop and use these technologies. therefore, my conclusion is\\nthat the best way of preventing these costs is to regulate ai and redirect ai research, away\\nfrom these harmful endeavors and towards areas where ai can create new tasks that increase\\n49',\n",
       " 'human productivity and new products and algorithms that can empower workers and citizens.\\nof course, i realize that such a redirection is unlikely, and regulation of ai is probably more\\ndi¢ cult than the regulation of many other technologies \\x97 both because of its fast-changing,\\npervasive nature and because of the international dimension. we also have to be careful, since\\nhistory is replete with instances in which governments and powerful interest groups opposed\\nnew technologies, with disastrous consequences for economic growth (see, e.g., acemoglu and\\nrobinson, 2012). nevertheless, the importance of these potential harms justi\\x85es the need to\\nstart having such conversations.\\n50',\n",
       " 'references\\nabramowitz, alan i. (2010) the disappearing center: engaged citizens, polarization,\\nand american democracy . new haven, ct: yale university press.\\nacemoglu, daron (2002) \\x93technical change, inequality, and the labor mar-\\nket,\\x94journal of economic literature , 40(1): 7\\x96 72.\\nacemoglu, daron (2019) \\x93it\\x92 s good jobs stupid,\\x94 economics for inclusive prosperity ,\\nresearch brief, june 2019. https://econ\\x85p.org/wp-content/uploads/2019/06/its-good-jobs-\\nstupid.pdf\\nacemoglu, daron (2021) \\x93ai\\x92 s future doesn\\x92 t have to be dystopian,\\x94 boston review ,\\nmay 20, 2021. http://bostonreview.net/forum/science-nature/daron-acemoglu-redesigning-ai\\nacemoglu, daron and david h. autor (2011) \\x93skills, tasks and technologies: impli-\\ncations for employment and earnings,\\x94in ashenfelter, orley and david card, eds., handbook\\nof labor economics, volume 4 : amsterdam, holland: el sevier.\\nacemoglu, daron, david h. autor, jonathon hazell and pascual restrepo\\n(2021) \\x93ai and jobs: evidence from online vacancies,\\x94nber working paper no. 28257.\\nacemoglu, daron and simon johnson (2022) men of genius: how hubris ruined\\ntechnology and prosperity . book manuscript.\\nacemoglu, daron, jon kleinberg and sendhil mullainathan (2022) \\x93problems of\\nonline communication,\\x94work in progress.\\nacemoglu, daron, ali makhdoumi, azarakhsh malekian and asu ozdaglar\\n(2021) \\x93too much data: prices and ine¢ ciencies in data markets,\\x94forthcoming american\\neconomic journal: micro .\\nacemoglu, daron, ali makhdoumi, azarakhsh malekian and asu ozdaglar\\n(2022) \\x93a model of behavioral manipulation,\\x94work in progress.\\nacemoglu, daron, andrea manera and pascual restrepo (2020) \\x93does the us\\ntax code favor automation?\\x94 brookings papers on economic activity , 2020(1): 231\\x96 285.\\nacemoglu, daron and andrew f. newman (2002) \\x93the labor market and corpo-\\nrate structure,\\x94 european economic review 46(10): 1733-1756.\\nacemoglu, daron, asu ozdaglar and james siderius (2021) \\x93misinformation:\\nstrategic sharing, homophily and endogenous echo chambers,\\x94nber working paper no.\\n28884.\\nacemoglu, daron and jörn-ste¤en pischke (1998) \\x93the structure of wages and\\n51',\n",
       " 'investment in gen. training,\\x94 journal of political economy, 107(3): 539-572.\\nacemoglu, daron and james a. robinson (2006) \\x93why did the west extend the\\nfranchise? democracy, inequality and growth in historical perspective,\\x94 quarterly journal\\nof economics, 115(4): 1167-1199.\\nacemoglu, daron and james a. robinson (2006) economic origins of dictatorship\\nand democracy . new york, ny: cambridge university press.\\nacemoglu, daron and james a. robinson (2008) \\x93persistence of power, elites and\\ninstitutions,\\x94 american economic review , 98(1): 267-93.\\nacemoglu, daron and james a. robinson (2012) why nations fail: the origins\\nof power, prosperity, and poverty. new york, ny: crown business.\\nacemoglu, daron and james a. robinson (2019) the narrow corridor: states,\\nsocieties, and the fate of liberty. new york, ny: penguin press.\\nacemoglu, daron and pascual restrepo (2018) \\x93the race between man and ma-\\nchine: implications of technology for growth, factor shares and employment,\\x94 american\\neconomic review , 108(6): 1488\\x96 1542.\\nacemoglu, daron and pascual restrepo (2019) \\x93automation and new tasks: how\\ntechnology changes labor demand,\\x94 journal of economic perspectives , 33(2): 3\\x96 30.\\nacemoglu, daron and pascual restrepo (2021) \\x93tasks, automation and the rise in\\nus wage inequality,\\x94nber working paper no. 28920.\\nagarwal, ajay, joshua s. gans and avi goldfarb (2018) prediction machines: the\\nsimple economics of arti\\x85cial intelligence. cambridge, ma: harvard business review.\\nallcott, hunt and matthew gentzkow (2017) \\x93social media and fake news in the\\n2016 election,\\x94 journal of economic perspectives , 31: 211\\x96 36.\\napplebaum, ann (2020) twilight of democracy: the seductive lure of authoritarian-\\nism. new york, ny: signal.\\nathey, susan, c. catalini, and catherine tucker (2017) \\x93the digital privac digital:\\nsmall money, small costs, small talk,\\x94nber working paper no. 23488.\\nautor, david h. (2014) \\x93skills, education and the rise of earnings inequality among\\nthe other 99 percent,\\x94 science 344(6186): 843-851.\\nautor, david h., frank levy and richard j. murnane (2003) \\x93the skill content\\nof recent technological change: an empirical exploration,\\x94 quarterly journal of economics,\\n118(4): 1279\\x96 1333.\\nautor, david h., david dorn, and gordon h. hanson (2013) \\x93the china syn-\\n52',\n",
       " 'drome: local labor market e¤ects of import competition in the united states,\\x94 american\\neconomic review 103(6): 2121\\x96 68\\nbergemann, dirk, alessandro bonatti, and tan gan (2021) \\x93markets for infor-\\nmation,\\x94yale mimeo.\\nbostrom, nick (2017) superintelligence . new york, ny: danod.\\nbrynjolfsson, erik and andrew mcafee (2014) the second machine age: work,\\nprogress, and prosperity in a time of brilliant technologies . new york, ny: w. w. norton\\n& company.\\nbudd, christopher, christopher harris, and john vickers (1993) \\x93a model of the\\nevolution of duopoly: does the asymmetry between firms tend to increase or decrease?\\x94\\nreview of economic studies 60(3): 543-573.\\nchoi, j.p., d.-s. jeon, and b.-c. kim (2019) \\x93privacy and personal data collection\\nwith information externalities,\\x94 journal of public economics , 173: 113\\x96 124.\\nchristian, brian (2019) the alignment problem: machine learning and human values .\\nnew york, ny: ww norton & company.\\ndreyfus, hubert l. (1992) what computers still can\\x92 t do: a critique of arti\\x85cial\\nreason. cambridge, ma: mit press.\\nfarboodi, maryam, r. mihet, thomas philippon, and laura veldkamp (2019)\\n\\x93big data and firm dynamics,\\x94 american economic review: papers and proceedings ,109,\\n38\\x96 42.\\nford, martin (2015) rise of robots . new york, ny: basic books.\\nforester, tom (1985) the information technology revolution . cambridge, ma: mit\\npress.\\nguriev, sergei, emeric henry, and ekaterina zhuravskaya (2020) \\x93checking and\\nsharing alt-facts.\\x94mimeo.\\nhanson jon d. and douglas a. kysar (1999) \\x93taking behavioralism seriously: some\\nevidence of market manipulation,\\x94 new york university law review , 74: 630.\\nhuntington, samuel p. (1991) the third wave: democratization in the late twentieth\\ncentury . norman, ok: university of oklahoma press.\\njones, charles i. and christopher tonetti (2020) \\x93non-rivalry in the economics of\\ndata,\\x94 american economic review, 110(9): 2819-58.\\njudis, john b. (2016) the populist explosion: how the great recession transformed\\namerican and european politics . new york, ny: columbia global reports.\\n53',\n",
       " 'kleinberg, j., lakkaraju, h., leskovec, j., ludwig, j., & mullainathan, s.\\n(2018) \\x93human decisions and machine predictions,\\x94 quarterly journal of economics , 133(1):\\n237-293.\\nklemperer, paul (1995) \\x93competition when consumers have switching costs: an\\noverview with applications to industrial organization, macroeconomics and international\\ntrade,\\x94 review of economic studies , 62(4): 515-539.\\nlanier, jaron (2018) ten arguments for deleting your social media accounts right\\nnow. new york, ny: ho¤mann and co.\\nlee, david s. (2009) \\x93wage inequality in the united states during the 1980s: rising\\nthis version or falling minimum wage?\\x94 quarterly journal of economics, 114(3): 977-1023.\\nlee, kai-fu (2018) ai superpowers: china, silicon valley, and the new world order .\\nnew york, ny: houghton mi\\xad in harcourt.\\nlevy, roee (2021) \\x93social media, news consumption, and polarization: evidence from\\na field experiment.\\x94 american economic review.\\nmaccarthy, m .(2016) \\x93new directions and privacy: disclosure, unfairness and exter-\\nnalities\\x94mimeo. https://ssrn.com/abstract=3093301.\\nmarantz, andrew (2020) antisocial: online extremists, techno-utopians and the hi-\\njacking of the american conversation. penguin, new york, ny\\nmishra, p. (2017) age of anger: a history of the present . macmillan, new york, ny.\\nmarko¤, john (1996) waves of democracy: social movements and political change .\\nthousands oaks: pine forge press.\\nmosleh, mohsen, cameron martel, dean eckles, and david g. rand (2021)\\n\\x93shared partisanship dramatically increases the social tie formation in a twitter field ex-\\nperiment,\\x94 proceedings of the national academy of sciences , 118(7): 1-3.\\nneapolitan, richard e. and xia jiang (2018) arti\\x85cial intelligence: with an intro-\\nduction to machine learning, 2nd ed. london, uk: chapman and hall/crc.\\nnilsson, nils j. (2009) the quest for arti\\x85cial intelligence: a history of ideas and\\nachievements. new york, ny: cambridge university press.\\npasquale, frank (2015) the black box society: the secret algorithms that control\\nmoney and information. cambridge, ma: harvard university press.\\nposner, eric a. (2002) law and social norms . cambridge, ma: harvard university\\npress.\\nposner, eric a. and e. glen weyl (2019) radical markets. princeton, nj: princeton\\n54',\n",
       " 'university press.\\nrussell, stuart j. and peter norvig (2009) arti\\x85cal intelligence: a modern approach,\\n3rd ed. hoboken, nj: prentice hall.\\nrussell, stuart j. (2019) human compatible: arti\\x85cial intelligence and the problem of\\ncontrol . new york, ny: penguin press.\\nsandel, michael j. (2020) the tyranny of merit: what\\x92 s become of the common good?\\nnew york, ny: penguin press.\\nshapiro, carl and joseph e. stiglitz (1984) \\x93equilibrium unemployment as worker\\ndiscipline device\\x94 american economic review 74(3): 433-444.\\nsimonite tom (2020) algorithms were supposed to fix the bail system. they haven\\x92 t.\\x94\\nwired. https://www.wired.com/story/algorithms-supposed-\\x85x-bail-system-they-havent/\\nsnyder, timothy (2017) on tyranny: twenty lessons from the twentieth century .\\ntoronton, ontario: tim duggan books.\\nsunstein, cass (2001) republic.com , princeton, nj: princeton university press.\\ntirole, jean (1989) industrial organization . cambridge ma: mit press.\\ntirole, jean (1921) \\x93digital dystopia,\\x94 american economic review , 111(6): 2007-48.\\nthompson, derek (2019) \\x93should we be afraid of ai in the criminal-justice system?\\x94\\nthe atlantic . https://www.theatlantic.com/ideas/archive/2019/06/should-we-be-afraid-of-ai-\\nin-the-criminal-justice-system/592084/\\nvarian, hal r. (2009) \\x93economic aspects of personal privacy,\\x94 internet policy and\\neconomics , 101\\x96 109. springer.\\nvosoughi, soroush, deb roy, and sinan aral (2018) \\x93the spread of true and false\\nnews online,\\x94 science , 359: 1146\\x96 1151.\\nwest, darrell m. (2018) the future of work: robots, ai and automation . , washing-\\nton, dc: brookings institution press.\\nzubo¤, shoshana (2019) the age of surveillance capitalism: the fight for a human\\nfuture at the new frontier of power. london, uk: pro\\x85le books.\\n55',\n",
       " 'darpa ’s explainable\\nartiﬁcial intelligence program\\ndavid gunning, david w. aha\\nndramatic success in machine learning\\nhas led to a new wave of ai applications (forexample, transportation , security, medicine,\\nﬁnance, defense) that offer tremendous\\nbeneﬁts but cannot explain their decisions\\nand actions to human users. darpa ’s\\nexplainable arti ﬁcial intelligence (xai)\\nprogram endeavors to create ai systems\\nwhose learned models and decisionscan be understood and appropriatelytrusted by end users. realizing this goal\\nrequires methods for learning more\\nexplainable models, designing effectiveexplanation interfaces, and understandingthe psychologic requirements for effective\\nexplanations. the xai developer teams are\\naddressing the ﬁrst two challenges by\\ncreating ml techniques and developingprinciples, strategies, and human-computer\\ninteraction techniques for generating effec-\\ntive explanations. another xai team isaddressing the third challenge by summa-\\nrizing, extending, and applying psychologic\\ntheories of explanation to help the xaievaluator de ﬁne a suitable evaluation\\nframework, which the developer teams\\nwill use to test their systems. the xai\\nteams completed the ﬁrst of this 4-year\\nprogram in may 2018. in a series ofongoing evaluations, the developer\\nteams are assessing how well their xam\\nsystems ’explanations improve user un-\\nderstanding, user trust, and user task\\nperformance.advances in machine learning (ml) techniques promise\\nto produce ai systems that perceive, learn, decide, and\\nact on their own. however, they will be unable to\\nexplain their decisions and actions to human users. this lackis especially important for the department of defense, whosechallenges require developing more intelligent, autonomous,\\nand symbiotic systems. explainable ai will be essential if\\nusers are to understand, appropriately trust, and effectivelymanage these arti ﬁcially intelligent partners. to address this,\\ndarpa launched its explainable arti ﬁcial intelligence (xai)\\nprogram in may 2017. darpa de ﬁnes explainable ai as ai\\nsystems that can explain their rationale to a human user,\\ncharacterize their strengths and weaknesses, and convey an\\nunderstanding of how they will behave in the future. namingthis program explainable ai (rather than interpretable,\\ncomprehensible, or transparent ai, for example) re ﬂects\\ndarpa ’s objective to create more human-understandable ai\\nsystems through the use of effective explanations. it alsoreﬂects the xai team ’s interest in the human psychology of\\nexplanation, which draws on the vast body of research and\\nexpertise in the social sciences.\\n44 ai magazine\\ncopyright © 2019, association for the advancement of arti ﬁcial intelligence. all rights reserved. issn 0738-4602deep learning and security',\n",
       " 'early ai systems were predominantly logical and\\nsymbolic; they performed some form of logical in-\\nference and could provide a trace of their inferencesteps, which became the basis for explanation. therewas substantial work on making these systems more\\nexplainable, but they fell short of user needs for\\ncomprehension (for example, simply summarizingthe inner workings of a system does not yield a suf-\\nﬁcient explanation) and proved too brittle against\\nreal-world complexities.\\nrecent ai success is due largely to new ml tech-\\nniques that construct models in their internal repre-\\nsentations. these include support vector machines,random forests, probabilistic graphical models, re-inforcement learning (rl), and deep learning (dl)\\nneural networks. although these models exhibit high\\nperformance, they are opaque. as their use has in-creased, so has research on explainability from the\\nperspectives of ml (chakraborty et al. 2017; ras et al.\\n2018) and cognitive psychology (miller 2017). simi-larly, many xai-related workshops have been held re-\\ncently on ml (for example, the international conference\\non machine learning, the conference on neural in-formation processing systems), ai (for example, the in-\\nternational joint conference on arti ﬁcial intelligence),\\nand hci (for example, the conference on human-computer interaction, intelligent user interfaces) con-ferences, as have special topic meetings related to xai.\\nthere seems to be an inherent tension between ml\\nperformance (for example, predictive accuracy) andexplainability; often the highest-performing methods\\n(for example, dl) are the least explainable, and the\\nmost explainable (for example, decision trees) are theleast accurate. figure 1 illustrates this with a notional\\ngraph of the performance-explainability trade-off for\\nvarious ml techniques.\\nwhen darpa formulated the xai program, it envi-\\nsioned three broad strategies to improve explainability,\\nwhile maintaining a high level of learning performance,\\nbased on promising research at the time ( ﬁgure 2): deep\\nexplanation, interpretable models, and model induction.\\ndeep explanation refers to modi ﬁed or hybrid dl\\ntechniques that learn more explainable features orrepresentations or that include explanation genera-\\ntion facilities. several design choices might produce\\nmore explainable representat ions (for example, training\\ndata selection, architectu ral layers, loss functions,\\nregularization, optimizat ion techniques, training\\nsequences). researchers have used deconvolutionalnetworks to visualize convolutional network layers, andtechniques existed for associating semantic concepts\\nwith deep network nodes. a pproaches for generating\\nimage captions could be extended to train a second deepnetwork that generates explan ations without explicitly\\nidentifying the original network ’s semantic features.\\ninterpretable models are ml techniques that learn\\nmore structured, interpretable, or causal models. early\\nexamples included bayesian rule lists (letham et al.\\n2015), bayesian program learning, learning models ofcausal relationships, and use of stochastic grammars\\nto learn more interpretable structure.model induction refers to techniques that experi-\\nment with any given ml model —such as a black\\nbox—to infer an approximate explainable model. for\\nexample, the model-agnostic explanation system ofribeiro et al. (2016) inferred explanations by ob-\\nserving and analyzing the input-output behavior of a\\nblack box model.\\ndarpa used these strategies to categorize a portfolio\\nof new ml techniques and provide future practitioners\\nwith a wider range of design options covering theperformance-explainability trade space.\\nxai concept and approach\\nthe xai program ’s goal is to create a suite of new or\\nmodi ﬁed ml techniques that produce explainable\\nmodels that, when combined with effective explanation\\ntechniques, enable end users to understand, appropri-\\nately trust, and effectively manage the emerging gen-eration of ai systems. the target of xai is an end user\\nwho depends on decisions or recommendations pro-\\nduced by an ai system, or actions taken by it, andtherefore needs to understand the system ’s rationale.\\nfor example, an intelligence analyst who receives rec-\\nommendations from a big da ta analytics system needs\\nto understand why it recommended certain activity forfurther investigation. similarly, an operator who tasks\\nan autonomous vehicle to drive a route needs to un-\\nderstand the system ’s decision-making model to ap-\\npropriately use it in future missions. figure 3 illustrates\\nthe xai concept: provide users with explanations that\\nenable them to understand the system ’s overall\\nstrengths and weaknesses, convey an understanding of\\nhow it will behave in future or different situations, and\\nperhaps permit users to correct the system ’sm i s t a k e s .\\nthis user-centered concept poses interrelated re-\\nsearch challenges: (1) how to produce more explain-\\nable models, (2) how to design explanation interfaces,\\nand (3) how to understand the psychologic require-ments for effective explanations. the ﬁrst two chal-\\nlenges are being addressed by the 11 xai research\\nteams, which are developing new ml techniques toproduce explainable models, and new principles,\\nstrategies, and hci techniques (for example, visuali-\\nzation, language understanding, language generation)to generate effective explanations. the third challenge\\nis the focus of another xai research team that is\\nsummarizing, extending, and applying psychologictheories of explanation.\\nthe xai program addresses two operationally rel-\\nevant challenge problem areas ( ﬁgure 4): data analytics\\n(classi ﬁcation of events of interest in heterogeneous\\nmultimedia data) and auto nomy (decision policies\\nfor autonomous systems). these areas represent\\ntwo important ml problem ca tegories (supervised\\nlearning and rl) and department of defense in-\\nterests (intelligence analysis and autonomous systems).\\nthe data analytics challenge was motivated by a\\ncommon problem: intelligence analysts are presented\\nwith decisions and recommendations from big data\\nsummer 2019 45deep learning and security',\n",
       " 'analytics algorithms and must decide which to report as\\nsupporting evidence in their analyses and which to\\npursue further. these algorithms often produce falsealarms that must be pruned and are subject to concept\\ndrift. furthermore, these a lgorithms often make recom-\\nmendations that the analyst must assess to determinewhether the evidence supports or contradicts their hy-\\npotheses. effective explanati ons will help confront these\\nissues.\\nthe autonomy challenge was motivated by the\\nneed to effectively manage ai partners. for example,\\nthe department of defense seeks semiautonomoussystems to augment war ﬁghter capabilities. operators\\nwill need to understand how these behave so they can\\ndetermine how and when to best use them in future\\nmissions. effective explanations will better enable suchdeterminations.\\nfor both challenge problem areas, it is critical to\\nmeasure explanation effectiveness. while it would beconvenient if a learned model ’s explainability could be\\nmeasured automatically, an xai system ’se x p l a n a t i o n\\neffectiveness must be assessed according to how itsexplanations aid human users. this requires human-in-the-loop psychologic experiments to measure the\\nuser’s satisfaction, mental model, task performance,\\nand appropriate trust. dar pa formulated an initial\\nexplanation evaluation framework that includes po-\\ntential measures of explanation effectiveness ( ﬁgure 5).\\nexploring and re ﬁning this framework is an important\\npart of the xai program ’sr e s e a r c ha g e n d a .\\nthe xai program ’s goal, concept, strategies, chal-\\nlenges, and evaluation framework are described inthe program ’s 2016 broad agency announcement.\\nfigure 6 displays the xai program ’s schedule, whichconsists of two phases. phase 1 (18 months) com-\\nmenced in may 2017 and includes initial technology\\ndemonstrations of xai systems. phase 2 (30 months)includes a sequence of evaluations against challenge\\nproblems selected by the system developers and the\\nxai evaluator. the ﬁrst formal evaluations of xai\\nsystems took place during the fall of 2018. this article\\ndescribes the developer teams ’progress leading up to\\nthese evaluations, whose results were presented at an xaiprogram meeting during the winter of 2019.\\nxai program\\ndevelopment and progress\\nfigure 7 summarizes the 11 xai tec hnical area 1 (ta1)\\ndeveloper teams and the ta 2t e a m[ f r o mt h ef l o r i d a\\ninstitute for human and machine cognition (ihmc)]that is developing the psychologic model of explanation.\\nthree ta1 teams are pursuing both challenge problem\\nareas (autonomy and data analytics), three are working ononly the former, and ﬁve are working on only the latter.\\nper the strategies described in ﬁgure 2, the ta1 teams are\\ninvestigating a diverse range of techniques for developingexplainable models and explanation interfaces.\\nnaturalistic\\ndecision-making foundations of xai\\nthe objective of the ihmc team (which includes\\nresearchers from macrocognition and michigan\\ntechnological university) is to develop and evaluate\\npsychologically plausible models of explanationanddevelop actionable concepts, methods, measures, and\\nmetrics for explanatory reasoning. the ihmc team is\\ndecision\\ntreesdeep\\nlearningensemble\\nmethods\\nrandom\\nforests\\nlearning performance\\nexplainabilitylearning techniques\\nstatistical\\nmodels\\nsvmsaogsperformance vs.\\nexplainability\\nneural nets\\nmarkov\\nmodelsmlnshbnssrl\\ncrfsbayesian\\nbelief netsgraphical\\nmodels\\nfigure 1. learning performance versus explainability trade-off for several categories of learning techniques.\\n46 ai magazinedeep learning and security',\n",
       " 'investigating the nature of explanation itself. what\\nmust happen for a person to be satis ﬁed with an attempt\\nto explain (1) the workings of a complex system and (2)why it acted the way it did in a given situation? to\\naddress such questions, the team has formulated a\\nnaturalistic model of human explanatory reasoning andis providing guidance to the performer teams on\\nmethods for evaluating the effectiveness of their xai\\nsystems ’explanations. the team reviewed the relevant\\nliteratures in philosophy of science and specializations\\nwithin psychology, from which criteria were synthe-\\nsized for assessing the “goodness ”of explanations. the\\nteam is also collecting and analyzing a corpus of cases inwhich individuals create or receive explanations of the\\nworkings of complex systems.\\nthis team developed measures for explanation\\ngoodness, a user ’s mental model (for example, cor-\\nrectness, completeness), and user task performance.\\nfrom this, the user can make reasonably accuratejudgments about when to trust (or doubt) the system.\\nto gain this insight, the user must explore the decision-\\nmaking processes and performance of an xai system,especially for boundary cases, including ways in which\\ndeep neural networks (dnns) can be spoofed. thismethodology was described in a series of essays\\n(hoffman and klein 2017; hoffman et al. 2017; klein2018; hoffman et al. 2018).\\nfigure 8 illustrates ihmc ’s model of the xai ex-\\nplanation process, highlighting measurement categories\\nfor assessing explanation effectiveness. the user re-ceives a recommendation or decision from an xai\\nsystem, along with an explanation that could be tested\\nfor goodness (versus preestablished criteria) and usersatisfaction. the explanation contributes to the user ’s\\nmental model of the ai system, which could be tested\\nfor accuracy and comprehension. the ai system ’s\\nrecommendations and the user ’s mental model may\\nenable, or decrease, user task performance, which\\ncould also be measured. these processes contribute to\\nthe user ’s appropriate, or inappropriate, trust of the ai\\nsystem. the xai evaluator is using this model to test\\nthe developer teams ’xai systems.\\nevaluation\\nthe xai program ’s independent government evalua-\\ntor is the naval research laboratory. for phase 1, thelaboratory (with ihmc ’s help) prepared an evaluation\\nframework for the ta1 teams to use as a template for\\nexplainability\\nmodel induction\\ntechniques to infer an \\nexplainable model from any \\nmodel as a black boxdeep explanation\\nmodified deep learning \\ntechniques to learn \\nexplainable featuresnew \\napproach\\ncreate a suite ofmachine learningtechniques thatproduce moreexplainable models,while maintaining ahigh level of learning performance\\ninterpretable models\\ntechniques to learn more \\nstructured, interpretable, \\ncausal modelsperformance vs.\\nexplainability\\ndecision\\ntreesdeep\\nlearning ensemble\\nmethods\\nrandom\\nforestslearning techniques\\nstatistical\\nmodels\\nsvmsaogsneural nets\\nmarkov\\nmodelsmlnshbnssrl\\ncrfsbayesian\\nbelief netsgraphical\\nmodels\\nmodel\\nexperiment??learning performance\\ninput\\nunitshidden\\nunitsoutput\\nunits41 42 45 45\\n19 16 18 16\\n5 3 31 1 31 1 33 1 31a1\\n0.3 0.7 0.7 0.1 0.1 0.1 0.9 0.1\\n1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.6\\n1.01.0 1.01.0 1.01.0 1.00.50.5\\nfigure 2. strategies for developing explainable models.\\nsummer 2019 47deep learning and security',\n",
       " 'designing and implementing their phase 1 evaluation\\nexperiments, where they will select a test problem or\\nproblems in the challenge problem areas of data an-alytics or autonomy; apply their new ml techniques\\nto learn an explainable model for their problems;\\nevaluate the performance of their learned ml model(table 1); combine their learned model with theirexplanation interface to create their explainable\\nlearning system; conduct experiments in which users\\nperform speci ﬁed tasks using the explainable learning\\nsystem; and measure explanation effectiveness by\\nemploying ihmc ’s model of the explanation process\\n(ﬁgure 8) and explanation effectiveness measurement\\ncategories (table 1).\\nthe evaluations will include the following experi-\\nmental conditions: (1) without explanation: the xaisystem is used to perform a task without providing\\nexplanations to the user; (2) with explanation: the\\nxai system is used to perform a task and generatesexplanations for every recommendation or decision itmakes and every action it takes; (3) partial explana-\\ntion: the xai system is used to perform a task and\\ngenerates only partial or ablated explanations (to as-sess various explanation features); and (4) control: a\\nbaseline state-of-the-art nonexplainable system is used\\nto perform a task.\\nexplainable learning systems\\ntable 2 summarizes the ta1 teams ’technical ap-\\nproaches and phase 1 test problems.deeply explainable ai\\nthe university of california, berkeley (ucb) team\\n(including researchers from boston university, the\\nuniversity of amsterdam, and kitware) is developing\\nan ai system that is human understandable by virtueof explicit structural interpretation (hu et al. 2017),\\nprovides post hoc (park et al. 2018) and introspective\\n(ramanishka et al. 2017) explanations, has predictivebehavior, and allows for appropriate trust (huanget al. 2018). the key challenges of deeply explain-\\nable ai (dexai) are to generate accurate explanations\\nof model behavior and select those that are most usefulto a user. ucb is addressing the former by creating\\nimplicit or explicit explanation models: they can im-\\nplicitly present complex latent representations in un-derstandable ways or build explicit structures that are\\ninherently understandable. these dexai models create\\na repertoire of possible explanatory actions. becausethese actions are generated without any user model,they are called re ﬂexive. for the second challenge, ucb\\nproposes rational explanations that use a model of the\\nuser’s beliefs when deciding which explanatory actions\\nto select. ucb is also developing an explanation interface\\nbased on these innovations informed by iterative design\\nprinciples.\\nucb is addressing both challenge problem areas.\\nfor autonomy, dexai will be demonstrated in ve-\\nhicle control (using the berkeley deep drive data setand the carla simulator) (kim and canny 2017)\\nand strategy game scenarios (starcraft ii). for data\\nlearning\\nprocess\\ntraining\\ndatalearned\\nfunctionoutputtoday\\nthis is a cat\\n(p = 0.93)• why did you do that?\\n• why not something else?• when do you succeed?\\n• when do you fail?\\n• when can i trust you?\\n• how do i correct an error? user with\\na task\\ntraining \\ndatanew\\nlearning\\nprocess\\nexplainable \\nmodelexplanation \\ninterfacetomorrow• i understand why\\n• i understand why not• i know when you’ll succeed\\n• i know when you’ll fail\\n• i know when to trust you• i know why you erredthis is a cat\\nit has fur,\\nwhiskers, claws\\nit has this feature\\nuser with\\na taskinput\\nunitshidden\\nunitsoutput\\nunits\\n414245 45\\n19 16 18 16\\n5331 131 133 131a1\\n0.3 0.7 0.7 0.1 0.1 0.1 0.9 0.1\\n1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.6\\n1.01.0 1.01.0 1.01.0 1.00.50.5\\nfigure 3. the xai concept.\\n48 ai magazinedeep learning and security',\n",
       " 'analytics, dexai will be demonstrated using visual\\nquestion answering (vqa) and ﬁltering tasks (for\\nexample, using large-scale data sets such as vqa-x\\nand act-x for vqa tasks and activity recognitiontasks, respectively), xview, and distinct describable\\nmoments (hendricks et al. 2018).\\ncausal models to explain learning\\nthe goal of the charles river analytics (cra) team\\n(including researchers from the university of massa-chusetts and brown university) is to generate andpresent causal explanations of ml operation, through\\nits causal models to explain learning (camel) ap-\\nproach. camel explanations are presented to a useras narratives in an interactive, intuitive interface.\\ncamel includes a causal probabilistic programming\\nf r a m e w o r kt h a tc o m b i n e sr e p resentations and learning\\nmethods from causal modeling (marazopoulou et al.\\n2015) with probabilistic p rogramming languages\\n(pfeffer 2016) to describe complex and rich phenomena.camel can be used to describe what an ml system did,\\nhow speci ﬁc data characteristics in ﬂuenced its outcome,and how changing these factors would affect this out-\\ncome. generative probabilistic models, represented in\\na probabilistic programming language, naturally ex-\\npress causal relationships; they are well suited for thistask of explaining ml systems.\\ncamel probes the internal representation of an ml\\nsystem to discover how it represents user-de ﬁned,\\nnatural domain concepts. it then builds a causal\\nmodel of their effect on the ml system ’so p e r a t i o nb y\\nconducting experiments in which the domain con-cepts are systematically included or removed. cra hasapplied this approach to dnns for classi ﬁcation and\\nrl.\\nonce learned, it uses causal probabilistic models to\\ninfer explanations of the system ’s predictions or ac-\\ntions. because inferences can be large and complex and\\ncan contain many interacting components, camelcomposes them into explanatory narratives that walk\\nthe user through the interactions of the major concepts\\nand their in ﬂuence on the ml system ’s output. the\\ncamel explanation interface, based on cognitive\\nsystems engineering design principles and established\\nlearn a \\nmodel\\nrecommend\\nexplanationexplainable \\nmodelexplanation \\ninterfacean analyst is \\nlooking foritems ofinterest inmassivemultimediadata sets\\nexplainable \\nmodelexplanation \\ninterfacedata \\nanalytics\\nclassification \\nlearning task\\nautonomy\\nreinforcement\\nlearning taskactions\\nexplanation\\nardupilot & sitl simulationan operator is \\ndirecting \\nautonomous \\nsystems to \\naccomplish a \\nseries of\\nmissionsclassifies items of \\ninterest in large data set\\nlearns decision policies \\nfor simulated missionsexplains why/why not \\nfor recommended itemsanalyst decides which \\nitems to report, pursue\\nexplains behavior in an \\nafter-action reviewoperator decides which \\nfuture tasks to delegateuse the \\nexplanationexplain \\ndecisions\\nmultimedia datatwo trucks performing a \\nloading activity\\n©getty\\nimages\\n©us army©air force research lab\\n©ardupikot.orgarducopter v3.0.1\\narducopter v3.0.1\\nclick the images above for “flight versions”arducopter v3.0.1\\ndownload firmwares px4io firmware\\nbeta firmwares pick provious firmwareload custom firmwarearducopter v3.0.1arducopter v3.0.1 arducopter v3.0.1\\n©ardupikot.org\\nfigure 4. xai challenge problem areas.\\nsummer 2019 49deep learning and security',\n",
       " 'hci techniques, allows users to understand and in-\\nteract with the explanatory narratives, engendering\\ntrust in automation and enabling effective user-system\\nteamwork.\\ncra is addressing both challenge problem areas.\\nfor data analytics, camel has been demonstrated\\nusing pedestrian detection (using the inria pedestriandata set) (harradon et al. 2018), and cra is working\\ntoward activity recognition tasks (using activitynet). for\\nautonomy, camel has been demonstrated on the atarigame amidar, and cra is working toward demon-strating it on starcraft ii.\\nlearning and\\ncommunicatingexplainable representationsfor analytics and autonomy\\nthe university of california, los angeles (ucla) team\\n(including researchers from oregon state university andmichigan state university) is developing interpretable\\nmodels that combine representational paradigms,including interpretable dnns , compositional graphical\\nmodels such as and-or graphs, and models that produce\\nexplanations at three levels (that is, compositionality,\\ncausality, and utility).\\nucla ’s system includes a performer that executes\\ntasks on multimodal input data and an explainer that\\nexplains its perception, cognitive reasoning, and de-cisions to a user. the performer outputs interpretable\\nrepresentations in a spatial, temporal, and causal\\nparse graph (stc-pg) for three-dimensional sceneperception (for analytics) and task planning (for au-tonomy). stc-pgs are compositional, probabilistic,\\nattributed, interpretable, and grounded on dnn\\nfeatures from images and videos. the explainer out-puts an explanatory parse graph in a dialogue process\\n(she and chai 2017), localizes the relevant subgraph\\nin the stc-pg, and infers the user ’s intent.\\nthe system represents explanations at three levels:\\n(1) concept compositions, represented by parse graph\\nfragments that depict how information is aggregatedfrom its constituents and contexts, how decisions are\\nmade at nodes under uncertainty, and the decision ’s\\nexplanation framework\\nthe system takes \\ninput from the current task and makes a \\nrecommendation,\\ndecision, or actionthe system provides \\nan explanation to the user that justifies its \\nrecommendation, \\ndecision, or actionthe user \\nmakes a decision \\nbased on the\\nexplanationexplainable\\nmodelexplanation\\ninterfacetask\\ndecisionrecommendation,\\ndecision or \\naction\\nexplanation xai systemmeasure of explanation\\neffectiveness\\nuser satisfaction\\n• clarity of the explanation (user rating)\\n• utility of the explanation (user rating)\\nmental model\\n• understanding individual decisions\\n• understanding the overall model\\n• strength/weakness assessment• ‘what will it do’ prediction\\n• ‘how do i intervene’ prediction\\ntask performance\\n• does the explanation improve the\\nuser’s decision, task performance? \\n• artificial decision tasks introduced to\\ndiagnose the user’s understanding \\ntrust assessment\\n• appropriate future use and trust\\ncorrectability (extra credit)\\n• identifying errors\\n• correcting errors\\n• continuous training\\nfigure 5. evaluating explanation effectiveness.\\n50 ai magazinedeep learning and security',\n",
       " 'conﬁdence levels; (2) causal a nd counterfactual rea-\\nsoning, realized by extracting causal diagrams from stc-\\npgs to predict what will happen if certain alternative\\nactions had been taken; and (3) utility explanations,which explain why the system made certain decisions.\\nucla is addressing both xai challenge problem\\nareas using a common framework of representationand inference. for data analytics, ucla demonstrated\\ntheir system using a network of video cameras for scene\\nunderstanding and event analysis. for autonomy,ucla demonstrated it in scenarios using robots exe-cuting tasks in physics-realistic virtual reality\\nplatforms and autonomous vehicle driving game\\nengines.\\nexplanation-informed acceptance\\ntesting of deep adaptive programs\\noregon state university (osu) is developing tools for\\nexplaining learned agents that perform sequentialdecision making and is identifying best principles for\\ndesigning explanation user interfaces. osu ’s explain-\\nable agent model employs e xplainable deep adaptive\\nprograms (xdaps), which combine adaptive programs,\\ndeep rl, and explainability. with xdaps, program-\\nmers can create agents by writing programs that in-clude choice points, which represent decisions thatare automatically optimized via deep rl through\\nsimulator interaction. for each choice point, deep rl\\nattaches a trained deep decision neural network(dnn), which can yield high performance but is in-\\nherently unexplainable.\\nafter initial xdap training, xact trains an explana-\\ntion neural network (qi and li 2017) for each dnn.\\nthese provide a sparse set of explanation features (x-\\nfeatures) that encode properties of a dnn ’sd e c i s i o n\\nlogic. such x-features, which are neural networks, are\\nnot initially human interpretable. to address this,xact enables domain experts to attach interpretable\\ndescriptions to x-features, and xdap programmers to\\nannotate environment reward types and other con-\\ncepts, which are automatically embedded into thednns as “annotation concepts ”during learning.\\nthe dnn decisions can be explained via the de-\\nscriptions of relevant x-fe atures and annotation con-\\ncepts, which can be furthe r understood via neural\\nnetwork saliency visualization tools. osu is investi-\\ngating the utility of saliency computations forexplaining sequential decision making.\\nosu ’s explanation user interface allows users to\\nnavigate thousands of learned agent decisions and\\nobtain visual and natural language (nl) explanations. itsdesign is based on information foraging theory (ift),\\nwhich allows a user to ef ﬁciently drill down to the most\\nuseful explanatory information at any moment. theassessment of rationales for learned decisions may more\\nefﬁciently identify ﬂaws in the agent ’s decision\\nmaking and improve user trust.\\nosu is addressing the autonomy challenge prob-\\nlem area and has demonstrated xact in scenarios\\nusing a custom-built real-time strategy game engine.pilot studies have informed the explanation user in-terface design by characterizing how users navigate\\nai-agent game play and tend to explain game de-\\ncisions (dodge et al. 2018).\\ncommon ground\\nlearning and explanation\\nthe palo alto research center (parc) team (including\\nresearchers from carnegie mellon university, the armycyber institute, the university of edinburgh, and the\\nuniversity of michigan) is developing an interactive\\nsensemaking system that c an explain the learned ca-\\npabilities of an xai system that controls a simulated\\nunmanned aerial system.\\napr may jun jul aug sep oct nov dec jan feb mar apr may jun jul aug sep oct nov dec jan feb mar apr may jun jul aug sep oct nov dec jan feb mar apr may jun jul aug sep o ct nov dec jan feb mar apr may\\nkickoff progress report tech demos eval 1 results eval 2 results eval 3 resultsfinalrefine and test explainable\\nlearning systems eval \\n3deliver software\\nlibraries and\\ntoolkits\\nsummarize current psychological\\ntheories of explanationdevelop theoretical model of\\nexplanationrefine and test model of explanation to support\\nsystem development and evaluationdeliver final\\nmodel of\\nexplanationdevelop and demonstrate explainable\\nlearning systems eval\\n1refine and test explainable\\nlearning systems eval\\n2\\npsychological model\\nof explanation\\n(1 team)explainable learning\\nsystems\\n(11 developer teams)evaluator (nrl) define evaluation frameworkprepare for\\neval 1eval\\n1analyze\\nresultsfy2021\\nphase 1\\ntechnology demonstrationsphase 2\\ngovernment evaluations\\nprepare for eval 2fy2017 fy2018 fy2019 fy2020\\neval\\n2analyze\\nresultsprepare for eval 3eval\\n3analyze results;\\naccept software\\nlibraries/toolkits\\nfigure 6. xai program schedule.\\nsummer 2019 51deep learning and security',\n",
       " 'an xai system ’s explanations should communicate\\nwhat information it uses to make decisions, whether it\\nunderstands how things work, and its goals. toaddress this, parc ’s common ground learning and\\nexplanation (cogle) and its users establish com-\\nmon ground about what terms to use in explana-tions and their meaning. this is enabled by parc ’s\\nintrospective discourse model, which interleaves\\nlearning and explaining processes.\\nperforming tasks in the natural world is challeng-\\ning for autonomous systems, requiring experience to\\ncreate enough knowledge for reliable high perfor-\\nmance. cogle employs k-models that encode an aiagent ’sd o m a i n - s p e c i ﬁc task knowledge. k-models orga-\\nnize this knowledge into levels of elements, where higher\\n(lower) levels model actions with longer range (local)effects. they support a competency-based frameworkthat informs and guides the learning and testing of xai\\nsystems.\\ncogle ’s multilayer architecture partitions its in-\\nformation processing into sensemaking, cognitive\\nmodeling, and learning. the learning layer employs\\ncapacity constrained recurrent and hierarchical dnnsto produce abstractions and compositions over the\\nstates and actions of unmanned aerial systems to sup-\\nport an understanding of generalized patterns. itcombines learned abstractions to create hierarchical,\\ntransparent policies that match those learned by thesystem. the cognitive layer bridges human-usable\\nsymbolic representations to the abstractions, composi-\\ntions, and generalized patterns.\\ncogle ’s explanation interfaces support performance\\nreview, risk assessment, and training. the ﬁrst provides a\\nmap that traces an unmanned aerial systems ’mission\\nactions and divides the action or decision ( ﬂight) path\\ninto explainable segments. the second interface ’s\\nt o o l se n a b l eu s e r st oe x a m i n ea n da s s e s st h es y s -\\ntem’s competencies and make predictions about\\nmission performance.\\ncogle will be demonstrated in ardupilot ’ss o f t -\\nware-in-the-loop simulato r and a discretized abstract\\nsimulation test bed. it will be evaluated by drone op-\\nerators and analysts. competency-based evaluation will\\nhelp parc to determine how best to develop appro-priate domain understandable models.\\nexplainable reinforcement learning\\ncarnegie mellon university is creating a new disci-pline of explainable rl to enable dynamic human-\\nmachine interaction and adaptation for maximum\\nteam performance. this effort has two goals: to de-velop new methods for learning inherently explain-\\nable rl policies and to develop strategies that can\\nexplain existing black-box policies. for the former,carnegie mellon is developing methods to improve\\nmodel learning for rl agents to capture the bene ﬁts\\ntraining data\\nexplainable \\nmodelexplanation \\ninterface\\ncp area performer explainable model explanation interface\\nbothucb deep learning reflexive and rational\\ncra causal model induction narrative generation\\nucla pattern theory+ 3-level explanation\\nautonomyosu adaptive programs acceptance testing\\nparc cognitive modeling interactive training\\ncmu explainable rl xrl interaction\\nanalyticssri deep learning show-and-tell explanations\\nraytheon bbn deep learning argumentation and pedagogy\\nutd probabilistic logic decision diagrams\\ntamu mimic learning interactive visualization\\nrutgers model induction bayesian teachingnew\\nlearning\\nprocesspsychological model of explanation\\nihmcexplanation\\nquality\\nuser satisfaction\\nuser’s mental\\nmodel\\ntrust or mistrust\\nappropriate\\ntrustappropriate usebetter\\nperformance\\nuser\\ncomprehensionuser\\nperformance\\nexplanation\\nfigure 7. xai research teams.\\n52 ai magazinedeep learning and security',\n",
       " 'of model-based approaches (ability to visualize plans\\nin the internal model space), while integrating\\nthe bene ﬁts of model-free approaches (simplicity\\nand higher ultimate performance). these includemethods that incrementally add states and actions toworld models after discovering relevant latent in-\\nformation, learn models via end-to-end training\\nof complex model-based optimal control policies,learn general dl models that directly integrate\\nand exploit rigid body phy sics (belbute-peres and\\nkolter 2017), and learn und erstandable predictive\\nstate representations using recurrent architectures\\n(hefny et al. 2018).\\ncarnegie mellon is also developing methods that\\ncan explain the actions and plans of black-box rlagents, observed either online or from system logs.\\nthis involves answering questions such as, why did\\nan agent choose a particular action? or, what train-ing data were most responsible for this choice? to\\nachieve this, carnegie mellon developed techniques\\nthat generate nl descriptions of agents from behaviorlogs and detect outliers or anomalies. carnegie mellon\\nalso developed improvements over traditional in-\\nﬂuence function methods in dl, allowing its xrl\\nsystem to precisely identify the portions of a train-\\ning set that most in ﬂuence a policy ’s outcome.carnegie mellon is addressing the autonomy chal-\\nlenge problem area and has demonstrated xrl in\\nseveral scenarios, including openai gym, atari\\ngames, autonomous vehicle simulation, mobile servicerobots, and self-improving educational software andgames.\\ndeep attention-based\\nrepresentations for explanation/explainable generative adversarial networks\\nsri international ’s team (including researchers from\\nthe university of toronto, the university of guelph,\\nand the university of california, san diego) is de-\\nveloping an explainable ml framework for multi-modal data analytics that generates show-and-tellexplanations with justi ﬁcations of decisions accom-\\npanied by visualizations of input data used to generate\\ninferences.\\nthe deep attention-based representations for\\nexplanationxplainable gener ative adversarial networks\\n(dare/x-gans) system employs dnn architecturesinspired by attentional models in visual neuroscience.\\nit identi ﬁes, retrieves, and presents evidence to a user as\\npart of an explanation. the attentional mechanismsprovide a user with a means for system probing and\\ncollaboration.\\nuseruser-system \\ntask  \\nperformance\\n“goodness” \\ncriteriatest of \\nsatisfactiontest of \\nunderstandingtest of \\nperformance\\ntrust or \\nmistrustappropriate \\ntrust and \\nreliancesystem\\nis assessed byreceives\\nmay initially\\ngives way to appropriate \\nuseenablesrevises improves\\nis assessed by is assessed by\\ncan engenderexplanationuser’s mental \\nmodel\\ninvolvesxai process\\nxai measurement \\ncategories\\nfigure 8. initial model of the explanation process and explanation effectiveness measurement categories.\\nsummer 2019 53deep learning and security',\n",
       " 'dare/x-gans uses generative adversarial net-\\nworks (gans), which learn to understand data by\\ncreating it, while learning representations with explan-atory power. gans are made explainable by using\\ninterpretable decoders that map unsupervised clus-\\nters onto parts-based representations. this involvesgenerating visual evidence, given text queries, using\\ntext-to-parts generation (vicol et al. 2018), the parts\\nbeing interpretable features such as human poses orbounding boxes. this evidence is then used to\\nsearch the queried visual data.\\nthe system presents explanations of its answers\\nbased on visual concepts extracted from the mul-timodal data inputs and kn o w l e d g eb a s eq u e r i e s .\\ngiven explanatory questions, it provides justi ﬁca-\\ntions, visual evidence used for decisions, and vi-sualizations of the system ’si n n e rw o r k i n g s .t h i s\\nshow-and-tell explanation interface ensures highly\\nintuitive explanations, made possible by atten-tional modules that localize evidence used for\\neach visual task. initial studies demonstrate that\\nsuch explanations substantially improve user taskperformance.\\nsri is addressing the data analytics challenge\\nproblem area and has demonstrated dare/x-gans\\nusing vqa and multimodal qa tasks with image andvideo data sets.\\nexplainable question answering system\\nthe raytheon bbn technologies team (including\\nresearchers from the georgia institute of technology,\\nmit, and the university of texas, austin) is devel-oping a system that answers unrestricted nl questions\\nposed by users about multimedia data and providesinteractive, explorable explanations of why it derived\\nan answer.\\nthe explainable question answering system\\n(equas) learns explainable dnn models in which\\ninternal structures (for example, individual neurons)\\nhave been aligned to semantic concepts (for example,wheels and handlebars) (zhou et al. 2015). this allows\\nneural activations within the network, during a de-\\ncision process, to be translated to nl explanations (forexample, “this object is a bicycle because it has two\\nwheels and handlebars ”). equas also uses neural\\nvisualization techniques to highlight input regionsassociated with neurons that most in ﬂuenced its de-\\ncisions. to express case-based explanations, equas\\nretains indexes and retrieves cases from its training\\ndata that support its choices. rejected alternatives arerecognized and ruled out using contrastive language,\\nvisualization, and examples. four explanation mo-\\ndalities map to key elements of argument construc-tion and interactive pedagogy: didactic statements,\\nvisualizations, cases, and rejections of alternative\\nchoices.\\nthe equas explanation interface allows users to\\nexplore the explanation space populated by these\\nexplanation modes. it enables iterative and guided\\ncollaborative interaction, allowing users to drill downinto the supporting evidence from each explanation\\ncategory.\\nraytheon bbn is addressing the analytics chal-\\nlenge problem area and has demonstrated initial\\nequas capabilities on vqa tasks for images, ex-\\nploring how different explanation modalities en-able users to understand and predict the behavior of\\nthe underlying vqa system.\\nmeasure description\\nml model performance\\nvarious measures (on a per-challenge problem area\\nbasis)accuracy/performance of the ml model in its given domain (to\\nunderstand whether performance improved or degraded relative to\\nstate-of-the-art nonexplainable baselines)\\nexplanation effectiveness\\nexplanation goodness features of explanations assessed against criteria for explanation\\ngoodness\\nexplanation satisfaction user ’s subjective rating of explanation completeness, usefulness,\\naccuracy, and satisfaction\\nmental model understanding user ’s understanding of the system and the ability to predict the system ’s\\ndecisions/behavior in new situations\\nuser task performance success of the user performing the tasks for which the system is designed\\nto support\\nappropriate trust and reliance user ’s ability to know when to, and when not to, trust the system ’s\\nrecommendations and decisions\\ntable 1. measurement categories.\\n54 ai magazinedeep learning and security',\n",
       " 'team explainable model explanation interface challenge problem\\nuc berkeley \\x81post hoc explanations by\\ntraining additional dl models\\x81reﬂexive explanations (arise\\nfrom the model)\\x81autonomy: vehicle control (bdd-\\nx, carla), strategy games\\n(starcraft ii)\\n\\x81explicit introspective\\nexplanations (nmns)\\x81rational explanations (comefrom reasoning about user ’s\\nbeliefs)\\x81analytics: visual qa and ﬁltering\\ntasks (vqa-x, act-x, xview,didemo, etc.)\\n\\x81reinforcement learning(informative rollouts, explicitmodular agent)\\ncharles river\\nanalyticsexperiment with the learned\\nmodel to team an explainable,causal, probabilistic\\nprogramming modelinteractive visualization based on\\nthe generation of temporal,spatial narratives from the\\ncausal, probabilistic models\\x81autonomy: atari, starcraft ii\\n\\x81analytics: pedestrian detection\\n(inria), activity recognition\\n(activitynet)\\nucla \\x81interpretable representations:\\nstc-aog (spatial, temporal,\\ncausal models), stc-pg (scene\\nand event interpretations inanalytics), stc-pg +(task plans\\nin autonomy)\\x81three-level explanation concept\\ncompositions, causal and\\ncounterfactual reasoning, utility\\nexplanation\\x81autonomy: robot executing daily\\ntasks in physics-realistic vr\\nplatform autonomous vehicle\\ndriving (gta5 game engine)\\n\\x81theory of mind representations(user ’s beliefs, user ’s mental\\nmodel of agent)\\x81explanation representations:x-aog (explanation model),x-pg (explanatory parse graph\\nas dialogue), x-utility (priority\\nand loss for explanations)\\x81analytics: network of video\\ncameras for scene understandingand event analysis\\noregon state xdaps, combination of adaptive\\nprograms, deep learning, and\\nexplainabiltyprovides a visual and nl\\nexplanation interlace for\\nacceptance testing by test pilotsbased on iftautonomy: real-time strategy sames\\nbased on custom-designed game\\nengine designed to supportexplanation; starcraft ii\\nparc three-layer architecture: learning\\nlayer (dnns), cognitive layer(act-r cognitive model),explanation layer (hci)\\n\\x81interactive visualization ofstates, actions, policies, valuesautonomy: mavsim wrapper over\\nardupilot simulation environment\\n\\x81module for test pilots to re ﬁne\\nand train the system\\ncarnegie mellon\\nuniversitya new scienti ﬁc discipline for xrl\\nxrl with work on new\\nalgorithms and representations\\x81interactive explanations of\\ndynamic systemsautonomy: openai gym, autonomy\\nin the electrical grid, mobile service\\nrobots, self-improving educational\\nsoftware\\x81human-machine interactionto improve performance\\nsri multiple dl techniques: attention-\\nbased mechanisms,\\ncompositional nmns, gans\\x81dnn visualization analytics: vqa (visual gnome,\\nflickr30), movieqa\\x81query evidence that explains\\ndnn decisions\\n\\x81generate nl justi ﬁcations\\nraytheon bbn \\x81semantic labeling of dnn\\nneurons\\x81comprehensive strategy basedon argumentation theoryanalytics: vqa for images and video\\n\\x81dnn audit trail construction \\x81nl generation\\n\\x81gradient-weighted class\\nactivation mapping\\x81dnn visualization\\nutd tplms enables users to explore and\\ncorrect the underlying modelas well as add backgroundknowledgeanalytics: infer activities in\\nmultimodal data (video and text),wet lab (biology), and textuallyannotated cooking scenes data\\nsets\\n(continued on following page)\\nsummer 2019 55deep learning and security',\n",
       " 'tractable probabilistic logic models:\\na new, deep explainable representation\\nthe university of texas at dallas (utd) team (in-\\ncluding researchers from ucla, texas a&m, and theindian institute of technology, delhi) is developing a\\nuniﬁed approach to xai using tractable probabilistic\\nlogic models (tplms).\\ntplms are a family of representations that in-\\nclude (for example) decisio n trees, binary decision\\ndiagrams, cutset networks, sentential decision dia-grams, ﬁrst-order arithmetic circuits, and tractable\\nmarkov logic (gogate and domingos 2016). the\\nutd system extends tplms to generate explana-tions of query results; hand le continuous variables,\\ncomplex constraints, and unseen entities; compactly\\nrepresent complex objects such as parse trees, lists, andshapes; and enable ef ﬁcient representation and rea-\\nsoning about time.\\nfor scalable inference, the system uses novel al-\\ngorithms to answer complex explanation queriesusing techniques including lifted inference, varia-\\ntional inference, and their combination. for fast and\\nincreased learning accuracy, it uses discriminativetechniques, deriving algorithms that compose nns\\nand support vector machines with tplms, using in-\\nterpretability as a bias to learn more interpretablemodels. these approaches are then extended to handlereal-world situations.\\nthe utd explanation interface displays in-\\nterpretable representations with multiple relatedexplanations. its interactive component allows\\nusers to debug a model and suggest alternative\\nexplanations.\\nutd is addressing the analytics challenge prob-\\nlem area and has demonstrated its system for rec-\\nognizing human activities in multimodal data(video and text), such as the textually annotated\\ncooking scenes data set.transforming deep learning to\\nharness the interpretability of shallowmodels: an interactive end-to-end system\\nthe texas a&m university (tamu) team (including\\nresearchers from washington state university) is\\ndeveloping an interpretable dl framework that uses\\nmimic learning to leverage explainable shallow\\nmodels and facilitates domain interpretation withvisualization and interaction. mimic learning\\nbridges the gap between deep and shallow models\\nand enables interpretability. the system also minesinformative patterns from raw data to enhance in-terpretability and learning performance.\\nthe system ’s interpretable learning algorithms ex-\\ntract knowledge from dnns for relevant explanations. itsdl module connects to a pattern-generation module\\nby leveraging the interpretability of the shallow\\nmodels. the learning system ’s output is displayed to\\nusers with visualization including coordinated and\\nintegrated views.\\nthe tamu system handles image (du et al. 2018) and\\ntext (gao et al. 2017) data and is being applied to the xai\\nanalytics challenge problem area. it provides effective\\ninterpretations of detecte d inaccuracies from diverse\\nsources while maintaining a competitive detection per-formance. the tamu system combines model-level (that\\nis, model transparency) and instance-level (that is, in-\\nstance explanation) interpretability to generate expla-nations that are more easily comprehended by users. this\\nsystem has been deployed on multiple tasks using data\\nfrom twitter, facebook, imagenet, cifar-10, onlinehealth care forums, and news websites.\\nmodel explanation by\\noptimal selection of teaching examples\\nrutgers university is extending bayesian teaching to\\nenable automatic explanation by selecting the data\\nteam explainable model explanation interface challenge problem\\ntexas a&m \\x81mimic learning framework\\ncombines dl models forprediction and shallow models\\nfor explanations.interactive visualization over\\nmultiple news, using heat mapsand topic modeling clusters to\\nshow predictive featuresanalytics: multiple tasks using data\\nfrom twitter, facebook, imagenet,and news websites\\n\\x81interpretable learningalgorithms extract knowledge\\nfrom dnns for relevant\\nexplanations\\nrutger s select the optimal trading\\nexamples to explain model\\ndecisions based on bayesian\\nteachingexample-based explanation of the\\nfull model, user-selected\\nsubstructure, user submitted\\nexamplesanalytics: image processing, text\\ncorpora, vqa, movie events\\ntable 2. summary of explainable learning system developer approaches and selected phase 1 test problems.\\n56 ai magazinedeep learning and security',\n",
       " 'subset that is most representative of a model ’s in-\\nference. rutgers ’approach allows for explanation of the\\ninferences of any probabilistic generative and discrimina-tive model, as well as in ﬂuential dl models (yang\\nand shafto 2017).\\nrutgers is also developing a formal theory of human-\\nmachine cooperation and supporting interactiveguided explanation of complex compositional models.\\ncommon among these is a core approach of building\\nfrom models of human learning to foster explainabilityand carefully controlled behavioral experiments to\\nquantify explainability.\\nexplanation by bayesian teaching inputs a data set,\\na probabilistic model, and an inference method andreturns a small subset of examples that best explains\\nthe model ’s inference. experiments with unfamiliar\\nimages show that explanations of inferences aboutcategories of (and speci ﬁc) images increase the accu-\\nracy of people ’s reasoning about a model (vong et al.\\n2018). experiments with familiar image categoriesshow that explanations allow users to accurately\\ncalibrate trust in model predictions.\\nexplanation of complex models is facilitated by\\ninteractive guided explanations. by exploiting com-\\npositionality and cooperative modi ﬁcations of ml\\nmodels, rutgers provides a generic approach tofostering understanding via guided exploration. in-teraction occurs through an interface that exposes\\nmodel structure and explains each component with\\na s p e c t so ft h ed a t a .t h er u t g e r sa p p r o a c hh a sb e e ndemonstrated to facilitate understanding of large text\\ncorpora, as assessed by a human ’s ability to accurately\\nsummarize the corpus after short, guided explanations.\\nrutgers is addressing the data analytics challenge\\nproblem area and has demonstrated its approach on\\nimages, text, combinations of these (for example,vqa), and structured simulations involving temporalcausal structure.\\nconclusions and future work\\ndarpa ’s xai program is developing and evaluating a\\nwide variety of new ml techniques: modi ﬁed dl\\ntechniques that learn explainable features; methods\\nthat learn more structured, interpretable, causal\\nmodels; and model induction techniques that infer anexplainable model from any black-box model. one year\\ninto the xai program, init ial technology demonstra-\\ntions and results indicate that these three broad strate-gies merit further investigation and will provide futuredevelopers with design options covering the perfor-\\nmance versus explainability trade space. the developer\\nteams ’xai systems are being evaluated to assess the\\nvalue of explanations that they provide, localizing the\\ncontributions of speci ﬁc techniques within this\\ntrade space.\\nacknowledgments\\nthe authors thank the xai development teams,speci ﬁcally their principle investigators, for their\\ninnovative research and contributions to this article:trevor darrell (ucb), brian ruttenberg and avi pfeffer\\n(cra), song-chun zhu (ucla), alan fern (osu),\\nmark ste ﬁk (parc), zico kolter (carnegie mellon),\\nmohamed amer and giedrius burachas (sri interna-tional), bill ferguson (raytheon bbn), vibhav gogate\\n(utd), xia (ben) hu (tamu), patrick shafto (rutgers),\\nand robert hoffman (ihmc). the authors owe aspecial thanks to marisa carrera for her exceptional\\ntechnical support to the xai program and her ex-\\ntensive editing skills.\\nreferences\\nbelbute-peres, f., and kolter, j. z. 2017. a modular differ-\\nentiable rigid body physics engine. paper presented at theneural information processing systems deep reinforcementlearning symposium. long beach, ca, december 7.\\nchakraborty, s.; tomsett, r.; raghavendra, r.; harborne, d.;\\nalzantot, m.; cerutti, f.; and srivastava, m.; et al. 2017.\\ninterpretability of deep learning models: a survey of re-sults. presented at the ieee smart world congress 2017\\nworkshop: dais 2017 —workshop on distributed ana-\\nlytics infrastructure and algorithms for multi-organiza-tion federations, san francisco, ca, august 4 –8. doi.org/10.\\n1109/uic-atc.2017.8397411\\ndodge, j.; penney, s.; hilderbrand, c.; anderson, a.; and\\nburnett, m. 2018. how the experts do it: assessing and\\nexplaining agent behaviors in real-time strategy games. inproceedings of the 2018 chi conference on human factors in\\ncomputing systems . new york: association for computing\\nmachinery. doi.org/10.1145/3173574.3174136\\ndu, m.; liu, n.; song, q.; and hu, x. 2018. towards ex-\\nplanation of dnn-based prediction and guided feature in-\\nversion. in proceedings of the 24th acm sigkdd international\\nconference on knowledge discovery and data mining , 1358 –67.\\nnew york: association for computing machinery. doi.org/10.1145/3219819.3220099\\ngao, j.; liu, n.; lawley, m.; and hu, x. 2017. an in-\\nterpretable classi ﬁcation framework for information ex-\\ntraction from online healthcare forums. journal of\\nhealthcare engineering : 2460174. doi.org/10.1155/2017/\\n2460174\\ngogate, v., and domingos, p. 2016. probabilistic theorem\\nproving. communications of the acm 59(7): 107 –15. doi.org/10.\\n1145/2936726\\nharradon, m.; druce, j.; and ruttenberg, b. 2018. causal\\nlearning and explanation of deep neural networks via\\nautoencoded activations. arxiv preprint. arxiv: 1802.00541v1\\n[cs.ai]. ithaca, ny: cornell university library.\\nhefny, a.; marinho, z.; sun, w.; srinivasa, s.; and gordon, g.\\n2018. recurrent predictive state policy networks. in pro-\\nceedings of the 35th international conference on machinelearning , 1954 –63. international machine learning society.\\nhendricks, l. a.; hu, r.; darrell, t.; and akata, z. 2018.\\ngrounding visual explanations. presented at the european\\nconference of computer vision (eccv). munich, germany;\\nseptember 8 –14. doi.org/10.1007/978-3-030-01216-8_17\\nhoffman, r.; miller, t.; mueller, s. t.; klein, g.; and clancey,\\nw. j. 2018. explaining explanation, part 4: a deep dive on\\ndeep nets. ieee intelligent systems 33(3): 87 –95. doi.org/10.\\n1109/mis.2018.033001421\\nhoffman, r. r.; and klein, g. 2017. explaining explanation,\\npart 1: theoretical foundations. ieee intelligent systems 32(3):\\n68–73. doi.org/10.1109/mis.2017.54\\nsummer 2019 57deep learning and security',\n",
       " 'h o f f m a n ,r .r . ,m u e l l e r ,s .t . ;a n dk l e i n ,g .2 0 1 7 .e x p l a i n i n g\\nexplanation, part 2: empirical foundations. ieee intelligent\\nsystems 32(4): 78 –86. doi.org/10.1109/mis.2017.3121544\\nhu, r.; andreas, j.; rohrbach, m.; darrell, t.; and saenko, k.\\n2017. learning to reason: end-to-end module networks forvisual question answering. in proceedings of the ieee in-\\nternational conference on computer vision , 804 –13. new york:\\nieee. doi.org/10.1109/iccv.2017.93\\nhuang, s. h.; bhatia, k.; abbeel, p.; and dragan, a. 2018.\\nestablishing appropriate trust via critical states. pre-sented at the 13th annual acm/ieee international\\nconference on human-robot interaction workshop on\\nexplainable robot behavior. madrid, spain; october 1 –5.\\ndoi.org/10.1109/iros.2018.8593649\\nkim, j., and canny, j. 2017. interpretable learning for\\nself-driving cars by visualizing causal attention. in\\nproceedings of the international conference on computer vi-sion, 2942 –50. new york: ieee. doi.org/10.1109/iccv.\\n2017.320\\nklein, g. 2018. explaining explanation, part 3: the causal\\nlandscape. ieee intelligent systems 33(2): 83 –88. doi.org/10.\\n1109/mis.2018.022441353\\nletham, b.; rudin, c.; mccormick, t. h.; and madigan, d.\\n2015. interpretable classi ﬁers using rules and bayesian\\nanalysis: building a better stroke prediction model. annals of\\napplied statistics 9(3): 1350 –71. doi.org/10.1214/15-\\naoas848\\nmarazopoulou, k.; maier, m.; and jensen, d. 2015. learning\\nthe structure of causal models with relational and temporaldependence. in proceedings of the thirty-first conference on\\nuncertainty in arti ﬁcial intelligence , 572 –81. association for\\nuncertainty in arti ﬁcial intelligence.\\nmiller, t. 2017. explanation in arti ﬁcial intelligence: insights\\nfrom the social sciences. arxiv preprint. arxiv:1706.07269v1[cs.ai]. ithaca, ny: cornell university library.\\npark, d. h.; hendricks, l. a.; akata, z.; rohrbach, a.; schiele,\\nb.; darrell, t.; and rohrbach, m. 2018. multimodal expla-\\nnations: justifying decisions and pointing to the evidence.inproceedings of the ieee conference on computer vision and\\npattern recognition . new york: ieee. doi.org/10.1109/cvpr.\\n2018.00915\\npfeffer, a. 2016. practical probabilistic programming .\\ngreenwich, ct: manning publications.\\nqi, z., and li, f. 2017. learning explainable embeddings for\\ndeep networks. paper presented at the nips workshop on\\ninterpreting, explaining and visualizing deep learning.\\nlong beach, ca, december 9.\\nramanishka, v.; das, a.; zhang, j.; and saenko, k. 2017. top-\\ndown visual saliency guided by captions. in proceedings of the\\n30th ieee conference on computer vision and pattern recognition ,\\n7206 –15. new york, ieee.\\nras, g.; van gerven, m.; and haselager, p. 2018 explanation\\nmethods in deep learning: users, values, concerns andchallenges. arxiv preprint. arxiv:1803.07517v2 [cs.ai].ithaca, ny: cornell university library.\\nribeiro, m. t.; singh, s.; and guestrin, c. 2016. “why should\\ni trust you? ”: explaining the predictions of any classi ﬁer. in\\nproceedings of the 22nd acm sigkdd international conference on\\nknowledge discovery and data mining ,1 1 3 5 –\\n44. new york:\\nassociation for computing machinery. doi.org/10.1145/2939672.2939778\\nshe, l., and chai, j. y. 2017. interactive learning for ac-\\nquisition of grounded verb semantics towards human-ro-bot communication. in proceedings of the 55th annual\\nmeeting of the association for computational linguistics , vol. 1,1634 –44. stroudsburg, pa: association for computation\\nlinguistics. doi.org/10.18653/v1/p17-1150\\nvicol, p.; tapaswi, m.; castrejon, l.; and fidler, s.\\n2018.moviegraphs: towards understanding human-cen-\\ntric situations from videos. in ieee conference on computer\\nvision and pattern recognition . new york: ieee. doi.org/10.\\n1109/cvpr.2018.00895\\nvong, w.-k.; sojitra, r.; reyes, a.; yang, s. c.-h.; and shafto,\\np. 2018. bayesian teaching of image categories. paper pre-sented at the 40th annual meeting of the cognitive sciencesociety (cogsci). madison, wi, july 25 –28.\\ny a n g ,s .c . - h . ,a n ds h a f t o ,p .2 0 1 7 .e x p l a i n a b l ea r t i ﬁcial in-\\ntelligence via bayesian teaching. paper presented at the 31stconference on neural information processing systemsworkshop on teaching machines, robots and humans. long\\nbeach, ca, december 9.\\nzhou, b.; khosla, a.; lapedriza, a.; oliva, a.; and torralba, a.\\n2015. object detectors emerge in deep scene cnns. paperpresented at the international conference on learning rep-\\nresentations. san diego, ca, may 7 –9.\\ndavid gunning is a program manager in darpa ’s in-\\nformation innovation of ﬁce, as an intergovernmental per-\\nsonnel act from the paci ﬁc northwest national labs.\\ngunning has more than 30 years of experience in developingai technology. in prior darpa tours he managed the pal\\nproject that produced siri and the cpof project that the us\\narmy adopted as its c2 system for use in iraq and afgha-nistan. gunning was also a program director at parc, asenior research manager at vulcan, senior vice president at\\nset corporation, vice president of cycorp, and a senior\\nscientist at the air force research labs. gunning holds an msin computer science from stanford university and an ms incognitive psychology from the university of dayton.\\ndavid w. aha is acting director of nrl ’s navy center for\\napplied research in ai in washington, d.c. his interests\\ninclude goal reasoning, xai, case-based reasoning, andmachine learning, among other topics. he has coorganizedmany events on these topics (for example, the ijcai-18 xai\\nworkshop), launched the uci repository for ml databases,\\nserved as an aaai councilor, and leads darpa xai ’s eval-\\nuation team.\\n58 ai magazinedeep learning and security',\n",
       " 'nber working paper series\\nai and international trade\\navi goldfarb\\ndaniel trefler\\nworking paper 24254\\nhttp://www.nber.org/papers/w24254\\nnational bureau of economic research\\n1050 massachusetts avenue\\ncambridge, ma 02138\\njanuary 2018\\nthe authors thank dave donaldson and hal varian for their thoughtful feedback. trefler \\nacknowledges the support of the “institutions, organizations and growth” program of the \\ncanadian institute for advanced research (cifar). the views expressed herein are those of the \\nauthors and do not necessarily reflect  the views of the national bureau of economic research.\\nat least one co-author has disclosed a financial relationship of potential relevance for this \\nresearch. further information is available online at http://www.nber.org/papers/w24254.ack\\nnber working papers are circulated for discussion and comment purposes. they have not been \\npeer-reviewed or been subject to the review by the nber board of directors that accompanies \\nofficial nber publications.\\n© 2018 by avi goldfarb and daniel trefler. all rights reserved. short sections of text, not to \\nexceed two paragraphs, may be quoted without explicit permission provided that full credit, \\nincluding © notice,  is given to the source.',\n",
       " 'ai and international trade\\navi goldfarb and daniel trefler\\nnber working paper no. 24254\\njanuary 2018\\njel no. f1,o33\\nabstract\\nthis paper explores the international dimensions of the economics of artificial intelligence.  \\ntrade theory emphasizes the roles of scale, competition, and knowledge creation and knowledge \\ndiffusion as fundamental to comparative advantage. we explore key features of ai with respect to \\nthese dimensions and describe the features of an appropriate model of international trade in the \\ncontext of ai. we then discuss policy implications with respect to investments in research, and \\nbehind-the-border regulations  such as privacy, data localization, standards, and competition. we \\nconclude by emphasizing that there is still much to learn before we have a comprehensive \\nunderstanding of how ai will affect trade.\\navi goldfarb\\nrotman school of management\\nuniversity of toronto\\n105 st. george street\\ntoronto, on m5s 3e6\\ncanada\\nand nber\\nagoldfarb@rotman.utoronto.ca\\ndaniel trefler\\nrotman school of management\\nuniversity of toronto\\n105 st. george street\\ntoronto, on m5s 3e6\\ncanada\\nand nber\\ndtrefler@rotman.utoronto.ca',\n",
       " ' \\n \\n 1 ai and international trade  \\n \\nthe last 200 years have produced a remarkable list of major innovations , not  the least of which is  \\nartificial intelligence (ai). like other major innovations, ai will likely raise average incomes and \\nimprove well -being, but it may also disrupt labor  market s, raise  inequality  and drive non-inclusive \\ngrowth. yet, even to the extent that progress has been made in understanding the impact of ai , \\nwe remain largely uninformed about its international dimensions . this is to our great loss. a \\nnumber of countries  are currently negotiating international agreements that will constrain the \\nability of sovereign governments to regulate ai , such as nafta and tpp -11. likewise, \\ngovernments around the world are freely spending public funds on  new ai clusters designed to \\nshift international comparative advantage towards their favored regions, including  the vector \\ninstitute in toronto and the tsinghua -baidu d eep learning lab around beijing . the international \\ndimensions of ai innovations and policies have not always been well thought out . this work \\nbegins the conversation.   \\n china has become the focal poi nt for much of the international discussion. the u .s. \\nnarrative has it that chinese protection has reduced the ability of dynamic u .s. firms such as \\ngoogle and amazon to  penetrate chinese market s. this protection has allowed china to develop \\nsignificant commercial ai capabilities, as evidenced by companies such as baidu (a search engine  \\nlike google ), alibaba (an e -commerce web portal like amazon), and tencent ( the developer of \\nwechat, which can be seen as combining  the functions of skype, facebook and app le pay ). while \\nno chinese ai -intensive compa ny has household recognition outside of china, everyone agrees \\nthat this will not last.  further, a host of behind -the-border regulatory asymmetries will help  \\nchinese firms to penetrate canadian and u .s. markets.  \\neven the p entagon is worried. chinese guided -missile  systems are sufficiently \\nsophisticated that they may disrupt how we think of modern warfare ; large and expensive military \\nassets such as aircraft carriers are becoming  overly  vulnerable to smart weapons.1 this may do \\nmore than transform  the massive defense industry;  these ai developments may radically shift the \\nglobal balance of power . \\nas international economists, we are used to hype and are typically dismissive of it. despite \\nai’s short life – agrawal , gans , and goldfarb (2017) date  its commercial birth to 2012 –  ai’s rapid \\ninsinuation into our daily economic and social activities forces us to evaluate  the international \\n                                                 \\n1 new york times, february 3, 2017.  see also preparing for the future of artificial intelligence , office of the \\npresident, october, 2016 .  \\n ',\n",
       " ' \\n \\n 2 implications of ai and propose b est-policy responses.  current policy responses often rest on a  \\nu.s. narrative  of a zero -sum game  in which either the u .s. or china will win .2 is this the right \\npremise  for examining ai impacts and for developing ai policies ? further, call s for immediate \\naction by prominent experts such as bill gates, stephen hawking  and elon musk will likely \\nencourage governments to loosen their pocket books, but will government subsidies be effective \\nin promoting broad -based prosperity or will subsidies become yet another form of ineffective \\ncorporate welfare?  what sp ecific policies are likely to tip the balance away from ineffective \\ncorporate handouts?  \\nusing  comparative advantage theory, trade economists have thought long and hard about \\nthe right mix of policies for successfully promoting  industry . many of our theorie s imply a laissez -\\nfaire free -trade approach. however, since the early 1980s our theories have shown that certain \\ntypes of government interventions  may be successful , e.g., krugman (1980) , grossman and \\nhelpman (1991) , and the more informal theories of porte r (1990) . these theories emphasize the \\nrole of scale and the role of knowledge creation and diffusion.  unfortunately, the precise policy \\nprescriptions produced by these theories are very sensitive to the form of scale and the form of \\nknowledge creation/diffusion.  and competition can play an important role too, e.g. , aghion et al. \\n(2001, 2005) and lin, trefler and yu (2017).   \\nwe therefore start in section 2 by identifying the key features of ai technology  in regard  \\nto scale and know ledge. to date there are no models that feature the particular scale and \\nknowledge characteristics that are empirically relevant  for ai. in section 3 we use these features \\n(1) to offer some suggestions for what an appropriate model might look like and (2) to draw \\nimplications for polic y. this leads to high -level thinking about policy. for example, it provides a \\nfoundation for our positive  assessment of  recent proposals put forward by  ai researcher geoff \\nhinton and others on the potential benefit of public investment s in ai .3 however, these models \\nare not sufficiently fine -grained  to directly capture existing regulatory issues  that “go behind the \\nborder ” such as privacy policy, data localization, technology standards and industrial regulation.   \\nin section 4 we therefore review the many behind -the-border policies that already impact ai and \\ndiscuss their implications for comparative advantage  and the design of trade agreements . we \\nbegin  with a factual overview of t he international dimensions of ai.  \\n \\n                                                 \\n2 e.g.,  https://www.economist.com/news/business/21725018- its-deep -pool -data -may -let-it-lead -artificial -\\nintelligence -china -may -match -or-beat -america  and http://www.reuters.com/article/us -usa-china -\\nartificialintelligence/u -s-weighs -restricting -chinese -investment -in-artificial -intelligence -iduskbn1942ox?il =0  \\n3 “artificial intelligence is the fu ture, and canada can seize it” by jordan jacobs, tomi poutanen, richard zemel, \\ngeoffrey hinton and ed clark.  globe and mail, january 7, 2017 . ',\n",
       " ' \\n \\n 3 1. from hype to policy  \\nstatistics about where ai is being done internationally and how it is diffusing can be tracked in a \\nnumber of ways , e.g., the number of basic research  articles, patents and  patent citations  produced \\nin a region;  the number of start -ups established in a region ; or the market cap italization of \\npublicly traded ai -based companies in a region. we look at two of these  indicators : basic research \\nand market cap italization . for the former, w e collect ed time -series data on the institutional \\naffiliation of all authors of papers presented at a major ai research conference, namely, t he \\nassociation for the advancement of artificial intelligence (aaai) conferen ce on artificial \\nintelligence. in table 1, we c ompare  the 2012 and 2017 conferences. in 2012, 41  percent  of authors \\nwere at u .s. institutions, but by 2017 this was down to 34  percent . the two other largest declines \\nwere recorded by canada and israel. while  these countries all increased the ir absolute number of \\nparticipants, in relative terms they all lost ground to china, which leap t from 10  percent  in 2012 \\nto 24  percent  in 2017.   \\n \\ntable 1. participants at a major ai conference  \\n \\nnotes: participation rates at the association for the advancement of \\nartificial intelligence (aaai) confere nce on artificial intelligence. \\nfor example, of the papers presented at the 2017 conference, 34  \\npercent  of authors had a u.s. affiliation.  \\n ',\n",
       " ' \\n \\n 4 we have not examined patent numbers, but suggestive work by fujii and managi (2017) \\npoints to weaker  international diffusion of ai : u.s. technology giants such as ibm and microsoft \\nremain far and away the world’s dominant patent applicants . \\nanother indication of the economic future of ai comes from the largest public companies \\nin the world by market capitalization.  table 2 lists the  12 largest companies worldwide.  what is \\nstriking about the table is the number of companies that might subjectively be described as “ ai \\nintensive. ” seven  of the 12 companies are heavily engaged in ai  (such as alphabet/google), three \\nare in finance  (where the use of ai is growing rapidly ) and one has a substantial pharmaceutical \\npresence (where ai is likely to  soon be reducing development costs) . what makes table 2 relevant \\nfor international trade is t he fact that two of the largest companies worldwide are now chinese \\nai-intensive firms (tencent and alibaba). it is truly remarkable that two high -tech companies \\nbased out of china – private companies, not state -owned enterprises –  are among the largest \\ncompanies in the world. while we had to move beyond the round number of 10 to make this point, \\nit is striking nonetheless.  it points to the major global shake -up that is coming . \\n \\ntable 2. world’s largest public companies and ai exposure  \\n \\nnotes: market capitalization of the largest public companies  as of march 31, \\n2017, from pwc (2017).  “ai exposure ” is our subjective ass essment of the  \\nrole of ai in company performance.   \\n \\nsome would conclude from tables 1 and 2 that almost all of the world’s largest companies \\nwill soon be competing directly against chinese companies when  – not if –  these chinese \\n',\n",
       " ' \\n \\n 5 companies go global. in 2000, robin li signaled his agreement by moving to china to establish \\nbaidu. the flood of u .s.-trained talent returning to china has continued . this year , former \\nmicrosoft executive qi lu joined baidu as coo. in describing china, lu  writes, “we have an \\nopportunity to lea d in the future of ai.”4 not everyone agrees . some have  argue d that china’s  ai-\\nintensive companies will not  be globally competitive until they compete head on in china with \\nglobal leaders such as  google. this flies in the face of a long history of chinese export successes \\nin other fields. indeed, sutton and trefler (2016) describe both theoretically and empirically how \\ndeveloping countries such as china initially enter new markets at a low level of quality, but over \\ntime develop the capabilities to deliver high -quality, internationally competitive goods and \\nservices.  \\nmany experts are weighing in on how to counter the “ chinese threat ” and, more generally, \\nhow to enrich local economies through cluster policies that support sustained competitive  \\nadvantage in ai -based market segments.  geoff hinton and collaborators  have convinced \\ncanadian governments to develop a major ai institute that would “graduate the most machine -\\nlearning phds and m asters students globally” and “become the engine for an ai supercluster that \\ndrives the economy of toronto, ontario and canada.”5 hinton also emphasizes the importance of \\naccess to data. “ why? because for a machine to “ think ” intelligently, it must be trained with lots \\nof data.”   \\nwhile we are supportive of hinton’s initiative, it raises two important points that loom \\nlarge in our thinking . first, economists who specialize in clusters are deeply skeptical about the \\nefficacy of cluster policies  (e.g., duranton, 2011 ). such policies have failed more often than not \\nand the theoretical justification for cluster policies is highly sensitive to assumptions about \\nknowledge diffusion . for example, will hinton’s phds  stay in canada and will the knowledge they \\ngenerate be commercialized in canada?  second, a host of behind -the-border regulations on \\nprivacy, data localization, technology standards and industrial policy  will a ffect the ability of \\ncanadian firms to access data relative to their competitors in larger markets such as the u .s., \\neurope and china. what is the current sta te of these  domestic data  regulations, how do they effect \\ntrade patterns, do they serve a public interest, are they being used as disguised protection to \\ngenerate comparative advantage , and should they be covered by international trade agreements \\n(as some would have been in the trans -pacific partnership (tpp)  e-commerce chapter) ? \\n                                                 \\n4 the economist , july 15 2017 . \\n5 globe and mail, january 7, 2017 . ',\n",
       " ' \\n \\n 6 the following sections help answer these questions and move us towards better policies \\nfor promoting ai and preventing both corporate welfare and welfare- reducing disguised \\nprotection.  \\n \\n2. the technological backdrop : \\nscale , scope , firm size and knowledge diffusion  \\n \\n the oxford english dictionary defines ai as  “the theory and development of computer \\nsystems able to perform tasks normally requiring human intelligence.” this has meant different \\nthings at different times. in the 1960s and 1970s, computer scientists approached this using rules , \\nif-then statements, and  symbolic logic.  it worked well for factory robots and for playing chess. by \\nthe 1980s, it became clear tha t symbolic logic could not deal with the complexi ties of non -artificial \\nsettings , and ai research slowed substantially. various approaches continued to be supported in \\na small number of locations, including by the canadian institute for advanced studies ( cifar ).  \\n the recent resurgence in ai research is driven by one such approach: the insight that \\ncomputers can “learn” from example. this approach is often called “machine learning” and is a \\nfield of computational statistics. the algorithm that has received the most attention is back \\npropagation in neural networks, most notably through “deep learning ,” but there is a large suite \\nof relevant technologies including deep learning, reinforcement learning, etc.  because the current \\nexcitement about ai is driven by machine learning, we focus on this particular set of algorithms \\nhere.  \\n for our purposes, we need to zero in on those aspects of ai technology that are central to \\nthinking about the economics of ai. we identify four aspects:  economies of scale associated with  \\ndata, economies of s cale associated with an ai research team, economies of scope in the use of the \\nteam for multiple applications, and knowledge externalities.  \\n \\na. economies of scale  from data  \\nstatistical predictions improve with the quantity and qual ity of data. recall from statistics 101 \\nthat the quality of prediction increases with n (or, more precisely with root n). all else being \\nequal, this means that companies that have more observations will generate more accurate \\npredictions. it is in t his sen se that economies of scale matter. still, because predictions increase \\nin root n, then, while scale matters, there are decreasing returns to scale in terms of the accuracy \\nof prediction.  ',\n",
       " ' \\n \\n 7  it is subtler  than this, however. google and microsoft both operate search engines. google \\nhas claimed their search engine has higher market share because it has  better quality.6 microsoft \\nhas claimed the higher quality is a direct consequence of scale. by having more data, google can \\npred ict what people want in their search results more accurately. google responds that microsoft \\nhas billions of search results. while google has more data, surely the law of large numbers applies \\nbefore one billion results. and so, more data does not give a m eaningful advantage. microsoft’s \\nresponse is the essence of where economies of scale bind. while they have billions of searches, \\nmany search queries are extremely rare. microsoft may only see two or three. and so google can \\npredict those rare queries much better. if people choose search engines based on quality \\ndifferences in rare searches, then google’s better data will lead to a substantial increase in market \\nshare. having a larger share gives google more data, which in turn improves quality and supports \\nan even larger share.  \\n the source of economies of scale here is  therefore in the form of direct network \\nexternalities. more customers generate more data , which in turn generates more customers. this \\nis different from the literature on tw o-sided markets and  indirect network externalities. the \\nnetwork externalities resemble the phone network, rather than externalities between buyers and \\nsellers on a marketplace like ebay. this is significant in a trade context because the trade literature \\nhas emphasized two -sided matching , e.g., rauch ( 1999 ) and mclaren ( 2000) . this is also \\ndifferent from all  of the trade  and market structure  literature , which emphasize economies of scale \\nthat are driven by fixed costs.  so trade theory does not currently have models that  are applicable \\nto the ai technology environment.   \\n the direct network externalities environment leads to a core aspect of competition in ai: \\ncompetition for data. the companies that have the best data make better predictions. this creates \\na positive feedback l oop so that they can collect even more data. in other words, the importance \\nof data leads to strong economies of scale.  \\n \\nb. economies of scale  from the overhead of developing ai capabilities  \\nanother source of economies of scale in ai involves the fixed cost of building an ai capability \\nwithin a firm. the main cost is in personnel. much of the software is open source, and in many \\ncases hardware can be purchased as a utility through cloud services. the uses of ai need to be big \\nenough to justify the substa ntial cost of building a team of ai specialists. world leaders in ai \\n                                                 \\n6 there is a chicken and egg problem, whether good algorithms drive market share or whether market share drives \\nhiring that leads to better algorithms.  for one point of view, see https://www.cnet.com/news/googles -varian -search -\\nscale- is-bogus/ .  ',\n",
       " ' \\n \\n 8 command very high pay, often in the millions or tens of millions . top academic researchers have \\nbeen hired to join google (hinton ), apple  (salakhutdinov) , facebook  (lecunn ), and uber  \\n(urtasun). so far, there has been a meaningful difference between employing the elite researchers \\nand others in terms of the capabilities of the ai  being developed .  \\n \\nc. economies of scope  \\nperhaps more than economies of scale, the fixed cost of building an ai  capacity generates \\neconomies of scope. it is only worth having an ai team within a company if there are a variety of \\napplications for them to work on. many of the currently leading ai firms are multiproduct firms. \\nfor example, google parent alphabet runs a search engine (google), an online video service \\n(youtube), a mobile device operating system (android), an autonomous vehicle division \\n(waymo), and a variety of other businesses. in most cases, the economies of scope happen on the \\nsupply side  through ai talent, better hardware and better software.  \\n another important source of economies of scope is the sharing of data across applications. \\nfor example, the data from google’s search engine might be valuable in helping determine the \\neffectiveness o f youtube advertising, or its mapping services might be needed for developing \\nautonomous vehicles.  the sharing of data is a key source of international friction on disguised \\nprotection behind the border. differences in privacy policies mean that it is easi er to share data \\nacross applications in some countries compared to others . for example, when ebay owned paypal, \\nit faced different restrictions for using the paypal data in canada compared to the united states. \\nwe will return to this subject below.  \\n this c ontrasts with the main emphasis in the trade literature on economies of scope, which \\nemphasizes the demand side.  economies of scope in ai do not seem to be about demand \\nexternalities in brand perception or in sales channels. instead, they appear to be driven by \\neconomies of scope in innovation. a wider variety of potential applications generates greater  \\nincentives to invest in an ai research team, and it generates more benefits to each particular ai \\nproject due to the potential to share data across applications.  \\n \\nd. knowledge exte rnalities  \\nthere is a tension in discussing knowledge diffusion in the ai sphere. on the one hand, the \\nspectacular scientific advances are often taught at universities and published in peer- reviewed \\njournals, providing businesses and government personnel with quick and easy access to frontier \\nresearch. further,  there is the migration of personnel across regions and countries as the above ',\n",
       " ' \\n \\n 9 examples of robin li and qi lu  show. this suggests that knowledge externalities are global in \\nscope.  \\n on the other hand, ai expertise has also tended to agglomerate in several narrowly defined \\nregions globally . as with other information technologies, much of the expertise is in silicon valley. \\nberlin, seattle, london, boston, shanghai, and to some extent toronto and montreal can all claim \\nto be hubs of ai innovation . this suggests that ai involves a lot of tacit knowledge that is not easily \\ncodified and transf erred to others.  \\n in fact, the traditional discussion of knowledge externalities takes on a more nuanced hue \\nin the context of ai. can these researchers communicate long distance? do they have to be \\ntogether? how important are agglomeration forces in ai? as of 2017, ai expertise remains \\nsurprisingly rooted in the locations of the universities that invented the technologies. google’s \\ndeepmind is in london because that i s where the lead researcher lived. then the first expansion \\nof deepmind outside  the u .k. was to edmonton alberta  because richard sutton, a key inventor \\nof reinforcement learning, lives in edmonton. uber opened an ai office in toronto because it  \\nwanted to hire raquel urtasun, a university of toronto professor.  \\n generally, there are a small num ber of main ai research departments: s tanford, carnegie \\nmellon university, the university of toronto and several others.  their location is often \\nsurprisingly disconnected from headquarters. and so companies open offices where the talent is, \\nrather than forcing the talent to move to where the company is.  \\n as we shall see, the exact nature of knowledge externalities is terribly important for \\nunderstanding whether cluster and other policies are likely to succeed. the nature of these \\nexternalities also has s ome unexpected implications such as the implications of non -compete \\nclauses (saxenian  1994 ) and the asymmetries in access to knowledge created by asymmetries in \\nwho can speak english versus who can speak chinese versus who can speak both.  \\n \\n3. trade theory  and the case for industrial and strategic trade policies  \\n \\n there are many voices in the industrialized world arguing for industrial policies and \\nstrategic trade policies to promote rising living standards. many of these voices point to the \\nachievements of china as an example of what is possible. much of what is claimed for china, and \\nwhat was once claimed for japan, is of dubious merit. china has redirected vast resources from \\nthe rural poor and urban savers towards state -owned enterprises that have mass ively \\nunderperformed . those firms continue to be major players in the economy and a major drag on \\neconomic growth (brandt and zhu 2000 ). it is thus significant that china’s greatest commercial ',\n",
       " ' \\n \\n 10 successes in ai ha ve come from private companies. so if we are to make the case for industrial \\nand strategic trade policies, we cannot blithely appeal to chinese state -directed successes. rather, \\nwe must understand  the characteristics of industries that increase the likelihood that government \\npolicy interventions will be successful .  \\n to this end, we start with a vanilla specific factors model of international trade ( mussa, \\n1974; mayer, 1974 ) in which the case for departures from free trade is weak. we then add on \\nadditional elements and examine which of these is impor tant for policy success. the first \\nconclusion is that scale and knowledge externalities are critical. the second is that these two \\nelements alone are not enough: their precise form also matters.  \\n \\na. scientists, heterogeneous scientists and superstar scientists  \\nmany factors enter into the location decisions of ai firms including access to local talent,  local \\nfinancing /management  and local markets . in this section , we focus on the role of university -\\nrelated talent. among the participants of this confere nce are three head researchers at top ai \\ncompanies : geoffrey hinton (university of toronto and google) , russ salakhutdinov (carnegie \\nmellon university and apple) , and yann lecun  (new york university and facebook) . each  joined \\nhis company  while retaining his academic position and each continues to live near his university \\nrather than near corporate  headquarters . these three examples are not  exceptional , as indicated \\nby the above examples of deepmind, richard sutton and  raquel  urtasun . \\n scientists : we begin with the simplest model of trade that allows for two types of \\nemployees, scientists and production workers . there are two industries, search engine s and \\nclothing . production w orkers are employed in both industries and move between them so that \\ntheir wages are equalized across industries. scientists are “ specific ” to the search engine industry \\nin that they are very good at ai algorithms and useless  at sewing. we also assume that scientists \\nand workers cannot migrate internationally. then it is immed iately obvious that the more \\nscientists a country has, the larger will be both the size and service exports of the search engine \\nindustry.  \\n we start with this benchmark model because in this setting  without scale or externalities, \\nthere is no scope for ma rket failure and hence there is no simple  case for any trade polic y other \\nthan free trade . for example, consider a policy of restricting imports of search engine services, as \\nchina has done with google. this restriction helps chinese scientists but can hurt chinese \\nproduction workers and consumers (ruffin and jones, 1977).  \\n there are several departures from this benchmark model that lead to welfare -enhancing \\nexport subsidies and other departures from free trade. as we shall see, t he two most important ',\n",
       " ' \\n \\n 11 are economies of scale and knowledge creation. however, we start instead with profits because  \\nprofits are at the core of arguments supporting  strategic trade policies ( krugman, 1986 ). since \\nthere are no profits i n the specific factors model we  introduce profits by introducing scientists of \\nheterogeneous quality.  \\n heterogeneous scientists : consider an industry in which firms provide a search engine \\nand generate advertising revenue. there is a continuum of scientists distinguished by their \\n“quality ” q. a firm is distinguished  by the quality of its chief scientist  and hence  firms are also  \\ninde xed by q . a higher quality scientist produces a better search engine. a firm engage s in activity  \\na that increase s advertising revenues r(a) where ra > 0. let p(q) be the proportion of c onsumers \\nwho choose firm  q’s search engine . it is natural to assume that p q > 0 i.e., a better scientist \\nproduces a more desirable search engine. the firm’s profit before payments to the scientist is \\nπ(a,q) = p (q) r(a) – c(a) where c(a) is the cost of  the firm’s ad generating activity . in this model \\nthe firm is  essentially  the sc ientist, but we can delink the two  by assuming that the scientist is paid \\nwith  stock options and so receives a fraction (1 –  µ) of the profits. i t is straightforward to show \\nthat profit π(a,q) is supermodular in ( a,q). this implies positive assortative matching ; firms with \\nbetter scientists engage in more ad -generating activity . this means that firms with better \\nscientists will also have more users (pq > 0), more revenues  [∂r(a(q),q)/∂q > 0],  and higher \\nprofits  [∂π(a(q),q)/∂q > 0]. putting th ese together, better scientists anchor bigger and more \\nprofitable  firms.7  \\n to place this model into an international trade setting, we assume that there a re multiple \\ncountries , a second constant -returns- to-scale industry (clothing)  and no international migration \\nof scientists or workers. because there are profits in the search engine in dustry, policies that \\nexpand that  industry generate higher profits. this is the foundation of strategic trade policy . in \\nits simplest form, if there are super -normal profits then  tariffs and other trade policies can be \\nused to shift profits away from the foreign country and to the domestic country.  \\n strategic trade policy was first developed by brander and spencer (1981) and variants of \\nit have appear ed in many of the models discussed below. unfortunately, the case for strategic \\ntrade policy is not as clear as it might seem. its  biggest logical problem is the assumption of \\n                                                 \\n7 the first -order condition for advertising activities  is µπa = µ( p ra – ca) = 0. we assume that the second -\\norder condition is satisfied: µ πaa < 0. supermodularity is given by ∂2µπ(a,q)/∂a∂q = pq ra > 0. the result \\nthat advertising activity levels a (q) are increasing in q comes  from differentiating the first -order condition: \\nµpq ra + µπaa aq = 0 or a q = –pq ra / πaa > 0. the result that average revenues  p(q)r(a) are increasing in q  \\nfollow s from ∂ p(q)r(a(q))/∂q = pqr + pr aaq > 0. the result that profits  π(a(q),q) are increasing in q follow s \\nfrom ∂µπ(a,q)/∂q = µπa aq + µpq r(a) = µ pq r(a) > 0  where we have used the first -order condition ( πa = 0) . ',\n",
       " ' \\n \\n 12 positive profits : if there is free entry, then entry will continue until profits are driven to zero.8 this \\nmeans that any government policy that encourages entry of firms or training of scientists will be \\noffset by inefficient entry of firms or scientists . put simply, strategic trade policies only work if \\nthere are profits, but with f ree entry there are no profits. see eaton and grossman (198 6). the \\nconclusion we draw  from this  is that the model needs enriching before it can be used to justify \\ntrade policy . \\n before enriching the model, we note that there are two other compelling reason s for being \\nskeptical about the efficacy of strategic trade policy. first, such policies set up political economy \\nincentives for firms to capture the regulatory process used  to determine the amount and form of \\ngovernment handouts. second, the logic of stra tegic trade policy fails if there is retaliation on the \\npart of the foreign government.  retaliation generates a trade war in which  both countries lose.  ai \\nmeets all the conditions that busch (2001) identifies as likely to lead to a trade war. we now turn \\nto enriching our model.   \\n superstar scientists :9 strategic trade policies  are more compelling  in settings where scale \\nand/or knowledge creation  and diffusion  are prevalent . to this end we follow section 2 above in \\nassuming that there are  economies of scale in data. this will cause  the market to be dominated by \\na small number of search engine firms , that is, it will turn our model into something that looks \\nlike a superstar model . to be more precise, it is a little different from standard superstar models \\nthat make assumptions on the demand side (rosen, 1981) . the superstar assumptions here are  \\non the supply side . \\n modifying our model slightly, we introduce scale in data by assuming that the share of  \\nconsumer s choosing a search engine ( p(q)) is increasing at an increasing rate ( pqq > 0).10 pqq > 0 \\nimplies that  profits and scientist earnings increase at an increasing rate , i.e., they are convex in \\nq.11 this , in turn , implies that the distribution  of firm size becomes highly skewed towards large \\nfirms. it also implies that the shareholders of large firms will make  spectacular earnings , i.e., the \\n1 percent  will pull away from the rest of society.  \\n in this setting we expect that a small number of large firms will capture most of the  world \\nmarket for search engines . further, these firms will be hugely profitable . we have in mind a \\nsituation like that found empirically in the  search engine market. the top five  leaders  are (billions \\n                                                 \\n8 free entry implies that ex ante profits are zero. of course, ex post  profits (operating profits of survivors) \\nare always positive; otherwise, survivors would exit.  \\n9 to our knowledge there are no superstar -and-trade models beyond manasse and turrini  (2001), which \\ndeals with trade and wage inequality . \\n10 this is an ad hoc assumption, but to  the extent that it has the flavor of scale economies, we will see less \\nad hoc va riants in the models reviewed below.   \\n11 from a previous footnote, ∂π(a(q),q)/∂q = p q r(a). hence ∂2π(a(q),q)/∂q2 = p qq r + p q ra aq > 0.  ',\n",
       " ' \\n \\n 13 of monthly visitors in parentheses): google (1 .8), bing ( 0.5), yahoo (0 .5), baidu (0.5) and ask \\n(0.3).12 if the chinese government subsidizes baidu or excludes google from china , then baidu \\ncaptures a  larger  share of the market . this generates higher profits and higher earnings f or \\nshareholders within china, making china bette r off both absolutely and relatively to the u .s. \\ndepending on the details of the model, the u .s. may or may not be absolutely worse off.  \\n this example is very similar to the mid -1980s discussions about commercial jet \\nproduction . at a time when it was understood that there was room for only two players in the \\nindust ry (boeing and mcdonnell douglas were the leaders), the europe an union (eu) heavily \\nsubsidized airbus and ultimately forced  mcdonnell dougla s to exit . these eu subsidies were \\nenormous, but ma y nevertheless have been valuable for eu taxpayers .13 \\n our superstar s model  provide s a more compelling case for government intervention \\nbecause scale in data acts as a natural barrier to entry that prevents the free -entry condition from \\noffsetting  the impacts of government policies. thus , the government can beneficially subsidize the \\neducation of ai scientists and/o r subsidize the entry of firms,  e.g., by offering tax breaks, \\nsubsid ies, expertise, incubators , etc. this establishes that scale economies and the super -normal \\nprofits they sometimes  imply  strengthen the  case for strategic trade policy.  \\n there is, however, one more assumption we have made that is essential to the argument \\nfor strategic trade policy, nam ely, that there are no international knowledge spillovers. in the \\nextreme, if all the knowledge created, for example, by canadian scientists, moved freely to the \\nu.s. or china, then a canadian subsidy would help the world, but would not differentially  help  \\ncanada. thi s establishes the critical role  of knowledge diffusion (in addition to scale) for thinking \\nabout government policies that promote ai.   \\n empirics : what do we know about superstar effects empirically? nothing from the trade \\nliterature. we know th at superstars matter for the rate and direction of innovation in academic \\nresearch. we know that universities have played a key role in developing ai expertise and that a \\nsmall number of university -affiliated chief scientists have played a key role in deve loping new \\ntechnologies. we also have some evidence of a knowledge externality. a zoulay et al . (2010)  show \\nthat the death of a superstar scientist in a field slows progress in the research area of the superstar . \\nthe field suffers as scientists associated with the deceased  superstar produce less  research . while  \\n                                                 \\n12 source: http://www.ebizmba.com/articles/search- engines , july, 2017.  \\n13 the subsidies have continued unabated for over four decades. in 2016, the wto found that wto -\\nnoncompliant eu subsidies were $10 billion. this does not include the wto- compliant subsidies. likewise, \\nthe wto found comparable numbers for wto- noncompliant u .s. subsidies of boeing.  see busch (2001) \\nfor a history.  this raises the possibility that subsidies that are intended to get a firm “on its feet ” become \\npermanent, which is yet another reason to be sceptical about strategic trade policies.  ',\n",
       " ' \\n \\n 14 azoulay et al. do not consider ai, their  work points to the existence of knowledge spillovers that \\nare local rather than global.   \\n inequality : this discussion has not had much to say about inequality. in our superstars \\nmodel, industrial policy and strategic trade policies are successful  precisely because they promote \\nlarge and highly profitable firms. we know that these firms account for an increasing share of \\ntotal economic activity and th at they are likely major contributors both to falling  labor  shares \\n(autor et al., 2017) and to rising top -end inequality. thus, the policies being supported by our \\nmodel do not lead to broad -based prosperity. this ca nnot be ignored.   \\n extensions : while the above model of ai science superstars is useful, it has a number of \\nother problems. it is beyond the scope of this paper to resolve these problems through additional  \\nmodel ing. instead, we highlight each problem and review the related international  trade and \\ngrowth literatures in order to provide  insights into how the model might be improved and what \\nthe implications of these improvements are for thinking about trade and trade policy. the \\nproblems we cover are the following.  \\n1. the scale assumption  pqq > 0 is ad hoc . in subsection b below , we consider scale return s \\nthat are external to the firm and show that the form of the scale returns matters for policy.  \\n2. in our model, t here is no knowledge creation within firms and no  knowledge diffusion \\nacross firms and borders . in subsection c below , we review endogenous growth models \\nand show that the form of knowledge diffusion, whether it is local or global, matters for \\npolicy .  \\n3. our model ignores the geography of the industry and so does not speak to economic \\ngeography and “ supercluster ” policies. we review the economic geography literature i n \\nsubsection d below .  \\n4. in section e below we discuss the implications for supercluster policies.   \\n \\nb. increasing returns to scale external to the firm  – a basic trade model  \\nwe start with a simple trade model featuring economies of scale  whos e geographic scope is \\nvariable , i.e., regional, national or international . the model captures the core insights of richer \\nmodels developed by ethier ( 1982 ), markusen ( 1981 ) and helpman (1984) along with more recent \\ndevelopments by grossman and rossi -hansberg ( 2010, 2012) . \\n  \\n  ',\n",
       " ' \\n \\n 15  firm i produces a homogeneous good using a production function  \\nqi = qαf(li,ki) \\nwhere li is employment of labor , ki is employment of capital,  f displays constant returns to scale , \\nq is industry  output  (q =  σ i qi) and 0  < α < 1. qα is like a solow residual in that i t controls \\nproductivity. the idea is that a firm’s productivity depends on the output of all  firms.14 if q is \\nworld  output  of the industry  then  productivity  qα is common to all f irms internationally  and scale \\nhas no implications for comparative advantage . on the other hand, i f q is national  output of the \\nindustry  then the country with the larger output q will have higher productivity  qα and hence will \\ncapture the entire world market.  \\n ai as an industry has a technology that lies somewhere between national returns to scale \\n(q is national output) and international returns to scale ( q is international output). with national \\nreturns to scale, a government policy  such as tariffs or production  subsidies that increase s \\ndomestic output will increase national  welfare because the policy raises average productivity at \\nhome  and also drive exports. whether it helps or hurts the foreign  country depends on a number \\nof factors such as the strength  of the scale returns (the size of α ) and the size of the countries \\n(helpman, 1984). most importantly, the domestic benefits of industrial and trade policies depend \\non the geographic extent of scale , i.e., how much of it is national versus international.   \\n whether scale operates at the national or international level  is not easy to assess and has \\nnot been attempted  for ai. for the dram market in the 1980s , irwin and klenow  (1994) show \\nthat exter nal economies of scale were entirely international rather than national.  other evidence \\nthat ai economies are international is the fact that ai algorithms have been disseminated  \\ninternationally  via scientific journals and teaching , and r&d -based ai knowledge  has diffused \\ninternationally  via imitation and reverse engineering . on the other hand, the co -location of ai \\nresearchers  in silicon valley and a handful of other technology hubs  is suggestive of national and \\neven sub -national returns to scale. azoulay et al. (2010) also suggests the existence of sub -national \\nreturns to scale. clearly, more research is needed on the extent of national versus international \\nreturns to scale  in ai . \\n \\nc. knowledge creation and diffusion: endogenous growth  \\nin the previous section , scale was  external to the firm  and, relatedly, firms did no research . we \\nnow introduce firm -level research . conveniently , some of the key implications of firm -level \\n                                                 \\n14 each firm ignores the impact of its output decision on q so that returns to scale can be treated as external \\nto the firm.   ',\n",
       " ' \\n \\n 16 innovation are similar to those from the previous section, namely, that trade policy depends in \\nlarge part on the extent to which knowledge spillovers are national or international. to see this, \\nwe review the main endogenous growth models that feature international t rade. these are \\ngrossman and helpman (1989, 1990, 1991 ), rivera -batiz and romer  (1991), and aghion and \\nhowitt  (2009, ch. 15 ). in these models , firms conduct costly  r&d and there is an externality that \\naffects the se costs. the dominant model in the trade literature features quality ladders ( grossman \\nand helpman, 1991 ) featuring  vertical (quality) differentiation . the highest -quality firm takes the \\nentire market and earns profits .15 \\n innovation improves the quality of the frontier firm  by a constant proportion  λ. at date t  \\n> 0, let n (t) be the number of quality improvements during the time interval (0, t) so that the \\nfrontier quality is λn(t). firms invest an amount r  in r&d and this generates an endog enous \\nprobability p(r) of becoming the quality leader (with quality λn(t)+1).  \\n a key feature of the r&d process is an externality: innovators stand  on the shoulders of \\ngiants in the sense that they improve on the frontier level of quality. had they improved on their \\nown quality, there would be no externality.  a two -sector, two -country quality ladder model  \\nappears in grossman and helpman (1991). gross man and helpman assume that there is a \\nstandard constant -returns- to-scale sector and a quality  sector.16 \\n another popular approach is romer’s (1990) expanding -varieties model. final goods \\nproducers combine varieties of intermediates using a ces production function so that there is \\nlove of variety. at any date t  there is a measure n(t) of varieties. the marginal returns to new \\nvarieties are positive, but diminishing. the key “ building on the shoulders of giants ” externality is \\nthat the cost of developing a new variety is inversely proportional to the measure of varieties. as \\na result, innovation costs fall over time, generating endogenous growth.  a one -sector, two -country \\nextensio n appears in rivera -batiz and romer  (1991). a two -sector, two -country extension \\nappears in grossman and helpman (1991).  \\n this  brief review  leads to a number of observations. a s in the previous section,  the benefit \\nof trade policy  depends on whether the externality operates at the national or international levels. \\nq of the previous section is replaced here by either λn(t) or n(t). hence, if each firm builds on the \\ninternational  frontier λn(t) or the international  number of varieties  n(t) then there are no \\nimplications for comparative advantage; however, if each firm builds on its national  λn(t) or \\n                                                 \\n15 ex post  profits are needed in order to justify r&d expenses. however, these models have a free- entry \\ncondition which drives ex ant e profits to zero.  \\n16 placing endogenous growth  into a two -sector model so as to facilitate a discussion of comparative \\nadvantage is not easy because the sector with improving quality slowly takes over the entire economy unless \\nother price or non -price “congestion ” forces prevent this.  ',\n",
       " ' \\n \\n 17 national  n(t) then the frontier country  will develop an increasingly strong comparative advantage \\nin the quality or expanding -varieties sector.  with national -level  externalities one country  will \\ncaptur e the lion’s share of the quality/varieties  sector. further, a  country can capture  this sector \\nby using  r&d and trade policies . \\n endogenous growth models provide important insight s into the details of r&d and trade \\npolicies . r&d policies directly target the knowledge  externality and so are preferred to (second -\\nbest) trade policies. one r&d policy avenue is to promote knowledge diffusion . this can be done \\nthrough subsidies to non -profit organizations targeting  local within -industry  interactions and \\nindustry -university collaborations . a second r&d policy avenue is to promote knowledge \\ncreation  through r&d subsidies that are available to al l firms , universities  and students . there is \\na tension between these two avenues ; knowledge diffusion can discourage knowledge creation \\nsince knowledge diffusion to competitors  reduces the returns to innovation. however, the tension \\nis sometimes constructi ve: silicon valley emerged from the shadows of massachusetts’ route 128 \\npartly because of an “ open -source attitude ” (saxenian, 1994) and californian restrictions on non-\\ncompete clauses  (marx and fleming 2012) . it is less likely that diffusion of knowledge to foreign \\ncountries will be as beneficial domestically.  \\n this class of models discourages policies that target individual firms or that “pick \\nwinners. ” to understand why industry leaders should not  be advantaged by policy, note that \\ncounter -intuitively,  industry leaders will be the least innovative firms due to the “market -stealing ” \\neffect.  if an entrant innovates , it steals the market  from the leader. if a leader innovates, it \\ncannibalizes  itself. leaders  therefore have less  of an incentive to innovate.  aghion et al. (2001, \\n2005) address this counter- intuitive result by develop ing a model in which leaders  innovate in \\norder to escape the competition.  aghion et al. (2017) and lim, trefler and yu (2017) are currently \\ndeveloping international trade models featuring escape the competition . \\n  in the context of ai, none of the above endogenous growth models is ideal , leading us to \\nconjecture about what an appropriate  model might look like. t he advantage of endogenous \\ngrowth models is that they emphasize knowledge creation and  diffusion. thinking more deeply \\nabout ai development and commercialization, it is useful to distinguish two aspects of what is \\ndone in the ai research departments of large firms. first, they improve ai algorithms, which ha ve \\nthe flavor of quality ladders. (recall that quality can be something that is perceived by consumers \\nor, as is relevant here, something that reduces marginal costs.)  second, ai research departments \\ndevelop new applications of existing ai , e.g., google uses ai for its search engine, autonomous \\nvehicles, youtube recommendations, advertising network,  energy use in data centers,  etc. this \\nsuggests an expanding -varieties model, but one that operates within  the firm. we are unaware of ',\n",
       " ' \\n \\n 18 any endogenous growth models that have both these features. grossman and helpman (1991) \\nhave the f irst and klette and kortum (2004 ) have the second. combining them in one model is \\nnot trivial and analytic results would likely hav e to be replaced with calibration.  \\n \\nd. new economic geography  and  agglomeration \\nthe discussion in the previous section points to the possibility that knowledge spillovers are \\nsubnational and this leads naturally to a theory of regional clusters such as silicon valley. n ew \\neconomic geography or neg (krugman, 1980) does not typically consider knowledge spillovers, \\nbut it does consider other local externalities that drive  regional clusters. three mechanisms have \\nbeen particularl y prominent: (1) demand -side “home -market effects, ” (2) upstream -downstream \\nlinkages, and (3) labor -market pooling. all of these theories feature two key elements: costs of \\ntrading across regions (e.g., tariffs) and increasing returns to scale at the firm level ( which can be \\nthought of as the fixed costs of developing a new product ). we explain the role of these two \\nelements  in the context of home -market effects .  \\n consider a model with ces monopolistic competition  and two regions ( j = 1, 2) . there are \\nvarieties of machines and the larger the set of machines to choose from , the more productive are \\nthe producers.  let nj be the measure of machine varieties available  in region  j. then with ces \\nproduction functions, productivity is proportional to n j.17 the fundamental factor pushing for \\nagglomeration is the strength of th is love-of-variety /productivity  externality . (this is related to \\nthe externality in romer’s expanding varieties model , which  is also proportional to nj.) as in \\nprevious models, the externality operates at the local level rather than  at the international  level. \\nthis externality encourages firms to co -locate or agglomerate since the agglomeration of firms \\ndrives up nj and productivity. the fundamental factor pushing against this agglom eration is trade \\ncosts : a firm can avoid trade costs by locating close to consumers rather than close to other \\nproducers . the main insight of this model is that i n equilibrium a disproportionate share of the \\nworld’s firms will  locate in a single region , and this region will thus have higher productivity. as \\na result, this region will be richer.  notice that firms are choosing to set up where the competition \\nis greatest and where wages and property values are the highest.  \\n the above model of agglomeration ha s been extended in countless ways (e.g., krugman \\nand venables , 1995 ; fajgelbaum et al., 2011 ; duranton and puga, 2001 ) and it is easy to think of \\napplications where the force for agglomeration is not the variety of machines, but the variety of \\nknowledge held by firms. if this knowledge is tacit, meaning it cannot be codified  and transmitted \\n                                                 \\n17 more precisely, productivity is proportional to n1/(σ–1) where σ > 1 is the elasticity of substitution between \\nvarieties.  ',\n",
       " ' \\n \\n 19 in a document)  then knowledge spillovers are only  transmitted locally via face -to-face \\ninteractions. in this case, knowledge externalities lead firms to agglomerate.  the result is regions \\nlike silicon valley.  \\n \\ne. cluster policies  \\ncluster policies have long been the politician’s best friend.  yet economists remain h ighly critical \\nof them.  in surveying the evidence for the success of these policies, uyarra and ramlogan (2012) \\nwrite :  \\n“there is no clear and unambiguous evidence that over the long term \\nclusters are able to generate strong and sustainable impacts in term s of \\ninnovation, productivity or employment.”  \\none of the world leaders in the economics of clusters, gilles duranton titled his 2011 survey \\n“california dreamin’: t he feeble case for cluster policies .” yet clusters remain fashionable.  \\n in light of what we have described, the first question is: when are cluster policies likely to \\nsucceed? the answer is that they are most likely to succeed when  there is clear evidence of scale \\neconomies and of knowledge creation together with local knowledge diffusion. ai displays these \\ncharacteristics, though the extent of international knowledge diffusion cannot be ignored.  \\n the second question is: what policies are likely to work? to answer this question we turn \\nto the insights of ajay agrawal, director of rotman’s creative destruction lab (cdl) and michael \\nporter, the business guru of cluster policies. we start with agrawal. agrawal identifies two \\nproblems with developing ai in the canadian context. first, there is a shortage of people with the \\nskills t o scale up companies. agrawal calls these people 1000xers. second, the cost of information \\nabout a start- up’s quality is so high that capital markets cannot identify the best and the brightest  \\nstart- ups. agrawal’s cdl addresses both of these problems by li nking start -ups with serial \\nentrepreneurs who can identify a good start- up, tap into 1000xers for growth and pass on \\nvaluable information about start -up quality to investors globally.  \\n another  approach to th e question  of what policies are likely to work utilizes porter’s (1990) \\ndiamond , which emphasizes fo ur features of clusters: (1) factor conditions such as universities \\nand an abundant supply of ai scientist s, (2) home -market -demand externalities for ai, (3) \\nexternalities flowing from suppliers of special ized intermediate inputs into ai such as financial \\nservices, and (4) a competitive environment. items 2 -4 involve effects that have already been \\ndescribed in our discussion of knowledge spillovers and lie at the heart of local agglomeration. \\nitem 1 is a mo re conventional economic factor , i.e., drive down the price of the key input by \\nsubsidizing its supply. yet porter’s research shows that many clusters are driven primarily by 1. ',\n",
       " ' \\n \\n 20 that is to say, the single most important policy in practice is simple:  follow hinton’s advice in \\ntraining a large number of ai scientists locally.  \\n our models also suggest two difficulties with hinton’s advice that must be shored up. first, \\nthere is international rather than national knowledge diffusion due to the fact that , for example,  \\ncanadian- trained scientists are likely to leave canada for silicon valley, china and other ai \\nhotspots. th is suggests value in programs like those used successfully in singapore that require \\nstudent loans to be repaid if the student d oes not work in singapore for a  minimum number of \\nyears.  \\n second, scale in data is a huge problem for a small country like canada. to understand \\nappropriate solutions for this, we now turn to the details of national regulatory environments that \\naffect data and the  use of ai.  \\n \\n4. behind the border trade barriers : the domestic regulatory environment  \\n given these models, we next turn to the specific regulatory issues that are likely to impact \\ntrade policy. many of t he core trade issues around ai involve access to data. data is a key input \\ninto ai, and there are a number of government policies that affect data access and data flows. to \\nthe extent these regulations vary across countries, they can advantage some countries’  ai \\nindustries. the models above suggest that this advantage can have consequences if there are \\neconomies of scale, local externalities and/or rents.  \\n we highlight five  policies in particular. the first three involve data:  domestic privacy \\npolicy, data lo calization rules and access to government data.  the others are  development of the  \\nregulation of ai application industries (such as autonomous vehicles) and protection of source \\ncode. privacy policy,  data localization and source code access  have already bec ome significant \\ntrade issues. for example, the tpp addresses all three  of these , as do the u .s. trade \\nrepresentative’s nafta renegotiation objectives. the u .s. position is that strong canadian and \\nmexican privacy rules, localization requirements and access  to foreign source code are all \\nimpediments to u .s. exports of ai -related goods.  in other words, the emphasis on trade policy in \\nthese areas is that regulation could be disguised protection that helps domestic firms and hurts \\nforeign  firms .  in the discussion below, we explore the extent to which this starting assumption is \\nappropriate.  \\n \\n privacy regulation : privacy regulation involves policies that restrict the collection and use \\nof data. such regulation differs across locations. privacy policy has the power to limit or expand \\nthe ability of firms to use ai effectively.  restrictions on the use of data mean restrictions on the ',\n",
       " ' \\n \\n 21 ability to use ai given the data available; however, restrictions on the use of data may also increase \\nthe supply of data availabl e if it leads consumers to trust firms that collect the data. although the \\ntheory is ambiguous, thus far, the empirical evidence favors the former effect on balance . stricter \\nprivacy regulations reduce the ability of firms and nonprofits to collect and use  data and therefore \\nlead s to less innovative use of data  (goldfarb and tucker 2012) . thus, firms in some countries \\nmay benefit from favorable privacy policy.  \\n we believe the most useful analogies for privacy policy in trade relate to labor and \\nenvironmental regulations. such regulations also differ across countries for a va riety of reasons . \\nthey could reflect differences in preferences across countries, or could be perceived as normal \\ngoods that wealthier countries are willing to pay for but poorer countrie s are not ( grossman and \\nkrueger , 1995 ). there is room for reasonable disagreement on how data might be collected or \\nused. some countries will restrict the information used in prediction while others will not. for \\nexample, for insurance, the data that can b e used varies by state, with different states providing a \\nvariety of restrictions on the use of race, religion, gender and sexual orientation in insurance.18 \\neven with such restrictions, if other variables provide surrogates for such categories, it is possi ble \\nthat firms may be forced to abandon ai methods entirely, for more transparent prediction \\ntechnologies.  in terms of privacy policy, we think it is useful to take as given that there are \\ndifferences across countries in their preferences for policies that restrict the collection and use of \\ndata.  \\n given these differences in preferences, what are the implications for trade? suppose that \\nthe optimal privacy policy for growing an ai industry involves relatively few restrictions on data. \\nai requires data, and s o the fewer government restrictions on data collection, the better the \\nindustry.19 to the extent that young firms tend to grow by focusing on the domestic market, this \\nwill advantage the growth of ai firms in some countries relative to others. thus, lax privacy \\npolicies may help domestic industry relative to countries with strict polici es just as lax labor and \\nenvironmental regulation may help the domestic industry.  \\n this suggests the potential of a “race to the bottom” in privacy policy. evidence for such \\nraces has been found in enforcement of labor policies (e.g. , davies and vadlamannati 2013) and \\nin environmental policies (e.g. , beron et al 2003 fredriksson and milliment 2002). there is \\nevidence that privacy regulation does disadvantage jurisdictions with respect to their advertising -\\n                                                 \\n18 http://repository.law.umich.edu/cgi/viewcontent.cgi?article=1163&context=law_econ_current  \\n19 impo rtantly, this is not a statement about the optimal privacy policy from the point of view of a firm. if \\nconsumers have a preference for privacy, the private sector can provide it even in the absence of \\nregulation. for a richer debate on this point, see gold farb and tucker (2012) and acquisti, taylor and \\nwagman (2016).  ',\n",
       " ' \\n \\n 22 supported software industries . in particular, goldfa rb and tucker ( 2011)  examined a change in \\neuropean privacy regulation  (implemented in 2004)  that made it more difficult  for european \\ninternet firms to collect data about their online customers.  this regulatory change was particularly \\nlikely to reduce the effectiveness of advertising on websites that relied on customer tracking data . \\nusing  a consistent measure of the effectiveness of thousands of online advertising campaigns, the \\nresults showed that european online advertising became about 65  percent  less ef fective after the \\nregulation took effect, compared to before the regulation and compared to advertising in other \\njurisdictions, mainly the united states. in other words, privacy regulation seemed to reduce the \\nability of companies to use data effectively. in a different context, miller and tucker (2011) show \\nthat state -level privacy restrictions can reduce the quality of health  care. while this evidence does \\nnot pertain to ai , just like ai, online advertising and health  care  use data as a key input.  in othe r \\nwords, the same forces will likely be at play for privacy regulation that restricts the ability of ai to \\noperate.  \\n under strategic trade models, such races to the bottom are likely to matter if there are \\nrents to be gained from ai. under endogenous grow th models with local spillovers and various \\nagglomeration models, this could create an equilibrium in which the ai industry moves to the \\ncountry with the most lax policies.  currently, privacy policies are much stricter in europe than in \\nthe u .s. or china.20 furthermore, there are a number of differences in such policies between the \\nu.s. and china. this may give the u .s. and china an advantage over europe in this industry.  \\n if stricter privacy policy is likely to hamstring domestic firms in favor of foreign o nes, we \\nwould expect policy to emphasize avoiding such a race to the bottom; however, recent trade \\nnegotiations have instead focused on privacy regulation as disguised pr otection. for example,  this \\nargument is at odds with the current u .s. trade negotiatio n objectives, which want to weaken \\ncanadian privacy laws. based on the existing evidence from other data -driven industries, we \\nbelieve this will help the canadian industry relative to the u .s. industry in the long run, even if it \\nbenefits american companie s that already do business in canada in the short run.  in addition, \\ntpp’s chapter 14 on electronic commerce contains provisions that attempt to limit disguised \\nprotection, but contains almost no  language that encourage s harmonization in privacy  policies  \\nbeyond a request in article 14.8.5 to “endeavor to exchange information on any such [personal \\ninformation protection] mechanisms  … and explore ways to extend these or other suitable \\narrangements to promote compatibility between them.” the words “endeavor” an d “explore” are \\n                                                 \\n20 canada sits somewhere in the middle. europe is strict on both data collection and its uses. canada’s \\ncore restrictions involve use for a purpose different from the collection context. the u .s. emphasizes \\ncontracts, and so as long as the privacy policy is clear, companies can collect and use data as they wish (at \\nleast outside of certain regulated industries like health and finance).  ',\n",
       " ' \\n \\n 23 what are known in the trade policy literature as “aspirational ” language and generally have no \\nforce . the ceta agreement is even more vague with respect to electronic commerce generally. \\nthe electronic commerce section, chapter 16, says little but “recognize the importance of” \\nelectronic commerce regulation and interoperability and that “the parties agree to maintain a \\ndialogue on issues raised by electronic commerce.”21 \\n it is important to note that this is not a statement about company strategy. the market \\nmay discipline and provide consumer protection with respect to privacy. apple , in particular , has \\nemphasized the protection of the personal information of its customers as it has rolled out ai \\ninitiatives, and it is an open question whe ther this strategy will pay off in terms of consumer \\nloyalty and access to better quality, if limited, data.  \\n we also want to emphasize that we do not have a position on the optimal amount of privacy \\nas enforced by regulation. in fact, we think this is a d ifficult question for economists to answer. \\ngiven that the empirical evidence suggests that privacy regulation, on balance and as \\nimplemented thus far, seems to reduce innovation, the determination of the optimal amount of \\nprivacy should not focus on maxim izing innovation (through, as the tpp emphasizes in article \\n14.8.1, “the contribution that this [privacy protection] makes to enhancing consumer confidence \\nin electronic commerce”). instead, it is a balance of the ethical value of (or even  right to ) privac y \\nand the innovativeness  and growth  of the domestic  ai industry.  \\n to reiterate, privacy regulation  is different from many other regulations because privacy \\n(perhaps disproportionately) hamstrings domestic firms. therefore,  trade negotiations should \\nnot sta rt with the assumption that privacy regulation i s disguised protection. instead, discussions  \\nshould start with the public policy goal of the “social benefits of protecting the personal \\ninformation of users of electronic commerce” that is also mentioned in article 14.8.1 of the tpp. \\nthen, if needed, discussions can move to any particular situation in which a privacy regulation \\nmight really be disguised protection.  as we hope is clear from the above discussion, domestic \\nprivacy regulations that restrict how f irms can collect and use data are unlikely to be disguised \\nprotection. we next turn to two other regulations that might use privacy as an excuse to favor, \\nrather than hamstring, domestic firms.  \\n \\n data localization:  data localization rules  involve restrictions on the ability of firms to \\ntransmit data on domestic users to a foreign country. such restrictions are often justified by \\n                                                 \\n21 https://ustr.gov/sites/default/files/tpp -final -text -electronic- commerce.pdf ,  \\nhttp://www.international.gc.ca/trade -commerce/trade -agreements -accords -commerciaux/agr -acc/ceta -aecg/text -\\ntexte/16.aspx?lang=eng   ',\n",
       " ' \\n \\n 24 privacy motivations. countries may want data to stay domestic for privacy and  (related)  national \\nsecurity reason s. in particular, the argument for data localization emphasizes that governments \\nwant the data of their citizens to be protected by the laws of the domestic country. foreign national \\nsecurity agencies should not have access to data that occurs within a cou ntry. and foreign \\ncompanies should be bound by the laws o f the country where the data were  collected. the \\nargument against such localization (at least in public) is technical: such localization imposes a \\nsignificant cost on foreign companies wanting to do business. they need to establish a presence \\nin every country, and they need to determine a system that ensures that the data is not routed \\ninternationally (something that is technically costly, particularly for integrated communications \\nnetworks such as wi thin europe or within north america). u .s.-based companies have lobbied \\nagainst such requirements.22 \\non the technical side, consider two parties, a and b, who reside in the same country. \\ninternet traffic between a and b cannot be confined within national bo rders without specific \\ntechnical guidance (and some cost to quality) because the internet may route data indirectly. in \\naddition, data on a transaction between a and b may be stored on a server located in a different \\ncountry. furthermore, if a and b reside  in different countries, then the data on that transaction \\nwill likely be stored in both countries.23 \\n data localization is an issue for ai because ai requires data. and it often involves merging \\ndifferent data sources together. the quality of aggregate pre dictions from ai will be lower if the \\nscale of data is limited to within a country. in other words, localization is a way to restrict the \\npossible scale of any country in ai, but at the cost of lower quality overall.  \\n put differently, data localization is a privacy policy that could favor domestic firms. unlike \\nthe consumer protection privacy policies highlighted above, it can favor domestic over fo reign \\nfirms because the foreign -firm ai experts may not have access to the data. tpp recognize s this \\nand expli citly restricts it in article 14.11.3a , which states that t he cross- border transfer of \\ninformation should not be restricted in a manner that would constitute “a disguised restriction on \\ntrade.”24  \\n                                                 \\n22 https://publicpolicy.googleblog.com/2015/02/the -impacts -of-data -localization -on.html  \\n23 dobson, tory and trefler. 2017.  \\n24 related to the issue of data localization is the question of who owns data collected on domestic individuals \\nby foreign individuals or firms. for example, consider an american company that uses peruvian s’ cell \\nphones to gather data on agriculture and climate.  who owns the rights to that data? are the americans \\nallowed to profit from that data? are contracts between the individual actors enough, or is there a need for \\ninternational laws or norms? the data might not be collected if not for the private companies,  but the \\ncompanies use the data in their own interest, rather than in the public interest or in the interest of the \\nperuvians who provided the data.  the recent attempts at a joint venture between monsanto and john deere, ',\n",
       " ' \\n \\n 25    \\nprivileged access to government data:  another potential restriction on trade that might \\nbe justified by privacy concerns involves access to government data. governments collect a great \\ndeal of data. such data might be valuable to training ais and improving their predictions. such \\ndata include tax and banking data, education data and health data. for example, as the only legal \\nprovider of most health  care services in ontario, the ontario government has unusually rich data \\non the health needs, decisions and outcomes of 14 million people. if domes tic firms are given \\nprivileged access to that data, it would create an indirect subsidy to the domestic ai industry.  \\n we think the most useful analogy in the current trade literature is the perennial softwood \\nlumber trade dispute between canada and the un ited states. in the softwood lumber case, most \\ntimber in canada is on government -owned land, while in the united stat es, most timber is on \\nprivately owned land. the u .s. complaints allege that canadian timber is priced too low, and is \\ntherefore a governmen t subsidy to the canadian lumber industry. while there have been various \\nagreements over the years, the disagreement has not been fully resolved. the superficial issue is \\nwhat a fair price should be for access to government resources.  the real issue is whe ther legitimate \\nregulatory differences can be argued to convey unfair advantage and therefore constitute a trade -\\nillegal subsidy.  \\n government data can be seen similarly. links between the state and the corporation vary \\nby country, and this might help some corporations more than others. what is a fair price for access \\nto the data? importantly , governments may not want to give foreign f irms access to such data for \\nthe same privacy and national security issues that underlie motivations for data localization . thus, \\nseemingly reasonable differences across countries in their data access policies can end up favoring \\nthe domestic industry .  \\n \\nindustrial regulation : most international agreements have a section on competition \\npolicy and industrial regulation. this is because regulation can be a source of unfair comparative \\nadvantage or disadvantage. in ai applications, this list is long. in additi on to the points around \\ndata and privacy highlighted above,  many applications of ai involve complementary technologies \\nin which standards might not yet exist  and the legal framework might still be evolving.  \\nfor example, in autonomous vehicles, a variety of  standards will need to be developed \\naround vehicle -to-vehicle communication, traffic signals and many other aspects of automotive \\ndesign. most of these standards will be negotiated by industry players (simcoe 2012), perhaps \\n                                                 \\nalong with the u.s. department of j ustice anti -trust concerns that scuttled the deal, highlight how tangible \\nthis issue is.  ',\n",
       " ' \\n \\n 26 with some government input.  as in other contexts, national champions can try to get their \\ngovernments to adopt standards that raise costs for foreign competition.  this leads to the \\npossibility of  international  standards wars. this is particularly true of standards that are likely to \\ninvolve a great deal of government input. for example, suppose governments require that the ai \\nbehind autonomous vehicles be sufficiently transparent that investigators are able to determine \\nwhat caused a crash. without international standards, different countries could require \\ninformation from different sensors, or they could require access to different aspects of the models \\nand data that underlie the technology. for companies, ensuring that their ai is compatible with \\nmultiple regulatory regimes in this mann er would be expensive. such domestic regulations could \\nbe a way to favor domestic firms. in other words, domestic technology standards around how ai \\ninteracts with the legal regime is a potential tool for disguised restriction on trade.  \\nthe autonomous vehi cle legal framework is evolving, with different countries (and even \\nstates within the u .s.) allowing different degrees of autonomy on their public roads. drones are \\nanother example where, in the u .s., the faa strictly regulates american airspace while chin a and \\nsome other countries  have  fewer restrictions. this may have allowed china’s commercial drone \\nindustry to be more advanced than the industry in the u .s.25 thus, regulation can also impact the \\nrate of innovation and therefore comparative advantage.  \\n \\n   source code: to the extent that ai may discriminate, governments may demand \\ninformation about the algorithms that underlie the ai’s predictions under anti -discrimination \\nlaws. more generally with respect to software, including ai, governments may demand ac cess to \\nsource code for security reasons,  for example,  to reduce fraud or to protect national security. thus, \\nusing consumer protection or national security as an excuse, governments could reduce the ability \\nof foreign firms to maintain trade secrets. furt hermore, cyberespionage of such trade secrets may \\nbe widespread, but that is beyond the scope of this chapter.26 broadly, this issue has been \\nrecognized in the tpp negotiations, with article 14.17 emphasizing that access to source code \\ncannot be required un less that source code underlies critical infrastructure or unless the source \\ncode is needed to obey other domestic regulations that are not disguised restrictions on trade.  \\n \\n                                                 \\n25 https://www.forbes.com/sites/sarahsu/2017/04/13/in -china -drone -delivery -promises -to-boost -\\nconsumption -especially -in-rural -areas/#47774daf68fe  \\n26 \\nhttps://obamawhitehou se.archives.gov/sites/default/files/omb/ipec/admin_strategy_on_mitigating_t\\nhe_theft_of_u.s._trade_secrets.pdf  ',\n",
       " ' \\n \\n 27  other policies that might affect the size of domestic ai industries include inte llectual \\nproperty, antitrust, r&d subsidies and national security. if ai is the next important strategic \\nindustry, then all of the standard questions arise with respect to trade policies in these industries. \\nwe do not discuss these in detail because we thi nk the trade -specific issues with respect to these \\npolicies are not distinct to ai but are captured more generally by the discussion of innovation and \\ntrade. the main point for these other aspects of domestic policy with respect to ai and trade is \\nthat the re are economies of scale in ai at the firm level. furthermore, we expect some of the \\nexternalities from  the ai industry to remain local.  \\n \\nai and international macroeconomics  \\n before concluding, it is important to recognize that ai will have implications f or \\ninternational  macroeconomics. for example, suppose that china does succeed in building a large \\nai industry. this will likely increase its trade surplus with the rest of the world, particularly in \\nservices. furthermore, suppose that china manages to cont rol wage inflation through promoting \\nmigration from rural to urban areas, and by relaxing the one -child policy. then, this is likely to \\nput upward pressure on the rmb and downward pressure on the dollar.  \\n this will have implications for u .s. labor markets. at the low end of the market, a \\nweakening dollar might repatriate manufacturing jobs. at the high end of the market, skilled u .s. \\nworkers will for the first time be exposed to competition from a low -wage country. in isolation, \\nthis would re duce one dimension of domestic u .s. inequality.  \\n if the chinese market becomes open to u .s. technology giants  (and vice versa), both the \\nmelitz  (2003)  model and the oberf ield (forthcoming)  model of trade predict that the giants  will \\ngrow even larger. in t he context in which these com panies have already absorbed one -fifth  of u .s. \\nvalue added, and may have contributed to u .s. top-end inequality, the impact of international \\ntrade in further growing these impact s may increase top -end inequality.  \\n \\nconclusion  \\n how will artificial intelligence affect the pattern of trade? and how does it make us think \\ndifferently about trade policy? i n this article we have tried to highlight some key points.  \\n first, the nature of the technology suggests that economies of scale and scope will be \\nimportant. furthermore, as a knowledge -intensive industry, knowledge externalities are likely to \\nbe important. prior literature on other industries suggests that such externalitie s are often local , \\nbut more evidence is needed . second, the  trade models that are likely to be most useful in \\nunderstanding the impact of ai are those that account for these points, specifically, scale, ',\n",
       " ' \\n \\n 28 knowledge creation  and the geography of knowledge diffusion. these models suggest that whether \\nai-focused trade policies (or ai- focused investments in clusters) are optimal will depend very \\nmuch on the presence of scale and the absence of rapid international knowledge diffusion.  third, \\nwe discussed whether and how regulation might be used to favor domestic industry . we \\nhighlighted that privacy policy that targets  consumer protection is unlike many other regulations \\nin that it is likely to hamstring domestic firms, even relative to foreign ones. so, rather than \\nfocusing trade discussions on how privacy policy might b e used as a disguised restriction on trade, \\nsuch discussions should  emphasize regulatory harmonization so as to avoid a race to the bottom. \\nin contrast, several other policies may be used to favor domestic firms including data localization \\nrules, limited a ccess to government data, industry regulation s such as those around the use of \\ndrones, and forced access to source code.  \\n generally, this is an exciting new area for trade research and policy. there is still much \\nto learn before we have a comprehensive und erstanding of these questions.  \\n \\nreferences  \\nacquisti,  alessandro,  curtis  taylor,  and liad  wagman.  2016.  \"the  economics  of \\nprivacy.\"  journal  of economic  literature , 54(2):  442-92. \\naghion, philippe and peter howitt, the economics of growth , mit press, july 2009.  \\naghion, philippe , antonin bergeaud, matthieu lequien, and marc melitz, “the impact of \\nexports on innovation: theory and evidence,” working paper, harvard university, \\nmarch 2017.  \\naghion, philippe , christopher harris, peter howitt, and john vickers, “c ompetition, \\nimitation and growth with step -by-step innovation,” review of economic studies , 2001, 68 \\n(3), 467 –492.  \\naghion, philippe , nick bloom, richard blundell, rachel griffith, and peter howitt, \\n“competition and innovation:  an inverted -u relationship,”  quarterly  journal  of economics , \\n2005,  120 (2), 701–728.  \\nagrawal, ajay, joshua gans, and avi goldfarb. 2016. the simple economics of machine \\nintelligence. harvard business review online . november 17  \\natkeson, andrew and ariel burstein, “innovation, firm dynamics, and international \\ntrade,” journal of political economy , 2010, 118 (3), 433 –484.   \\nautor, david, david dorn, lawrence f. katz, christina patterson, and john van reenen, \\n“concentrating on the fal l of the labor share,” working paper 23108, nber january 2017.  ',\n",
       " ' \\n \\n 29 azoulay, pierre, joshua s.  graff zivin, and jialan wang, “superstar extinction,” quarterly \\njournal of economics , 2010, 125 (2), 549 –589.  \\nberon,  kurt j. , james c.  murdoch,  and wim p.m.  vijverbe rg, “why cooperate? public goods, \\neconomic power, and the montreal p rotocol ,” review of economics and statistics , 85 (2) (2003), \\n286–297.  \\nbrander, james a. and barbara j. spencer, “tariffs and the extraction of foreign monopoly \\nrents under potential entry,” canadian journal of economics , august 1981, 14 (3), 371 –\\n389.  \\nbusch, marc l., trade warriors: states, firms, and strategic -trade policy in high -technology \\ncompetition , cambridge:   cambridge university press,  2001.  \\ndavies, ronald b., and  krishna chaitanya vadlamannati, “a race to the bottom in labor \\nstandards? an e mpirical  investigation, ” journal of development economics , 2013,  103, 1–14. \\nduranton, gilles, “california dreamin’: the feeble case for cluster policies,” review of \\neconomic analysis , july 2011, 3 (1), 3 –45. \\nduranton, gilles, and diego puga, “nursery cities: urban diversity, process innovation, and \\nthe life cycle of products,” american economic review , december 2001, 91 (5), 1454 –1477.  \\neaton, jonathan, and gene m. grossman. 1986. o ptimal trade and industrial policy under \\noligo poly.  the quarterly journal of econom ics, 101(2), 383 -406.  \\nethier, wilfred j., “national and international returns to scale in the modern theory of \\ninternational  trade,”  american  economic  review , june  1982,  72 (3), 389–405.  \\nfajgelbaum, pablo, gene m. grossman, and elhanan helpman, “income distribution, \\nproduct quality, and international trade,” journal of political economy , august 2011, 119 \\n(4), 721 –765.  \\nfredriksson,  per g. , and  daniel l. millimet, “ strategic interaction and the determination of \\nenvironmental policy across u.s. states, ” journal of urban economics , 2002,  51 (1), 101 –122. \\ngoldfarb, avi and catherine tucker,  “privacy regulation and online advertising ,” management \\nscience , 2011, 57(1), 57 –71.  \\ngold farb, avi, and catherine tucker, “privacy and innovation,” i n innovation policy and the \\neconomy , eds. josh lerner and scott stern , 2012, 12 . nber, university of chicago press, 65 –89. \\ngrossman, gene m. and elhanan helpman, “product development and international   \\ntrade,” journal of political economy , december 1989, 97 (6), 1261 –1283. \\ngrossman, gene m. and elhanan helpman, “trade, innovation, a nd growth,” american \\neconomic review papers and proceedings , may 1990, 80 (2), 86 –91. ',\n",
       " ' \\n \\n 30 grossman, gene m. and elhanan helpman, innovation and growth in the global \\neconomy , cambridge, mass. and london: mit press, 1991.   \\ngrossman, gene m. and alan b. krueger, “economic growth and the environment, ” quarterly \\njournal of economics , may 1995, 110 (2), 353 –377. \\ngrossman, gene m. and esteban rossi -hansberg, “external economies and international \\ntrade redux,” quarterly journal of economics , 2010, 125 (2), 829 –858.  \\ngrossman, gene m. and esteban rossi -hansberg , “task trade between similar countries,” \\neconometrica , 2012, 80 (2), 593 –629.  \\nhelpman, elhanan, “increasing returns, imperfect markets, and trade theory,” in peter b. \\nkenen ronald w. jones, ed., handbook of international economics , new york and \\namsterdam and oxford: northholland, 1984, pp. 325 –365.  \\nirwin, douglas a and peter j klenow, “learning -by-doing spillovers in the semiconductor \\nindustry,” journal of political economy , december 1994, 102 (6), 1200 –1227.  \\nklette, tor jakob and samuel kortum, “innovating firms and aggregate innovation,” \\njournal of political economy , october 2004, 112 (5), 986 –1018.  \\nkrugman, paul, strategic trade policy and the new international economics , cambridge:  ma:  \\nmit press, 1986.  \\nkrugm an, paul r., “scale economies, product differentiation, and the pattern of trade,” \\namerican economic review , december 1980, 70 (5), 950 –959.  \\nkrugman, paul r. and anthony j. venables, “globalization and the inequality of nations,” \\nquarterly journal of economics , november 1995, 110 (4), 857 –880. \\nlileeva, alla and daniel trefler, “improved access to foreign markets raises plant -level \\nproductivity ... for some plants,” quarterly journal of economics , august 2010, cxxv (3), \\n1051 –1100.  \\nlim, kevin, daniel trefler,  and miaojie yu, “trade and innovation: the role of scale and \\ncompetition effects,” working paper, university of toronto, january 2017.  \\nmclaren, john, “ ‘c=globalization’ and vertical structure,’ american economic review , \\ndecember 2000, 90  (5), 1239 –1254.   \\nmanasse, paolo and alessandro turrini, “trade, wages, and s uperstars,” journal of \\ninternational economics , 2001, 54 (1), 97 –117. \\nmarkusen, james r., “trade and the gains from trade with imperfect competition,” journal \\nof international economics , november 1981, 11 (4), 531– 551. ',\n",
       " ' \\n \\n 31 marx, m ., and l. fleming. “non -compete agreements: barriers to entry…and exit?” in j. lerner \\nand s. stern, eds., innovation policy and the economy  12. (2012).  \\nmayer, wolfgang, “short -run and long -run equilibrium for a small open economy,” \\njournal of political economy , september -october 1974, 82 (5), 955– 967.   \\nmelitz, marc j., “the impact of trade on intra -industry reallocations and aggregate industry \\nproductivit y,” econometrica , november 2003, 71  (6), 1695 –1725  \\nmiller, a. r. and c. tucker . 2011. can healthcare it save babies?  journal of political economy . \\n119(2), 289- 332. \\nmussa, michael l., “tariffs and the distribution of income: the importance of factor \\nspecificity, substitutability, and intensity in the short and long run,” journal of political \\neconomy , november -december 1974, 82 (6), 1191 –1203.  \\noberfield, ezra, “ a theor y of input -output architecture ,” econometrica , forthcoming.  \\nporter, michael e., “the competitive advantage of nations,” harvard business review , \\nmarch - april 1990, 68 (2), 73 –93. \\nrauch, james e., “networks versus markets in international trade,” journal of  international \\neconomics , 1999, 48  (1), 7 –35. \\nrivera -batiz, luis a. and paul m. romer, “economic integration and endogenous growth,” \\nquarterly journal of economics , may 1991, 106 (2), 531 –555.  \\nromer, paul m., “endogenous technological change,” journal of political economy , \\noctober 1990, 98 (5), s71 –102.  \\nrosen, sherwin. \"the economics of superstars.\"  the american economic review  71, no. 5 \\n(1981): 845- 58.  \\nruffin, roy j. and ronald w.  jones, “protection and real wages:  the neoclassical   \\nambiguity,” journal of economic theory , april 1977, 14 (2), 337 –348.  \\nsaxenian, annalee, regional advantage culture and competition in silicon valley and route \\n128, cambridge:  ma:  harvard university press, 1994.  \\nsimcoe,  timothy,  “standard  setting  committees:  consensu s governance  for shared  technology  \\nplatforms,”  american  economic  review , 2012, 102 (1), 305–36. \\nuyarra, elvira and ronnie ramlogan, “the effects of cluster policy on innovation \\ncompendium of evidence on the effectiveness of innovation policy intervention,” technical \\nreport, manchester institute of innovation research manchester business school, march    \\n2012.  ',\n",
       " 'what ai can and can’t do \\n(yet) for your business\\nartificial intelligence is a moving target. here’s how to take  \\nbetter aim.  \\nby michael chui, james manyika, and mehdi miremadi\\nartificial intelligence (ai)  seems to be everywhere. we experience it at \\nhome and on our phones. before we know it—if entrepreneurs and business \\ninnovators are to be believed—ai will be in just about every product and \\nservice we buy and use. in addition, its application to business problem solving \\nis growing in leaps and bounds. and at the same time, concerns about ai’s \\nimplications are rising: we worry about the impact of ai-enabled automation \\non the workplace, employment, and society. \\na reality sometimes lost amid both the fears and the headline triumphs, such \\nas alexa, siri, and alphago, is that the ai technologies themselves—namely, \\nmachine learning and its subset, deep learning—have plenty of limitations \\nthat will still require considerable effort to overcome. this is an article about \\nthose limitations, aimed at helping executives better understand what may be \\nholding back their ai efforts. along the way, we will also highlight promising \\nadvances that are poised to address some of the limitations and create a new \\nwave of opportunities. \\nour perspectives rest on a combination of work at the front lines—researching, \\nanalyzing, and assessing hundreds of real-world use cases—and our \\ncollaborations with some of the thought leaders, pioneering scientists, january 2018',\n",
       " ' 2and engineers working at the frontiers of ai. we’ve sought to distill this \\nexperience to help executives who often, in our experience, are exposed only \\nto their own initiatives and not well calibrated as to where the frontier is or \\nwhat the pace setters are already doing with ai.  \\nsimply put, ai’s challenges and limitations are creating a “moving target” \\nproblem for leaders: it is hard to reach a leading edge that’s always advancing. \\nit is also disappointing when ai efforts run into real-world barriers, which \\ncan lessen the appetite for further investment or encourage a wait-and-see \\nattitude, while others charge ahead. as recent mckinsey global institute \\nresearch indicates, there’s a yawning divide between leaders and laggards in \\nthe application of ai both across and within sectors (exhibit 1). \\nexecutives hoping to narrow the gap must be able to address ai in an \\ninformed way. in other words, they need to understand not just where ai can \\nboost innovation, insight, and decision making; lead to revenue growth; and \\ncapture of efficiencies—but also where ai can’t  yet provide value. what’s \\nmore, they must appreciate the relationship and distinctions between \\nqweb 2017\\nai limitationsexhibit 1 of 2\\nfuture ai demand trajectory, % change in ai spending over next 3 years¹   \\nleading sectors  \\nfalling behind \\ncurrent ai adoption, % of companies²   \\n1estimated average, weighted by company size; demand trajectory based on midpoint of range selected by \\nsurvey respondent.\\n/two.superioradopting 1 or more ai technologies at scale or in business core; weighted by company size.\\nsource: mckinsey global institute ai adoption and use survey; mckinsey global institute analysismedia and \\nentertainmentleaders in the adoption of ai also intend to invest more in the near \\nfuture compared with laggards.\\n0113\\n12\\n11\\n10\\n9\\n8765\\n4\\n3\\n2\\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32high tech and \\ncommunications\\nautomotive \\nand assemblyfinancial \\nservices\\nenergy and \\nresourcestransportation \\nand logistics\\nconsumer \\nand packaged \\ngoods\\nbuilding materials \\nand constructionprofessional \\nservicestravel and \\ntourism\\nretail\\neducationhealthcareexhibit 1',\n",
       " ' 3technical constraints and organizational ones, such as cultural barriers; \\na dearth of personnel capable of building business-ready, ai-powered \\napplications; and the “last mile” challenge of embedding ai in products \\nand processes. if you want to become a leader who understands some of \\nthe critical technical challenges slowing ai’s advance and is prepared to \\nexploit promising developments that could overcome those limitations and \\npotentially bend the trajectory of ai—read on.\\nchallenges, limitations, and opportunities\\na useful starting point is to understand recent advances in deep-learning \\ntechniques. arguably the most exciting developments in ai, these advances \\nare delivering jumps in the accuracy of classification and prediction, and are \\ndoing so without the usual “feature engineering” associated with traditional \\nsupervised learning. deep learning uses large-scale neural networks that \\ncan contain millions of simulated “neurons” structured in layers. the most \\ncommon networks are called convolutional neural networks (cnns) and \\nrecurrent neural networks (rnns). these neural networks learn through \\nthe use of training data and backpropagation algorithms. \\nwhile much progress has been made, more still needs to be done.1 a critical \\nstep is to fit the ai approach to the problem and the availability of data. since \\nthese systems are “trained” rather than programmed, the various processes \\noften require huge amounts of labeled data to perform complex tasks \\naccurately. obtaining large data sets can be difficult. in some domains, they \\nmay simply not be available, but even when available, the labeling efforts can \\nrequire enormous human resources. \\nfurther, it can be difficult to discern how a mathematical model trained \\nby deep learning arrives at a particular prediction, recommendation, or \\ndecision. a black box, even one that does what it’s supposed to, may have \\nlimited utility, especially where the predictions or decisions impact society \\nand hold ramifications that can affect individual well-being. in such cases, \\nusers sometimes need to know the “whys” behind the workings, such as why \\nan algorithm reached its recommendations—from making factual findings \\nwith legal repercussions to arriving at business decisions, such as lending, \\nthat have regulatory repercussions—and why certain factors (and not others) \\nwere so critical in a given instance. \\n1  stuart russel et al., “research priorities for robust and beneficial artificial intelligence,”  ai magazine , winter 2015, \\naaai.org. ',\n",
       " ' 4let’s explore five interconnected ways in which these limitations, and the \\nsolutions emerging to address them, are starting to play out. \\nlimitation 1: data labeling \\nmost current ai models are trained through “supervised learning.” this \\nmeans that humans must label and categorize the underlying data, which can \\nbe a sizable and error-prone chore. for example, companies developing self-\\ndriving-car technologies are hiring hundreds of people to manually annotate \\nhours of video feeds from prototype vehicles to help train these systems. at \\nthe same time, promising new techniques are emerging, such as in-stream \\nsupervision (demonstrated by eric horvitz and his colleagues at microsoft \\nresearch), in which data can be labeled in the course of natural usage.2 \\nunsupervised or semisupervised approaches reduce the need for large, \\nlabeled data sets. two promising techniques are reinforcement learning and \\ngenerative adversarial networks.\\nreinforcement learning.  this unsupervised technique allows algorithms to \\nlearn tasks simply by trial and error. the methodology hearkens to a “carrot \\nand stick” approach: for every attempt an algorithm makes at performing \\na task, it receives a “reward” (such as a higher score) if the behavior is \\nsuccessful or a “punishment” if it isn’t. with repetition, performance \\nimproves, in many cases surpassing human capabilities—so long as the \\nlearning environment is representative of the real world.\\nreinforcement learning has famously been used in training computers to \\nplay games—most recently, in conjunction with deep-learning techniques. \\nin may 2017, for example, it helped the ai system alphago to defeat world \\nchampion ke jie in the game of go. in another example, microsoft has \\nfielded decision services that draw on reinforcement learning and adapt \\nto user preferences. the potential application of reinforcement learning \\ncuts across many business arenas. possibilities include an ai-driven \\ntrading portfolio that acquires or loses points for gains or losses in value, \\nrespectively; a product-recommendation engine that receives points for \\nevery recommendation-driven sale; and truck-routing software that receives \\na reward for on-time deliveries or reducing fuel consumption. \\nreinforcement learning can also help ai transcend the natural and social \\nlimitations of human labeling by developing previously unimagined \\nsolutions and strategies that even seasoned practitioners might never have \\n2  eric horvitz, “machine learning, reasoning, and intelligence in daily life: directions and challenges,” proceedings of \\nartificial intelligence techniques for ambient intelligence , hyderabad, india, january 2007.',\n",
       " ' 5considered. recently, for example, the system alphago zero, using a novel \\nform of reinforcement learning, defeated its predecessor alphago after \\nlearning to play go from scratch. that meant starting with completely \\nrandom play against itself rather than training on go games played by and \\nwith humans.3\\ngenerative adversarial networks (gans).  in this semisupervised learning \\nmethod, two networks compete against each other to improve and refine \\ntheir understanding of a concept. to recognize what birds look like, for \\nexample, one network attempts to distinguish between genuine and fake \\nimages of birds, and its opposing network attempts to trick it by producing \\nwhat look very much like images of birds, but aren’t. as the two networks \\nsquare off, each model’s representation of a bird becomes more accurate. \\nthe ability of gans to generate increasingly believable examples of data \\ncan significantly reduce the need for data sets labeled by humans. training \\nan algorithm to identify different types of tumors from medical images, \\nfor example, would typically require millions of human-labeled images \\nwith the type or stage of a given tumor. by using a gan trained to generate \\nincreasingly realistic images of different types of tumors, researchers could \\ntrain a tumor-detection algorithm that combines a much smaller human-\\nlabeled data set with the gan’s output.\\nwhile the application of gans in precise disease diagnoses is still a way off, \\nresearchers have begun using gans in increasingly sophisticated contexts. \\nthese include understanding and producing artwork in the style of a \\nparticular artist and using satellite imagery, along with an understanding of \\ngeographical features, to create up-to-date maps of rapidly developing areas. \\nlimitation 2: obtaining massive training data sets \\nit has already been shown that simple ai techniques using linear models \\ncan, in some cases, approximate the power of experts in medicine and \\nother fields.4 the current wave of machine learning, however, requires \\ntraining data sets that are not only labeled but also sufficiently large and \\ncomprehensive. deep-learning methods call for thousands of data records \\nfor models to become relatively good at classification tasks and, in some \\ncases, millions for them to perform at the level of humans.5\\n3  demis hassabis et al., alphago zero: learning from scratch , deepmind.com.\\n4  robyn m. dawes, “the robust beauty of improper linear models in decision making,” american psychologist , \\n1979, volume 34, number 7, pp. 571–82.\\n5  ian goodfellow, yoshua bengio, and aaron courville,  deep learning , cambridge, ma: mit press, 2016.',\n",
       " ' 6the complication is that massive data sets can be difficult to obtain or create \\nfor many business use cases (think: limited clinical-trial data to predict \\ntreatment outcomes more accurately). and each minor variation in an \\nassigned task could require another large data set to conduct even more  \\ntraining. for example, teaching an autonomous vehicle to navigate a mining \\nsite where the weather continually changes will require a data set that \\nencompasses the different environmental conditions the vehicle might encounter. \\none-shot learning is a technique that could reduce the need for large data \\nsets, allowing an ai model to learn about a subject when it’s given a small \\nnumber of real-world demonstrations or examples (even one, in some cases). \\nai’s capabilities will move closer to those of humans, who can recognize \\nmultiple instances of a category relatively accurately after having been \\nshown just a single sample—for example, of a pickup truck. in this still-\\ndeveloping methodology, data scientists would first pre-train a model in \\na simulated virtual environment that presents variants of a task or, in the \\ncase of image recognition, of what an object looks like. then, after being \\nshown just a few real-world variations that the ai model did not see in virtual \\ntraining, the model would draw on its knowledge to reach the right solution.6\\nthis sort of one-shot learning could eventually help power a system to scan \\ntexts for copyright violations or to identify a corporate logo in a video after \\nbeing shown just one labeled example. today, such applications are only in \\ntheir early stages. but their utility and efficiency may well expand the use of \\nai quickly, across multiple industries. \\nlimitation 3: the explainability problem\\nexplainability is not a new issue for ai systems.7 but it has grown along with \\nthe success and adoption of deep learning, which has given rise both to more \\ndiverse and advanced applications and to more opaqueness. larger and more \\ncomplex models make it hard to explain, in human terms, why a certain \\ndecision was reached (and even harder when it was reached in real time). \\nthis is one reason that adoption of some ai tools remains low in application \\nareas where explainability is useful or indeed required. furthermore, as the \\napplication of ai expands, regulatory requirements could also drive the need \\nfor more explainable ai models.8\\n6  yan duan et al.,  one-shot imitation learning , december 2017, arxiv.org.\\n7  eric horvitz et al., “the use of a heuristic problem-solving hierarchy to facilitate the explanation of hypothesis-\\ndirected reasoning,” proceedings of medinfo , october 1986, pp. 27–31.\\n8  see, for example, the european union’s proposed general data protection regulation, which would introduce  \\nnew requirements for the use of data.',\n",
       " ' 7two nascent approaches that hold promise for increasing model \\ntransparency are local-interpretable-model-agnostic explanations (lime) \\nand attention techniques (exhibit 2). lime attempts to identify which \\nparts of input data a trained model relies on most to make predictions in \\ndeveloping a proxy interpretable model. this technique considers certain \\nsegments of data at a time and observes the resulting changes in prediction \\nto fine-tune the proxy model and develop a more refined interpretation (for \\nexample, by excluding eyes rather than, say, noses to test which are more \\nimportant for facial recognition). attention techniques visualize those \\npieces of input data that a model considers most as it makes a particular \\ndecision (such as focusing on a mouth to determine if an image depicts a \\nhuman being).\\nanother technique that has been used for some time is the application of \\ngeneralized additive models (gams). by using single-feature models, gams \\nlimit interactions between features, thereby making each one more easily exhibit 2qweb 2017\\nai limitationsexhibit 2 of 2\\nturning off all but \\na few interpretable components of this image reveals the probability that the model will identify …\\nwords relevant to food quality …\\n… or to service is a sensitivity analysis that reveals which parts of an input matter most \\nto the eventual output.\\n… a tree frog\\n54%… billiard balls\\n7%… a balloon\\n5%\\nshines a spotlight on where the model is looking when it makes \\na particular decision. attention\\n/one.superiorlime  = local-interpretable-model-agnostic explanations.\\nsource: carlos guestrin, marco tulio ribeiro, and sameer singh, “introduction to local interpretable model-agnostic explanations (lime),” august 12, 2016 , \\no’reilly, oreilly.com; minlie huang, yequan wang, li zhao, and xiaoyan zhu, attention-based lstm for aspect-level sentiment classiﬁcation, tsinghua \\nuniversity; pixabay\\nthey have one of the fastest delivery times in the city.new techniques hold promise for making ai more transparent.\\nthe fajita we tried was tasteless and burned and the mole sauce was way too sweet.',\n",
       " ' 8interpretable by users.9 employing these techniques, among others, to \\ndemystify ai decisions is expected to go a long way toward increasing the \\nadoption of ai. \\nlimitation 4: generalizability of learning\\nunlike the way humans learn, ai models have difficulty carrying their \\nexperiences from one set of circumstances to another. in effect, whatever a \\nmodel has achieved for a given use case remains applicable to that use case \\nonly. as a result, companies must repeatedly commit resources to train yet \\nanother model, even when the use cases are very similar. \\none promising response to this challenge is transfer learning.10 in this \\napproach, an ai model is trained to accomplish a certain task and then \\nquickly applies that learning to a similar but distinct activity. deepmind \\nresearchers have also shown promising results with transfer learning in \\nexperiments in which training done in simulation is then transferred to real \\nrobotic arms.11\\nas transfer learning and other generalized approaches mature, they could \\nhelp organizations build new applications more quickly and imbue existing \\napplications with more diverse functionality. in creating a virtual personal \\nassistant, for example, transfer learning could generalize user preferences \\nin one area (such as music) to others (books). and users are not restricted \\nto digital natives. transfer learning can enable an oil-and-gas producer, for \\ninstance, to expand its use of ai algorithms trained to provide predictive \\nmaintenance for wells to other equipment, such as pipelines and drilling \\nplatforms. transfer learning even has the potential to revolutionize business \\nintelligence: consider a data-analyzing ai tool that understands how to \\noptimize airline revenues and can then adapt its model to changes in weather \\nor local economics. \\nanother approach is the use of something approximating a generalized \\nstructure that can be applied in multiple problems. deepmind’s alphazero, \\nfor example, has made use of the same structure for three different games: it \\nhas been possible to train a new model with that generalized structure  \\n  9  yin lou, rich caruana, and johannes gehrke, “intelligible models for classification and regression,” proceedings \\nof the 18th acm sigkdd international conference on knowledge discovery and data mining,  new york: acm, \\n2012, pp. 150–58. \\n10  for an earlier example application, see john guttag, eric horvitz, and jenna wiens, “a study in transfer learning: \\nleveraging data from multiple hospitals to enhance hospital-specific predictions,” journal of the american \\nmedical informatics association , 2014, volume 21, number 4, pp. 699–706.\\n 11  andrei a. rusu et al., sim-to-real robot learning from pixels with progressive nets , october 2016, arxiv.org.',\n",
       " ' 9to learn chess in a single day, and it then soundly beat a world-champion \\nchess program.12\\nfinally, consider the possibilities in emerging meta-learning techniques that \\nattempt to automate the design of machine-learning models. the google \\nbrain team, for example, uses automl to automate the design of neural \\nnetworks for classifying images in large-scale data sets. these techniques \\nnow perform as well as those designed by humans.13 that’s a promising \\ndevelopment, particularly as talent continues to be in short supply for many \\norganizations. it’s also possible that meta-learning approaches will surpass \\nhuman capabilities and yield even better results. importantly, however, \\nthese techniques are still in their early days. \\nlimitation 5: bias in data and algorithms \\nso far, we’ve focused on limitations that could be overcome through \\ntechnical solutions already in the works, some of which we have described. \\nbias is a different kind of challenge. potentially devastating social \\nrepercussions can arise when human predilections (conscious or unaware) \\nare brought to bear in choosing which data points to use and which to \\ndisregard. furthermore, when the process and frequency of data collection \\nitself are uneven across groups and observed behaviors, it’s easy for problems \\nto arise in how algorithms analyze that data, learn, and make predictions.14 \\nnegative consequences can include misinformed recruiting decisions, \\nmisrepresented scientific or medical prognoses, distorted financial models \\nand criminal-justice decisions, and misapplied (virtual) fingers on legal \\nscales.15 in many cases, these biases go unrecognized or disregarded under \\nthe veil of “advanced data sciences,” “proprietary data and algorithms,” or \\n“objective analysis.” \\nas we deploy machine learning and ai algorithms in new areas, there \\nprobably will be more instances in which these issues of potential bias \\nbecome baked into data sets and algorithms. such biases have a tendency \\nto stay embedded because recognizing them, and taking steps to address \\nthem, requires a deep mastery of data-science techniques, as well as a more \\nmeta-understanding of existing social forces, including data collection. in all, \\n12  david silver et al., mastering chess and shogi by self-play with a general reinforcement learning algorithm , \\ndecember 2017, arxiv.org.\\n13  google research blog , “automl for large scale image classification and object detection,” blog entry by barret \\nzoph, vijay vasudevan, jonathon shlens, and quoc le, november 2, 2017, research.googleblog.com.\\n14  jon kleinberg, sendhil mullainathan, and manish raghavan, inherent trade-offs in the fair determination of risk \\nscores , november 2016, arxiv.org.\\n15  see the work of julia angwin, jeff larson, surya mattu, lauren kirchner, and terry parris jr. of propublica.',\n",
       " ' 10debiasing is proving to be among the most daunting obstacles, and certainly \\nthe most socially fraught, to date. \\nthere are now multiple research efforts under way, as well as efforts to \\ncapture best practices, that address these issues in academic, nonprofit, \\nand private-sector research. it’s none too soon, because the challenge is \\nlikely to become even more critical, and more questions will arise. consider, \\nfor example, the fact that many of these learning and statistically based \\npredictive approaches implicitly assume that the future will be like the past. \\nwhat should we do in sociocultural settings where efforts are under way to \\nspur change—and where making decisions based on past behavior could \\ninhibit progress (or, worse, build in resistance to change)? a wide variety  \\nof leaders, including business leaders, may soon be called upon to answer \\nsuch questions.\\nhitting the moving target\\nsolutions to the limitations we have described, along with the widespread \\ncommercial implementation of many of the advances described here, could \\nbe years away. but the breathtaking range of possibilities from ai adoption \\nsuggests that the greatest constraint for ai may be imagination. here are a \\nfew suggestions for leaders striving to stay ahead of—or at least not fall too far \\nbehind—the curve:\\ndo your homework, get calibrated, and keep up. while most executives \\nwon’t need to know the difference between convolutional and recurrent \\nneural networks, you should have a general familiarity with the capabilities \\nof today’s tools, a sense of where short-term advances are likely to occur, and \\na perspective on what’s further beyond the horizon. tap your data-science \\nand machine-learning experts for their knowledge, talk to some ai pioneers \\nto get calibrated, and attend an ai conference or two to help you get the \\nreal facts; news outlets can be helpful, but they can also be part of the hype \\nmachine. ongoing tracking studies by knowledgeable practitioners, such as \\nthe ai index (a project of the stanford-based one hundred year study on \\nartificial intelligence), are another helpful way to keep up.16\\nadopt a sophisticated data strategy. ai algorithms need assistance to unlock \\nthe valuable insights lurking in the data your systems generate. you can help \\nby developing a comprehensive data strategy that focuses not only on the \\ntechnology required to pool data from disparate systems but also on data \\navailability and acquisition, data labeling, and data governance. although \\nnewer techniques promise to reduce the amount of data required for training \\n16  see the ai index (aiindex.org) and the one hundred year study (ai100.stanford.edu).',\n",
       " ' 11ai algorithms, data-hungry supervised learning remains the most prevalent \\ntechnique today. and even techniques that aim to minimize the amount of \\ndata required still need some  data. so a key part of this is fully knowing your \\nown data points and how to leverage them. \\nthink laterally. transfer-learning techniques remain in their infancy, but \\nthere are ways to leverage an ai solution in more than one area. if you solve \\na problem such as predictive maintenance for large warehouse equipment, \\ncan you also apply the same solution to consumer products? can an effective \\nnext-product-to-buy solution be used in more than one distribution channel? \\nencourage business units to share knowledge that may reveal ways to use \\nyour best ai solutions and thinking in more than one area of the company. \\nbe a trailblazer. keeping up with today’s ai technologies and use cases is not \\nenough to remain competitive for the long haul. engage your data-science \\nstaff or partner with outside experts to solve a high-impact use case with \\nnascent techniques, such as the ones discussed in this article, that are poised \\nfor a breakthrough. further, stay informed about what’s possible and what’s \\navailable. many machine-learning tools, data sets, and trained models for \\nstandard applications (including speech, vision, and emotion detection) are \\nbeing made widely available. sometimes they come in open source and in \\nother cases through application programming interfaces (apis) created by \\npioneering researchers and companies. keep an eye on such possibilities to \\nboost your odds of staking out a first-mover or early-adopter advantage. \\nthe promise of ai is immense, and the technologies, tools, and processes \\nneeded to fulfill that promise haven’t fully arrived. if you think you can let \\nthe technology develop and then be a successful fast follower, think again. it’s \\nvery difficult to leapfrog from a standing start, particularly when the target \\nis moving so rapidly and you don’t understand what ai tools can and can’t \\ndo now. with researchers and ai pioneers poised to solve some of today’s \\nthorniest problems, it’s time to start understanding what is happening a t  \\nthe ai frontier so you can position your organization to learn, exploit, and \\nmaybe even advance the new possibilities. \\nmichael chui is a partner of the mckinsey global institute (mgi) and is based in mckinsey’s \\nsan francisco office; james m anyika i s the chairman of mgi and a senior partner in the san \\nfrancisco office; and m ehdi miremadi i s a partner in the chicago office.\\nthe authors wish to thank jack clark at openai, jeffrey dean at google brain, professor \\nbarbara grosz at harvard university, demis hassabis at deepmind, eric horvitz at microsoft \\nresearch, and martin wicke for their insights on the ideas in this article. they also wish to \\nthank their mckinsey colleagues steven adler, ali akhtar, adib ayay, ira chadha, rita chung, \\nnicolaus henke, sankalp malhotra, and pieter nel for their contributions to this article.\\ncopyright © 2018 mckinsey & company.  all rights reserved.',\n",
       " 'advanced review\\ncausability and explainability of artificial intelligence in medicine\\nandreas holzinger1| georg langs2| helmut denk3| kurt zatloukal3| heimo müller1,3\\n1institute for medical informatics, statistics and\\ndocumentation, medical university graz, graz,\\naustria\\n2department of biomedical imaging and image-\\nguided therapy, computational imaging research\\nlab, medical university of vienna, vienna,\\naustria\\n3institute of pathology, medical university graz,\\ngraz, austria\\ncorrespondence\\nandreas holzinger, institute for medical\\ninformatics, statistics and documentation,\\nmedical university graz, a-8036, austria.\\nemail: andreas.holzinger@medunigraz.at\\nfunding information\\nfeaturecloud, grant/award number: 826078\\nh2020 eu project; hochschulraum-\\ninfrastrukturmittelfonds; mefo, grant/awardnumber: mefo-graz; this work was partially\\nsupported by the austrian science fund fwf\\n(i2714-b31) and the eu under h2020 (765148)\\n[correction added on 11 june 2019, after first\\nonline publication: “explainabilty ”has been\\ncorrected to “explainability ”in the article title.]explainable artificial intelligence (ai) is attracting much interest in medicine.\\ntechnically, the problem of explainability is as old as ai itself and classic ai repre-sented comprehensible retraceable approaches. however, their weakness was in\\ndealing with uncertainties of the real world. through the introduction of probabilis-\\ntic learning, applications became increasingly successful, but increasingly opaque.explainable ai deals with the implementation of transparency and traceability of\\nstatistical black-box machine learning methods, particularly deep learning (dl).\\nwe argue that there is a need to go beyond explainable ai. to reach a level ofexplainable medicine we need causability. in the same way that usability encom-\\npasses measurements for the quality of use, causability encompasses measurements\\nfor the quality of explanations. in this article, we provide some necessary defini-tions to discriminate between explainability and causability as well as a use-case of\\ndl interpretation and of human explanation in histopathology. the main contribu-\\ntion of this article is the notion of causability, which is differentiated from explain-ability in that causability is a property of a person, while explainability is aproperty of a system\\nthis article is categorized under:\\nfundamental concepts of data and knowledge > human centricity and user\\ninteraction\\nkeywords\\nartificial intelligence, causability, explainability, explainable ai, histopathology,medicine\\n1|introduction and motivation\\nartificial intelligence (ai) is perhaps the oldest field of computer science and very broad, dealing with all aspects of mimick-\\ning cognitive functions for real-world problem solving and building systems that learn and think like people. therefore, it isoften called machine intelligence (poole, mackworth, & goebel, 1998) to contrast it to human intelligence (russell & norvig,2010). the field revolved around the intersection of cognitive science and computer science (tenenbaum, kemp, griffiths, &goodman, 2011). ai now raises enormous interest due to the practical successes in machine learning (ml). in ai there wasalways a strong linkage to explainability, and an early example is the advice taker proposed by mccarthy in 1958 as a “pro-\\ngram with common sense ”(mccarthy, 1960). it was probably the first time proposing common sense reasoning abilities as\\nthekeyto ai. recent research emphasizes more and more that ai systems should be able to build causal models of the world\\nthat support explanation and understanding, rather than merely solving pattern recognition problems (lake, ullman, tenen-baum, & gershman, 2017).received: 19 november 2018 revised: 26 january 2019 accepted: 24 february 2019\\ndoi: 10.1002/widm.1312\\nthis is an open access article under the terms of the creative commons attribution license, which permits use, distribution and reproduction in any me dium,\\nprovided the original work is properly cited.\\n© 2019 the authors. wires data mining and knowledge discovery published by wiley periodicals, inc.\\nwires data mining knowl discov. 2019;9:e1312. wires.wiley.com/dmkd 1o f1 3\\nhttps://doi.org/10.1002/widm.1312\\n',\n",
       " \"ml is a very practical field of ai with the aim to develop software that can automatically learn from previous data to gain\\nknowledge from experience and to gradually improve it's learning behavior to make predictions based on new data\\n(michalski, carbonell, & mitchell, 1984). the grand challenges are in sense-making, in context understanding, and in decision\\nmaking under uncertainty (holzinger, 2017). ml can be seen as the workhorse of ai and the adoption of data intensive mlmethods can meanwhile be found everywhere, throughout science, engineering and business, leading to more evidence-based\\ndecision-making (jordan & mitchell, 2015). the enormous progress in ml has been driven by the development of new statis-\\ntical learning algorithms along with the availability of large data sets and low-cost computation (abadi et al., 2016). one now-\\nadays extremely popular method is deep learning (dl).\\ndl is a family of ml models based on deep convolutional neural networks having a long history (schmidhuber, 2015).\\ndl is very popular today because they are achieving amazing results even at human level performance (lecun, bengio, &\\nhinton, 2015). a best practice example is a recent work of the thrun group, where they achieved with a dl approach perfor-mance on par with medical doctors, demonstrating that such approaches are able to classify skin cancer with a level of compe-\\ntence comparable to human dermatologists (esteva et al., 2017). a further example is the promising results of identifying\\ndiabetic retinopathy and related eye diseases (ting et al., 2017). all these are very good examples of the progress and useful-ness of ai, but even the most prominent proponents of these (automatic) approaches recently emphasize that usable intelli-\\ngence is difficult to reach because we need not only to learn from prior data, to extract knowledge, to generalize, and to fight\\nthe curse of dimensionality, but to disentangle the underlying explanatory factors of the data in order to understand the contextin an application domain (bengio, courville, & vincent, 2013), where to date a doctor-in-the-loop is indispensable\\n(holzinger, 2016).\\nmedicine as application domain is among the greatest challenges of ai/ml/dl. in medical decision support we are con-\\nfronted with uncertainty, with probabilistic, unknown, incomplete, imbalanced, heterogeneous, noisy, dirty, erroneous, inaccu-\\nrate and missing data sets in arbitrarily high-dimensional spaces (holzinger, dehmer, & jurisica, 2014), (lee & holzinger,2016). often we are simply lacking of large data sets (holzinger, 2016). a grand goal of future medicine is in modeling the\\ncomplexity of patients to tailor medical decisions, health practices and therapies to the individual patient (holzinger, 2014).\\nthis poses challenges particularly in the integration, fusion and mapping of various distributed and heterogeneous data up tothe visual analysis of these heterogeneous data (turkay, jeanquartier, holzinger, & hauser, 2014). consequently, explain-\\nable-ai in the context of medicine must take into account that diverse data may contribute to a relevant result. this requires\\nthat medical professionals must have a possibility to understand how and why a machine decision has been made (holzinger,\\nbiemann, pattichis, & kell, 2017).\\nexplainability is at least as old as ai itself and rather a problem that has been caused by it. in the pioneering days of ai\\n(newell, shaw, & simon, 1958), reasoning methods were logical and symbolic. these approaches were successful, but only\\nin a very limited domain space and with extremely limited practical applicability. a typical example is mycin (shortliffe &buchanan, 1975), which was an expert system developed in lisp to identify bacteria causing severe infections and to recom-\\nmend antibiotics. mycin was never used in clinical routine, maybe because of its stand-alone character and the high effort in\\nmaintaining its knowledge base. however, these early ai systems reasoned by performing some form of logical inference onhuman readable symbols, and were able to provide a trace of their inference steps. this was the basis for explanation, and\\nthere is some early related work available, for example, (johnson, 1994; lacave & diez, 2002; swartout, paris, & moore,\\n1991). here, we should mention that there are three types of explanations: (1) a peer-to-peer explanation as it is carried outamong physicians during medical reporting; (2) an educational explanation as it is carried out between teachers and students;\\n(3) a scientific explanation in the strict sense of science theory (popper, 1935). we emphasize that in this article we mean the\\nfirst type of explanation.\\nin medicine there is growing demand for ai approaches, which are not only performing well, but are trustworthy, transpar-\\nent, interpretable and explainable for a human expert; in medicine, for example, sentences of natural language (hudec, bed-nrov, & holzinger, 2018). methods and models are necessary to reenact the machine decision-making process, to reproduce\\nand to comprehend both the learning and knowledge extraction process. this is important, because for decision support it is\\nnecessary to understand the causality of learned representations (gershman, horvitz, & tenenbaum, 2015; pearl, 2009;\\npeters, janzing, & schölkopf, 2017).\\nmoreover, explainability of ai could help to enhance trust of medical professionals in future ai systems. research\\ntowards building explainable-ai systems for application in medicine requires to maintain a high level of learning performance\\nfor a range of ml and human-computer interaction techniques. there is an inherent tension between ml performance (predic-tive accuracy) and explainability. often the best-performing methods such as dl are the least transparent, and the ones provid-\\ning a clear explanation (e.g., decision trees) are less accurate (bologna & hayashi, 2017).\\ncurrently, explanations of why predictions are made, or how model parameters capture underlying biological mechanisms\\nare elusive. a further constraint is that humans are limited to visual assessment or review of explanations for a (large) number2o f1 3 holzinger et al .\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n\",\n",
       " \"of axioms. this result in one of the main question: can we deduce properties without experiments —directly from pure obser-\\nvations? (peters et al., 2017).\\nunderstanding, interpreting, or explaining are often used synonymously in the context of explainable-ai (doran, schulz, &\\nbesold, 2017), and various techniques of interpretation have been applied in the past. there is a helpful discussion on the“myth of model interpretability ”by lipton (2016). in the context of explainable-ai the term “understanding ”usually means a\\nfunctional understanding of the model, in contrast to a low-level algorithmic understanding of it, that is, to seek to characterize\\nthe model's black-box behavior, without trying to elucidate its inner workings or its internal representations. montavon,samek, and müller (2017) discriminate in their work between interpretation , which they define as a mapping of an abstract\\nconcept into a domain that the human expert can perceive and comprehend; and explanation , which they define as a collection\\nof features of the interpretable domain, that have contributed to a given example to produce a decision.\\nwe argue that in medicine explainable ai is urgently needed for many purposes including medical education, research and\\nclinical decision making (holzinger, 2018). if medical professionals are complemented by sophisticated ai systems and insome cases future ai systems even play a huge part in the decision making process, human experts must still have themeans —on demand —to understand and to retrace the machine decision process.\\nat the same time, it is interesting to know that while it is often assumed that humans are always able to explain their deci-\\nsions, this is often notthe case! sometimes experts are not able to provide an explanation based on the various heterogeneous\\nand vast sources of different information. consequently, explainable-ai calls for confidence, safety, security, privacy, ethics,fairness and trust (kieseberg, weippl, & holzinger, 2016), and brings usability (holzinger, 2005) and human-ai interaction\\ninto a new and important focus (miller, howe, & sonenberg, 2017). all these aspects together are crucial for applicability inmedicine generally, and for future personalized medicine, in particular (hamburg & collins, 2010).\\nfirst we provide some definitions to explain what kind of explainability we mean —this will lead us to the term “causabil-\\nity”in contrast to the well-known term “causality ”; then we discuss briefly the state-of-the-art of some current explainable\\nmodels, and continue with an example and a medical use-case from histopathology. we conclude with pointing to the urgentneed of a systems causability scale to measure the quality of an explanation (hoffman, mueller, klein, & litman, 2018),which must also include social aspects of human communication (miller, 2019).\\n2|from explainability to causability\\nin an ideal world both human and machine statements would be identical, and congruent with the ground truth, which is\\ndefined for machines and humans equally. however, in the real world we face two problems:\\n(i) ground truth cannot always be well defined, especially when making a medical diagnosis.\\n(ii) human (scientific) models are often based on causality as an ultimate aim for understanding underlying mechanisms,\\nand while correlation is accepted as a basis for decisions, it is viewed as an intermediate step. in contrast today's successfulml algorithms are typically based on probabilistic models and provide only a crude basis for further establishing causalmodels. when discussing the explainability of a machine statement, we therefore propose to distinguish between:\\nexplainability in a technical sense highlights decision-relevant parts of the used representations of the algorithms and active parts in the algori thmic model, that\\neither contribute to the model accuracy on the training set, or to a specific prediction for one particular observation. it does not refer to anexplicit human model.\\ncausability as the extent to which an explanation of a statement to a human expert achieves a specified level of causal understanding with effectivene ss,\\nefficiency and satisfaction in a specified context of use.\\nas causability is measured in terms of effectiveness, efficiency, satisfaction related to causal understanding and its trans-\\nparency for a user, it refers to a human understandable model. this is always possible for an explanation of a human state-ment, as the explanation is per se defined related to a human model. however, to measure the causability of an explanation ofa machine statement this has to be based on a causal model, which is not the case for most ml algorithms, or a mappingbetween both has to be defined.\\nhere, we must distinguish between an explainable model ( “explainable ai ”) and an explanation interface which makes the\\nresults gained in the explainable model not only usable but also useful to the expert. as a measure for the usability of such anhuman-ai interaction interface we propose to use the term causability (see figure 1).\\nthe term ai itself is actually an unfortunate one for engineering, since the phenomenon of intelligence is very difficult to\\ndefine and is dependent on a wealth of different factors; therefore, we limit ourselves here only to explicitly relevant facts forexplainability.holzinger et al . 3o f1 3\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n\",\n",
       " 'understanding is not only recognizing, perceiving and reproducing (stimulus –response on a physiological level), and not only\\nthe content comprehension and mere representation of facts, but the intellectual understanding of the context in which these facts\\nappear. rather, understanding can be seen as a bridge between perceiving and reasoning. from capturing the context, withoutdoubt an important indicator of intelligence, the current state-of-the-art ai is still many miles away. on the other hand, people are\\nvery well able to instantaneously capture the context and make very good generalizations from very few data points.\\nexplaining (interpretation) means to provide causes of observed phenomena in a comprehensible manner through a lin-\\nguistic description of its logical and causal relationships. in the theory of science, according to the hypothetical-deductivemodel of karl popper, causal explanations are the foundation of science in order to derive facts from laws and conditions in a\\ndeductive way. consequently, causality and causal reasoning is an extremely important area for explainable ai (pearl & mac-\\nkenzie, 2018). understanding and explaining are prerequisites for retraceability. the question remains open: “what is princi-\\npally understandable for a human? ”.\\ndirectly understandable, hence explainable for humans are data, objects or any graphical representations ≤r\\n3, for example,\\nimages (arrays of pixels, glyphs, correlation functions, graphs, 2d/3d projections etc., or text (sequences of natural language).\\nhumans are able to perceive data as images or words and process it as information in a physiological sense, cognitively inter-\\npret the extracted information with reference to their subjective previous knowledge (humans have a lot of prior knowledge)\\nand integrating this new knowledge into their own cognitive knowledge space. strictly speaking, there must be made a distinc-tion between understanding natural images (pictures), understanding text (symbols) and understanding spoken language.\\nnot directly understandable, thus not explainable for humans are abstract vectorspaces > r\\n3(e.g., word-embeddings) or\\nundocumented, that is, previously unknown input features (e.g., sequences of text with unknown symbols (e.g., chinese for\\nan english speaker). an example shall illustrate it: in the so-called word embedding (mikolov, chen, corrado, & dean,2013), words and/or phrases are assigned to vectors. conceptually, this is a mathematical embedding of a space with one\\ndimension per word into a continuous vector space with a reduced dimension. methods to generate such a “mapping ”include,\\nfor example, deep neural nets and probabilistic models with an explicit representation in relation to the context in which the\\nwords appear.\\nfor more details on the theory behind scientific explainability we refer to the principles of abductive reasoning (ma et al.,\\n2010) and point to some current work (babiker & goebel, 2017; goebel et al., 2018).\\n3|general approaches of explainable ai models\\nwe can distinguish two types of explainable ai, which can be denominated with latin names used in law (fellmeth & hor-\\nwitz, 2009): posthoc explainability = “(lat.) after this ”, occurring after the event in question; for example, explaining what the\\nmodel predicts in terms of what is readily interpretable; ante-hoc explainability = “(lat.) before this ”, occurring before the\\nwhy did the algorithm do that?\\ncan i trust these results?\\nhow can i correct an error?\\na possible solution\\nthe domain expert can understand why...\\nthe domain expert can learn and correct errors...\\nthe domain expert can re-enact on demand...explanation\\ninterfaceexplainable\\nmodel\\ninput datainput data\\nvar[at x]= – σ at  xi– – σj=1  x j1\\nn1nnn\\nn=12= atvxxa.\\n= atvxxa.var[at x]= – σ at  xi– – σj=1  x j1\\nn1nnn\\nn=12θ\\nθ\\nfigure 1 the best performing statistical approaches today are black-boxes and do not foster understanding, trust and error correction (above). this implies\\nan urgent need not only for explainable models, but also for explanation interfaces —and as a measure for the human-ai interaction we need the concept of\\ncausability —analogous to usability in classic human-computer interaction4o f1 3 holzinger et al .\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " 'event in question; for example, incorporating explainability directly into the structure of an ai-model, explainability by\\ndesign.\\nposthoc systems aim to provide local explanations for a specific decision and make it reproducible on demand (instead of\\nexplaining the whole systems behavior). a representative example is local interpretable model-agnostic explanations (lime)developed by ribeiro, singh, and guestrin (2016b), which is a model-agnostic system, where x2r\\ndis the original represen-\\ntation of an instance being explained, and x02rd0is used to denote a vector for its interpretable representation (e.g., xmay be\\na feature vector containing word embeddings, with x0being the bag of words). the goal is to identify an interpretable model\\nover the interpretable representation that is locally faithful to the classifier. the explanation model is g:rd0!r,g2g,\\nwhere gis a class of potentially interpretable models, such as linear models, decision trees, or rule lists; given a model g2g,\\nit can be visualized as an explanation to the human expert (for details please refer to (ribeiro, singh, & guestrin, 2016a)).another example for a posthoc system is black box explanations through transparent approximations (beta), a model-agnostic framework for explaining the behavior of any black-box classifier by simultaneously optimizing for fidelity to theoriginal model and interpretability of the explanation introduced by lakkaraju, kamar, caruana, and leskovec (2017).\\nbach et al. (2015) presented a general solution to the problem of understanding classification decisions by pixel-wise\\ndecomposition of nonlinear classifiers which allows visualization of the contributions of single pixels to predictions forkernel-based classifiers over bag of words features and for multilayered neural networks.\\nante-hoc systems are interpretable by design towards glass-box approaches (holzinger et al., 2017, 2018); typical exam-\\nples include linear regression, decision trees and fuzzy inference systems. the latter have a long tradition and can be designedfrom expert knowledge or from data and provides —from the viewpoint of human-ai interaction —a good framework for the\\ninteraction between human expert knowledge and hidden knowledge in the data (guillaume, 2001). a further example waspresented by caruana et al. (2015), where high-performance generalized additive models with pairwise interactions (gams)were applied to problems from the medical domain yielding intelligible models, which uncovered surprising patterns in thedata that previously had prevented complex learned models from being fielded in this domain; of importance is that they dem-onstrated scalability of such methods to large data sets containing hundreds of thousands of patients and thousands of attri-\\nbutes while remaining intelligible and providing accuracy comparable to the best (unintelligible) ml methods. a furtherexample for ante-hoc methods can be seen in poulin et al. (2006), where they described a framework for visually explainingthe decisions of any classifier that is formulated as an additive model and showed how to implement this framework in thecontext of three models: naïve bayes, linear support vector machines and logistic regression, which they implemented success-fully into a bioinformatics application (szafron et al., 2004).\\n3.1 |example: interpreting a deep neural network\\ndeep neural networks (dnn), particularly convolutional neural networks (cnn) and recurrent neural networks (rnn) have\\nbeen demonstrated to be applicable to a wide range of practical problems, from image recognition (simonyan & zisserman,2014) and image classification (esteva et al., 2017) to movement recognition (singh et al., 2017). at the same time these\\napproaches are also remarkable from a scientific point of view, since they reflect human processes. for instance, humans orga-\\nnize their ideas hierarchically (bengio, 2009; schmidhuber, 2015), and recent work has observed evidence about how learnedmodels in cnns are similar to those found in the human visual ventral pathway (khaligh-razavi & kriegeskorte, 2014).since the early phases of research on artificial neural networks, people have tried to make them explainable. one of the earlyapproaches was the approach of gradients in the form of sensitivity analysis (simonyan & zisserman, 2014).\\nan artificial neural network (nn) is a collection of neurons organized in a sequence of multiple layers, where neurons\\nreceive as input the neuron activations from the previous layer, and perform a simple computation (e.g., a weighted sum of the\\ninput followed by a nonlinear activation). the neurons of the network jointly implement a complex nonlinear mapping from\\nthe input to the output. this mapping is learned from the data by adapting the weights of each individual neuron using back-propagation, which repeatedly adjusts the weights of the connections in the network in order to minimize the differencebetween the current output vector and the desired output vector. as a result of the weight adjustments, internal hidden unitswhich are not part of the input or output come to represent important features of the task domain, and the regularities in thetask are captured by the interactions of these units (refer to the original paper of rumelhart, hinton, and williams (1986) andthe review by widrow and lehr (1990) for an overview).\\ntypically, deep neural networks are trained using supervised learning on large and carefully annotated data sets. however,\\nthe need for such data sets restricts the space of problems that can be addressed. on one hand, this has led to a proliferation ofdeep learning results on the same tasks using the same well-known data sets (rolnick, veit, belongie, & shavit, 2017). onthe other hand, to the emerging relevance of weakly- and un-supervised approaches that aim at reducing the need for annota-tions (schlegl, seeböck, waldstein, schmidt-erfurth, & langs, 2017; seeböck et al., 2018).holzinger et al . 5o f1 3\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " \"several approaches to probe and interpret deep neural networks exist (kendall & gal, 2017). uncertainty provides a mea-\\nsure of how small perturbations of training data would change model parameters, the so-called model uncertainty orepistemic\\nuncertainty , or how input parameter changes would affect the prediction for one particular example, the predictive uncertainty ,\\noraleatoric variability (gal, 2016). in a bayesian deep learning approach, pawlowski, brock, lee, rajchl, and glocker\\n(2017) approximate model parameters through variational methods, resulting in uncertainty information of model weights,\\nand a means to derive predictive uncertainty from the model outputs. providing uncertainty facilitates the appropriate use of\\nmodel predictions in scenarios where different sources of information are combined as typically the case in medicine. we canfurther differentiate aleatoric uncertainty, into homoscedatic uncertainty independent of a particular input, and heteroscedatic\\nuncertainty possibly changing with different inputs to the system.\\nmethods for attribution seek to link a particular output of the deep neural network to input variables. sundararajan, taly,\\nand yan (2017) analyze the gradients of the output when changing individual input variables. in a sense this traces the predic-tion uncertainty back to the components of a multivariate input. zhou, khosla, lapedriza, oliva, and torralba (2016) use acti-\\nvation maps to identify parts of images relevant for a network prediction. recently attribution approaches for generative\\nmodels have been introduced. baumgartner, koch, tezcan, ang, and konukoglu (2017) demonstrate how image areas thatare specific to the foreground class in wasserstein generative adversarial networks (wgan) can be identified and high-\\nlighted in the data. biffi et al. (2018) learn interpretable features for variational auto encoders (vae) by learning gradients inthe latent embedding space that it linked to the classification result.\\nactivation maximization (montavon et al., 2017) identifies input patterns that lead to maximal activations relating to spe-\\ncific classes in the output layer (berkes & wiskott, 2006; simonyan & zisserman, 2014). this makes the visualization of pro-\\ntotypes of classes possible, and assesses which properties the model captures for classes\\n1(erhan, bengio, courville, &\\nvincent, 2009). for a neural network classifier mapping data points xto a set of classes ( ωc)c, the approach identifies highly\\nprobable regions in the input space, that create high output probabilities for a particular class. these positions can be found byintroducing a data density model in the standard objective function log p(ω\\nc|x)−λkxk2that is maximized during model\\ntraining. instead of the ℓ2-norm regularizer that implements a preference for inputs that are close to the origin, the density\\nmodel or “expert ”(montavon et al., 2017) results in the term log p(ωc|x) + log p(x) that is to be maximized. here, the proto-\\ntype is encouraged to simultaneously produce strong class response and to resemble the data. by application of bayes' rule,\\nthe newly defined objective can be identified, up to modeling errors and a constant term, as the class-conditioned data density\\np(x|ωc). the learned prototype thus corresponds to the most likely input xfor the class ωc(figure 2).\\na possible choice for the expert is a gaussian restricted boltzmann machine (rbm). the rbm is a two-layer, bipartite,\\nundirected graphical model with a set of binary hidden units p(h), a set of (binary or real-valued) visible units p(v), with sym-\\nmetric connections between the two layers represented by a weight matrix w.the probabilistic semantics for an rbm is\\ndefined by its energy function (for details see the chapter by hinton (2012). its probability function can be written as:\\nlogpxðþ=p\\njfjxðþ−1\\n2x>σ−1x+ cst :, where fjxðþ= log 1 + exp w>\\njx+bj/c16/c17 /c16/c17\\nare factors with parameters learned from the\\ndata. when interpreting more complex concepts such as natural images classes, other density models such as convolutional\\nrbm's (lee, grosse, ranganath, & ng, 2009) or pixel rnn's (oord, kalchbrenner, & kavukcuoglu, 2016) are suitable.\\nthe selection of the so-called expert p(x) plays an important role. basically, there are four different cases: in the case\\nwhere “the expert ”is absent, that is, the optimization problem reduces to the maximization of the class probability function p\\nfigure 2 an overview of how deep learning models can be probed for information regarding uncertainty, attribution, and prototypes6o f1 3 holzinger et al .\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n\",\n",
       " \"(ωc|x). in the case where we see the other extreme, that is, the expert is overfitted on some data distribution, and thus, the\\noptimization problem becomes essentially the maximization of the expert p(x) itself.\\nwhen using activation maximization for the purpose of model validation, an overfitted expert must be especially avoided,\\nas the latter could hide interesting failure modes of the model p(ωc|x). a slightly underfitted expert (case b), for example, that\\nsimply favors images with natural colors, can already be sufficient. on the other hand, when using am to gain knowledge on\\na correctly predicted concept ωc, the focus should be to prevent underfitting. indeed, an underfitted expert would expose\\noptima of p(ωc|x) potentially distant from the data, and therefore, the prototype x?would not be truly representative of ωc.\\nunsupervised learning and generative models. in certain applications, it is helpful to not only predict based on input data,\\nbut learn the structure of a set of training examples, to either provide a parametric representation of its density p(x), or at least\\nbe able to sample from this density generating examples of the same type as the training examples. examples are boltzmann\\nmachines, autoencoders, or generative adversarial networks) which do not provide the density function directly, but are able\\nto sample from it, usually via the following two steps:\\n1. sample from a simple distribution qzðþ/c24 n0,iðþ which is defined in an abstract code space z;\\n2. apply to the sample a decoding function g:z!x, that maps it back to the original input domain.\\nthere are two aspects of models learned by unsupervised learning that are relevant in the context of explainability. first,\\nthe latent representations learned in these models can hold structure that reflects relatively complex relationship patterns in thedata. for instance, in mikolov et al. (2013) the authors show that word embeddings can reflect semantic similarity. second,being able to generate instances, or even instances that are as close as possible to an observation, provides means to study the\\ndifference of examples to a class. this is relevant in medicine, where the discovery and study of anomalies that are potentially\\nlinked to disease is relevant schlegl et al. (2017).\\none example is the generative adversarial network (gan) introduced by goodfellow et al. (2014). it consists of two\\nmodels: a generative model gthat captures the data distribution, and a discriminative model dthat estimates the probability\\nthat a sample came from the training data rather than from g.the training procedure for gis to maximize the probability of\\ndmaking an error —which works like a minimax (minimizing a possible loss for a worst case maximum loss) two-player\\ngame. in the space of arbitrary functions gandd, a unique solution exists, with grecovering the training data distribution\\nanddequal to\\n1\\n2everywhere; in the case where ganddare defined by multilayer perceptrons, the entire system can be\\ntrained with backpropagation.\\nto learn the generator's distribution pgover data x, a prior must be defined on the input noise variables pz(z), and then a\\nmapping to the data space as g(z;θg), where gis a differentiable function represented by a multilayer perceptron with param-\\neters θg. the second multilayer perceptron d(x;θd) outputs a single scalar. d(x) represents the probability that xcame from\\nthe data rather than pg.dcan be trained to maximize the probability of assigning the correct label to both training examples\\nand samples from g.simultaneously gcan be trained to minimize log(1 −d(g(z))); in other words, dandgplay the follow-\\ning two-player minimax game with value function v(g,d):\\nmin\\ngmax\\ndvd,gðþ =ex/c24pdataxðþlogdxðþ ½/c138 +ez/c24pzzðþlog 1−dg zðþðþ ðþ½/c138 : ð1þ\\nnguyen, dosovitskiy, yosinski, brox, and clune (2016) proposed building a prototype for ωcby incorporating such a\\ngenerative model in the activation maximization framework. the optimization problem is redefined as:\\nmax\\nz2zlogpωcjgzðþ ðþ −λzkk2, ð2þ\\nwhere the first term is a composition of the newly introduced decoder and the original classifier, and where the second term is\\nanℓ2-norm regularizer in the code space. once a solution z?to the optimization problem is found, the prototype for ωcis\\nobtained by decoding the solution, that is, x?=g(z?).\\ntheℓ2-norm regularizer in the input space can be understood in the context of image data as favoring gray-looking\\nimages. the effect of the ℓ2-norm regularizer in the code space can instead be understood as encouraging codes that have high\\nprobability. high probability codes do not necessarily map to high density regions of the input space; for more details refer tothe excellent tutorial given by montavon et al. (2017).\\n3.2 |example use-case histopathology\\nthis section demonstrates the complexity of explanations of a human pathologist. for the following diagnosisholzinger et al . 7o f1 3\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n\",\n",
       " 'steatohepatitis with mild portal and incomplete-septal fibrosis and mild centrilobular fibrosis of chicken wire\\ntype. the morphological picture corresponds to alcoholic steatohepatitis. history of alcohol abuse?\\n3.2.1 |example for human posthoc explanation\\nwe asked an experienced pathologist to explain what he considered relevant in the histology slides. a very small portion of\\nthe histological sections are shown in figure 3 as illustration. for this specific diagnosis the pathologist gave the following\\nfacts as posthoc explanation:\\n\\x81liver biopsy with 10 evaluable portal fields.\\n\\x81lobule architecture preserved.\\n\\x81liver cells arranged in regular plates one cell layer thick.\\n\\x81portal fields slightly widened and slightly fibrotic.\\n\\x81isolated incomplete porto-portal and porto-central septa.\\n\\x81portal fields slightly inflamed with mixed-cell (lymphocytes, sporadic neutrophil granulocytes) inflammatory inflitrates.\\ninflammation restricted to portal field.\\n\\x81parenchymatous border plate intact, liver cells with low anisocaryosis, moderately large droplet fatty liver (estimated\\nparenchyma fatty degeneration at 30% of parenchymal area).\\n\\x81lobular central hepatic cells balloonized, light cytoplasmic with incorporation of mallory-denk bodies.\\n\\x81most of these liver cells are surrounded by neutrophil granulocytes and some of them are interspersed (satelliteosis).\\n\\x81minor perivenular fibrosis (=central sclerosis).\\n\\x81kupffer cells slightly diffusely increased, isolated kupffer cell nodules detectable.\\n\\x81in the berliner blue stain minor parenchymatous and kupffer cell siderosis.\\n3.2.2 |example for the ante-hoc structure of explanations\\nwe also asked the pathologist to explain the process and most relevant concepts in liver pathology. please note, that the fol-\\nlowing description just demonstrates the structure and complexity and is far away from a textbook on liver pathology. the\\npathologist described the following procedure and observation as an ante-hoc explanation for liver pathology:\\n\\x81describe in the macroscopic evaluation of the histological section the following features:\\n–type, number and size of specimens (surgical specimen or biopsy)\\n–tissue cohesion of biopsies\\n–staining quality (h & e/cab/sirius red/iron/ev. pas, immunohsistochemistry)\\n–already visible exogenous tissue (tumor)\\n\\x81describe in microscopic evaluation at low magnification the following features:\\n–lobular architecture preserved/disturbed in the sense of fibrosis or necrosis/destroyed in the context of cirrhosis or tumors\\n–number of assessable portal fields (optimal 10 –15 per slide)\\n–liver cell (hepatocyte) plates regular-one cell layer thick/several cell layers thick\\nportal track\\nkupffer cell erythrocyte\\nsinusoid\\nendothelial cell nucleushepatocyte\\nnucleushepatocyte\\nlarge lipid dropletbile ducts portal vein artery\\nfigure 3 features in a histology slide annotated by a human expert pathologist8o f1 3 holzinger et al .\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " '–inflammatory changes portal/lobular/combined; necrosis lobular peripheral/lobular central)\\n–presence or absence of tissue\\n\\x81describe in microscopic evaluation at higher magnification the following features:\\n–portal tracts: regular/extended/fibrotic/rounded/edematous\\n–connective tissue parenchyma border: sharp/unsharp\\n–parenchymatous border plate: preserved/partially destroyed/mostly destroyed/nonexistent inflammatory infiltrates portal/-\\nperiportal-interface, sparse/tight/localized-follicular/ lymphocytic/ lymphohistiocytic/neutrophil-granulocytic/ stressed-eosino-phil-granulocytic/granulomatous;\\n–abnormal content of the portal field not present (tumor cells/foreign bodies/parasites)\\n–portal vessels (arteria hepatica, vena portae, and lymphatic vessels) present/expanded/narrowed/inflammatory;\\n–bile ducts: present/elongated/absent/single-layer epithelium/multilayer epithelium/polymorphic epithelium/inflammatory\\nchanges/partially destructed/scarred/content (bile thrombus/porphyrinthrombus);\\n–ductal reaction absent/low/pronounced /ductal cholestasis.\\n–lobules (lobulus, liver parenchyma): liver cells large/balloonized/small-atrophic/anisocytosis/apoptosis\\n–cytoplasm: granular/net-like/light cytoplasmic-glycogen-rich/diffuse homogenized/focally homogenized\\n–cytoplasmic inclusions fat large droplet/fat small droplet/ lipofuscin granules/siderin granules/aat inclusions/fibrinogen\\ninclusions/mallory denk bodies (mdb), hyaline bodies/bilirubin\\n–canalicular bilirubinostasis\\n–necroses disseminated/confluent/lobular central/lobular periphery/bridging porto-central/bridging centro-central/massive;\\n—liver cell nuclei anisocaryosis/pycnosis/punch cores/ “sand cores “/core inclusions;\\n–kupffer cells focally increased (nodular)/diffus increased/enlarged/inclusions (siderin, pigment, erythrocytes, pathogen,\\nforeign material);\\n–star cells (stellate cells) increased\\n–sinusoidal dilated/abnormal content (e.g., blood, fibrin, and tumor cells)\\n–central vein lumen open/narrowed/ obliterated/inflamed/wall fibrosis.\\n–fibrosis: portal/perisinusoidal/pericellular/perivenular/septal/porto-portal/porto-central/centro-central/meshed wire fibrosi-\\ns/incomplete cirrhosis/cirrhosis.\\n–foreign tissue (tumor tissue to be characterized morphologically, primary/secondary-metastatic/unclear).\\nfor a specific case values of all above features contribute to the diagnosis with different weights and causal relations pre-\\nsent in the human model on liver pathology, which an expert acquired by training and experience.\\n4|future outlook\\n4.1 |weakly supervised learning\\nsupervised learning is very expensive in the medical domain because it is cumbersome to get strong supervision information and\\nfully ground-truth labels. particularly, labeling a histopathological image is not only time-consuming but also a critical task forcancer diagnosis, as it is clinically important to segment the cancer tissues and cluster them into various classes (xu, zhu, chang,\\nlai, & tu, 2014). digital pathological images generally have some issues to be considered, including the very large image size\\n(and the involved problems for dl), insufficiently labeled images (the small training data available), the time needed from thepathologist (expensive labeling), insufficient labels (region of interest), different levels of magnification (resulting in differentlevels of information), color variation and artifacts (sliced and placed on glass slides) etc. (komura & ishikawa, 2018).\\nweakly supervised learning (xu et al., 2014) is an umbrella term for a variety of methods to construct predictive models\\nby learning with weak supervision; weak because of either incomplete, inexact or inaccurate supervision. in a strong supervi-\\nsion task we want to learn f:x!yfrom the training data set d=(x\\n1,y1),…(xm,ym), wherein xis the feature space and\\n(xi,yi) are always assumed to be identically and independently distributed data (which is not the case in real-world problems!).\\nin the context of weakly supervised learning, we propose classifying whole slide images according to widely used scoring\\nsystems based on association with histomorphological characteristics and an overall predictive score, and to provide in addi-\\ntion a relevance map generated by observing the human expert during diagnosis making. by the combination of well-known\\nhuman features and new multiscale morphological classifiers the human causal model can be on the one hand extended andon the other hand the cnn model can be explained with known histomorphological features. we propose to extract from bothbenign and malign single cell nuclei and to classify chromatin organization (araujo et al., 2017) within the nuclei to correlatethese to histopathological features and molecular markers.holzinger et al . 9o f1 3\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " '4.2 |structural causal models\\na very important direction is research towards structural causal models (pearl, 2009; pearl & mackenzie, 2018; peters et al.,\\n2017). current ai work on either a statistical or model-free mode. this entails severe limits on both effectiveness and perfor-mance. such systems cannot reason about interventions and retrospection and, therefore, cannot serve for strong ai (pearl &mackenzie, 2018). to achieve human level intelligence, ai need the guidance of a model of reality, similar to the ones usedin causal inference tasks. consequently, we propose to: (1) develop new visualization techniques that can be trained by medi-cal experts, as they can explore the underlying explanatory factors of the data and (2) formalize a structural causal model ofhuman decision making and mapping features in these to dl approaches. in digital pathology such mechanistic models can beused to analyze and predict the response of a functional network behavior to features in histology slides, molecular data andfamily history.\\n4.3 |develop causability as a new scientific field\\nthe human-computer interaction community has established a range of usability methods (holzinger, 2005). similar to these\\nusability methodologies, methods and tests, we need the development of causability methodologies, methods and tests, whichare based on clear scientific principles and theories of causality in order to establish causability as a scientific field which willbecome necessary with increased use of ai. the same as usability measures ensures the “quality of use ”(bevan, 1995), causa-\\nbility measures must ensure the “quality of explanations ”.\\naccording to the three layer causal hierarchy by pearl (2018):level 1: association p(y|x) with the typical activity of “seeing ”and questions including “how would seeing x change\\nmy belief in y? ”, in our use-case above this was the question of “what does a feature in a histology slide the pathologist about\\na disease? ”\\nlevel 2: intervention p(y|do(x),z) with the typical activity of “doing ”and questions including “what if i do x? ”, in our\\nuse-case above this was the question of “what if the medical professional recommends treatment x —will the patient be\\ncured? ”\\nlevel 3: counterfactuals p(y\\nx|x0,y0) with the typical activity of “retrospection ”and questions including “was y the cause\\nfor x? ”, in our use-case above this was the question of “was it the treatment that cured the patient? ”\\nfor each of these levels we have to develop methods to measure effectiveness (does an explanation describe a statement\\nwith an adequate level of detail), efficiency (is this done with a minimum of time and effort) and user satisfaction (how satis-factory was the explanation for the decision making process). again we should mention that there are three types of explana-tions: (1) a peer-to-peer explanation as it is carried out among physicians during medical reporting; (2) an educationalexplanation as it is carried out between teachers and students; (3) a scientific explanation in the strict sense of science theory(popper, 1935). we emphasize that in this article we always refer to the first type of explanation.\\n5|conclusion\\nai is already one of the key technologies in our economy. it will bring changes similar to the introduction of the steam engine\\nor electricity. however, concerns about potential loss of control in the human-ai relationship are growing. issues such as\\nautonomous driving and the unclear decision making of the vehicle, for example, in extreme cases shortly before an accidentcollision, have long been the subject of public debate. the same goes for the question of the extent to which ai can or shouldsupport medical decisions or even make them itself. in many cases it will be necessary to understand how a machine decisionwas made and to assess the quality of the explanation.\\nwhile rule-based solutions of the early ai in the 1950s represented comprehensible “glass box ”approaches, their weak-\\nness lay in dealing with uncertainties of the real world. many problems from our everyday lives cannot be represented by for-\\nmal, mathematical rules of logic. the failure of such algorithms to solve problems that are relatively simple for humans, suchas natural language, recognizing faces, or understanding a joke, ultimately led to the “ai winter ”in the 1980s. only through\\nthe triumph of probabilistic and statistical learning methods in connection with the success of artificial neural networks ( “deep\\nlearning ”) did ai applications become increasingly successful.\\ntoday, dl algorithms are very useful in our daily lives: autonomous driving, face recognition, speech understanding, rec-\\nommendation systems, etc. already work very well. however, it is very difficult for people to understand how these algorithmscome to a decision. ultimately, these are so-called “black box ”models. the problem is that even if we understand the underly-\\ning mathematical principles and theories, such models lack an explicit declarative representation of knowledge. early ai solu-tions (at that time called expert systems) had the goal from the beginning of making solutions comprehensible, understandable10 of 13 holzinger et al .\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " 'and thus explainable, which was also possible in very narrowly defined problems. of course, we should mention that many\\nproblems do possibly not need explanations for everything at any time.\\nhere, the area of explainable ai is not only useful and necessary, but also represents a huge opportunity for ai solutions\\nin general. the generally accused opacity of ai can thus be reduced and necessary trust built up. exactly this can promote the\\nacceptance with future users lastingly.\\nthe main problem of the most successful current ml systems, recently emphasized by pearl (2018), is that they work on a\\nstatistical, or model-free mode, which entails severe limitations on their performance. such systems are not able to understand\\nthe context, hence cannot reason about interventions and retrospection. however, such approaches needs the guidance of a\\nhuman model similar to the ones used in causality research (pearl, 2009; pearl & mackenzie, 2018) to answer the question\\n“why? ”. the establishment of causability as a solid scientific field can help here.\\n“data can tell you that the people who took a medicine recovered faster than those who did not take it, but they\\ncant tell you why. maybe those who took the medicine did so because they could afford it and would have recov-ered just as fast without it. ”\\njudea pearl (2018), the book of why: the new science of cause and effect\\nacknowledgments\\nwe gratefully acknowledge the support of our industrial partner kapsch, the biobank graz, the bbmri.at team, the eu fea-\\nturecloud project and the critical review from our colleagues at the medical university graz. last but not least we want to\\nthank the anonymous reviewers for their critics and useful comments.\\nconflict of interest\\nthe authors have declared no conflicts of interest for this article.\\nendnote\\n1presented as a poster during the icml 2009 workshop on learning feature hierarchies, http://www.cs.toronto.edu/ rsala-\\nkhu/deeplearning/program.html.\\norcid\\nandreas holzinger https://orcid.org/0000-0002-6786-5194\\nreferences\\nabadi, m., agarwal, a., barham, p., brevdo, e., chen, z., citro, c., corrado, g. s., davis, a., dean, j., & devin, m. (2016). tensorflow: large-scale ma chine learning\\non heterogeneous distributed systems. arxiv:1603.04467.\\naraujo, t., aresta, g., castro, e., rouco, j., aguiar, p., eloy, c., …campilho, a. (2017). classification of breast cancer histology images using convolutional neural\\nnetworks. plos one ,12, e0177544.\\nbabiker, h. k. b., & goebel, r. (2017). an introduction to deep visual explanation. arxiv:1711.09482.\\nbach, s., binder, a., montavon, g., klauschen, f., müller, k.-r., & samek, w. (2015). on pixel-wise explanations for non-linear classifier decision s by layer-wise rel-\\nevance propagation. plos one ,10, e0130140.\\nbaumgartner, c. f., koch, l. m., tezcan, k. c., ang, j. x., & konukoglu, e. (2017). visual feature attribution using wasserstein gans. paper presented at proceedings\\nof the ieee computer society conference on computer vision and pattern recognition.\\nbengio, y. (2009). learning deep architectures for ai. foundations and trends in machine learning ,2,1–127.\\nbengio, y., courville, a., & vincent, p. (2013). representation learning: a review and new perspectives. ieee transactions on pattern analysis and machine intelli-\\ngence ,35, 1798 –1828.\\nberkes, p., & wiskott, l. (2006). on the analysis and interpretation of inhomogeneous quadratic forms as receptive fields. neural computation ,18, 1868 –1895.\\nbevan, n. (1995). measuring usability as quality of use. software quality journal ,4, 115–130.\\nbiffi, c., oktay, o., tarroni, g., bai, w., de marvao, a., doumou, g., …rueckert, d. (2018). learning interpretable anatomical features through deep generative\\nmodels: application to cardiac remodeling. paper presented at international conference on medical image computing and computer-assisted intervention\\n(pp. 464 –471). springer.\\nbologna, g., & hayashi, y. (2017). characterization of symbolic rules embedded in deep dimlp networks: a challenge to transparency of deep learning. journal of arti-\\nficial intelligence and soft computing research ,7, 265–286.\\ncaruana, r., lou, y., gehrke, j., koch, p., sturm, m., & elhadad, n. (2015). intelligible models for healthcare: predicting pneumonia risk and hospit al 30-day readmis-\\nsion. paper presented at 21th acm sigkdd international conference on knowledge discovery and data mining (kdd ’15) (pp. 1721 –1730). acm.\\ndoran, d., schulz, s., & besold, t. r. (2017). what does explainable ai really mean? a new conceptualization of perspectives. arxiv:1710.00794.holzinger et al . 11 of 13\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " 'erhan, d., bengio, y., courville, a., & vincent, p. (2009). visualizing higher-layer features of a deep network. university of monetreal technical report nr. 1341.\\nesteva, a., kuprel, b., novoa, r. a., ko, j., swetter, s. m., blau, h. m., & thrun, s. (2017). dermatologist-level classification of skin cancer with de ep neural net-\\nworks. nature ,542, 115–118.\\nfellmeth, a. x., & horwitz, m. (2009). guide to latin in international law . oxford, england: oxford university press.\\ngal, y. (2016). uncertainty in deep learning . cambridge, england: university of cambridge.\\ngershman, s. j., horvitz, e. j., & tenenbaum, j. b. (2015). computational rationality: a converging paradigm for intelligence in brains, minds, and m achines. science ,\\n349, 273–278.\\ngoebel, r., chander, a., holzinger, k., lecue, f., akata, z., stumpf, s., kieseberg, p., & holzinger, a. (2018). explainable ai: the new 42?. paper presented at\\nspringer lecture notes in computer science lncs 11015 (pp. 295 –303). springer.\\ngoodfellow, i., pouget-abadie, j., mirza, m., xu, b., warde-farley, d., ozair, s., …bengio, y. (2014). generative adversarial nets. in z. ghahramani, m. welling,\\nc. cortes, n. d. lawrence, & k. q. weinberger (eds.), advances in neural information processing systems (nips) (pp. 2672 –2680). montreal, canada: neural\\ninformation processing systems foundation.\\nguillaume, s. (2001). designing fuzzy inference systems from data: an interpretability-oriented review. ieee transactions on fuzzy systems ,9, 426–443.\\nhamburg, m. a., & collins, f. s. (2010). the path to personalized medicine. new england journal of medicine ,363, 301–304.\\nhinton, g. e. (2012). a practical guide to training restricted boltzmann machines. in neural networks: tricks of the trade, lecture notes in computer science lncs\\n(vol. 7700, pp. 599 –619). heidelberg: springer.\\nhoffman, r. r., mueller, s. t., klein, g., & litman, j. (2018). metrics for explainable ai: challenges and prospects. arxiv:1812.04608.\\nholzinger, a. (2005). usability engineering methods for software developers. communications of the acm ,48,7 1–74.\\nholzinger, a. (2014). trends in interactive knowledge discovery for personalized medicine: cognitive science meets machine learning. ieee intelligent informatics\\nbulletin ,15,6–14.\\nholzinger, a. (2016). interactive machine learning for health informatics: when do we need the human-in-the-loop? brain informatics ,3, 119–131.\\nholzinger, a. (2017). introduction to machine learning and knowledge extraction (make). machine learning and knowledge extraction ,1,1–20 http://www.mdpi.\\ncom/2504-4990/1/1/1\\nholzinger, a (2018). from machine learning to explainable ai. paper presented at 2018 world symposium on digital intelligence for systems and machines (disa).\\nholzinger, a., biemann, c., pattichis, c. s., & kell, d. b. (2017). what do we need to build explainable ai systems for the medical domain? arxiv:1712.09923.\\nholzinger, a., dehmer, m., & jurisica, i. (2014). knowledge discovery and interactive data mining in bioinformatics —state-of-the-art, future challenges and research\\ndirections. bmc bioinformatics ,15, i1.\\nholzinger, a., plass, m., holzinger, k., crisan, g. c., pintea, c.-m., & palade, v. (2017). a glass-box interactive machine learning approach for sol ving np-hard prob-\\nlems with the human-in-the-loop. arxiv:1708.01104.\\nholzinger, a., plass, m., kickmeier-rust, m., holzinger, k., crian, g. c., pintea, c.-m., & palade, v. (2018). interactive machine learning: experi mental evidence for\\nthe human in the algorithmic loop. applied intelligence ,1–14.\\nhudec, m., bednrov, e., & holzinger, a. (2018). augmenting statistical data dissemination by short quantified sentences of natural language. journal of official statis-\\ntics (jos) ,34, 981–1010.\\njohnson, w. l. (1994). agents that learn to explain themselves. paper presented at twelfth national conference on artificial intelligence (aaai ’94) (pp. 1257 –1263).\\naaai.\\njordan, m. i., & mitchell, t. m. (2015). machine learning: trends, perspectives, and prospects. science ,349, 255–260.\\nkendall, a., & gal, y. (2017). what uncertainties do we need in bayesian deep learning for computer vision? in advances in neural information processing systems\\n(pp. 5574 –5584). long beach, ca: neural information processing systems foundation.\\nkhaligh-razavi, s.-m., & kriegeskorte, n. (2014). deep supervised, but not unsupervised, models may explain it cortical representation. plos computational biology ,\\n10, e1003915.\\nkieseberg, p., weippl, e., & holzinger, a. (2016). trust for the doctor-in-the-loop. in european research consortium for informatics and mathematics (ercim) news:\\ntackling big data in the life sciences (vol. 104, pp. 32 –33). sophia antipolis, france: european research consortium for informatics and mathematics.\\nkomura, d., & ishikawa, s. (2018). machine learning methods for histopathological image analysis. computational and structural biotechnology journal ,16,3 4–42.\\nlacave, c., & diez, f. j. (2002). a review of explanation methods for bayesian networks. the knowledge engineering review ,17, 107–127.\\nlake, b. m., ullman, t. d., tenenbaum, j. b., & gershman, s. j. (2017). building machines that learn and think like people. behavioral and brain sciences ,40, e253.\\nlakkaraju, h., kamar, e., caruana, r., & leskovec, j. (2017). interpretable and explorable approximations of black box models. arxiv:1707.01154.\\nlecun, y., bengio, y., & hinton, g. (2015). deep learning. nature ,521, 436–444.\\nlee, h., grosse, r., ranganath, r., & ng, a. y. (2009). convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. paper\\npresented at 26th annual international conference on machine learning (icml ’09) (pp. 609 –616). acm.\\nlee, s., & holzinger, a. (2016). knowledge discovery from complex high dimensional data. in s. michaelis, n. piatkowski, & m. stolpe (eds.), solving large scale\\nlearning tasks. challenges and algorithms, lecture notes in artificial intelligence, lnai 9580 (pp. 148 –167). heidelberg, germany: springer.\\nlipton, z. c. (2016). the mythos of model interpretability. arxiv:1606.03490.\\nma, j., broda, k., goebel, r., hosobe, h., russo, a., & satoh, k. (2010) speculative abductive reasoning for hierarchical agent systems. paper presented at interna-\\ntional workshop on computational logic in multi-agent systems (pp. 49 –64). springer.\\nmccarthy, j. (1960). programs with common sense (pp. 75 –91). rle and mit computation center.\\nmichalski, r. s., carbonell, j. g., & mitchell, t. m. (1984). machine learning: an artificial intelligence approach . heidelberg, germany: springer.\\nmikolov, t., chen, k., corrado, g., & dean, j. (2013). efficient estimation of word representations in vector space. arxiv:1301.3781.\\nmiller, t. (2019). explanation in artificial intelligence: insights from the social sciences. artificial intelligence ,267,1–38.\\nmiller, t., howe, p., & sonenberg, l. (2017) explainable ai: beware of inmates running the asylum or: how i learnt to stop worrying and love the social an d beha-\\nvioural sciences. arxiv: 1712.00547.\\nmontavon, g., samek, w., & müller, k.-r. (2017). methods for interpreting and understanding deep neural networks. arxiv:1706.07979.\\nnewell, a., shaw, j. c., & simon, h. a. (1958). chess-playing programs and the problem of complexity. ibm journal of research and development ,2, 320–335.\\nnguyen, a., dosovitskiy, a., yosinski, j., brox, t., & clune, j. (2016). synthesizing the preferred inputs for neurons in neural networks via deep gen erator networks.\\nin d. d. lee, m. sugiyama, u. v. luxburg, i. guyon, & r. garnett (eds.), advances in neural information processing systems 29 (nips 2016) (pp. 3387 –3395).\\nbarcelona, spain: neural information processing systems foundation.\\noord, a. v. d., kalchbrenner, n., and kavukcuoglu, k. (2016). pixel recurrent neural networks. arxiv: 1601.06759.\\npawlowski, n., brock, a., lee, m. c., rajchl, m., & glocker, b. (2017). implicit weight uncertainty in neural networks. arxiv preprint arxiv:1711.01297.\\npearl, j. (2009). causality: models, reasoning, and inference (2nd ed.). cambridge, england: cambridge university press.\\npearl, j. (2018). theoretical impediments to machine learning with seven sparks from the causal revolution. arxiv:1801.04016.\\npearl, j., & mackenzie, d. (2018). the book of why . new york, ny: basic books.\\npeters, j., janzing, d., & schölkopf, b. (2017). elements of causal inference: foundations and learning algorithms . cambridge, ma: mit-press.12 of 13 holzinger et al .\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " 'poole, d. l., mackworth, a. k., & goebel, r. (1998). computational intelligence: a logical approach . new york, ny: oxford university press.\\npopper, k. (1935). die logik der forschung. zur erkenntnistheorie der modernen naturwissenschaft . wien, austria: springer-verlag.\\npoulin, b., eisner, r., szafron, d., lu, p., greiner, r., wishart, d. s., …anvik, j. (2006). visual explanation of evidence with additive classifiers. in national confer-\\nence on artificial intelligence (pp. 1822 –1829). cambridge, ma: mit press.\\nribeiro, m. t., singh, s., & guestrin, c. (2016a). model-agnostic interpretability of machine learning. arxiv:1606.05386.\\nribeiro, m. t., singh, s., & guestrin, c. (2016b). why should i trust you?: explaining the predictions of any classifier. paper presented at proceedings of the 22nd\\nacm sigkdd international conference on knowledge discovery and data mining (pp. 1135 –1144). acm.\\nrolnick, d., veit, a., belongie, s., & shavit, n. (2017). deep learning is robust to massive label noise. arxiv:1705.10694.\\nrumelhart, d. e., hinton, g. e., & williams, r. j. (1986). learning representations by back-propagating errors. nature ,323, 533–536.\\nrussell, s. j., & norvig, p. (2010). artificial intelligence: a modern approach (3rd ed.). upper saddle river: prentice hall.\\nschlegl, t., seeböck, p., waldstein, s. m., schmidt-erfurth, u., & langs, g. (2017). unsupervised anomaly detection with generative adversarial ne tworks to guide\\nmarker discovery. in international conference on information processing in medical imaging (pp. 146 –157). heidelberg, germany: springer.\\nschmidhuber, j. (2015). deep learning in neural networks: an overview. neural networks ,61,8 5–117.\\nseeböck, p., waldstein, s. m., klimscha, s., bogunovic, h., schlegl, t., gerendas, b. s., …langs, g. (2018). unsupervised identification of disease marker candidates\\nin retinal oct imaging data. ieee transactions on medical imaging. ,1 .\\nshortliffe, e. h., & buchanan, b. g. (1975). a model of inexact reasoning in medicine. mathematical biosciences ,23, 351–379.\\nsimonyan, k., & zisserman, a. (2014). very deep convolutional networks for large-scale image recognition. arxiv:1409.1556.\\nsingh, d., merdivan, e., psychoula, i., kropf, j., hanke, s., geist, m., & holzinger, a. (2017). human activity recognition using recurrent neural ne tworks. in\\na. holzinger, p. kieseberg, a. m. tjoa, & e. weippl (eds.), machine learning and knowledge extraction: lecture notes in computer science lncs 10410\\n(pp. 267 –274). cham: springer.\\nsundararajan, m., taly, a., & yan, q. (2017). axiomatic attribution for deep networks. arxiv preprint arxiv: 1703.01365.\\nswartout, w., paris, c., & moore, j. (1991). explanations in knowledge systems: design for explainable expert systems. ieee expert ,6,5 8–64.\\nszafron, d., lu, p., greiner, r., wishart, d. s., poulin, b., eisner, r., …fyshe, a. (2004). proteome analyst: custom predictions with explanations in a web-based tool\\nfor high-throughput proteome annotations. nucleic acids research ,32, w365 –w371.\\ntenenbaum, j. b., kemp, c., griffiths, t. l., & goodman, n. d. (2011). how to grow a mind: statistics, structure, and abstraction. science ,331, 1279 –1285.\\nting, d. s. w., cheung, c. y.-l., lim, g., tan, g. s. w., quang, n. d., gan, a., …lee, s. y. (2017). development and validation of a deep learning system for dia-\\nbetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes. jama ,318, 2211 –2223.\\nturkay, c., jeanquartier, f., holzinger, a., & hauser, h. (2014). on computationally-enhanced visual analysis of heterogeneous data and its applic ation in biomedical\\ninformatics. in a. holzinger & i. jurisica (eds.), interactive knowledge discovery and data mining: state-of-the-art and future challenges in biomedical informatics.\\nlecture notes in computer science lncs 8401 (pp. 117 –140). heidelberg, germany: springer.\\nwidrow, b., & lehr, m. a. (1990). 30 years of adaptive neural networks: perceptron, madaline, and backpropagation. proceedings of the ieee ,78, 1415 –1442.\\nxu, y., zhu, j.-y., chang, e. i. c., lai, m., & tu, z. (2014). weakly supervised histopathology cancer image segmentation and classification. medical image analysis ,\\n18, 591–604.\\nzhou, b., khosla, a., lapedriza, a., oliva, a., & torralba, a. (2016). learning deep features for discriminative localization. paper presented at proceedings of the\\nieee conference on computer vision and pattern recognition (2921 –2929).\\nhow to cite this article: holzinger a, langs g, denk h, zatloukal k, müller h. causability and explainability of arti-\\nficial intelligence in medicine. wires data mining knowl discov . 2019;9:e1312. https://doi.org/10.1002/widm.1312holzinger et al . 13 of 13\\n 19424795, 2019, 4, downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1312 by south korea national provision, wiley online library on [24/04/2024]. see the terms and conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on wiley online library for rules of use; oa articles are governed by the applicable creative commons license\\n',\n",
       " 'intelligence \\nunleashed\\nan argument for ai in education\\nrose luckin\\nwayne holmesucl knowledge lab,  university college london\\nmark griffiths\\nlaurie b. forcierpearson\\nopen ideas at pearsonsharing independent insights on the big, unanswered questions in education\\n',\n",
       " 'open ideas at pearson',\n",
       " 'open ideas at pearson \\npearson’s goal is to help people make progress \\nin their lives through learning. this means we are always learning too. \\nthis series of publications, open ideas, is one of \\nthe ways in which we do this. we work with some of the best minds in education – from teachers and \\ntechnologists, to researchers and big thinkers – to \\nbring their independent ideas and insights to a wider audience. \\nhow do we learn, and what keeps us motivated to \\ndo so? what is the body of knowledge and skills \\nthat learners need as we move into the second half of the 21st century? how can smart digital technologies be best deployed to realise the goal of \\na more personalised education? how can we build \\neducation systems that provide high quality learning opportunities to all? \\nthese questions are too important for the best ideas \\nto stay only in the lecture theatre, on the bookshelf, \\nor alone in one classroom. instead they need to be found and supported, shared and debated, adopted and refined.\\nour hope is that open ideas helps with this task, \\nand that you will join the conversation.about',\n",
       " 'open ideas at pearson\\ncreative commons \\nthis work is licensed under the creative commons attribution 4.0 international licence. to view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0 or send a letter to creative commons, po box 1866, mountain view, ca 94042, usa. \\nsuggested reference: luckin, r., holmes, w., griffiths, m. & forcier, \\nl. b. (2016). intelligence unleashed. an argument for ai in education.   \\nlondon: pearson.\\ncopyright 2016the contents of this paper and the opinions expressed herein are those \\nof the authors alone.\\nisbn: 9780992424886pearson\\npearson is the world’s learning \\ncompany, with expertise in educational courseware and \\nassessment, and a range of \\nteaching and learning services powered by technology.  \\nour mission is to help people make \\nprogress through access to better learning. we believe that learning opens up opportunities, creating fulfilling careers and better lives.\\n ucl knowledge lab\\nthe ucl knowledge lab (previously \\nknown as the london knowledge  \\nlab) is an interdisciplinary research \\ncentre at the ucl institute of \\neducation, university college london. our mission is both to understand  \\nand to design ways in which new \\ndigital technologies can support  \\nand transform learning and teaching \\nthroughout the life course, at home and at work. \\nwe start from the belief that new \\ntechnologies, when we fully exploit their possibilities, will change not only the ways we learn, but what \\nwe learn, as well as how we work, \\nhow we collaborate, and how we communicate. based on research and evidence, we are devising new pedagogies, implementing innovative \\ndigital systems, developing new areas \\nof knowledge, and informing policy-makers and educational stakeholders.',\n",
       " 'the authors\\nrose luckin\\nrose luckin is professor of learner centred design at the ucl knowledge lab, university college london. she has been developing and writing about \\nartificial intelligence in education (aied) for over 20 years, and has been an \\nactive member of the international aied society since its inception. her research explores how to increase participation by teachers and learners in the design and use of technologies. in addition to over 50 peer-reviewed articles and two \\nedited volumes, prof. luckin is the author of re-designing learning contexts \\n(routledge, 2010), and lead author of the influential decoding learning  report \\n(nesta, 2012).\\nwayne holmes\\nwayne holmes is a researcher at the ucl knowledge lab, university college \\nlondon and he teaches about education and technology at the graduate school of education, university of bristol. he has been involved in education and education research for more than 20 years, receiving his phd in education \\n(learning and technology) from the university of oxford, and co-founding an \\ned-tech web platform on which students answered 300+ million questions. his research interests are in education, the learning sciences, and artificial intelligence in education (aied).\\nmark griffiths\\nmark griffiths is director of research within the office of the chief education advisor at pearson. he leads on the office’s efforts to use world-class research to influence and inform pearson’s products and services. prior to pearson  \\nhe worked at nesta – the uk’s innovation charity – where he invested in  \\nover a dozen organisations that use technology or social action to improve school-aged learning.\\nlaurie b. forcier\\nlaurie forcier leads the open ideas thought leadership series within the  \\noffice of the chief education advisor at pearson. she has over 15 years’ \\nexperience in the education sector, covering research, evaluation, policy, and administration. she was a member of the research team that produced land  \\nof plenty, the final report of the congressional commission on the advancement of women and minorities in science, engineering, and technology development, and is co-editor of improving the odds for america’s children (harvard education \\npress, 2014).about',\n",
       " 'open ideas at pearson\\nacknowledgements\\nthe authors wish to thank \\nmichael barber and amar kumar at pearson for giving us the space and \\nencouragement that has allowed \\nus to form our own collaborative learning group around aied. we are also very grateful to the many \\npearson colleagues who have \\nprovided helpful guidance to this project or comments on this paper, including john behrens, kristen dicerbo, erin farber, josh fleming, \\njosé gonzález-brenes, denis hurley, \\njohann larusson, nathan martin, janine mathó, ashley peterson-deluca, david porcaro, and \\nvikki weston. \\nwe also want to thank mutlu \\ncukurova, beate grawemeyer, manolis mavrikis, and kaska \\nporayska-pomsta of the ucl \\nknowledge lab, for their support  \\nand colleagueship.\\ntwo people deserve a special \\nacknowledgement: ben du boulay for being a supportive and critical friend of this project from the start, and joshua underwood, co-author \\nof a 2011 paper that provided the \\ninspiration for this one. open ideas at pearson',\n",
       " 'intelligence unleashedintelligence unleashed\\ncontents\\nforeword by sir michael barber\\nintroductionwhat is artificial intelligence (ai)?a brief introduction to artificial  \\nintelligence in education (aied)what aied can offer learning right nowthe next phase of aiedtaking it to the next level: how aied  \\ncan help us respond to the biggest  \\nunsolved issues in education\\nbringing it all together: the continuing  \\nrace between education and technologyrecommendations to help us  \\nunleash intelligence\\n  references8\\n11\\n13\\n17\\n23\\n3241\\n45\\n49\\n5615\\nwill ai take over \\nfrom humans?\\n31\\nteachers and aied\\n39\\nthe ethics of ai  \\nand aied\\n40\\naied and the physical world\\n52\\nlearning from the \\napproach that  jump-started \\ndriverless cars\\n53\\nlearning from darpa',\n",
       " 'foreword by  \\nsir michael barber\\nfor thirty years i have attended conferences where \\nspeakers have spoken to slides comparing images of an early 20th century classroom with one from today, and have \\npointedly asked: ‘why so little change?’ the modern variant \\ngoes something like this: smart technologies have already transformed so many parts of our lives – from how we date to how we book a taxi. it would seem that there is no doubt \\nthat ai will also significantly influence what we teach and \\nlearn, as well as how we do it. and yet...\\nadopting a puzzled stance as to why things have not \\nchanged more has some value. it prompts us to examine our \\nassumptions, our habits, and our routines. it only takes us \\nso far, though. more is needed. \\nwhat we need – what we should demand – is an explanation \\nof why and how things could be different. first, we need to be \\nempowered by an understanding of what artificial intelligence in education (aied) is, what it delivers, and how it goes about doing that. \\nsecond, we need a clear explanation of how the field of \\nartificial intelligence can connect to the core of teaching  \\nand learning, so that we can avoid general-purpose technologies being used in ways that do not deliver the  \\nstep changes in learner outcomes we seek. for example, smart technologies that adapt to what is liked, rather than what is learnt, or that deliver more efficient administration, but not more efficient learning. \\nthird, we need concrete options that will allow us to make \\nthe potential of aied real at the system level – that is, at the scale that will allow it to support the teaching profession broadly and impact positively on the learning experience \\nof each and every student. and fourth, we need to ask and \\nanswer some profound ethical questions – for example, about the acceptable uses that can be made of the data that aied collects. \\nin other words, what we need is a degree of specificity about \\naied that allows us to assess, invest, plan, deliver, and test. this is what this paper offers – a useful primer on aied and  \\na compelling argument about what it can offer learning.open ideas at pearson 8',\n",
       " 'from what ai is and how aied-driven learning systems are \\nbuilt, onto its potential role in addressing the profound issue of robots and machines taking over more and more current \\njobs, it covers a vital range of topics with ease and elegance. \\nit is also a good read, with entertaining references from pac-man and stephen hawking, sci-fi and ancient philosophy. and, yes, it is understandable to a non-technical reader!\\nto make my own case for reading this paper, let me move \\nto a more local, anecdotal, level. recently a member of my pearson team talked to me about a phonics learning app he had bought for his young son. we could easily identify \\nthe affordances that the technology brought – perfect \\npronunciation of 42 phonics sounds, infinite patience, and a healthy spillover of engagement from the software to learning. \\nyet, it was equally easy to identify ways in which some basic \\naied techniques could have made the app so much better. content was re-presented even after it had been mastered, which led to boredom. other content was accessible even \\nthough it was much too difficult, leading to frustration.  \\nand there were no speech recognition capabilities present  \\nto verify the learner’s pronunciation, or blending of sounds.\\nasking for these features is not asking for science fiction. \\ninstead, it is asking us to incorporate findings from fields like the learning sciences into aied tools so that these insights are realised in cheaper, more effective ways. this paper offers a long-list of where we should look for this combination of \\nlearning insights and technology – for example, collaborative \\nlearning, meta-cognition (or knowing about one’s own thinking), useful feedback, and student motivation.\\nfunders and founders, policy makers and philanthropists \\n– in fact, anyone who takes seriously the urgent need to embark on the next stage of education system reform – should read and debate this paper. only then will we (finally) make good on the promise of smarter technologies for \\nlearning (and, as a side effect, get rid of those boring slides).intelligence unleashed 9',\n",
       " '',\n",
       " 'introduction\\nwe wrote this short paper on artificial intelligence in \\neducation (aied) with two aims in mind. the first was to explain to a non-specialist, interested reader what aied is:  \\nits goals, how it is built, and how it works. after all, only by securing a certain degree of understanding can we move beyond the science-fiction imagery of ai, and the associated fears. the second aim was to set out the argument for what \\naied can offer learning, both now and in the future, with an \\neye towards improving learning and life outcomes for all. \\nthroughout, our approach has been to start with teaching \\nand learning – and then describe how well designed and \\nthoughtful aied can usefully contribute. crucially we do not \\nsee a future in which aied replaces teachers. what we do  \\nsee is a future in which the role of the teacher continues to evolve and is eventually transformed; one where their \\ntime is used more effectively and efficiently, and where their \\nexpertise is better deployed, leveraged, and augmented.\\nalthough some might find the concept of aied alienating,  \\nthe algorithms  and models that comprise aied form the  \\nbasis of an essentially human endeavour. aied offers the \\npossibility of learning that is more personalised, flexible, inclusive, and engaging. it can provide teachers and learners with the tools that allow us to respond not only to what is \\nbeing learnt, but also to how it is being learnt, and how the \\nstudent feels. it can help learners develop the knowledge  \\nand skills that employers are seeking, and it can help teachers create more sophisticated learning environments than would otherwise be possible. for example, aied that can enable \\ncollaborative learning, a difficult task for one teacher to do \\nalone, by making sure that the right group is formed for the task-at-hand, or by providing targeted support at just the right time.\\nwe look towards a future when extraordinary aied  \\ntools will support teachers in meeting the needs of all  \\nlearners. drawing on the power of both human and artificial  \\nintelligence, we will lessen achievement gaps, address  \\nteacher retention and development, and equip parents \\nto better support their children’s (and their own) learning. importantly, doing this will require much more than borrowing the language of ai – we need to go deep, \\nharnessing the power of genuine aied, and then working  \\nto apply it in real-life contexts at scale.11 intelligence unleashed',\n",
       " 'open ideas at pearson\\ntrue progress will require the development of an aied \\ninfrastructure. this will not, however, be a single monolithic aied system. instead, it will resemble the marketplace \\nthat has developed for smartphone apps: hundreds and \\nthen thousands of individual aied components, developed in collaboration with educators, conformed to uniform international data standards, and shared with researchers \\nand developers worldwide. these standards will enable \\nsystem-level data collation and analysis that help us learn much more about learning itself and how to improve it. \\nif we are ultimately successful, aied will also contribute \\na proportionate response to the most significant social \\nchallenge that ai has already brought – the steady replacement of jobs and occupations with clever algorithms and robots. it is our view that this phenomena provides a new \\ninnovation imperative in education, which can be expressed \\nsimply: as humans live and work alongside increasingly smart machines, our education systems will need to achieve at levels that none have managed to date.\\nour response, we argue, should be to take on the role  \\nof metaphorical judo masters. that is, we should harness \\nthe power and strength of ai itself. in that way we can help teachers to equip learners – whatever their age – with the \\nknowledge and flexible skills that will allow them to  \\nunleash their human intelligence and thrive in this  \\nre-shaped workforce.\\nto be candid, the impetus for this paper arose from our \\nimpatience with the status quo. despite nearly three  \\ndecades of work, aied is in many ways still a cottage industry, \\nand the benefits and enormous potential of the field remain mostly unrealised. sadly, many of the best ideas in aied \\ncurrently make it no further than the lab, or perhaps a lecture \\nhall. aied is hampered by a funding system that encourages siloed research, and that shies away from dealing with the essential messiness of education contexts. we believe this needs to change.\\nthis is our attempt at contributing to that change, through \\nexplaining, arguing, and putting forward some evocative, and perhaps provocative, views of the future. it is our hope that \\nthis paper will provide a deeper understanding of aied, and \\nstimulate a much-needed debate.\\nlet us start by introducing ai.12',\n",
       " 'what is artificial \\nintelligence (ai)?intelligence unleashed 13',\n",
       " 'open ideas at pearson 14\\nit can be difficult to define artificial intelligence (ai), even for \\nexperts. one reason is that what ai includes is constantly shifting. as nick bostrom, a leading ai expert from oxford \\nuniversity, explains: “[a] lot of cutting edge ai has filtered into \\ngeneral applications, often without being called ai because once something becomes useful enough and common enough it is not labeled ai anymore.”\\n1 instead, it is considered  \\na computer program, or an algorithm, or an app, but not ai. \\nanother reason for the difficulty in defining ai is the interdisciplinary nature of the field. anthropologists,biologists, computer scientists, linguists, philosophers, psychologists, and neuroscientists all contribute to the \\nfield of ai, and each group brings their own perspective \\nand terminology. \\nfor our purposes, we define ai as computer systems that \\nhave been designed to interact with the world through \\ncapabilities (for example, visual perception and speech \\nrecognition) and intelligent behaviours (for example, assessing the available information and then taking the most sensible action to achieve a stated goal) that we \\nwould think of as essentially human.\\n2\\nthe use of ai in our day-to-day life is increasing ever more \\nrapidly. for example, ai scientists are currently building on new approaches in machine learning , computer modelling, \\nand probability statistics to improve financial decision making\\n3, and are using decision theory  and neuroscience to \\ndrive the development of more effective medical diagnostics.4  \\nand with the recent launch of openai, a non-profit artificial intelligence research company with an initial investment \\nof $1b, we expect this acceleration to continue apace – \\nincluding, we predict, in the area of aied.\\n5algorithm\\na defined list of \\nsteps for solving  \\na problem. \\na computer program \\ncan be viewed as an \\nelaborate algorithm. in ai, an algorithm is \\nusually a small pro -\\ncedure that solves a \\nrecurrent problem. \\nmachine learning\\ncomputer systems \\nthat learn from data, enabling them to \\nmake increasingly \\nbetter predictions.\\ndecision theory\\nthe mathematical \\nstudy of strategies \\nfor optimal decision-making between \\noptions involving \\ndifferent risks or expectations of gain \\nor loss depending on \\nthe outcome.',\n",
       " 'will ai take over \\nfrom humans?\\nsome in the scientific community \\nworry that ai is a pandora’s box with \\ndangerous consequences. as far \\nback as 1993, the computer scientist \\nvernon vinge popularised the notion \\nof the singularity, the point at which \\nan ai-powered computer or robot \\nbecomes capable of redesigning and \\nimproving itself or of designing ai \\nmore advanced than itself. inevitably, \\nit is argued, this will lead to ai that \\nfar exceeds human intelligence, \\nunderstanding, and control, and to \\nwhat vinge describes as the end of the \\nhuman era.6 more recently, stephen \\nhawking and other leading scientists \\nincluding stuart russell, max tegmark, \\nand frank wilczek have also warned \\nus about the potential downsides of ai \\nbecoming too clever.7\\nthis worrying idea has fed hollywood \\nfilms for decades, from 2001: a space \\nodyssey in the 60s, the terminator \\nseries of the 80s, and the more recent \\ntranscendence  – all of which depict \\none version or another of a dystopian \\nworld dominated by out-of-control ai. \\nbefore we get too worried, however, \\nit is worth making a note about \\nthe current capabilities of artificial \\nintelligence. major advances \\nin ‘general ai’, ai that that could \\nsuccessfully perform any intellectual \\ntask that a human being could, would \\nbe necessary for any singularity to \\noccur. and right now, general ai does \\nnot exist. general ai is very different from the \\n“domain specific ai” most of us are \\nfamiliar with. these domain specific \\nais focus on one thing – for example, \\nmastering chess (deep blue or giraffe), \\nor go (google’s deep mind), driving \\na car (google’s self-driving cars), or \\nrecognising a passport photograph as \\na representation of a particular person. \\neven for leading ai advocates, the \\nsingularity appears to be due to arrive \\nat some ever-receding future date, \\nusually around thirty years from the \\ntime they are writing!8\\nhowever, ai is getting more \\nsophisticated, and it is already having \\na profound impact on our economy. \\nin a 2013 study, the economists frey \\nand osborne used ai techniques \\nthemselves to begin the task of \\nidentifying the effects of automation \\non the jobs market. according to  \\ntheir estimates about 47 percent of \\ncurrent us jobs are at high-risk of \\nbeing carried out by machines in the \\nnext decade or two.9 to date, it is \\nmiddle-income jobs that have been most affected, reflecting the tasks  \\nthat are currently most susceptible  \\nto automation.\\n10 \\npast waves of profound changes in \\nthe economy (for example, the move \\nfrom an agricultural driven economy \\nto an industrial one) have been \\naccommodated by changing the  \\nreach and the nature of education  \\nand learning. 15 intelligence unleashed',\n",
       " 'the understandable guiding thought \\nhas been that if “workers have \\nflexible skills and if the educational \\ninfrastructure expands sufficiently, \\n[then] … the race between technology \\nand education will not be won by \\neither side and prosperity will be \\nwidely shared.”11 \\nwhether this will hold true in the face \\nof rapidly developing ai is contested. \\nan historical view provides evidence \\nthat technological change has always \\nbrought with it a host of new roles that we could not have previously \\npredicted or imagined. others, \\nlike martin ford, believe that as \\nautomation takes over more and more \\nsophisticated tasks, the number of \\njobs will be simply too small to sustain \\ncurrent employment rates.12\\nwe take an optimistic stance that \\naligns with the historical view. we also \\nbelieve that aied has a major role to \\nplay in helping us prepare for the new \\nroles that the economy will create – a \\ntopic we return to later in this paper.open ideas at pearson 16',\n",
       " 'intelligence unleashed 17\\na brief \\nintroduction  to artificial intelligence  \\nin education (aied)\\n ',\n",
       " 'open ideas at pearsonthe application of artificial intelligence to education (aied) has \\nbeen the subject of academic research for more than 30 years.the field investigates learning wherever it occurs, in traditional \\nclassrooms or in workplaces, in order to support formal education \\nas well as lifelong learning. it brings together ai, which is itself interdisciplinary, and the learning sciences (education, psychology, neuroscience, linguistics, sociology, and anthropology) to promote \\nthe development of adaptive learning environments  and other \\naied tools that are flexible, inclusive, personalised, engaging, \\nand effective. at the heart of aied is the scientific goal to “make computationally \\nprecise and explicit forms of educational, psychological and social knowledge which are often left implicit.”\\n13 in other words, in addition to \\nbeing the engine behind much ‘smart’ ed tech, aied is also a powerful tool to open up what is sometimes called the ‘black box of learning,’ \\ngiving us deeper, and more fine-grained understandings of how \\nlearning actually happens (for example, how it is influenced by the learner’s socio-economic and physical context, or by technology). \\nthese understandings may then be applied to the development of \\nfuture aied software and, importantly, can also inform approaches  \\nto learning that do not involve technology. for example, aied can  \\nhelp us see and understand the micro-steps that learners go through in learning physics, or the common misconceptions that arise.\\n14  \\nthese understandings can then be used to good effect by  \\nclassroom teachers. \\nas we have said, ai involves computer software that has been \\nprogrammed to interact with the world in ways normally requiring human intelligence. this means that ai depends both on knowledge \\nabout the world, and algorithms to intelligently process \\nthat knowledge.\\nthis knowledge about the world is represented in so called ‘ models’. \\nthere are three key models at the heart of aied: the pedagogical \\nmodel, the domain model, and the learner model.\\ntake the example of an aied system that is designed to provide \\nappropriate individualised feedback to a student. achieving this \\nrequires that the aied system knows something about:\\n•    effective approaches to teaching (which is represented in a  \\npedagogical model)\\n•   the subject being learned (represented in the domain model)\\n•   the student (represented in the learner model)\\nexamples of the specific knowledge that might be integrated into  \\neach of these models is displayed opposite.adaptive learning \\nenvironments\\na digital learning \\nenvironment that adapts teaching and \\nlearning approaches \\nand materials to the capabilities and \\nneeds of individual \\nlearners.\\nmodels\\nthese represent \\nsomething from \\nthe real world in a computer system \\nor process, to assist \\ncalculations and predictions.18',\n",
       " 'intelligence unleashedto delve deeper into just one of these examples,  \\nlearner models are ways of representing the interactions  \\nthat happen between the computer and the learner.  \\nthe interactions represented in the model (such as the \\nstudent’s current activities, previous achievements,  \\nemotional state, and whether or not they followed  \\nfeedback) can then be used by the domain and pedagogy \\ncomponents of an aied programme to infer the success  \\nof the learner (and teacher). the domain and pedagogy \\nmodels also use this information to determine the next  \\nmost appropriate interaction (learning materials or  \\nlearning activities). importantly, the learner’s activities are \\ncontinually fed back into the learner model, making the \\nmodel richer and more complete, and the system ‘smarter’.aied models what the model represents examples of specific knowledge \\nrepresented in aied models\\npedagogical \\nmodelthe knowledge and expertise  \\nof teaching‘productive failure’ (allowing  \\nstudents to explore a concept  \\nand make mistakes before being \\nshown the ‘right’ answer)\\nfeedback (questions, hints, or \\nhaptics), triggered by student actions, \\nwhich is designed to help the \\nstudent improve their learning\\nassessment to inform and  \\nmeasure learning\\ndomain model knowledge of the subject being \\nlearned (domain expertise)how to add, subtract, or multiply  \\ntwo fractions\\nnewton’s second law (forces)\\ncauses of world war i\\nhow to structure an argument\\ndifferent approaches to reading  \\na text (e.g. for sense or for detail)\\nlearner \\nmodelknowledge of the learner the student’s previous  \\nachievements and difficulties\\nthe student’s emotional state the student’s engagement in \\nlearning (for example: time-  \\non-task)\\nhaptics\\nany form of \\ninteraction involving \\ntouch. in the case of aied, this could \\nbe something like \\na smartphone vibration in \\nresponse to a \\ncorrect answer.19',\n",
       " 'so, what would a piece of education technology driven by \\naied look like? figure 1 (shown opposite) is a simplified picture \\nof a typical model-based adaptive tutor. it is based on the \\nthree core models as described above: the learner model \\n(knowledge of the individual learner), the pedagogy model (knowledge of teaching), and the domain model (knowledge  \\nof the subject being learned and the relationships between \\nthe different parts of that subject matter). aied algorithms \\n(implemented in the system’s computer code) process that knowledge to select the most appropriate content to be delivered to the learner, according to their individual capabilities and needs. \\nwhile this content (which might take the form of text, sound, \\nactivity, video, or animation) is being delivered to the learner, continuous analysis of the learner’s interactions (for example, \\ntheir current actions and answers, their past achievements, \\nand their current affective state) informs the delivery of feedback (for example, hints and guidance), to help them progress through the content they are learning.  \\ndeep analysis of the student’s interactions is also used to \\nupdate the learner model; more accurate estimates of the student’s current state (their understanding and motivation, for example) ensures that each student’s learning experience \\nis tailored to their capabilities and needs, and effectively \\nsupports their learning. \\nsome systems include so-called open learner models, which \\npresent the outcomes of the analysis back to the learners and \\nteachers. these outcomes might include valuable information \\nabout the learner’s achievements, their affective state, or any misconceptions that they held. this can help teachers understand their students’ approach to learning, and allows \\nthem to shape future learning experiences appropriately.  \\nfor the learners, open learner models can help motivate \\nthem by enabling them to track their own progress, and  \\ncan also encourage them to reflect on their learning.\\none of the advantages of adaptive aied systems is that they \\ntypically gather large amounts of data, which, in a virtuous circle, can then be computed to dynamically improve the pedagogy and domain models. this process helps inform \\nnew ways to provide more efficient, personalised, and \\ncontextualised support, while also testing and refining our understanding of the processes of teaching and learning.open ideas at pearson 20',\n",
       " 'intelligence unleashed\\nmeta-cognitive\\nmetacognition is \\nsometimes defined \\nsimply as ‘knowing \\nabout one’s thinking’. \\nit has two elements: \\nbeing aware of \\nthinking and being \\nable to control or \\nregulate it.figure 1\\naied system showing a simplified picture of a typical  \\nmodel-based adaptive tutor.  \\nin addition to the learner, pedagogical, and domain models, \\naied researchers have also developed models that represent \\nthe social, emotional, and meta-cognitive  aspects of learning. \\nthis allows aied systems to accommodate the full range of \\nfactors that influence learning. \\ntaken together, this set of increasingly rich aied models might \\nbecome the field’s greatest contribution to learning.domain \\nmodel\\nlearner\\nmodelpedagogy\\nmodelalgorithms\\nprocessing the knowledge \\nrepresented in the models\\ndata analysis\\nai techniques (such as machine \\nlearning and pattern recognition)adaptive content\\nlearning content (e.g. text or video) adapted to \\nthe needs and capabilities of the individual learner\\ndata capture\\nthe learner’s interactions, achievements,  \\naffect (emotion), speech...learner interfacefeedback\\nopen learner model\\nmaking the learning explicit,  \\nfor teachers & learners to see21',\n",
       " '',\n",
       " 'intelligence unleashed 23\\nwhat aied can \\noffer learning right now',\n",
       " 'open ideas at pearsona multitude of aied-driven applications are already in use \\nin our schools and universities. many incorporate aied and educational data mining (edm)  techniques to ‘track’ the \\nbehaviours of students – for example, collecting data on  \\nclass attendance and assignment submission in order to identify (and provide support) to students at risk of abandoning their studies. \\nother ai researchers are exploring novel user interfaces, \\nsuch as natural language processing, speech and gesture recognition, eye-tracking, and other physiological  \\nsensors, which could be used to augment both aied  \\nand non-aied software. \\nhere, however, we focus on three categories of aied  \\nsoftware applications that have been designed to support \\nlearning most directly: personal tutors for every learner, \\nintelligent support for collaborative learning, and intelligent virtual reality. \\naied can provide an intelligent,  \\npersonal tutor for every learner\\none-to-one human tutoring has long been thought to \\nbe the most effective approach to teaching and learning (since at least aristotle’s tutoring of alexander the great!) \\nunfortunately, one-to-one tutoring is untenable for all \\nstudents. not only will there never be enough human tutors; it would also never be affordable. all of this begs the question: how can we make the positive impact of one-to-one \\ntutoring available to all learners across all subjects? \\nthis is where intelligent tutoring systems (its) come in. its \\nuse ai techniques to simulate one-to-one human tutoring, delivering learning activities best matched to a learner’s \\ncognitive needs and providing targeted and timely feedback, \\nall without an individual teacher having to be present. some its put the learner in control of their own learning in order to help students develop self-regulation skills; others use \\npedagogical strategies to scaffold learning so that the learner \\nis appropriately challenged and supported.\\nthe 1970s brought some of the first ai systems to offer \\nindividualised and adaptive instruction. for example \\nbuggy\\n15, a ground-breaking system designed to teach basic \\naddition and subtraction, used a model of the possible \\nmisconceptions that learners might exhibit in their procedural \\narithmetic. this ‘bug library’, effectively the system’s domain \\nmodel, was used to diagnose each error that a student made scaffold\\nin the context \\nof education, \\nscaffolding is a \\nteaching method \\nthat enables a \\nstudent to solve a \\nproblem, carry out \\na task, or achieve \\na goal through the \\ngradual scaling \\nback of outside \\nassistance.educational  \\ndata mining\\nthe development \\nand use of methods \\nto analyse and \\ninterpret the ‘big \\ndata’ that comes \\nfrom computer-\\nbased learning \\nsystems and from \\nschool, college, \\nor university \\nadministrative and management \\nsystems.24',\n",
       " 'intelligence unleashedso that appropriate tutoring could be offered. initially, it was \\nlimited by the bugs that it could recognise, those that had been included in the original code. over time, additional \\nmisconceptions were found and added to the library.\\ninstead of models, many recent its use machine learning \\ntechniques, self-training algorithms based on large data sets, \\nand neural networks , to enable them to make appropriate \\ndecisions about what learning content to provide to the \\nlearner. however, with this approach, it can be difficult to make the rationale for those decisions explicit. \\nmodern model-based adaptive systems can be far more \\nflexible. they enable the rationale for each decision taken by the system to be made explicit and understandable by humans (and thus potentially applicable to classroom \\nteaching). throughout the last decade, increasingly \\nsophisticated learner, pedagogy, and domain models have been introduced in numerous adaptive tutors to support  \\nthe individualisation of learning. \\nfor example, the italk2learn system\\n16, designed to help \\nyoung students learn about fractions, used a learner model \\nthat included information about the learner’s mathematics \\nknowledge, their cognitive needs, their affective (emotional) \\nstate, the feedback they had received and their responses to that feedback.\\nmodel-based adaptive tutors can include a range of aied \\ntools that:\\n•  model learners’ cognitive and affective states\\n17\\n•  use dialogue to engage the student in socratic learning \\nexperiences, that is learning experiences that involve enquiry and discussion, questioning and answering\\n18\\n•  include open learner models to promote reflection and  \\nself-awareness19\\n•  adopt meta-cognitive scaffolding (for example, by providing dynamic help or using a narrative framework) to increase learner motivation and engagement\\n20\\n•  use social simulation models – for example, to enable language learning students to engage more successfully with speakers of their target language by understanding \\ncultural and social norms\\n21neural networks\\nnetworks of \\ninterconnected \\ndata sets, based on \\na vastly simplified \\nunderstanding \\nof brain neural \\nnetworks.25',\n",
       " 'open ideas at pearson26\\naied can provide intelligent  \\nsupport for collaborative learning\\nresearch over decades has suggested that collaboration, \\nwhether between a pair of students undertaking a project together or a community of students participating in an \\nonline course, can foster higher learning outcomes than \\nlearning alone.\\n22 collaborative learning is effective because  \\nit encourages participants to articulate and justify their thinking, to reflect on other explanations, to resolve \\ndifferences through constructive dialogue, and to build \\nshared knowledge and meaning. collaborative learning can also enhance motivation; if students care about the group, they become more engaged with the task and achieve better \\nlearning outcomes.\\n23\\nhowever, research also suggests that collaboration between \\nlearners does not happen spontaneously.24 for example, \\ngroup members might not have the social interaction skills needed to collaborate effectively. this can be especially \\ndifficult in the context of online collaborations, where \\nparticipants rarely meet in person. \\nthis is where aied can contribute. several approaches have \\nbeen investigated and here we focus on four: adaptive group \\nformation, expert facilitation, virtual agents, and intelligent moderation. \\nadaptive group formation \\nthis uses ai techniques and knowledge about individual \\nparticipants, most often represented in learner models, to form a group best suited for a particular collaborative task. the aim might be to design a grouping of students all \\nat a similar cognitive level and of similar interests, or one \\nwhere the participants bring different but complementary knowledge and skills.\\n25\\nexpert facilitationhere models of effective collaboration – known as ‘collaboration patterns’ – are used to provide interactive \\nsupport to the collaborating students.\\n26 these patterns\\nare either provided by the system authors or mined from \\nprevious collaborations. for example, ai techniques such as \\nmachine learning or markov modelling  have been used to \\nidentify effective collaborative problem-solving strategies. \\nthese can then be used to train systems to recognise when \\nstudents are having trouble understanding the concepts \\nthat they are sharing with each other, or to provide targeted support of the right form at the right time. markov \\nmodelling\\nan approach used \\nin probability \\ntheory to represent \\nrandomly changing \\nsystems.',\n",
       " 'intelligence unleashed27\\nthey can also show students (and their teachers) \\nhow well an individual is contributing to group work, an historically difficult activity to parse and assess.\\n27 \\nintelligent virtual agents\\na third approach involves intelligent virtual agents \\nthat are introduced into the collaborative process.28 \\nthese ai agents might mediate online student interaction, or simply contribute to the dialogues,  \\nby acting as:\\n•    an expert participant (a coach or a tutor)\\n•    a virtual peer (an artificial student at a similar \\ncognitive level to the learner, but one who is capable of introducing novel ideas)\\n•    someone the participants might themselves teach – for example, the artificial student might hold deliberate misconceptions, or provide alternative \\npoints of view to stimulate productive argument \\nor reflection\\n29 \\nintelligent moderation\\nwith large student numbers working in multiple \\ncollaborative groups, it can be impossible for a person to make any sense of the large volume  \\nof data that the participants are generating in  \\ntheir discussions. \\nintelligent moderation uses ai techniques such as \\nmachine learning and shallow text processing  to \\nanalyse and summarise the discussions to enable a \\nhuman tutor to guide the students towards fruitful \\ncollaboration. for example, the system might provide alerts to human tutors to inform them of significant events (such as students going off topic \\nor repeating misconceptions) that may require  \\ntheir intervention or support.\\n30shallow text \\nprocessing\\na method of text \\nanalysis that \\nidentifies – but does \\nnot ‘understand’ – \\nparticular words.',\n",
       " 'open ideas at pearson28\\nintelligent virtual reality to support  \\nlearning in authentic environments\\nartificial intelligence first appeared in a digital game in 1979, \\nwhen the developers of pac-man used a technique known as state machine (transitioning between states depending \\non conditions) to control whether or not a ghost ran towards \\nor away from a player. the ai in most modern digital games builds on this simple approach. as the game-based story unfolds, autonomous non-player characters (agents) take information from both the game and the player and, based on that information, use ai algorithms to determine the most \\nappropriate actions to take. \\nvirtual reality for learning works in a similar way. it provides \\nauthentic immersive experiences (the subjective impression \\nthat one is participating in a realistic experience) that simulate \\nsome aspect of the real world to which the user would not otherwise have access (such as dangerous environments  \\nor somewhere geographically or historically inaccessible).  \\nresearch has shown that giving opportunities for students to \\nexplore, interact with, and manipulate aspects of a simulated \\nworld, perhaps investigating ‘what if’ scenarios, (such as, ‘what if there is a drought?’), enables them to transfer what they have learnt to the real world.\\n31 ',\n",
       " 'intelligence unleashed29\\nfor example, a virtual submarine might allow  \\nthe user to shrink to a microscopic level to \\ninvestigate natural processes that occur under  \\nthe surface of a rock pool, or the student might  \\nbe able to explore a nuclear power plant, ancient rome or the outer planets.\\nvirtual reality becomes ‘intelligent’ when it is \\naugmented with artificial intelligence. ai might be used simply to enhance the virtual world, giving it the ability to interact with and respond to the user’s actions in ways that feel more natural. or, drawing \\non intelligent tutoring systems, ai might also be \\nintegrated to provide on-going intelligent support and guidance to ensure that the learner engages properly with the intended learning objectives \\nwithout becoming confused or overwhelmed.\\nvirtual pedagogical agents might also be included, \\nacting as teachers, learning facilitators, or student peers in collaborative learning ‘quests’. these  \\nagents might provide alternative perspectives,  \\nask questions, and give feedback, all based on a properly specified pedagogical model.\\nmany studies have demonstrated that immersion \\nin intelligent virtual reality can enhance educational outcomes, enabling students to construct their own individual understanding of the world being explored.\\n32 some have also been shown to have \\nthe potential to release what chris dede, a leading learning scientist, calls ‘trapped intelligence’ – that  \\nis, they allow low-achieving students to build their self confidence by shifting their self image from being a poor academic performer to, for example,  \\na successful virtual scientist.\\n33\\n',\n",
       " 'open ideas at pearson 30\\nin addition, intelligent synthetic characters in virtual \\nworlds can play roles in settings that are too dangerous or unpleasant for learners. for example, fearnot is a school-\\nbased intelligent virtual environment that presents bullying \\nincidents in the form of a virtual drama. learners, who have been victims of bullying, play the role of an invisible friend to a character in the drama who is bullied. the learner offers \\nthe character advice about how to behave between episodes \\nin the drama and, in so doing, explores bullying issues and effective coping strategies.\\n34 \\nintelligent virtual reality can also be used for intelligent team \\ntraining during which virtual humans are able to reason about \\nindividual events, carry out actions, and negotiate options, with the aim of guiding human trainees to make similar assessments – for example in peacekeeping scenarios.\\n35\\n...\\ntaken together, these three types of applications have been \\nused to create learning environments that are not just more \\npersonalised, but also more inclusive and engaging. for example, they can provide additional help for learners with special educational needs, motivate learners who cannot \\nattend school, and support disadvantaged populations.\\n36\\naied applications can also be more flexible than the \\nalternatives. many are deployed online, meaning that they can be available on personal and portable devices within,  \\nand beyond, formal educational settings. aied researchers are also exploring the use of mobile devices to deliver adaptive materials for anytime, anywhere, social and collaborative learning (while still monitoring and providing \\nintelligent support as needed).\\n37 \\naied has made great progress, but has barely scratched the surface. there is exciting promise as the existing technologies \\ndevelop, mature, and scale. yet, the aied horizon includes much more than simply ‘more of the same’. aied developers are getting better at recognising how to blend human and \\nmachine intelligence effectively, which means that future  \\naied is poised to make significant strides in a number of \\ncritical areas.\\nlet’s now turn our attention to this horizon.',\n",
       " 'intelligence unleashed 31 intelligence unleashed\\nteachers \\nand aied\\nwe are in no doubt that teachers  \\nneed to be central agents in the  \\nnext phase of aied. in one sense  \\nthis is obvious – it is teachers who  \\nwill be the orchestrators of when,  \\nand how, to use these aied tools. \\nin turn, the aied tools, and the data \\ndriven insights that these tools provide, will empower teachers to decide how best to marshal the \\nvarious resources at their disposal. \\nmore than this, though, teachers \\n– alongside learners and parents – should be central to the design of \\naied tools, and the ways in which they \\nare used. this participatory design methodology will ensure that the messiness of real classrooms is taken \\ninto account and that the tools deliver \\nthe support that educators need – not the support that technologists or designers think they need. teachers who take part in these processes will \\ngain increased technological literacy, \\nnew design skills, and a greater understanding of what aied systems can offer.\\nas mentioned earlier, we predict that \\nthe increased introduction of ai-powered tools will serve as a catalyst for the transformation of the role of \\nthe teacher. aied is well placed to take \\non some of the tasks that we currently expect teachers to do – marking and record keeping, for example. \\nfreedom from routine, time-\\nconsuming tasks will allow teachers  \\nto devote more of their energies  \\nto the creative and very human acts  \\nthat provide the ingenuity and \\nempathy needed to take learning  \\nto the next level.as this transformation takes place, teachers will need to develop new \\nskills (maybe through professional development delivered through  \\nan aied system). specifically they  \\nwill need:\\n•    a sophisticated understanding  \\nof what aied systems can do to \\nenable them to evaluate and make \\nsound value judgements about  \\nnew aied products \\n•    to develop research skills to  \\nallow them to interpret the data \\nprovided by aied technologies, to ask the most useful questions of the data, and to walk students through \\nwhat the data analysis is telling \\nthem (for instance, using open learner models)\\n•    new teamworking and management skills as each teacher will have ai assistants in addition to their usual human teaching assistants, and they \\nwill be responsible for combining \\nand managing these resources  \\nmost effectively\\nmost excitingly, with the evolution of the teacher’s role will also come the evolution of the classroom, as aied tools allow us to realise what it is unrealistic to expect any teacher \\nor lecturer to do alone. for example, \\nmaking the positive impact of one-to-one tutoring available to every child, or realising effective collaborative \\nlearning (a difficult activity to keep on \\ntrack without some form of additional support).',\n",
       " 'the next \\nphase of aiedopen ideas at pearson 32',\n",
       " 'intelligence unleashed 33\\nthe future of aied is inextricably linked to the future of ai. \\nthe increasing consumerisation of ai technologies brings with it a massive increase in the number of people who are \\ndeveloping ai. the pace of innovation and development in \\ngeneral is at its fastest rate ever\\n38 and the current popularity \\nof ai should mean that innovation in aied is a focus of attention for an increasing number of businesses.\\nin this section, we look to the edges of theory and practice  \\nto consider some of the advances we expect to see through \\nthe continued growth of aied, as well as some of the new \\ntechnologies we expect to be developed. some of these will \\nhappen sooner than others, and all can be seen as both opportunities and challenges. having said this, we see these developments in a positive light, and have here focused on conveying the exciting potential that aied has to improve \\neducation for all.\\naied will help learners gain 21st century skills\\nthere is an increasing recognition that so-called 21st century \\nskills are essential for current and future work environments, \\nwith many groups advancing lists (some short and others long!) of the skills people will need to fully engage in employment and society.\\nto take one example, the world economic forum have \\nproposed 16 skills, split across three categories:\\n39\\ncategory helps students \\napproach...related skills\\nfoundational literacies...everyday tasksliteracy\\nnumeracy scientific literacy\\n information \\ncommunication  technology literacy\\nfinancial literacy  cultural and civic \\nliteracy\\ncompetencies ...complex challenges critical thinking and \\nproblem-solving communication \\n collaboration\\ncharacter \\nqualities...changing environmentscuriosity\\ninitiative \\npersistence/gritadaptability leadership\\n social and cultural \\nawareness',\n",
       " '34 open ideas at pearson\\nwe agree with the common wisdom that skills like \\nthese are – and always have been – important, and that they should be part of any approach to lifelong \\nlearning. there are, however, at least two salient \\nchallenges that need to be addressed if we are to realise this agenda:\\n1    we must develop reliable and valid indicators \\nthat will allow us to track learner progress on all the skills and capabilities needed to thrive in the current century – at the level of the individual, the district, and the country. this will need to \\ninclude difficult to measure characteristics such \\nas creativity and curiosity.\\n2    we need a better understanding of the most effective teaching approaches and the learning contexts that allow these skills to be developed.\\naied can help with both.\\nfirst, aied has the tools and techniques to conduct \\nthe fine-grained analysis that allows us to track each learner’s development of skills and capabilities \\nas they interact and learn over time. this tracking \\nof individual learners can then be collated and interpreted as required to provide knowledge about progress at the school, district, and country level. \\nthe increasing range of data capture devices – \\nsuch as biological data, voice recognition, and eye tracking – will enable aied systems to provide new types of evidence for currently difficult to assess \\nskills. for example, a practice-based learning  \\nexperience that incorporates elements of problem \\nsolving or collaboration might be assessed using a combination of data sources including voice recognition (to identify who is doing and saying what \\nin a team activity) and eye tracking (to explore which \\nlearner is focusing on which learning resources at any particular moment in time).\\nsecond, the increasing use of aied systems  \\nwill enable the collection of mass data about  \\nwhich teaching and learning practices work best. \\nthis data will enable us to track learner progress against different teaching approaches and, in turn, \\nwill allow us to develop a dynamic catalogue of the \\nbest teaching practices suited to the development  \\nof different skills and capabilities, in particular the 21st century skills, across a range of environments.\\npractice-based \\nlearning\\npractice-based \\nlearning is learning \\nundertaken, \\ntypically in teams, \\nin real-life contexts \\n(e.g. learning \\nundertaken \\nby healthcare \\nprofessionals in \\nworking hospitals).',\n",
       " '35 intelligence unleashed\\nimportantly, in investigating these practices, we will also \\nbe able to relate learner progress to the contexts in which learning has taken place, and then build context models into \\nour aied systems. already there are fledgling methodologies \\nthat take into account contextual elements such as the physical or virtual space, the people who are available to help, and the learning tools available such as the curriculum, \\ntechnology, or books.\\n40 \\nover time, these models will enable us to identify the best teaching approaches for different contexts. and, they \\nwill help us identify how contextual factors (such as the combinations of technology, teachers and the environment) can be adjusted to improve the efficacy of particular teaching, \\napproaches – insights that will help students gain 21st \\ncentury skills as well as other types of knowledge.\\naied will support a \\nrenaissance in assessment \\nwe echo the assertion made by peter hill and michael barber \\nin preparing for a renaissance in assessment, that of the three core components of learning (curriculum, learning and \\nteaching, and assessment), it is in many ways assessment that \\nis holding us back.\\n41 we also agree with the assertion that \\ntechnology holds part of the solution. in the near future,  \\nwe predict that aied will contribute to improving assessment \\nin three key ways.\\naied will provide just-in-time \\nassessments to shape learning\\nthe continued and growing use of technologies in education \\nwill allow increasing amounts of data to be collected about teachers and learners. this so called ‘big data’ is already being studied using learning analytics  to recognise data patterns \\nof potential educational interest. for example, analytics have \\nbeen used with high levels of accuracy to predict when a  \\nstudent is likely to fail an assessment or ‘drop-out’ from an \\nonline course. \\nsoon the sophistication of these learning analytics will be \\ncomplemented by ai techniques to provide just-in-time information about learner successes, challenges, and needs that can then be used to shape the learning experience itself. for example, aied will enable learning analytics to identify \\nchanges in learner confidence and motivation while learning  \\na foreign language, say, or a tricky equation. learning \\nanalytics\\nlearning analytics \\nare used to find \\npatterns in large \\ndata sets, like those \\ngenerated by online \\nlearning systems, \\nto enable modelling \\nand prediction.',\n",
       " 'open ideas at pearson 36\\nthis information can then be used to provide timely \\ninterventions to help students – which could be in the form of technology-assisted support, individual attention from a \\nteacher, or some combination of the two.\\naied will provide new insights into how learning  \\nis progressing\\nin addition to timeliness, the data gleaned from digital \\nteaching and learning experiences will give us new insights that cannot be ascertained from existing assessments.  \\nfor example, as well as identifying whether or not a learner gave the correct answer, datasets could be analysed to help \\nteachers understand how the learner arrived at their answer. \\nthe data might also help us better understand cognitive processes such as remembering and forgetting, and the fundamental impact that these have on learning and student \\noutcomes. aied analysis might also identify if and when a \\nstudent is confused, bored, or frustrated, to help teachers understand and enhance a learner’s emotional readiness  \\nfor learning.\\naied will help us move beyond ‘stop-and-test’\\nas documented by kristen dicerbo and john behrens in impacts of the digital ocean  on education, the models and \\ntechniques developed by aied researchers over the last 25 \\nyears have resulted in an ever rising ocean of digital data \\non learning and teaching, telling us much about the data we need to collect in order to assess students while they learn .\\n42 \\nwith ongoing aied analysis of a student’s learning  \\nactivities, there will be no need for the stop-and-test approach that characterises many current assessments. instead of traditional assessments that rely upon  \\nevaluating small samples of what a student has been  \\ntaught, aied-driven assessments will be built into  \\nmeaningful learning activities, perhaps a game or a collaborative project, and will assess all of the learning  \\n(and teaching) that takes place, as it happens.\\n43',\n",
       " 'intelligence unleashed 37\\naied will embody new insights \\nfrom the learning sciences\\n \\nai and aied have always been interdisciplinary fields. moving forward, aied will continue to leverage new insights in \\ndisciplines such as psychology and educational neuroscience \\nto better understand the learning process, and so build more accurate models that are better able to predict – and influence – a learner’s progress, motivation, and perseverance. \\nan example from education neuroscience\\none example of the way that neuroscience can inform \\neducation and the design of aied systems can be found in the work of paul howard-jones, professor of neuroscience and education at the university of bristol. his work suggests \\nthat learning can be improved when it is linked to uncertain \\nrewards\\n44 – that is, situations in which a learner knows that \\na reward may be given upon their completion of a task, but there is no certainty that the reward will appear on \\nevery occasion. this is counter-intuitive to typical education \\npractices where rewards are consistently related to success. \\nthe use of uncertain rewards is much more common in the \\nworld of computer games, hence the current interest in the \\ndesign of educational games that use the motivational impact of uncertain rewards to engage learners and to enhance their learning. the addition of aied techniques to the design of these educational games would enable, for example, the \\nprovision of uncertain rewards to be calibrated to a learner’s \\nindividual reaction to a given level of uncertainty. \\nan example from psychology\\nfor several years now psychologists, most notably carol \\ndweck of stanford university, have been exploring the role of ‘mindsets’ in learning.\\n45 they make a distinction between \\nlearners who believe that intelligence does not change over time (a ‘fixed mindset’) and those who believe that their \\nabilities can be developed (a ‘growth mindset’). learners with \\na growth mindset see challenges as things to be overcome; they persist and value effort more, which leads to them enjoying more success as learners. there is increasing \\nevidence that a growth mindset can be taught and that \\nchanging students’ mindsets can have a substantial impact  \\non their grades and achievement test scores.\\n46\\nthere is already a role for technology when it comes to \\nhelping learners to develop a growth mindset; indeed  \\ncarol dweck’s team have developed brainology, a piece  \\nof software to provide support and content for promoting \\na growth mindset.47 the addition of ai to the technology ',\n",
       " 'open ideas at pearson 38\\nwould bring greater possibilities. for example, with ai \\nthe system could adapt to a learner’s goal orientation or mindset, or scaffold learners towards a growth mindset.\\n48 \\nmore sophisticated learner models would be able to capture learners’ mindsets, including how these change over time, \\nand adapt teaching accordingly. this might include providing \\ntargeted feedback to teachers to enable them to support each learner to develop a growth mindset in the most effective way. \\naied will give us lifelong learning partners \\nit is said that in ancient china each royal prince studied  \\nwith a companion as well as a royal teacher. perhaps the chinese emperors knew that their children would learn  \\nmore effectively with another; it is certainly the belief in  \\nmuch contemporary psychology.\\n49\\nearly aied research in the 1980s brought this ancient story to life through the development of learning companion systems. these systems provided each learner with a \\ncollaborative computer-based learning companion (or \\ncompanions). it was the role of the companion to use collaboration and competition to stimulate student  \\nlearning. the companion could also act as a student for  \\nthe human learner to tutor, and in so doing the student learns by teaching. the computer-based teacher offered examples and guidance to human and computer student alike and determined the order and content of the topics  \\nto be tackled.\\n50 \\nthe next generation of learning companions will offer  \\nhuge potential for future teaching and learning. there are  \\nno technical barriers to the development of learning companions that can accompany and support individual learners throughout their studies – in and beyond school. \\nthese lifelong learning companions could be based in the \\ncloud, accessible via a multiplicity of devices, and be  \\noperated offline as needed.\\nrather than teaching all subject areas, the learning \\ncompanion might call in specialist aied systems or humans \\nwith expertise in the particular subject area required by the learner. in addition, the companion could focus on helping learners to become better at learning through developing a \\ngrowth mindset or an impressive array of 21st century skills. \\nand because this type of system can help all learners to access learning resources that are optimal for their needs, it \\nwill be suitable for struggling learners as well as those who \\nare high achieving. ',\n",
       " 'the ethics of ai \\nand aied\\nai development is accelerating, \\npermeating every aspect of our lives. \\nthe question is, are we prepared  \\nto let that happen without proper \\ndebate or control? the ethics of \\nai, as written about extensively \\nby the oxford philosopher nick \\nbostrum, need especially careful \\nattention: “responsibility, transparency, \\nauditability, incorruptibility, \\npredictability (...); all criteria that must be considered in an algorithm \\nintended to replace human  \\njudgement of social functions”.\\n51\\nfor example, what happens if ai ‘goes \\nwrong’ (see, for example, the role of \\nalgorithms in the 2010 financial ‘flash \\ncrash’)?52 who is responsible, the \\nend-user or the programmer? what \\nwill happen when an autonomous \\nvehicle is involved in a traffic accident? \\nwill it be possible to understand how \\nit arrived at its decision so that it \\nmight be corrected to prevent future \\nproblems? already this can be difficult \\nif the ai uses neural networks. and \\nare ais open to manipulation? we are \\nall too aware of the consequences of \\ncomputer hacking; what might happen \\nif an ai were developed or modified for \\ncriminal purposes?\\nfor aied, these ethical questions \\nare equally, if not more, acute, and \\nquestions need to be identified and \\naddressed. for example, we know that \\nthe sharing of data is essential to the \\nintegration of aied systems, and that \\nsharing of anonymised data has the \\npotential to move the field forward by leaps and bounds by cutting back \\non wasteful duplicative efforts. but \\nthis type of sharing introduces a host \\nof problems and questions, from \\nindividual privacy to proprietary intellectual property concerns. indeed, \\nthe growing volume and diversity of \\ndata generated by aied systems only \\nserves to double-down on the already \\nexisting ethical concerns about what \\nhappens to education data. what \\nare the implications of the methods, \\ntechnologies, and ideologies that \\nunderpin the generation, analysis, \\ninterpretation, and use of aied system \\ndata? who owns the data, who can \\nuse it, for what purposes, and who is \\nultimately accountable?\\nanother consideration is the way \\nin which aied systems aim to effect \\nlasting behavioural change on \\ntheir users. for example, a system \\nmay make recommendations, use \\npersuasion, or offer feedback to \\nengender personal relationships \\nbetween humans and machines. \\nbehaviour change is certainly \\none intervention that can be truly \\ntransformative, but it is again not \\nwithout serious ethical considerations.\\nother concerns have been raised \\nwith regard to learning companions. \\nalthough they are intended to support \\nlearners throughout their lives, there \\nare fears that a companion that \\n‘followed’ you would instead result  \\nin the perpetual recording of  \\nlearner failures to the detriment  \\nof future progress. \\nsimilarly, the concept of an aied \\nteaching assistant raises worries \\nthat the technology will be used \\nas a classroom spy to record and \\nreport any perceived suboptimal \\nperformance by the teacher. \\nfinally, we have a new responsibility \\nto ensure that society as a whole has \\nsufficient aied literacy – that is, enough \\nto ensure that we use these new \\ntechnologies appropriately, effectively, \\nand ethically. intelligence unleashed 39',\n",
       " 'open ideas at pearson 40\\naied and the \\nphysical world\\nfor some, the word ‘artificial’ in aied \\ncan give the sense that the technology \\nis somehow removed from our real, \\nphysical lives. we have made the \\nargument here that aied is at its  \\ncore, a very real, very human \\nendeavour. moving forward, aied  \\nwill increasingly draw on our physical \\nenvironments and our physical beings \\n– and so make these integral to the \\nlearning process.\\naied will augment our \\nphysical landscape\\naugmented reality systems (ar) will \\ngo one step beyond intelligent virtual \\nreality systems by enabling learners \\nand teachers to experience and \\ninteract differently with the physical \\nworld around them. ar technology  \\ncan display an overlay of information \\nabout a person’s environment, \\nallowing formal classroom content to \\noverlay the learner’s physical reality. \\nfor example, the age, architecture \\nstyle, or heat efficiency of the buildings \\naround a learner could be visualised  \\nas they move around the world. \\nwe have already seen how existing \\naied systems feature socially and \\nculturally intelligent avatars that \\nguide and support learners in virtual \\nenvironments. the addition of aied to \\nar systems will allow for personalised, \\nadaptive educational experiences \\nwith virtual mentors or tutors guiding \\nstudents through field trips, leaving \\nteachers to concentrate on those \\nlearners whose needs are greatest. \\n aied will connect to the \\ninternet of things\\nthe network of objects or ‘things’ \\nwith embedded computing systems, \\nsensors, and network connectivity \\nare referred to collectively as the \\n‘internet of things’ (iot). iot permits \\nany network-enabled objects to \\nbe interconnected with any other network-enabled object or machine. \\nthis opens up new possibilities for \\naied systems, for example to support \\nlearners developing motor skills \\nthat need consistent and extended \\npractice, such as dancing, playing a \\nmusical instrument, or even learning  \\nsurgical procedures.\\naied will be attuned to how we \\nfeel and how we move\\nrecent research supports the idea \\nthat learning is significantly influenced \\nby how we feel (our affect), and how \\nwe move.\\n53 these insights suggest \\nthat learning technologies can be \\nimproved by taking these additional inputs into account. already, learner \\nmodels are no longer limited solely to \\nrepresenting and recording learners’ \\nacademic progress,\\n54 and sensors that \\ncan be worn in clothing or strapped to \\nbody parts (e.g. the fitbit) have already \\nbeen developed. \\naied systems of the future will \\nincreasingly support the whole  \\nlearner through sophisticated  \\nmodels that also capture data about \\na learner’s emotional and physical \\nstate. these enriched models will \\nfurther contribute to what is known \\nabout how we learn, and will provide \\nindividual teachers with real time \\ninformation about their students’ \\nphysical and emotional well-being as \\nwell as their cognitive development, \\nallowing for appropriate and timely \\ninterventions in all the areas that \\nmatter to learning.',\n",
       " 'taking it to \\nthe next level: how aied can  \\nhelp us respond to the biggest unsolved issues  \\nin education41 intelligence unleashed',\n",
       " 'open ideas at pearson 42\\npolicy makers often call them ‘wicked-issues’ – social problems that  \\nare complex, connected, and seemingly resistant to intervention.  \\nsadly, education does not lack for its fair share. \\nif aied is to attract the attention and investment that we believe it deserves, \\nthen it is only right to ask how aied can be realistically applied to address these unsolved issues. here we take two big issues – achievement gaps,  \\nand teacher development, retention and shortages – and show how aied can provide a response.\\ntackling achievement gaps\\ncurrently, we are failing to meet the needs of all learners. the gap between \\nthose who achieve the most and those who achieve the least is a challenge \\nthat teachers, school leaders, administrators, and government officials face every day, in every country. globally, students from poorer backgrounds perform worse than students from richer backgrounds.\\n55 the results of this \\nachievement gap impacts upon a country’s economy as well as the social well-being of their population.\\n56 the reasons behind the achievement gaps \\nin different countries vary, but the fact remains that not all learners are achieving their potential at school.\\nwe take it as essential that all children should have at least basic skills \\n(reading, writing, and mathematics), and yet, across the world, we are not there. for example, in the uk, nine million working age adults have low basic \\nskills in either literacy, numeracy, or both. to make this real, this means that \\nthese adults will struggle with simple everyday tasks such as assessing how much fuel is left in their vehicle by looking at the gauge, or understanding the instructions on over–the-counter medications.\\n57 \\nwe have already shown some of the ways in which aied can offer a new \\nset of tools for addressing this challenge. for example, students who need \\nextra help can be offered one-to-one tutoring from adaptive aied tutors, both at school and at home, to improve their levels of success. increased collaboration between education neuroscience and aied developers will \\nprovide technologies that can offer better information, and support specific \\nlearning difficulties that might be standing in the way of a child’s progress. moreover, and important to addressing the socioeconomic gap, these aied systems will scale broadly as the reduction in their cost makes them increasingly affordable to schools and school systems. \\naied could also offer needed support before a learner begins formal \\neducation, perhaps even before they are born. there is strong evidence that the first five years of a child’s life have a large influence on that child’s \\neducational attainment.\\n58 unfortunately, we see evidence of poor school \\nreadiness for many students, particularly children from low-income \\nfamilies. this means they enter school at a significant disadvantage to their \\nwealthier counterparts in areas including language, early maths and science \\nunderstanding, physical well being and motor development, and social and emotional development. this can mean that a child may enter school unable to identify numbers, interact with peers, or use the bathroom on their own.\\n59',\n",
       " '43 intelligence unleashed\\nlow-income parents may also have had limited education \\nopportunities, meaning they may face serious challenges in providing at-home learning support to their children. aied systems can provide \\ntailored support to parents in the same way that they can for teachers \\nand students, improving education and outcomes for both parents and their children.\\nimagine, for example, providing parents with aied assistants that could \\nadvise them about strategies for talking to their child, sharing songs, and enjoying books. this could enable all parents to provide the right sort of support in those all important early years. for parents who have problems with numeracy or literacy, the aied assistant could help \\nboost these skills too. \\nto avoid what’s known as the matthew effect\\n60 – the all too common \\nsituation in which learners who are already privileged gain the most \\nfrom new resources, further exacerbating existing inequalities –  \\naied assistants should be available for all parents, with additional support provided to those parents who need it most. this will  \\nhelp ensure that all parents are well informed, supported, and  \\nengaged in their child’s education.\\ndeveloping teacher expertise, addressing teacher retention, \\nand providing respite where teacher shortages are acuteteacher expertise is key to learner attainment, but high-quality continuous teacher development has significant costs, both in terms \\nof time and money. in the same way that aied systems can offer \\none-to-one or group tutoring to students, so it can do the same on an ongoing basis for teachers. this training can be designed to meet the specific needs of the teacher, be completed wherever and whenever \\nthey like, and can be used to access a community of like-minded \\nprofessionals who give advice and guidance. \\naied could also help teachers find and share the best teaching \\nresources. imagine, for example, navigating a popular tool like tes\\n61  \\nor teachers pay teachers62 with your own aied assistant who knows \\nthe resources you have found useful in the past, the details of your students, and the teaching schemes and curricula used in your \\ninstitution. your aied assistant could accurately predict the resources \\nthat would work best for you and your students as well as uploading the resources you have created and successfully used.\\nintelligent support for teachers could also help address the issue of \\nteacher retention where we see many skilled professionals leaving the profession due to ‘burnout’.\\n63 now that a cloud-based intelligent \\nassistant for every teacher is a realistic possibility, we can provide support to reduce teacher stress and workload. the teacher’s aied \\nassistant will be available through any and all of the teacher’s devices \\nso that it can be deployed as needed wherever the teacher is working. ',\n",
       " 'open ideas at pearson 44\\noutside the classroom, the assistant could greatly reduce \\nthe amount of teacher time needed for grading. inside the classroom, the teacher could give the assistant the task \\nof offering one-to-one tutoring to a group of children who \\nare struggling to understand fractions. the assistant would maintain a learner model for each student and would use  \\nthis to identify suitable teaching materials. this would free  \\nup the teacher to turn their attention to an individual student, or work with a group on a different topic.  in many parts of the world acute teacher shortages present enormous challenges. for example, 33 countries do not \\ncurrently, and will not have, enough teachers to provide  \\nevery child with a primary education by 2030. in fact, the \\nworld will need to recruit 25.8 million schoolteachers to achieve this goal.\\n64\\nalthough the most effective implementations of aied will deploy it alongside the expertise and empathy that is peculiarly human, in some instances this simply would not be \\npossible, at least in the short-term. this means we will need \\nto rely on technology to make available high-quality learning experiences to places where this is currently lacking.\\none illustrative example is the work of sugatra mitra, who \\nfamously provided children in an indian slum with free access to a computer placed in a wall between his office and the public space. he christened this experiment the ‘hole in the wall’, the goal of which was to understand if children could \\nform effective self-organised learning groups, in this case \\naround learning how to use a computer. \\nthis work then led to his creation of school in the cloud, “a \\ncreative online space where children from all over the world \\ncan gather to answer ‘big questions’, share knowledge and benefit from help and guidance from online educators.”\\n65\\nnow, imagine if we could add aied to technologies like these. for example, aied could provide the intelligent support to aid learners in their collaboration, it could provide open learner \\nmodels to help volunteer online educators understand the \\nright support that a given learner might need, or it could intelligently pair the most appropriate volunteer with the  \\nright student.\\nthis is not to disguise the urgent need to make high-quality \\neducator expertise available in the parts of the world that currently lack it. far from it. however, where there is a moral urgency to use technology to provide high-quality learning \\nexperiences, we would be remiss to not add in aied.\\n ',\n",
       " 'intelligence unleashed 45\\nbringing it  \\nall together: the continuing  \\nrace between education and technology\\n66',\n",
       " '46 open ideas at pearson\\nwe do not lack for predictions of how the existing mix of jobs in the \\neconomy will be upended by the steady rise of the robots, and ever smarter algorithms deployed on ever bigger data-sets. however, the \\nimplications of this for learning has received relatively little sustained \\nand serious attention. \\nthis is not surprising given that the debate, to date, is understandably \\nbeing led by economists rather than educators. it also reflects gaps in \\nexisting quantitative research which focus largely on job categories, rather than skills, and on the roles likely to be automated, rather than those likely to be created.\\nthroughout this paper we have set out the aied pieces that could \\n– with further development and smart real-world testing – offer a proportionate response to the new innovation imperative in education. simply stated the imperative is this: as humans live and work alongside \\nincreasingly smart machines, our education systems will need to \\nachieve at levels that none have managed to date.\\nin our minds, this imperative trumps even the significant impacts \\nof globalisation, and brings existing issues in education, such as \\nachievement gaps, into ever sharper relief.\\nto summarise the argument so far we thought it would be useful to \\ndo two things. first, map the catalogue of aied tools that can help \\nus address this enormous challenge by supporting the next phase \\nof education system reform. and, second, set out the ways in which aied can be deployed to help us understand how successfully we are realising this reform agenda.\\nif you like, just as learners need timely and actionable feedback, so  \\ntoo do our education systems as they prepare learners for the  \\nfuture economy.before we go on to this, however, it is important to remind ourselves \\nthat the ‘purposes’ of education are wider than getting a job. for example, a list would include discovering your passions, experiencing the flow and satisfaction of good work, and being a moral person with the capacity and will to affect positive change in your family, \\ncommunity, country, and the world.\\nhaving said this, getting a good job is consistent with the list above. \\nindeed, it is one of the central reasons why governments invest  \\nin education. \\nthe table opposite shows our mapping of the tools of aied against the \\nlikely requirements of the jobs market in 15 years’ time.',\n",
       " '47 intelligence unleashed\\nin 15 years  \\ntime...the implication for \\nlearning...how aied can help...\\nmany of the new \\njobs created \\nwill be much \\nmore cognitively \\ndemanding than \\nthose currently \\navailable students will need to \\nlearn as efficiently and \\neffectively as possiblegive every learner their own  \\npersonal tutor, in every subject\\nprovide every teacher with their  \\nown ai teaching assistant\\naied to deliver timely, smarter,  \\nteacher professional development \\naied tools that help every parent \\nsupport their child’s learning \\nwe will need to seriously \\nattend to the non-\\ncognitive factors that \\ninfluence learning –  \\ngrit, tenacity and \\nperseverance; affect; \\n‘mindset’aied tools that embody new insights  \\nfrom neuroscience or psychology\\nmaking available new insights into how \\nlearning is going for an individual and the \\nfactors that make it more likely to occur\\nin light of that, providing the right support, \\nat the right time, to keep learning on track\\nstudents will need to \\nachieve higher-order  \\nskills – e.g. problem \\nsolving – alongside \\n‘knowing what’intelligent virtual reality to allow learners \\nto be supported to learn in authentic \\nenvironments – and to transfer that \\nlearning back to the real world\\nsocial skills will be \\nwhere humans \\ncontinue to excelstudents need to be \\neffective collaborative \\nproblem solvers and makers, able to build on \\nothers’ ideas and extend \\nand sensitively critique an argumentintelligent support for collaborative learning\\nthe ability to get on with \\nothers, to empathise \\nand create a human \\nconnection, will continue \\nto be valued aied techniques to help us understand \\nbetter how to deliver a wider variety  \\nof attributes, and how well a learner  \\nis acquiring them\\nwe will need to \\nre-skill large parts \\nof the current \\nworkforce – in \\nessence, creating  \\na learning societywe will need new ways of \\nequipping adult learners \\nwith new skills – more \\nfrequently, quickly, \\nand effectivelyaied tools that support learners to become \\neffective, self-regulated learners for lifelong \\nlearning\\nlifelong learning companions to advise, \\nrecommend, and track learning\\nmore flexible learning environments, \\nallowing learners to learn at a time  \\nand a place that works best for themusing aied to effect education system reform',\n",
       " 'open ideas at pearson 48\\nwe will need to do all this without a significant uplift in the \\ncurrent investment we make in learning. with the steady application of moore’s law , alongside wise investment, there is \\nevery reason to believe that the cost of aied applications will diminish overtime, allowing this potential to be realised at a price that is affordable within current spending parameters.\\nusing aied to measure education system reform\\nonce we put the tools of aied in place as described above, we will have new and powerful ways to measure system-level achievement. through the implementation of sensible common data standards and data sharing requirements,  \\naied will be able to provide analysis about teaching and learning at every level, whether that is a particular subject, class, college, district, or country. this will mean that  \\nevidence about country performance will be available from \\naied analysis, calling into question the need for international \\ntesting such as pisa and timms, at least in their current form.\\n67\\nwith this information available, system leaders and strategists will need to develop fresh skills to probe the data and establish the potential causes of any underperformance,  \\nand the most likely solutions. for example, aied could produce the school level data analysis that will indicate in real-time when a school is experiencing problems. a team of experts could then be called in to determine how these \\nproblems can be quickly resolved.\\neducation systems will need to be nimble to take advantage \\nof the rich real-time systems level analysis that will be continuously available. synergistically, it may be aied systems \\nthat provide the scaffolding to enable leaders and policy \\nmakers to develop these new skills and abilities.\\n...\\nthe view we have sketched out, that aied will play a critical \\nrole in the next phase of education system reform, will not happen by chance. this takes us to the final section of this paper: the practical things that need to be done now for the \\nintelligence of aied to be unleashed.moore’s law\\na computing \\nterm, established \\nby gordon moore \\naround 1970, \\nwhich states \\nthat processor \\nspeeds, or overall \\nprocessing power \\nfor computers,  \\nwill double every \\ntwo years.',\n",
       " 'intelligence unleashed 49\\nrecommendations  \\nto help us unleash intelligence',\n",
       " 'open ideas at pearson 50\\nin alive in the swamp68, michael fullan and katelyn donnelly \\ndescribe three powerful forces that must be combined if \\nwe are to deliver on the promise of technology to catapult \\nlearning dramatically forward. one is pedagogy, or the \\nscience of how we teach and learn; the second is technology itself, which we have said a great deal about already; and the final component is system change, or our understanding of \\nhow to deliver change so that it has a positive impact on each \\nand every learner.\\nthe future ability of aied to tackle real-life challenges in \\neducation depends on how we attend to each of these three \\ndimensions – that is: (i) we need intelligent technologies that \\nembody what we know about great teaching and learning in (ii) enticing consumer grade products, which (iii) are then used effectively in real-life settings that combine the best of human \\nand machine.\\nhow does aied currently fare against these dimensions?  \\nand, more importantly, what needs to be done to unleash  \\nthe full intelligence of aied?\\nlearner, \\nparent, \\nteacher\\nsystem  \\nchangetechnologypedagogy',\n",
       " 'intelligence unleashed 51\\npedagogy\\naied research has, to date, mainly \\ntackled the low-hanging fruit of education – for example, learning in \\nhighly structured domains such as \\nintroductory mathematics or physics, or applying ai techniques on highly structured datasets such as university \\nadministration systems.\\nthese gains are essential but they  \\nare not enough. if we are to bring about  \\na step-change in the breadth and  \\nquality of learning for all learners,  \\nif we are to tackle the persistent and \\nunsolved challenges of learning in the 21st century, funders and researchers \\nneed to go deeper and wider.\\nin short, aied needs to begin with the \\npedagogy and be more ambitious!\\nrecommendations\\n•    do not get seduced by the \\ntechnology, start with the learning.\\n•    focus existing aied funding on the \\nareas that are likely to deliver the \\nstep-changes in learning that will \\nmake a real difference. \\n•    move beyond the disjointed, un-prioritised and siloed approaches  \\nthat characterise the current aied funding landscape.\\n•    scope out a series of ambitious challenge prizes that begin with insights from the learning sciences \\nand educational practice (see \\noverleaf).technology\\naied is currently something of a cottage industry – research and development takes place in small pockets and at \\nmodest scale, mostly by researchers \\nwith limited funding and without commercial partnerships. the result is that many of the applications that are \\ndeveloped never move beyond the \\nprototype stage, at which point much  \\nof what has been learnt is lost.\\nthe solution is not to funnel money into \\nthe development of a single monolithic \\naied system that tackles every subject, and every possible learning scenario. \\ninstead, success will lie in the \\ndevelopment of a multitude of individual aied components that specialise in a particular expertise: for example, a subject area or a specific learner need. \\nto realise this means putting in \\nplace the structures, incentives, and funding that will allow an ecosystem \\nof innovation and collaboration to be \\ncreated around aied.\\nrecommendations\\n•    develop the infrastructure that \\nenables iterative innovation, and  \\nless re-invention, in aied (for example, \\napis, shared data standards, and \\nshared learner models).\\n•    create smart demand for aied \\ntechnologies. for example, \\ngovernments and philanthropists could guarantee a market for aied solutions that have been shown \\nto work in real life settings. this \\nwould unlock needed collaborations between aied researchers and commercial entities.\\n•    found a darpa for education that  \\nwill accelerate the transition of aied tools from the lab into real-world use  \\n(see overleaf).',\n",
       " '52 open ideas at pearson\\nlearning from \\nthe approach that \\njump-started \\ndriverless cars  \\nin 2004, the authors levy and \\nmurnane famously wrote that \\n“executing a left turn against  \\noncoming traffic involves so many \\nfactors that it is hard to imagine \\ndiscovering the set of rules that can \\nreplicate a driver’s behavior”.69\\nin the same year, the us defense \\nadvanced research projects agency \\n(darpa) offered $1m for the team that \\ndeveloped a self-driving car that could \\nnavigate a 142-mile route. for this first \\nprize, no team was successful.\\nhowever, just one year later (when the \\nprize money was doubled) five vehicles \\ncompleted the course. the winning \\nteam was led by stanford university’s \\nsebastian thrun, who went on to  \\nlead google’s autonomous vehicles \\nteam and, when there, began \\n‘hoovering up’ the best engineers  \\nfrom the darpa challenges.similarly, we believe there would be \\nvalue in a suite of well-funded, global \\nchallenge prizes that pose complex \\nlearning problems, and then reward \\nthose who provide the most exciting \\nand effective aied solutions.\\nit’s not difficult to create a list of grand \\nchallenges that could form the basis \\nfor such an approach – for example, \\ngaps in student achievement, 21st \\ncentury skills or even preparing \\nstudents for jobs that do not yet exist.\\nalthough the xprize foundation \\nare currently running two ‘grand \\nchallenges’ in learning – a $7m \\ncompetition to help adult learners \\nwho struggle with literacy, and a $15m \\ncompetition to empower children to \\ntake control of their own learning – \\nneither are specifically encouraging \\nthe development of aied based \\nsolutions. in short, there is a big gap \\nto be filled.\\nmoreover, sensible challenge prizes \\nin this area should be as much about \\nconsciousness-raising and movement \\nbuilding as they are about the \\nresulting solutions. after all, there\\nis still a lot of work to be done to \\nconvey the usefulness of aied to \\nparents, policy-makers, educators,  \\nand learners.\\njust such an approach has been taken \\nby the uk innovation agency nesta, \\nwho created huge media interest \\naround their £10m longitude prize \\nwhich (as a result of a public vote) was eventually focused on the urgent \\nproblem of global antibiotic resistance.',\n",
       " 'intelligence unleashed 53\\nlearning from \\ndarpa \\nin the us defense advanced research \\nprojects agency (darpa) model the best talents in diverse fields conduct \\nbasic research in order to solve \\nreal-world problems that are both ambitious and relevant. the goals  \\nare clear, but how you get there is not yet known.\\ncreating similar centres of \\nindependent interdisciplinary expertise \\nin aied, funded long term and focused on delivering real-world capabilities, would allow us to cross the chasm of basic to applied research, and provide \\nthe long-term funding and ambition \\nthat is needed.\\na fundamental goal for these agencies \\nshould be creating the technical \\ninfrastructure that allows for the development of an ecosystem of aied innovation. this could include standards for interoperability that \\nenable researchers and developers  \\nto share and build upon each  \\nothers’ work.\\nthey should also look at developing \\ncapabilities that can be re-applied in multiple aied applications. for instance, at the moment each and every aied application has to develop \\nits own learner model, which can take \\nup to a year of effort. developing a learner model that can be called on by separate applications would head-\\noff duplicated effort and allow the \\ncreation of bigger data sets.these, in turn, would enable deep learning techniques to extend and \\nrefine the learner model so that it is \\nuseful for an increasing number of learner types and contexts.\\non a related note, it is striking that \\nsome of the most ‘successful’ uses of aied have been developed by the us military. for example, america’s army is an intelligent virtual learning \\nenvironment which uses an ai-\\ndriven, first-person shooter, digital-game format to allow young people to experience virtual soldiering. it \\nhas been used successfully since \\n2002 both for recruiting and as a pedagogically-robust and immersive training tool.\\nsimilarly, darpa have developed a \\ndigital tutor to allow navy it workers to develop the skills to solve complex it problems. it has been reported \\nto be more effective than traditional \\nclassroom learning.\\n70\\nimagine what we might see if we were to put the same effort into improving our schools, universities, \\nand community colleges with properly \\nresearched and comprehensively evaluated aied.',\n",
       " 'open ideas at pearson 54\\nsystem change\\naied will have to function in blended learning  \\nspaces where digital technologies and traditional \\nclassroom activities complement each other. \\nrealising this means addressing the ‘messiness’  \\nof real classrooms, universities, or workplace-\\nlearning environments, and involving teachers  \\nand learners in the co-design of aied so that  \\nour diagram instead looks like this: \\nlearner, \\nparent, \\nteacher\\nsystem  \\nchangetechnologypedagogy\\nhowever, too little attention has been given to designing and describing how aied concretely fits within the lived experience of real learners and \\neducators. ',\n",
       " 'there has been even less attention given to \\nproviding the right professional support to allow \\neducators to realise these re-designed models  \\nof learning.\\nwe also need much better evidence of what works \\nin aied when it is implemented in real classrooms, \\nand universities – after all, how can we ask aied to \\ntackle the big problems in education, or system \\nowners to take aied seriously, if we do not also \\nprovide the means to allow us to establish  \\nwhether the proposed solutions work?\\nrecommendations\\n•    involve teachers, students, and parents to ensure \\nthat future aied systems meet their needs (a \\nparticipatory design process that will lead to better \\naied products, to teachers more knowledgeable \\nabout the processes of learning, and to more \\nsuccessful learners).\\n•   take the next step to iterate and intelligently \\nevaluate aied applications in real world contexts.\\n•   develop data standards that prioritise both the \\nsharing of data and the ethics underlying data use.\\n...\\nwe do not underestimate the new-thinking, \\ninevitable wrong-turns, and effort required to \\nrealise these recommendations. however, if we \\nare to properly unleash the intelligence of aied, we \\nmust do things differently - via new collaborations, \\nsensible funding, and (always) a keen eye on the \\npedagogy. the potential prize is too great to act \\notherwise. 55 intelligence unleashed',\n",
       " 'open ideas at pearson\\n1  (2006, july 26). ai set to exceed human brain power. \\nretrieved from http://www.cnn.com\\n2 (2005). ode: the oxford dictionary of english \\n(oxford dictionaries online). oxford: oxford \\nuniversity press. and russell, s. j., norvig, p.,  \\n& davis, e. artificial intelligence: a modern approach.   \\nupper saddle river: prentice hall.\\n3 with some systems, known as ‘robo advisors’, \\nalgorithms create an investment portfolio suited \\nto an investor’s individual profile (including, for \\nexample, their investment aims and their personal \\nattitude to risk) and then can manage that portfolio, \\nmaking independent decisions, on a daily basis. \\nretrieved from http://www.forbes.com/sites/\\nrobertberger/2015/02/05/7-robo-advisors-that-\\nmake-investing-effortless/#1e029bcf7e48  \\n4 bennett, c. c., & hauser, k. (2013). “artificial \\nintelligence framework for simulating clinical \\ndecision-making: a markov decision process \\napproach”. artificial intelligence in medicine.  57(1),9–\\n19.\\n5 retrieved from https://openai.com/blog/\\nintroducing-openai/\\n6 vinge, v. (1993). vernor vinge on the singularity. \\npresented at the vision-21 symposium sponsored \\nby nasa lewis research center and the ohio \\naerospace institute.\\n7 hawking, s., russell, s., tegmark, m., & wilczek,  \\nf. (2014). transcendence looks at the implications \\nof artificial intelligence - but are we taking ai \\nseriously enough? retrieved from http://www.\\nindependent.co.uk/news/science/stephen-hawking-\\ntranscendence-looks-at-the-implications-of-\\nartificial-intelligence--but-are-we-taking-ai-seriously-\\nenough-9313474.html \\n8  vinge, v. (1993). vernor vinge on the singularity. \\npresented at the vision-21 symposium sponsored \\nby nasa lewis research center and the ohio \\naerospace institute.\\n9  frey, c. b., osborne, m. a. (2013). the future \\nof employment: how susceptible are jobs to \\ncomputerisation.\\n10  autor, d. and dorn, d. (2013). “the growth of \\nlow-skill service jobs and the polarization of \\nthe us labor market.” american economic review \\n103(5): 1553–1597. http://dx.doi.org/10.1257/\\naer.103.5.1553\\n11 goldin, c. & katz, l. f. (2010). the race between \\neducation and technology. cambridge: harvard \\nuniversity press.\\n12 ford, m. (2015). rise of the robots: technology and the \\nthreat of a jobless future.  basic books.13 self, j. (1999). “the defining characteristics of \\nintelligent tutoring systems research: itss \\ncare, precisely”. international journal of artificial \\nintelligence in education  (ijaied). 10, 350–364.\\n14 vanlehn, k., lynch, c., schulze, k., shapiro, j. a., \\nshelby, r., taylor, l., ... & wintersgill, m. (2005).  \\n“the andes physics tutoring system: lessons \\nlearned”. international journal of artificial intelligence \\nin education.  15(3), 147-204.\\n15 brown, j. s. & burton, r. r. (1978). “diagnostic \\nmodels for procedural bugs in basic mathematical \\nskills”. cognitive science.  2, 155-191.\\n16 retrieved from http://www.italk2learn.eu\\n17 grawemeyer, b., mavrikis, m., holmes, w.,  \\n& gutiérrez-santos, s. (2015). adapting feedback \\ntypes according to students’ affective states.  \\nin conati, c., heffernan, n., mitrovic, a., & verdejo, \\nm. f. (eds.). artificial intelligence in education 17th \\ninternational conference, aied 2015. madrid, spain, \\njune 22-26, 2015 proceedings (vol. 9112). madrid, \\nspain: springer international publishing.\\n18 litman, d. (2009). language processing in aied: \\nsuccesses and challenges. presented at the panel \\non the evolution of aied @ aied09. brighton, uk.\\n19  dimitrova, v., mccalla, g., bull, s. (2007). preface: \\n“open learner models: future research directions”. \\ninternational journal of artificial intelligence in \\neducation.  special issue of the ijaied (part 2).\\n20 du boulay, b., rebolledo-mendez, g., luckin, \\nr., martínez-mirón, e., & harris, a. (2007). \\n“motivationally intelligent systems: diagnosis and \\nfeedback”. in: aied. 563–565.\\n21 johnson, w. l., valente, a. (2009). “tactical language \\nand culture training systems: using ai to teach \\nforeign languages and cultures”. ai magazine. \\n30(2), 72.\\n22 dillenbourg, p., baker, m. j., blaye, a., & o’malley,  \\nc. (1995). the evolution of research on collaborative \\nlearning. in reimann, p. & spada, h. (eds.) learning \\nin humans and machine: towards an interdisciplinary \\nlearning science  (pp. 189–211). bingley: emerald.\\n23 slavin, r. e. (2010). co-operative learning: what \\nmakes group-work work. in hanna, d., david, i.,  \\n& francisco, b. (eds.), the nature of learning: using \\nresearch to inspire practice  (pp. 161-178). chicago: \\noecd publishing. \\n24 ibid.\\n25 muehlenbrock, m. (2006). “learning group \\nformation based on learner profile and context”. \\ninternational journal on elearning.  5(1), 19.56\\nreferences',\n",
       " 'intelligence unleashed\\n26 mclaren, b. m., scheuer, o., & mikšátko, j. \\n(2010). “supporting collaborative learning \\nand e-discussions using artificial intelligence \\ntechniques”. international journal of artificial \\nintelligence in education.  20(1), 1–46.\\n27 upton, k., & kay, j. (2009). narcissus: group and \\nindividual models to support small group work.  \\nin houben, g., mccalla, g., pianesi, f., & zancanaro, \\nm. user modeling, adaptation, and personalization  \\n(pp. 54-65). berlin heidelberg: springer. \\n28 vizcaíno, a. (2005). “a simulated student can \\nimprove collaborative learning”. international \\njournal of artificial intelligence in education.  15(1), \\n3–40.\\n29 one example of this type of virtual agent can be \\nfound in betty’s brain (http://www.teachableagents.\\norg/research/bettysbrain.php), a computer-based \\nlearning environment developed at vanderbilt \\nuniversity.\\n30 de laat, m., chamrada, m., & wegerif, r. (2008). \\nfacilitate the facilitator: awareness tools to support \\nthe moderator to facilitate online discussions \\nfor networked learning. in: proceedings of the 6th \\ninternational conference on networked learning   \\n(pp. 80–86).\\n31 barab, s. a., gresalfi, m., & ingram-goble, a.  \\n(2010). “transformational play: using games  \\nto position person, content, and context”.  \\neducational researcher.  39(7), 525–536.\\n32 hassani, k., nahvi, a., & ahmadi, a. (2013). design \\nand implementation of an intelligent virtual \\nenvironment for improving speaking and listening \\nskills. interactive learning environments  (pp. 1–20).\\n33 dede, c. (2009). “immersive interfaces for \\nengagement and learning”. science,  323(5910),  \\n66-69. \\n34 vannini, n., enz, s., sapouna, m., wolke, d., watson, \\ns., woods, s., ... & aylett, r. (2011). ““fearnot!”: \\na computer-based anti-bullying-programme \\ndesigned to foster peer intervention. european \\njournal of psychology of education. 26(1), 21-44.\\n35 see, for example, traum, d., rickel, j., gratch, j. & \\nmarsella, s. (2003). negotiation over tasks in hybrid \\nhuman-agent teams for simulation-based training. \\nin proceedings of the second international joint \\nconference on autonomous agents and multiagent \\nsystems. 441-448. acm.\\n36 sarkis, h. (2004). cognitive tutor algebra 1 program \\nevaluation, miami-dade county public schools. \\nlighthouse point, fl: the reliability group.\\n37 upton and kay, 2009. 38 kaminska, i. (2015, june 25). innovating fast or \\nslow? gates vs wolf edition. retrieved from http://\\nftalphaville.ft.com/tag/technology/\\n39 retrieved from http://www3.weforum.org/docs/\\nwefusa_newvisionforeducation_report2015.pdf\\n40 luckin, r. (2010). re-designing learning contexts: \\ntechnology-rich, learner-centred ecologies.  london: \\nroutledge.\\n41 hill, p. & barber, m. (2014). preparing for a \\nrenaissance in assessment.  london: pearson. \\n42 dicerbo, k. e. & behrens, j. t. (2014). impacts of the \\ndigital ocean on education. london: pearson.\\n43 hill & barber. (2014). dicerbo, k. (2014, december \\n17). why an assessment renaissance means fewer tests.  \\nretrieved from http://researchnetwork.pearson.\\ncom/digital-data-analytics-and-adaptivelearning/\\nassessment-renaissance-means-fewertests\\n44 howard-jones, p., holmes, w., demetriou, s., jones, \\nc., tanimoto, e., morgan, o. & davies, n. (2014). \\n“neuroeducational research in the design and \\nuse of a learning technology. learning, media and \\ntechnology. 40(2), 1–20.\\n45 see, for example, dweck, c. s., & leggett, e. l. \\n(1988). “a social-cognitive approach to motivation \\nand personality”. psychological review. 95(2), 256-73 \\nor dweck, c. s. (2006). mindset: the new psychology  \\nof success. new york: random house.\\n46 dweck, c. s. (2010). “even geniuses work hard”. \\neducational leadership. 68(1), 16-20.\\n47 retrieved from http://www.mindsetworks.com/\\nbrainology/\\n48 harris, a., bonnett, v., luckin, r., yuill, n., & \\navramides, k. (2009). scaffolding effective \\nhelpseeking behaviour in mastery and performance \\noriented learners. in dimitrova, v., mizoguchi,  \\nr., du boulay, b., & graesser, a. c. (eds.) aied 2009, \\nfrontiers in artificial intelligence and applications  (pp. \\n425-432). 200, ios press.\\n49 cole, m. (1996). cultural psychology: a once and \\nfuture discipline.  harvard university press.\\n50 see, for example, chan, t. w. (1991). integration-\\nkid: a learning companion system. in mylopolous, \\nj. & reiter, r. (eds.) proceedings of the 12th \\ninternational conference on artificial intelligence. \\n2,1094-1099. australia, morgan: kaufmann \\npublishers, inc.\\n51 bostrom, n., yudkowsky, e. (2013). the ethics \\nof artificial intelligence. cambridge: cambridge \\nuniversity press.  57',\n",
       " 'open ideas at pearson52 (2010, october 1). what caused the flash crash?  \\none big, bad trade.  the economist online. retrieved \\nfrom http://www.economist.com.\\n53 lindgren, r., & johnson-glenberg, m. \\n(2013).“emboldened by embodiment six precepts \\nfor research on embodied learning and mixed \\nreality. educational researcher. 42(8), 445-452.\\n54 graesser, a. c., chipman, p., king, b., mcdaniel,  \\nb., & d’mello, s. (2007). emotions and learning  \\nwith autotutor. in luckin, l. koedinger,  \\nk. & greer, j. (eds.) frontiers in artificial intelligence \\nand applications.  158, 569-571. ios press.\\n55 conroy, m.& rothstein, r. (2013, january 15). \\ninternational test show achievement gaps in all \\ncountries, with big gains for u.s. disadvantaged \\nstudents.  retrieved from http://www.epi.org\\n56 hanushek, e. a. & woessmann, l. (2010). the high \\ncost of low educational performance: the long-run \\neconomic impact of improving pisa outcomes.  paris: \\noecd.\\n57 kuczera, m., field, s. & windisch, h. c. (2016). \\nbuilding skills for all: a review of england.  paris: oecd. \\n58 bertram, t. & pascal, c. (2014). early years literature \\nreview. retrieved from https://www.early-education.\\norg.uk/sites/default/files/crec%20early%2years%20\\nlit%20review202014%20for%20ee.pdf\\n59 paton, g. (2014, october 16). four-in-10 children ‘not \\nready for school’ at the age of five. the telegraph. \\nretrieved from http://www.telegraph.co.uk/\\n60 a term commonly used in psychology and sociology \\nthat makes reference to a verse from the gospel \\naccording to matthew (xxv, 29), “for unto every \\none that hath shall be given, and he shall have \\nabundance: but from him that hath not shall be \\ntaken away even that which he hath.”\\n61 retrieved from https://www.tes.com/teaching-\\nresources\\n62 retrieved from https://www.teacherspayteachers.\\ncom/\\n63 house of commons library. (2015). teachers: social \\nindicators. sn/sg/2626  \\n64 unesco. (2015). sustainable development goal for \\neducation cannot advance without more teachers.\\nuis fact sheet no.33. retrieved from http://www.\\nuis.unesco.org/education/documents/fs33-2015-\\nteachers.pdf \\n65 retrieved from https://www.theschoolinthecloud.\\norg/\\n66 goldin and katz, 201067 mayer-schönberger, v., & cukier, k. (2013). big data: \\na revolution that will transform how we live, work, and \\nthink. new york: houghton mifflin harcourt.\\n68 fullan, m., & donnelly, k. (2013). alive in the swamp: \\nassessing digital innovations in education.  london: \\nnesta.\\n69 levy, f., & murnane, r. j. (2004.) the new division \\nof labor: how computers are creating the next job \\nmarket. princeton university press. \\n70 fletcher, j. d. & morrison, j. e. (2012). darpa digital \\ntutor: assessment data. alexandria, va: institute for \\ndefense analyses.  retrived from http://www.acuitus.\\ncom/web/pdf/d4686-df.pdf58\\nreferences',\n",
       " 'intelligence unleashed\\ndesign bond & coyne\\nprint dayfold',\n",
       " 'pearson\\n80 strand\\nlondon\\nwc2r 0rl\\nwww.pearson.com\\njoin the conversation\\n@pearson\\n#openideas',\n",
       " '230  \\n  \\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101\\nopen access abstr act\\nartificial intelligence (ai) aims to mimic human cognitive \\nfunctions. it is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. we survey the current status of ai applications in healthcare and discuss its future. ai can be applied to various types of healthcare data (structured and unstructured). popular ai techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. major disease areas that use ai tools include cancer, neurology and cardiology. we then review in more details the ai applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. we conclude with discussion about pioneer ai systems, such as ibm watson, and hurdles for real-life deployment of ai.\\noverview of the medic a l a rtifici a l \\nintelligence (a\\ni\\n) rese\\na\\nrch\\nrecently ai techniques have sent vast waves \\nacross healthcare, even fuelling an active discussion of whether ai doctors will eventu-ally replace human physicians in the future. we believe that human physicians will not be replaced by machines in the foreseeable future, but ai can definitely assist physicians to make better clinical decisions or even replace human judgement in certain functional areas of healthcare (eg, radiology). the increasing availability of healthcare data and rapid devel-opment of big data analytic methods has made possible the recent successful applica-tions of ai in healthcare. guided by relevant clinical questions, powerful ai techniques can unlock clinically\\n \\nrelevant information hidden \\nin the massive amount of data, which in turn can assist clinical decision making.\\n1–3 \\nin this article, we survey the current status \\nof ai in healthcare, as well as discuss its future. we first briefly review four relevant aspects from medical investigators’ perspectives:1.\\n motivations of applying ai in healthcare\\n2.\\n data \\ntypes that have be analysed by ai sys-\\ntems3.\\n mechanisms that enable ai systems to gen\\n-\\nerate clinical meaningful results\\n4.\\n disease types that the ai communities are \\ncurrently tackling.\\nm\\notivation\\nthe advantages of ai have been extensively discussed in the medical literature.\\n3–5 ai \\ncan use sophisticated algorithms to\\n \\n‘learn’ \\nfeatures from a large volume of healthcare data, and then use the obtained insights to assist clinical practice. it can also be equipped with learning and self-correcting abilities to improve its accuracy based on feedback. an ai system can assist physicians by providing up-to-date medical information from jour -\\nnals, textbooks and clinical practices to inform proper patient care.\\n6 in addition, an \\nai system can help to reduce diagnostic and therapeutic errors that are inevitable in the human clinical practice.\\n3 4 6–10 moreover, an \\nai system extracts useful information from a large patient population to assist making real-time inferences for health risk alert and health outcome prediction.\\n11\\nhealthcare data\\nbefore ai systems can be deployed in health\\n-\\ncare applications, they need to be ‘trained’ through data that are generated from clin-ical activities, such as screening, diagnosis, treatment assignment and so on, so that they can learn similar groups of subjects, associa-tions between subject features and outcomes of interest. these clinical data often exist in but not limited to the form of demographics, medical notes, electronic recordings from medical devices, physical examinations and clinical laboratory and images.\\n12\\nspecifically, in the diagnosis stage, a substan-\\ntial proportion of the ai literature analyses data from diagnosis imaging, genetic testing and electrodiagnosis (figure\\n \\n1). for example, \\njha and topol urged\\n \\n radiologists to adopt \\nai technologies when analysing diagnostic images that contain vast data information.\\n13 \\nli et al studied the uses of abnormal genetic artificial intelligence in healthcare: past, \\npresent and\\n \\nfuture\\nfei jiang,1 yong jiang,2 hui zhi,3 yi dong,4 hao li,5 sufeng ma,6 yilong wang,7 \\nqiang dong,4 haipeng shen,8 yongjun wang9\\n1department of statistics and \\nactuarial sciences, university of \\nhong kong, hong kong, china\\n2department of neurology, \\nbeijing tiantan hospital, capital medical university, beijing, china\\n3biostatistics and clinical \\nresearch methodology unit, university of hong kong li ka shing faculty of medicine, hong kong, china\\n4department of neurology, \\nhuashan hospital, fudan university, shanghai, china\\n5china national clinical \\nresearch center for neurological diseases, beijing, china\\n6dothealth, shanghai, china\\n7department of neurology, \\ntiantan clinical trial and research center for stroke, beijing, china\\n8faculty of business and \\neconomics, university of hong kong, hong kong, china\\n9department of neurology, \\nbeijing tiantan hospital, beijing, china\\nc\\norrespondence to\\nprof yongjun wang;  \\n \\nyongjunwang1962@\\n \\ngmail.\\n \\ncomto cite: jiang\\xa0f, jiang\\xa0y, zhi\\xa0h, et\\xa0al. artificial intelligence in healthcare: past, present and future. stroke and vascular neurology 2017;2: e000101. doi:10.1136/svn-2017-000101\\nreceived 12 june 2017\\naccepted 14 june 2017published online first 22\\xa0june\\xa02017\\nreview on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " ' 231\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access\\nexpression in long non-coding rnas to diagnose gastric \\ncancer.14 shin et al developed an electrodiagnosis support \\nsystem for localising neural injury.15\\nin addition, physical examination notes and clinical \\nlaboratory results are the other two major data sources (figure\\n \\n1). we distinguish them with image, genetic and \\nelectrophysiological (ep) data because they contain large portions of unstructured narrative texts, such as clin-ical notes, that are not directly analysable. as a conse-quence, the corresponding ai applications focus on first converting the unstructured text to machine-understand-able electronic medical record (emr). for example, karakülah et al used ai technologies to extract pheno-\\ntypic features from case reports to enhance the diagnosis accuracy of the congenital anomalies.\\n16\\nai devices\\nthe above discussion suggests that ai devices mainly fall into two major categories. the first categor\\ny includes \\nmachine learning (ml) techniques that analyse struc-tured data such as imaging, genetic and ep data. in the medical applications, the ml procedures attempt to cluster patients’ traits, or infer the probability of the disease outcomes.\\n17 the second category includes natural \\nlanguage processing (nlp) methods that extract infor -\\nmation from unstructured data such as clinical notes/medical journals to supplement and enrich structured medical data. the nlp procedures target at turning texts to machine-readable structured data, which can then be analysed by ml techniques.\\n18\\nfor better presentation, the  flow chart in figure  2  \\ndescribes the road map from clinical data generation, through nlp data\\n \\nenrichment and ml data analysis, to \\nclinical decision making. we comment that the road map starts and ends with clinical activities. as powerful as ai techniques can be, they have to be motivated by clinical problems and be applied to assist clinical practice in the end.\\nd\\nisease focus\\ndespite the increasingly rich ai literature in healthcare, the research mainly concentrates around a few disease types: cancer, nervous system disease and cardiovascular disease (figure\\n \\n3). we discuss several examples below.\\n1.\\n cancer: \\nsomashekhar et al demonstrated that the ibm \\nwatson for oncology would be a reliable ai system for assisting the diagnosis of cancer through a double-blinded validation study.\\n19 esteva et al analysed clinical \\nimages to identify skin cancer subtypes.20\\n2. neurology: bouton et al developed an ai system to \\nrestore the control of movement in patients with quadriplegia.\\n21 farina et al tested the power of an of-\\nfline\\n \\nman/machine interface that uses the discharge \\ntimings of spinal motor neurons to control upper-limb prostheses.\\n22\\n3. cardiology: dilsizian  and siegel discussed the \\npotential application of the ai system to diagnose the heart disease through cardiac image.\\n3 arterys \\nrecently received clearance from the us food and drug administration\\n \\n(fda) to market its arterys \\ncardio dl application, which uses ai to provide automated, editable ventricle segmentations based on conventional cardiac mri images.\\n23\\nthe concentration around these three diseases is not \\ncompletely unexpected. all three diseases are leading causes of death; therefore, early diagnoses are crucial to prevent the deterioration of patients’ health status. furthermore, early diagnoses can be potentially achieved \\nfigure 1  the data types consider ed in the artificial intelligence artificial (ai) literature. the comparison is obtained through \\nsearching the diagnosis techniques in the ai literature on the pubmed database. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " '232\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access \\nthrough improving the analysis procedures on imaging, \\ngenetic, ep or emr, which is the strength of the ai system.\\nbesides the three major diseases, ai has been applied \\nin other diseases as well. two very recent examples\\n \\nwere \\nlong et al,\\n \\nwho analysed the ocular image data to diag-\\nnose congenital cataract disease,24 and  gulshan et al, \\nwho\\n \\ndetected referable diabetic retinopathy through the \\nretinal fundus photographs.25\\nthe rest of the paper is organised as follows. in section \\n2, we describe popular ai devices in ml\\n \\nand nlp; the \\nml\\n \\ntechniques are further grouped into classical tech-\\nniques and the more recent deep learning. section 3 focuses on discussing ai applications in neurology, from the three aspects of early disease prediction and diagnosis, treatment, outcome prediction and prognosis evaluation. we then conclude in section 4 with some discussion about the future of ai in healthcare.\\nt\\nhe a\\ni\\n devices: \\nml\\n\\xa0\\na\\nnd \\nnl\\np\\nin this section, we review the ai devices (or techniques) that have been found useful in the medial applications. we categorise them into three groups: the classical machine learning techniques,\\n26 the more recent deep \\nlearning techniques27 and the nlp  methods.28\\nclassical ml\\nml\\n constructs \\ndata\\n analytical \\nalgorithms to extract \\nfeatures from data. inputs to ml\\n \\nalgorithms include \\npatient ‘traits’ and sometimes medical outcomes of \\nfigure 2  the r oad map from clinical data generation to natural language processing\\xa0data enrichment, to machine learning \\ndata analysis, to clinical decision making.\\xa0emr,\\xa0electronic medical record; ep , electrophysiological.  on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " ' 233\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access\\ninterest. a patient’s traits commonly include baseline \\ndata, such as age, gender, disease history and so on, and disease-specific data, such as diagnostic imaging, gene expressions, ep test, physical examination results, clin-ical symptoms, medication and so on. besides the traits, patients’ medical outcomes are often collected in clin-ical research. these include disease indicators, patient’s survival times and quantitative disease levels, for example, tumour sizes. to fix ideas, we denote the jth trait of the ith patient by x\\nij, and the outcome of interest by yi.\\ndepending on whether to\\n \\nincorporate the outcomes, \\nml\\n \\nalgorithms can be divided into two major categories: \\nunsupervised learning and supervised learning. unsuper -\\nvised learning is well known for feature extraction, while supervised learning is suitable for predictive modelling via building some relationships between the patient traits (as input) and the outcome of interest (as output). more recently, semisupervised learning has been proposed as a hybrid between unsupervised learning and super -\\nvised learning, which is suitable for scenarios where the outcome is missing for certain subjects. these three types of learning are illustrated in figure\\n \\n4.\\nclustering and principal component analysis (pca) \\nare two major unsupervised learning methods. clustering groups subjects with similar traits together into clusters, without using the outcome information. clustering algo-rithms output the cluster labels for the patients through maximising and minimising the similarity of the patients within and between the clusters. popular clustering algo-rithms include k-means clustering, hierarchical clustering and gaussian mixture clustering. pca is mainly for dimen-sion reduction, especially when the trait is recorded in a large number of dimensions, such as the number of genes in a genome-wide association study. pca projects the data \\nfigure 3  the leading 10\\xa0disease types consider ed in the artificial intelligence\\xa0(ai) literature. the first vocabularies in the \\ndisease names are displayed. the comparison is\\xa0obtained through searching the disease types in the ai literature on pubmed.\\nfigure 4  graphical illustration of unsupervised lear ning, supervised learning and semisupervised learning. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " '234\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access \\nonto a few principal component (pc) directions, without \\nlosing too much information about the subjects. some-times, one can first use pca to reduce the dimension of the data, and then use clustering to group the subjects.\\non the other hand, supervised learning considers the \\nsubjects’ outcomes together with their traits, and goes through a certain training process to determine the best outputs associated with the inputs that are closest to the outcomes on average. usually, the output formulations vary with the outcomes of interest. for example, the outcome can be the probability of getting a particular clinical event, the expected value of a disease level or the expected survival time.\\nclearly, compared with unsupervised learning, super -\\nvised learning provides more clinically relevant results; hence ai applications in healthcare most often use super -\\nvised learning. (note that unsupervised learning can be used as part of the preprocessing step to reduce dimen-sionality or identify subgroups, which in turn makes the follow-up supervised learning step more efficient.) relevant techniques include linear regression, logistic regression, naïve bayes, decision tree, nearest neighbour, random forest, discriminant analysis, support vector machine (svm) and neural network.\\n27 figure  5 displays \\nthe popularity of the various supervised learning tech-niques in medical applications, which clearly shows that svm and neural network are the most popular ones. this remains the case when restricting to the three major data types (image, genetic and ep), as shown in figure\\n \\n6.\\nbelow we will provide more details about the mechanisms \\nof svm and neural networks, along with application exam-ples in the cancer, neurological and cardiovascular disease areas.\\ns\\nupport vector machine\\nsvm is mainly used for classifying the subjects into two groups, where the outcome y\\ni is a classifier: yi = −1 or 1 represents whether the ith patient is in group 1 or 2, \\nrespectively. (the method can be extended for scenarios with more than two groups.) the basic assumption is that the subjects can be separated into two groups through a decision boundary defined on the traits x\\nij, which can be \\nwritten as:\\n ai=∑p\\nj=1wjxij+b, \\nwhere wj is the weight putting on the jth trait to manifest \\nits relative importance on affecting the outcome among the others. the decision rule then follows that if a\\ni >0, \\nthe i\\nth patient is classified to group 1, that is, labelling yi \\n= −1; if ai <0, the patient is classified to group 2, that is, \\nlabelling yi=1. the class memberships are indeterminate \\nfor the points with ai=0. see figure  7 for an illustration \\nwith\\n p=2, b=0 , a1=1, and a2=−1.\\nthe training goal is to find  \\nthe optimal wjs so that \\nthe resulting classifications agree with the outcomes as much as possible, that is, with the smallest misclassifi -\\ncation error, the error of classifying a patient into the wrong group. intuitively, the best weights must allow (1) the sign of a\\ni to be the same as yi so the classification is \\ncorrect; and  \\n(2) |ai| to be far away from 0 so the ambiguity \\nof the classification is minimised. these can be achieved by selecting w\\njs that minimise a quadratic loss function.29 \\nfurthermore, assuming that the new patients come from the same population, the resulting \\n  \\nwjs can be applied to \\nclassify these new patients based on their traits.\\nan important property of svm is that the determination \\nof the model parameters is a convex optimisation problem so the solution is always global optimum. furthermore, many existing convex optimisation tools are readily appli-cable for the svm implementation. as such, svm has been extensively used in medical research. for instance, orrù et al applied svm to identify imaging biomarkers of neurolog-ical and psychiatric disease.\\n30 sweilam et al reviewed the use \\nof svm in the diagnosis of cancer.31 khedher et al used the \\nfigure 5  the machine lear ning algorithms used in the medical literature. the data are generated through searching the \\nmachine learning algorithms within healthcare on pubmed. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " ' 235\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access\\ncombination of svm and other statistical tools to achieve \\nearly detection of alzheimer’s disease.32 farina et al used \\nsvm to test the power of an offline\\n \\nman/machine interface \\nthat controls upper-limb prostheses.22neural network\\none can think about neural network as an extension of linear regression to capture complex non-linear relation\\n-\\nships between input variables and an outcome. in neural \\nfigure 6  the machine lear ning algorithms used for imaging (upper), genetic (middle) and electrophysiological (bottom) data. \\nthe data are generated through searching the machine learning algorithms for\\xa0each data type on pubmed. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " '236\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access \\nnetwork, the associations between the outcome and the \\ninput variables are depicted through multiple hidden layer combinations of prespecified functionals. the goal is to estimate the weights through input and outcome data so that the average error between the outcome and \\ntheir predictions is minimised. we describe the method in the following example.\\nmirtskhulava et al used neural network in stroke diag-\\nnosis.\\n33 in their analysis, the input variables xi1, . . . , xip \\nare p=16\\n stroke-related symptoms, including paraesthesia \\nof the\\n \\narm or leg, acute confusion, vision, problems with \\nmobility and so on. the outcome yi is binary: yi=1/0 indi-\\ncates the ith patient has/does not have stroke. the output parameter of interest is the probability of stroke,\\n \\nai, which \\ncarries the form of\\n ai=h{∑d\\nk=1w2lfk(∑p\\nl=1w1lxil+w10)+w20}\\n. \\nin the above equation, the w10 and w20≠0 guarantee the \\nabove form to be valid even when all xij, fk are 0; the w1l \\nand w2ls are the weights to characterise the relative impor -\\ntance of the corresponding multiplicands on affecting the outcome; the f\\nks and h are prespecified functionals to \\nmanifest how the weighted combinations influence the disease risk as a whole. a stylised illustration is provided in figure\\n \\n8.\\nthe training goal is to find\\n \\nthe weights wij, which mini -\\nmise the prediction error ∑n\\ni=1(\\nyi−ai)2. the minimis-\\nation can be performed through standard optimisation algorithms, such as local quadratic approximation or \\nfigure 7  an illustration of the support vector machine.\\nfigure 8  an illustration of neural network. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " ' 237\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access\\ngradient descent optimisation, that are included in both \\nmatlab and r. if the new data come from the same population, the resulting w\\nij can be used to predict the \\noutcomes based on their specific traits.29\\nsimilar techniques have been used to diagnose cancer \\nby khan et al, where the inputs are the pcs estimated from 6567 genes and the outcomes are the tumour catego-ries.\\n34 dheeba et al used neural network to predict breast \\ncancer, with the inputs being the texture information from mammographic images and the outcomes being tumour indicators.\\n35 hirschauer et al used a more sophis-\\nticated neural network model to diagnose parkinson’s disease based on the inputs of motor, non-motor symp-toms and neuroimages.\\n36\\ndeep learning: a new era of ml\\ndeep learning is a modern extension of the classical neural \\nnetwork technique. one can view deep learning \\nas a neural network with many layers (as in figure\\n \\n9). \\nrapid development of modern computing enables deep learning to build up neural networks with a large number of layers, which is infeasible for classical neural networks. as such, deep learning can explore more complex non-linear patterns in the data. another reason for the recent popularity of deep learning is due to the increase\\n \\nof \\nthe volume and complexity of data.37 figure  10  shows that \\nthe application of deep learning in the field of medical research nearly doubled in 2016. in addition, figure\\n \\n11 \\nshows that a clear majority of deep learning is used in imaging analysis, which makes sense given that images are naturally complex and high volume.different from the classical neural network, deep \\nlearning uses more hidden layers so that the algorithms \\ncan handle complex data with various structures.\\n27 in the \\nmedical applications, the commonly used deep learning algorithms include convolution neural network (cnn), recurrent neural network, deep belief network and deep neural network. figure\\n \\n12 depicts their trends and rela-\\ntive popularities from 2013 to 2016. one can see that the cnn is the most popular one in 2016.\\nthe cnn is developed in viewing of the incompetence \\nof the classical ml algorithms when handling high dimen-sional data, that is, data with a large number of traits. tradi-tionally, the ml algorithms are designed to analyse data when the number of traits is small. however, the image data are naturally high-dimensional because each image normally contains thousands of pixels as traits. one solu-tion is to perform dimension reduction: first preselect a subset of pixels as features, and then perform the ml algorithms on the resulting lower dimensional features. however, heuristic feature selection procedures may lose information in the images. unsupervised learning tech-niques such as pca or clustering can be used for data-driven dimension reduction.\\nthe cnn was first proposed and advocated for the \\nhigh-dimensional image analysis by lecun et al.\\n38 the \\ninputs for cnn are the properly normalised pixel values on the images. the cnn then transfers the pixel values in the image through weighting in the convolution layers and sampling in the subsampling layers alternatively. the final output is a recursive function of the weighted \\nfigure 9  an illustration of deep lear ning with two hidden layers. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " '238\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access \\ninput values. the weights are trained to minimise the \\naverage error between the outcomes and the predic-tions. the implementation of cnn has been included in popular software packages such as caffe from berkeley ai research,\\n39 cntk from microsoft40 and tensorflow from \\ngoogle.41\\nrecently, the cnn has been successfully implemented \\nin the medical area to assist disease diagnosis. long et al used it to diagnose congenital cataract disease through learning the ocular images.\\n24 the cnn yields over 90% \\naccuracy on diagnosis and treatment suggestion. esteva et al performed the cnn to identify skin cancer from clinical images.\\n20 the proportions of correctly predicted \\nmalignant lesions (ie, sensitivity) and benign lesions (ie, specificity) are both over 90%, which indicates the supe-rior performance of the cnn. gulshan et al applied the cnn to detect referable diabetic retinopathy through the retinal fundus photographs.\\n25 the sensitivity and \\nspecificity of the algorithm are both over 90%, which demonstrates the effectiveness of using the technique on the diagnosis of diabetes. it is worth mentioning that in all these applications, the performance of the cnn is \\nfigure 10  curr ent trend for deep learning. the data are generated through searching the deep learning in healthcare and \\ndisease category on pubmed.\\nfigure 11  the data sour ces for deep learning. the data are generated through searching deep learning in combination with \\nthe diagnosis techniques on pubmed. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " ' 239\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access\\ncompetitive against experienced physicians in the accu-\\nracy for classifying both normal and disease cases.\\nn\\natural language processing\\nthe image, ep and genetic data are machine-understand-able so that the ml algorithms can be directly performed after proper preprocessing or quality control processes. however, large proportions of clinical information are in the form of narrative text, such as physical examination, clinical laboratory reports, operative notes and\\n \\ndischarge \\nsummaries, which are unstructured and incomprehen-sible for the computer program. under this context, nlp targets at extracting useful information from the narra-tive text to assist clinical decision making.\\n28\\nan nlp pipeline comprises two main components: \\n(1) text processing\\n \\nand (2) classification. through text \\nprocessing, the nlp identifies a series of disease-relevant keywords in the clinical notes based on the historical databases.\\n42 then a subset of the keywords are selected \\nthrough examining their effects on the classification of the normal and abnormal cases. the validated keywords then enter and enrich the structured data to support clin-ical decision making.\\nthe nlp pipelines have been developed to assist clin-\\nical decision making on alerting treatment arrangements, monitoring adverse effects and so on. for example, fiszman et al showed that introducing nlp for reading \\nthe chest x-ray reports would assist the antibiotic assistant system to alert physicians for\\n \\nthe possible need for anti-in-\\nfective therapy.43 miller et al used nlp to automatically \\nmonitor the laboratory-based adverse effects.44 further -\\nmore, the nlp pipelines can help with disease diagnosis. for instance, castro et al identified 14 cerebral aneurysms disease-associated variables through implementing nlp on the clinical notes.\\n45 the resulting variables are success-\\nfully used for classifying the normal patients and the patients with cerebral, with 95% and 86%\\n accuracy rates \\non the training and validation samples, respectively\\n. afzal \\net al implemented the nlp to extract the peripheral arte-rial disease-related keywords from narrative clinical notes. the keywords are then used to classify the normal and the patients with peripheral arterial disease, which achieves over 90% accuracy.\\n42\\nai applicati o ns in str o ke\\nstroke is a common and frequently\\n \\noccurring disease that \\naffects more than 500\\n million people worldwide. it is the \\nleading cause of death in china and the fifth in north america. \\nstroke had cost about us$689\\n billion in medical \\nexpenses across the world, causing heavy burden to coun\\n-\\ntries and families.46 47 therefore, research on prevention \\nand treatment for stroke has great significance. in recent years, ai techniques have been used in more and more stroke-related studies. below we summarise some of the relevant ai techniques in the three main areas of stroke care: early disease prediction and diagnosis, treatment, as well as outcome prediction and prognosis evaluation.\\ne\\narly detection and diagnosis\\nstroke, for 85% of the time, is caused by thrombus in the vessel called cerebral infarction. however, for lack of judgement of early stroke symptom, only a few patients could receive timely treatment. villar et al developed a movement-detecting device for early stroke prediction.\\n48 \\ntwo ml algorithms\\n \\n— genetic fuzzy finite state machine \\nfigure 12  the four main deep lear ning algorithm and their popularities. the data are generated through searching algorithm \\nnames in healthcare and disease category on pubmed. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " '240\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access \\nand pca —  were implemented into the device for the \\nmodel \\nbuilding solution. the detection process included \\na human activity recognition stage and a stroke-onset \\ndetection stage. once the movement of the patient is significantly different from the normal pattern, an alert of stroke would be activated and evaluated for treatment as soon as possible. similarly, maninini et al proposed a wearable device for collecting data about normal/patho-logical gaits for stroke prediction.\\n49 the data would be \\nextracted and modelled by hidden markov models and svm, and the algorithm could correctly classify 90.5% of the subjects to the right group.\\nfor diagnosis of stroke, neuroimaging techniques, \\nincluding mri and ct, are important for disease evalu-ation. some studies have tried to apply ml methods to neuroimaging data to assist with stroke diagnosis. rehme et al used svm in resting-state functional mri data, by which endophenotypes of motor disability after stroke were identified and classified.\\n50 svm can correctly clas-\\nsify patients with stroke with 87.6% accuracy. griffis et\\n \\nal\\n \\ntried naïve bayes classification to identify stroke \\nlesion in t1-weighted mri.51 the result is comparable \\nwith human expert manual lesion delineation. kamnitsas et al tried three-dimensional cnn (3d cnn) for lesion segmentation in multimodel brain mri.\\n52 they also used \\nfully connected conditional random field model for final postprocessing of the cnn’s soft segmentation maps. rondina et al analysed stroke anatomical mri images \\nusing gaussian process regression, and found that the patterns of voxels performed better than lesion load per region as the predicting features.\\n53\\nml methods have also been applied to analyse ct scans \\nfrom patients with stroke. free-floating intraluminal thrombus may be formed as lesion after stroke, which is difficult to be distinguished with carotid plaque on the ct imaging. thornhill et\\n \\nal\\n \\nused three ml algorithms \\nto classify these two types by quantitative shape analysis, including linear discriminant analysis, artificial neural network and svm.\\n54 the accuracy for each method varies \\nbetween 65.2% and 76.4%.\\ntreatment\\nml has also been applied for predicting and analysing the \\nperformance of stroke treatment. as a critical step \\nof emergency measure, the outcome of intravenous thrombolysis (tpa) has strong relationship with the prog-nosis and survival rate. bentley et al used svm to predict whether patients with tpa treatment would develop symp-tomatic intracranial haemorrhage by ct scan.\\n55 they \\nused whole-brain images as the input into the svm, which performed better than conventional radiology-based methods. to improve the\\n \\nclinical decision-making process \\nof tpa treatment, love et al proposed a stroke treatment model by analysing practice guidelines, meta-analyses and clinical trials using bayesian belief network.\\n56 the \\nmodel consisted of 56 different variables and three deci-sions for analysing the procedure of diagnosis, treatment and outcome prediction. ye et al used interaction trees and subgroup analysis to explore appropriate tpa dosage based on patient characteristics, taking into account both the risk of bleeding and the treatment efficacy.\\n57\\noutcome prediction and prognosis evaluationmany factors can affect stroke prognosis and disease mortality. compared with conventional methods, ml methods have advantages in improving prediction perfor -\\nmance. to better support clinical decision-making process, zhang et al proposed a model for predicting 3-month \\ntreatment outcome by analysing physiological parameters during 48\\n hours after stroke using logistic regression.58 \\nasadi et al compiled a database of clinical information of \\n107 patients with acute anterior or posterior circulation stroke who underwent intra-arterial therapy.\\n59 the authors \\nanalysed the data via artificial neural network and svm, and obtained prediction accuracy above 70%. they also used ml techniques to identify factors influencing outcome in brain arteriovenous malformation treated with endo-vascular embolisation.\\n60 while standard regression anal-\\nysis model could only achieve a 43% accuracy rate, their methods worked much better with 97.5% accuracy.\\nbirkner et\\n \\nal\\n used \\nan optimal algorithm to predict 30-day \\nmortality and obtained more accurate prediction than existing methods.\\n61 similarly, king et al used svm to predict \\nstroke mortality at discharge.62 in addition, they proposed \\nthe use of the synthetic minority oversampling technique to reduce the stroke outcome prediction bias caused by between-class imbalance among multiple data\\n \\nsets.\\nbrain images have been analysed to predict the outcome \\nof stroke treatment. chen et al analysed ct scan data via ml for evaluating the cerebral oedema following hemi-spheric infarction.\\n63 they built random forest to automat-\\nically identify cerebrospinal fluid and analyse the shifts on ct scan, which is more efficient and accurate than conventional methods. siegel et al extracted functional connectivity from mri and functional mri data, and used ridge regression and multitask learning for cognitive defi-ciency prediction after stroke.\\n64 hope et al studied the \\nrelationship between lesions extracted from mri images and the treatment outcome via gaussian process regres-sion model.\\n65 they used the model to predict the severity \\nof cognitive impairments after stroke and the course of recovery over time.\\nco\\nnclusi\\no\\nn \\na\\nnd discussi\\no\\nn\\nwe reviewed the motivation of using ai in healthcare, presented the various healthcare data that ai has analysed and surveyed the major disease types that ai has been deployed. we then discussed in details the two major cate-gories of ai devices: ml\\n \\nand nlp. for ml, we focused \\non the two most popular classical techniques: svm\\n \\nand \\nneural network, as well as the modern deep learning tech-nique. we then surveyed the three major categories of ai applications in stroke care.\\na successful ai system must possess the ml\\n \\ncomponent \\nfor handling structured data (images, ep data, genetic  on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " \" 241\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access\\ndata) and the nlp  component for mining unstructured \\ntexts. the sophisticated algorithms then need to be \\ntrained through healthcare data before the system can assist physicians with disease diagnosis and treatment suggestions.\\nthe ibm w\\natson system is a pioneer in this field. the \\nsystem includes both ml\\n \\nand nlp\\n \\nmodules, and has \\nmade promising progress in oncology. for example, in a cancer research, 99% of the treatment recommenda-tions from watson are coherent with the physician deci-sions.\\n66 furthermore, watson collaborated with quest \\ndiagnostics to offer\\n the \\nai genetic diagnostic analysis.66 \\nin addition, the system started to make impact on actual clinical practices. for example, through analysing genetic data, watson successfully identified the rare secondary leukaemia caused by myelodysplastic syndromes in japan.\\n67\\nthe cloud-based cc-cruiser in24 can be one prototype \\nto connect an ai system with the front-end data input and the back-end clinical actions. more specifically, when patients come, with their permission, their demographic information and clinical data (images, ep results, genetic results, blood pressure, medical notes and so on) are collected into the ai system. the ai system then uses the patients’ data to come up with\\n \\nclinical suggestions. these \\nsuggestions are sent to physicians to assist with their clin-ical decision making. feedback about the suggestions (correct or wrong) will also be collected and fed back into the ai system so that it can keep improving accuracy.\\nstroke is a chronic disease with acute events. stroke \\nmanagement is a rather complicated process with a series of clinical decision points. traditionally clinical research solely focused on a single or very limited clinical questions, while ignoring the continuous nature of stroke manage-ment. taking the advantage of large amount of data with rich information, ai is expected to help with studying much more complicated yet much closer to real-life clin-ical questions, which then leads to better decision making in stroke management. recently, researchers have started endeavours along this direction and obtained promising initial results.\\n57\\nalthough the ai technologies are attracting substantial \\nattentions in medical research, the real-life implementa-tion is still facing obstacles. the\\n \\nfirst hurdle\\n \\ncomes from \\nthe regulations. current regulations lack of standards to assess the safety and efficacy\\n \\nof ai systems. to over -\\ncome the difficulty, the us\\n \\nfda made the first attempt to \\nprovide guidance for assessing ai systems.68 the first guid-\\nance classifies ai systems to be the ‘general wellness prod-ucts’, which are loosely regulated as long as the devices intend for only general wellness and present low risk to users. the second guidance justifies the use of real-world evidence to access the performance of ai systems. lastly, the guidance clarifies the rules for the adaptive design in clinical trials, which would be widely used in assessing the operating characteristics of ai systems. not long after the disclosure of these guidances, arterys’ medical imaging platform became the first fda-approved deep learning clinical platform that can help cardiologists to diagnose cardiac diseases.\\n23\\nthe second hurdle is data exchange. in order to work \\nwell, ai systems need to be trained (continuously) by data from clinical studies. however, once an ai system gets deployed after initial training with historical data, continuation of the data supply becomes a crucial issue for further development and improvement of the system. current healthcare environment does not provide incen-tives for sharing data on the system. nevertheless, a health-care revolution is under way to stimulate data sharing in the usa.\\n69 the reform starts with changing the health \\nservice payment scheme. many payers, mostly insurance companies, have shifted from rewarding the physicians by shifting the treatment volume to the treatment outcome. furthermore, the payers also reimburse for a medica-tion or a treatment procedure by its efficiency. under this new environment, all the parties in the healthcare system, the physicians, the pharmaceutical companies and\\n \\nthe patients, have greater incentives to compile and \\nexchange information. similar approaches are being explored in china.\\ncorrection notice  this pa per has been corrected since it was published online \\nfirst. owing to a scripting error, some of the publisher names in the references were replaced with 'bmj publishing group'. this only affected the full text version, not the pdf. we have since corrected these errors and the correct publishers have been inserted into the references. figures 6-9 have also been corrected.\\nc\\nompeting interests\\n none dec\\nlared.\\nprovenance and peer review\\n commissioned; internally peer reviewed.\\nd\\nata sharing statement\\n no additional da\\nta are available.\\nopen access\\n this is an open \\naccess article distributed in accordance with the \\ncreative commons attribution non commercial (cc by-nc 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. see: http://\\n crea\\ntivecommons.\\n org/\\n \\nlicenses/\\n \\nby-\\n \\nnc/\\n \\n4.\\n \\n0/\\n© article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. all rights reserved. no commercial use is permitted unless otherwise expressly granted.\\nrefe rences\\n 1. mur doch tb, detsky as. the inevitable application of big data to \\nhealth care. jama 2013;309:1351–2.\\n 2.\\n kolker e, özdemir v\\n, kolker e. how healthcare can refocus on its \\nsuper-customers (patients, n\\n =1) and customers (doctors and \\nnurses) by leveraging lessons fr\\nom amazon, uber, and watson. \\nomics 2016;20:329–33.\\n 3.\\n dilsizian se, siegel el. artificial intelligence in medicine and car\\ndiac \\nimaging: harnessing big data and advanced computing to provide \\npersonalized medical diagnosis and treatment. curr cardiol rep 2014;16:441.\\n 4.\\n patel vl, shortlif\\nfe eh, stefanelli m, et al. the coming of age of \\nartificial intelligence in medicine. artif intell med 2009;46:5–17.\\n 5.\\n jha s, t\\nopol ej. adapting to artificial intelligence: radiologists and \\npathologists as information specialists. jama 2016;316:2353–4.\\n 6.\\n pearson t\\n. how to replicate watson hardware and systems design \\nfor your own use in your basement. 2011 https://www.\\n ibm.\\n com/\\n \\ndeveloperworks/\\n \\ncommunity/\\n \\nblogs/\\n \\ninsidesystemstorage/\\n \\nentry/\\n \\nibm_\\n \\nwatson_\\n \\nhow_\\n \\nto_\\n \\nbuild_\\n \\nyour_\\n \\nown_\\n \\nwatson_\\n \\njr_\\n \\nin_\\n \\nyour_\\n \\nbasement7?\\n \\nlang=\\n en (accessed 1 jun 2017).\\n 7.\\n w\\neingart sn, wilson rm, gibberd rw, et al. epidemiology of medical \\nerror. bmj 2000;320:774–7.\\n 8.\\n graber ml, franklin n, gor\\ndon r. diagnostic error in internal \\nmedicine. arch intern med 2005;165:1493–9. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from \",\n",
       " \"242\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access \\n 9. winters b, custer j, galvagno sm, et al. diagnostic errors in the \\nintensive care unit: a systematic review of autopsy studies. bmj qual \\nsaf 2012;21:894–902.\\n 10.\\n lee cs, nagy pg, w\\neaver sj, et al. cognitive and system factors \\ncontributing to diagnostic errors in radiology. ajr am j roentgenol 2013;201:611–7.\\n 11.\\n neill db. using artiﬁcial intelligence to impr\\nove hospital inpatient \\ncare. ieee intell syst 2013;28:92–5.\\n 12.\\n administration ufad. guidance for industry: electr\\nonic source data \\nin clinical investigations. 2013 https://www.\\n fda.\\n gov/\\n downloads/\\n \\ndrugs/\\n guidances/\\n ucm328691.\\n pdf (accessed 1 jun 2017).\\n 13.\\n gillies rj, kinahan pe, hricak h. radiomics: images ar\\ne more than \\npictures, they are data. radiology 2016;278:563–77.\\n 14.\\n li cy\\n, liang gy , yao wz, et al. integrated analysis of long non-\\ncoding rna competing interactions reveals the potential role in progression of human gastric cancer. int j oncol 2016;48:1965–76.\\n 15.\\n shin h, kim kh, song c, \\net al. electrodiagnosis support system for \\nlocalizing neural injury in an upper limb. j am med inform assoc 2010;17:345–7.\\n 16.\\n karakülah g, dicle o, ko\\nşaner o, et al. computer based extraction of \\nphenoptypic features of human congenital anomalies from the digital literature with natural language processing techniques. stud health technol inform 2014;205:570–4.\\n 17.\\n dar\\ncy am, louie ak, roberts lw. machine learning and the \\nprofession of medicine. jama 2016;315:551–2.\\n 18.\\n murf\\nf hj, fitzhenry f , matheny me, et al. automated identification \\nof postoperative complications within an electronic medical record using natural language processing. jama 2011;306:848–55.\\n 19.\\n somashekhar sp\\n, kumarc r, rauthan a, et al. abstract s6-07: \\ndouble blinded validation study to assess performance of ibm artificial intelligence platform, watson for oncology in comparison with manipal multidisciplinary tumour board ? first study of 638 breast cancer cases. cancer res 2017;77(4 suppl):s6-07.\\n 20.\\n esteva a, kupr\\nel b, novoa ra, et al. dermatologist-level \\nclassification of skin cancer with deep neural networks. nature 2017;542:115–8.\\n 21.\\n bouton ce, shaikhouni a, annetta nv\\n, et al. restoring cortical \\ncontrol of functional movement in a human with quadriplegia. nature 2016;533:247–50.\\n 22.\\n farina d, v\\nujaklija i, sartori m, et al. man/machine interface based on \\nthe discharge timings of spinal motor neurons after targeted muscle reinnervation. nat biomed eng 2017;1:0025.\\n 23.\\n marr b. first fda appr\\noval for clinical cloud-based deep learning in \\nhealthcare. 2017. https://www.\\n \\nforbes.\\n \\ncom/\\n \\nsites/\\n \\nbernardmarr/\\n \\n2017/\\n \\n01/\\n \\n20/\\n \\nfirst-\\n \\nfda-\\n \\napproval-\\n \\nfor-\\n \\nclinical-\\n \\ncloud-\\n \\nbased-\\n \\ndeep-\\n \\nlearning-\\n \\nin-\\n \\nhealthcar\\ne/#\\n 7a0ed8dc161c (accessed 1 jun 2017).\\n 24.\\n long e, lin h, liu z, \\net al. an artificial intelligence platform for the \\nmultihospital collaborative management of congenital cataracts, 2017.\\n 25.\\n gulshan v\\n, peng l, coram m, et al. development and validation of \\na deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. jama 2016;316:2402–10.\\n 26.\\n james g, witten d, hastie t\\n, et al. an introduction to statistical \\nlearning with applications in r. first edition: springer, 2013.\\n 27.\\n goodfellow i, bengio y\\n, courville a. deep learning. first edition: the \\nmit press, 2016.\\n \\n28.\\n kantor \\np . foundations of statistical natural language processing: mit \\npress, 1999:91–2.\\n 29.\\n bishop cm, ed. \\npattern recognition and machine learning \\n(information science and statistics, 2007.\\n 30.\\n orrù g, pettersson-y\\neo w, marquand af , et al. using support \\nvector machine to identify imaging biomarkers of neurological and psychiatric disease: a critical review. neurosci biobehav rev 2012;36:1140–52.\\n 31.\\n sweilam nh, tharwat aa, abdel moniem nk, moniem nka. support vector machine for diagnosis cancer disease: a comparative study\\n. \\negyptian informatics journal 2010;11:81–92.\\n 32.\\n khedher l, ram?r\\nez j, g?rriz jm, et al. early diagnosis of \\nalzheimer?s disease based on partial least squares, principal component analysis and support vector machine using segmented mri images. neurocomputing 2015;151:139–50.\\n 33.\\n in: mirtskhulava l, w\\nong j, al-majeed s, pearce g, et al; eds. \\nartificial neural network model in stroke diagnosis. modelling and simulation (uksim), 2015 17th uksim-amss international conference on: ieee, 2015.\\n 34.\\n khan j, w\\nei js, ringnér m, et al. classification and diagnostic \\nprediction of cancers using gene expression profiling and artificial neural networks. nat med 2001;7:673–9.\\n 35.\\n dheeba j, albert singh n, t\\namil selvi s. computer-aided detection \\nof breast cancer on mammograms: a swarm intelligence optimized wavelet neural network approach. j biomed inform 2014;49:45–52. 36.  hirschauer tj, adeli h, bufor d ja. computer-aided diagnosis of \\nparkinson's disease using enhanced probabilistic neural network. j med syst 2015;39:179.\\n 37.\\n ravi d, w\\nong c, deligianni f , et al. deep learning for health \\ninformatics. ieee j biomed health inform 2017;21:4–21.\\n 38.\\n lecun y\\n, bottou l, bengio y , et al. gradient-based learning applied \\nto document recognition. proc ieee inst electr electron eng 1998;86:2278–324.\\n 39.\\n resear\\nch ba. caﬀe. 2017. http://\\n \\ncaffe.\\n \\nberkeleyvision.\\n \\norg/ (accessed \\n1 jun 2017).\\n 40.\\n seide f\\n, agarwal a, eds. cntk: microsoft's open-source deep-\\nlearning toolkit. acm sigkdd international conference on knowledge discovery and data mining, 2016.\\n 41.\\n abadi m, agarwal a, barham p\\n, et al; tensorflow: large-scale \\nmachine learning on heterogeneous distributed systems, 2016.\\n 42.\\n afzal n, sohn s, abram s, \\net al. mining peripheral arterial disease \\ncases from narrative clinical notes using natural language processing. j vasc surg 2017;65:1753–61.\\n 43.\\n fiszman m, chapman ww\\n, aronsky d, et al. automatic detection \\nof acute bacterial pneumonia from chest x-ray reports. j am med inform assoc 2000;7:593–604.\\n 44.\\n miller tp\\n, li y , getz kd, et al. using electronic medical record data to \\nreport laboratory adverse events. br j haematol 2017;177:283–6.\\n 45.\\n castr\\no vm, dligach d, finan s, et al. large-scale identification of \\npatients with cerebral aneurysms using natural language processing. neurology 2017;88:164–8.\\n 46.\\n saenger ak, christenson rh. str\\noke biomarkers: progress and \\nchallenges for diagnosis, prognosis, differentiation, and treatment. clin chem 2010;56:21–33.\\n 47.\\n heeley e, anderson cs, huang y\\n, et al. role of health insurance in \\naverting economic hardship in families after acute stroke in china. stroke 2009;40:2149–56.\\n 48.\\n villar jr, gonzález s, sedano j, \\net al. improving human activity \\nrecognition and its application in early stroke diagnosis. int j neural syst 2015;25:1450036.\\n 49.\\n mannini a, t\\nrojaniello d, cereatti a, et al. a machine learning \\nframework for gait classification using inertial sensors: application to elderly, post-stroke and huntington's disease patients. sensors 2016;16:134.\\n 50.\\n rehme ak, v\\nolz lj, feis dl, et al. identifying neuroimaging markers \\nof motor disability in acute stroke by machine learning techniques. cereb cortex 2015;25:3046–56.\\n 51.\\n grif\\nfis jc, allendorfer jb, szaflarski jp . voxel-based gaussian naïve \\nbayes classification of ischemic stroke lesions in individual t1-weighted mri scans. j neurosci methods 2016;257:97–108.\\n 52.\\n kamnitsas k, ledig c, newcombe vf\\n, et al. efficient multi-scale \\n3d cnn with fully connected crf for accurate brain lesion segmentation. med image anal 2017;36:61–78.\\n 53.\\n rondina jm, filippone m, gir\\nolami m, et al. decoding post-stroke \\nmotor function from structural brain imaging. neuroimage clin 2016;12:372–80.\\n 54.\\n thor\\nnhill re, lum c, jaberi a, et al. can shape analysis differentiate \\nfree-floating internal carotid artery thrombus from atherosclerotic plaque in patients evaluated with cta?for stroke or transient ischemic attack? acad radiol 2014;21:345–54.\\n 55.\\n bentley p\\n, ganesalingam j, carlton jones al, et al. prediction of \\nstroke thrombolysis outcome using ct brain machine learning. neuroimage clin 2014;4:635–40.\\n 56.\\n love a, ar\\nnold cw, el-saden s, et al. unifying acute stroke \\ntreatment guidelines for a bayesian belief network. stud health technol inform 2013;192:1012.\\n 57.\\n y\\ne h, shen h, dong y , et al. using evidence-based medicine through \\nadvanced data analytics to work toward a national standard for hospital-based acute ischemic stroke treatment. mainland china, 2017.\\n 58.\\n zhang q, xie y\\n, ye p , et al. acute ischaemic stroke prediction from \\nphysiological time series patterns. australas med j 2013;6:280–6.\\n 59.\\n asadi h, dowling r, y\\nan b, et al. machine learning for outcome \\nprediction of acute ischemic stroke post intra-arterial therapy. plos one 2014;9:e88225.\\n 60.\\n asadi h, kok hk, looby s, \\net al. outcomes and complications after \\nendovascular treatment of brain arteriovenous malformations: a prognostication attempt using artificial intelligence. world neurosurg 2016;96:562–9.\\n 61.\\n birkner md, kalantri s, solao v\\n, et al. creating diagnostic scores \\nusing data-adaptive regression: an application to prediction of 30-day mortality among stroke victims in a rural hospital in india. ther clin risk manag 2007;3:475–84.\\n 62.\\n ho kc, speier w\\n, el-saden s, et al. predicting discharge mortality \\nafter acute ischemic stroke using balanced data. amia annu symp proc 2014;2014:1787–96. on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from \",\n",
       " ' 243\\njiang\\xa0f, et\\xa0al. stroke and vascular neurology 2017;2:e000101. doi:10.1136/svn-2017-000101open access\\n 63. chen y , dhar r, heitsch l, et al. automated quantification of cerebral \\nedema following hemispheric infarction: application of a machine-\\nlearning algorithm to evaluate csf shifts on serial head cts. neuroimage clin 2016;12:673–80.\\n 64.\\n siegel js, ramsey le, snyder az, \\net al. disruptions of network \\nconnectivity predict impairment in multiple behavioral domains after stroke. proc natl acad sci usa 2016;113:e4367–e4376.\\n 65.\\n hope tm, seghier ml, lef\\nf ap , et al. predicting outcome and \\nrecovery after stroke with lesions extracted from mri images. neuroimage clin 2013;2:424–33.\\n 66.\\n lohr s. ibm is counting on its bet on w\\natson, and paying big \\nmoney for it. 2016 https://www.\\n \\nnytimes.\\n \\ncom/\\n \\n2016/\\n \\n10/\\n \\n17/\\n \\ntechnology/\\n \\nibm-\\n \\nis-\\n \\ncounting-\\n \\non-\\n \\nits-\\n \\nbet-\\n \\non-\\n \\nwatson-\\n \\nand-\\n \\npaying-\\n \\nbig-\\n \\nmoney-\\n \\nfor-\\n \\nit.\\n \\nhtml (accessed 1 jun 2017). 67.  otake t . ibm big data used for rapid diagnosis of rare leukemia \\ncase in japan. 2016 http://www.\\n \\njapantimes.\\n \\nco.\\n \\njp/\\n \\nnews/\\n \\n2016/\\n \\n08/\\n \\n11/\\n \\nnational/\\n \\nscience-\\n \\nhealth/\\n \\nibm-\\n \\nbig-\\n \\ndata-\\n \\nused-\\n \\nfor-\\n \\nrapid-\\n \\ndiagnosis-\\n \\nof-\\n \\nrar\\ne-\\n \\nleukemia-\\n \\ncase-\\n \\nin-\\n \\njapan (accessed 1 jun 2017).\\n 68.\\n graham j. artificial intelligence, machine lear\\nning, and the fda. \\n2016 https://www.\\n \\nforbes.\\n \\ncom/\\n \\nsites/\\n \\ntheapothecary/\\n \\n2016/\\n \\n08/\\n \\n19/\\n \\nartificial-\\n \\nintelligence-\\n \\nmachine-\\n \\nlearning-\\n \\nand-\\n \\nthe-\\n \\nfda/#\\n \\n4aca26121aa1 \\n(accessed 1 jun 2017).\\n 69.\\n kayyali b, knott d, kuiken sv\\n. the big-data revolution in us health \\ncare: accelerating value and innovation. 2013 http://www.\\n mckinsey\\n.\\n \\ncom/\\n \\nindustries/\\n \\nhealthcare-\\n \\nsystems-\\n \\nand-\\n \\nservices/\\n \\nour-\\n \\ninsights/\\n \\nthe-\\n \\nbig-\\n \\ndata-\\n \\nrevolution-\\n \\nin-\\n \\nus-\\n \\nhealth-\\n \\ncare (accessed 1 jun 2017). on april 24, 2024 by guest. protected by copyright. http://svn.bmj.com/ stroke vasc neurol: first published as 10.1136/svn-2017-000101 on 21 june 2017. downloaded from ',\n",
       " 'habitat: a platform for embodied ai research\\nmanolis savva1,4*, abhishek kadian1*, oleksandr maksymets1*, yili zhao1,\\nerik wijmans1,2,3, bhavana jain1, julian straub2, jia liu1, vladlen koltun5,\\njitendra malik1,6, devi parikh1,3, dhruv batra1,3\\n1facebook ai research,2facebook reality labs,3georgia institute of technology,\\n4simon fraser university,5intel labs,6uc berkeley\\nabstract\\nwe present habitat, a platform for research in embodied\\nartiﬁcial intelligence (ai). habitat enables training embod-\\nied agents (virtual robots) in highly efﬁcient photorealistic\\n3d simulation. speciﬁcally, habitat consists of:\\n(i)habitat-sim : a ﬂexible, high-performance 3d sim-\\nulator with conﬁgurable agents, sensors, and generic 3d\\ndataset handling. habitat-sim is fast – when rendering\\na scene from matterport3d, it achieves several thousand\\nframes per second (fps) running single-threaded, and can\\nreach over 10,000fps multi-process on a single gpu.\\n(ii)habitat-api : a modular high-level library for end-to-\\nend development of embodied ai algorithms – deﬁning tasks\\n(e.g. navigation, instruction following, question answering),\\nconﬁguring, training, and benchmarking embodied agents.\\nthese large-scale engineering contributions enable us to\\nanswer scientiﬁc questions requiring experiments that were\\ntill now impracticable or ‘merely’ impractical. speciﬁcally,\\nin the context of point-goal navigation: (1) we revisit the\\ncomparison between learning and slam approaches from\\ntwo recent works [ 19,16] and ﬁnd evidence for the oppo-\\nsite conclusion – that learning outperforms slam if scaled\\nto an order of magnitude more experience than previous\\ninvestigations, and (2) we conduct the ﬁrst cross-dataset\\ngeneralization experiments {train, test }×{matterport3d,\\ngibson}for multiple sensors {blind, rgb, rgbd, d }and\\nﬁnd that only agents with depth (d) sensors generalize across\\ndatasets. we hope that our open-source platform and these\\nﬁndings will advance research in embodied ai.\\n1. introduction\\nimagine walking up to a home robot and asking ‘hey –\\ncan you go check if my laptop is on my desk? and if so, bring\\n*denotes equal contribution.it to me. ’ in order to be successful, such a robot would need\\na range of skills – visual perception (to recognize scenes and\\nobjects), language understanding (to translate questions and\\ninstructions into actions), and navigation in complex environ-\\nments (to move and ﬁnd things in a changing environment).\\nwhile there has been signiﬁcant progress in the vision\\nand language communities thanks to recent advances in deep\\nrepresentations [ 14,11], much of this progress has been\\non ‘internet ai’ rather than embodied ai. the focus of the\\nformer is pattern recognition in images, videos, and text on\\ndatasets typically curated from the internet [ 10,18,4]. the\\nfocus of the latter is to enable action by an embodied agent\\n(e.g. a robot) in an environment . this brings to the fore active\\nperception, long-term planning, learning from interaction,\\nand holding a dialog grounded in an environment.\\na straightforward proposal is to train agents directly in\\nthe physical world – exposing them to all its richness. this\\nis valuable and will continue to play an important role in the\\ndevelopment of ai. however, we also recognize that train-\\ning robots in the real world is slow (the real world runs no\\nfaster than real time and cannot be parallelized), dangerous\\n(poorly-trained agents can unwittingly injure themselves, the\\nenvironment, or others), resource intensive (the robot(s) and\\nthe environment(s) in which they execute demand resources\\nand time), difﬁcult to control (it is hard to test corner-case\\nscenarios as these are, by deﬁnition, infrequent and chal-\\nlenging to recreate), and not easily reproducible (replicating\\nconditions across experiments and institutions is difﬁcult).\\nwe aim to support a complementary research program:\\ntraining embodied agents ( e.g. virtual robots) in rich realistic\\nsimulators and then transferring the learned skills to reality.\\nsimulations have a long and rich history in science and\\nengineering (from aerospace to zoology). in the context of\\nembodied ai, simulators help overcome the aforementioned\\nchallenges – they can run orders of magnitude faster than\\nreal-time and can be parallelized over a cluster; training\\nin simulation is safe, cheap, and enables fair comparison\\n9339\\n',\n",
       " 'replica (straub et al., 201 9)datasets\\nmatterport3d (chang et al., 2017)\\n 2d-3d-s(armeni et al., 201 7)\\nsimulators\\nai2-thor\\n(kolve et al., 2017)minos\\n(savva et al., 2017)\\ngibson\\n(zamir et al., 2018)\\nchalet\\n(yan et al., 2018)house3d\\n(wu et al., 2017)habitat sim\\ngeneric dataset\\nsupporthabitat apihabitat platform\\nembodiedqa\\n(das et al., 2018)tasks\\ninteractive qa\\n(gordon et al., 2018)\\nvision -language navigation\\n(anderson et al., 2018)\\nlanguage grounding\\n(hill et al., 2017)visual navigation\\n(zhu et al., 2017 , gupta et al., 2017 )\\nfigure 1: the ‘software stack’ for training embodied agents involves (1) datasets providing 3d assets with semantic annotations, (2)\\nsimulators that render these assets and within which an embodied agent may be simulated, and (3) tasks that deﬁne evaluatable problems that\\nenable us to benchmark scientiﬁc progress. prior work (highlighted in blue boxes) has contributed a variety of datasets, simulation software,\\nand task deﬁnitions. we propose a uniﬁed embodied agent stack with the habitat platform, including generic dataset support, a highly\\nperformant simulator ( habitat-sim ), and a ﬂexible api ( habitat-api ) allowing the deﬁnition and evaluation of a broad set of tasks.\\nand benchmarking of progress in a concerted community-\\nwide effort. once a promising approach has been developed\\nand tested in simulation, it can be transferred to physical\\nplatforms that operate in the real world [ 6,15].\\ndatasets have been a key driver of progress in computer\\nvision, nlp, and other areas of ai [ 10,18,4,1]. as the\\ncommunity transitions to embodied ai, we believe that sim-\\nulators will assume the role played previously by datasets.\\nto support this transition, we aim to standardize the entire\\n‘software stack’ for training embodied agents (figure 1):\\nscanning the world and creating photorealistic 3d assets, de-\\nveloping the next generation of highly efﬁcient and paralleliz-\\nable simulators, specifying embodied ai tasks that enable\\nus to benchmark scientiﬁc progress, and releasing modu-\\nlar high-level libraries for training and deploying embodied\\nagents. speciﬁcally, habitat consists of the following:\\n1.habitat-sim : a ﬂexible, high-performance 3d\\nsimulator with conﬁgurable agents, multiple sensors, and\\ngeneric 3d dataset handling (with built-in support for mat-\\nterport3d, gibson, and replica datasets).\\n2.habitat-api : a modular high-level library for end-\\nto-end development of embodied ai algorithms – deﬁning\\nembodied ai tasks ( e.g. navigation, instruction following,\\nquestion answering), conﬁguring and training embodied\\nagents (via imitation or reinforcement learning, or via classic\\nslam), and benchmarking using standard metrics [ 2].\\nthe habitat architecture and implementation combine\\nmodularity and high performance. when rendering a scene\\nfrom the matterport3d dataset, habitat-sim achieves\\nseveral thousand frames per second (fps) running single-\\nthreaded, and can reach over 10,000fps multi-process ona single gpu, which is orders of magnitude faster than the\\nclosest simulator. habitat-api allows us to train and\\nbenchmark embodied agents with different classes of meth-\\nods and in different 3d scene datasets.\\nthese large-scale engineering contributions enable us to\\nanswer scientiﬁc questions requiring experiments that were\\ntill now impracticable or ‘merely’ impractical. speciﬁcally,\\nin the context of point-goal navigation [ 2], we make two\\nscientiﬁc contributions:\\n1.we revisit the comparison between learning and\\nslam approaches from two recent works [ 19,16] and ﬁnd\\nevidence for the opposite conclusion – that learning out-\\nperforms slam if scaled to an order of magnitude more\\nexperience than previous investigations.\\n2.we conduct the ﬁrst cross-dataset generalization exper-\\niments{train, test}×{matterport3d, gibson }for multiple\\nsensors{blind1, rgb, rgbd, d }×{gps+compass }and\\nﬁnd that only agents with depth ( d) sensors generalize well\\nacross datasets.\\nwe hope that our open-source platform and these ﬁndings\\nwill advance and guide future research in embodied ai.\\n2. related work\\nthe availability of large-scale 3d scene datasets [ 5,24,8]\\nand community interest in active vision tasks led to a recent\\nsurge of work that resulted in the development of a variety\\nof simulation platforms for indoor environments [ 17,7,13,\\n22,26,3,27,28,21]. these platforms vary with respect to\\n1blind refers to agents with no visual sensory inputs.\\n9340\\n',\n",
       " 'the 3d scene data they use, the embodied agent tasks they\\naddress, and the evaluation protocols they implement.\\nthis surge of activity is both thrilling and alarming. on\\nthe one hand, it is clearly a sign of the interest in embodied\\nai across diverse research communities (computer vision,\\nnatural language processing, robotics, machine learning). on\\nthe other hand, the existence of multiple differing simulation\\nenvironments can cause fragmentation, replication of effort,\\nand difﬁculty in reproduction and community-wide progress.\\nmoreover, existing simulators exhibit several shortcomings:\\n–tight coupling of task ( e.g. navigation), simulation plat-\\nform ( e.g. gibsonenv), and 3d dataset ( e.g. gibson). ex-\\nperiments with multiple tasks or datasets are impractical.\\n–hard-coded agent conﬁguration ( e.g. size, action-space).\\nablations of agent parameters and sensor types are not\\nsupported, making results hard to compare.\\n–suboptimal rendering and simulation performance. most\\nexisting indoor simulators operate at relatively low frame\\nrates (10-100 fps), becoming a bottleneck in training\\nagents and making large-scale learning infeasible. take-\\naway messages from such experiments become unreliable\\n– has the learning converged to trust the comparisons?\\n–limited control of environment state. the structure of the\\n3d scene in terms of present objects cannot be program-\\nmatically modiﬁed ( e.g. to test the robustness of agents).\\nmost critically, work built on top of any of the existing\\nplatforms is hard to reproduce independently from the plat-\\nform, and thus hard to evaluate against work based on a\\ndifferent platform, even in cases where the target tasks and\\ndatasets are the same. this status quo is undesirable and mo-\\ntivates the habitat effort. we aim to learn from the successes\\nof previous frameworks and develop a unifying platform that\\ncombines their desirable characteristics while addressing\\ntheir limitations. a common, unifying platform can sig-\\nniﬁcantly accelerate research by enabling code re-use and\\nconsistent experimental methodology. moreover, a common\\nplatform enables us to easily carry out experiments testing\\nagents based on different paradigms (learned vs. classical)\\nand generalization of agents between datasets.\\nthe experiments we carry out contrasting learned and\\nclassical approaches to navigation are similar to the recent\\nwork of mishkin et al. [ 19]. however, the performance\\nof the habitat stack relative to minos [ 22] used in [ 19]\\n– thousands vs. one hundred frames per second – allows\\nus to evaluate agents that have been trained with signiﬁ-\\ncantly larger amounts of experience (75 million steps vs. ﬁve\\nmillion steps). the trends we observe demonstrate that\\nlearned agents can begin to match and outperform classical\\napproaches when provided with large amounts of training\\nexperience. other recent work by koijima and deng [ 16] has\\nalso compared hand-engineered navigation agents against\\nlearned agents but their focus is on deﬁning additional met-\\nrics to characterize the performance of agents and to establish\\nfigure 2: example rendered sensor observations for three sensors\\n(color camera, depth sensor, semantic instance mask) in two differ-\\nent environment datasets. a matterport3d [ 8] environment is in\\nthe top row, and a replica [ 25] environment in the bottom row.\\nmeasures of hardness for navigation episodes. to our knowl-\\nedge, our experiments are the ﬁrst to train navigation agents\\nprovided with multi-month experience in realistic indoor\\nenvironments and contrast them against classical methods.\\n3. habitat platform\\nthe development of habitat is a long-term effort to en-\\nable the formation of a common task framework [ 12] for\\nresearch into embodied agents, thereby supporting system-\\natic research progress in this area.\\ndesign requirements. the issues discussed in the previous\\nsection lead us to a set of requirements that we seek to fulﬁll.\\n–highly performant rendering engine : resource-\\nefﬁcient rendering engine that can produce multiple chan-\\nnels of visual information ( e.g. rgb, depth, semantic\\ninstance segmentation, surface normals, optical ﬂow) for\\nmultiple concurrently operating agents.\\n–scene dataset ingestion api : makes the platform agnos-\\ntic to 3d scene datasets and allows users to use their own\\ndatasets.\\n–agent api : allows users to specify parameterized em-\\nbodied agents with well-deﬁned geometry, physics, and\\nactuation characteristics.\\n–sensor suite api : allows speciﬁcation of arbitrary num-\\nbers of parameterized sensors ( e.g. rgb, depth, contact,\\ngps, compass sensors) attached to each agent.\\n–scenario and task api : allows portable deﬁnition of\\ntasks and their evaluation protocols.\\n–implementation : c++ backend with python api and\\ninteroperation with common learning frameworks, mini-\\nmizes entry threshold.\\n–containerization : enables distributed training in clusters\\nand remote-server evaluation of user-provided code.\\n–humans-as-agents : allows humans to function as agents\\nin simulation in order to collect human behavior and in-\\nvestigate human-agent or human-human interactions.\\n–environment state manipulation : programmatic con-\\n9341\\n',\n",
       " 'trol of the environment conﬁguration in terms of the ob-\\njects that are present and their relative layout.\\ndesign overview. the above design requirements cut across\\nseveral layers in the ‘software stack’ in figure 1. a mono-\\nlithic design is not suitable for addressing requirements at\\nall levels. we, therefore, structure the habitat platform to\\nmirror this multi-layer abstraction.\\nat the lowest level is habitat-sim , a ﬂexible, high-\\nperformance 3d simulator, responsible for loading 3d scenes\\ninto a standardized scene-graph representation, conﬁguring\\nagents with multiple sensors, simulating agent motion, and\\nreturning sensory data from an agent’s sensor suite. the\\nsensor abstraction in habitat allows additional sensors such\\nas lidar and imu to be easily implemented as plugins.\\ngeneric 3d dataset api using scene graphs.\\nhabitat-sim employs a hierarchical scene graph\\nto represent all supported 3d environment datasets, whether\\nsynthetic or based on real-world reconstructions. the\\nuse of a uniform scene graph representation allows us to\\nabstract the details of speciﬁc datasets, and to treat them in a\\nconsistent fashion. scene graphs allow us to compose 3d\\nenvironments through procedural scene generation, editing,\\nor programmatic manipulation.\\nrendering engine. thehabitat-sim backend module\\nis implemented in c++ and leverages the magnum graphics\\nmiddleware library2to support cross-platform deployment\\non a broad variety of hardware conﬁgurations. the simu-\\nlator backend employs an efﬁcient rendering pipeline that\\nimplements visual sensor frame rendering using a multi-\\nattachment ‘uber-shader’ combining outputs for color cam-\\nera sensors, depth sensors, and semantic mask sensors. by\\nallowing all outputs to be produced in a single render pass,\\nwe avoid additional overhead when sensor parameters are\\nshared and the same render pass can be used for all outputs.\\nfigure 2shows examples of visual sensors rendered in three\\ndifferent supported datasets. the same agent and sensor\\nconﬁguration was instantiated in a scene from each of the\\nthree datasets by simply specifying a different input scene.\\nperformance. habitat-sim achieves thousands of\\nframes per second per simulator thread and is orders of mag-\\nnitude faster than previous simulators for realistic indoor\\nenvironments (which typically operate at tens or hundreds of\\nframes per second) – see table 1for a summary and the sup-\\nplement for more details. by comparison, ai2-thor [ 17]\\nand chalet [ 28] run at tens of fps, minos [ 22] and gib-\\nson [ 27] run at about a hundred, and house3d [ 26] runs at\\nabout300fps.habitat-sim is2-3orders of magnitude\\nfaster. by operating at 10,000frames per second we shift\\nthe bottleneck from simulation to optimization for network\\ntraining. based on tensorflow benchmarks, many popular\\nnetwork architectures run at frame rates that are 10-100x\\n2https://magnum.graphics/1process 5processes\\nsensors / resolution 128 256 512 128 256 512\\nrgb 4,093 1,987 848 10 ,592 3,574 2,629\\nrgb + depth 2,050 1,042 423 5 ,223 1,774 1,348\\ntable 1: performance of habitat-sim in frames per second\\nfor an example matterport3d scene (id 17drp5sb8fy) on an intel\\nxeon e5-2690 v4 cpu and nvidia titan xp gpu, measured at\\ndifferent frame resolutions and with a varying number of concur-\\nrent simulator processes sharing the gpu. see the supplement for\\nadditional benchmarking results.\\nlower on a single gpu3. in practice, we have observed that\\nit is often faster to generate images using habitat-sim\\nthan to load images from disk .\\nefﬁcient gpu throughput. currently, frames rendered\\nbyhabitat-sim are exposed as python tensors through\\nshared memory. future development will focus on even\\nhigher rendering efﬁciency by entirely avoiding gpu-to-\\ncpu memory copy overhead through the use of cuda-gl\\ninteroperation and direct sharing of render buffers and tex-\\ntures as tensors. our preliminary internal testing suggests\\nthat this can lead to a speedup by a factor of 2.\\nabove the simulation backend, the habitat-api layer\\nis a modular high-level library for end-to-end development\\nin embodied ai. setting up an embodied task involves speci-\\nfying observations that may be used by the agent(s), using\\nenvironment information provided by the simulator, and con-\\nnecting the information with a task-speciﬁc episode dataset.\\n–task : this class extends the simulator’s\\nobservations class and action space with task-\\nspeciﬁc ones. the criteria of episode termination and\\nmeasures of success are provided by the task . for\\nexample, in goal-driven navigation, task provides\\nthe goal and evaluation metric [ 2]. to support this\\nkind of functionality the task has read-only access to\\nsimulator andepisode-dataset .\\n–episode : a class for episode speciﬁcation that includes\\nthe initial position and orientation of an agent , scene id,\\ngoal position, and optionally the shortest path to the goal.\\nan episode is a description of an instance of the task.\\n–environment : the fundamental environment concept\\nfor habitat, abstracting all the information needed for\\nworking on embodied tasks with a simulator.\\nmore details about the architecture of the habitat plat-\\nform, performance measurements, and examples of api use\\nare provided in the supplement.\\n3https://www.tensorflow.org/guide/performance/\\nbenchmarks\\n9342\\n',\n",
       " '4. pointgoal navigation at scale\\nto demonstrate the utility of the habitat platform de-\\nsign, we carry out experiments to test for generalization of\\ngoal-directed visual navigation agents between datasets of\\ndifferent environments and to compare the performance of\\nlearning-based agents against classic agents as the amount\\nof available training experience is increased.\\ntask deﬁnition. we use the pointgoal task (as deﬁned by\\nanderson et al.[2]) as our experimental testbed. this task is\\nostensibly simple to deﬁne – an agent is initialized at a ran-\\ndom starting position and orientation in an environment and\\nasked to navigate to target coordinates that are provided rela-\\ntive to the agent’s position; no ground-truth map is available\\nand the agent must only use its sensory input to navigate.\\nhowever, in the course of experiments, we realized that\\nthis task leaves space for subtle choices that (a) can make a\\nsigniﬁcant difference in experimental outcomes and (b) are\\neither not speciﬁed or inconsistent across papers, making\\ncomparison difﬁcult. we attempt to be as descriptive as pos-\\nsible about these seemingly low-level choices; we hope the\\nhabitat platform will help iron out these inconsistencies.\\nagent embodiment and action space. the agent is physi-\\ncally embodied as a cylindrical primitive shape with diame-\\nter0.2mand height 1.5m. the action space consists of four\\nactions:turn_left ,turn_right ,move_forward ,\\nandstop . these actions are mapped to idealized actua-\\ntions that result in 10degree turns for the turning actions\\nand linear displacement of 0.25mfor themove_forward\\naction. the stop action allows the agent to signal that it\\nhas reached the goal. habitat supports noisy actuations but\\nexperiments in this paper are conducted in the noise-free\\nsetting as our analysis focuses on other factors.\\ncollision dynamics. some previous works [ 3] use a coarse\\nirregular navigation graph where an agent effectively ‘tele-\\nports’ from one location to another ( 1-2mapart). others [ 9]\\nuse a ﬁne-grained regular grid ( 0.01mresolution) where the\\nagent moves on unoccupied cells and there are no collisions\\nor partial steps. in habitat and our experiments, we use\\na more realistic collision model – the agent navigates in a\\ncontinuous state space4and motion can produce collisions\\nresulting in partial (or no) progress along the direction in-\\ntended – simply put, it is possible for the agent to ‘slide’\\nalong a wall or obstacle. crucially, the agent may choose\\nmove_forward (0.25m) and end up in a location that is\\nnot0.25m forward of where it started; thus, odometry is not\\ntrivial even in the absence of actuation noise.\\ngoal speciﬁcation: static or dynamic? one conspicuous\\nunderspeciﬁcation in the pointgoal task [ 2] is whether the\\ngoal coordinates are static (i.e. provided once at the start of\\nthe episode) or dynamic (i.e. provided at every time step).\\n4up to machine precision.the former is more realistic – it is difﬁcult to imagine a real\\ntask where an oracle would provide precise dynamic goal co-\\nordinates. however, in the absence of actuation noise and col-\\nlisions, every step taken by the agent results in a known turn\\nor translation, and this combined with the initial goal location\\nis functionally equivalent to dynamic goal speciﬁcation. we\\nhypothesize that this is why recent works [ 16,19,13] used\\ndynamic goal speciﬁcation. we follow and prescribe the\\nfollowing conceptual delineation – as a task, we adopt static\\npointgoal navigation; as for the sensor suite , we equip our\\nagents with an idealized gps sensor. this orients us towards\\na realistic task (static pointgoal navigation), disentangles\\nsimulator design (actuation noise, collision dynamics) from\\nthe task deﬁnition, and allows us to compare techniques by\\nsensors used (rgb, depth, gps, compass, contact sensors).\\nsensory input. the agents are endowed with a single color\\nvision sensor placed at a height of 1.5mfrom the center of\\nthe agent’s base and oriented to face ‘forward’. this sensor\\nprovides rgb frames at a resolution of 2562pixels and with\\na ﬁeld of view of 90degrees. in addition, an idealized depth\\nsensor is available, in the same position and orientation as\\nthe color vision sensor. the ﬁeld of view and resolution\\nof the depth sensor match those of the color vision sensor.\\nwe designate agents that make use of the color sensor by\\nrgb, agents that make use of the depth sensor by depth ,\\nand agents that make use of both by rgbd . agents that\\nuse neither sensor are denoted as blind . all agents are\\nequipped with an idealized gps and compass – i.e., they\\nhave access to their location coordinates, and implicitly their\\norientation relative to the goal position.\\nepisode speciﬁcation. we initialize the agent at a start-\\ning position and orientation that are sampled uniformly at\\nrandom from all navigable positions on the ﬂoor of the envi-\\nronment. the goal position is chosen such that it lies on the\\nsame ﬂoor and there exists a navigable path from the agent’s\\nstarting position. during the episode, the agent is allowed to\\ntake up to 500actions. this threshold signiﬁcantly exceeds\\nthe number of steps an optimal agent requires to reach all\\ngoals (see the supplement). after each action, the agent\\nreceives a set of observations from the active sensors.\\nevaluation. a navigation episode is considered successful\\nif and only if the agent issues a stop action within 0.2mof\\nthe target coordinates, as measured by a geodesic distance\\nalong the shortest path from the agent’s position to the goal\\nposition. if the agent takes 500actions without the above\\ncondition being met the episode ends and is considered un-\\nsuccessful. performance is measured using the ‘success\\nweighted by path length’ ( spl) metric [ 2]. for an episode\\nwhere the geodesic distance of the shortest path is land the\\nagent traverses a distance p,spl is deﬁned as s·l/max(p,l),\\nwheresis a binary indicator of success.\\nepisode dataset preparation. we create pointgoal naviga-\\n9343\\n',\n",
       " 'tion episode-datasets for matterport3d [ 8] and gibson [ 27]\\nscenes. for matterport3d we followed the publicly available\\ntrain/val/test splits. note that as in recent works [ 9,19,16],\\nthere is no overlap between train, val, and test scenes. for\\ngibson scenes, we obtained textured 3d surface meshes from\\nthe gibson authors [ 27], manually annotated each scene on\\nits reconstruction quality (small/big holes, ﬂoating/irregular\\nsurfaces, poor textures), and curated a subset of 106 scenes\\n(out of 572); see the supplement for details. an episode is de-\\nﬁned by the unique id of the scene, the starting position and\\norientation of the agent, and the goal position. additional\\nmetadata such as the geodesic distance along the shortest\\npath (gdsp ) from start position to goal position is also in-\\ncluded. while generating episodes, we restrict the gdsp\\nto be between 1mand30m. an episode is trivial if there\\nis an obstacle-free straight line between the start and goal\\npositions. a good measure of the navigation complexity\\nof an episode is the ratio of gdsp to euclidean distance\\nbetween start and goal positions (notice that gdsp can only\\nbe larger than or equal to the euclidean distance). if the\\nratio is nearly 1, there are few obstacles and the episode is\\neasy; if the ratio is much larger than 1, the episode is difﬁcult\\nbecause strategic navigation is required. to keep the navi-\\ngation complexity of the precomputed episodes reasonably\\nhigh, we perform rejection sampling for episodes with the\\nabove ratio falling in the range [1,1.1]. following this, there\\nis a signiﬁcant decrease in the number of near-straight-line\\nepisodes (episodes with a ratio in [1,1.1]) – from 37% to\\n10% for the gibson dataset generation. this step was not\\nperformed in any previous studies. we ﬁnd that without this\\nﬁltering, all metrics appear inﬂated. gibson scenes have\\nsmaller physical dimensions compared to the matterport3d\\nscenes. this is reﬂected in the resulting pointgoal dataset –\\naveragegdsp of episodes in gibson scenes is smaller than\\nthat of matterport3d scenes.\\nbaselines. we compare the following baselines:\\n–random chooses an action randomly among\\nturn_left ,turn_right , andmove_forward\\nwith uniform distribution. the agent calls the stop\\naction when within 0.2mof the goal (computed using the\\ndifference of static goal and dynamic gps coordinates).\\n–forward only always calls the move_forward action,\\nand calls the stop action when within 0.2m of the goal.\\n–goal follower moves towards the goal direction. if it is\\nnot facing the goal (more than 15degrees off-axis), it\\nperformsturn_left orturn_right to align itself;\\notherwise, it calls move_forward . the agent calls the\\nstop action when within 0.2m of the goal.\\n–rl (ppo) is an agent trained with reinforcement learn-\\ning, speciﬁcally proximal policy optimization [ 23]. we\\nexperiment with rl agents equipped with different visual\\nsensors: no visual input ( blind ),rgb input,depth\\ninput, and rgb with depth ( rgbd ). the model consistsof a cnn that produces an embedding for visual input,\\nwhich together with the relative goal vector is used by an\\nactor (gru) and a critic (linear layer). the cnn has the\\nfollowing architecture: {conv 8×8, relu, conv 4 ×4,\\nrelu, conv 3 ×3, relu, linear, relu }(see supplement\\nfor details). let rtdenote the reward at timestep t,dtbe\\nthe geodesic distance to goal at timestep t,sa success\\nreward and λa time penalty (to encourage efﬁciency). all\\nmodels were trained with the following reward function:\\nrt=(\\ns+dt−1−dt+λif goal is reached\\ndt−1−dt+λ otherwise\\nin our experiments sis set to10andλis set to−0.01.\\nnote that rewards are only provided in training environ-\\nments; the task is challenging as the agent must generalize\\nto unseen test environments.\\n–slam [ 19]is an agent implementing a classic robotics\\nnavigation pipeline (including components for localiza-\\ntion, mapping, and planning), using rgb and depth sen-\\nsors. we use the classic agent by mishkin et al.[19] which\\nleverages the orb-slam2 [ 20] localization pipeline,\\nwith the same parameters as reported in the original work.\\ntraining procedure. when training learning-based agents,\\nwe ﬁrst divide the scenes in the training set equally among\\n8(gibson), 6(matterport3d) concurrently running simula-\\ntor worker threads. each thread establishes blocks of 500\\ntraining episodes for each scene in its training set partition\\nand shufﬂes the ordering of these blocks. training continues\\nthrough shufﬂed copies of this array. we do not hardcode the\\nstop action to retain generality and allow for comparison\\nwith future work that does not assume gps inputs. for the\\nexperiments reported here, we train until 75million agent\\nsteps are accumulated across all worker threads. this is\\n15x larger than the experience used in previous investiga-\\ntions [ 19,16]. training agents to 75million steps took (in\\nsum over all three datasets): 320gpu-hours for blind ,\\n566gpu-hours for rgb,475gpu-hours for depth , and\\n906gpu-hours for rgbd (overall2267 gpu-hours).\\n5. results and findings\\nwe seek to answer two questions: i) how do learning-\\nbased agents compare to classic slam and hand-coded\\nbaselines as the amount of training experience increases and\\nii) how well do learned agents generalize across 3d datasets.\\nit should be tacitly understood, but to be explicit – ‘learn-\\ning’ and ‘slam’ are broad families of techniques (and not\\na single method), are not necessarily mutually exclusive,\\nand are not ‘settled’ in their development. we compare rep-\\nresentative instances of these families to gain insight into\\nquestions of scaling and generalization, and do not make any\\nclaims about intrinsic superiority of one or the other.\\n9344\\n',\n",
       " 'figure 3: average spl of agents on the val set over the course of training. previous work [ 19,16] has analyzed performance at 5-10\\nmillion steps. interesting trends emerge with more experience: i) blind agents initially outperform rgb andrgbd but saturate quickly;\\nii) learning-based depth agents outperform classic slam. the shaded areas around curves show the standard error of spl over ﬁve seeds.\\ngibson mp3d\\nsensors baseline spl succ spl succ\\nblindrandom 0.02 0.03 0.01 0.01\\nforward only 0.00 0.00 0.00 0.00\\ngoal follower 0.23 0.23 0.12 0.12\\nrl (ppo) 0.42 0.62 0.25 0.35\\nrgb rl (ppo) 0.46 0.64 0.30 0.42\\ndepth rl (ppo) 0.79 0.89 0.54 0.69\\nrgbdrl (ppo) 0.70 0.80 0.42 0.53\\nslam [ 19]0.51 0.62 0.39 0.47\\ntable 2: performance of baseline methods on the pointgoal task [ 2]\\ntested on the gibson [ 27] and mp3d [ 8] test sets under multiple\\nsensor conﬁgurations. rl models have been trained for 75million\\nsteps. we report average rate of episode success and spl [ 2].\\nlearning vs slam. to answer the ﬁrst question we plot\\nagent performance ( spl) on validation ( i.e. unseen) episodes\\nover the course of training in figure 3(top: gibson, bottom:\\nmatterport3d). slam [ 19] does not require training and\\nthus has a constant performance (0.59 on gibson, 0.42 on\\nmatterport3d). all rl (ppo) agents start out with far worse\\nspl, but rl (ppo) depth , in particular, improves dra-\\nmatically and matches the classic baseline at approximately\\n10m frames (gibson) or 30m frames (matterport3d) of ex-\\nperience, continuing to improve thereafter. notice that if\\nwe terminated the experiment at 5m frames as in [ 19] we\\nwould also conclude that slam [ 19] dominates. interest-\\ningly,rgb agents do not signiﬁcantly outperform blind\\nagents; we hypothesize because both are equipped with gps\\nsensors. indeed, qualitative results (figure 4and video in\\nsupplement) suggest that blind agents ‘hug’ walls and\\nimplement ‘wall following’ heuristics. in contrast, rgb sen-sors provide a high-dimensional complex signal that may be\\nprone to overﬁtting to train environments due to the variety\\nacross scenes (even within the same dataset). we also notice\\nin figure 3thatall methods perform better on gibson than\\nmatterport3d. this is consistent with our previous analysis\\nthat gibson contains smaller scenes and shorter episodes.\\nnext, for each agent and dataset, we select the best-\\nperforming checkpoint on validation and report results on\\ntest in table 2. we observe that uniformly across the datasets,\\nrl (ppo)depth performs best, outperforming rl (ppo)\\nrgbd (by 0.09-0.16 spl), slam (by 0.15-0.28 spl), and\\nrgb (by 0.13-0.33 spl) in that order (see the supplement for\\nadditional experiments involving noisy depth). we believe\\ndepth performs better than rgbd because i) the pointgoal\\nnavigation task requires reasoning only about free space and\\ndepth provides relevant information directly, and ii) rgb\\nhas signiﬁcantly more entropy (different houses look very\\ndifferent), thus it is easier to overﬁt when using rgb. we ran\\nour experiments with 5 random seeds per run, to conﬁrm that\\nthese differences are statistically signiﬁcant. the differences\\nare about an order of magnitude larger than the standard devi-\\nation of average spl for all cases ( e.g. on the gibson dataset\\nerrors are,depth :±0.015,rgb:±0.055,rgbd :±0.028,\\nblind :±0.005). random and forward-only agents have\\nvery low performance, while the hand-coded goal follower\\nandblind baseline see modest performance.see the sup-\\nplement for additional analysis of trained agent behavior.\\nin figure 4we plot example trajectories for the rl (ppo)\\nagents, to qualitatively contrast their behavior in the same\\nepisode. consistent with the aggregate statistics, we observe\\nthatblind collides with obstacles and follows walls, while\\ndepth is the most efﬁcient. see the supplement and the\\nvideo for more example trajectories.\\ngeneralization across datasets. our ﬁndings so far are\\nthat rl (ppo) agents signiﬁcantly outperform slam [ 19].\\nthis prompts our second question – are these ﬁndings\\n9345\\n',\n",
       " 'gibson mp3d\\nblindspl=0.28 rgbspl=0.57\\nrgbdspl=0.91 depthspl=0.98blindspl=0.35 rgbspl=0.88\\nrgbdspl=0.90 depthspl=0.94\\nfigure 4: navigation examples for different sensory conﬁgurations\\nof the rl (ppo) agent, visualizing trials from the gibson and\\nmp3d val sets. a blue dot andred dot indicate the starting and\\ngoal positions, and the blue arrow indicates ﬁnal agent position.\\ntheblue-green-red line is the agent’s trajectory. color shifts from\\nblue to red as the maximum number of agent steps is approached.\\nsee the supplemental materials for more example trajectories.\\ngibson mp3d\\nblindgibson\\nmp3d\\nrgbgibson\\nmp3d\\ndepthgibson\\nmp3d\\nrgbdgibson\\nmp3d0.250.34\\n0.280.42\\n0.300.40\\n0.250.46\\n0.540.68\\n0.560.79\\n0.420.53\\n0.440.70\\nfigure 5: generalization of agents between datasets. we report\\naverage spl for a model trained on the source dataset in each row,\\nas evaluated on test episodes for the target dataset in each column.\\ndataset speciﬁc or do learned agents generalize across\\ndatasets? we report exhaustive comparisons in figure 5\\n– speciﬁcally, average spl for all combinations of {train,\\ntest}×{matterport3d, gibson }for all agents {blind ,\\nrgb,rgbd ,depth}. rows indicate (agent, train set) pair,\\ncolumns indicate test set. we ﬁnd a number of interesting\\ntrends. first, nearly all agents suffer a drop in performance\\nwhen trained on one dataset and tested on another, e.g.rgbd\\ngibson→gibson0.70vsrgbd gibson→matterport3d 0.53\\n(drop of 0.17). rgb andrgbd agents suffer a signiﬁcant\\nperformance degradation, while the blind agent is least\\naffected (as we would expect).\\nsecond, we ﬁnd a potentially counter-intuitive trend –\\nagents trained on gibson consistently outperform their coun-\\nterparts trained on matterport3d, even when evaluated on\\nmatterport3d . we believe the reason is the previously noted\\nobservation that gibson scenes are smaller and episodes are\\nshorter (lower gdsp ) than matterport3d. gibson agents are\\ntrained on ‘easier’ episodes and encounter positive reward\\nmore easily during random exploration, thus bootstrapping\\nlearning. consequently, for a ﬁxed computation budget gib-\\nson agents are stronger universally (not just on gibson). thisﬁnding suggests that visual navigation agents could beneﬁt\\nfrom curriculum learning.\\nthese insights are enabled by the engineering of habitat,\\nwhich made these experiments as simple as a change in the\\nevaluation dataset name.\\n6. future work\\nwe described the design and implementation of the habi-\\ntat platform. our goal is to unify existing community efforts\\nand to accelerate research into embodied ai. this is a long-\\nterm effort that will succeed only by full engagement of the\\nbroader research community.\\nexperiments enabled by the generic dataset support and\\nthe high performance of the habitat stack indicate that\\ni) learning-based agents can match and exceed the perfor-\\nmance of classic visual navigation methods when trained\\nfor long enough and ii) learned agents equipped with depth\\nsensors generalize well between different 3d environment\\ndatasets in comparison to agents equipped with only rgb.\\nfeature roadmap. our near-term development roadmap\\nwill focus on incorporating physics simulation and enabling\\nphysics-based interaction between mobile agents and ob-\\njects in 3d environments. habitat-sim ’s scene graph\\nrepresentation is well-suited for integration with physics en-\\ngines, allowing us to directly control the state of individual\\nobjects and agents within a scene graph. another planned\\navenue of future work involves procedural generation of 3d\\nenvironments by leveraging a combination of 3d reconstruc-\\ntion and virtual object datasets. by combining high-quality\\nreconstructions of large indoor spaces with separately re-\\nconstructed or modelled objects, we can take full advantage\\nof our hierarchical scene graph representation to introduce\\ncontrolled variation in the simulated 3d environments.\\nlastly, we plan to focus on distributed simulation settings\\nthat involve large numbers of agents potentially interacting\\nwith one another in competitive or collaborative scenarios.\\nacknowledgments. we thank the reviewers for their help-\\nful suggestions. the habitat project would not have been\\npossible without the support and contributions of many in-\\ndividuals. we are grateful to angel xuan chang, devendra\\nsingh chaplot, xinlei chen, georgia gkioxari, daniel gor-\\ndon, leonidas guibas, saurabh gupta, jerry (zhi-yang) he,\\nrishabh jain, or litany, joel macey, dmytro mishkin, mar-\\ncus rohrbach, amanpreet singh, yuandong tian, yuxin wu,\\nfei xia, deshraj yadav, amir zamir, and jiazhi zhang for\\ntheir help.\\n9346\\n',\n",
       " 'references\\n[1]phil ammirato, patrick poirson, eunbyung park, jana\\nkošecká, and alexander c berg. a dataset for developing\\nand benchmarking active vision. in icra , 2017.\\n[2]peter anderson, angel x. chang, devendra singh chaplot,\\nalexey dosovitskiy, saurabh gupta, vladlen koltun, jana\\nkosecka, jitendra malik, roozbeh mottaghi, manolis savva,\\nand amir roshan zamir. on evaluation of embodied naviga-\\ntion agents. arxiv:1807.06757 , 2018.\\n[3]peter anderson, qi wu, damien teney, jake bruce, mark\\njohnson, niko sünderhauf, ian reid, stephen gould, and\\nanton van den hengel. vision-and-language navigation: in-\\nterpreting visually-grounded navigation instructions in real\\nenvironments. in cvpr , 2018.\\n[4]stanislaw antol, aishwarya agrawal, jiasen lu, margaret\\nmitchell, dhruv batra, c. lawrence zitnick, and devi parikh.\\nvqa: visual question answering. in iccv , 2015.\\n[5]iro armeni, ozan sener, amir r. zamir, helen jiang, ioannis\\nbrilakis, martin fischer, and silvio savarese. 3d semantic\\nparsing of large-scale indoor spaces. in cvpr , 2016.\\n[6]alex bewley, jessica rigley, yuxuan liu, jeffrey hawke,\\nrichard shen, vinh-dieu lam, and alex kendall. learning\\nto drive from simulation without real world labels. in icra ,\\n2019.\\n[7]simon brodeur, ethan perez, ankesh anand, florian golemo,\\nluca celotti, florian strub, jean rouat, hugo larochelle,\\nand aaron c. courville. home: a household multimodal\\nenvironment. arxiv:1711.11017 , 2017.\\n[8]angel chang, angela dai, thomas funkhouser, maciej hal-\\nber, matthias niessner, manolis savva, shuran song, andy\\nzeng, and yinda zhang. matterport3d: learning from rgb-\\nd data in indoor environments. in international conference\\non 3d vision (3dv) , 2017.\\n[9]abhishek das, samyak datta, georgia gkioxari, stefan lee,\\ndevi parikh, and dhruv batra. embodied question answer-\\ning. in cvpr , 2018.\\n[10] jia deng, wei dong, richard socher, li-jia li, kai li, and\\nfei-fei li. imagenet: a large-scale hierarchical image\\ndatabase. in cvpr , 2009.\\n[11] jacob devlin, ming-wei chang, kenton lee, and kristina\\ntoutanova. bert: pre-training of deep bidirectional trans-\\nformers for language understanding. arxiv:1810.04805 ,\\n2018.\\n[12] david donoho. 50 years of data science. in tukey centennial\\nworkshop , 2015.\\n[13] saurabh gupta, james davidson, sergey levine, rahul suk-\\nthankar, and jitendra malik. cognitive mapping and planning\\nfor visual navigation. in cvpr , 2017.\\n[14] kaiming he, xiangyu zhang, shaoqing ren, and jian sun.\\ndeep residual learning for image recognition. in cvpr , 2016.[15] jemin hwangbo, joonho lee, alexey dosovitskiy, dario\\nbellicoso, vassilios tsounis, vladlen koltun, and marco\\nhutter. learning agile and dynamic motor skills for legged\\nrobots. science robotics , 2019.\\n[16] noriyuki kojima and jia deng. to learn or not to learn:\\nanalyzing the role of learning for navigation in virtual envi-\\nronments. arxiv:1907.11770 , 2019.\\n[17] eric kolve, roozbeh mottaghi, daniel gordon, yuke zhu,\\nabhinav gupta, and ali farhadi. ai2-thor: an interactive\\n3d environment for visual ai. arxiv:1712.05474 , 2017.\\n[18] tsung-yi lin, michael maire, serge belongie, james hays,\\npietro perona, deva ramanan, piotr dollár, and c. lawrence\\nzitnick. microsoft coco: common objects in context. in\\neccv , 2014.\\n[19] dmytro mishkin, alexey dosovitskiy, and vladlen koltun.\\nbenchmarking classic and learned navigation in complex 3d\\nenvironments. arxiv:1901.10915 , 2019.\\n[20] raúl mur-artal and juan d. tardós. orb-slam2: an\\nopen-source slam system for monocular, stereo and rgb-d\\ncameras. ieee transactions on robotics , 33(5), 2017.\\n[21] xavier puig, kevin ra, marko boben, jiaman li, tingwu\\nwang, sanja fidler, and antonio torralba. virtualhome: sim-\\nulating household activities via programs. in cvpr , 2018.\\n[22] manolis savva, angel x. chang, alexey dosovitskiy,\\nthomas funkhouser, and vladlen koltun. minos: mul-\\ntimodal indoor simulator for navigation in complex environ-\\nments. arxiv:1712.03931 , 2017.\\n[23] john schulman, filip wolski, prafulla dhariwal, alec rad-\\nford, and oleg klimov. proximal policy optimization algo-\\nrithms. arxiv:1707.06347 , 2017.\\n[24] shuran song, fisher yu, andy zeng, angel x chang, mano-\\nlis savva, and thomas funkhouser. semantic scene comple-\\ntion from a single depth image. in cvpr , 2017.\\n[25] julian straub, thomas whelan, lingni ma, yufan chen, erik\\nwijmans, simon green, jakob j. engel, raul mur-artal, carl\\nren, shobhit verma, anton clarkson, mingfei yan, brian\\nbudge, yajie yan, xiaqing pan, june yon, yuyang zou, kim-\\nberly leon, nigel carter, jesus briales, tyler gillingham,\\nelias mueggler, luis pesqueira, manolis savva, dhruv batra,\\nhauke m. strasdat, renzo de nardi, michael goesele, steven\\nlovegrove, and richard newcombe. the replica dataset: a\\ndigital replica of indoor spaces. arxiv:1906.05797 , 2019.\\n[26] yi wu, yuxin wu, georgia gkioxari, and yuandong tian.\\nbuilding generalizable agents with a realistic and rich 3d\\nenvironment. arxiv:1801.02209 , 2018.\\n[27] fei xia, amir r. zamir, zhiyang he, alexander sax, jiten-\\ndra malik, and silvio savarese. gibson env: real-world\\nperception for embodied agents. in cvpr , 2018.\\n[28] claudia yan, dipendra misra, andrew bennnett, aaron wals-\\nman, yonatan bisk, and yoav artzi. chalet: cornell house\\nagent learning environment. arxiv:1801.07357 , 2018.\\n9347\\n',\n",
       " 'artificial intelligence, for real\\nyou’ve been told it will transform everything. \\nyou’ve been told you need to invest in it. but you haven’t been told how. start here.\\nby erik brynjolfsson and andrew mcafeethebigidea\\nreprint bg1704\\npublished on hbr.org   july 2017\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'artificial intelligence, for real erik brynjolfsson and andrew mcafee03   article  \\nthe business \\nof artificial intelligence\\n12   article  \\nwhat’s driving the machine learning explosion?\\n14   article  \\ninside facebook’s ai workshop\\n20   article   ai can be a troublesome teammate\\n22   q&a: hilary mason  \\nhow ai fits into your data science team\\n24   article  \\nwhy ai can’t write this article (yet)\\n29   live webinar  \\ndeep learning’s  \\nnext frontier\\n30   video  \\nartificial intelligence, real food\\n\\u2002hbr.org\\u2002the big idea  2 next in the big idea\\nseptember 2017dr. vivek h. murthy, the 19th surgeon general of \\nthe united states and a \\ntech entrepreneur, makes a case for why addressing social isolation and cultivating emotional well-being at work can make a real difference \\nin fighting loneliness in \\nthe u.s. drawing on his experience as both the nation’s doctor and an internist, murthy shares his insights on how our colleagues and actions at \\nwork hold the keys to our \\nhealth and the impact of our work.cover: what does it mean to be \\nhuman? what do we recognize as artificial? the art for this series was generated from a series of photographs of humans, but because of an application of distortion, you may not recognize the features they portray. or you may. (source: hbr design staff)\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'the business of artificial intelligence\\nfor more than 250 years the fundamental drivers of economic \\ngrowth have been technological innovations. the most important of these are what economists call general-purpose technologies — a category that includes the steam engine, electricity, and the internal combustion engine. each one catalyzed waves of complementary innovations and opportunities. the internal combustion engine, for example, gave rise to cars, trucks, airplanes, chain saws, and lawnmowers, along with big-box retailers, shopping centers, cross-docking warehouses, new supply chains, and, when you think \\nabout it, suburbs. companies as diverse as walmart, ups, and uber \\nfound ways to leverage the technology to create profitable new business models.\\n©2017  harvard business school publishing corporation. all rights reserved.for article reprints call 800-988-0886 or 617-783-7500, or visit hbr.orgartificial intelligence, for real erik brynjolfsson and andrew mcafee\\nwhat it can — and cannot — do for your organization  \\nby erik brynjolfsson and andrew mcafee \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  4 the most important general-purpose technology \\nof our era is artificial intelligence, particularly machine \\nlearning (ml) — that is, the machine’s ability to keep \\nimproving its performance without humans having to explain exactly how to accomplish all the tasks it’s given. within just the past few years machine learning \\nhas become far more effective and widely available. we \\ncan now build systems that learn how to perform tasks on their own.\\nwhy is this such a big deal? two reasons. first, we \\nhumans know more than we can tell: we can’t explain exactly how we’re able to do a lot of things — from rec-ognizing a face to making a smart move in the ancient \\nasian strategy game of go. prior to ml, this inability to \\narticulate our own knowledge meant that we couldn’t automate many tasks. now we can.\\nsecond, ml systems are often excellent learners. \\nthey can achieve superhuman performance in a wide range of activities, including detecting fraud and di -\\nagnosing disease. excellent digital learners are being deployed across the economy, and their impact will be \\nprofound.\\nin the sphere of business, ai is poised have a \\ntransformational impact, on the scale of earlier gen-eral-purpose technologies. although it is already in \\nuse in thousands of companies around the world, most big opportunities have not yet been tapped. the effects of ai will be magnified in the coming decade, \\nas manufacturing, retailing, transportation, finance, \\nhealth care, law, advertising, insurance, entertain-ment, education, and virtually every other industry transform their core processes and business models to \\ntake advantage of machine learning. the bottleneck \\nnow is in management, implementation, and business imagination.\\nlike so many other new technologies, however, ai \\nhas generated lots of unrealistic expectations. we see business plans liberally sprinkled with references to machine learning, neural nets, and other forms of the \\ntechnology, with little connection to its real capabilities. \\nsimply calling a dating site “ai-powered, ” for example doesn’t make it any more effective, but it might help with fundraising. this article will cut through the noise \\nto describe the real potential of ai, its practical implica-\\ntions, and the barriers to its adoption.erik brynjolfsson  \\n(@erikbryn)  is the director \\nof mit’s initiative on the \\ndigital economy, the schussel family professor of management science \\nat the mit sloan school \\nof management, and a research associate at nber. his research examines the effects of information technologies on business strategy, productivity and performance, digital commerce, and intangible assets. at mit he teaches \\ncourses on the economics \\nof information and the analytics lab.\\nbrynjolfsson was among \\nthe first researchers to measure it’s productivity contributions and the complementary role of organizational capital and other intangibles. his \\nresearch provided the first \\nquantification of online product variety value, known as the “long tail,” and developed pricing \\nand bundling models for \\ninformation goods. he earned his ab and his sm in applied mathematics and decision sciences at harvard and his phd in managerial economics at the sloan school.\\nbrynjolfsson is the author \\nof several books, including, \\nwith andrew mcafee, \\nmachine, platform, crowd: harnessing our digital future (2017) and the new \\nyork times best seller the second machine age: work, progress, and prosperity in a time of brilliant technologies (2014). you \\ncan find his papers here.\\nandrew mcafee  \\n \\n(@amcafee), a principal \\nresearch scientist at mit, studies how digital technologies are changing business, the economy, \\nand society. with erik \\nbrynjolfsson he coauthored machine, platform, crowd: harnessing our digital future (2017) and the  \\nsecond machine age: work, progress, and prosperity in a time of brilliant technologies (2014), which \\nwas a new york times best \\nseller and was shortlisted \\nfor the financial times/\\nmckinsey business book of the year award. mcafee writes academic papers, a \\nblog for the financial times, and articles for publications including harvard business \\nreview, the economist, the \\nwall street journal, and \\nthe new york times. he \\nhas talked about his work on charlie rose and 60 \\nminutes; at ted, davos, and \\nthe aspen ideas festival;  \\nand in front of many other audiences.\\nmcafee was educated \\nat harvard and mit, where he is a cofounder of the \\ninstitute’s initiative on the \\ndigital economy.the authors  \\nerik brynjolfsson  \\nand andrew mcafee\\nwhat can ai do today?\\nthe term artificial intelligence was coined in 1955 by \\njohn mccarthy , a math professor at dartmouth who \\norganized the seminal conference on the topic the fol-\\nlowing year. ever since, perhaps in part because of its evocative name, the field has given rise to more than its share of fantastic claims and promises. in 1957 the \\neconomist herbert simon predicted that computers \\nwould beat humans at chess within 10 years. (it took \\n40.) in 1967 the cognitive scientist marvin minsky  \\nsaid, “within a generation the problem of creating \\n‘artificial intelligence’ will be substantially solved. ” \\nsimon and minsky were both intellectual giants, but \\nthey erred badly. thus it’s understandable that dra-matic claims about future breakthroughs meet with a \\ncertain amount of skepticism.artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nalthough ai is already in use in thousands of \\ncompanies around the world, most big opportunities have not yet been tapped.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  5 \\nartificial intelligence, for real erik brynjolfsson and andrew mcafee let’s start by exploring what ai is already doing \\nand how quickly it is improving. the biggest advances \\nhave been in two broad areas: perception and cogni-\\ntion. in the former category some of the most practical advances have been made in relation to speech. voice recognition is still far from perfect, but millions of peo -\\nple are now using it — think siri, alexa, and google assistant. the text you are now reading was originally dictated to a computer and transcribed with sufficient accuracy to make it faster than typing. a study by the \\nstanford computer scientist james landay and col-\\nleagues found that speech recognition is now about \\nthree times as fast, on average, as typing on a cell \\nphone. the error rate, once 8.5%, has dropped to 4.9%. what’s striking is that this substantial improvement has come not over the past 10 years but just since the sum-\\nmer of 2016.\\n image recognition, too, has improved dramatically. \\nyou may have noticed that facebook and other apps now recognize many of your friends’ faces in posted \\nphotos and prompt you to tag them with their names. an app running on your smartphone will recognize vir-tually any bird in the wild. image recognition is even re -\\nplacing id cards at corporate headquarters. vision sys-tems, such as those used in self-driving cars, formerly made a mistake when identifying a pedestrian as often as once in 30 frames (the cameras in these systems re-\\ncord about 30 frames a second); now they err less often \\nthan once in 30 million frames. the error rate for recog-nizing images from a large database called imagenet, \\nwith several million photographs of common, obscure, \\nor downright weird images, fell from higher than 30% in 2010 to about 4% in 2016 for the best systems. (see the exhibit “puppy or muffin?”)\\nthe speed of improvement has accelerated rapidly \\nin recent years as a new approach, based on very large or “deep” neural nets, was adopted. the ml approach for vision systems is still far from flawless — but even \\npeople have trouble quickly recognizing puppies’ faces \\nor, more embarrassingly, see their cute faces where none exist.\\n the second type of major improvement has been \\nin cognition and problem solving. machines have al-ready beaten the finest (human) players of poker and go — achievements that experts had predicted would \\ntake at least another decade. google’s deepmind team \\nhas used ml systems to improve the cooling efficiency at data centers by more than 15%, even after they were optimized by human experts. intelligent agents are be-ing used by the cybersecurity company deep instinct \\nto detect malware, and by paypal to prevent money \\nlaundering. a system using ibm technology auto -\\nmates the claims process at an insurance company in singapore, and a system from lumidatum, a data puppy or muffin? progress in image recognition\\nmachines have made real strides in \\ndistinguishing among similar-looking \\ncategories of images.\\nsource  electronic frontier foundation © hbr.orgvision error rate\\n051015202530%\\nalgorithms\\nhumans\\n2015 2016 2014 2013 2012 2011 2010karen zack/@teenybiscuit\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  6 \\nartificial intelligence, for real erik brynjolfsson and andrew mcafeeunderstanding machine learning\\nthe most important thing to understand about ml is \\nthat it represents a fundamentally different approach \\nto creating software: the machine learns from exam-\\nples, rather than being explicitly programmed for a particular outcome. this is an important break from previous practice. for most of the past 50 years, ad-\\nvances in information technology and its applica-\\ntions have focused on codifying existing knowledge and procedures and embedding them in machines. indeed, the term “coding” denotes the painstaking \\nprocess of transferring knowledge from developers’ \\nheads into a form that machines can understand and execute. this approach has a fundamental weakness: much of the knowledge we all have is tacit, meaning \\nthat we can’t fully explain it. it’s nearly impossible for \\nus to write down instructions that would enable an-other person to learn how to ride a bike or to recognize a friend’s face.\\nin other words, we all know more than we can tell. \\nthis fact is so important that it has a name: polanyi’s paradox, for the philosopher and polymath michael \\npolanyi, who described it in 1964. polanyi’s paradox not \\nonly limits what we can tell one another but has histor-ically placed a fundamental restriction on our ability to \\nendow machines with intelligence. for a long time that science platform firm, offers timely advice to improve \\ncustomer support. dozens of companies are using ml to decide which trades to execute on wall street, \\nand more and more credit decisions are made with \\nits help. amazon employs ml to optimize inventory and improve product recommendations to custom-ers. infinite analytics developed one ml system to \\npredict whether a user would click on a particular ad, \\nimproving online ad placement for a global consumer packaged goods company, and another to improve \\ncustomers’ search and discovery process at a brazilian \\nonline retailer. the first system increased advertising roi threefold, and the second resulted in a $125 mil-\\nlion increase in annual revenue.\\nmachine learning systems are not only replacing \\nolder algorithms in many applications, but are now superior at many tasks that were once done best by \\nhumans. although the systems are far from perfect, their error rate — about 5% — on the imagenet data-base is at or better than human-level performance. \\nvoice recognition, too, even in noisy environments, is \\nnow nearly equal to human performance. reaching this threshold opens up vast new possibilities for transform-ing the workplace and the economy. once ai-based \\nsystems surpass human performance at a given task, \\nthey are much likelier to spread quickly. for instance, aptonomy and sanbot, makers respectively of drones \\nand robots, are using improved vision systems to auto -\\nmate much of the work of security guards. the software \\ncompany affectiva, among others, is using them to rec-ognize emotions such as joy, surprise, and anger in fo -\\ncus groups. and enlitic is one of several deep-learning start-ups that use them to scan medical images to help diagnose cancer.\\nthese are impressive achievements, but the appli-\\ncability of ai-based systems is still quite narrow. for in-stance, their remarkable performance on the imagenet database, even with its millions of images, doesn’t al-\\nways translate into similar success “in the wild, ” where \\nlighting conditions, angles, image resolution, and con -\\ntext may be very different. more fundamentally, we can marvel at a system that understands chinese speech \\nand translates it into english, but we don’t expect such \\na system to know what a particular chinese character means — let alone where to eat in beijing. if someone  performs a task well, it’s natural to assume that the \\nperson has some competence in related tasks. but ml \\nsystems are trained to do specific tasks, and typically their knowledge does not generalize. the fallacy that a computer’s narrow understanding implies broader un-derstanding is perhaps the biggest source of confusion, \\nand exaggerated claims, about ai’s progress. we are far \\nfrom machines that exhibit general intelligence across diverse domains.input x output y application\\nvoice recording transcript speech recognition\\nhistorical market data future market data trading bots\\nphotograph caption image tagging\\ndrug chemical properties treatment efficacy pharma r&d\\nstore transaction details is the transaction fraudulent? fraud detection\\nrecipe ingredients customer reviews food recommendations\\npurchase histories future purchase behavior customer retention\\ncar locations and speed traffic flow traffic lights\\nfaces names face recognitionsupervised learning systems\\nas two pioneers in the field, tom mitchell and michael i. jordan, \\nhave noted, most of the recent progress in machine learning \\ninvolves mapping from a set of inputs to a set of outputs. some \\nexamples:\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  7 \\nartificial intelligence, for real erik brynjolfsson and andrew mcafeeof the field, deep neural nets don’t seem to level off in \\nthis way: more data leads to better and better predic-\\ntions. some very large systems are trained by using 36 \\nmillion examples or more. of course, working with ex -\\ntremely large data sets requires more and more process-ing power, which is one reason the very big systems are \\noften run on supercomputers or specialized computer \\narchitectures.\\nany situation in which you have a lot of data on be-\\nhavior and are trying to predict an outcome is a poten-\\ntial application for supervised learning systems. jeff \\nwilke, who leads amazon’s consumer business, says that supervised learning systems have largely replaced \\nthe memory-based filtering algorithms that were used \\nto make personalized recommendations to customers. in other cases, classic algorithms for setting inventory levels and optimizing supply chains have been replaced \\nby more efficient and robust systems based on machine \\nlearning. jpmorgan chase introduced a system for re -\\nviewing commercial loan contracts; work that used to take loan officers 360,000 hours can now be done in a \\nfew seconds. and supervised learning systems are now \\nbeing used to diagnose skin cancer. these are just a few \\nexamples.\\nit’s comparatively straightforward to label a body of \\ndata and use it to train a supervised learner; that’s why supervised ml systems are more common than un su-\\npervised ones, at least for now. unsupervised learning \\nsystems seek to learn on their own. we humans are ex -\\ncellent unsupervised learners: we pick up most of our \\nknowledge of the world (such as how to recognize a tree) with little or no labeled data. but it is exceedingly difficult to develop a successful machine learning sys-\\ntem that works this way.\\nif and when we learn to build robust unsupervised \\nlearners, exciting possibilities will open up. these ma-\\nchines could look at complex problems in fresh ways to limited the activities that machines could productively perform in the economy.\\nmachine learning is overcoming those limits. in this \\nsecond wave of the second machine age, machines built by humans are learning from examples and using struc-tured feedback to solve on their own problems such as \\npolanyi’s classic one of recognizing a face.\\ndifferent flavors of machine learning\\nartificial intelligence and machine learning come \\nin many flavors, but most of the successes in recent \\nyears have been in one category: supervised learning \\nsystems, in which the machine is given lots of exam-ples of the correct answer to a particular problem. this process almost always involves mapping from a \\nset of inputs, x, to a set of outputs, y. for instance, the \\ninputs might be pictures of various animals, and the correct outputs might be labels for those animals: dog, cat, horse. the inputs could also be waveforms from \\na sound recording and the outputs could be words: \\n“yes, ” “no, ” “hello, ” “good-bye. ” (see the exhibit “supervised learning systems. ”)\\nsuccessful systems often use a training set of data \\nwith thousands or even millions of examples, each of which has been labeled with the correct answer. the system can then be let loose to look at new examples. \\nif the training has gone well, the system will predict an-\\nswers with a high rate of accuracy.\\n the algorithms that have driven much of this suc-\\ncess depend on an approach called deep learning, which \\nuses neural networks. deep learning algorithms have a \\nsignificant advantage over earlier generations of ml algorithms: they can make better use of much larger data sets. the old systems would improve as the num-ber of examples in the training data grew, but only up to \\na point, after which additional data didn’t lead to better \\npredictions. according to andrew ng, one of the giants \\nabove: this is what it means to \\nwork with artificial intelligence. the results are human and not human. recognizable but also unexpected. are they beautiful? frightening? delightful?\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  8 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nencountered before, speeding up the “pick and place” \\nprocess in distribution centers for consumer goods. \\nin reinforcement learning systems the programmer \\nspecifies the current state of the system and the goal, lists allowable actions, and describes the elements of the environment that constrain the outcomes for each \\nof those actions. using the allowable actions, the sys -\\ntem has to figure out how to get as close to the goal as \\npossible. these systems work well when humans can specify the goal but not necessarily how to get there. \\nfor instance, microsoft used reinforcement learning to \\nselect headlines for msn.com news stories by “reward-\\ning” the system with a higher score when more visitors \\nclicked on the link. the system tried to maximize its score on the basis of the rules its designers gave it. of help us discover patterns — in the spread of diseases, in price moves across securities in a market, in custom-\\ners’ purchase behaviors, and so on — that we are cur-\\nrently unaware of. such possibilities lead yann lecun, the head of ai research at facebook and a professor at nyu, to compare supervised learning systems to the \\nfrosting on the cake and unsupervised learning to the \\ncake itself.\\nanother small but growing area within the field is \\nreinforcement learning. this approach is embedded \\nin systems that have mastered atari video games and \\nboard games like go. it is also helping to optimize data \\ncenter power usage and to develop trading strategies for \\nthe stock market. robots created by kindred use ma-chine learning to identify and sort objects they’ve never \\ndesigning and implementing new combinations of technologies, \\nhuman skills, and capital assets to meet customers’ needs requires large-scale creativity and planning. it is a task that machines are \\nnot very good at.below: look deep, and you’ll see \\nthe human in the algorithm. look deeper, and you’ll see the algorithm in the intelligence.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  9 \\nartificial intelligence, for real erik brynjolfsson and andrew mcafeethe salespeople had increased their effectiveness by \\n54% and were able to serve twice as many customers \\nat a time.\\nthe ai start-up workfusion takes a similar ap-\\nproach. it works with companies to bring higher lev -\\nels of automation to back-office processes such as paying international invoices and settling large trades \\nbetween financial institutions. the reason these pro -\\ncesses haven’t been automated yet is that they’re com-plicated; relevant information isn’t always presented \\nthe same way every time (“how do we know what \\ncurrency they’re talking about?”), and some inter-\\npretation and judgment are necessary. workfusion’s \\nsoftware watches in the background as people do their work and uses their actions as training data for the cog-nitive task of classification (“this invoice is in dollars. \\nthis one is in yen. this one is in euros… ”). once the sys-\\ntem is confident enough in its classifications, it takes over the process.\\nmachine learning is driving changes at three levels: \\ntasks and occupations, business processes, and busi -\\nness models. an example of task-and-occupation re-design is the use of machine vision systems to identify \\npotential cancer cells — freeing up radiologists to focus \\non truly critical cases, to communicate with patients, and to coordinate with other physicians. an example of process redesign is the reinvention of the workflow \\nand layout of amazon fulfillment centers after the in-\\ntroduction of robots and optimization algorithms based on machine learning. similarly, business models need \\nto be rethought to take advantage of ml systems that \\ncan intelligently recommend music or movies in a per-sonalized way. instead of selling songs à la carte on the basis of consumer choices, a better model might offer \\na subscription to a personalized station that predicted \\nand played music a particular customer would like, even if the person had never heard it before.\\nnote that machine learning systems hardly ever re-\\nplace the entire job, process, or business model. most often they complement human activities, which can make their work ever more valuable. the most effec-\\ntive rule for the new division of labor is rarely, if ever, \\n“give all tasks to the machine. ” instead, if the successful completion of a process requires 10 steps, one or two of them may become automated while the rest become \\nmore valuable for humans to do. for instance, the chat \\nroom sales support system at udacity didn’t try to build a bot that could take over all the conversations; rather, \\nit advised human salespeople about how to improve \\ntheir performance. the humans remained in charge but became vastly more effective and efficient. this \\napproach is usually much more feasible than trying to \\ndesign machines that can do everything humans can do. it often leads to better, more satisfying work for the course, this means that a reinforcement learning sys-tem will optimize for the goal you explicitly reward, not necessarily the goal you really care about (such as life-time customer value), so specifying the goal correctly and clearly is critical.\\nputting machine learning to work\\nthere are three pieces of good news for organizations looking to put ml to use today. first, ai skills are \\nspreading quickly. the world still has not nearly enough \\ndata scientists and machine learning experts, but the demand for them is being met by online educational \\nresources as well as by universities. the best of these, \\nincluding udacity, coursera, and fast.ai, do much more than teach introductory concepts; they can actually get \\nsmart, motivated students to the point of being able to \\ncreate industrial-grade ml deployments. in addition to training their own people, interested companies can use online talent platforms such as upwork, topcoder, \\nand kaggle to find ml experts with verifiable expertise.\\nthe second welcome development is that the \\nnecessary algorithms and hardware for modern ai \\ncan be bought or rented as needed. google, amazon, \\nmicrosoft, salesforce, and other companies are mak -\\ning powerful ml infrastructure available via the cloud. \\nthe cutthroat competition among these rivals means \\nthat companies that want to experiment with or deploy \\nml will see more and more capabilities available at  \\never-lower prices over time.\\nthe final piece of good news, and probably the \\nmost underappreciated, is that you may not need all that much data to start making productive use of ml. the performance of most machine learning systems improves as they’re given more data to work with, so \\nit seems logical to conclude that the company with \\nthe most data will win. that might be the case if “win” means “dominate the global market for a single appli-\\ncation such as ad targeting or speech recognition. ” but \\nif success is defined instead as significantly improving performance, then sufficient data is often surprisingly easy to obtain.\\n for example, udacity cofounder sebastian thrun \\nnoticed that some of his salespeople were much more effective than others when replying to inbound queries in a chat room. thrun and his graduate student zayd \\nenam realized that their chat room logs were essentially \\na set of labeled training data — exactly what a super-vised learning system needs. interactions that led to a \\nsale were labeled successes, and all others were labeled \\nfailures. zayd used the data to predict what answers successful salespeople were likely to give in response to \\ncertain very common inquiries and then shared those \\npredictions with the other salespeople to nudge them toward better performance. after 1,000 training cycles, \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  10 \\nartificial intelligence, for real erik brynjolfsson and andrew mcafeethird, when the ml system does make errors, as it \\nalmost inevitably will, diagnosing and correcting ex -\\nactly what’s going wrong can be difficult. the underly -\\ning structure that led to the solution can be unimagin-\\nably complex, and the solution may be far from optimal if the conditions under which the system was trained \\nchange.\\nwhile all these risks are very real, the appropriate \\nbenchmark is not perfection but the best available al-\\nternative. after all, we humans, too, have biases, make \\nmistakes, and have trouble explaining truthfully how \\nwe arrived at a particular decision. the advantage of machine-based systems is that they can be improved \\nover time and will give consistent answers when pre-\\nsented with the same data.\\ndoes that mean there is no limit to what artificial in-\\ntelligence and machine learning can do? perception and \\ncognition cover a great deal of territory — from driving \\na car to forecasting sales to deciding whom to hire or promote. we believe the chances are excellent that ai will soon reach superhuman levels of performance in \\nmost or all of these areas. so what won’t ai and ml be \\nable to do?\\nwe sometimes hear “artificial intelligence will never \\nbe good at assessing emotional, crafty, sly, inconsistent human beings — it’s too rigid and impersonal for that. ” we don’t agree. ml systems like those at affectiva are already at or beyond human-level performance in dis-\\ncerning a person’s emotional state on the basis of tone \\nof voice or facial expression. other systems can infer when even the world’s best poker players are bluffing well enough to beat them at the amazingly complex \\ngame heads-up no-limit texas hold’em. reading \\npeople accurately is subtle work, but it’s not magic. it requires perception and cognition — exactly the areas \\nin which ml is currently strong and getting stronger all \\nthe time.\\na great place to start a discussion of the limits of ai \\nis with pablo picasso’s observation about computers: \\n“but they are useless. they can only give you answers. ” \\nthey’re actually far from useless, as ml’s recent tri-umphs show, but picasso’s observation still provides in-sight. computers are devices for answering questions, \\nnot for posing them. that means entrepreneurs, inno -\\nvators, scientists, creators, and other kinds of people \\nwho figure out what problem or opportunity to tackle \\nnext, or what new territory to explore, will continue to \\nbe essential.people involved and ultimately to a better outcome for customers.\\ndesigning and implementing new combinations of \\ntechnologies, human skills, and capital assets to meet customers’ needs requires large-scale creativity and planning. it is a task that machines are not very good \\nat. that makes being an entrepreneur or a business \\nmanager one of society’s most rewarding jobs in the age of ml.\\nrisks and limits\\nthe second wave of the second machine age brings with it new risks. in particular, machine learning \\nsystems often have low “interpretability, ” meaning \\nthat humans have difficulty figuring out how the sys-tems reached their decisions. deep neural networks may have hundreds of millions of connections, each \\nof which contributes a small amount to the ultimate \\ndecision. as a result, these systems’ predictions tend to resist simple, clear explanation. unlike humans, machines are not (yet!) good storytellers. they can’t \\nalways give a rationale for why a particular applicant \\nwas accepted or rejected for a job, or a particular med-icine was recommended. ironically, even as we have \\nbegun to overcome polanyi’s paradox, we’re facing a \\nkind of reverse version: machines know more than they can tell us.\\nthis creates three risks. first, the machines may \\nhave hidden biases, derived not from any intent of the designer but from the data provided to train the sys-tem. for instance, if a system learns which job appli-cants to accept for an interview by using a data set of \\ndecisions made by human recruiters in the past, it may \\ninadvertently learn to perpetuate their racial, gender, ethnic, or other biases. moreover, these biases may not \\nappear as an explicit rule but, rather, be embedded in \\nsubtle interactions among the thousands of factors considered.\\na second risk is that, unlike traditional systems built \\non explicit logic rules, neural network systems deal with statistical truths rather than literal truths. that can make it difficult, if not impossible, to prove with com-plete certainty that the system will work in all cases — \\nespecially in situations that weren’t represented in the \\ntraining data. lack of verifiability can be a concern in mission-critical applications, such as controlling a nu-\\nclear power plant, or when life-or-death decisions are \\ninvolved.while all the risks of ai are very real, the appropriate benchmark \\nis not perfection but the best available alternative.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  11 \\nartificial intelligence, for real erik brynjolfsson and andrew mcafeethis capability, it allowed them to explore the environ-\\nment far more effectively; that catalyzed an enormous \\nincrease in the number of species, both predators and \\nprey, and in the range of ecological niches that were filled. today as well we expect to see a variety of new products, services, processes, and organizational forms \\nand also numerous extinctions. there will certainly be \\nsome weird failures along with unexpected successes.\\nalthough it is hard to predict exactly which com-\\npanies will dominate in the new environment, a gen-\\neral principle is clear: the most nimble and adaptable \\ncompanies and executives will thrive. organizations \\nthat can rapidly sense and respond to opportunities \\nwill seize the advantage in the ai-enabled landscape. so the successful strategy is to be willing to experiment and learn quickly. if managers aren’t ramping up ex -\\nperiments in the area of machine learning, they aren’t doing their job. over the next decade, ai won’t replace managers, but managers who use ai will replace those \\nwho don’t.\\n\\u2002similarly, there’s a huge difference between pas-\\nsively assessing someone’s mental state or morale and actively working to change it. ml systems are getting \\nquite good at the former but remain well behind us at the latter. we humans are a deeply social species; other humans, not machines, are best at tapping into social \\ndrives such as compassion, pride, solidarity, and shame \\nin order to persuade, motivate, and inspire. in 2014 the ted conference and the xprize foundation announced  \\nan award for “the first artificial intelligence to come to \\nthis stage and give a ted talk compelling enough to \\nwin a standing ovation from the audience. ” we doubt \\nthe award will be claimed anytime soon.\\nwe think the biggest and most important opportuni-\\nties for human smarts in this new age of superpowerful \\nml lie at the intersection of two areas: figuring out what \\nproblems to work on next, and persuading a lot of peo -\\nple to tackle them and go along with the solutions. this \\nis a decent definition of leadership, which is becoming \\nmuch more important in the second machine age.\\nthe status quo of dividing up work between minds \\nand machines is falling apart very quickly. companies \\nthat stick with it are going to find themselves at an ev -\\ner-greater competitive disadvantage compared with rivals who are willing and able to put ml to use in all the places where it is appropriate and who can figure out how to effectively integrate its capabilities with \\nhumanity’s.\\na time of tectonic change in the business world has \\nbegun, brought on by technological progress. as was the case with steam power and electricity, it’s not ac-\\ncess to the new technologies themselves, or even to the best technologists, that separates winners from losers. instead, it’s innovators who are open-minded enough \\nto see past the status quo and envision very different \\napproaches, and savvy enough to put them into place. one of machine learning’s greatest legacies may well be the creation of a new generation of business leaders.\\nin our view, artificial intelligence, especially ma-\\nchine learning, is the most important general-purpose technology of our era. the impact of these innovations \\non business and the economy will be reflected not only \\nin their direct contributions but also in their ability to enable and inspire complementary innovations. new products and processes are being made possible by bet -\\nter vision systems, speech recognition, intelligent prob -\\nlem solving, and many other capabilities that machine learning delivers.\\nsome experts have gone even further. gil pratt, who \\nnow heads the toyota research institute, has compared \\nthe current wave of ai technology to the cambrian ex -\\nplosion 500 million years ago that birthed a tremendous \\nvariety of new life forms. then as now, one of the key new capabilities was vision. when animals first gained \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'getty images\\nmachine learning systems \\nhave been around since the 1950s, so why are we suddenly seeing breakthroughs in so \\nmany diverse areas? three factors are \\nat play: enormously increased data, \\nsignificantly improved algorithms, and substantially more-powerful computer hardware. over the past two decades (depending on the application) data availability has increased as much as 1,000-fold, key algorithms have \\nimproved 10-fold to 100-fold, and \\nhardware speed has improved by at least 100-fold. according to mit’s tomaso poggio, these can combine to generate improvements of up to a article\\nwhat’s driving the machine learning explosion?\\nthree factors make this ai’s moment.  \\nby erik brynjolfsson and andrew mcafee\\nmillionfold in applications such as the pedestrian-detection vision systems used in self-driving cars.\\nlet’s look at each factor in turn.data. music cds, movie dvds, and \\nweb pages have been adding to the \\nworld’s stock of digitally encoded \\ninformation for decades, but over the past few years the rate of creation has exploded. signals from sensors in smartphones and industrial equipment, digital photos and videos, a nonstop global torrent of social media, and \\nmany other sources combine to put \\nus in a totally unprecedented era of data abundance. ninety percent of the digital data in the world today has been created in the past two years alone. with the burgeoning internet of things (iot) promising to connect billions of new devices and their data streams, it’s a sure bet we’ll have far more digital data to work with in the coming \\ndecade.\\nalgorithms. the data deluge is \\nimportant not only because it makes \\nexisting algorithms more effective but also because it encourages, supports, and accelerates the development of \\nbetter algorithms. the algorithms and \\napproaches that now dominate the discipline — such as deep supervised learning and reinforcement learning — \\n \\nshare a vital basic property: their results improve as the amount of training data they’re given increases. the performance of an algorithm \\nusually levels off at some point, after \\nwhich feeding it more data has little or no effect. but that does not yet appear to be the case for many of the algorithms being widely used today. at the same time, new algorithms are transferring the learning from \\n\\u2002hbr.org\\u2002the big idea  12 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'waves from speech into meaningful \\ntext, for example — would take literally centuries to run on 1990s-vintage hardware. successes motivate more \\nbright researchers to go into the field \\nand more investors and executives to fund further work.\\nfurther amplifying these synergies \\nare two additional technologies: global networking and the cloud. the mobile internet can now deliver digital technologies virtually anywhere on the \\nplanet, connecting billions of potential \\ncustomers to ai breakthroughs. think about the intelligent assistants you’re probably already using on your smartphone, the digital knowledge bases that large companies now share globally, and the crowdsourced \\nsystems, like wikipedia and kaggle, \\nwhose main users and contributors are smart people outside your organization.\\nperhaps even more important is \\nthe potential of cloud-based ai and robotics to accelerate learning and diffusion. consider a robot in one location that struggles with a task, \\nsuch as recognizing an object. once it \\nhas mastered that task, it will be able to upload that knowledge to the cloud and share it with other robots that use a compatible knowledge-representation system (rethink robotics is working on such a platform). in this way robots, working independently, can effectively \\ngather data from hundreds, thousands, \\nand eventually millions of eyes and ears. by combining their information in a single system, they can learn vastly more rapidly and share their insights almost instantaneously.\\u2002\\n\\u2002hbr.org\\u2002the big idea  13 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\none application to another, making it possible to learn from fewer and fewer examples.\\ncomputer hardware. moore’s \\nlaw — that integrated circuit capability steadily doubles every 18 to 24 months — celebrated its 50th anniversary in 2015, at which time it was still going strong. some have commented recently that it’s running up against the limits of physics and so will slow down in the years to come; \\nand indeed, clockspeed for standard \\nmicroprocessors has leveled off. but by a fortuitous coincidence, a related type of computer chip, called a graphic processing unit, or gpu, turns out to be very effective when applied to the types of calculations needed for \\nneural nets. in fact, speedups of 10x \\nare not uncommon when neural nets are moved from traditional central processing units to gpus. gpus were initially developed to rapidly display graphics for applications such as computer gaming, which provided scale economies and drove down unit costs, but an increasing number of them are now used for neural nets. as \\nneural net applications become even \\nmore common, several companies have developed specialized chips optimized for this application, including google’s tensor processing unit, or tpu. according to shane legg, a cofounder of google deepmind, a training run that takes one day on a single tpu device \\nwould have taken a quarter of a million \\nyears on an 80486 from 1990. this can generate about another 10-fold improvement.\\nthese improvements have a \\nsynergistic effect on one another. for instance, the better hardware makes it easier for engineers to test and develop \\nbetter algorithms and, of course, \\nenables machines to crunch much larger data sets in a reasonable amount of time. some of the applications being solved today — converting sound \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'getty images\\nwithin facebook’s \\ncavernous building 20, about halfway \\nbetween the lobby \\n(panoramic views \\nof the ravenswood slough) and the kitchen (hot breakfast, smoothies, gourmet coffee), in a small conference room called lollapalooza, joaquin candela is trying to explain artificial intelligence to a layperson.\\ncandela — bald, compact, thoughtful — \\n \\nruns facebook’s applied machine learning (aml) group — the engine room of ai at facebook, which, increasingly, makes it the engine room of facebook in \\ngeneral. after some verbal searching, he \\nfinally says:\\n“look, a machine learning algorithm really is a lookup table, right? where the key is the input, like an image, and article\\ninside facebook’s ai workshop\\nat the social network behemoth, machine learning has become a \\nplatform for the platform.\\nby scott berinato\\nthe value is the label for the input, like ‘a horse.’ i have a bunch of examples of something. pictures of horses. i give the \\nalgorithm as many as i can. ‘this is a \\nhorse. this is a horse. this isn’t a horse. this is a horse.’ and the algorithm keeps those in a table. then, if a new example comes along — or if i tell it to watch for new examples — well, the algorithm just goes and looks at all those examples we fed it. which rows in \\nthe table look similar? and how similar? \\nit’s trying to decide, ‘is this new thing a horse? i think so.’ if it’s right, the image gets put in the ‘this is a horse’ group, and if it’s wrong, it gets put in the ‘this isn’t a horse’ group. next time, it has more data to look up.\\n“one challenge is how do we decide \\nhow similar a new picture is to the ones stored in the table. one aspect of machine learning is to learn similarity functions. another challenge is, what happens when your table grows really large? for every new image, you would need to make a zillion comparisons…. so another aspect of machine learning is to approximate a large stored table with a function \\ninstead of going through every image. \\nthe function knows how to roughly estimate what the corresponding value should be. that’s the essence of ml — to approximate a gigantic table \\nwith a function. this is what learning \\nis about.”\\nthere’s more to it than that, obviously, \\nbut it’s a good starting point when talking about ai, because it makes it sound real, almost boring. mechanical. so much of the conversation around ai is awash in mystical descriptions of its \\npower and in reverence for its near-\\nmagic capabilities. candela doesn’t like that and tries to use more-prosaic terms. it’s powerful, yes, but not magical. it has limitations. during presentations, he’s fond of showing a slide with a wizard and a factory, telling audiences that facebook thinks of ai like the latter, \\nbecause “wizards don’t scale.”\\nand that’s what facebook has done \\nwith ai and machine learning: scaled it \\n\\u2002hbr.org\\u2002the big idea  14 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  15 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nsolving for. know what business \\nchallenge you need to address. “you might look for the shiniest algorithm or the people who are telling you they \\nhave the most advanced algorithm. \\nand you really should be looking for people who are most obsessed with getting any algorithm to do a job. that’s kind of a profound thing that i think is lost in a lot of the conversation. i had a conversation with our resident machine learning geek at our office, and we were \\njust talking about different people doing \\nai. he said, ‘nobody really thinks their algorithms are very good or whatever.’ it makes me think, maybe that’s fine.\\n“i’m not saying don’t work on the \\nalgorithm at all. i’m saying that focusing on giving it more data and better data, \\nand then experimenting faster, makes a \\nlot more sense.”\\nso rather than defining success as \\nbuilding the best natural language processing algorithm, he defines it as deploying one that will help users find a restaurant when they ask their friends, “where can i get a good bite around here?” instead of being thrilled that some computer vision algorithm is nearing \\npixel-perfect object recognition, he gets \\nexcited if that ai is good enough to notice that you post a lot of pictures of the beach and can help you buy a swimsuit.\\nthe strategy worked when he started \\nat facebook. ad revenues rose. candela’s profile rose. it was suggested that aml become a centralized function \\nfor all of facebook. candela said \\nno. twice. “i was concerned about the ‘if you build it, they will come’ phenomenon.” just creating bits of artificial intelligence in the hope that people would see the value and adopt it wouldn’t work.\\nbut he did pick his spots. he \\ncollaborated with the feeds team while saying no to many other groups. then he worked with the messenger team. his team grew and took on more projects with other teams.he compares it to soyuz,  the 1960s \\nsoviet spacecraft. basic but reliable. gets the job done even if it’s not the newest, best thing. “it’ll get you up \\nthere and down. but it’s not the latest \\ncovnet [convolutional neural net] of the month.”\\nyou might assume, then, that the \\nfirst thing candela set out to do was to upgrade the algorithm. get rid of soyuz in favor of a space plane. it wasn’t. “to get more value, i can do three things,” \\nhe says. “i can improve the algorithm \\nitself, make it more sophisticated. i can throw more and better data at the algorithm so that the existing code produces better results. and i can change the speed of experimentation to get more results faster.\\n“we focused on data and speed, not \\non a better algorithm.”\\ncandela describes this decision as \\n“dramatic” and “hard.” computer scientists, especially academic-minded ones, are rewarded for inventing new algorithms or improving existing ones. a better statistical model is the goal. \\ngetting cited in a journal is validation. \\nwowing your peers gives you cred.\\nit requires a shift in thinking to get \\nthose engineers to focus on business impact before optimal statistical model. he thinks many companies are making the mistake of structuring their efforts around building the best algorithms, \\nor hiring developers who claim to have \\nthe best algorithms, because that’s how many ai developers think.\\nbut for a company, a good algorithm \\nthat improves the business is more valuable than vanguard statistical models. in truth, candela says, real \\nalgorithmic breakthroughs are few and \\nfar between — two or three a year at best. if his team focused its energies there, it would take lots of effort to make marginal gains.\\nhe hammers these points home \\nconstantly: figure out the impact on the business first. know what you’re at a breakneck pace. a few years ago the company’s machine learning group numbered just a few and needed days to run an experiment. now, candela \\nsays, several hundred employees run \\nthousands of experiments a day. ai is woven so intricately into the platform that it would be impossible to separate the products — your feed, your chat, your kid’s finsta — from the algorithms. nearly everything users see and do is informed by ai and machine learning.\\nunderstanding how and why facebook \\nhas so fully embraced ai can help any organization that’s ready to invest in an algorithmic future. it would be easy to assume that facebook, with all its resources, would simply get the best talent and write the best algorithms — \\ngame over. but candela took a different \\napproach. certainly the talent is strong, and the algorithms are good. some of them are designed to “see” images or automatically filter them. some understand conversations and can respond to them. some translate between languages. some try to predict what you’ll like and buy.\\nbut in some ways the algorithms are \\nnot his main focus. instead, he’s been busy creating an ai workshop in which anyone in the company can use ai to achieve a goal. basically, candela built an ai platform for the platform. whether you’re a deeply knowledgeable programmer or a complete newbie, you can take advantage of his wares.\\nhere’s how he did it and what you can \\nlearn from it.\\nsoyuz\\ncandela, a veteran of microsoft research, arrived at facebook in 2012 to work in the company’s ads business. he and a handful of staffers inherited a \\nranking algorithm for better targeting \\nusers with ads. \\ncandela describes the machine \\nlearning code he inherited as “robust but not the latest.” more than once \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'for transferring the science into the \\nproduct. it does not do research for research’s sake, and it does not build and ship products. as the upward \\nslope in the product’s readiness shows, \\nit’s a dynamic space. pointing to h2, candela says, “this needs to feel uncomfortable all the time. the people you need to hire need to be okay with that, and they need to be incredibly selfless. because if your work is successful, you spin it out. and you \\nneed to fail quite a bit. i’m comfortable \\nwith a 50% failure rate.”\\nif the team is failing less, candela \\nsuspects its members are too risk averse, or they’re taking on challenges that are sliding them closer to h1’s product focus. “maybe we do \\nsomething like that and it works, but \\nit’s still a failure, because the product teams should be taking that on, not us. if you own a piece of technology that the ads team should operate themselves to generate value, give it to them, and then increase your level of ambition in the machine learning space before something becomes product.”\\nso candela’s team is neither earning \\nthe glory of inventing new statistical models nor putting products out into the world. it’s a factory of specialists who translate others’ science for others’ \\nproducts and fail half the time.\\npush/pull\\nall that being said, the lines between the \\nthree realms — h3, h2, and h1 — still aren’t crisp. in some cases candela’s team does look at the science of \\nmachine learning, to solve specific \\nproblems. and sometimes it does help build the products.\\nthat was especially true as aml got \\noff the ground, because many people in the business hadn’t yet been exposed to ai and what it could do for them. in one case aml built a translation \\nalgorithm. the team dipped into \\nthe research space to look at how existing translation algorithms worked and could be improved, because bad translations, which either don’t \\n\\u2002hbr.org\\u2002the big idea  16 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nby 2015 candela could see that his \\ngroup would need to centralize, so he turned his attention to how he’d build such an operation. he was still worried \\nabout the “build it and they will come” \\nphenomenon, so he focused less on how his team would be structured and more on how the group would connect to the rest of facebook. “you build a factory that makes amazing widgets, and you forget to design the loading docks into your factory?” he laughs. \\n“well, enjoy your widgets.”\\nonly then, about three years in, did \\ncandela think about upgrading some \\nof his algorithms. (incidentally, even today, the emergency escape spacecraft attached to the international space station is a soyuz. )\\nh2\\ncandela goes to a whiteboard to describe how he built his ai factory inside facebook. the key, he says, was figuring out where on the product development path ai fits. he draws something like the graph on this page (see the exhibit “where ai fits in at \\nfacebook”).\\nh3 — horizon 3 or three years out \\nfrom product — is the realm of r&d \\nand science. often, data scientists who work on ai think of themselves as here, improving algorithms and looking for new ways to get machines to learn. \\ncandela didn’t put his team here for \\nthe reasons already mentioned. it’s too far from impact on the business. h1, approaching product delivery, is where the product teams live — the feeds team, the instagram team, the ads team. ai doesn’t go here either, because it would be difficult to retrofit products \\nthis deeply developed. it would be like \\nbuilding a car and then deciding that it should be self-driving after you started to put it together.\\nthat leaves h2, between the science \\nand the product, as the place aml lives at facebook. aml is a conduit source  facebook © hbr.orgwhere ai fits in at facebook\\nr&d aml product deliveryproduct readiness\\ntimeh3 h2 h1\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'this created common denominators so \\nthat one team — say, computer vision —  \\ncould work on any machine learning \\napplication involving parsing images and reuse its work whenever possible.\\nnext came a large-scale engineering \\neffort to build facebook’s own ai backbone, called fblearner flow. here algorithms are deployed once and made reusable for anyone who may need them. the time-consuming parts of setting up and running experiments are automated, and past results are stored and made available and easily \\nsearchable. and the system runs through a serious hardware array, so many \\nexperiments can be run simultaneously. (the system allows for more than 6 \\nmillion predictions a second). all of this \\nis to increase the velocity of running experiments on the data and scale.\\n\\u2002hbr.org\\u2002the big idea  17 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nmake sense or create a misleading interpretation, are in some ways worse than no translation.\\n“early on it was more push, more \\ntenacity on our part,” candela says. “but it was gentle tenacity. we weren’t going to throw something over the fence and tell the product team, ‘this is great, use it.’” that meant that his team helped write some product code. doing a little bit of the science and a little bit of the product in addition to \\nits core function was meant to inspire \\nthe product team members to see what aml could do for them.\\nwhat the two teams built — a \\nproduct that allowed community pages to instantly translate into several languages — worked. other projects \\nwere similarly pushed out, and now \\nthe international team and other product groups at facebook are pulling from aml, asking to use code in their products themselves.\\n“look, it’s nowhere near where i want \\nit to be,” candela says. “i’d like to have all the product leaders in the company get together quarterly for ai reviews. that will certainly happen. but the \\nconversation in the past two years has \\ncompletely changed. now if i walk from one end of this building to the other and i bump into, i don’t know, the video team or the messenger team, they’ll stop me and say, ‘hey, we’re excited to try this. we think we can build a product on this.’ that didn’t happen \\nbefore.”\\naml’s success, though, has created a \\nnew challenge for candela. now that \\neveryone wants a piece of aml, the factory has to scale.\\nlayer cake\\ncandela couldn’t scale just by saying yes to every project and adding bodies to get the work done. so he organized in other ways. first he subdivided his team \\naccording to the type of ai its members \\nwould focus on:applied machine learning\\naudio speechtranslation\\ntext\\nnatural \\nlanguage\\nsource  facebook © hbr. orgcamera\\ncomputer\\nphotographylauracomputer\\nvisionvisualself-serve  ai\\nfor non-technical users, e. g. lumos\\nreusable engine s\\nfor developers outside of aml , e.g. clue\\nml algorithms\\ngeneralizable by discipline\\ndeep learning framework\\ncaﬀe2\\nai backbone\\nfblearner flowless\\nmoreai/ml expertise require d\\nself-serve  ai\\nfor non-technical users, e. g. lumos\\nreusable engine s\\nfor developers outside of aml , e.g. clue\\nml algorithms\\ngeneralizable by discipline\\ndeep learning framework\\ncaﬀe2\\nai backbone\\nfblearner flowless\\nmoreability to build and customize aiself-serve  ai\\nfor non-technical users, e. g. lumos\\nreusable engine s\\nfor developers outside of aml , e.g. clue\\nml algorithms\\ngeneralizable by discipline\\ndeep learning framework\\ncaﬀe2\\nai backbone\\nfblearner flowmore\\nlessease of use\\nsource  facebook © hbr. org\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'them, aml’s role diminished. now \\nthe messenger team has improved m suggestions by building dozens more intents on its own.\\nstill, this bit of natural language ai \\nwasn’t built just for chat. it’s reusable. it was codified as clue, for “conversational learning understanding engine.” it found its way into more facebook applications. it’s being adapted for status updates and feeds. social recommendations — or social rex, as everyone calls them — are \\nincreasingly driven by ai. if you typed \\n“i’m traveling to omaha and i really want to find a good steak downtown,” ai might respond as if it were one of your friends, with a comment on your post, rex such as a list of steakhouses, and a tagged map of where they are relative \\nto downtown. if your friend replied to \\nyou and said, “it also has some great vegetarian restaurants,” the algorithm might again reply with pertinent data.\\nsocial rex intents are not yet being \\ndeveloped without aml, but the goal is to have them move out of candela’s group, just as m suggestions did.\\nin general, the idea is to make product \\nteams ai-capable themselves. “we’ll teach you to fish,” candela says, “and you go fish, and we’ll drag up the next thing. we’ll build a fishing boat. and once you’re using the fishing boat, i’m going to build a cannery, right?”\\nat the moment, about 70% of the ai \\nwork on the backbone is done by people outside candela’s team. that’s possible in part because of the interface with ai. in some cases, as with a tool called lumos, machine learning can be used by nondevelopers.\\nhorseback riding and cereal boxes\\nlumos is computer vision ai, a tool that \\ncan comb through photos on facebook or instagram or other platforms and learn what they contain. you can \\ntrain it to see anything. it has helped \\nautomate the discovery and banning of pornographic or violent content, ip appropriation (improper use of brands and logos), and other unwelcome \\ncontent. it can also help identify things \\nyou like and do (to drive personalized advertising and recommendations), on the basis of photos in your feeds.\\ni watch a demo in which engineers \\nselect “horseback riding” as our intent, the thing we’ll be looking for. the interface is simple: a few clicks, a couple of forms to fill out — what are you \\nlooking for? how much data do you want \\nto look at? — and the algorithm gets to work finding pictures of horseback riding. thumbnails start to fill the page.\\nthe algorithm has searched for \\nhorseback riding before, so it’s already \\nquite good at finding it. my guess is that \\nnorth of 80% of the images that pop up are indeed of horseback riding, and they show remarkable variety. here’s one with someone posing at a standstill. here’s one with the horse rearing. here’s an equestrian jumping. the algorithm finds shapes and boundaries between shapes and builds on previous knowledge of what those interactions \\nmean. it knows things about what \\ncombination of pixels is most likely a person, for example, and what’s a horse. it knows when it “sees” a person and a horse together with the person situated close above the horse. and it decides that this looks like horseback riding.\\nwe also find pictures that aren’t \\nhorseback riding — one is a person standing next to a horse; another is a person on a mule — and check those off as not matches. they’re framed in red, in case there’s any doubt. the algorithm internalizes that information — adds it to the lookup table — for use next time. \\na simple chart at the top of the page \\nshows the algorithm’s accuracy and confidence over time. it’s always an s curve, slow to learn at first, then rapidly improving, then tapering off on how \\nmuch more accurate it can get. it’s very \\ngood at seeing horseback riding.\\n\\u2002hbr.org\\u2002the big idea  18 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nthe system was also designed to \\naccommodate many kinds of possible users. candela believes that for ai to work, and to scale even further, he must \\nhelp people outside aml do the work \\nthemselves. he created what he calls a layer cake of artificial intelligence.\\nthe bottom layers focus on aml’s \\nwork: refining the core engine (with a strong focus on optimizing performance, especially for mobile) and working with machine learning algorithms. the \\nupper layers focus on tools that make \\nit possible for those outside aml to exploit the algorithms with less aml involvement. “it’s all about what you expose to the user,” candela says. in some cases he’s built systems that developers outside aml can take \\nadvantage of to build and run their own \\nmodels.\\nrex\\na good example of candela’s team structure and the push/pull dynamic comes from some ai built to surface content on the basis of what you type. the natural-language machine learning team created an engine to understand conversational typing.\\nthis bit of intelligence first found its \\nway into the messenger chat client. aml developed the models while the product team developed use cases and “intents” — lingo for the types of tasks you want the engine to learn. for example, training natural language ai \\nto recognize and reliably respond to a \\nphrase like “i’m looking for the best…” is an intent.\\nthe first few such intents were \\ndeployed to messenger through a product called m suggestions.\\nif you sent a chat to a friend that said \\n“i’ll meet you there in 30 minutes,” m \\nsuggestions might prompt you with an \\noffer to hire a car.\\nas the tools for building intent \\nmodels developed and the product team became more conversant with \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'at interpreting text in context to find \\nsophisticated meaning. for example, i may type, “gee, i love that movie about the superheroes. it’s so, so original! \\ni hope they make a hundred more \\nof them.” my friends, who know me and know some of the mechanics of sarcasm, may readily understand that my meaning is the opposite of what i’m typing. artificial intelligence is still learning how to decide the meaning of something like that. to figure out if \\ni’m being sarcastic, it has to go much \\nfurther than just learning how to parse grammar and vocabulary. it has to see what else i’ve said and posted, and try to find other clues that will tell it whether i really loved the movie and i want 100 more or i actually detested \\nit — because getting that wrong is \\nnot good for a platform that wants to create affinities with me. if i was being sarcastic and my feed starts filling up with superhero movie ads, i’m probably not enjoying the experience.\\nnot magic\\nit’s details like these — showing where ai is still limited, and how humans have such a core role in training it, and how solving problems and creating value \\nare more important than finding great \\nmodels — that candela is thinking about near the end of the day, when he’s talking about the mythic status ai has gained. he’s railing against what he perceives as laziness in those who find the idea of ai-as-magic-bullet appealing and don’t apply critical thinking to it.\\n“what frustrates me,” he says, “is that \\neverybody knows what a statistician is and what a data analyst can do. if i want to know ‘hey, what age segment behaves in what way?’ i get the data analyst.\\n“so when people skip that, and they \\ncome to us and say, ‘hey, give me a machine learning algorithm that will do what we do,’ i’m like, ‘what is it that i look like? what problem are you trying to solve? what’s your goal? what are \\nthe trade-offs?’” sometimes they’re \\nsurprised that there are trade-offs. “if that person doesn’t have answers to those questions, i’m thinking, ‘what the hell are you thinking ai is?’”\\nthey are thinking it’s magic.“but it’s not. that’s the part where i \\ntell people, ‘you don’t need machine learning. you need to build a data science team that helps you think \\nthrough a problem and apply the \\nhuman litmus test. sit with them. look at your data. if you can’t tell what’s going on, if you don’t have any intuition, if you can’t build a very simple, rule-\\nbased system — like, hey, if a person \\nis younger than 20 and living in this geography, then do this thing — if you can’t do that, then i’m extremely nervous even talking about throwing ai at your problem.’\\n“i’m delighted when other executives \\ncome to me and start not from wanting to understand the technology but from a problem they have that they’ve \\nthought very, very deeply about. and \\nsometimes — often, in fact — a simple, good old rule-based system, if you have the right data, will get you 80% of the way to solving the problem.”\\n“and guess what? it’s going to have \\nthe benefit that everybody understands it. exhaust the human brain first.”\\u2002\\nabout the author: scott berinato  is a \\nsenior editor at harvard business review and \\nthe author of good charts: the hbr guide to making smarter, more persuasive data visualizations (2016).\\n\\u2002hbr.org\\u2002the big idea  19 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nother potentially valuable pictures \\nare harder for ai to parse. “receipts” \\nis tricky to suss out because it can look to a computer just like type on a page; \\nbut there would be some interesting \\napps for ai that could recognize and “read” receipts. the engineers show how bowling alleys and escalators often confuse the algorithm because they have similar shapes and visual properties.\\ni ask, “what about something like \\n‘food’?” this brings us to an important point about machine learning: it’s only as good as its training.\\nwe call up food as a topic to train. \\nindeed, we see lots of pictures of fruits and vegetables, a few of plates at restaurants. all food. we also see a \\ncereal box. is that food?\\nwell, yes. or no. it’s a box. but there’s \\nfood in it. when we buy it, we’re buying \\nfood, not the box. if i asked if there was any food in the cupboard, you wouldn’t say, “no, just a cereal box.” (or, more pertinent to facebook, if i posted a picture of a cereal box, should it think i’m posting about food or about a box?) as a picture, as a piece of data, it’s a \\nbox.\\nshould we mark this as a match or a \\nmiss? here’s part of the art of machine \\nlearning. when training algorithms, one needs to use clearly definable categories. food is probably too general in some ways, and the algorithm will either improperly hit or miss on images \\nbecause it’s hard to know what we \\nmean when we say, “show me pictures of food.” “vegetable” is a better idea to train on. and when training, everyone must define terms in the same way. imagine two people training the algorithm when one always marks cereal boxes as food, and the other \\nmarks them as not food. now imagine \\nthat happening at scale, on terabytes of visual data.\\nthe same applies to natural language \\nprocessing. humans are very good \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'getty images\\nartificial intelligence \\npromises to make decisions better and faster than humans can — \\n \\neven smart humans. ai’s \\nsuperiority is clear when the choice is “which road should i take home?” or “how should i organize distribution \\nchains?” but in life-or-death situations, \\ncan ai deliver?\\ni’m a social psychologist who studies \\ntechnology, but when i was in college, i worked for a geophysical surveying company. we looked for natural gas in the frozen forests of northern canada. most sites were remote and very \\ncold. many could be reached only by \\nhelicopter.\\none winter afternoon a pilot at \\none of those sites radioed with bad news: a storm had moved in, making article\\nai can be a troublesome teammate\\nai is a focused intelligence, groomed for maximum perfection.  \\nthat’s why, research shows, most people don’t trust it.  \\nby kurt gray\\nvisibility poor and flying dangerous. \\nmy crew chief, ian, had to make a difficult decision: should he risk our lives by flying in the storm or by staying \\novernight in the frigid wilderness with \\nno food or shelter? he chose to stay overnight. although we faced freezing temperatures, i had full faith in ian’s decision. he had worked for years as a wilderness firefighter, and he knew about survival. i literally trusted him with my life. \\nif my company had been using ai, ian \\nmight not have been making decisions that night. a computer program could have weighed the weather against the costs of losing the crew against the costs of losing the helicopter against many other factors. that intelligent \\nmachine might have come to the same \\nconclusion ian did — that stranding us overnight was the best possible \\nchoice — but would i have trusted that \\ndecision? would i have felt safe?\\nmy work since suggests that i would \\nnot have trusted ai with my life. and that lack of trust raises serious roadblocks for the full implementation of ai in the workforce, even when no \\nlives are at stake.\\nmy research examines how people \\nunderstand other minds — human \\nminds, animal minds, and computer minds — and reveals that their contents are more ambiguous than we often think. we can never directly experience \\nthe thoughts and feelings of others, and \\nso we’re left to make our best guesses about questions such as: does your baby love you as much as you love him? when your boss smiles, is she actually happy? does your dog feel embarrassed when you catch it doing something \\nnaughty?\\nalthough biological minds can be hard \\nto understand, the nature of computer \\nminds is even more opaque. when deep blue beats garry kasparov at chess, does it want to win or is it just programmed to do so? when google alerts us to the best route home after \\n\\u2002hbr.org\\u2002the big idea  20 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  21 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nwork, does it really understand what \\nit means to commute? when netflix recommends a movie we might like, does it care about our enjoyment?\\npeople perceiving the minds of ai see \\nthem as very one-sided — capable of powerful thought but totally incapable of feeling. it’s a pretty accurate perception of current technology, because neither google nor netflix can fall in love or enjoy the taste of chocolate. but what truly limits ai — or \\nat least its role in the workforce — is \\nthat people believe that robots will never feel.\\nin part, it’s that inability to feel that \\nmakes people regard ai as untrustworthy.  \\nthis is incredibly important for the deployment of ai. will employees \\ntrust something that views them in \\npurely functional terms — as workers with certain skill sets — rather than as individuals with hopes and concerns?\\ntrusting team members requires at \\nleast three things: mutual concern, a shared sense of vulnerability, and faith in \\ncompetence. mutual concern — knowing \\nthat your teammates care about your \\nwell-being — is perhaps the most basic element of trust. when a platoon leader risks being shot by going behind enemy lines to rescue one of his soldiers, he is not making the optimal decision from a functional perspective. however, the very fact that — unlike an ai system — \\nhe will choose this “irrational” course \\nof action makes everyone in the platoon trust him more, which leads to better overall team performance.\\nin everyday situations, where careers \\nand promotions are at stake, we still want to know that supervisors \\nand coworkers see us as people \\nrather than as variables in a giant optimization problem. we want to be something more than a row in an inventory spreadsheet. but that’s all ai understands us to be.\\nwe mistrust ai not only because it \\nseems to lack emotional intelligence but also because it lacks vulnerability. if humans mess up in a job, they can be fired, lose a bonus, or even die. but in an ai workplace, if an expert decision-making system wrongly recommends one course of action over another, the computer suffers no consequences. \\nai systems are gambling only with the \\nfates of others, never with their own.\\nthe third impediment to trust is \\nactually ai’s strength: its superhuman ability to calculate and predict. we are quick to trust ai’s competence after seeing firsthand how it can arrive at \\nhuge sums in seconds or forecast the \\nmovement of stocks. unfortunately, this can work against ai, because it performs well only under narrow conditions. when it is pushed to operate outside its limits — when a whole family uses the same netflix account, or when google is asked to \\npredict the outcome of a relationship — \\ndisappointment is inevitable.\\ni recently spoke with someone in \\nthe office of naval research, part of the u.s. department of defense, who outlined how technologically inexperienced sailors operate ai systems. first they approach ai with a \\nsense of awe, expecting it to complete \\nevery job perfectly. but if a system makes mistakes that seem — from the point of view of humans — obviously stupid, the sailors stop using it altogether, even in the structured situations in which ai would actually \\nexcel. to build trust, ai needs to \\ncommunicate its confidence or, even better, express its fear of failure.\\nno one can dispute that ai is leaping \\nahead in sophistication, but our ability to trust it is lagging behind. this is important because in many industries success requires deep and implicit trust \\nwithin teams. on oil rigs and in army \\nplatoons, trusting your teammates can be a matter of life or death. in less dangerous businesses, trust can make the difference between succeeding and failing to close a deal or finish a project. we trust other people not because they are incredibly smart — like ai — but because they have emotional connections, specifically with us.\\nthat doesn’t mean ai isn’t useful. \\nquite the contrary. it represents \\na deconstructed mind, a focused \\nintelligence groomed for maximum performance. in so many ways, it is unlike the well-rounded human mind, which can comprehend language, solve problems, and understand others’ feelings all at the same time.\\nif i were working at that surveying job \\nin northern canada today, i still might not trust a computer to save my life in the forest, but i would trust ai to screen the weather and decide against our even venturing forth that morning. i’m glad i had a human crew chief, but i wish a computer had prevented our \\nbeing stranded in the first place.\\u2002\\nabout the author: kurt gray  is an associate \\nprofessor of psychology and neuroscience at \\nthe university of north carolina, chapel hill. he received his phd from harvard university. gray studies mind perception, moral \\njudgment, social dynamics, and creativity and \\nis an award-winning researcher and teacher. he is a coauthor (with daniel wegner) of the mind club: who thinks, what feels, and why it matters.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'getty images\\nin their hbr big idea feature, \\nerik brynjolfsson and andrew mcafee argue that ai and machine learning will soon become \\n“general-purpose technologies” as \\nsignificant as electricity or the internal \\ncombustion engine. they represent a landmark change in our technical capabilities and will power the next wave of economic growth.\\nbut how will we put them into \\npractice? where in the organization will \\nthese new capabilities sit, and how will \\ncompanies take advantage of them?\\nto get a practical, on-the-ground \\nview, hbr senior editor walter frick spoke with hilary mason, the founder of fast forward labs, a machine intelligence research firm. here are \\nexcerpts from their conversation.\\nhbr: ai is a hot topic right now. as a \\ndata scientist and a researcher, how do you think about the recent progress in your field?q&a: hilary mason\\nhow ai fits into your data science team\\nit helps to know the three things data scientists do.\\nmason:  if we were having this \\nconversation eight or 10 years ago, it would have been about big data — about whether we could even build the \\ninfrastructure to get all the data in one \\nplace and query it. once you can do that, you can do analytics — which is essentially counting things to answer questions that have business value or product value. people could always count things in data, but the change we saw about eight years ago was that new \\nsoftware made doing it affordable and \\naccessible for a wide variety of people who never could do it before. \\nand that led to the rise of data \\nscience, which is about counting things cleverly, predicting things, and building models on data. because that \\nmodeling was now so much cheaper, it \\nwas applied not just to very high value problems, like actuarial science, but to things that may seem fairly trivial, like recommendations, search results, and that kind of stuff. then we had machine learning, which \\nis a set of tools inside data science that let you count things cleverly and incorporate feedback loops. we began using the models to get more data from \\nthe world and fed it back into those \\nmodels so that they improved over time. \\nnow today we talk about ai. the term \\nitself is a little bit loose and has both a technical meaning and a marketing meaning, but it’s essentially about using \\nmachine learning — and specifically \\ndeep learning — to enable applications that are built on top of this stack. that means that you can’t do ai without machine learning. you also can’t do machine learning without analytics, and you can’t do analytics without data infrastructure. and so that’s how i see \\nthem all being related.\\nhow do machine learning and ai fit into \\ncompanies’ existing data capabilities?data science is used in multiple ways inside an organization, and a really common mistake i see people make in \\nmanaging it is assuming that because \\nit runs on one tech stack, it’s just one thing. but i’d break it down into three capabilities, all of which rely on the same technology. the first capability is understanding the business. that’s \\n\\u2002hbr.org\\u2002the big idea  22 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'function of data science because it can \\ngenerate new product opportunities. for example, several companies are using deep learning very successfully in \\ne-commerce recommendation systems. \\nthen of course deep learning affects the r&d function by pushing the frontier of what is technically possible.\\nso data science is about analytics, \\nproduct development, and r&d. is this a walk-before-you-run situation? or \\nshould companies attempt all three at \\nonce?it’s a little bit of both. you’ll leave opportunities on the table if you pursue only one of these use cases. however, it really helps to get your infrastructure and analytics piece to \\nbe fairly solid before jumping into r&d. \\nand in practice we see that people are much more comfortable investing in cost-saving initiatives before they invest in new revenue opportunities. it’s just more culturally acceptable.\\nwhat other mistakes do you see com\\n-\\npanies making in their data science \\nefforts?a big one involves process. we’ve noticed that people shoehorn this kind \\nof stuff into the software-engineering \\nprocess, and that doesn’t work. developing data science systems is fundamentally different in several ways. at the outset of a data science project, you don’t know if it’s going to work. at the outset of a software-engineering project, you know it’s going to work. \\nthis means that software-engineering \\nprocesses fail when they encounter uncertainty. by contrast, data science requires an experimental process that allows for uncertainty. \\nalso, every company has its own \\ncultural hurdle to get over. a lot of \\ncompanies aren’t places where you \\ncan work on something that doesn’t succeed, so the poor data scientists who do the risky research projects end up getting penalized in their annual \\nreviews because they worked on \\nsomething for two months that didn’t pay off, even though they did great work. data science requires having that cultural space to experiment and work on things that might fail. companies need to understand that they’re investing in a portfolio of initiatives, some of which will eventually pay off, generating dramatically \\nmore value than incremental product \\nimprovements do.\\nhow do you navigate all the buzz \\naround this topic, and how do you rec\\n-\\nommend executives do so?i remain a relentless optimist about the potential of what we’re now calling ai, but i’m also a pragmatist in the \\nsense that i need to deliver systems \\nthat work to our clients, and that is quite a constraint. there are some folks running around making claims that are clearly exaggerated and ridiculous. in other cases things that a few years ago we would have called a regression analysis are now being called ai, just to enhance their value from a marketing perspective. so my advice is to keep \\nin mind that there is no magic. at a \\nconceptual level nothing here is out of reach of any executive’s understanding. and if someone is pitching you on an idea and says, “i don’t want to explain how it works, but it’s ai,” it’s really important to keep asking: how does it work? what data goes in? what \\npatterns might be in the data that the \\nsystem could be learning? and what comes out? because what comes out of a deep learning system is generally just a previously unlabeled data point that now has a label, along with some confidence in that label, and that’s it. \\nit’s not intelligent in the sense that you \\nand i are — and we’re still a long, long way away from anything that looks like the kind of intelligence a human has.\\u2002analytics, or business intelligence — being able to ask questions and analyze information to make better decisions. it’s usually run out of the cfo or coo’s \\noffice. it’s not necessarily a technical \\ndomain. \\nthe second capability is product \\ndata science: building algorithms and systems — which may use machine learning and ai — that actually improve the product. this is where things like spam filters, recommendation \\nsystems, search algorithms, and data \\nvisualization come in. this capability usually sits under a line of business and is run out of product development or engineering. \\nthe last data capability is one that \\ntends to get neglected or lumped in \\nwith product data science. it’s an r&d \\ncapability — using data to open up new product, new business, and new revenue opportunities. \\nand are all three capabilities changed \\nby machine learning and ai?let’s take a moment and look more closely at what deep learning offers, since it’s central to a lot of what \\npeople now call ai and a big part of the \\nprogress in machine learning in recent years. first, deep learning makes data that was previously inaccessible to any kind of analysis accessible — you can actually find value in video and audio data, for example. the number of companies that have a large amount \\nof that kind of data is still fairly small, \\nbut i do think it’s likely to increase over time. even analytics is impacted by the ability to use image data rather than just text or structured data. second, deep learning enables new approaches to solving very difficult data science problems — text summarization, for \\nexample. deep learning allows you to \\ncreate predictive models at a level of quality and sophistication that was previously out of reach. and so deep learning also enhances the product \\n\\u2002hbr.org\\u2002the big idea  23 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'getty images\\nroger schank, a researcher \\nand former professor, once proposed a novel goal for artificial intelligence: a \\ncomputer should be able \\nto watch west side story and recognize \\nthe plot of romeo and juliet. schank and his students believed that stories are central to intelligence, reasoning, and meaning. by schank’s measure, today’s ai isn’t intelligent at all.\\nthe feature article on ai that hbr.org \\npublished earlier this week is, ironically, a good example of the kind of work that computers can’t yet do. it was written by two experts who drew on decades of experience to formulate a thesis, assemble evidence, and construct a narrative. and three editors helped \\nto shape the nearly 5,000 words that \\nmade it into the final piece.\\nthe fact that software can’t yet \\nwrite an article like that isn’t a knock on ai, or evidence that it won’t be transformative. but that fact offers a window into how, exactly, machine learning technologies work, what they article\\nwhy ai can’t write this article (yet)\\nmachines are learning faster and better than ever, but they still \\nhave limitations. by walter frick\\nare and aren’t good at right now, and how they’ll develop as writing tools — or even writers — in the future.\\nnot ready for long-form\\ntoday’s ai works by formulating tasks as prediction problems and then using statistical techniques and lots of data to make predictions. one simple \\nexample of a text-based prediction \\nproblem is auto-complete. when i type “how’d” into a text message, my phone uses data and statistical modeling to predict what’s coming next. it offers “it,” “you,” or “the.” “it” is what i had in mind, and once i select that, my phone moves on to predicting the next \\nword. this time it’s so confident that \\ni’m going to select “go” (which is right) that it doesn’t even offer other options but instead moves on to the next word, suggesting “go with” or “go today.” in machine learning, prediction problems like this are called supervised learning.  \\ngiven a data set containing the right answer — in this case lots of completed text messages — an algorithm learns to recognize patterns, such as that “go” often follows “how’d it.” (another kind of machine learning, unsupervised learning, works differently, but supervised learning has driven most of \\nthe recent progress in the field.)\\nthe process of writing a magazine \\nfeature can’t easily be distilled into a \\nprediction problem, however — at least not yet. as sam bowman, a professor at new york university, told a recent conference on ai and journalism, “the \\nnotion of really generating long-form \\ncoherent text without a very clear, journalist-specified template is quite far away.” researchers have shown that machine learning can generate coherent text in specific settings, bowman notes, but “really building systems that are \\nable to go all the way from an abstract \\nidea or a set of facts to a long-form coherent text is still something that’s quite difficult.”\\nto illustrate that difficulty, bowman \\npointed to a screenplay, titled \\nsunspring, written last year using \\nmachine learning. the script was generated by feeding dozens of science fiction screenplays into a neural network — a type of machine learning algorithm — at the character level, meaning that the unit of data \\nthe algorithm was learning from was \\na single character of text. given the characters that had come before, the \\n\\u2002hbr.org\\u2002the big idea  24 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'exist only in the sense that they’ve \\nbeen given sentences to speak. the script shows how far machine learning has to go before it masters \\nstorytelling, or becomes “intelligent.” \\nyet the algorithm’s ability to construct sentences and to recognize basic features of a screenplay suggests that ai could play a role in the future of writing. but that future, at least in the near term, is limited.\\nai-generated summaries\\none area of writing in which machine learning is already making useful progress is summaries. finding the most important parts of a text and producing \\na summary is an extremely common \\nwriting task: press teams compile “clips” of the day’s news, reporters summarize previous developments while writing a story, think tanks summarize a new study, book editors summarize a chapter. some of that work can now be done by machines, and start-ups  \\nand tech companies alike are racing to \\nbuild tools and products to make it more accessible.\\nauto-summarization techniques usually \\nfit one of two categories: extractive or abstractive. extractive methods try to identify the most important sentences \\nin a document and then create a \\nsummary by stitching them together. modern versions of this technique are quite complicated, but the original idea, which hans peter luhn introduced at ibm in 1958, gives a sense of the \\napproach. luhn proposed that the words \\nused most frequently in a document \\n\\u2002hbr.org\\u2002the big idea  25 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nalgorithm was learning to predict which character would come next. \\nthe result appears above. you don’t \\nwant to skip it.\\nthat the actors in sunspring are \\nspeaking actual english words is itself impressive (even if they don’t make much sense): before the neural network “read” those scripts, it not only didn’t know how to write a screenplay but also had no knowledge of the english language. it learned some of the \\nfeatures of a screenplay — for instance, \\nthat lines of text should be assigned to characters and that stage directions should be included. again, it learned all this just by reading a few dozen scripts.\\nwhat it didn’t pick up from all those \\nscreenplays was the art of narrative. \\nsunspring has no story. its characters \\n► play  9:02  \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  26 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nbuilt by fast forward labs, a research \\nfirm. using actual articles and summaries from a website of reading recommendations, the fast forward \\nteam trained a neural network to \\nscore sentences according to the likelihood that they would be included in a summary. the highest-scoring sentences, combined in the order in which they appear in the original article, become the summary. in the case of our article, the model’s highest-\\nscoring sentence is the one beginning \\n“the most important general-purpose technology of our era is artificial intelligence,” which is also arguably the article’s thesis. in that sense, the extractive summarizer did well. but when the top seven sentences are \\narranged in their original order, the \\nfirst sentence includes the pronoun worked very well. as the sunspring script illustrates, generating new language is difficult. but progress in deep learning, a subfield of machine learning, has \\nled to renewed interest in abstractive \\nsummarization and produced some promising results.\\nto illustrate what machine learning \\ncan and can’t do, let’s compare an editor-written summary of our ai feature with two automated summaries, one extractive and one abstractive. (see \\nthe sidebar “three summaries: human, \\nextractive, and abstractive.”)\\nthe first summary was written by an \\nhbr editor. it’s grammatically correct, it contains the article’s main point, and it speaks in the third person (“the authors describe”).\\nthe second summary is extractive \\nand was produced using a prototype (excluding very common words such as “the” and “and”) offer clues to the document’s subject. sentences that contain those common words are \\ntherefore most representative of the \\ndocument; by extracting those sentences and combining them into a paragraph, something approximating a summary can be created. (even in describing this original approach, i’m oversimplifying. for more, see an excellent history of the subfield of automatic summarization, by \\nkathy mckeown, of columbia university, \\nand ani nenkova, of the university of pennsylvania.)\\nabstractive summaries, by contrast, \\nattempt to articulate the information contained in one or more documents in original language written by the \\nalgorithm. this approach is more \\nambitious, and until recently it hasn’t human\\n“general-purpose technologies,” such as the internal combustion engine, have been the fundamental drivers of economic growth for 250 years. \\nartificial intelligence — particularly \\nmachine learning (ml) — is the most \\nimportant such technology of our era. in the coming decade, practically \\nevery industry will transform its keys \\nprocesses and business models to take advantage of ml. but not all expectations surrounding ai are realistic. in this article the authors describe its real potential, its practical implications, \\nand the barriers to its adoption.\\nthey note three pieces of good news \\nfor organizations looking to put ml \\nto use today: ai skills are spreading quickly, through online educational resources as well as universities; the necessary algorithms and hardware for modern ai can be bought or rented as \\nneeded; and companies may not need \\nall that much data to start making productive use of ml.\\nthey also note three risks: machines \\nmay have hidden biases, derived from the data used to train them; neural networks deal with statistical rather than literal truths; and diagnosing and correcting system errors is often difficult, because a solution’s underlying structure can be unimaginably complex.\\nextractive\\nthe most important of these are what economists call general-purpose technologies — a category that includes the steam engine, electricity, and the internal combustion engine. companies as diverse as walmart, ups, and uber found ways to leverage the \\ntechnology to create profitable new \\nbusiness models. the most important general-purpose technology of our era is artificial intelligence, particularly machine learning (ml) — that is, the machine’s ability to keep improving its \\nperformance without humans having to \\nexplain exactly how to accomplish all the tasks it’s given. in the sphere of business, ai is poised have a transformational impact, on the scale of earlier general-purpose technologies. although it is already in use in thousands of companies around the world, most big opportunities have not yet been tapped. \\nwhat can ai do today? the term \\nartificial intelligence was coined in 1955 by john mccarthy, a math professor at dartmouth who organized the seminal conference on the topic the following year. the fallacy that a computer’s narrow understanding implies broader \\nunderstanding is perhaps the biggest \\nsource of confusion, and exaggerated claims, about ai’s progress. \\n —fast forward labs\\nabstractive\\ncompanies as diverse as walmart, ups, and uber found ways to manipulate the technology to create profitable new business models. in the sphere \\nof business, ai is poised to have a \\ntransformational impact, on the scale of earlier general purpose technologies. in the past few years machine learning has become far more effective and widely available.\\n —alexander rushthree summaries: human, extractive, and abstractive\\nhere are summaries of the big idea article “the business of artificial intelligence,”  \\nby erik brynjolfsson and andrew mcafee.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  27 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\ndocuments and extract it. finally, that \\ninformation has to be presented to the end user. somewhere along the way, many of these systems take a fourth \\nstep: they try to identify some structure \\nfor the story. is it a chronology of independent events? a biography of a person? part of a larger story? structure can both help the system decide what information is important and provide an outline of how to present it to the end user.\\nthis process resembles the way \\nhumans approach at least simple research and writing tasks. john o’neil edits bloomberg’s explanatory quicktake, but before that he worked on topic pages at the new york times.  \\nhe describes the process he and \\nhis team used to write the text for \\nthose topic pages (which have since changed format): first, find four or five key articles the times had published \\nabout the subject. second, identify the background paragraphs in each story (as opposed to the news). third, write a summary that combined the information from those background paragraphs. at least when writing topic pages, the key \\nsteps for both humans and software are \\nthe same.\\nthe future of ai and writing\\nif these tools have been around for years, even in an imperfect form, why haven’t they had more impact on writing? one reason, as with so much revolutionary \\ntechnology, is culture. on the one hand, \\nmany writers don’t perceive a need for these tools; on the other, computer scientists haven’t always been concerned with how people will actually use their work. in auto-summarization, according to ani nenkova, the focus has mostly been on improving accuracy, rather than \\non thinking about how the technology \\ncould be embedded in a tool that people would actually use.\\nmoney is another factor — lots of \\nwriters and newsrooms don’t have much assistant. hill describes google searching as “shallow” and “frenetic.” “it’s horrifically laborious, all the searching you would do,” says susannah locke, an editor at vox.com. she found \\nherself thinking, “isn’t there something \\nthat can do this for me?” tim lee, of ars technica, describes his process of “unstructured” reading: finding 10 to 15 papers on a subject, reading them, and taking notes. he dreams of a tool that can take 1,000 pages on a topic and \\nidentify the 10 pages to start with.\\nthe immediate opportunity isn’t to fully \\nautomate the research process but to \\nmake it more structured and efficient. “i don’t understand why news sites don’t let you just click a name and assemble a backgrounder,” says brian ulicny, a data scientist at thomson reuters \\nlabs. (disclosure: ulicny’s wife and i are \\ncolleagues.) in 2006, while at lycos, ulicny authored a paper in which he \\ndescribes an “information fusion engine.” type in a name or a topic, as you might in google, and instead of returning a list of links, the system arranges paragraphs \\nfrom content found across the web \\ninto a “coherent summary report or background briefing,” what ulicny calls “something like the level of the first draft of a wikipedia article.”\\nulicny isn’t the only one to suggest \\nthat topic or news overviews can be automatically generated by software. \\ncomputer scientists have been building \\nsystems and publishing papers along  \\nthese lines for more than 15 years. these projects are technically complex, and they vary in important ways. but they face the same challenges and follow a similar process.\\nhilary mason, a data scientist and the \\nfounder of fast forward labs, outlines the main tasks these systems must perform: first, they have to identify source data, meaning some number of text documents such as news articles. then they need to identify the most important information within those “these” with no mention of what it refers to. ( teaching these systems to \\nrecognize the noun to which a pronoun refers is difficult, and the fast forward prototype did not attempt it.)\\nthe third summary, courtesy of \\nalexander rush, a professor of engineering at harvard, is abstractive. rush trained his system to write three-sentence summaries of cnn articles, and although he emphasizes that it isn’t state-of-the-art, he offered \\nto try it on the first 450 words of our \\nai feature. “the system is, in theory, abstractive,” he says, “so it can generate anything it wants. in practice, it looks like it is generating mostly sentences it sees in the original article itself.” in other words, it avoids the nonsensical results of sunspring, but \\nat the cost of originality. and like the \\nextractive summary, this one captures the article’s key themes but includes a reference to “the technology” without providing necessary context.\\nare these summaries good enough to \\nreplace human-written ones? perhaps \\nnot quite. but that’s not the right \\nquestion. a better one is whether ai-written first drafts of summaries might speed up our process. and here the answer is almost certainly yes.\\nai as research assistant\\nsummarization may seem too narrow a task to make much of a difference in the writing process, but combined with related technologies, it creates \\nthe opportunity to assist writers in a \\ncrucial part of their process: research. and research is “the hardest thing we do as writers,” according to david hill, the editor in chief of singularityhub,  \\na niche technology and science publication.\\ngoogle, whose search algorithms \\nlean on ai, has already transformed the research process and made writers significantly more productive. but google isn’t a perfect research \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  28 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nof it. “most of the progress [in natural \\nlanguage processing] happened when security analysts and the government were interested in being able to monitor \\nforeign news,” says nenkova, whose phd \\nwas funded by darpa. finance, too, is an area in which machine learning and natural language processing have had an impact, in large part because the money has been there to make it happen.\\nthe final reason these tools haven’t \\nmade more of a dent in writing is \\nsimply that the results haven’t been \\ngood enough to consistently serve readers well on their own. in his paper, ulicny describes an auto-generated backgrounder for the retired hockey player mario lemieux. the system recognized key subtopics that should be \\npart of the explainer, such as “games,” \\n“seasons,” and “pittsburgh penguins.” it also added “ice” — a topic that’s clearly related in some sense but that no writer would include in a profile of a hockey player.\\nall of this is changing. the technology \\nis getting both better and easier to use, and more and more writers and media companies are recognizing that smart \\nsoftware can help them do their work. \\nit’s clear to me that machine learning does have a near-term role in many types of writing, but for the most part it won’t involve producing full-fledged articles. rather, it will help journalists produce those articles more effectively.\\nlots of people are working on tools \\nto make that happen. david hill has a grant to create an open-source research assistant. frase, an early-stage start-up in boston, is working on something similar, though its founders plan to target content marketers as initial customers. google docs already has such a tool, but its utility is limited. \\nvox built a slack bot to show writers \\nolder articles that they might want to cite in new stories. ibm watson built a prototype called watson angles that summarized news stories, created timelines, and highlighted significant quotations. the prototype, which was removed from the web last fall, also included some key pieces of metadata, \\nsuch as sentiment analysis of how reddit \\nusers had responded to the news story in question, ranging from positive to negative.\\nthese projects are just the beginning. \\nimagine a news story on the recent fire in london that mentions the fact that your friend who lives there posted an \\nhour ago that she was safe. or text that \\nautomatically adjusts to the reader’s level of background knowledge. or fact-checking built into a word processor. or topic pages covering a long tail of niche subjects that smaller audiences are passionate about but that few publishers \\ntoday can afford to produce. or a \\nresearch assistant that recalls a relevant story written a century ago just as readily as one written last week.\\nalgorithms still can’t craft a narrative \\nthe way a person can — they can’t write a decent screenplay, or pass schank’s romeo and juliet test. for the most part, \\nthey can’t reason about cause and effect. \\nthey can’t write stirring prose, and they can’t persuade a public official to go on the record about an important policy. still, there’s plenty they can do. ai may not be able to tell a great story, but it can help us better tell our own.\\u2002\\nabout the author: walter frick is a senior \\nassociate editor at harvard business review.  \\nhe was a 2016 knight visiting nieman fellow at harvard university, during which time he researched how machine learning will change \\nthe field of explanatory journalism.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '\\u2002hbr.org\\u2002the big idea  29 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nphotography: elie honeinlive webinar \\ndeep learning’s next frontier\\nwatch the recorded event here.\\nhbr’s editor in chief, adi ignatius, and \\nandrew ng,  former chief scientist at baidu \\nand a cofounder of coursera, discuss \\nartificial intelligence and machine learning. \\nthey demystify ai and talk about its real-world impact today — and about the most \\npressing challenges and opportunities it \\npresents for businesses in the future.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'getty images\\n\\u2002hbr.org\\u2002the big idea  30 artificial intelligence, for real erik brynjolfsson and andrew mcafee\\nvideo\\nartificial intelligence, real food \\nwe asked ibm’s ai to create recipes and then had celebrity chef ming tsai cook them. watch \\nwhat happened. by harvard business review staff\\nchef watson can’t chop, dice, or julienne. “he” has no taste buds or appetite. but \\nask the chef for a recommendation on cooking with green olives, and his knowledge is vast, incorporating data points from a library of recipes and an encyclopedia of flavor profiles.\\none of the early applications of ibm’s watson technology, chef watson’s \\nintelligence is in food. specifically, how ingredients can come together to form new, never-before-tried recipes. the goal for chef watson, ibm says, is to “surprise and delight human chefs.”\\nhbr enlisted two cooks to partner with watson in the kitchen: ming tsai, a \\nrenowned professional chef, and gretchen gavett, an hbr editor and kitchen novice. we asked each of them to cook with watson as an experiment in how humans and machines work together. was it surprising and delightful? or a recipe for disaster? \\nwatch and find out.the goal for chef watson, ibm says, is to \\n“surprise and delight human chefs. ”\\n► play  8:55   \\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " '4,800 data points a da y .  \\ndream or nightmare?\\nget more from your data.  in 2025, the average person will use a connected device every 18 \\nseconds—an estimated 4,800 times a day.* the good news? that’s \\na lot of data. the not so good? 90% of it is likely to be unstructured. are you ready to keep up with that much information? we’ve been solving big data problems for 20 years. let us help with yours.\\ng.co/cloudguidetoml\\n*reinsel, david, et al. “data age 2025: the evolution of data to life-critical.” idc, april 2017© 2017 google inc.\\nthis document is authorized for use only by terrence carroll (terrencepcarroll@gmail.com). copying or posting is an infringement of copyright. please contact \\ncustomerservice@harvardbusiness.org or 800-988-0886 for additional copies.',\n",
       " 'see discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/352899612\\nai literacy: deﬁnition, teaching, evaluation and ethical issues\\nconf erence paper  · july 2021\\ncitations\\n6reads\\n7,578\\n4 author s, including:\\ntsz kit ng\\nuniv ersity of hong k ong\\n61 publica tions \\xa0\\xa0\\xa01,172  citations \\xa0\\xa0\\xa0\\nsee profile\\njac ka l ok l eung\\nthe hong k ong univ ersity of scienc e and t echnolog y\\n25 publica tions \\xa0\\xa0\\xa0440 citations \\xa0\\xa0\\xa0\\nsee profile\\nall c ontent f ollo wing this p age was uplo aded b y tsz kit ng  on 12 no vember 2021.\\nthe user has r equest ed enhanc ement of the do wnlo aded file.',\n",
       " ' \\n84th annual meeting of the association for information science & technology | oct. 29 – nov. 3, 2021 | salt lake city, ut. author(s) retain \\ncopyright, but asis&t receives an exclusive publication licens e. \\nasis&t annual meeting 2021 504  short papers  ai literacy: definition, teaching, evaluation and \\nethical issues  \\n \\ndavy tsz kit ng  \\nfaculty of education  \\nuniversity of hong kong, china  \\ndavyngtk@connect.hku.hk  jac ka lok leung  \\nfaculty of educatio n \\nuniversity of hong kong, china  \\negjac@connect.hku.hk  kai wah samuel chu  \\nfaculty of education  \\nuniversity of hong kong, china  \\nsamchu@hku.hk  \\nmaggie shen qiao  \\nfaculty of education  \\nuniversity of hong kong, china  \\nsqiao@connect.hku.hk     \\n \\nabstract  \\nartificial intelligence (ai) is at the top of the agenda for education leaders today in educating the next generation \\nacross the globe. however, public understanding of ai technologies and how to define ai literacy is under -explored. \\nthis vision poses upcoming challenges for our next generation to learn about ai. on this note, an exploratory review was conducted to conceptualize the newly emerging concept “ai literacy”, in search for a sound theoretical foundation to define, teach and evaluate ai literacy. grounded in literature on 18 existing peer -reviewed articles, \\nthis review proposed four aspects (i.e, know and understand, use, evaluate, and ethical issues) for fostering ai literacy based on the adaptation of classic literacies. this study sheds light on  the consolidated definition, teaching, \\nand ethical concerns on ai literacy, establishing the groundwork for future research such as competency development and assessment criteria on ai literacy.  \\nkeywords  \\nai literacy; ai learning and teaching; ai in education; ai ethics; ai literacy questionnaire.  \\nintroduction  \\nartificial intelligence (ai) was first defined as “the science and engineering of making intelligent machines” in 1956 (mccarthy, 2007, p.2). throughout several decades of the 20th century, ai has evolved progressively into \\nintelligent machines and algorithms that can reason and adapt based on sets of rules and environment which mimic \\nhuman intelligence (mccarthy, 2007). wang (2019) broadened the definition of ai which can perform cognitive tasks part icularly learning and problem -solving with the exciting technological innovations such as machine learning \\nand neural networks (zawacki -richter et al., 2019). currently, the use of ai has spread across industries (e.g., \\nbusiness, science, art, education) t o enhance user experience and improve efficiency. applications of ai exist in \\nmany parts of our everyday life (e.g., smart home appliances, smartphones, google, siri). vast majority of the \\npublic acknowledges the existence of ai services and devices, but seldom do they know about the concepts and \\ntechnology behind, or aware of potential ethical issues related to ai (burgsteiner et al., 2016; ghallab, 2019). similar to classic literacy which includes reading/writing and mathematical abilities, ai literacy ha s emerged as a \\nnew skill set in response to this new era of intelligence. as a small number of existing articles found in the web of science and scopus databases, google scholar search is used to identify the dramatic increase in ai literacy publications from 2014 to 2021 (see fig. 1).  \\n \\nfigure 1. ai literacy articles from google scholar published by year  \\n',\n",
       " \" \\nasis&t annual meeting 2021 505  short papers  as ai becomes more and more important, researchers began to define ai literacy based on the term ‘literacy’ which \\nhas been applied to define skill sets in varied disciplines (long & magerto, 2020). however, few studies have \\nprovided comprehensive explanations on how to conceptualize ai literacy. to fill this gap, this study reviewed the relevant literature, and analyzed how scholars define “ai literacy”, how it can be learned, and what are the ethical concerns. specifically, the present study poses the following four research questions: 1. how do researchers define the term “ai literacy”?; 2. how do educators help learners develop ai literacy?; 3. how do researchers evaluate students’ ai literacy skills?; 4. what are the ethical concerns in the domain of ai literacy?  \\nmethod  \\nin search for literature on ai literacy, both peer -reviewed scholarly articles and conference papers from k -12 to \\nhigher education levels  published from 2016 to 2021 through the web of science and scopus  were included in this \\nreview. the aforementioned databases were considered among the world's most trusted citation indices platforms for evidence- based quality scientific research and hence  helped us to ensure the inclusion of quality scientific content \\n(mongeon & paul -hus, 2016). the articles that contained the phrase “ai literacy” in either the title, the abstract, \\nmain text or keywords were downloaded and reviewed by the researchers. the search resulted in 20 articles. after \\nexcluding irrelevant studies, as of apr 11, 2021, a total of 18 articles were identified. through studying the main \\ncontent in the selected articles, similar meaningful concepts were identified and extracted for further thematic analysis. to establish coding reliability, six (30%) of the articles were randomly picked, blind- coded and analyzed \\nby the two researchers. disagreements were resolved through discussing the disputed studies.  \\nresults & discussion  \\nrq 1: how do researchers define the term “ai literacy”?  of the 18 articles, 12 articles defined ai literacy based \\non the ideas of ‘literacy’. since the 1970s, computer applications have gained popularity across industries. it was \\nnecessary for users to become competent in using computer systems related to their specific task or job. as such, the term “digital literacy” emerged to assess basic computer -related concepts and skills. the importance of digital \\nliteracy increases as more people depend on the use of computer technologies to develop new social and econ omic \\nopportunities (leahy & dolan, 2010). in succession to digital advancement, ai started to arise and imitate human \\nintelligence in machines for computers to learn, reason and perceive. it was initially used in scientific research and \\nacademic environmen ts but had yet become ubiquitous in our daily lives. four aspects of fostering ai literacy were \\nidentified from the review (see table 1).  \\nai literacy  definitions  f sample references  sample studies  \\nknow & \\nunderstand ai  know the basic functions of ai \\nand how to use ai applications in \\neveryday life ethically.  18 even though transparency in algorithms and ai in general \\nhas been acknowledged to be ethically important, the public \\nlacks understanding of even the basic functions of ai. efforts \\nto make ai more co mprehensible exist (robinson, 2020).  lee et al. (2021); \\nkandlhofer et al., \\n2016); robinson \\n(2020).  \\napply ai   applying ai knowledge, concepts \\nand applications in different \\nscenarios.   18 apply k-means clustering in science contexts… explore the \\nmapping relationship between facial features and data values \\nand apply the concept to brainstorm other objects such as \\nlego (wan et al., 2020).  druga et al. (2019); \\njulie et al. (2020); vazhayil et al. (2 019).   \\nevaluate & \\ncreate ai  higher -order thinking skills (e.g., \\nevaluate, appraise, predict, design) \\nwith ai applications.  12 design & build experiences: technology exploration and \\ncreation activities supported students in making sense of the \\nunderlying ai concepts. (lee, 2020).  druga et al. (2019); han \\net al. (2019); how & \\nhung (2019).  \\nai ethics  human -centered considerations \\n(e.g., fairness, accountability, \\ntransparency, ethics)  9 “ai for social good”  measures an individual’s perception of \\nthe social environment surrounding the behavior, which is \\nrelated to subjective norms (chai et al., 2020).  chai et al. (2020); \\ndruga et al. (2019);  \\ngong et al. (2020).  \\ntable 1. coding framework of ai literacy  \\nknow and understand ai: all 18 articles conceptualize ai literacy as educating learners about acquiring \\nfundamental concepts, skills, knowledge and attitudes that require no prior knowledge. on top of being the end users of ai applications, learne rs should understand the technologies behind. burgsteiner et al. (2016) and kandlhofer et \\nal. (2016) defined ai literacy as the ability to understand the basic techniques and concepts behind ai in different products and services. many students know these a i-empowered services, but they were not familiarized with the \\nunderlying concepts such as computational thinking concepts, data structures. sound knowledge about ai and principles of computer science will be of vast importance for their future careers (bur gsteiner et al., 2016; \\nkandlhofer et al., 2016). moreover, some researchers associate ai literacy with perceived abilities, confidence and readiness in learning ai. in k -12 education, druga et al. (2019) and lee et al., (2021) designed learning curriculums  \\nand activities that foster ai literacy that focuses on how learners gain ai concepts.  \\napply ai: all articles emphasized the importance to educate learners to know how to apply ai concepts and \\napplications in different contexts (e.g., druga et al., 2019; lee et al., 2021). for example, rodríguez -garcía et al. \\n(2020) evaluated learningml, a machine learning model builder, to educate citizens to understand ai applications \\nand how it can affect our lives, as well as knowing the ethical issues regarding ai technologies. in addition, half of \",\n",
       " ' \\nasis&t annual meeting 2021 506  short papers  the studies (n=9) discussed the human -centered considerations and focused on using ai concepts and application \\nethically, which would be further discussed in rq4. three out of 18 articles borrowed the ideas of computational \\nthinking to interplay ai literacy and ai thinking (see appendix 1). ai thinking refers to the construction of logic \\nand algorithms in order to support students’ understanding of how to use knowledge bases for problem -solving, \\nprocessing semantics and handling unstructured data (vazhayil et al., 2019). for example, how and hung (2019) \\nleveraged ai thinking through conducting data analytics with computing and interpreted new findings from the machine- learned discovery of hidden patterns in data.  \\nevaluate and c reate ai: ai augments human intelligence with digital automation and 12 articles alluded ai literacy \\nto engage learners in higher -order thinking activities. other than knowing and using ai with concepts and practices, \\nsome studies had extended ai literacy to two other competencies that enabled individuals to critically evaluate ai technologies, communicate and collaborate effectively with ai (e.g., long & magerko, 2020). for example, han et al. (2019) enhanced students’ scientific and technological knowledge which then was applied in scientific research -\\nbased learning to solve practical problems. long et al. (2019) engaged citizens in co- creating ai amenities in public \\nspaces to broaden their public ai literacy and experiences. students with the ability to e valuate and create ai could \\ninfer from, connect, manipulate, and categorize ai concepts together in novel ways. overall, although these articles showed slight variations on the definition of ai literacy, they support the notion that everyone, especially k -12 \\nchildren, acquire basic ai knowledge and abilities, and enhance motivation and career interest (chai et al., 2020b). in addition to knowing and using ai ethically, ai literacy serves as a set of competencies that enables individuals to critically evalua te ai technologies, communicate and collaborate effectively with ai (long & magerko, 2020).  \\nrq 2. how do educators teach and learn ai?  in k-12 education, researchers (n=12) designed learning \\ncurriculums and activities that foster ai literacy that focuses o n how learners gain ai concepts, as well as using ai \\nto incorporate into their own applications (e.g., druga et al., 2019; lee et al., 2021). long and magerko (2020) and rodríguez -garcía et al. (2020) mentioned touretzky et al (2019)’s five “big ideas” of ai which provide a strong \\nfoundation for future research on fostering ai literacy (see appendix 2). in another study, rodríguez -garcía et al. \\n(2020) evaluated learningml, a machine learning model builder, to develop critical thinking, and k -12 children on \\nai fundamentals to understand what can be made with ai, how it can affect their lives, and the ethical issues regarding ai technologies. in higher education, two researchers claimed that ai knowledge and skills become more advanced to meet the future job demands. kandlhofer et al. (2016) and burgsteiner et al. (2016) listed a set of ai concepts that has potential to become the basis for careers in science and engineering: automata, intelligent agents, graphs and data structures, basics of computer science, machine learning, etc.  based on the ai bible written by \\nrussell and norvig (2009). four studies mentioned the importance of educating citizens on fundamental ai \\nconcepts, and the impacts of ai technologies on their everyday lives. for example, robinson (20 20) mentioned that \\nthe norwegian policy document titled “ai for everyone: elements of ai” (p. 44) asserts the government will make \\nai learning courses globally accessible in 2020, which conceptualizes ai literacy as educating their citizens about the elements of ai that require no prior knowledge (robinson, 2020).  \\nlearning artefacts:  given the complexity of ai, age -appropriate learning artefacts were important to scaffold \\nstudents’ ai conceptual understandings, and enhance their motivation and interest in l earning ai. in recent years, \\nthere has been an increase in hardware and software that enhance ai concepts accessible to younger learners. appendix 3 provides an overview of the types of ai learning artefacts ranging from hardware (n=5) to software -\\nfocused artefacts (n=3), intelligent agents (n=4) and unplugged learning tools (n=5). the democratization of current \\nai technologies encourages students to make intelligent agents and machine learning models without needing to program (long & magerto, 2020). in this context, we can see an opportunity for educators to democratize access to \\nai literacy and reinforce the ai concepts through these emerging tools. alternatively, educators designed unplugged \\nlearning activities to foster students’ ai literacy without using a computer through engaging approaches such as case study, role -playing and storytelling (e.g., julie et al., 2020).   \\nrq 3. how do researchers evaluate students’ ai literacy skills?  among 18 studies, 11 articles adopted \\nquantitative (n=9) and qualitativ e (n=6) evaluation methods to examine how students enhance their literacy skills \\n(see appendix 4). to evaluate k -12 students’ ai literacy, one important component is to promote their intention to \\nlearn and possess basic knowledge about ai. nine studies assessed the knowledge acquisition of k -12 and \\nuniversity students via group discussion and pre - and post -knowledge tests (e.g., what are the characteristics of \\ndepth- first search?), and students’ perceived abilities (e.g., how would you rate your knowledge a bout search \\nalgorithms?) (kandlhofer et al., 2016; wan et al., 2020). other than self- reported questionnaires, the study assessed \\nstudents’ output that used artefacts such as computer programs, documentations and presentations of their experiments. five researchers also collected qualitative data by taking pictures, field notes during teaching, and \\ninterviewing students to understand their motivations, expectations and lessons learned. druga (2019) recorded \\nstudents’ interaction with ai agents through field  observations and adopted a three -attribute ai perception \\nquestionnaire to evaluate how 102 children (7- 12 years old) interacted and perceived their ai agents in their lessons. ',\n",
       " \" \\nasis&t annual meeting 2021 507  short papers  these 3 attributes measure whether the agents are smarter, truthful and underst and them. three studies discussed \\nother aspects such as confidence in using ai, motivation, ai for societal good. in another study, chai et al. (2020a) \\nmeasured ai literacy as students’ perception of their knowledge and skills of using ai technology, and designed and \\nadministered an instrument to 545 students (aged 13- 18) with 7 aspects. dai et al. (2020) further included \\n‘relevance’ as the eighth aspect that is associated with ai literacy. they considered ai literacy as the knowledge foundation that provides students with a perception of ai technology.  \\nrq 4. what are the ethical concerns in the domain of ai literacy?  as ai plays an important role in day- to-day \\ndecision making, misused or poorly designed ai could cause irreparable harm to humans and the soci ety (fourtané, \\n2020). ai -concerned scientists and engineers like elon musk expound on the horrors that future ai technologies \\nmay wreak on humanity in decades to come (johnson, 2019). however, only half of the studies in this review had mentioned human- centered considerations and raised attention to educate citizens to become socially responsible \\n(ahmad et al., 2020) . gong et al. (2020) found that students pay little attention to ethical concerns such as bias in ai \\nand legal responsibility (8%), and intelle ctual property (9%). as such, educators should not only focus on enhancing \\nstudents’ ai abilities and interests, but also help students to realize the societal impact and ethical concerns.  \\nto bring up future responsible citizens who compete in using ai in a reliable, trustworthy and fair way, \\ncomputational techniques must be facilitated in an innovative and responsible manner, while prioritizing issues of fairness, accountability, transparency, and ethics by drawing on fields with a sociotechnical orientat ion (hagendorff, \\n2021; microsoft, 2021). ai literacy in k -12 education is at its starting point. it highlights how people comprehend \\nai concepts and apply ai. broadening participation in ai for all is necessary to ensure that the design and utilization of ai technologies are inclusive to address under -representation of people of colour and women in ai. for example, \\nlee et al. (2021) designed a middle -school ai literacy curriculum on ethics education that incorporates algorithmic \\nbias, ethical design of reco mmender systems, unanticipated consequences into a series of ai learning activities such \\nas training models with teachable machine, generating texts and redesigning videos. a student gave a feedback during the interview: “if people who make the ais don’t think enough through it, they can have bad consequences. they will get sued if they don’t check over or get into damages” (p.194). the study envisioned that the foundation \\nof future ai industries would be built on “principles of inclusivity, provide equitable access, include consideration \\nof multiple stakeholders and potential users, and minimize the potential for bias” (p.191). another study conducted by druga (2019) engaged 108 children (aged 7- 12) from different countries and social economics status to construct \\na guideline to discuss how educators can design inclusive learning activities such as avoiding deceiving technologies, offering ways for children to customize and program the machine, and encouraging reflection and collaboration by allowing children to share and modify each other's projects. moreover, robinson (2020) conducted \\na document analysis and pointed out that a guiding framework for ai government policy is important for citizens to \\nhave a common ethical, responsible and human -centered basis to better support the development of ai technology in \\ntheir society. with the democratization of current ai technologies, educators should not only teach students to build machine learning models, but also guide them on how to implement these emerging tech nologies ethically. to \\nsummarize, conceptualizing ai literacy with human -centered considerations is crucial to building a future inclusive \\nsociety.  \\nconclusion  \\nin this review, a variety of definitions of ai literacy was noticed. the most common approach to define ai literacy is to base on different types of ‘literacies’ which have recently been applied to define skill sets in varied disciplines. in our review, most researchers advocated that instead of merely knowing how to use ai applications, learners should be inculcated with the underlying ai concepts for their future career, as well as the ethical concerns of ai \\napplications to become a responsible citizen.  since ai literacy is an emerging field that there is a lack of journals \\npublished in this field, several limitations are found in this review. the keyword search limits the scope of domain \\nspecificity within the ai context without focusing on other subfields of ai like machine learning, neural network, etc. some authors designed interventions and learning programs to discuss how to foster ai literacy in their studies without explicitly defining it. although we believe there is a larger pool of studies concerning the development of ai literacy, they may not be entirely captured to avoid any misinterpretation of their underlying concepts in ai \\nliteracy. in addition, future studies are needed to examine effective means to foster students’ ai literacy, its \\nassessment criteria and ethical concerns. we hope this review will inspire scholars, educators, and gov ernment \\nofficers to begin the discussion on how to define, implement and evaluate ai literacy in the future.  \\nreferences  \\nahmad, m. a., teredesai, a., & eckert, c. (2020, january). fairness, accountability, transparency in ai at scale: lessons fro m \\nnational programs. in proceedings of the 2020 conference on fairness, accountability, and transparency (pp. 690-690).  \\nbaker, t., smith, l., and anissa, n. (2019). educ -ai-tion rebooted? exploring the future of artificial intelligence in schools \\nand colleges  (london : nesta). available online at: https://www.nesta.org.uk/report/education -rebooted . \",\n",
       " \" \\nasis&t annual meeting 2021 508  short papers  burgsteiner, h., kandlhofer, m., & steinbauer, g. (2016, march). irobot : teaching the basics of artificial intelligence in high \\nschools. in proceedings of the aaai conference on artificial intelligence  (vol. 30, no. 1).  \\nchai, c. s., wang, x., & xu, c. (2020a). an extended theory of planned behavior for the modelling of chines e secondary school \\nstudents’ intention to learn artificial intelligence. mathematics , 8(11), 2089.  \\nchai, c. s., lin, p. y., jong, m. s. y., dai, y., chiu, t. k., & huang, b. (2020b, august). factors influencing students' \\nbehavioral intention to continue ar tificial intelligence learning. in 2020 international symposium on educational \\ntechnology (iset)  (pp. 147 -150). ieee.  \\ndai, y., chai, c. s., lin, p. y., jong, m. s. y., guo, y., & qin, j. (2020). promoting students’ well -being by developing their \\nreadiness for the artificial intelligence age. sustainability, 12 (16), 6597.  \\ndruga, s., vu, s. t., likhith, e., & qiu, t. (2019). inclusive ai literacy for kids around the world. in proceedings of fablearn \\n2019 (pp. 104 -111).  \\nertmer, p. a., & ottenbreit -leftwich, a.  t. (2010). teacher technology change: how knowledge, confidence, beliefs, and culture \\nintersect. journal of research on technology in education, 42(3), 255 -284.  \\nfourtané, s. (2020, august). ethics of ai: benefits and risks of artificial intelligence syste ms. interesting engineering. \\nretrieved from https://interestingengineering.com/ethics -of-ai-benefits -and-risks-of -artificial -intelligen ce-systems  \\ngenlott, a. a., & grönlund, å. (2013). improving literacy skills through learning reading by writing: the iwtr method \\npresented and tested. computers & education, 67, 98-104. \\nghallab, m. (2019). responsible ai: requirements and challenges.  ai pe rspectives, 1 (1), 1 -7. \\ngong, x., tang, y., liu, x., jing, s., cui, w., liang, j., & wang, f. y. (2020, october). k -9 artificial intelligence education in \\nqingdao: issues, challenges and suggestions. in 2020 ieee international conference on networking, sens ing and control \\n(icnsc) (pp. 1 -6). ieee.  \\nhagendorff, t. (2020). the ethics of ai ethics: an evaluation of guidelines. minds and machines, 30 (1), 99 -120. \\nhan, x., hu, f., xiong, g., liu, x., gong, x., niu, x., ... & wang, x. (2018). design of ai+ curriculum  for primary and \\nsecondary schools in qingdao. in 2018 chinese automation congress (cac)  (pp. 4135- 4140). ieee. \\nhow, m. l., & hung, w. l. d. (2019). educing ai -thinking in science, technology, engineering, arts, and mathematics \\n(steam) education. education  sciences , 9(3), 184.  \\njohnson, k (2019, november). ai ethics is all about power. venturebeat insider - the machine making sense of ai.  retrieved \\nfrom https://venturebeat.com/2019/11/11/ai -ethics -is-all-about -power/  \\njulie, h., alyson, h., & anne -sophie, c. (2020, october). designing digital literacy activities: an interdisciplinary and \\ncollaborative approach. in 2020 ieee frontiers in education conference (fie)  (pp. 1- 5). iee e. \\nkandlhofer, m., steinbauer, g., hirschmugl -gaisch, s., & huber, p. (2016, october). artificial intelligence and computer \\nscience in education: from kindergarten to university. in 2016 ieee frontiers in education conference (fie)  (pp. 1 -9). \\nieee.  \\nleahy, d., & dolan, d. (2010, september). digital literacy: a vital competence for 2010?. in ifip international conference on \\nkey competencies in the knowledge society (pp. 210 -221). springer, berlin, heidelberg.  \\nlong, d., & magerko, b. (2020, april). what is ai literacy? competencies and design considerations. in proceedings of the \\n2020 chi conference on human factors in computing systems  (pp. 1-16).  \\nlong, d., jacob, m., & magerko, b. (2019). designing co-creative ai for public spaces. in proceedings of the 2019 on creativity \\nand cognition (pp. 271 -284).  \\nmccarthy, j. (2007). from here to human-level ai. artificial intelligence , 171(18), 1174-1182.  \\nmcclelland, c. (2020). the impact of artificial intelligence - widespread job losses. retrieved from \\nhttps://www.iotfo rall.com/impact -of-artificial-intelligence -job-losses \\nmicrosoft. (2021). fate: fairness, accountability, transparency, and ethics in ai. retrieved from \\nhttps://www.microsoft.com/en -us/research/theme/fate/  \\nmohammadyari, s., & singh, h. (2015). understanding the effect of e -learning on individual performance: the role of digital \\nliteracy. computers & education , 82, 11 -25. \\nmongeon, p., & paul -hus, a. (2016). the journal coverage of web of science and scopus: a comparative analysis. \\nscientometrics , 106(1), 213-228.  \\nng, t. k. (2021). new interpretation of extracurricular activities via social networking sites: a case study of artificial \\nintelligence learning at a secondary school in hong kong. journal of education and training studies,  9(1), 49 -60. \\nng, t.k. & chu, s. k.w. (2021). motivating students to learn ai through social networking sites: a case study in hong kong. \\nonline learning, 2 5(1), 195 -208. \\nrodríguez -garcía, j. d., moreno -león, j., román -gonzález, m., & robles, g. (2020, october). introducing artificial \\nintelligence fundamentals with learningml: artificial intelligence made easy. in eighth international conference on \\ntechnologi cal ecosystems for enhancing multiculturality  (pp. 18- 20). \",\n",
       " ' \\nasis&t annual meeting 2021 509  short papers  russell stuart, j., & norvig, p. (2009). artificial intelligence: a modern approach . prentice hall.  \\nschaper, m. m., malinverni , l., & valero, c. (2020, october). robot presidents: who should rule the world? teaching critical \\nthinking in ai through reflections upon food traditions. in proceedings of the 11th nordic conference on human-\\ncomputer interaction: shaping experiences, sha ping society  (pp. 1 -4). \\nsemuels, a. (2020). millions of americans have lost jobs in the pandemic —and robots and ai are replacing them faster \\nthan ever. retrieved from https://time.com/5876604/machines -jobs -coronavirus/  \\nvazhayil, a., shetty, r., bhavani, r. r., & akshay, n. (2019, december). focusing on teacher education to introduce ai in \\nschools: perspectives and illustrative findings. in 2019 ieee tenth international conference on technology for education \\n(t4e) (pp. 71 -77). ieee.  \\nwang, p. (2019). on defining artificial intelligence. journal of artificial general intelligence , 10(2), 1 -37. \\nzawacki -richter, o., marín, v. i., bond, m., and gouverneur, f. (2019). systemati c review of research on artificial intelligence \\napplications in higher education – where are the educators? int. j. educ. technol. higher edu.  16:39. doi: 10.1186/s41239-\\n019-0171 -0 \\nappendix 1 –5 \\nfor more details, please visit https://bit.ly/3dsij4g.  \\n \\nview publication stats\\n',\n",
       " 'neural approaches to\\nconversational ai\\nquestion answering, task-oriented\\ndialogues and social chatbots\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'other titles in foundations and trendsr\\rin information retrieval\\nweb forum retrieval and text analytics: a survey\\ndoris hoogeveen, li wang, timothy baldwin and karin m. verspoor\\nisbn: 978-1-68083-350-8\\ndisplay advertising with real-time bidding (rtb) and behavioural\\ntargeting\\njun wang, weinan zhang and shuai yuan\\nisbn: 978-1-68083-310-2\\napplications of topic models\\njordan boyd-graber, yuening hu and david mimno\\nisbn: 978-1-68083-308-9\\nsearching the enterprise\\nudo kruschwitz and charlie hull\\nisbn: 978-1-68083-304-1\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'neural approaches to\\nconversational ai\\nquestion answering, task-oriented dialogues\\nand social chatbots\\njianfeng gao\\nmicrosoft research\\njfgao@microsoft.com\\nmichel galley\\nmicrosoft research\\nmgalley@microsoft.com\\nlihong li\\ngoogle brain\\nlihong@google.com\\nboston — delft\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'foundations and trendsr\\rin information retrieval\\npublished, sold and distributed by:\\nnow publishers inc.\\npo box 1024\\nhanover, ma 02339\\nunited states\\ntel. +1-781-985-4510\\nwww.nowpublishers.com\\nsales@nowpublishers.com\\noutside north america:\\nnow publishers inc.\\npo box 179\\n2600 ad delft\\nthe netherlands\\ntel. +31-6-51115274\\nthe preferred citation for this publication is\\nj. gao, m. galley and l. li. neural approaches to conversational ai . foundations\\nand trendsr/circlecopyrtin information retrieval, vol. 13, no. 2-3, pp. 127–298, 2019.\\nisbn: 978-1-68083-553-3\\nc/circlecopyrt2019 j. gao, m. galley and l. li\\nall rights reserved. no part of this publication may be reproduced, stored in a retrieval system,\\nor transmitted in any form or by any means, mechanical, photocopying, recording or otherwise,\\nwithout prior written permission of the publishers.\\nphotocopying. in the usa: this journal is registered at the copyright clearance center, inc., 222\\nrosewood drive, danvers, ma 01923. authorization to photocopy items for internal or personal\\nuse, or the internal or personal use of speciﬁc clients, is granted by now publishers inc for users\\nregistered with the copyright clearance center (ccc). the ‘services’ for users can be found on\\nthe internet at: www.copyright.com\\nfor those organizations that have been granted a photocopy license, a separate system of payment\\nhas been arranged. authorization does not extend to other kinds of copying, such as that for\\ngeneral distribution, for advertising or promotional purposes, for creating new collective works,\\nor for resale. in the rest of the world: permission to photocopy must be obtained from the\\ncopyright owner. please apply to now publishers inc., po box 1024, hanover, ma 02339, usa;\\ntel. +1 781 871 0245; www.nowpublishers.com; sales@nowpublishers.com\\nnow publishers inc. has an exclusive license to publish this material worldwide. permission\\nto use this content must be obtained from the copyright license holder. please apply to now\\npublishers, po box 179, 2600 ad delft, the netherlands, www.nowpublishers.com; e-mail:\\nsales@nowpublishers.com\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'foundations and trendsr\\rin information\\nretrieval\\nvolume 13, issue 2-3, 2019\\neditorial board\\neditors-in-chief\\nmaarten de rijke\\nuniversity of amsterdam\\nthe netherlandsyiqun liu\\ntsinghua university\\nchina\\neditors\\nben carterette\\nuniversity of delaware\\ncharles l.a. clarke\\nuniversity of waterloo\\nclaudia hauﬀ\\ndelft university of technology\\ndiane kelly\\nuniversity of tennessee\\ndoug oard\\nuniversity of maryland\\nellen m. voorhees\\nnational institute of standards and\\ntechnology\\nfabrizio sebastiani\\nconsiglio nazionale delle ricerche, italy\\nhang li\\nbytedance technology\\nian ruthven\\nuniversity of strathclyde, glasgow\\njaap kamps\\nuniversity of amsterdam\\njames allan\\nuniversity of massachusetts, amherstjian-yun nie\\nuniversité de montreal\\njimmy lin\\nuniversity of maryland\\nleif azzopardi\\nuniversity of glasgow\\nlynda tamine\\nuniversity of toulouse\\nmark d. smucker\\nuniversity of waterloo\\nrodrygo luis teodoro santos\\nuniversidade federal de minas gerais\\nryen white\\nmicrosoft research\\nshane culpepper\\nrmit\\nsoumen chakrabarti\\nindian institute of technology\\ntie-yan liu\\nmicrosoft research\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'editorial scope\\ntopics\\nfoundations and trendsr/circlecopyrtin information retrieval publishes survey and\\ntutorial articles in the following topics:\\n•applications of ir\\n•architectures for ir\\n•collaborative ﬁltering and\\nrecommender systems\\n•cross-lingual and multilingual\\nir\\n•distributed ir and federated\\nsearch\\n•evaluation issues and test\\ncollections for ir\\n•formal models and language\\nmodels for ir\\n•ir on mobile platforms\\n•indexing and retrieval of\\nstructured documents\\n•information categorization and\\nclustering\\n•information extraction\\n•information ﬁltering and\\nrouting•metasearch, rank aggregation\\nand data fusion\\n•natural language processing for\\nir\\n•performance issues for ir\\nsystems, including algorithms,\\ndata structures, optimization\\ntechniques, and scalability\\n•question answering\\n•summarization of single\\ndocuments, multiple\\ndocuments, and corpora\\n•text mining\\n•topic detection and tracking\\n•usability, interactivity, and\\nvisualization issues in ir\\n•user modelling and user\\nstudies for ir\\n•web search\\ninformation for librarians\\nfoundations and trendsr/circlecopyrtin information retrieval, 2019, volume 13, 5\\nissues. issn paper version 1554-0669. issn online version 1554-0677.\\nalso available as a combined paper and online subscription.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'contents\\n1 introduction 2\\n1.1 who should read this paper? . . . . . . . . . . . . . . . 4\\n1.2 dialogue: what kinds of problems? . . . . . . . . . . . . 5\\n1.3 a uniﬁed view: dialogue as optimal decision making . .7\\n1.4 the transition of nlp to neural approaches . . . . . . . 9\\n2 machine learning background 13\\n2.1 machine learning basics . . . . . . . . . . . . . . . . . . 13\\n2.2 deep learning . . . . . . . . . . . . . . . . . . . . . . . . 17\\n2.3 reinforcement learning . . . . . . . . . . . . . . . . . . . 23\\n3 question answering and machine reading comprehension 29\\n3.1 knowledge base . . . . . . . . . . . . . . . . . . . . . . . 30\\n3.2 semantic parsing for kb-qa . . . . . . . . . . . . . . . . 31\\n3.3 embedding-based methods . . . . . . . . . . . . . . . . . 32\\n3.4 multi-step reasoning on kb . . . . . . . . . . . . . . . . 34\\n3.5 conversational kb-qa agents . . . . . . . . . . . . . . . 40\\n3.6 machine reading for text-qa . . . . . . . . . . . . . . . 44\\n3.7 neural mrc models . . . . . . . . . . . . . . . . . . . . . 47\\n3.8 conversational text-qa agents . . . . . . . . . . . . . . . 53\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '4 task-oriented dialogue systems 56\\n4.1 overview . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\\n4.2 evaluation and user simulation . . . . . . . . . . . . . . . 62\\n4.3natural language understanding and dialogue state tracking 68\\n4.4 dialogue policy learning . . . . . . . . . . . . . . . . . . 73\\n4.5 natural language generation . . . . . . . . . . . . . . . . 83\\n4.6 end-to-end learning . . . . . . . . . . . . . . . . . . . . . 86\\n4.7 further remarks . . . . . . . . . . . . . . . . . . . . . . . 88\\n5 fully data-driven conversation models and social bots 90\\n5.1 end-to-end conversation models . . . . . . . . . . . . . . 91\\n5.2 challenges and remedies . . . . . . . . . . . . . . . . . . 95\\n5.3 grounded conversation models . . . . . . . . . . . . . . . 103\\n5.4 beyond supervised learning . . . . . . . . . . . . . . . . . 105\\n5.5 data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\\n5.6 evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . 109\\n5.7 open benchmarks . . . . . . . . . . . . . . . . . . . . . . 112\\n6 conversational ai in industry 114\\n6.1 question answering systems . . . . . . . . . . . . . . . . 114\\n6.2 task-oriented dialogue systems (virtual assistants) . . . .118\\n6.3 chatbots . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\n7 conclusions and research trends 124\\nacknowledgements 128\\nreferences 129\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'neural approaches to\\nconversational ai\\njianfeng gao1, michel galley2and lihong li3\\n1microsoft research; jfgao@microsoft.com\\n2microsoft research; mgalley@microsoft.com\\n3google brain; lihong@google.com\\nabstract\\nthe present paper surveys neural approaches to conversa-\\ntional ai that have been developed in the last few years.\\nwe group conversational systems into three categories: (1)\\nquestion answering agents, (2) task-oriented dialogue agents,\\nand (3) chatbots. for each category, we present a review\\nof state-of-the-art neural approaches, draw the connection\\nbetween them and traditional approaches, and discuss the\\nprogress that has been made and challenges still being faced,\\nusing speciﬁc systems and models as case studies.\\njianfeng gao, michel galley and lihong li (2019), “neural approaches to conversa-\\ntional ai”, foundations and trendsr/circlecopyrtin information retrieval: vol. 13, no. 2-3, pp\\n127–298. doi: 10.1561/1500000074.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '1\\nintroduction\\ndevelopinganintelligentdialoguesystem1thatnotonlyemulateshuman\\nconversation, but also answers questions on topics ranging from latest\\nnews about a movie star to einstein’s theory of relativity, and fulﬁlls\\ncomplex tasks such as travel planning, has been one of the longest\\nrunning goals in ai. the goal has remained elusive until recently. we\\nare now observing promising results both in academia and industry, as\\nlarge amounts of conversational data become available for training, and\\nthe breakthroughs in deep learning (dl) and reinforcement learning\\n(rl) are applied to conversational ai.\\nconversational ai is fundamental to natural user interfaces. it is\\na rapidly growing ﬁeld, attracting many researchers in the natural\\nlanguage processing (nlp), information retrieval (ir) and machine\\nlearning (ml) communities. for example, sigir 2018 has created a\\nnew track of artiﬁcial intelligence, semantics, and dialog to bridge\\nresearch in ai and ir, especially targeting question answering (qa),\\ndeep semantics and dialogue with intelligent agents.\\n1“dialogue systems” and “conversational ai” are often used interchangeably in\\nthe scientiﬁc literature. the diﬀerence is reﬂective of diﬀerent traditions. the former\\nterm is more general in that a dialogue system might be purely rule-based rather\\nthan ai-based.\\n2\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '3\\nrecent years have seen the rise of a small industry of tutorials and\\nsurvey papers on deep learning and dialogue systems. yih et al.(2015b),\\nyihet al.(2016), and gao (2017) reviewed deep learning approaches\\nfor a wide range of ir and nlp tasks, including dialogues. chen et al.\\n(2017e) presented a tutorial on dialogues, with a focus on task-oriented\\nagents. serban et al.(2015; 2018) surveyed public dialogue datasets\\nthat can be used to develop conversational agents. chen et al.(2017b)\\nreviewed popular deep neural network models for dialogues, focusing on\\nsupervised learning approaches. the present work substantially expands\\nthe scope of chen et al.(2017b) and serban et al.(2015) by going\\nbeyond data and supervised learning to provide what we believe is the\\nﬁrst survey of neural approaches to conversational ai, targeting nlp\\nand ir audiences.2its contributions are:\\n•we provide a comprehensive survey of the neural approaches to\\nconversational ai that have been developed in the last few years,\\ncovering qa, task-oriented and social bots with a uniﬁed view of\\noptimal decision making.\\n•we draw connections between modern neural approaches and\\ntraditional approaches, allowing us to better understand why and\\nhow the research has evolved and to shed light on how we can\\nmove forward.\\n•we present state-of-the-art approaches to training dialogue agents\\nusing both supervised and reinforcement learning.\\n•we sketch out the landscape of conversational systems developed\\nin the research community and released in industry, demonstrating\\nviacasestudiestheprogressthathasbeenmadeandthechallenges\\nthat we are still facing.\\n2one important topic of conversational ai that we do not cover is spoken\\nlanguage understanding (slu). slu systems are designed to extract the meaning\\nfrom speech utterances and their application are vast, ranging from voice search in\\nmobile devices to meeting summarization. the present work does encompass many\\nspoken dialogue systems – for example young et al.(2013) – but does not focus\\non components related to speech. we refer readers to tur and de mori (2011) for a\\nsurvey of slu.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '4 introduction\\n1.1 who should read this paper?\\nthis paper is based on tutorials given at the sigir and acl confer-\\nences in 2018 (gao et al.,2018a; gao et al.,2018b), with the ir and\\nnlp communities as the primary target audience. however, audiences\\nwith other backgrounds (such as machine learning) will also ﬁnd it an\\naccessible introduction to conversational ai with numerous pointers,\\nespecially to recently developed neural approaches.\\nwe hope that this paper will prove a valuable resource for students,\\nresearchers, and software developers. it provides a uniﬁed view, as well\\nas a detailed presentation of the important ideas and insights needed to\\nunderstand and create modern dialogue agents that will be instrumental\\nto making world knowledge and services accessible to millions of users\\nin ways that seem natural and intuitive.\\nthis survey is structured as follows:\\n•the rest of this chapter introduces dialogue tasks and presents a\\nuniﬁed view in which open-domain dialogue is formulated as an\\noptimal decision making process.\\n•chapter 2introduces basic mathematical tools and machine learn-\\ning concepts, and reviews recent progress in the deep learning\\nand reinforcement learning techniques that are fundamental to\\ndeveloping neural dialogue agents.\\n•chapter 3describes question answering (qa) agents, focusing\\non neural models for knowledge-base qa and machine reading\\ncomprehension (mrc).\\n•chapter 4describes task-oriented dialogue agents, focusing on\\napplying deep reinforcement learning to dialogue management.\\n•chapter 5describes social chatbots, focusing on fully data-driven\\nneural approaches to end-to-end generation of conversational re-\\nsponses.\\n•chapter 6gives a brief review of several conversational systems\\nin industry.\\n•chapter 7concludes the paper with a discussion of research trends.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '1.2. dialogue: what kinds of problems? 5\\nfigure 1.1: ahuman-agentdialogueduringtheprocessofmakingabusinessdecision.\\n(usr: user, agt: agent) the dialogue consists of multiple segments of diﬀerent types.\\nturns 1 and 2 are a social chat segment. turns 3 to 5 are a qa segment. turns 6\\nand 7 are a task-completion segment.\\n1.2 dialogue: what kinds of problems?\\nfig.1.1shows a human-agent dialogue during the process of making\\na business decision. the example illustrates the kinds of problems a\\ndialogue system is expected to solve:\\n•question answering : the agent needs to provide concise, direct\\nanswers to user queries based on rich knowledge drawn from vari-\\nous data sources including text collections such as web documents\\nand pre-compiled knowledge bases such as sales and marketing\\ndatasets, as the example shown in turns 3 to 5 in fig. 1.1.\\n•task completion : the agent needs to accomplish user tasks rang-\\ning from restaurant reservation to meeting scheduling (e.g., turns\\n6 to 7 in fig. 1.1), and to business trip planning.\\n•social chat : the agent needs to converse seamlessly and appro-\\npriately with users — like a human as in the turing test — and\\nprovide useful recommendations (e.g., turns 1 to 2 in fig. 1.1).\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '6 introduction\\nfigure 1.2: two architectures of dialogue systems for (top) traditional task-oriented\\ndialogue and (bottom) fully data-driven dialogue.\\none may envision that the above dialogue can be collectively accom-\\nplished by a set of agents, also known as bots, each of which is designed\\nfor solving a particular type of task, e.g., qa bots, task-completion\\nbots, social chatbots. these bots can be grouped into two categories,\\ntask-oriented andchitchat, depending on whether the dialogue is con-\\nducted to assist users to achieve speciﬁc tasks, e.g., obtain an answer\\nto a query or have a meeting scheduled.\\nmost of the popular personal assistants in today’s market, such as\\namazon alexa, apple siri, google home, and microsoft cortana, are\\ntask-oriented bots. these can only handle relatively simple tasks, such\\nas reporting weather and requesting songs. an example of a chitchat\\ndialogue bot is microsoft xiaoice. building a dialogue agent to fulﬁll\\ncomplex tasks as in fig. 1.1remains one of the most fundamental\\nchallenges for the ir and nlp communities, and ai in general.\\na typical task-oriented dialogue agent is composed of four modules,\\nas illustrated in fig. 1.2(top): (1) a natural language understanding\\n(nlu) module for identifying user intents and extracting associated\\ninformation; (2) a state tracker for tracking the dialogue state that\\ncaptures all essential information in the conversation so far; (3) a\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '1.3. a uniﬁed view: dialogue as optimal decision making 7\\ndialogue policy that selects the next action based on the current state;\\nand (4) a natural language generation (nlg) module for converting\\nagent actions to natural language responses. in recent years there has\\nbeen a trend towards developing fully data-driven systems by unifying\\nthese modules using a deep neural network that maps the user input to\\nthe agent output directly, as shown in fig. 1.2(bottom).\\nmost task-oriented bots are implemented using a modular system,\\nwhere the bot often has access to an external database on which to\\ninquire about information to accomplish the task (young et al.,2013;\\ntur and de mori, 2011). social chatbots, on the other hand, are often\\nimplemented using a unitary (non-modular) system. since the primary\\ngoal of social chatbots is to be ai companions to humans with an\\nemotional connection rather than completing speciﬁc tasks, they are\\noften developed to mimic human conversations by training dnn-based\\nresponse generation models on large amounts of human-human conver-\\nsational data (ritter et al.,2011; sordoni et al.,2015b; vinyals and\\nle,2015; shang et al.,2015). only recently have researchers begun to\\nexplore how to ground the chitchat in world knowledge (ghazvininejad\\net al.,2018) and images (mostafazadeh et al.,2017) so as to make the\\nconversation more contentful and interesting.\\n1.3 a uniﬁed view: dialogue as optimal decision making\\nthe example dialogue in fig. 1.1can be formulated as a decision making\\nprocess. it has a natural hierarchy: a top-level process selects what\\nagent to activate for a particular subtask (e.g., answering a question,\\nscheduling a meeting, providing a recommendation or just having a\\ncasual chat), and a low-level process, controlled by the selected agent,\\nchooses primitive actions to complete the subtask.\\nsuch hierarchical decision making processes can be cast in the\\nmathematical framework of optionsover markov decision processes\\n(mdps)(sutton et al.,1999b),whereoptionsgeneralizeprimitiveactions\\nto higher-level actions. in a traditional mdp setting, an agent chooses a\\nprimitive action at each time step. with options, the agent can choose a\\n“multi-step” action which for example could be a sequence of primitive\\nactions for completing a subtask.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '8 introduction\\nif we view each option as an action, both top- and low-level processes\\ncan be naturally captured by the reinforcement learning framework. the\\ndialogue agent navigates in a mdp, interacting with its environment\\nover a sequence of discrete steps. at each step, the agent observes the\\ncurrent state, and chooses an action according to a policy. the agent\\nthen receives a reward and observes a new state, continuing the cycle\\nuntil the episode terminates. the goal of dialogue learning is to ﬁnd\\noptimal policies to maximize expected rewards. table 1.1formulates\\nan sample of dialogue agents using this uniﬁed view of rl, where the\\nstate-action spaces characterize the complexity of the problems, and\\nthe rewards are the objective functions to be optimized.\\nthe uniﬁed view of hierarchical mdps has already been applied\\nto guide the development of some large-scale open-domain dialogue\\nsystems. recent examples include sounding board3, a social chatbot\\nthat won the 2017 amazon alexa prize, and microsoft xiaoice4, ar-\\nguably the most popular social chatbot that has attracted more than\\n660 million users worldwide since its release in 2014. both systems use\\na hierarchical dialogue manager: a master (top-level) that manages the\\noverall conversation process, and a collection of skills (low-level) that\\nhandle diﬀerent types of conversation segments (subtasks).\\nthe reward functions in table 1.1, which seem contradictory in\\ncps (e.g., we need to minimize cps for eﬃcient task completion but\\nmaximize cps for improving user engagement), suggest that we have to\\nbalance the long-term and short-term gains when developing a dialogue\\nsystem. for example, xiaoice is a social chatbot optimized for user\\nengagement, but is also equipped with more than 230 skills, most of\\nwhich are qa and task-oriented. xiaoice is optimized for expected cps\\nwhich corresponds a long-term, rather than a short-term, engagement.\\nalthough incorporating many task-oriented and qa skills can reduce\\ncps in the short term since these skills help users accomplish tasks\\nmore eﬃciently by minimizing cps, these new skills establish xiaoice\\nas an eﬃcient and trustworthy personal assistant, thus strengthening\\nthe emotional bond with human users in the long run.\\n3https://sounding-board.github.io/\\n4https://www.msxiaobing.com/\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '1.4. the transition of nlp to neural approaches 9\\ntable 1.1: reinforcement learning for dialogue. cps stands for conversation-turns\\nper session, and is deﬁned as the average number of conversation-turns between the\\nbot and the user in a conversational session.\\ndialogue state action reward\\nqaunderstanding of\\nuser query intentclariﬁcation\\nquestions\\nor answersrelevance of answer,\\n(min) cps\\ntask-orientedunderstanding of\\nuser goaldialogue-act and\\nslot/valuetask success rate,\\n(min) cps\\nchitchatconversation history\\nand user intentresponsesuser engagement,\\nmeasured in cps\\ntop-level botunderstanding of\\nuser top-level intentoptionsuser engagement,\\nmeasured in cps\\nalthough rl provides a uniﬁed ml framework for building dialogue\\nagents, applying rl requires training the agents by interacting with\\nreal users, which can be expensive in many domains. hence, in practice,\\nwe often use a hybrid approach that combines the strengths of diﬀerent\\nml methods. for example, we might use imitation and/or supervised\\nlearning methods (if there is a large amount of human-human conversa-\\ntional corpus) to obtain a reasonably good agent before applying rl to\\ncontinue improving it. in the paper, we will survey these ml approaches\\nand their use for training dialogue systems.\\n1.4 the transition of nlp to neural approaches\\nneural approaches are now transforming the ﬁeld of nlp and ir, where\\nsymbolic approaches have been dominating for decades.\\nnlp applications diﬀer from other data processing systems in their\\nuse of language knowledge of various levels, including phonology, mor-\\nphology, syntax, semantics and discourse (jurafsky and martin, 2009).\\nhistorically, much of the nlp ﬁeld has organized itself around the\\narchitecture of fig. 1.3, with researchers aligning their work with one\\ncomponent task, such as morphological analysis or parsing. these tasks\\ncan be viewed as resolving (or realizing) natural language ambiguity\\n(or diversity) at diﬀerent levels by mapping (or generating) a natural\\nlanguage sentence to (or from) a series of human-deﬁned, unambiguous,\\nsymbolic representations, such as part-of-speech (pos) tags, context\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '10 introduction\\nfigure 1.3: traditional nlp component stack. figure credit: bird et al.(2009).\\nfree grammar, ﬁrst-order predicate calculus. with the rise of data-driven\\nand statistical approaches, these components have remained and have\\nbeen adapted as a rich source of engineered features to be fed into a\\nvariety of machine learning models (manning et al.,2014).\\nneural approaches do not rely on any human-deﬁned symbolic rep-\\nresentations but learn in a task-speciﬁc neural space where task-speciﬁc\\nknowledge is implicitly represented as semantic concepts using low-\\ndimensional continuous vectors. as fig. 1.4illustrates, neural methods\\nin nlp tasks (e.g., machine reading comprehension and dialogue) often\\nconsist of three steps: (1) encoding symbolic user input and knowledge\\ninto their neural semantic representations, where semantically related\\nor similar concepts are represented as vectors that are close to each\\nother; (2) reasoning in the neural space to generate a system response\\nbased on input and system state; and (3) decoding the system response\\ninto a natural language output in a symbolic space. encoding, reason-\\ning and decoding are implemented using neural networks of diﬀerent\\narchitectures, all of which may be stacked into a deep neural network\\ntrained in an end-to-end fashion via back propagation.\\nend-to-end training results in tighter coupling between the end\\napplication and the neural network architecture, lessening the need for\\ntraditional nlp component boundaries like morphological analysis and\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '1.4. the transition of nlp to neural approaches 11\\nfigure 1.4: symbolic and neural computation.\\nparsing. this drastically ﬂattens the technology stack of fig. 1.3, and\\nsubstantially reduces the need for feature engineering. instead, the focus\\nhas shifted to carefully tailoring the increasingly complex architecture\\nof neural networks to the end application.\\nalthough neural approaches have already been widely adopted in\\nmany ai tasks, including image processing, speech recognition and\\nmachine translation (e.g., goodfellow et al.,2016), their impact on\\nconversational ai has come somewhat more slowly. only recently have\\nwe begun to observe neural approaches establish state-of-the-art re-\\nsults on an array of conversation benchmarks for both component\\ntasks and end applications and, in the process, sweep aside the tradi-\\ntional component-based boundaries that have deﬁned research areas\\nfor decades. this symbolic-to-neural shift is also reshaping the conver-\\nsational ai landscape by opening up new tasks and user experiences\\nthat were not possible with older techniques. one reason for this is\\nthat neural approaches provide a consistent representation for many\\nmodalities, capturing linguistic and non-linguistic (e.g., image and video\\n(mostafazadeh et al.,2017)) features in the same modeling framework.\\nthere are also works on hybrid methods that combine the strengths\\nof both neural and symbolic approaches e.g., (mou et al.,2016; liang et\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '12 introduction\\nal.,2016). as summarized in fig. 1.4, neural approaches can be trained\\nin an end-to-end fashion and are robust to paraphrase alternations, but\\nare weak in terms of execution eﬃciency and explicit interpretability.\\nsymbolic approaches, on the other hand, are diﬃcult to train and\\nsensitive to paraphrase alternations, but are more interpretable and\\neﬃcient in execution.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references\\nagichtein, e., d. carmel, d. pelleg, y. pinter, and d. harman. 2015.\\n“overview of the trec 2015 liveqa track”. in: trec.\\nai, h. and d. j. litman. 2008. “assessing dialog system user simu-\\nlation evaluation measures using human judges”. in: proceedings\\nof the 46th annual meeting of the association for computational\\nlinguistics (acl). 622–629.\\nai, h., a. raux, d. bohus, m. eskenazi, and d. litman. 2007. “com-\\nparing spoken dialog corpora collected with recruited subjects\\nversus real users”. in: proceedings of the 8th sigdial workshop on\\ndiscourse and dialogue . 124–131.\\nal-rfou, r., m. pickett, j. snaider, y. sung, b. strope, and r. kurzweil.\\n2016. “conversational contextual cues: the case of personalization\\nand history for response ranking”. corr. abs/1606.00372.\\nalbrecht, j. and r. hwa. 2007. “a re-examination of machine learning\\napproaches for sentence-level mt evaluation”. in: proceedings\\nof the 45th annual meeting of the association of computational\\nlinguistics. prague, czech republic. 880–887.\\nallen, j. f., d. k. byron, m. o. dzikovska, g. ferguson, l. galescu,\\nand a. stent. 2001. “toward conversational human-computer\\ninteraction”. ai magazine . 22(4): 27–38.\\n129\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '130 references\\nangeli,g.,p.liang,andd.klein.2010.“asimpledomain-independent\\nprobabilistic approach to generation”. proceedings of the 2010\\nconference on empirical methods in natural language processing\\n(emnlp) : 502–512.\\nauer, s., c. bizer, g. kobilarov, j. lehmann, r. cyganiak, and z.\\nives. 2007. “dbpedia: a nucleus for a web of open data”. in: the\\nsemantic web. springer. 722–735.\\nbahdanau, d., k. cho, and y. bengio. 2015. “neural machine transla-\\ntion by jointly learning to align and translate”. in: proc. of iclr.\\nbanerjee, s. and a. lavie. 2005. “meteor: an automatic metric for\\nmt evaluation with improved correlation with human judgments”.\\nin:acl workshop on intrinsic and extrinsic evaluation measures\\nfor machine translation and/or summarization . 65–72.\\nbao, j., n. duan, m. zhou, and t. zhao. 2014. “knowledge-based ques-\\ntion answering as machine translation”. in: proceedings of the 52nd\\nannual meeting of the association for computational linguistics\\n(volume 1: long papers). vol. 1. 967–976.\\nbapna, a., g. tür, d. hakkani-tür, and l. p. heck. 2017. “towards\\nzero-shot frame semantic parsing for domain scaling”. in: pro-\\nceedings of the 18th annual conference of the international speech\\ncommunication association (interspeech). 2476–2480.\\nbarlier, m., j. pérolat, r. laroche, and o. pietquin. 2015. “human-\\nmachine dialogue as a stochastic game”. in: proceedings of the\\n16th annual meeting of the special interest group on discourse and\\ndialogue (sigdial). 2–11.\\nbaxter, j. and p. bartlett. 2001. “inﬁnite-horizon policy-gradient\\nestimation”. journal of artiﬁcial intelligence research . 15: 319–\\n350.\\nbaxter, j., p. bartlett, and l. weaver. 2001. “experiments with inﬁnite-\\nhorizon, policy-gradient estimation”. journal of artiﬁcial intelli-\\ngence research . 15: 351–381.\\nbell, j. 1999. “pragmatic reasoning: inferring contexts”. in: inter-\\nnational and interdisciplinary conference on modeling and using\\ncontext. springer. 42–53.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 131\\nbellemare, m. g., s. srinivasan, g. ostrovski, t. schaul, d. saxton, and\\nr. munos. 2016. “unifying count-based exploration and intrinsic\\nmotivation”. in: advances in neural information processing systems\\n(nips). 1471–1479.\\nberant, j., a. chou, r. frostig, and p. liang. 2013. “semantic parsing\\non freebase from question-answer pairs”. in: proceedings of the 2013\\nconference on empirical methods in natural language processing.\\n1533–1544.\\nbertsekas, d. p. and j. n. tsitsiklis. 1996. neuro-dynamic programming .\\nathena scientiﬁc.\\nbhatia, p., m. gavaldà, and a. einolghozati. 2017. “soc2seq: social\\nembedding meets conversation model”. corr. abs/1702.05512.\\nbird, s., e. klein, and e. loper. 2009. natural language processing\\nwith python . o’reilly.\\nblack, a. w., s. burger, a. conkie, h. w. hastie, s. keizer, o. lemon,\\nn. merigaud, g. parent, g. schubiner, b. thomson, j. d. williams,\\nk.yu,s.j.young,andm.eskénazi.2011.“spokendialogchallenge\\n2010: comparison of live and control test results”. in: proceed-\\nings of the 12th annual meeting of the special interest group on\\ndiscourse and dialogue (sigdial) . 2–7.\\nbohus, d. and e. horvitz. 2009. “models for multiparty engagement in\\nopen-world dialog”. in: proceedings of the 10th annual meeting of\\nthe special interest group on discourse and dialogue (sigdial) .\\n225–234.\\nbohus, d. and e. horvitz. 2011. “multiparty turn taking in situated di-\\nalog: study, lessons, and directions”. in: proceedings of the 12nnual\\nmeeting of the special interest group on discourse and dialogue\\n(sigdial). 98–109.\\nbohus, d. and a. i. rudnicky. 2009. “the ravenclaw dialog manage-\\nment framework: architecture and systems”. computer speech &\\nlanguage. 23(3): 332–361.\\nbohus, d., c. w. saw, and e. horvitz. 2014. “directions robot: in-\\nthe-wild experiences and lessons learned”. in: proceedings of the\\ninternational conference on autonomous agents and multi-agent\\nsystems (aamas) . 637–644.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '132 references\\nbollacker, k., c. evans, p. paritosh, t. sturge, and j. taylor. 2008.\\n“freebase: a collaboratively created graph database for structuring\\nhuman knowledge”. in: proceedings of the 2008 acm sigmod\\ninternational conference on management of data. acm. 1247–1250.\\nbordes, a., y. -l. boureau, and j. weston. 2017. “learning end-to-\\nend goal-oriented dialog”. in: proceedings of the international\\nconference on learning representations (iclr) .\\nbordes, a., n. usunier, a. garcia-duran, j. weston, and o. yakhnenko.\\n2013. “translating embeddings for modeling multi-relational data”.\\nin:advances in neural information processing systems . 2787–2795.\\nbos, j., e. klein, o. lemon, and t. oka. 2003. “dipper: description\\nand formalisation of an information-state update dialogue system\\narchitecture”. in: proceedings of the 4th annual meeting of the\\nspecial interest group on discourse and dialogue (sigdial) . 115–\\n124.\\nbraunschweiler, n. and a. papangelis. 2018. “comparison of an end-to-\\nend trainable dialogue system with a modular statistical dialogue\\nsystem”. in: proceedings of the 19th annual conference of the\\ninternational speech communication association (interspeech).\\n576–580.\\nbudzianowski,p.,s.ultes,p. -h.su,n.mrkšić,t. -h.wen,i.casanueva,\\nl. m. rojas-barahona, and m. gašić. 2017. “sub-domain modelling\\nfor dialogue management with hierarchical reinforcement learn-\\ning”.in:proceedings of the 18h annual sigdial meeting on discourse\\nand dialogue (sigdial). 86–92.\\ncallison-burch, c., p. koehn, c. monz, and j. schroeder. 2009. “find-\\nings of the 2009 workshop on statistical machine translation”. in:\\nproceedings of the fourth workshop on statistical machine transla-\\ntion. athens, greece. 1–28.\\ncaruana, r. 1998. “multitask learning”. in: learning to learn. springer.\\n95–133.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 133\\ncasanueva, i., p. budzianowski, p. -h. su, s. ultes, l. m. rojas-\\nbarahona, b. -h. tseng, and m. gašić. 2018. “feudal reinforcement\\nlearning for dialogue management in large domains”. in: pro-\\nceedings of the 2018 conference of the north american chapter of\\nthe association for computational linguistics: human language\\ntechnologies (naacl-hlt). 714–719.\\ncer, d., c. d. manning, and d. jurafsky. 2010. “the best lexical\\nmetric for phrase-based statistical mt system optimization”. in:\\nhuman language technologies: the 2010 annual conference of\\nthe north american chapter of the association for computational\\nlinguistics. hlt ’10. los angeles, california. 555–563.\\nchandramohan, s., m. geist, f. lefèvre, and o. pietquin. 2011. “user\\nsimulation in dialogue systems using inverse reinforcement learn-\\ning”. in: proceedings of the 12th annual conference of the interna-\\ntional speech communication association (interspeech). 1025–\\n1028.\\nchapelle, o. and l. li. 2012. “an empirical evaluation of thompson\\nsampling”. in: advances in neural information processing systems\\n24 (nips). 2249–2257.\\nchen, d., j. bolton, and c. d. manning. 2016a. “a thorough exami-\\nnation of the cnn/daily mail reading comprehension task”. arxiv\\npreprint arxiv:1606.02858 .\\nchen, d., a. fisch, j. weston, and a. bordes. 2017a. “reading\\nwikipedia to answer open-domain questions”. arxiv 1704.00051 .\\nchen, h., x. liu, d. yin, and j. tang. 2017b. “a survey on dia-\\nlogue systems: recent advances and new frontiers”. arxiv preprint\\narxiv:1711.01731.\\nchen, j., c. wang, l. xiao, j. he, l. li, and l. deng. 2017c. “q-\\nlda: uncovering latent patterns in text-based sequential decision\\nprocesses”. in: advances in neural information processing systems\\n30. 4984–4993.\\nchen, l., b. tan, s. long, and k. yu. 2018. “structured dialogue\\npolicy with graph neural networks”. in: proceedings of the 27th\\ninternational conference on computational linguistics (coling) .\\n1257–1268.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '134 references\\nchen, l., x. zhou, c. chang, r. yang, and k. yu. 2017d. “agent-\\naware dropout dqn for safe and eﬃcient on-line dialogue policy\\nlearning”. in: proceedings of the 2017 conference on empirical\\nmethods in natural language processing (emnlp). 2454–2464.\\nchen, y. -n., a. celikyilmaz, and d. hakkani-tür. 2017e. “deep learn-\\ning for dialogue systems”. in: proceedings of the 55th annual meet-\\ning of the association for computational linguistics (tutorial ab-\\nstracts). 8–14.\\nchen,y.-n.andj.gao.2017.“open-domainneuraldialoguesystems”.\\nin:proceedings of the eighth international joint conference on\\nnatural language processing (tutorial abstracts). 6–10.\\nchen, y. -n., d. hakkani-tür, g. tur, j. gao, and l. deng. 2016b.\\n“end-to-end memory networks with knowledge carryover for multi-\\nturn spoken language understanding”. in: proceedings of the\\n17th annual meeting of the international speech communication\\nassociation. 3245–3249.\\ncho, k., b. van merrienboer, d. bahdanau, and y. bengio. 2014a. “on\\nthe properties of neural machine translation: encoder–decoder\\napproaches”.in: proceedings of ssst-8, eighth workshop on syntax,\\nsemantics and structure in statistical translation. doha, qatar.\\n103–111.\\ncho, k., b. van merrienboer, c. gulcehre, d. bahdanau, f. bougares, h.\\nschwenk, and y. bengio. 2014b. “learning phrase representations\\nusing rnn encoder–decoder for statistical machine translation”.\\nin:proceedings of the 2014 conference on empirical methods in\\nnatural language processing (emnlp) . doha, qatar. 1724–1734.\\nchoi, e., h. he, m. iyyer, m. yatskar, w. -t. yih, y. choi, p. liang,\\nand l. zettlemoyer. 2018. “quac: question answering in context”.\\narxiv preprint arxiv:1808.07036.\\nclark, p., i. cowhey, o. etzioni, t. khot, a. sabharwal, c. schoenick,\\nand o. tafjord. 2018. “think you have solved question answer-\\ning? try arc, the ai2 reasoning challenge”. arxiv preprint\\narxiv:1803.05457.\\ncolby, k. m. 1975. artiﬁcial paranoia: a computer simulation of\\nparanoid processes. new york, ny, usa: elsevier science inc.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 135\\ncole, r. a. 1999. “tools for research and education in speech science”.\\nin:proceedings of international conference of phonetic sciences .\\n1277–1280.\\ncore, m. g. and j. f. allen. 1997. “coding dialogs with the damsl\\nannotation scheme”. in: proceedings of aaai fall symposium on\\ncommunicative action in humans and machines. 28–35.\\ncorston-oliver, s., m. gamon, and c. brockett. 2001. “a machine\\nlearning approach to the automatic evaluation of machine trans-\\nlation”. in: proceedings of 39th annual meeting of the association\\nfor computational linguistics. toulouse, france. 148–155.\\ncôté, m. -a., á. kádár, x. yuan, b. kybartas, t. barnes, e. fine,\\nj. moore, m. hausknecht, l. el asri, m. adada, w. tay, and a.\\ntrischler. 2018.“textworld: alearning environmentfortext-based\\ngames”. arxiv:1806.11532.\\ncrook, p. a., a. marin, v. agarwal, k. aggarwal, t. anastasakos, r.\\nbikkula,d.boies,a.celikyilmaz,s.chandramohan,z.feizollahi,r.\\nholenstein, m. jeong, o. z. khan, y. -b. kim, e. krawczyk, x. liu,\\nd. panic, v. radostev, n. ramesh, j. -p. robichaud, a. rochette,\\nl. stromberg, and r. sarikaya. 2016. “task completion platform:\\na self-serve multi-domain goal oriented dialogue platform”. in:\\nproceedings of the 2016 conference of the north american chapter\\nof the association for computational linguistics: human language\\ntechnologies (hlt-naacl): demonstrations session. 47–51.\\ncuayáhuitl, h., s. renals, o. lemon, and h. shimodaira. 2010. “eval-\\nuation of a hierarchical reinforcement learning spoken dialogue\\nsystem”. computer speech and language . 24(2): 395–429.\\ncuayáhuitl, h., s. yu, a. williamson, and j. carse. 2016. “deep re-\\ninforcement learning for multi-domain dialogue systems”. arxiv\\npreprint arxiv:1611.08675 .\\ndai, b., a. shaw, n. he, l. li, and l. song. 2018a. “boosting the\\nactor with dual critic”. in: proceedings of the sixth international\\nconference on learning representations (iclr) .\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '136 references\\ndai, b., a. shaw, l. li, l. xiao, n. he, z. liu, j. chen, and l.\\nsong. 2018b. “sbeed: convergent reinforcement learning with\\nnonlinear function approximation”. in: proceedings of the thirty-\\nfifth international conference on machine learning (icml-18).\\n1133–1142.\\ndang, h. t., d. kelly, and j. j. lin. 2007. “overview of the trec\\n2007 question answering track”. in: trec. vol. 7. 63.\\ndann, c., t. lattimore, and e. brunskill. 2017. “unifying pac and\\nregret: uniform pac bounds for episodic reinforcement learning”.\\nin:advances in neural information processing systems 30 (nips).\\n5717–5727.\\ndas, a., s. kottur, k. gupta, a. singh, d. yadav, j. m. moura, d.\\nparikh, and d. batra. 2017a. “visual dialog”. in: cvpr.\\ndas, r., s. dhuliawala, m. zaheer, l. vilnis, i. durugkar, a. krishna-\\nmurthy, a. smola, and a. mccallum. 2017b. “go for a walk and\\narrive at the answer: reasoning over paths in knowledge bases using\\nreinforcement learning”. arxiv preprint arxiv:1711.05851.\\ndaubigney, l., m. gašić, s. chandramohan, m. geist, o. pietquin, and\\ns. j. young. 2011. “uncertainty management for on-line optimi-\\nsation of a pomdp-based large-scale spoken dialogue system”.\\nin:proceedings of the 12th annual conference of the international\\nspeech communication association (interspeech) . 1301–1304.\\ndaubigney, l., m. geist, s. chandramohan, and o. pietquin. 2012. “a\\ncomprehensive reinforcement learning framework for dialogue\\nmanagement optimization”. ieee journal of selected topics in\\nsignal processing. 6(8): 891–902.\\ndayan, p. and g. e. hinton. 1993. “feudal reinforcement learning”.\\nin:advances in neural information processing systems 5 (nips) .\\n271–278.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 137\\ndevault, d., r. artstein, g. benn, t. dey, e. fast, a. gainer, k.\\ngeorgila, j. gratch, a. hartholt, m. lhommet, g. m. lucas, s.\\nmarsella, f. morbini, a. nazarian, s. scherer, g. stratou, a. suri,\\nd. r. traum, r. wood, y. xu, a. a. rizzo, and l. -p. morency.\\n2014. “simsensei kiosk: a virtual human interviewer for healthcare\\ndecision support”. in: proceedings of the international conference\\non autonomous agents and multi-agent systems (aamas) . 1061–\\n1068.\\ndevlin, j., m. -w. chang, k. lee, and k. toutanova. 2018. “bert:\\npre-training of deep bidirectional transformers for language under-\\nstanding”. arxiv preprint arxiv:1810.04805.\\ndhingra, b., l. li, x. li, j. gao, y. -n. chen, f. ahmed, and l. deng.\\n2017. “towards end-to-end reinforcement learning of dialogue\\nagents for information access”. in: acl (1). 484–495.\\ndhingra, b., h. liu, z. yang, w. w. cohen, and r. salakhutdinov. 2016.\\n“gated-attention readers for text comprehension”. arxiv preprint\\narxiv:1606.01549.\\ndietterich, t. g. 2000. “hierarchical reinforcement learning with\\nthe maxq value function decomposition”. journal of artiﬁcial\\nintelligence research . 13: 227–303.\\nding, y., y. liu, h. luan, and m. sun. 2017. “visualizing and under-\\nstanding neural machine translation”. in: proceedings of the 55th\\nannual meeting of the association for computational linguistics\\n(volume 1: long papers). vancouver, canada. 1150–1159.\\ndodge, j., a. gane, x. zhang, a. bordes, s. chopra, a. miller, a.\\nszlam, and j. weston. 2016. “evaluating prerequisite qualities for\\nlearning end-to-end dialog systems”. in: iclr.\\ndunn, m., l. sagun, m. higgins, u. guney, v. cirik, and k. cho. 2017.\\n“searchqa: a new q&a dataset augmented with context from a\\nsearch engine”. arxiv preprint arxiv:1704.05179.\\neckert, w., e. levin, and r. pieraccini. 1997. “user modeling for\\nspoken dialogue system evaluation”. in: proceedings of the 1997\\nieee workshop on automatic speech recognition and understand-\\ning (asru). 80–87.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '138 references\\nel asri, l., j. he, and k. suleman. 2016. “a sequence-to-sequence\\nmodel for user simulation in spoken dialogue systems”. in: pro-\\nceedings of the 17th annual conference of the international speech\\ncommunication association (interspeech). 1151–1155.\\nel asri, l., r. laroche, and o. pietquin. 2012. “reward function\\nlearning for dialogue management”. in: proceedings of the sixth\\nstarting ai researchers’ symposium (stairs) . 95–106.\\nengel, y., s. mannor, and r. meir. 2005. “reinforcement learning\\nwith gaussian processes”. in: proceedings of the 22nd international\\nconference on machine learning (icml). 201–208.\\neric, m., l. krishnan, f. charette, and c. d. manning. 2017. “key-\\nvalue retrieval networks for task-oriented dialogue”. in: proceed-\\nings of the 18th annual sigdial meeting on discourse and dialogue\\n(sigdial). 37–49.\\nernst, d., p. geurts, and l. wehenkel. 2005. “tree-based batch mode\\nreinforcement learning”. journal of machine learning research. 6:\\n503–556.\\nfang, h., s. gupta, f. iandola, r. k. srivastava, l. deng, p. dollár,\\nj. gao, x. he, m. mitchell, j. c. platt, l. zitnick, and g. zweig.\\n2015. “from captions to visual concepts and back”. in: proceedings\\nof the ieee conference on computer vision and pattern recognition.\\n1473–1482.\\nfatemi, m., l. el asri, h. schulz, j. he, and k. suleman. 2016. “policy\\nnetworks with two-stage training for dialogue systems”. in: pro-\\nceedings of the 17th annual meeting of the special interest group\\non discourse and dialogue (sigdial) . 101–110.\\nfedorenko, d. g., n. smetanin, and a. rodichev. 2017. “avoiding\\necho-responses in a retrieval-based conversation system”. corr.\\nabs/1712.05626.\\nfung, p., d. bertero, y. wan, a. dey, r. h. y. chan, f. b. siddique, y.\\nyang, c. wu, and r. lin. 2016. “towards empathetic human-robot\\ninteractions”. corr. abs/1605.04072.\\ngalley,m.,c.brockett,a.sordoni,y.ji,m.auli,c.quirk,m.mitchell,\\nj. gao, and b. dolan. 2015. “deltableu: a discriminative metric\\nfor generation tasks with intrinsically diverse targets”. in: acl-\\nijcnlp. 445–450.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 139\\ngao, j. 2017. “an introduction to deep learning for natural language\\nprocessing”. in: international summer school on deep learning,\\nbilbao.\\ngao, j., m. galley, and l. li. 2018a. “neural approaches to conver-\\nsational ai”. in: the 41st international acm sigir conference\\non research & development in information retrieval . acm. 1371–\\n1374.\\ngao, j., m. galley, and l. li. 2018b. “neural approaches to conversa-\\ntional ai”. proc. of acl 2018, tutorial abstracts : 2–7.\\ngao, j., x. he, w. -t. yih, and l. deng. 2014a. “learning continuous\\nphrase representations for translation modeling”. in: proceedings\\nof the 52nd annual meeting of the association for computational\\nlinguistics (volume 1: long papers). vol. 1. 699–709.\\ngao, j., p. pantel, m. gamon, x. he, and l. deng. 2014b. “model-\\ning interestingness with deep neural networks”. in: proceedings of\\nthe 2014 conference on empirical methods in natural language\\nprocessing (emnlp) . 2–13.\\ngardner, m., p. talukdar, j. krishnamurthy, and t. mitchell. 2014.\\n“incorporating vector space similarity in random walk inference\\nover knowledge bases”. in: proceedings of the 2014 conference on\\nempirical methods in natural language processing (emnlp) . 397–\\n406.\\ngašić, m., c. breslin, m. henderson, d. kim, m. szummer, b. thomson,\\np. tsiakoulis, and s. j. young. 2013. “on-line policy optimisation\\nof bayesian spoken dialogue systems via human interaction”. in:\\nproceedings of the ieee international conference on acoustics,\\nspeech and signal processing (icassp) . 8367–8371.\\ngašic,m.,d.kim,p.tsiakoulis,c.breslin,m.henderson,m.szummer,\\nb. thomson, and s. young. 2014. “incremental on-line adaptation\\nof pomdp-based dialogue managers to extended domains”. in:\\nproceedings of the 15th annual conference of the international\\nspeech communication association (interspeech) . 140–144.\\ngašić, m., n. mrkšić, p. -h. su, d. vandyke, t. -h. wen, and s. j. young.\\n2015. “policy committee for adaptation in multi-domain spoken\\ndialogue systems”. in: proceedings of the 2015 ieee workshop on\\nautomatic speech recognition and understanding (asru) . 806–812.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '140 references\\ngašić, m. and s. j. young. 2014. “gaussian processes for pomdp-\\nbased dialogue manager optimization”. ieee trans. audio, speech\\n& language processing. 22(1): 28–40.\\ngeorgila, k., j. henderson, and o. lemon. 2006. “user simulation for\\nspoken dialogue systems: learning and evaluation”. in: proceedings\\nof the 9th international conference on spoken language processing\\n(interspeech). 1065–1068.\\nghazvininejad, m., c. brockett, m. -w. chang, b. dolan, j. gao, w. -t.\\nyih, and m. galley. 2018. “a knowledge-grounded neural conver-\\nsation model”. in: 5110–5117.\\ngiménez, j. and l. màrquez. 2008. “a smorgasbord of features for\\nautomatic mt evaluation”. in: proceedings of the third workshop\\non statistical machine translation . 195–198.\\ngoodfellow, i., y. bengio, and a. courville. 2016. deep learning. mit\\npress.\\ngoodfellow, i., j. pouget-abadie, m. mirza, b. xu, d. warde-farley,\\ns. ozair, a. courville, and y. bengio. 2014. “generative adversarial\\nnets”. in: nips. 2672–2680.\\ngraham, y. and t. baldwin. 2014. “testing for signiﬁcance of increased\\ncorrelation with human judgment”. in: proceedings of the 2014\\nconference on empirical methods in natural language processing\\n(emnlp). doha, qatar. 172–176.\\ngraham, y., t. baldwin, and n. mathur. 2015. “accurate evaluation\\nof segment-level machine translation metrics”. in: naacl-hlt.\\ngraves, a. and j. schmidhuber. 2005. “framewise phoneme classiﬁca-\\ntion with bidirectional lstm and other neural network architec-\\ntures”.neural networks . 18: 602–610.\\ngu, j., z. lu, h. li, and v. o. li. 2016. “incorporating copying mecha-\\nnism in sequence-to-sequence learning”. in: proceedings of the 54th\\nannual meeting of the association for computational linguistics\\n(volume 1: long papers). 1631–1640.\\ngu, s., t. lillicrap, z. ghahramani, r. e. turner, and s. levine. 2017.\\n“q-prop:sample-eﬃcientpolicygradientwithanoﬀ-policycritic”.\\nin:proceedings of the 5th international conference on learning\\nrepresentations (iclr).\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 141\\nguu, k., j. miller, and p. liang. 2015. “traversing knowledge graphs\\nin vector space”. arxiv preprint arxiv:1506.01094.\\nhakkani-tür, d., g. tür, a. celikyilmaz, y. -n. chen, j. gao, l. deng,\\nand y.-y. wang. 2016. “multi-domain joint semantic frame pars-\\ning using bi-directional rnn-lstm”. in: proceedings of the 17th\\nannual conference of the international speech communication as-\\nsociation (interspeech). 715–719.\\nhakkani-tür, d., g. tur, l. heck, a. fidler, and a. celikyilmaz. 2012.\\n“a discriminative classiﬁcation-based approach to information\\nstate updates for a multi-domain dialog system”. in: proceedings\\nof the 13th annual conference of the international speech commu-\\nnication association (interspeech). 330–333.\\nhartikainen, m., e. -p. salonen, and m. turunen. 2004. “subjective eval-\\nuation of spoken dialogue systems using servqual method”. in:\\nproceedings of the 8th international conference on spoken language\\nprocessing (interspeech). 2273–2276.\\nhausknecht, m. and p. stone. 2015. “deep recurrent q-learning for\\npartially observable mdps”. in: proceedings of the aaai fall\\nsymposium on sequential decision making for intelligent agents.\\n29–37.\\nhe, j., j. chen, x. he, j. gao, l. li, l. deng, and m. ostendorf. 2016.\\n“deep reinforcement learning with a natural language action\\nspace”.in: proceedings of the 54th annual meeting of the association\\nfor computational linguistics (acl). 1621–1630.\\nhe, s., c. liu, k. liu, and j. zhao. 2017a. “generating natural answers\\nby incorporating copying and retrieving mechanisms in sequence-\\nto-sequence learning”. in: acl. vol. 1. 199–208.\\nhe, w., k. liu, y. lyu, s. zhao, x. xiao, y. liu, y. wang, h. wu,\\nq. she, x. liu, t. wu, and h. wang. 2017b. “dureader: a chi-\\nnese machine reading comprehension dataset from real-world\\napplications”. arxiv preprint arxiv:1711.05073.\\nhenderson, j., o. lemon, and k. georgila. 2008. “hybrid reinforce-\\nment/supervised learning of dialogue policies from fixed data\\nsets”.computational linguistics. 34(4): 487–511.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '142 references\\nhenderson, m. 2015. “machine learning for dialog state tracking: a\\nreview”. in: proceedings of the first international workshop on\\nmachine learning in spoken language processing.\\nhenderson, m., b. thomson, and j. d. williams. 2014a. “the 3rd\\ndialog state tracking challenge”. in: proceedings of the 2014 ieee\\nspoken language technology workshop (slt). 324–329.\\nhenderson, m., b. thomson, and j. d. williams. 2014b. “the second\\ndialog state tracking challenge”. in: proceedings of the 15th annual\\nmeeting of the special interest group on discourse and dialogue\\n(sigdial). 263–272.\\nhenderson, m., b. thomson, and s. j. young. 2013. “deep neural\\nnetwork approach for the dialog state tracking challenge”. in:\\nproceedings of the 14th annual meeting of the special interest group\\non discourse and dialogue (sigdial) . 467–471.\\nhermann, k. m., t. kocisky, e. grefenstette, l. espeholt, w. kay,\\nm. suleyman, and p. blunsom. 2015. “teaching machines to read\\nand comprehend”. in: advances in neural information processing\\nsystems. 1693–1701.\\nhewlett, d., a. lacoste, l. jones, i. polosukhin, a. fandrianto, j. han,\\nm. kelcey, and d. berthelot. 2016. “wikireading: a novel large-\\nscale language understanding task over wikipedia”. arxiv preprint\\narxiv:1608.03542.\\nhill, f., a. bordes, s. chopra, and j. weston. 2015. “the goldilocks\\nprinciple: reading children’s books with explicit memory represen-\\ntations”. arxiv preprint arxiv:1511.02301.\\nhinton, g. e. and d. van camp. 1993. “keeping the neural networks\\nsimple by minimizing the description length of the weights”. in:\\nproceedings of the sixth annual conference on computational learning\\ntheory. acm. 5–13.\\nhinton, g., l. deng, d. yu, g. e. dahl, a. mohamed, n. jaitly, a.\\nsenior, v. vanhoucke, p. nguyen, t. n. sainath, and b. kingsbury.\\n2012. “deep neural networks for acoustic modeling in speech\\nrecognition: the shared views of four research groups”. ieee\\nsignal processing magazine . 29(6): 82–97.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 143\\nhochreiter, s. 1991. “untersuchungen zu dynamischen neuronalen net-\\nzen. diploma thesis, institut für informatik, lehrstuhl prof. brauer,\\ntechnische universität münchen”.\\nhochreiter, s. and j. schmidhuber. 1997. “long short-term memory”.\\nneural computation . 9(8): 1735–1780.\\nhofmann, k., l. li, and f. radlinski. 2016. “online evaluation for\\ninformation retrieval”. foundations and trends in information\\nretrieval. 10(1): 1–117.\\nholtzman, a., j. buys, m. forbes, a. bosselut, d. golub, and y. choi.\\n2018. “learning to write with cooperative discriminators”. in: acl.\\nmelbourne, australia. 1638–1649.\\nhori, c. and t. hori. 2017. “end-to-end conversation modeling track\\nin dstc6”. corr. abs/1706.07440.\\nhori, c., t. hori, s. watanabe, and j. r. hershey. 2015. “context\\nsensitive spoken language understanding using role dependent\\nlstm layers”. tech. rep. no. tr2015-134. mitsubishi electric\\nresearch laboratories.\\nhori, c., j. perez, k. yoshino, and s. kim. 2017. “the sixth dialog\\nstate tracking challenge”. http://workshop.colips.org/dstc6.\\nhorvitz, e. 1999. “principles of mixed-initiative user interfaces”. in:\\nproceeding of the conference on human factors in computing\\nsystems (chi). 159–166.\\nhouthooft, r., x. chen, y. duan, j. schulman, f. d. turck, and p.\\nabbeel. 2016. “vime: variational information maximizing explo-\\nration”. in: advances in neural information processing systems 29\\n(nips). 1109–1117.\\nhu, m., y. peng, and x. qiu. 2017. “mnemonic reader for machine\\ncomprehension”. arxiv preprint arxiv:1705.02798.\\nhuang, h. -y., c. zhu, y. shen, and w. chen. 2017. “fusionnet: fusing\\nvia fully-aware attention with application to machine comprehen-\\nsion”.arxiv preprint arxiv:1711.07341.\\nhuang, q., z. gan, a. celikyilmaz, d. o. wu, j. wang, and x. he. 2018.\\n“hierarchically structured reinforcement learning for topically\\ncoherent visual story generation”. corr. abs/1805.08191.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '144 references\\nhuang, p. -s., x. he, j. gao, l. deng, a. acero, and l. heck. 2013.\\n“learning deep structured semantic models for web search using\\nclickthrough data”. in: proceedings of the 22nd acm international\\nconference on conference on information & knowledge management.\\n2333–2338.\\nhuang, x., a. acero, and h. -w. hon. 2001. spoken language processing:\\na guide to theory, algorithm, and system development. prentice hall.\\nhuber, b., d. mcduﬀ, c. brockett, m. galley, and b. dolan. 2018.\\n“emotional dialogue generation using image-grounded language\\nmodels”. in: chi. 277:1–277:12.\\ninaba, m. and k. takahashi. 2016. “neural utterance ranking model\\nfor conversational dialogue systems”. in: sigdial. 393–403.\\niyyer, m., w. -t. yih, and m. -w. chang. 2017. “search-based neural\\nstructured learning for sequential question answering”. in: proceed-\\nings of the 55th annual meeting of the association for computational\\nlinguistics (volume 1: long papers). vol. 1. 1821–1831.\\njafarpour, s., c. j. burges, and a. ritter. 2010. “filter, rank, and\\ntransfer the knowledge: learning to chat”. advances in ranking . 10:\\n2329–9290.\\njaksch, t., r. ortner, and p. auer. 2010. “near-optimal regret bounds\\nfor reinforcement learning”. journal of machine learning research .\\n11: 1563–1600.\\njia, r. and p. liang. 2017. “adversarial examples for evaluating reading\\ncomprehension systems”. arxiv preprint arxiv:1707.07328.\\njiang, n., a. krishnamurthy, a. agarwal, j. langford, and r. e.\\nschapire. 2017. “contextual decision processes with low bellman\\nrank are pac-learnable”. in: proceedings of the 34th international\\nconference on machine learning (icml). 1704–1713.\\njiang, n. and l. li. 2016. “doubly robust oﬀ-policy evaluation for\\nreinforcement learning”. in: proceedings of the 33rd international\\nconference on machine learning (icml). 652–661.\\njoshi, m., e. choi, d. s. weld, and l. zettlemoyer. 2017. “triviaqa:\\na large scale distantly supervised challenge dataset for reading\\ncomprehension”. arxiv preprint arxiv:1705.03551.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 145\\njung, s., c. lee, k. kim, m. jeong, and g. g. lee. 2009. “data-\\ndriven user simulation for automated evaluation of spoken dialog\\nsystems”. computer speech and language . 23: 479–509.\\njurafsky, d. and j. h. martin. 2009. speech & language processing .\\nprentice hall.\\njurafsky, d. and j. h. martin. 2018. speech and language processing:\\nan introduction to natural language processing, computational\\nlinguistics, and speech recognition . draft of august 12th, 2018.\\nwebsite: https://web.stanford.edu/~jurafsky/slp3. prentice-hall.\\nkaelbling, l. p., m. l. littman, and a. p. moore. 1996. “reinforcement\\nlearning: a survey”. journal of artiﬁcial intelligence research . 4:\\n237–285.\\nkakade, s. 2001. “a natural policy gradient”. in: advances in neural\\ninformation processing systems 13 (nips). 1531–1538.\\nkalchbrenner, n. and p. blunsom. 2013. “recurrent continuous trans-\\nlation models”. in: proceedings of the 2013 conference on empirical\\nmethods in natural language processing. seattle, washington, usa.\\n1700–1709.\\nkannan, a. and o. vinyals. 2016. “adversarial evaluation of dialogue\\nmodels”. in: nips workshop on adversarial training .\\nkhandelwal, u., h. he, p. qi, and d. jurafsky. 2018. “sharp nearby,\\nfuzzy far away: how neural language models use context”. in:\\nproceedings of the 56th annual meeting of the association for com-\\nputational linguistics (volume 1: long papers). melbourne, aus-\\ntralia. 284–294.\\nkim, s., l. f. d’haro, r. e. banchs, j. d. williams, and m. henderson.\\n2016a. “the fourth dialog state tracking challenge”. in: proceed-\\nings of the 7th international workshop on spoken dialogue systems\\n(iwsds). 435–449.\\nkim, s., l. f. d’haro, r. e. banchs, j. d. williams, m. henderson, and\\nk. yoshino. 2016b. “the fifth dialog state tracking challenge”.\\nin:proceedings of the 2016 ieee spoken language technology\\nworkshop (slt-16) . 511–517.\\nkočisky, t., j. schwarz, p. blunsom, c. dyer, k. m. hermann, g. melis,\\nand e. grefenstette. 2017. “the narrativeqa reading comprehen-\\nsion challenge”. arxiv preprint arxiv:1712.07040.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '146 references\\nkoehn, p. 2004. “statistical signiﬁcance tests for machine translation\\nevaluation”. in: proceedings of emnlp 2004. barcelona, spain.\\n388–395.\\nkoehn, p., f. j. och, and d. marcu. 2003. “statistical phrase-based\\ntranslation”. in: proceedings of the 2003 conference of the north\\namerican chapter of the association for computational linguistics\\non human language technology - volume 1. naacl ’03 . edmonton,\\ncanada. 48–54.\\nkoller, a. and m. stone. 2007. “sentence generation as a planning prob-\\nlem”. in: proceedings of the 45th annual meeting of the association\\nfor computational linguistics (acl-07). 336–343.\\nkomatani, k., n. kanda, m. nakano, k. nakadai, h. tsujino, t. ogata,\\nand h. g. okuno. 2006. “multi-domain spoken dialogue system\\nwith extensibility and robustness against speech recognition er-\\nrors”. in: proceedings of the sigdial 2006 workshop. 9–17.\\nkonda, v. r. and j. n. tsitsiklis. 1999. “actor-critic algorithms”.\\nin:advances in neural information processing systems 12 (nips).\\n1008–1014.\\nkondadadi, r., b. howald, and f. schilder. 2013. “a statistical nlg\\nframework for aggregated planning and realization”. in: proceed-\\nings of the 51st annual meeting of the association for computational\\nlinguistics (acl). 1406–1415.\\nkotti, m., v. diakoloukas, a. papangelis, m. lagoudakis, and y.\\nstylianou. 2018. “a case study on the importance of belief state\\nrepresentation for dialogue policy management”. in: proceedings\\nof the 19th annual conference of the international speech commu-\\nnication association (interspeech). 986–990.\\nkulesza, a. and s. m. shieber. 2004. “a learning approach to im-\\nproving sentence-level mt evaluation”. in: proceedings of the 10th\\ninternational conference on theoretical and methodological issues\\nin machine translation . baltimore, md.\\nkumar,a.,o.irsoy,p.ondruska,m.iyyer,j.bradbury,i.gulrajani,v.\\nzhong, r. paulus, and r. socher. 2016. “ask me anything: dynamic\\nmemory networks for natural language processing”. in: international\\nconference on machine learning. 1378–1387.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 147\\nlai, g., q. xie, h. liu, y. yang, and e. hovy. 2017. “race: large-scale\\nreading comprehension dataset from examinations”. arxiv preprint\\narxiv:1704.04683.\\nlangkilde, i. and k. knight. 1998. “generation that exploits corpus-\\nbased statistical knowledge”. in: proceedings of the 36th annual\\nmeeting of the association for computational linguistics and 17th\\ninternational conference on computational linguistics (coling-\\nacl). 704–710.\\nlao, n. and w. w. cohen. 2010. “relational retrieval using a combina-\\ntion of path-constrained random walks”. machine learning . 81(1):\\n53–67.\\nlao, n., t. mitchell, and w. w. cohen. 2011. “random walk inference\\nand learning in a large scale knowledge base”. in: proceedings of the\\nconference on empirical methods in natural language processing.\\n529–539.\\nlarsson, s. and d. r. traum. 2000. “information state and dialogue\\nmanagementinthetrindidialoguemoveenginetoolkit”. natural\\nlanguage engineering . 6(3–4): 323–340.\\nlee, j. y. and f. dernoncourt. 2016. “sequential short-text classi-\\nﬁcation with recurrent and convolutional neural networks”. in:\\nproceedings of the 2016 conference of the north american chapter\\nof the association for computational linguistics: human language\\ntechnologies (naacl-hlt). 515–520.\\nlee, s. and r. jha. 2019. “zero-shot adaptive transfer for conversa-\\ntional language understanding”. in: proceedings of the thirty-third\\naaai conference on artiﬁcial intelligence (aaai-19), to appear .\\nlei, w., x. jin, z. ren, x. he, m. -y. kan, and d. yin. 2018. “sequicity:\\nsimplifying task-oriented dialogue systems with single sequence-to-\\nsequence architectures”. in: proceedings of the 56th annual meeting\\nof the association for computational linguistics (acl). 1437–1447.\\nlemon, o. 2011. “learning what to say and how to say it: joint op-\\ntimisation of spoken dialogue management and natural language\\ngeneration”. computer speech & language. 25(2): 210–221.\\nlevin, e., r. pieraccini, and w. eckert. 2000. “a stochastic model of\\nhuman-machine interaction for learning dialog strategies”. ieee\\ntransactions on speech and audio processing . 8(1): 11–23.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '148 references\\nlewis, m., d. yarats, y. dauphin, d. parikh, and d. batra. 2017. “deal\\nor no deal? end-to-end learning of negotiation dialogues”. in:\\nproceedings of the 2017 conference on empirical methods in natural\\nlanguage processing (emnlp-17). 2443–2453.\\nli, j., m. galley, c. brockett, j. gao, and b. dolan. 2016a. “a diversity-\\npromoting objective function for neural conversation models”. in:\\nnaacl-hlt. 110–119.\\nli, j., m. galley, c. brockett, j. gao, and b. dolan. 2016b. “a persona-\\nbased neural conversation model”. in: acl. 994–1003.\\nli, j., a. h. miller, s. chopra, m. ranzato, and j. weston. 2017a.\\n“dialogue learning with human-in-the-loop”. in: iclr.\\nli, j., a. h. miller, s. chopra, m. ranzato, and j. weston. 2017b.\\n“learning through dialogue interactions by asking questions”. in:\\niclr.\\nli, j., w. monroe, a. ritter, d. jurafsky, m. galley, and j. gao.\\n2016c. “deep reinforcement learning for dialogue generation”. in:\\nemnlp. 1192–1202.\\nli, j., w. monroe, t. shi, s. jean, a. ritter, and d. jurafsky. 2017c.\\n“adversarial learning for neural dialogue generation”. in: pro-\\nceedings of the 2017 conference on empirical methods in natural\\nlanguage processing. copenhagen, denmark. 2157–2169.\\nli, l., h. he, and j. d. williams. 2014. “temporal supervised learning\\nfor inferring a dialog policy from example conversations”. in: pro-\\nceedings of the 2014 ieee spoken language technology workshop\\n(slt). 312–317.\\nli, l., j. d. williams, and s. balakrishnan. 2009. “reinforcement\\nlearning for spoken dialog management using least-squares pol-\\nicy iteration and fast feature selection”. in: proceedings of the\\n10th annual conference of the international speech communication\\nassociation (interspeech). 2475–2478.\\nli, x., y. -n. chen, l. li, j. gao, and a. celikyilmaz. 2017d. “end-to-\\nend task-completion neural dialogue systems”. in: proceedings\\nof the 8th international joint conference on natural language\\nprocessing (ijcnlp). 733–743.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 149\\nli, x., y. -n. chen, l. li, j. gao, and a. celikyilmaz. 2017e. “investiga-\\ntion of language understanding impact for reinforcement learning\\nbased dialogue systems”. corr abs/1703.07055.\\nli,x.,l.li,j.gao,x.he,j.chen,l.deng,andj.he.2015.“recurrent\\nreinforcement learning: a hybrid approach”. arxiv:1509.03044.\\nli, x., z. c. lipton, b. dhingra, l. li, j. gao, and y. -n. chen.\\n2016d. “a user simulator for task-completion dialogues”. corr\\nabs/1612.05688.\\nli,x.,s.panda,j.liu,andj.gao.2018.“microsoftdialoguechallenge:\\nbuilding end-to-end task-completion dialogue systems”. arxiv\\npreprint arxiv:1807.11125 .\\nli, y. 2018. “deep reinforcement learning”. arxiv 1810.06339.\\nliang, c., j. berant, q. le, k. d. forbus, and n. lao. 2016. “neural\\nsymbolic machines: learning semantic parsers on freebase with weak\\nsupervision”. arxiv preprint arxiv:1611.00020.\\nlin, c.-y. 2004. “rouge: a package for automatic evaluation of\\nsummaries”. in: acl workshop. 74–81.\\nlin, l.-j. 1992. “self-improving reactive agents based on reinforce-\\nment learning, planning and teaching”. machine learning . 8(3–4):\\n293–321.\\nlipton, z. c., j. gao, l. li, x. li, f. ahmed, and l. deng. 2018. “bbq-\\nnetworks: eﬃcient exploration in deep reinforcement learning for\\ntask-oriented dialogue systems”. in: aaai. 5237–5244.\\nlita, l. v., m. rogati, and a. lavie. 2005. “blanc: learning evalua-\\ntion metrics for mt”. in: proceedings of the conference on human\\nlanguage technology and empirical methods in natural language\\nprocessing .hlt ’05. vancouver, british columbia, canada. 740–\\n747.\\nlitman, d. j. and j. f. allen. 1987. “a plan recognition model for\\nsubdialogues in conversations”. cognitive science. 11(163–200).\\nliu, b. and i. lane. 2016. “attention-based recurrent neural network\\nmodels for joint intent detection and slot filling”. in: proceed-\\nings of the 17th annual conference of the international speech\\ncommunication association (interspeech). 685–689.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '150 references\\nliu, b. and i. lane. 2017. “iterative policy learning in end-to-end\\ntrainable task-oriented neural dialog models”. in: proceedings of\\nthe 2017 ieee automatic speech recognition and understanding\\nworkshop (asru). 482–489.\\nliu, b. and i. lane. 2018. “adversarial learning of task-oriented\\nneural dialog models”. in: proceedings of the 19th annual sigdial\\nmeeting on discourse and dialogue (sigdial). 350–359.\\nliu, b., g. tür, d. hakkani-tür, p. shah, and l. p. heck. 2018a. “dia-\\nlogue learning with human teaching and feedback in end-to-end\\ntrainable task-oriented dialogue systems”. in: proceedings of the\\n2018 conference of the north american chapter of the associa-\\ntion for computational linguistics: human language technologies\\n(naacl-hlt) . 2060–2069.\\nliu, c.-w., r. lowe, i. serban, m. noseworthy, l. charlin, and j.\\npineau. 2016. “how not to evaluate your dialogue system: an\\nempirical study of unsupervised evaluation metrics for dialogue\\nresponse generation”. in: emnlp. 2122–2132.\\nliu, h., y. feng, y. mao, d. zhou, j. peng, and q. liu. 2018b. “action-\\ndepedent control variates for policy optimization via stein’s iden-\\ntity”.in: proceedings of the 6th international conference on learning\\nrepresentations (iclr).\\nliu, q., l. li, z. tang, and d. zhou. 2018c. “breaking the curse of\\nhorizon: inﬁnite-horizon oﬀ-policy estimation”. in: advances in\\nneural information processing systems 31 (nips-18) . 5361–5371.\\nliu, r., w. wei, w. mao, and m. chikina. 2017. “phase conductor\\non multi-layered attentions for machine comprehension”. arxiv\\npreprint arxiv:1710.10504 .\\nliu, x., y. shen, k. duh, and j. gao. 2018d. “stochastic answer\\nnetworks for machine reading comprehension”. in: acl. 1694–1704.\\nlowe, r., m. noseworthy, i. v. serban, n. angelard-gontier, y. bengio,\\nand j. pineau. 2017. “towards an automatic turing test: learning\\nto evaluate dialogue responses”. in: acl. 1116–1126.\\nlowe, r., n. pow, i. serban, and j. pineau. 2015. “the ubuntu dialogue\\ncorpus: a large dataset for research in unstructured multi-turn\\ndialogue systems”. in: sigdial. 285–294.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 151\\nlu, z. and h. li. 2014. “a deep architecture for matching short texts”.\\nin:advances in neural information processing systems 27. curran\\nassociates, inc. 1368–1375.\\nluan, y., c. brockett, b. dolan, j. gao, and m. galley. 2017. “multi-\\ntask learning for speaker-role adaptation in neural conversation\\nmodels”. in: ijcnlp. 605–614.\\nluong, t., h. pham, and c. d. manning. 2015. “eﬀective approaches\\nto attention-based neural machine translation”. in: proceedings\\nof the 2015 conference on empirical methods in natural language\\nprocessing . lisbon, portugal. 1412–1421.\\nmadotto, a., c. -s. wu, and p. fung. 2018. “mem2seq: eﬀectively\\nincorporating knowledge bases into end-to-end task-oriented\\ndialog systems”. in: proceedings of the 56th annual meeting of the\\nassociation for computational linguistics (acl). 1468–1478.\\nmairesse, f. and s. young. 2014. “stochastic language generation in di-\\nalogue using factored language models”. computational linguistics .\\n40(4): 763–799.\\nmanning, c., m. surdeanu, j. bauer, j. finkel, s. bethard, and d. mc-\\nclosky. 2014. “the stanford corenlp natural language processing\\ntoolkit”. in: proceedings of 52nd annual meeting of the association\\nfor computational linguistics: system demonstrations. 55–60.\\nmao, j., w. xu, y. yang, j. wang, z. huang, and a. yuille. 2015. “deep\\ncaptioning with multimodal recurrent neural networks (m-rnn)”.\\nin:iclr.\\nmccann, b., j. bradbury, c. xiong, and r. socher. 2017. “learned in\\ntranslation: contextualized word vectors”. in: advances in neural\\ninformation processing systems. 6297–6308.\\nmccann, b., n. s. keskar, c. xiong, and r. socher. 2018. “the natural\\nlanguage decathlon: multitask learning as question answering”.\\narxiv preprint arxiv:1806.08730.\\nmctear, m. f. 2002. “spoken dialogue technology: enabling the con-\\nversational user interface”. acm computing surveys . 34(1): 90–\\n169.\\nmei, h., m. bansal, and m. r. walter. 2017. “coherent dialogue with\\nattention-based language models”. in: aaai. 3252–3258.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '152 references\\nmelamud, o., j. goldberger, and i. dagan. 2016. “context2vec: learning\\ngeneric context embedding with bidirectional lstm”. in: proceed-\\nings of the 20th signll conference on computational natural\\nlanguage learning . 51–61.\\nmesnil, g., y. dauphin, k. yao, y. bengio, l. deng, d. z. hakkani-\\ntür, x. he, l. p. heck, g. tür, d. yu, and g. zweig. 2015. “using\\nrecurrent neural networks for slot filling in spoken language\\nunderstanding”. ieee/acm transactions on audio, speech & lan-\\nguage processing. 23(3): 530–539.\\nmesnil, g., x. he, l. deng, and y. bengio. 2013. “investigation of\\nrecurrent-neural-network architectures and learning methods for\\nspoken language understanding”. in: proceedings of the 14th an-\\nnual conference of the international speech communication associ-\\nation (interspeech). 3771–3775.\\nmikolov, t., i. sutskever, k. chen, g. s. corrado, and j. dean. 2013.\\n“distributed representations of words and phrases and their compo-\\nsitionality”. in: advances in neural information processing systems .\\n3111–3119.\\nminsky, m. and s. papert. 1969. perceptrons: an introduction to com-\\nputational geometry . mit press.\\nmitchell, t. 1997. machine learning. new york: mcgraw-hill.\\nmnih, v., adrià, p. badia, m. mirza, a. graves, t. p. lillicrap, t.\\nharley, d. silver, and k. kavukcuoglu. 2016. “asynchronous meth-\\nods for deep reinforcement learning”. in: proceedings of the 33rd\\ninternational conference on machine learning (icml). 1928–1937.\\nmnih, v., k. kavukcuoglu, d. silver, a. a. rusu, j. veness, m. g. belle-\\nmare, a. graves, m. riedmiller, a. k. fidjeland, g. ostrovski, s.\\npetersen, c. beattie, a. sadik, i. antonoglou, h. king, d. kumaran,\\nd. wierstra, s. legg, and d. hassabis. 2015. “human-level control\\nthrough deep reinforcement learning”. nature. 518: 529–533.\\nmorgenstern, l. and c. l. ortiz. 2015. “the winograd schema chal-\\nlenge: evaluating progress in commonsense reasoning”. in: proceed-\\nings of the twenty-ninth aaai conference on artiﬁcial intelligence .\\naaai’15. austin, texas. 4024–4025.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 153\\nmostafazadeh, n., c. brockett, b. dolan, m. galley, j. gao, g. sp-\\nithourakis, and l. vanderwende. 2017. “image-grounded conver-\\nsations: multimodal context for natural question and response\\ngeneration”. in: ijcnlp. 462–472.\\nmou, l., z. lu, h. li, and z. jin. 2016. “coupling distributed and\\nsymbolic execution for natural language queries”. arxiv preprint\\narxiv:1612.02741.\\nmrkšić, n., d. ó. séaghdha, b. thomson, m. gašić, p. -h. su, d.\\nvandyke, t. -h. wen, and s. j. young. 2015. “multi-domain dialog\\nstate tracking using recurrent neural networks”. in: proceedings\\nof the 53rd annual meeting of the association for computational\\nlinguistics and the 7th international joint conference on natural\\nlanguage processing of the asian federation of natural language\\nprocessing (acl). 794–799.\\nmrkšić, n., d. ó. séaghdha, t. -h. wen, b. thomson, and s. j. young.\\n2017. “neural belief tracker: data-driven dialogue state tracking”.\\nin:proceedings of the 55th annual meeting of the association for\\ncomputational linguistics (acl). 1777–1788.\\nmunos, r. and c. szepesvári. 2008. “finite-time bounds for sampling-\\nbased fitted value iteration”. journal of machine learning re-\\nsearch. 9: 815–857.\\nnarasimhan, k., t. d. kulkarni, and r. barzilay. 2015. “language\\nunderstanding for text-based games using deep reinforcement\\nlearning”. in: proceedings of the 2015 conference on empirical\\nmethods in natural language processing (emnlp). 1–11.\\nneelakantan, a., b. roth, and a. mccallum. 2015. “compositional\\nvector space models for knowledge base completion”. arxiv preprint\\narxiv:1504.06662.\\nnguyen, d. q. 2017. “an overview of embedding models of entities\\nand relationships for knowledge base completion”. arxiv preprint\\narxiv:1703.08098.\\nnguyen, t., m. rosenberg, x. song, j. gao, s. tiwary, r. majumder,\\nand l. deng. 2016. “ms marco: a human generated machine\\nreading comprehension dataset”. arxiv preprint arxiv:1611.09268.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '154 references\\noch, f. j. 2003. “minimum error rate training in statistical machine\\ntranslation”. in: proceedings of the 41st annual meeting of the\\nassociation for computational linguistics. sapporo, japan. 160–\\n167.\\noch, f. j. and h. ney. 2003. “a systematic comparison of various\\nstatistical alignment models”. computational linguistics. 29(1):\\n19–51.\\noch, f. j. and h. ney. 2004. “the alignment template approach to\\nstatistical machine translation”. comput. linguist. 30(4): 417–449.\\noh, a. h. and a. i. rudnicky. 2002. “stochastic natural language gen-\\neration for spoken dialog systems”. computer speech & language.\\n16(3–4): 387–407.\\nosband, i., c. blundell, a. pritzel, and b. v. roy. 2016. “deep explo-\\nration via bootstrapped dqn”. in: advances in neural information\\nprocessing systems 29 (nips-16). 4026–4034.\\nosband, i. and b. v. roy. 2017. “why is posterior sampling better\\nthan optimism for reinforcement learning?” in: proceedings of\\nthe 34th international conference on machine learning (icml).\\n2701–2710.\\npado, s., d. cer, m. galley, d. jurafsky, and c. d. manning. 2009.\\n“measuring machine translation quality as semantic equivalence:\\na metric based on entailment features”. machine translation :\\n181–193.\\npaek, t. 2001. “empirical methods for evaluating dialog systems”. in:\\nproceedings of the 2nd annual meeting of the special interest group\\non discourse and dialogue (sigdial) . 1–9.\\npaek, t. and r. pieraccini. 2008. “automating spoken dialogue man-\\nagement design using machine learning: an industry perspective”.\\nspeech communication . 50(8–9): 716–729.\\npapangelis, a., m. kotti, and y. stylianou. 2018a. “towards scalable\\ninformation-seeking multi-domain dialogue”. in: proceedings of\\nthe 2018 ieee international conference on acoustics, speech and\\nsignal processing (icassp). 6064–6068.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 155\\npapangelis, a., p. papadakos, y. stylianou, and y. tzitzikas. 2018b.\\n“spoken dialogue for information navigation”. in: proceedings of the\\n19th annual sigdial meeting on discourse and dialogue (sigdial).\\n229–234.\\npapineni, k., s. roukos, t. ward, and w. -j. zhu. 2002. “bleu: a\\nmethod for automatic evaluation of machine translation”. in: acl.\\n311–318.\\nparr, r. and s. j. russell. 1998. “reinforcement learning with hierar-\\nchies of machines”. in: advances of neural information processing\\nsystems 10 (nips). 1043–1049.\\npasupat, p. and p. liang. 2015. “compositional semantic parsing on\\nsemi-structured tables”. arxiv preprint arxiv:1508.00305.\\npeng, b., x. li, j. gao, j. liu, and k. -f. wong. 2018. “integrat-\\ning planning for task-completion dialogue policy learning”. corr\\nabs/1801.06176.\\npeng, b., x. li, l. li, j. gao, a. celikyilmaz, s. lee, and k. -f. wong.\\n2017. “composite task-completion dialogue policy learning via\\nhierarchical deep reinforcement learning”. in: emnlp. 2231–2240.\\npennington,j.,r.socher,andc.manning.2014.“glove:globalvectors\\nfor word representation”. in: proceedings of the 2014 conference on\\nempirical methods in natural language processing (emnlp) . 1532–\\n1543.\\npeters, j., s. vijayakumar, and s. schaal. 2005. “natural actor-critic”.\\nin:proceedings of the 16th european conference on machine learn-\\ning (ecml). 280–291.\\npeters,m. e., m.neumann, m.iyyer, m. gardner,c.clark, k. lee, and\\nl. zettlemoyer. 2018. “deep contextualized word representations”.\\narxiv preprint arxiv:1802.05365.\\npietquin, o. and t. dutoit. 2006. “a probabilistic framework for dialog\\nsimulation and optimal strategy learning”. ieee transactions on\\naudio, speech & language processing . 14(2): 589–599.\\npietquin, o., m. geist, s. chandramohan, and h. frezza-buet. 2011.\\n“sample-eﬃcient batch reinforcement learning for dialogue man-\\nagement optimization”. acm transactions on speech and language\\nprocessing . 7(3): 7:1–7:21.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '156 references\\npietquin, o. and h. hastie. 2013. “a survey on metrics for the eval-\\nuation of user simulations”. the knowledge engineering review .\\n28(1): 59–73.\\nprecup, d., r. s. sutton, and s. p. singh. 2000. “eligibility traces for\\noﬀ-policy policy evaluation”. in: proceedings of the 17th interna-\\ntional conference on machine learning (icml) . 759–766.\\nprzybocki, m., k. peterson, s. bronsart, and g. sanders. 2009. “the\\nnist 2008 metrics for machine translation challenge—overview,\\nmethodology, metrics, and results”. machine translation . 23(2):\\n71–103.\\nputerman, m. l. 1994. markov decision processes: discrete stochastic\\ndynamic programming. new york: wiley-interscience.\\nrajpurkar, p., r. jia, and p. liang. 2018. “know what you don’t\\nknow: unanswerable questions for squad”. arxiv 1806.03822 .\\nrajpurkar, p., j. zhang, k. lopyrev, and p. liang. 2016. “squad:\\n100,000+ questions for machine comprehension of text”. arxiv\\npreprint arxiv:1606.05250 .\\nram, a., r. prasad, c. khatri, a. venkatesh, r. gabriel, q. liu, j.\\nnunn, b. hedayatnia, m. cheng, a. nagar, e. king, k. bland, a.\\nwartick, y. pan, h. song, s. jayadevan, g. hwang, and a. pettigrue.\\n2018. “conversational ai: the science behind the alexa prize”.\\ncorr. abs/1801.03604.\\nramshaw, l. a. and m. marcus. 1995. “text chunking using transfor-\\nmation based learning”. in: third workshop on very large corpora\\n(vlc at acl). 82–94.\\nranzato, m., s. chopra, m. auli, and w. zaremba. 2015. “sequence\\nlevel training with recurrent neural networks”. arxiv 1511.06732 .\\nravuri, s. v. and a. stolcke. 2015. “recurrent neural network and\\nlstm models for lexical utterance classiﬁcation”. in: proceed-\\nings of the 16th annual conference of the international speech\\ncommunication association (interspeech). 135–139.\\nravuri, s. v. and a. stolcke. 2016. “a comparative study of recurrent\\nneural network models for lexical domain classiﬁcation”. in: pro-\\nceedings of the 2016 ieee international conference on acoustics,\\nspeech and signal processing (icassp) . 6075–6079.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 157\\nreddy, s., d. chen, and c. d. manning. 2018. “coqa: a conversational\\nquestion answering challenge”. arxiv preprint arxiv:1808.07042.\\nren, g., x. ni, m. malik, and q. ke. 2018a. “conversational query\\nunderstanding using sequence to sequence modeling”. in: proceed-\\nings of the 2018 world wide web conference on world wide web.\\ninternational world wide web conferences steering committee.\\n1715–1724.\\nren, l., k. xie, l. chen, and k. yu. 2018b. “towards universal\\ndialogue state tracking”. in: proceedings of the 2018 conference\\non empirical methods in natural language processing (emnlp).\\n2780–2786.\\nrich, c., c. l. sidner, and n. lesh. 2001. “collagen: applying\\ncollaborative discourse theory to human-computer interaction”.\\nai magazine . 22(4): 15–25.\\nrichardson, m., c. j. burges, and e. renshaw. 2013. “mctest: a\\nchallenge dataset for the open-domain machine comprehension of\\ntext”. in: proceedings of the 2013 conference on empirical methods\\nin natural language processing . 193–203.\\nrichardson, s. d., w. b. dolan, and l. vanderwende. 1998. “mind-\\nnet: acquiring and structuring semantic information from text”.\\nin:proceedings of the 36th annual meeting of the association for\\ncomputational linguistics and 17th international conference on\\ncomputational linguistics-volume 2 . 1098–1102.\\nrieser,v.ando.lemon.2008.“learningeﬀectivemultimodaldialogue\\nstrategies from wizard-of-oz data: bootstrapping and evaluation”.\\nin:proceedings of the 46th annual meeting of the association for\\ncomputational linguistics (acl). 638–646.\\nrieser, v. and o. lemon. 2010. “natural language generation as plan-\\nning under uncertainty for spoken dialogue systems”. in: empirical\\nmethods in natural language generation: data-oriented methods\\nand empirical evaluation. vol. 5790. lecture notes in computer\\nscience. springer. 105–120.\\nrieser, v. and o. lemon. 2011. “learning and evaluation of dialogue\\nstrategies for new applications: empirical methods for optimiza-\\ntion from small data sets”. computational linguistics . 37(1): 153–\\n196.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '158 references\\nrieser, v., o. lemon, and x. liu. 2010. “optimising information\\npresentation for spoken dialogue systems”. in: proceedings of the\\nforty-eighth annual meeting of the association for computational\\nlinguistics (acl-10). 1009–1018.\\nritter, a., c. cherry, and w. dolan. 2011. “data-driven response\\ngeneration in social media”. in: emnlp. 583–593.\\nroemmele, m., c. bejan, and a. s. gordon. 2011. “choice of plausible\\nalternatives: an evaluation of commonsense causal reasoning”.\\nin:aaai spring symposium - technical report .\\nrosenblatt, f. 1957. “the perceptron: a perceiving and recognizing\\nautomaton”. reportno. 85-460-1. ithaca, new york: project para,\\ncornell aeronautical laboratory.\\nrosenblatt, f. 1962. principles of neurodynamics. new york: spartan\\nbooks.\\nross, s., g. j. gordon, and d. bagnell. 2011. “a reduction of imitation\\nlearning and structured prediction to no-regret online learning”.\\nin:proceedings of the 14th international conference on artiﬁcial\\nintelligence and statistics (aistats) . 627–635.\\nroy, n., j. pineau, and s. thrun. 2000. “spoken dialogue management\\nusing probabilistic reasoning”. in: proceedings of the 38th annual\\nmeeting of the association for computational linguistics (acl).\\n93–100.\\nrusso, d. j., b. van roy, a. kazerouni, i. osband, and z. wen. 2018.\\n“a tutorial on thompson sampling”. foundations and trends in\\nmachine learning. 11(1): 1–96.\\nsaha, a., v. pahuja, m. m. khapra, k. sankaranarayanan, and s.\\nchandar. 2018. “complex sequential question answering: towards\\nlearning to converse over linked question answer pairs with a\\nknowledge graph”. arxiv preprint arxiv:1801.10314.\\nsalimans, t., i. j. goodfellow, w. zaremba, v. cheung, a. radford,\\nand x. chen. 2016. “improved techniques for training gans”.\\ncorr. abs/1606.03498.\\nsarikaya, r., g. e. hinton, and a. deoras. 2014. “application of deep\\nbelief networks for natural language understanding”. ieee/acm\\ntransactions on audio, speech & language processing . 22(4): 778–\\n784.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 159\\nschapire, r. e. and y. singer. 2000. “boostexter: a boosting-based\\nsystem for text categorization”. machine learning. 39(2/3): 135–\\n168.\\nschatzmann, j., k. georgila, and s. young. 2005a. “quantitative evalu-\\nation of user simulation techniques for spoken dialogue systems”.\\nin:proceedings of the 6th sigdial workshop on discourse and dia-\\nlogue. 45–54.\\nschatzmann, j., m. n. stuttle, k. weilhammer, and s. young. 2005b.\\n“eﬀects of the user model on simulation-based learning of dialogue\\nstrategies”. in: proceedings of the ieee workshop on automatic\\nspeech recognition and understanding (asru) . 220–225.\\nschatzmann, j., k. weilhammer, m. stuttle, and s. young. 2006. “a\\nsurvey of statistical user simulation techniques for reinforcement-\\nlearning of dialogue management strategies”. the knowledge en-\\ngineering review. 21(2): 97–126.\\nschatzmann, j. and s. young. 2009. “the hidden agenda user simula-\\ntion model”. ieee transactions on audio, speech, and language\\nprocessing . 17(4): 733–747.\\nschulman, j., s. levine, p. abbeel, m. i. jordan, and p. moritz. 2015a.\\n“trust region policy optimization”. in: proceedings of the thirty-\\nsecond international conference on machine learning (icml) .\\n1889–1897.\\nschulman, j., p. moritz, s. levine, m. jordan, and p. abbeel. 2015b.\\n“high-dimensionalcontinuouscontrolusinggeneralizedadvantage\\nestimation”. arxiv:1506.02438.\\nsee, a., p. j. liu, and c. d. manning. 2017. “get to the point:\\nsummarization with pointer-generator networks”. arxiv preprint\\narxiv:1704.04368.\\nseo, m., a. kembhavi, a. farhadi, and h. hajishirzi. 2016. “bidirec-\\ntional attention ﬂow for machine comprehension”. arxiv preprint\\narxiv:1611.01603.\\nserban, i. v., r. lowe, l. charlin, and j. pineau. 2015. “a survey\\nof available corpora for building data-driven dialogue systems”.\\narxiv preprint arxiv:1512.05742.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '160 references\\nserban, i. v., r. lowe, p. henderson, l. charlin, and j. pineau. 2018.\\n“a survey of available corpora for building data-driven dialogue\\nsystems: the journal version”. dialogue & discourse. 9(1): 1–49.\\nserban, i. v., a. sordoni, y. bengio, a. c. courville, and j. pineau.\\n2016. “building end-to-end dialogue systems using generative\\nhierarchical neural network models”. in: aaai. 3776–3783.\\nserban, i. v., a. sordoni, r. lowe, l. charlin, j. pineau, a. courville,\\nand y. bengio. 2017. “a hierarchical latent variable encoder-decoder\\nmodel for generating dialogues”. in: aaai. 3295–3301.\\nshah, p., d. z. hakkani-tür, b. liu, and g. tür. 2018. “bootstrapping a\\nneuralconversationalagentwithdialogueself-play,crowdsourcing\\nand on-line reinforcement learning”. in: proceedings of the 2018\\nconference of the north american chapter of the association for\\ncomputational linguistics: human language technologies (naacl-\\nhtl). 41–51.\\nshang, l., z. lu, and h. li. 2015. “neural responding machine for\\nshort-text conversation”. in: acl-ijcnlp . 1577–1586.\\nshao, c. c., t. liu, y. lai, y. tseng, and s. tsai. 2018. “drcd: a\\nchinese machine reading comprehension dataset”. arxiv preprint\\narxiv:1806.00920.\\nshao, y., s. gouws, d. britz, a. goldie, b. strope, and r. kurzweil.\\n2017. “generating high-quality and informative conversation re-\\nsponses with sequence-to-sequence models”. in: emnlp. 2210–\\n2219.\\nshen, y., j. chen, p. huang, y. guo, and j. gao. 2018. “m-walk:\\nlearning to walk in graph with monte carlo tree search”. corr.\\nabs/1802.04394.\\nshen, y., x. he, j. gao, l. deng, and g. mesnil. 2014. “a latent\\nsemantic model with convolutional-pooling structure for information\\nretrieval”. in: proceedings of the 23rd acm international conference\\non conference on information and knowledge management . acm.\\n101–110.\\nshen, y., p. huang, m. chang, and j. gao. 2016. “implicit reasonet:\\nmodeling large-scale structured relationships with shared mem-\\nory”.corr. abs/1611.04642.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 161\\nshen, y., p. -s. huang, m. -w. chang, and j. gao. 2017a. “travers-\\ning knowledge graph in vector space without symbolic space\\nguidance”. arxiv preprint arxiv:1611.04642.\\nshen, y., p. -s. huang, j. gao, and w. chen. 2017b. “reasonet: learn-\\ning to stop reading in machine comprehension”. in: proceedings of\\nthe 23rd acm sigkdd international conference on knowledge\\ndiscovery and data mining. acm. 1047–1055.\\nshen, y., x. liu, k. duh, and j. gao. 2017c. “an empirical analysis\\nof multiple-turn reasoning strategies in reading comprehension\\ntasks”.arxiv preprint arxiv:1711.03230.\\nshum, h., x. he, and d. li. 2018. “from eliza to xiaoice: challenges\\nand opportunities with social chatbots”. corr. abs/1801.01957.\\nsingh,s.p.,d.litman,m.j.kearns,andm.walker.2002.“optimizing\\ndialogue management with reinforcement learning: experiments\\nwith the njfun system”. journal of artiﬁcial intelligence research .\\n16: 105–133.\\nsocher, r., d. chen, c. d. manning, and a. ng. 2013. “reasoning\\nwith neural tensor networks for knowledge base completion”. in:\\nadvances in neural information processing systems . 926–934.\\nsordoni, a., p. bachman, a. trischler, and y. bengio. 2016. “iterative\\nalternating neural attention for machine reading”. arxiv preprint\\narxiv:1606.02245.\\nsordoni, a., y. bengio, h. vahabi, c. lioma, j. grue simonsen, and\\nj.-y. nie. 2015a. “a hierarchical recurrent encoder-decoder for\\ngenerative context-aware query suggestion”. in: proceedings of\\nthe 24th acm international on conference on information and\\nknowledge management. cikm ’15. melbourne, australia: acm.\\n553–562.\\nsordoni, a., m. galley, m. auli, c. brockett, y. ji, m. mitchell, j. -y.\\nnie, j. gao, and b. dolan. 2015b. “a neural network approach\\nto context-sensitive generation of conversational responses”. in:\\nnaacl-hlt. 196–205.\\nstanojević, m. and k. sima’an. 2014. “fitting sentence level trans-\\nlation evaluation with many dense features”. in: proceedings of\\nthe 2014 conference on empirical methods in natural language\\nprocessing (emnlp) . doha, qatar. 202–206.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '162 references\\nstent, a., r. prasad, and m. a. walker. 2004. “trainable sentence\\nplanning for complex information presentations in spoken dia-\\nlog systems”. in: proceedings of the 42nd annual meeting of the\\nassociation for computational linguistics (acl). 79–86.\\nstone, m., c. doran, b. l. webber, t. bleam, and m. palmer. 2003.\\n“microplanning with communicative intentions: the spud system”.\\ncomputational intelligence . 19(4): 311–381.\\nstrehl, a. l., l. li, and m. l. littman. 2009. “reinforcement learning\\nin finite mdps: pac analysis”. journal of machine learning\\nresearch. 10: 2413–2444.\\nstrub, f., h. de vries, j. mary, b. piot, a. c. courville, and o.\\npietquin. 2017. “end-to-end optimization of goal-driven and vi-\\nsually grounded dialogue systems”. in: proceedings of the 26th\\ninternational joint conference on artiﬁcial intelligence (ijcai) .\\n2765–2771.\\nsu, p.-h., m. gasic, n. mrksic, l. m. rojas-barahona, s. ultes, d.\\nvandyke, t. -h. wen, and s. j. young. 2016a. “on-line active re-\\nward learning for policy optimisation in spoken dialogue systems”.\\nin:proceedings of the 54th annual meeting of the association for\\ncomputational linguistics (acl). vol. 1. 2431–2441.\\nsu, p.-h., m. gašić, n. mrkšić, l. rojas-barahona, s. ultes, d. vandyke,\\nt.-h. wen, and s. young. 2016b. “continuously learning neural\\ndialogue management”. arxiv preprint: 1606.02689.\\nsu, p.-h., m. gašić, and s. young. 2018a. “reward estimation for\\ndialogue policy optimisation”. computer speech & language. 51:\\n24–43.\\nsu, p.-h., d. vandyke, m. gašić, d. kim, n. mrkšić, t. -h. wen, and\\ns. young. 2015. “learning from real users: rating dialogue success\\nwith neural networks for reinforcement learning in spoken dia-\\nlogue systems”. in: proceedings of the 16th annual conference of the\\ninternational speech communication association (interspeech).\\n2007–2011.\\nsu, s.-y., x. li, j. gao, j. liu, and y. -n. chen. 2018b. “discriminative\\ndeep dyna-q: robust planning for dialogue policy learning”. in:\\nproceedings of the 2018 conference on empirical methods in natural\\nlanguage processing (emnlp). 3813–3823.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 163\\nsu, s.-y., k.-l. lo, y. t. yeh, and y. -n. chen. 2018c. “natural lan-\\nguage generation by hierarchical decoding with linguistic pat-\\nterns”. in: proceedings of the 2018 conference of the north american\\nchapter of the association for computational linguistics: human\\nlanguage technologies (naacl-hlt). 61–66.\\nsuchanek, f. m., g. kasneci, and g. weikum. 2007. “yago: a core\\nof semantic knowledge”. in: proceedings of the 16th international\\nconference on world wide web. acm. 697–706.\\nsuhr, a., s. iyer, and y. artzi. 2018. “learning to map context-\\ndependent sentences to executable formal queries”. arxiv preprint\\narxiv:1804.06868.\\nsutskever, i., o. vinyals, and q. le. 2014. “sequence to sequence\\nlearning with neural networks”. in: nips. 3104–3112.\\nsutton, r. s. 1990. “integrated architectures for learning, planning,\\nand reacting based on approximating dynamic programming”. in:\\nproceedings of the seventh international conference on machine\\nlearning. 216–224.\\nsutton, r. s. 1988. “learning to predict by the methods of temporal\\ndiﬀerences”. machine learning. 3(1): 9–44.\\nsutton, r. s. and a. g. barto. 2018. reinforcement learning: an\\nintroduction . 2nd edition. mit press.\\nsutton, r. s., d. mcallester, s. p. singh, and y. mansour. 1999a.\\n“policy gradient methods for reinforcement learning with function\\napproximation”. in: advances in neural information processing\\nsystems 12 (nips). 1057–1063.\\nsutton, r. s., d. precup, and s. p. singh. 1999b. “between mdps\\nand semi-mdps: a framework for temporal abstraction in rein-\\nforcement learning”. artiﬁcial intelligence. 112(1–2): 181–211. an\\nearlier version appeared as technical report 98-74, department\\nof computer science, university of massachusetts, amherst, ma\\n01003. april, 1998.\\nszegedy, c., w. zaremba, i. sutskever, j. bruna, d. erhan, i. j. goodfel-\\nlow, and r. fergus. 2013. “intriguing properties of neural networks”.\\ncorr. abs/1312.6199.\\nszepesvári, c. 2010. algorithms for reinforcement learning . morgan &\\nclaypool.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '164 references\\ntalmor, a. and j. berant. 2018. “the web as a knowledge-base for\\nanswering complex questions”. arxiv preprint arxiv:1803.06643.\\ntang, d., x. li, j. gao, c. wang, l. li, and t. jebara. 2018. “subgoal\\ndiscovery for hierarchical dialogue policy learning”. in: proceedings\\nof the 2018 conference on empirical methods in natural language\\nprocessing (emnlp) . 2298–2309.\\ntesauro, g. 1995. “temporal diﬀerence learning and td-gammon”.\\ncommunications of the acm . 38(3): 58–68.\\nthomas, p. s. and e. brunskill. 2016. “data-eﬃcient oﬀ-policy policy\\nevaluation for reinforcement learning”. in: proceedings of the 33rd\\ninternational conference on machine learning (icml). 2139–2148.\\nthompson, w. r. 1933. “on the likelihood that one unknown proba-\\nbility exceeds another in view of the evidence of two samples”.\\nbiometrika. 25(3–4): 285–294.\\ntiedemann, j. 2012. “parallel data, tools and interfaces in opus”.\\nin:proceedings of the eight international conference on language\\nresources and evaluation (lrec’12) . istanbul, turkey: european\\nlanguage resources association (elra). 2214–2218.\\ntoutanova, k., v. lin, w. -t. yih, h. poon, and c. quirk. 2016. “com-\\npositional learning of embeddings for relation paths in knowledge\\nbase and text”. in: proceedings of the 54th annual meeting of the\\nassociation for computational linguistics (volume 1: long papers).\\nvol. 1. 1434–1444.\\ntraum, d. r. 1999. “speech acts for dialogue agents”. in: foundations\\nof rational agency . springer. 169–201.\\ntrischler, a., t. wang, x. yuan, j. harris, a. sordoni, p. bachman, and\\nk. suleman. 2016. “newsqa: a machine comprehension dataset”.\\narxiv preprint arxiv:1611.09830.\\ntromp, j. and g. farnebäck. 2006. “combinatorics of go”. in: pro-\\nceedings of the fifth international conference on computers and\\ngames.lecture notes in computer science . no. 4630. 84–99.\\ntur, g. and r. de mori. 2011. spoken language understanding: systems\\nfor extracting semantic information from speech . john wiley & sons.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 165\\nultes, s., p. budzianowski, i. casanueva, n. mrkšić, l. m. rojas-\\nbarahona, p.-h. su, t.-h. wen, m. gašić, and s. j. young. 2017a.\\n“domain-independent user satisfaction reward estimation for di-\\nalogue policy learning”. in: proceedings of the 18th annual con-\\nference of the international speech communication association\\n(interspeech). 1721–1725.\\nultes, s., p. budzianowski, i. casanueva, n. mrkšić, l. m. rojas-\\nbarahona, p. -h. su, t. -h. wen, m. gašić, and s. j. young. 2017b.\\n“reward-balancing for statistical spoken dialogue systems using\\nmulti-objective reinforcement learning”. in: proceedings of the 18th\\nannual sigdial meeting on discourse and dialogue (sigdial). 65–\\n70.\\nultes, s., l. m. rojas-barahona, p. -h. su, d. vandyke, d. kim, i.\\ncasanueva, p. budzianowski, n. mrkšić, t. -h. wen, m. gašić, and\\ns. j. young. 2017c. “pydial: a multi-domain statistical dialogue\\nsystem toolkit”. in: proceedings of the fifty-ﬁfth annual meeting\\nof the association for computational linguistics (acl), system\\ndemonstrations. 73–78.\\nvan den oord, a., s. dieleman, h. zen, k. simonyan, o. vinyals, a.\\ngraves, n. kalchbrenner, a. senior, and k. kavukcuoglu. 2016.\\n“wavenet: a generative model for raw audio”. arxiv:1609.03499.\\nvan hasselt, h., a. guez, and d. silver. 2016. “deep reinforcement\\nlearning with double q-learning”. in: proceedings of the thirtieth\\naaai conference on artiﬁcial intelligence (aaai-16) . 2094–2100.\\nvaswani, a., n. shazeer, n. parmar, j. uszkoreit, l. jones, a. n.\\ngomez, l. kaiser, and i. polosukhin. 2017. “attention is all you\\nneed”. in: advances in neural information processing systems 30 .\\ncurran associates, inc. 5998–6008.\\nvinyals, o., m. fortunato, and n. jaitly. 2015a. “pointer networks”.\\nin:advances in neural information processing systems 28. curran\\nassociates, inc. 2692–2700.\\nvinyals, o. and q. le. 2015. “a neural conversational model”. in:\\nicml deep learning workshop.\\nvinyals, o., a. toshev, s. bengio, and d. erhan. 2015b. “show and\\ntell: a neural image caption generator”. in: proceedings of the ieee\\nconference on computer vision and pattern recognition . 3156–3164.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '166 references\\nvries, h. de, f. strub, s. chandar, o. pietquin, h. larochelle, and a. c.\\ncourville. 2017. “guesswhat?! visual object discovery through\\nmulti-modaldialogue”.in: proceedings of the 2017 ieee conference\\non computer vision and pattern recognition (cvpr) . 4466–4475.\\nwalker, m. a. 2000. “an application of reinforcement learning to\\ndialogue strategy selection in a spoken dialogue system for email”.\\njournal of artiﬁcial intelligence research . 12: 387–416.\\nwalker, m. a., d. j. litman, c. a. kamm, and a. abella. 1997.\\n“paradise: a framework for evaluating spoken dialogue agents”.\\nin:proceedings of the 35th annual meeting of the association for\\ncomputational linguistics (acl). 271–280.\\nwalker, m. a., d. j. litman, c. a. kamm, and a. abella. 1998.\\n“evaluating spoken dialogue agents with paradise: two case\\nstudies”. computer speech & language. 12(4): 317–347.\\nwalker, m. a., a. stent, f. mairesse, and r. prasad. 2007. “individual\\nand domain adaptation in sentence planning for dialogue”. journal\\nof artiﬁcial intelligence research. 30: 413–456.\\nwalker, m., c. kamm, and d. litman. 2000. “towards developing\\ngeneral models of usability with paradise”. natural language\\nengineering. 6(3–4): 363–377.\\nwang, c., y. wang, p. -s. huang, a. mohamed, d. zhou, and l. deng.\\n2017a. “sequence modeling via segmentations”. in: proceedings of\\nthe 34th international conference on machine learning. 3674–3683.\\nwang, w., n. yang, f. wei, b. chang, and m. zhou. 2017b. “gated\\nself-matching networks for reading comprehension and question\\nanswering”. in: proceedings of the 55th annual meeting of the as-\\nsociation for computational linguistics (volume 1: long papers).\\nvol. 1. 189–198.\\nwang, y. -y., l. deng, and a. acero. 2005. “spoken language un-\\nderstanding: an introduction to the statistical framework”. ieee\\nsignal processing magazine . 22(5): 16–31.\\nwang, z., h. chen, g. wang, h. tian, h. wu, and h. wang. 2014.\\n“policylearningfordomainselectioninanextensiblemulti-domain\\nspoken dialogue system”. in: proceedings of the 2014 conference\\non empirical methods in natural language processing (emnlp).\\n57–67.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 167\\nwang, z., t. schaul, m. hessel, h. van hasselt, m. lanctot, and n.\\nde freitas. 2016. “dueling network architectures for deep rein-\\nforcement learning”. in: proceedings of the third international\\nconference on machine learning (icml-16). 1995–2003.\\nwatkins, c. j. 1989. “learning from delayed rewards”. phd thesis.\\nuk: king’s college, university of cambridge.\\nwei, w., q. v. le, a. m. dai, and l. -j. li. 2018. “airdialogue: an\\nenvironment for goal-oriented dialogue research”. in: proceedings\\nof the 2018 conference on empirical methods in natural language\\nprocessing (emnlp) . 3844–3854.\\nweissenborn, d., g. wiese, and l. seiﬀe. 2017. “fastqa: a simple and\\neﬃcient neural architecture for question answering”. arxiv preprint\\narxiv:1703.04816.\\nweizenbaum, j. 1966. “eliza: a computer program for the study\\nof natural language communication between man and machine”.\\ncommun. acm. 9(1): 36–45.\\nwelbl, j., p. stenetorp, and s. riedel. 2017. “constructing datasets\\nfor multi-hop reading comprehension across documents”. arxiv\\npreprint arxiv:1710.06481 .\\nwen, t.-h., m. gašić, n. mrkšić, l. m. rojas-barahona, p. -h. su, d.\\nvandyke, and s. j. young. 2016. “multi-domain neural network\\nlanguage generation for spoken dialogue systems”. in: proceedings\\nof the 2016 conference of the north american chapter of the associ-\\nation for computational linguistics: human language technologies\\n(hlt-naacl) . 120–129.\\nwen, t.-h., m. gašić, n. mrkšić, p. -h. su, d. vandyke, and s. j.\\nyoung. 2015. “semantically conditioned lstm-based natural lan-\\nguage generation for spoken dialogue systems”. in: proceedings\\nof the 2015 conference on empirical methods in natural language\\nprocessing (emnlp) . 1711–1721.\\nwen, t.-h., d. vandyke, n. mrkšić, m. gašić, l. m. rojas-barahona,\\np.-h. su, s. ultes, and s. j. young. 2017. “a network-based end-to-\\nend trainable task-oriented dialogue system”. in: proceedings of\\nthe 15th conference of the european chapter of the association for\\ncomputational linguistics (eacl). arxiv reprint arxiv:1604.04562.\\n438–449.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '168 references\\nwiering, m. and m. van otterlo. 2012. reinforcement learning: state\\nof the art . springer.\\nwilliams, j. d. 2006. “partially observable markov decision processes\\nfor spoken dialogue management”. phd thesis . cambridge, uk:\\ncambridge university.\\nwilliams, j. d. 2008. “evaluating user simulations with the cramér-von\\nmises divergence”. speech communication . 50(10): 829–846.\\nwilliams, j. d., k. asadi, and g. zweig. 2017. “hybrid code networks:\\npractical and eﬃcient end-to-end dialog control with supervised\\nand reinforcement learning”. in: proceedings of the 55th annual\\nmeeting of the association for computational linguistics (acl).\\nvol. 1. 665–677.\\nwilliams, j. d., m. henderson, a. raux, b. thomson, a. w. black,\\nand d. ramachandran. 2014. “the dialog state tracking challenge\\nseries”.ai magazine . 35(4): 121–124.\\nwilliams, j. d., a. raux, d. ramachandran, and a. w. black. 2013.\\n“the dialog state tracking challenge”. in: proceedings of the 14th\\nannual meeting of the special interest group on discourse and\\ndialogue (sigdial). 404–413.\\nwilliams, j. d. and s. j. young. 2007. “partially observable markov\\ndecision processes for spoken dialog systems”. computer speech\\nand language. 21(2): 393–422.\\nwilliams, j. d. and g. zweig. 2016. “end-to-end lstm-based dialog\\ncontrol optimized with supervised and reinforcement learning”.\\nwilliams, r. j. 1992. “simple statistical gradient-following algorithms\\nfor connectionist reinforcement learning”. machine learning. 8:\\n229–256.\\nwinata, g. i., o. kampman, y. yang, a. dey, and p. fung. 2017. “nora\\nthe empathetic psychologist”. in: proc. interspeech. 3437–3438.\\nwu, c.-s., a. madotto, g. i. winata, and p. fung. 2018. “end-to-end\\ndynamic query memory network for entity-value independent\\ntask-oriented dialog”. in: proceedings of the 2018 ieee inter-\\nnational conference on acoustics, speech and signal processing\\n(icassp). 6154–6158.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 169\\nwu, j., m. li, and c. -h. lee. 2015. “a probabilistic framework for\\nrepresenting dialog systems and entropy-based dialog management\\nthrough dynamic stochastic state evolution”. ieee/acm transac-\\ntions on audio, speech and language processing (taslp) . 23(11):\\n2026–2035.\\nwu,q.,c.j.burges,k.m.svore,andj.gao.2010.“adaptingboosting\\nfor information retrieval measures”. information retrieval . 13(3):\\n254–270.\\nwu, y., m. schuster, z. chen, q. v. le, m. norouzi, w. macherey,\\nm. krikun, y. cao, q. gao, k. macherey, j. klingner, a. shah,\\nm. johnson, x. liu, l. kaiser, s. gouws, y. kato, t. kudo, h.\\nkazawa, k. stevens, g. kurian, n. patil, w. wang, c. young, j.\\nsmith, j. riesa, a. rudnick, o. vinyals, g. corrado, m. hughes,\\nand j. dean. 2016. “google’s neural machine translation system:\\nbridging the gap between human and machine translation”. corr.\\nabs/1609.08144.\\nxing, c., w. wu, y. wu, m. zhou, y. huang, and w. ma. 2018.\\n“hierarchicalrecurrentattentionnetworkforresponsegeneration”.\\nin:aaai. 5610–5617.\\nxiong, c., v. zhong, and r. socher. 2016. “dynamic coattention net-\\nworks for question answering”. arxiv preprint arxiv:1611.01604.\\nxiong, w., t. hoang, and w. y. wang. 2017. “deeppath: a rein-\\nforcement learning method for knowledge graph reasoning”. arxiv\\npreprint arxiv:1707.06690 .\\nxu, p., a. madotto, c. -s. wu, j. h. park, and p. fung. 2018. “emo2vec:\\nlearning generalized emotion representation by multi-task train-\\ning”.arxiv preprint arxiv:1809.04505.\\nxu, z., b. liu, b. wang, c. sun, x. wang, z. wang, and c. qi.\\n2017. “neural response generation via gan with an approximate\\nembedding layer”. in: emnlp. 617–626.\\nyaman, s., l. deng, d. yu, y. -y. wang, and a. acero. 2008. “an\\nintegrative and discriminative technique for spoken utterance\\nclassiﬁcation”. ieee transactions on audio, speech & language\\nprocessing . 16(6): 1207–1214.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '170 references\\nyan, r., y. song, and h. wu. 2016. “learning to respond with deep\\nneural networks for retrieval-based human-computer conversa-\\ntion system”. in: proceedings of the 39th international acm sigir\\nconference on research and development in information retrieval .\\nsigir. pisa, italy: acm. 55–64.\\nyang, b., w. -t. yih, x. he, j. gao, and l. deng. 2015. “embedding\\nentities and relations for learning and inference in knowledge bases”.\\nin:iclr.\\nyang, f., z. yang, and w. w. cohen. 2017a. “diﬀerentiable learning of\\nlogical rules for knowledge base completion”. corr, abs/1702.08367.\\nyang, x., y. -n. chen, d. z. hakkani-tür, p. crook, x. li, j. gao, and\\nl. deng. 2017b. “end-to-end joint learning of natural language\\nunderstanding and dialogue manager”. in: proceedings of the 2017\\nieee international conference on acoustics, speech and signal\\nprocessing (icassp) . 5690–5694.\\nyao, k., g. zweig, m. -y. hwang, y. shi, and d. yu. 2013. “recurrent\\nneural networks for language understanding”. in: proceedings of\\nthe 14th annual conference of the international speech communi-\\ncation association (interspeech). 2524–2528.\\nyao, k., g. zweig, and b. peng. 2015. “attention with intention for a\\nneural network conversation model”. in: nips workshop on ma-\\nchine learning for spoken language understanding and interaction.\\nyao, x. and b. van durme. 2014. “information extraction over struc-\\ntured data: question answering with freebase”. in: proceedings\\nof the 52nd annual meeting of the association for computational\\nlinguistics (volume 1: long papers). vol. 1. 956–966.\\nyih, w.-t., m.-w. chang, x. he, and j. gao. 2015a. “semantic pars-\\ning via staged query graph generation: question answering with\\nknowledge base”. in: acl. 1321–1331.\\nyih, w.-t., x. he, and j. gao. 2015b. “deep learning and continuous\\nrepresentations for natural language processing”. in: proceed-\\nings of the 2015 conference of the north american chapter of the\\nassociation for computational linguistics: tutorial .\\nyih, w.-t., x. he, and j. gao. 2016. “deep learning and continu-\\nous representations for natural language processing”. in: ijcai:\\ntutorial.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " 'references 171\\nyoung, s. j., m. gašić, s. keizer, f. mairesse, j. schatzmann, b. thom-\\nson, and k. yu. 2010. “the hidden information state model: a\\npractical framework for pomdp-based spoken dialogue manage-\\nment”.computer speech & language. 24(2): 150–174.\\nyoung, s., c. breslin, m. gašić, m. henderson, d. kim, m. szummer, b.\\nthomson, p.tsiakoulis, ande. t.hancock. 2016. “evaluationofsta-\\ntistical pomdp-based dialogue systems in noisy environments”.\\nin:situated dialog in speech-based human-computer interaction.\\nsignals and communication technology. springer. 3–14.\\nyoung, s., m. gašić, b. thomson, and j. d. williams. 2013. “pomdp-\\nbased statistical spoken dialog systems: a review”. proceedings of\\nthe ieee . 101(5): 1160–1179.\\nyu, a. w., d. dohan, m. -t. luong, r. zhao, k. chen, m. norouzi,\\nand q. v. le. 2018. “qanet: combining local convolution with\\nglobal self-attention for reading comprehension”. arxiv preprint\\narxiv:1804.09541.\\nzhang, j., t. zhao, and z. yu. 2018a. “multimodal hierarchical re-\\ninforcement learning policy for task-oriented visual dialog”. in:\\nproceedings of the 19th annual sigdial meeting on discourse and\\ndialogue (sigdial). 140–150.\\nzhang, r., j. guo, y. fan, y. lan, j. xu, and x. cheng. 2018b.\\n“learning to control the speciﬁcity in neural response generation”.\\nin:proceedings of the 56th annual meeting of the association for\\ncomputational linguistics (volume 1: long papers). melbourne,\\naustralia. 1108–1117.\\nzhang, s., e. dinan, j. urbanek, a. szlam, d. kiela, and j. weston.\\n2018c.“personalizingdialogueagents:ihaveadog,doyouhavepets\\ntoo?” in: proceedings of the 56th annual meeting of the association\\nfor computational linguistics (volume 1: long papers) . melbourne,\\naustralia. 2204–2213.\\nzhang, s., x. liu, j. liu, j. gao, k. duh, and b. van durme. 2018d.\\n“record: bridging the gap between human and machine common-\\nsense reading comprehension”. arxiv preprint arxiv:1810.12885.\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " '172 references\\nzhang, y., m. galley, j. gao, z. gan, x. li, c. brockett, and b.\\ndolan. 2018e. “generating informative and diverse conversational\\nresponses via adversarial information maximization”. in: neurips.\\n1815–1825.\\nzhao, t. and m. eskénazi. 2016. “towards end-to-end learning for\\ndialog state tracking and management using deep reinforcement\\nlearning”. in: proceedings of the 17th annual meeting of the special\\ninterest group on discourse and dialogue (sigdial) . 1–10.\\nzhao, t., a. lu, k. lee, and m. eskenazi. 2017. “generative encoder-\\ndecoder models for task-oriented spoken dialog systems with\\nchatting capability”. in: acl. 27–36.\\nzhou, l., j. gao, d. li, and h. -y. shum. 2018. “the design and\\nimplementation of xiaoice, an empathetic social chatbot”. arxiv\\npreprint arxiv:1812.08989 .\\nfull text available at: http://dx.doi.org/10.1561/1500000074',\n",
       " \"brain intelligence: go beyond artificial intelligence \\nhuimin lu1,*, yujie li2, min chen3, hyoungseop kim1, seiichi serikawa1 \\n \\n1kyushu institute of technology, japan \\n2yangzhou university, china \\n3huazhong university of science and technology, china \\nluhuimin@ieee.org  \\nabstract \\nartificial intelligence (ai) is an important technology that su pports daily social life and economic \\nactivities. it contributes greatly to the sustainable growth of  japan's economy and solves various social \\nproblems. in recent years, ai has attracted attention as a key for growth in developed countries such \\nas europe and the united states and developing countries such a s china and india. the attention has \\nbeen focused mainly on developing new artificial intelligence i nformation communication technology \\n(ict) and robot technology (rt). although recently developed ai  technology certainly excels in \\nextracting certain patterns, there are many limitations. most i ct models are overly dependent on big \\ndata, lack a self-idea function, and are complicated. in this p aper, rather than merely developing next-\\ngeneration artificial intelligence technology, we aim to develo p a new concept of general-purpose \\nintelligence cognition technolog y called “beyond ai”. specifica lly, we plan to develop an intelligent \\nlearning model called “brain intelligence (bi)” that generates new ideas about even ts without having \\nexperienced them by using artificial life with an imagine funct ion. we will also conduct \\ndemonstrations of the developed bi intelligence learning model on automatic driving, precision \\nmedical care, and industrial robots. \\nkeywords:  brain intelligence; artificial intelligence; artificial life \\n \\n1. introduction \\nfrom siri [1] to alphago [2], artificial intelligence (ai) is d eveloping rapidly. while science \\nfiction often portrays ai as rob ots with human-like characteris tics, ai can encompass anything from \\ne-commerce prediction algorithms  to ibm’s watson machines [3]. however, artificial intelligence \\ntoday is properly known as weak ai, which is designed to perfor m a special task (e.g., only facial \\nrecognition or only internet sear ches or only driving a car). w hile weak ai may outperform humans \\nat a specific task, such as playing chess or solving equations,  general ai would outperform humans at \\nnearly every cognitive task.  \\nin recent years, the us governmen t has supported basic research  on ai, which is centered on robots \\nand pattern recognition (voice, images, etc.). microsoft has an nounced real-time tran slation robots and \\ninnovative image recognition technologies [4]. amazon uses arti ficial intelligence for autonomous \",\n",
       " 'robots in delivery systems [5]. facebook has also developed fac ial recognition technology based on \\nartificial intelligence called “deepface” [6]. robots and artif icial intelligence are being actively \\nstudied in university institutions in the united states. innova tive technologies, such as corporate \\ncooperation and deep learning, are emerging. the robot car deve loped by the artificial intelligence \\nlaboratory at stanford university  has set a faster time than an  active racer [7]. the computer science \\nand artificial intelligence laboratory at massachusetts institu te of technology has developed a \\ncleaning robot and a four-foot walking robot [8]. \\nmeanwhile, ai is the main technology expected to improve japane se ict’s innovation and robot \\ntechnology in the near future. ict in japan has rapidly advance d in recent years. to secure japan’s \\nstatus as a world-class “technological superpower”, the japanes e government has formulated projects \\nsuch as the “science an d technology basic plan [9]” and the “ar tificial intelligence technology \\nconference [10]”. japan is expecting to utilize state-of-the-ar t artificial intelligence and robots to solve \\nvarious problems. \\nhowever, through some research, we found that recent artificial  intelligence technologies have \\nmany limitations. in the following, we list some representative  limitations and analyze the reasons \\nwhy recent ai cannot break through  these inherent disadvantages . \\n \\nlimitations of artificial intelligence \\nin recent years, artificial intel ligence technologies have deve loped dramatically due to improvement \\nin the processing capacity of computers and the accumulation of  big data. however, the results of \\ncurrent artificial intelligence technologies remain limited to specific intellectual areas, such as image \\nrecognition, speech recognition, and dialogue response. that is , current ai is a specialized type of \\nartificial intelligence acting intellectually in a so-called in dividual area (see figure 1). examples \\ninclude techniques such as convolutional neural networks (cnn) or deep residual learning \\n(resnet) for visual recognition, recurrent neural networks (rnn ) or deep neural networks (dnn) \\nfor speech recognition, and represent learning (rl) for dialogu e understanding. all of these are a \\npart of the intellectual work carried out by each area of the h uman brain; they are only a substitute and \\ndo not perform all of the functions of the human brain. in othe r  w o r d s ,  a i  h a s  n o t  b e e n  a b l e  t o  \\ncooperate with whole-brain functions such as self-understanding , self-control, self-consciousness and \\nself-motivation. specifically, we conclude that the limitations  of the recent artificial intelligence \\ntechnologies are the following: \\n(1) frame problem  \\nconsidering all the events that can occur in the real world, si nce it takes a large amount of time due \\nto big data training, ai is typically limited to a single frame  or type of problem. for example, if you \\nrestrict the algorithm to apply only to chess, shogi, image rec ognition, or speech recognition, only \\ncertain results can be expected. however, when trying to cope w ith every phenomenon in the real ',\n",
       " 'world, there is an infinite number of possibilities that we hav e to anticipate, so the extraction time \\nbecomes infinite due to overloading of the database. \\n \\nfigure 1. shortages of current artificial intelligence. \\n \\n(2) association function problem  \\nmachine learning and artificial intelligence are excellent at e xtracting a particular pattern. however, \\nthe results of machine learning are easy to misuse. current art ificial intelligence technology depends \\non large-scale data and can obtain results using only numerical  values, but it does not have the \\nassociation function like the human brain. that is, a single pa rt of the brain cannot  be as intelligent as \\nthe whole brain. \\n(3) symbol grounding problem  \\nit is necessary to link symbols with their meanings, but this t ask is often not resolved in current \\nartificial intelligence. for exa mple, if you know the individua l meaning of the word “horse” and the \\nmeaning of the word “stripes”, then when you are taught that “z e b r a  =  h o r s e  +  s t r i p e s ” ,  y o u  c a n  \\nunderstand that “a zebra is a horse with stripes”. however, the  computer cannot make the same \\nconnections between ideas. \\n(4) mental and physical problem  \\nwhat is the relationship between the mind and body? that is, if  the mind is generally thought of as \\nnon-material, how can the physical body be affected by it? whet her or not this is possible has not been \\nelucidated. \\n',\n",
       " '  in conclusion, we can see that there are many problems unsolv ed in current artificial intelligence. \\nin this paper, we first review the most recent algorithms for w eak ai. then, we introduce the next-\\ngeneration intelligence architecture, brain intelligence, which  is an advanced artificial intelligence for \\nsolving the disadvantages of weak ai algorithms. \\n2. artificial i ntelligence \\nthe market and business for ai technologies is changing rapidly . in addition to speculation and \\nincreased media attention, many start-up companies and internet  giants are racing to acquire ai \\ntechnologies in business investment. narrative science survey f ound that 38% of enterprises have \\nbeen using ai in 2016, and the number will increase to 62% in 2 018. forrester research expects ai \\ninvestment in 2017 to grow by more than 300% compared with 2016 . idc estimates that the ai market \\nwill grow from $ 8 billion in 2016 to $ 47 billion in 2020 [11] . \\ncurrent artificial intelligence includes a variety of technolog ies and tools, some time-tested and \\nothers that are relatively new. to help understand what is hot and what is not, forrester has just released \\na techradar report on artificial intelligence (application deve lopers), detailing the 9 technologies for \\nwhich companies should consider using artificial intelligence t o support decisions. \\n2.1 natural language generation \\nnatural language generation (nlg) is used to generate text from  computer data using ai, especially \\ndeep learning architectures, to generate the nlg tasks. deep ne ural networks (dnn) are undoubtedly \\none of the most popular research  a r e a s  i n  t h e  c u r r e n t  n l g  f i e l d . dnn are designed to learn \\nrepresentations at increasing lay ers of abstraction by adopting  backpropagation [12], feedforwards \\n[13], log-bilinear models [14], and recurrent neural networks ( rnn) [15]. their advantage over \\ntraditional models is that dnn models represent voice sequences  of varying lengths, so similar \\nhistories have related representations. they overcome the disad vantage of traditional models, which \\nhave data sparseness and a record er for remembering the paramet ers. \\nlong short-term memory architectures (lstm) [16], which are a f urther development upon rnn, \\ncontain memory cells and multiplicative gates that control the information’s access. mei et al. [17] \\nproposed a lstm-based architecture, which uses the encoder-deco der framework, for content \\nselection and realization. luong et al. [18] showed that parsin g the datasets used for co-training in \\nencoder and decoder can improve the translation efficiency. in most of these methods, it is hard to \\nbalance between achieving adequate textual output and generatin g text efficiently and robustly. \\nltsm is currently used for customer service, report generation and summary of business \\nintelligence insight. examples of suppliers include attivio, au tomated insights, cambridge semantics, \\ndigital reasoning, lucidworks, n arrative science, sas, and yseo p. \\n2.2 speech recognition \\nhidden markov models (hmm) [19] are useful tools for speech rec ognition. in recent years, deep \\nfeedforward networks (dfn) have gained attention for solving is sues of recognition. it seems that ',\n",
       " 'hmm combines with rnn as a better solution. however, the hmm-rn n model does not perform as \\nwell as deep networks. speech recognition’s goal is to translat e human language and convert it into a \\nuseful format for computer applications. graves et al. [20] pro posed a deep long short-term memory \\nrnns for speech recognition. thi s model is an end-to-end learni ng method that jointly trains two \\nseparate rnns as acoustic and linguistic models. it is widely u sed in current interactive voice response \\nsystems and mobile applications. examples of suppliers include nice, nuance communications, \\nopentext, and verint systems. \\n2.3 virtual/augmented reality \\nvirtual reality uses simple devices and advanced systems that c an network with humans. virtual \\nreality is a computer-generated simulation of a 3d environment that can be interacted with in a \\nseemingly real manner. artificial intelligence will be used in augmented reality for future remote \\nehealth [21, 22]. it is currently  used in customer service and support and as a smart home manager \\n[23, 49-52]. sample vendors include amazon, apple, artificial s olutions, assist ai, creative virtual, \\ngoogle, ibm, ipsoft, microsoft, and satisfi. \\n2.4 ai-optimized hardware \\nbecause of the rapid growth of d ata in recent years, it is poss ible for engineers to use the massive \\namounts of data to learn patterns. most artificial intelligence  models are proposed to meet these needs. \\nthese models require a large amount of data and computing power  to train and are limited by the need \\nfor better hardware accelerati on to accommodate scaling beyond current data and model sizes. \\ngraphics processing units (gpu) [24], general purpose processor s (gpgpu) [25] and field \\nprogrammable gate arrays (fpga) [26] are required to efficientl y run ai-oriented co mputational tasks. \\ngpu has orders of magnitude more computational cores than tradi tional general purpose processors \\n(gpp) and allows a greater ability to perform parallel computat ions. in particular, gpgpu is usually \\nused. unlike gpus, fpga has a flexible hardware configuration, and provides better performance per \\nwatt than gpus. however, it is difficult to program fpga device s because of the special architecture. \\nsample vendors include alluviat e, cray, google, ibm, intel, and  nvidia. \\n2.5 decision management \\ndecision-making plays a critical role in achieving sustainable development during turbulent \\nfinancial markets. with the improvement of information communic ation technology (ict), ai-based \\ntechniques, such as decision tree (dt), support vector machine (svm), neural network (nn), and deep \\nlearning, have been used for decision making [27]. engines that  insert rules and logic into ai systems \\nare used for initial setup/training and ongoing maintenance and  tuning. a mature technology, which is \\nused in a wide variety of enterprise applications, assisting in  or performing automated decision making. \\nsample vendors include advanced systems concepts, informatica, maana, pegasystems, and uipath. \\n2.6 deep learning platforms \\ncurrently, research used in pattern recognition and classificat ion is primarily supported by very ',\n",
       " \"large data sets. few approaches look for providing a solution b etter than existing big-data processing \\nplatforms, which usually runs over a large-scale commodity cpu cluster. moreover, gpus seem to \\nthe best platforms to train ai networks [28]. however, recent p latforms are worse than the human \\nbrain in processing perception and require large amounts of spa ce and energy. to this end, rajat et al. \\n[29] trained a dbn model with 100 million parameters using an n vidia gtx280 graphics card with \\n240 cores. adam et al. [30] proposed a cots hpc deep neural net work training system. google \\ndeveloped distbelief [31], which uses thousands of cpus to trai n the deep neural network; see figure \\n2. microsoft developed project adam [32] to use fewer machines for training. other sample vendors, \\nsuch as qualcomm’s zeroth platform [33], ibm’s truenorth [34], and manchester university’s \\nspinnaker [35] are also in devel opment. besides, there are also  some software packages for deep \\nlearning. these packages include tensorflow, theano, torch/pyto rch, mxnet, caffe as well as high \\nlevel package keras. it would also be good to mention google's tpu when mentioning the hardware \\nplatforms. \\n \\nfigure 2 google distbelief a pproach for dnn training [31]. \\n \\n2.7 robotic process automation \\nrobotic process automation (rpa) [36] uses software and algorit hms to automate human action to \\n\",\n",
       " 'support efficient business processes. a software robot is used instead of humans for typing and clicking \\nand even analyzing data in different applications. rpa is curre ntly used where it is too expensive or \\ninefficient for humans to execute a task or a process. research ers are promoting the adoption of rpa \\nin the financial area. rpa has a lso been applied to trading in treasuries, affecting accounting staff \\ninvolved in the banking area. ai, as a solution for big data, p rovides a new possibility for accurate \\nprediction of rpa. sample vendors include advanced systems conc epts, automation anywhere, \\nblue prism, uipath, and workfusion. \\n2.8 text analytics and nlp \\nnatural language processing (nlp) uses and supports text analyt ics by facilitating the \\nunderstanding of sentence struct ure and meaning, sentiment, and  intent through statistical and machine \\nlearning methods. nlp is a way for computers to understand, ana lyze, and derive meaning from human \\nlanguage in a smart and useful way. we introduce the following ai methods applied to nlp. \\n  recurrent neural networks (rnn) [37] make full use of sequent ial information. as we all know, the \\ninputs and outputs of traditional neural networks are independe nt. in practice, it must predict the words \\nbefore a sentence. the so-called rnn is a recurrent network bec ause it performs the same task for \\nevery element of a sequence, with the output being dependent on  the previous computations. there \\nare many types of improved rnn models that have been proposed t o solve some of the shortcomings \\nof the original rnn model. bidirectional rnn [38] is based on t he principle that the output may not \\ndepend only on the previous elements in the sequence but also o n the future elements. deep \\nbidirectional rnn [39] is similar to bidirectional rnn but impr oved by adding multiple layers per \\ntime step. long short-term memory (lstm) [40] uses the same mec hanism to decide what to keep in \\nand what to erase from memory that is used in rnns.    recursive neural network [41] is another deep neural network created by applying the same set of \\nweights recursively over a structure in order to produce a stru ctured prediction over the input by \\nt r a n s f e r r i n g  a  g i v e n  s t r u c t u r e  i n topological order. dependency  neural network (dcnn) [53] is a \\nmethod proposed to capture long-distance dependencies. dcnn con sists of a convolutional layer built \\non top of an lstm model. dynamic k-max pooling neural network [ 54] is another type of network \\nthat uses a non-linear max pooling subsampling operator to retu rn the maximum of a set of values. \\nt h i s  n e t w o r k  o u t p u t s  k  m a x i m u m  v a l u e s  i n  t h e  s e q u e n c e  a n d  o p t i m izes select k values by other \\nfunctions. multi-column cnn [55] shares the same word embedding  and multiple columns of \\nconvolutional neural networks. ranking cnn [56] takes the relat ion classificatio n task using a \\nconvolutional neural network that performs classification by ra nking. context-dependent cnn [57] \\nconsists of two components: a convolutional sentence model that  s u m m a r i z e s  t h e  m e a n i n g  o f  t h e  \\nsource sentence and the target p hrase and a matching model that  compares the two representations \\nwith a multilayer perceptron. sample vendors include basis tech nology, coveo, expert system, \\nindico, knime, lexalytics, linguamatics, mindbreeze, sinequa, s tratifyd, and synapsify. ',\n",
       " '2.9 visual recognition \\ndeep learning has been shown to be one of the best solutions fo r computer vision. a large number \\nof methods have been developed to improve the performance of tr aditional deep-learning algorithms. \\nin general, these methods can be divided into three categories:  convolutional neural networks, \\nautoencoders, and sparse and rest ricted boltzmann machines. in this paper, we focus on searching \\nconvolutional neural network models.   the pipeline of the traditional convolutional neural network architecture consists of three main sets \\nof layers: convolutional, pooling, and fully connected layers. different layers play different roles in \\nthe classification. convolutional layers are used to convolve t he image to generate feature maps. the \\nmain advantages of convolutional  layers are that the weight-sha ring mechanism reduces the number \\nof parameters and local connectiv ity learns the relationships b etween the neighbor pixels. in addition, \\nit is invariant to the location of the objects in the image.   the pooling layers are usually u sed after the convolutional l ayers to reduce the dimensions of the \\nfeature maps and to adjust the parameters. average pooling and max pooling are used in most cases. \\nfollowing the last pooling layers, the fully connected layers a re used to convert the two-dimensional \\nfeature maps into one-dimensiona l feature vectors. several stat e-of-the-art convolutional neural \\nnetwork models are reviewed below.   convolutional neural networks (cnn) [43] are similar to tradi tional neural networks (nn). they \\nare made up of neurons that have learnable weights and biases. the main difference between cnn \\nand nn is the number of layers. cnn use several layers of convo lutions with nonlinear activation \\nfunctions applied to the results.   a l e x n e t  [ 4 2 ]  c o n t a i n s  e i g h t  l a y e r s .  t h e  f i r s t  f i v e  l a y e r s  a r e  the convolutional layers, and the \\nfollowing three layers are the fu lly connected layers. compared  to cnn [43], alexnet has advantages \\nsuch as data augmentation, dropout [44], relu, local response n ormalization, and overlapping \\npooling.   the main contribution of vggnet [45] is to increase the netwo r k  d e p t h  u s i n g  v e r y  s m a l l  \\nconvolution filters. the total number of layers in vggnet is 16 –19. however, the use of max-pooling \\nlayers results in a loss of accurate spatial information.    szegedy et al. [46] contributed to improving the use of compu ting resources inside a network. the \\ngooglenet method increases the width and depth of the network w hile keeping the computational \\nbudget constant. based on arora et al.’s research [47], the lay er-by-layer construction can analyze the \\ncorrelation statistics of the last layer and then combine them into groups. one of the main advantages \\no f  g o o g l e n e t  i s  t h a t  i t  a l l o w s  t h e  n u m b e r  o f  l a y e r s  a t  e a c h  s t a ge to be increased without an \\nuncontrolled blow-up in the computational complexity. another b enefit is that this network is 2–3 \\ntimes faster than similarly performing networks. however, it is  complex to configure the design of \\nthis network.  ',\n",
       " '  there is a trend for deeper layers to result in better networ k performance. however, with increasing \\nnetwork depth, the training accuracy becomes saturated and then  rapidly degrades. he et al. [48] solved \\nthis problem using a deep residual learning framework. addition al “shortcut connections” are added \\nto feedforward neural networks because short connections add ne ither extra parameters nor \\ncomputational complexity.  \\n3. brain intelligence (bi) \\nthere are many approaches [58-61] proposed to solve the limitat ions of recent ai. however, these \\nmodels are simply extended from the current ai models. this pap er introduces the following items for \\nexplaining the concept of bi, which is different from artificia l intelligence, but extends upon current \\nartificial intelligence. \\nthe bi intelligent learning model fuses the benefits of artific ial life (al) and ai. currently, the \\nmainstream research on deep learning is a method of learning ex pressions extracted from essential \\ninformation of observational data by a deep neural network with  a large number of layers. however, \\nresearch on multitask learning that learns multiple tasks at th e same time and transition studies that \\ndivert learning results for a certain task to other tasks is st ill insufficient. for this reason, ai models \\nbased on unsupervised learning and shallow neural networks will  become trends in future. in this paper, \\nwe will combine various regional ai methods using a particular rule, especially unsupervised learning \\nmethods. it is essential to develop a new intelligent learning model with a small database and the \\nability to understand concepts. therefore, we propose a brain i ntelligence model with memory and \\nidea function in figure 3. the bi model network combines artifi cial life technology and artificial \\nintelligence technology with memory function. ',\n",
       " ' \\nfigure 3. the concept of the bi model network. different neural  networks are connected by artificial \\nlife-based network, which can sha re the parameters, trained res ults, and structures to parents and \\nsons. \\n \\nresearch on current ai mainly focuses on individual areas such as dialogue comprehension, visual \\nrecognition, and auditory discrimination and so on. research on  whole-brain functions is still \\ninsufficient. for example, there are few studies on perceptual understanding models and self-thinking \\nmodels. therefore, in this resear ch, we will clarify the functi on and mechanisms of the whole brain \\nand make efforts to realize it as artificial intelligence. bi n etwork is consisted by many simple sub-\\nnetworks. the parameters of each sub-networks is updated by s-s ystem [62], which can modify the \\nsub-networks by reproduction, selection, and mutation.  \\ndifferent from neuroevolution of augmenting topologies (neat) [ 63, 64], the proposed bi mode \\nnetwork does not just use the neural network structure and para meter optimization mechanism, it \\nimproves the structure of current ai models using s-system. hyp erneat [65], a type of a-life based \\nnn, which uses the compositional pattern producing network (cpp n) for pattern generation and uses \\nneat for parameters optimization. hyperneat cannot overcome the  drawbacks of the neat network. \\nother gene-based models, such as gene regulatory network (grn) [66] and evolving reaction \\nnetwork (ern) [67], are also stu died by some researchers. these  methods are inspired by biological \\ncharacteristics, which do not ta ke into account the usage of al l the brain’s function. cognitive \\ncomputing (cc) [68] is proposed a new model from the view of hu man cognitive functions. the bi \\nmodel network is investigated from an engineering point of view , in the future, we will develop a \\n',\n",
       " 'super-intelligent brain function model that intends to discover  problems itself and autonomously \\nenhance its abilities.  \\n4. conclusion \\nin this paper, we have presented state-of-the-art artificial in telligence tools for individual application \\nareas, such as natural language processing and visual recogniti on. the main contributions of this work \\nare as follows. first, this is an overview of current deep lear ning methods. we have summarized the \\nnine potential applications in detail. second, this paper puts together all the problems of recent ai \\nmodels, which will direct future  work for researchers. third, i n this paper, we first proposed the brain \\nintelligence model, which is a model fusing artificial intellig ence and artificial life. al models, such \\nas the s-system, have the benefits of an association function, which is different from generative \\nadversarial networks (gan), for building big data within a life  evolution process. it is foreseeable that \\nthe bi model can solve the issues of the frame problem, the ass ociation function problem, the symbol \\ngrounding problem, and the mental/physical problem.  \\nacknowledgements \\nthis work was supported by leading initiative for excellent you ng researcher (leader) of \\nministry of education, culture, sports, science and technology- japan (16809746), grants-in-aid for \\nscientific research of jsps (17k 14694), research fund of chines e academy of sciences \\n(no.mge2015kg02), research fund of  s t a t e  k e y  l a b o r a t o r y  o f  m a r i ne geology in tongji \\nuniversity (mgk1608), research fund of state key laboratory of ocean engineering in shanghai \\njiaotong university (1510), research fund of the telecommunicat ions advancement foundation, \\nand fundamental research develop ing association for shipbuildin g and offshore. \\n \\nreferences \\n[1] siri, https://en.wikipedia.org/wiki/siri  (accessed on 2017/4/20). \\n[2] alphago, https://deepmind.com/research/alphago/  (accessed on 2017/4/20). \\n[3] ibm watson, https://www.ibm.com/watson/  (accessed on 2017/4/20). \\n[4] microsoft translator speech api, https://www.microsoft.com/en-us/translator/speech.aspx  \\n(accessed on 2017/4/20). \\n[5] amazon prime air, https://www.amazon.com/amazon-prime-air/b?node=8037720011  (accessed \\non 2017/4/20). \\n[6] y . taigman, m. yang, m. ranzato, l. wolf, “deepface: closin g the gap to human-level \\nperformance in face verification,” ieee international conferenc e on computer vision and pattern \\nrecognition (cvpr2014), pp.1-8, 2014. [7] stanford artificial intelligence laboratory, http://ai.stanford.edu/  (accessed on 2017/4/20). ',\n",
       " '[8] mit bigdog, https://slice.mit.edu/big-dog/  (accessed on 2017/4/20). \\n[9] the 4th science and technology  basic plan of japan, http://www8.cao.go.jp/cstp/english/basic/  \\n(accessed on 2017/4/20). \\n[10] ai expo, http://www.ai-expo.jp/en/  (accessed on 2017/4/20). \\n[ 1 1 ] 2 0 1 7  w i l l  b e  t h e  y e a r  o f  a i ,  http://fortune.com/2016/12/30/the-year-of-artificial-intelligen ce/ \\n(accessed on 2017/4/20). \\n[12]y . lecun, y . bengio, g. hint on, “deep learning,” nature, vo l.521, no.7553, pp.436-444, 2015. \\n[13]y . bengio, r. ducharme, p. vincent, c. janvin, “a neural pr obabilistic language model,” journal \\nof machine learning research, vol.3, pp.1137-1155, 2003. [14]a. mnih, g. hinton, “three ne w graphical models for statist ical language modelling,” in proc of \\nicml07, pp.641-648, 2007. [15]t. mikolov, m. karafiat, l. burget, j. cernocky, s. khudanp ur, “recurrent neural network based \\nlanguage model,” in proc of interspeech10, pp.1045-1048, 2010. [16]i. sutskever, o. vinyals, q. le, “sequence to sequence lear ning with neural networks,” in \\nadvances in neural information processing systems, pp.3104-3112 , 2014. \\n[17]h. mei, m. bansal, m. walter, “what to talk about and how? selective generation using lstms \\nwith coarse-to-fine alignment,” in naacl-hlt, pp.1-11, 2016. [18]m. luong, q. le, i . sutskever, o. vinyals, l. kaiser, “mult itask sequence to sequence learning,” \\nin proc iclr, pp .1-10, 2016. \\n[19]h. bourlard, m. morgan, “connnectionist speech recognition:  a hybrid approach,” kluwer \\nacademic publishers, 1994. [20]a. graves, a. mohamed, g. hinton, “speech recognition with deep recurrent neural networks,” \\nin icassp2013, p p.1-5, 2013. \\n[21]b. wiederhold, g. riva, m. wiederhold, “virtual reality in healthcare: medical simulation and \\nexperiential interface,” annual review of cyber therapy and tel emedicine, vol.13, 239 pages, 2015. \\n[22]g. bartsch, a. mitra, s. mitra, a. almal, k. steven, d. ski nner, d. fry, p. lenehan, w. worzel, \\nr. cote, “use of artificial intelligence and machine learning a lgorithms with gene expression profiling \\nto predict recurrent nonmuscle invasive urothelial carcinoma of  the bladder,” the journal of urology, \\nvol.195, pp.493-498, 2016. [23]n. labonnote, k. hoyland, “smart home technologies that sup port independent living: challenges \\nand opportunities for the building industry – a systematic mapp ing study,” intelligent buildings \\ninternational, vol.29, no.1, pp.40-63, 2017. [24]s. chetlur, c. woolley, p. vandermersch, j. cohen, j. tran,  b. catanzaro, e. shelhamer, “cudnn: \\nefficient primitives for deep learning,” pp.1-10, arxiv:1410.07 59, 2014. \\n[25] a. coates, b. huval, t. wang, d. wu, b. catanzaro, n. andr ew, “deep learning with cots hpc \\nsystems,” in proc of the 30\\nth international conference on mach ine learning, pp.1337-1345, 20 13. ',\n",
       " '[26] g. lacey , g. t aylor , s. areibi, “deep learning on fpgas: p ast, present, and future,” pp.1-8, \\narxiv: 1602.04283, 2016. [27]w. lin, s. lin, t. yang, “integrated business prestige and artificial intelligence for corporate \\ndecision making in dynamic environments,” cybernetics and syste ms, doi: \\n10.1080/01969722.2017.1284533, pp.1-22, 2017. [28]a. ratnaparkhi, e. pilli, r. joshi, “survey of scaling plat forms for deep neural networks,” in proc \\nof international conference on emerging trends in communication  technologies, pp.1-6, 2016. \\n[29]r. raina, a. madhavan, a. ng, “large-scale deep unsupervise d learning using graphics \\nprocessors,” in proc of 26\\nth annual international conference on machine learning, pp.873-88 0, 2009. \\n[30]b. catanzaro, “deep learning with cots hpc systems,” in pro c of the 30th international \\nconference on machine learning, pp.1337-1345, 2013. [31]j. dean, g. corrado, r. monga, k. chen, m. devin, q. le, m.  mao, m. ranzato, a. senior, p. \\ntucker, k. yang, a. ng, “large scale distributed deep networks, ” in proc of advances in neural \\ninformation processing systems, pp.1223-1231, 2012. [32]t. chilimbi, y . suzue, j. apacible, k. kalyanaraman, “proje ct adam: building an efficient and \\nscalable deep learning training system,” in proc of 11\\nth usenix symposium on operating systems \\ndesign and implementation, pp.571-582, 2014. [33]qualcomm zeroth, https://www.qualcomm.com/invention/cognitive-technologies/zerot h \\n(accessed on 2017/4/27). \\n[34]p. merolla, j. arthur, r. alvarez-lcaza, a. cassidy, j. saw ada, f. akopyan, b. jackson, n. imam, \\nc. guo, y . nakamura, b. brezzo, i. v o, s. esser, r. appuswamy, b. taba, a. amir, m. flickner, w. \\nrisk, r. manohar, d. modha, “a million spiking-neuron integrate d circuit with a scalable \\ncommunication network and interface,” science, vol.345, no.6197 , pp.668-673, 2014. \\n[35]m. khan, d. lester, l. plana, a. rast, x. jin, e. painkras,  s. furber, “spiinnaker: mapping \\nneural networks onto a massively -parallel chip multiprocessor,”  in proc of ieee international joint \\nconference on neural networks, pp.2849-2856, 2008. [36]m. lacity, l. willcocks, “a new approach to automating serv ices,” mit sloan management \\nreview, vol.2016, pp.1-16, 2016. [37]t mikolov, m. karafiat, l. burget, j. cernocky, s. khudanpu r, “recurrent neural network based \\nlanguage model,” in proc of interspeech2010, pp.1045-1048, 2010 . \\n[38]m. schuster, k. paliwal, “bidirectional recurrent neural ne tworks,” ieee transactions on signal \\nprocessing, vol.45, no.11, pp.2673-2681, 1997. [39]a. graves, n. jaitly, a. mohamed, “hybrid speech recognitio n with deep bidirectional lstm,” \\nin proc of ieee workshop on automatic speech recognition and un derstanding, pp.1-4, 2013. \\n[40]a. graves, j. schmidhuber, “framewise phoneme classificatio n with bidirectional lstm and \\nother neural network architecutres,” neural networks, vol.18, n o.5-6, pp.602-610, 2005. ',\n",
       " '[41]a. mishra, v . desai, “drought forecasting using feed-forwar d recursive neural network,” \\necological modelling, vol.198, no.1-2, pp.127-138, 2006. [42]a. karpathy, g. toderici, s. shetty, t. leung, r. sukthanka r, and f. li, “large-scale video \\nclassification with convolutional neural networks,” in proc of ieee conference on computer vision \\nand pattern recognition, pp.1725-1732, 2014. [43]y . lecun, b. boser, j. denker, d. henderson, r. howard, w. hubbard, and l. jackel, \\n“backpropagation applied to handwritten zip code recognition,” neural computation, vol.1, no.4, \\npp.541-551, 1989. [44] r. bell, and y . koren, “lessons from the netflix prize cha llenge,” acm sigkdd explorations \\nnewsletter, vol.9, no.2, pp.75-79, 2007. [45]k. simonyan, and a. zisserman , “very deep convolutional net works for large-scale image \\nrecognition,” in proc of ieee iclr2015, pp.1-14, 2015. [ 4 6 ] c .  s z e g e d y ,  w .  l i u ,  y .  j i a ,  p .  s e r m a n e t ,  s .  r e e d ,  d .  a n g u e l ov, d. erhan, v . vanhoucke, a. \\nrabinovich, “going deeper with c onvolutions,” in proc of ieee c onference on computer vision and \\npattern recognition, pp.1-12, 2015. [47]s. arora, a. bhaskara, r. ge, and t. ma, “provable bounds f or learning some deep \\nrepresentations,” arxiv:abs/1310.6343, 2013. [48]k. he, x. zhang, s. ren, j. sun, “deep residual learning fo r image recognition,” in proc. of ieee \\nconference on computer vision and pattern recognition, pp.1-12,  2016. \\n[49]m. chen, y . ma, y . li, d. wu, y . zhang, “wearable 2.0: enab ling human-cloud integration in \\nnext generation healthcare systems,” ieee communications magazi ne, vol. 54, no. 12, pp. 3-9, \\n2017. [50] j. song, y . zhang, “tola: topic- oriented learning assistance ba sed on cyber-physical system \\nand big data,” future generation computer systems, doi:10.1016/ j.future.2016.05.040, 2016. \\n[51]y . zhang, “grorec: a group-centric intelligent recommender system integrating social, mobile and \\nbig data technologies,” ieee transactions on services computing , vol. 9, no. 5, pp . 786-795, 2016. \\n[52]q. liu, y . ma, m. alhussein, y . zhang, l. peng, “green data  center with iot sensing and cloud-\\nassisted smart temperature controlling system,” computer networ ks, v ol. 101, pp. 104-112, june 2016. \\n[53]d. chen, c. manning, “a fast and accurate dependency parser  using neural networks,” in proc of \\nempirical methods in natural language processing, pp.740-750, 2 014. \\n[54]n. kalchbrenner, e. grefenstette, p. blunsom, “a convolutio nal neural network for modelling \\nsentences,” in proc of annual meeting of the association for co mputational linguistics, pp.655-665, \\n2014. [55]d. ciresan, u. meier, j. masci, j. schmidhuber, “multi-colu mn deep neural network for traffic \\nsign classification,” neural networks, vol.32, pp.333-338, 2012 . \\n[56]c. santos, b. xiang, b. zhou, “classifying relations by ran king with convolutional neural ',\n",
       " 'networks,” in proc of annual meeting of the association for com putational linguistics, pp.626-634, \\n2015. [57]b. hu, z. tu, z. lu, q. chen, “context-dependent translatio n selection using convolutional neural \\nnetwork,” in proc of annual meeting of the association for comp utational linguistics, pp.536-541, \\n2015. [58]y . li, h. lu, j. li, x. li, y . li, s. serikawa, “underwater  image de-scattering and classification \\nby deep neural network,” computers & electrical engineering, vo l.54, pp.68-77, 2016. \\n[5 9] h .  l u,  b .  l i,  j .  z hu,  y .  l i ,  y .  l i,  x .  x u,  l .  h e ,  x .  l i,  j .  li, s. serikawa, “wound intensity \\ncorrection and segmentation with convolutional neural networks, ” concurrency and computation: \\npractice and experience, vol.29, no.6, pp.1-8, 2017. [60]h. lu, y . li, t. uemura, z. ge, x. xu, l. he, s. serikawa, h. kim, “fdcnet: filtering deep \\nconvolutional network for marine organism classification,” mult imedia tools and applications, pp.1-\\n14, 2017. [61]h. lu, y . li, l. zhang, s. serikawa, “contrast enhancement for images in turbid water,” journal \\nof the optical society of america, vol.32, no.5, pp.886-893, 20 15. \\n[62]s. serikawa, t. shimomura, “proposal of a system of functio n-discovery using a bug type of \\nartificial life,” transactions of iee japan, vol.118-c, no.2, p p.170-179, 1998. \\n[63]k. stanley, r. miikkulainen, “evolving neural networks thro ugh augmenting topologies,” \\nevolutionary computation, vol.10, no.2, pp.99-127, 2002. [64]j. schrum, r. miikkulainen, “evolving multimodal behavior w ith modular neural networks in ms. \\npac-man,” in proc of the genetic and evolutionary computation c onference, pp.325-332, 2014. \\n[65]k. stanley, d. ambrosio, j. gauci, “a hypercube-based encod ing for evolving large-scale neural \\nnetworks,” artificial life, vol.15, no.2, pp.185-212, 2009. [66]f. emmert-streib, m. dehmer, b. haibe-kains, “gene regulato ry networks and their applications: \\nunderstanding biological and medical problems in terms of netwo rks,” frontiers in cell and \\ndevelopmental biology, vol.2, no.38, pp.1-7, 2014. [67]h. dinh, m. aubert, n. noman, t. fujii, y . rondelez, h. iba , “an effective method for evolving \\nreaction networks in synthetic biochemical systems,” ieee trans actions on evolutionary \\ncomputation, vol.19, no.3, pp.374-386, 2015. [68]k. hwang, m. chen, “big-data analytics for cloud, iot and c ognitive computing,” wiley press, \\n432 pages, 2017.  ',\n",
       " 'this paper is included in the proceedings of the \\n13th usenix symposium on operating systems design \\nand implementation (osdi ’18).\\noctober 8–10, 2018 • carlsbad, ca, usa\\nisbn 978-1-939133-08-3\\nopen access to the proceedings of the \\n13th usenix symposium on operating systems \\ndesign and implementation  \\nis sponsored by usenix.ray: a distributed framework  \\nfor emerging ai applications\\nphilipp moritz, robert nishihara, stephanie wang, alexey tumanov,  \\nrichard liaw, eric liang, melih elibol, zongheng yang, william paul,  \\nmichael i. jordan, and ion stoica, uc berkeley\\nhttps://www.usenix.org/conference/osdi18/presentation/nishihara',\n",
       " 'ray: a distributed framework for emerging ai applications\\nphilipp moritz\\x03, robert nishihara\\x03, stephanie wang, alexey tumanov, richard liaw,\\neric liang, melih elibol, zongheng yang, william paul, michael i. jordan, ion stoica\\nuniversity of california, berkeley\\nabstract\\nthe next generation of ai applications will continuously\\ninteract with the environment and learn from these inter-\\nactions. these applications impose new and demanding\\nsystems requirements, both in terms of performance and\\nﬂexibility. in this paper, we consider these requirements\\nand present ray—a distributed system to address them.\\nray implements a uniﬁed interface that can express both\\ntask-parallel and actor-based computations, supported by\\na single dynamic execution engine. to meet the perfor-\\nmance requirements, ray employs a distributed scheduler\\nand a distributed and fault-tolerant store to manage the\\nsystem’s control state. in our experiments, we demon-\\nstrate scaling beyond 1.8 million tasks per second and\\nbetter performance than existing specialized systems for\\nseveral challenging reinforcement learning applications.\\n1 introduction\\nover the past two decades, many organizations have been\\ncollecting—and aiming to exploit—ever-growing quanti-\\nties of data. this has led to the development of a plethora\\nof frameworks for distributed data analysis, including\\nbatch [ 20,64,28], streaming [ 15,39,31], and graph [ 34,\\n35,24] processing systems. the success of these frame-\\nworks has made it possible for organizations to analyze\\nlarge data sets as a core part of their business or scientiﬁc\\nstrategy, and has ushered in the age of “big data. ”\\nmore recently, the scope of data-focused applications\\nhas expanded to encompass more complex artiﬁcial intel-\\nligence (ai) or machine learning (ml) techniques [ 30].\\nthe paradigm case is that of supervised learning , where\\ndata points are accompanied by labels, and where the\\nworkhorse technology for mapping data points to labels\\nis provided by deep neural networks. the complexity of\\nthese deep networks has led to another ﬂurry of frame-\\nworks that focus on the training of deep neural networks\\n\\x03equal contributionand their use in prediction. these frameworks often lever-\\nage specialized hardware (e.g., gpus and tpus), with the\\ngoal of reducing training time in a batch setting. examples\\ninclude tensorflow [7], mxnet [18], and pytorch [46].\\nthe promise of ai is, however, far broader than classi-\\ncal supervised learning. emerging ai applications must\\nincreasingly operate in dynamic environments, react to\\nchanges in the environment, and take sequences of ac-\\ntions to accomplish long-term goals [ 8,43]. they must\\naim not only to exploit the data gathered, but also to ex-\\nplore the space of possible actions. these broader require-\\nments are naturally framed within the paradigm of rein-\\nforcement learning (rl). rl deals with learning to oper-\\nate continuously within an uncertain environment based\\non delayed and limited feedback [ 56]. rl-based systems\\nhave already yielded remarkable results, such as google’s\\nalphago beating a human world champion [54], and are\\nbeginning to ﬁnd their way into dialogue systems, ua vs\\n[42], and robotic manipulation [25, 60].\\nthe central goal of an rl application is to learn a\\npolicy—a mapping from the state of the environment to a\\nchoice of action—that yields effective performance over\\ntime, e.g., winning a game or piloting a drone. finding ef-\\nfective policies in large-scale applications requires three\\nmain capabilities. first, rl methods often rely on simula-\\ntionto evaluate policies. simulations make it possible to\\nexplore many different choices of action sequences and to\\nlearn about the long-term consequences of those choices.\\nsecond, like their supervised learning counterparts, rl al-\\ngorithms need to perform distributed training to improve\\nthe policy based on data generated through simulations or\\ninteractions with the physical environment. third, poli-\\ncies are intended to provide solutions to control problems,\\nand thus it is necessary to serve the policy in interactive\\nclosed-loop and open-loop control scenarios.\\nthese characteristics drive new systems requirements:\\na system for rl must support ﬁne-grained computations\\n(e.g., rendering actions in milliseconds when interacting\\nwith the real world, and performing vast numbers of sim-\\nusenix association 13th usenix symposium on operating systems design and implementation    561\\n',\n",
       " 'ulations), must support heterogeneity both in time (e.g.,\\na simulation may take milliseconds or hours) and in re-\\nsource usage (e.g., gpus for training and cpus for simu-\\nlations), and must support dynamic execution, as results\\nof simulations or interactions with the environment can\\nchange future computations. thus, we need a dynamic\\ncomputation framework that handles millions of hetero-\\ngeneous tasks per second at millisecond-level latencies.\\nexisting frameworks that have been developed for\\nbig data workloads or for supervised learning work-\\nloads fall short of satisfying these new requirements for\\nrl. bulk-synchronous parallel systems such as map-\\nreduce [ 20], apache spark [ 64], and dryad [ 28] do not\\nsupport ﬁne-grained simulation or policy serving. task-\\nparallel systems such as ciel [ 40] and dask [ 48] provide\\nlittle support for distributed training and serving. the\\nsame is true for streaming systems such as naiad [ 39]\\nand storm [ 31]. distributed deep-learning frameworks\\nsuch as tensorflow [ 7] and mxnet [ 18] do not naturally\\nsupport simulation and serving. finally, model-serving\\nsystems such as tensorflow serving [ 6] and clipper [ 19]\\nsupport neither training nor simulation.\\nwhile in principle one could develop an end-to-end so-\\nlution by stitching together several existing systems (e.g.,\\nhorovod [ 53] for distributed training, clipper [ 19] for\\nserving, and ciel [ 40] for simulation), in practice this ap-\\nproach is untenable due to the tight coupling of these com-\\nponents within applications. as a result, researchers and\\npractitioners today build one-off systems for specialized\\nrl applications [ 58,41,54,44,49,5]. this approach im-\\nposes a massive systems engineering burden on the devel-\\nopment of distributed applications by essentially pushing\\nstandard systems challenges like scheduling, fault toler-\\nance, and data movement onto each application.\\nin this paper, we propose ray, a general-purpose\\ncluster-computing framework that enables simulation,\\ntraining, and serving for rl applications. the require-\\nments of these workloads range from lightweight and\\nstateless computations, such as for simulation, to long-\\nrunning and stateful computations, such as for training.\\nto satisfy these requirements, ray implements a uniﬁed\\ninterface that can express both task-parallel andactor-\\nbased computations. tasks enable ray to efﬁciently and\\ndynamically load balance simulations, process large in-\\nputs and state spaces (e.g., images, video), and recover\\nfrom failures. in contrast, actors enable ray to efﬁciently\\nsupport stateful computations, such as model training, and\\nexpose shared mutable state to clients, (e.g., a parameter\\nserver). ray implements the actor and the task abstrac-\\ntions on top of a single dynamic execution engine that is\\nhighly scalable and fault tolerant.\\nto meet the performance requirements, ray distributes\\ntwo components that are typically centralized in existing\\nframeworks [ 64,28,40]: (1) the task scheduler and (2) a\\nstate (si+1) (observation)reward (ri+1)action (ai)policy improvement(e.g., sgd)trajectory: s0, (s1, r1), …, (sn, rn)policytrainingservingsimulationpolicyevaluation environment\\nagent\\nfigure 1: example of an rl system.\\nmetadata store which maintains the computation lineage\\nand a directory for data objects. this allows ray to sched-\\nule millions of tasks per second with millisecond-level\\nlatencies. furthermore, ray provides lineage-based fault\\ntolerance for tasks and actors, and replication-based fault\\ntolerance for the metadata store.\\nwhile ray supports serving, training, and simulation\\nin the context of rl applications, this does not mean that\\nit should be viewed as a replacement for systems that pro-\\nvide solutions for these workloads in other contexts. in\\nparticular, ray does not aim to substitute for serving sys-\\ntems like clipper [ 19] and tensorflow serving [ 6], as\\nthese systems address a broader set of challenges in de-\\nploying models, including model management, testing,\\nand model composition. similarly, despite its ﬂexibility,\\nray is not a substitute for generic data-parallel frame-\\nworks, such as spark [ 64], as it currently lacks the rich\\nfunctionality and apis (e.g., straggler mitigation, query\\noptimization) that these frameworks provide.\\nwe make the following contributions :\\n\\x0fwe design and build the ﬁrst distributed frame-\\nwork that uniﬁes training, simulation, and serving—\\nnecessary components of emerging rl applications.\\n\\x0fto support these workloads, we unify the actor and\\ntask-parallel abstractions on top of a dynamic task\\nexecution engine.\\n\\x0fto achieve scalability and fault tolerance, we pro-\\npose a system design principle in which control state\\nis stored in a sharded metadata store and all other\\nsystem components are stateless.\\n\\x0fto achieve scalability, we propose a bottom-up dis-\\ntributed scheduling strategy.\\n2 motivation and requirements\\nwe begin by considering the basic components of an rl\\nsystem and ﬂeshing out the key requirements for ray. as\\nshown in figure 1, in an rl setting, an agent interacts\\nrepeatedly with the environment . the goal of the agent\\nis to learn a policy that maximizes a reward . apolicy is\\n562    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " '// evaluate policyby interacting with env. (e.g., simulator)rollout(policy, environment):trajectory=[]state= environment.initial_state()while(notenvironment.has_terminated()):action= policy.compute(state) // servingstate,reward= environment.step(action) // simulationtrajectory.append(state,reward)returntrajectory// improve policy iteratively until it convergestrain_policy(environment):policy= initial_policy()while(policyhas not converged):trajectories = []forifrom1 tok:// evaluate policyby generating krolloutstrajectories.append(rollout(policy, environment))// improve policypolicy= policy.update(trajectories) // trainingreturnpolicyfigure 2: typical rl pseudocode for learning a policy.\\na mapping from the state of the environment to a choice\\nofaction . the precise deﬁnitions of environment, agent,\\nstate, action, and reward are application-speciﬁc.\\nto learn a policy, an agent typically employs a two-step\\nprocess: (1) policy evaluation and (2) policy improvement .\\nto evaluate the policy, the agent interacts with the envi-\\nronment (e.g., with a simulation of the environment) to\\ngenerate trajectories , where a trajectory consists of a se-\\nquence of (state, reward) tuples produced by the current\\npolicy. then, the agent uses these trajectories to improve\\nthe policy; i.e., to update the policy in the direction of the\\ngradient that maximizes the reward. figure 2 shows an\\nexample of the pseudocode used by an agent to learn a\\npolicy. this pseudocode evaluates the policy by invok-\\ningrollout (environment ,policy ) to generate trajectories.\\ntrain policy ()then uses these trajectories to improve the\\ncurrent policy via policy .update (trajectories ). this pro-\\ncess repeats until the policy converges.\\nthus, a framework for rl applications must provide\\nefﬁcient support for training ,serving , and simulation\\n(figure 1). next, we brieﬂy describe these workloads.\\ntraining typically involves running stochastic gradient\\ndescent (sgd), often in a distributed setting, to update the\\npolicy. distributed sgd typically relies on an allreduce\\naggregation step or a parameter server [32].\\nserving uses the trained policy to render an action based\\non the current state of the environment. a serving system\\naims to minimize latency, and maximize the number of\\ndecisions per second. to scale, load is typically balanced\\nacross multiple nodes serving the policy.\\nfinally, most existing rl applications use simulations\\nto evaluate the policy—current rl algorithms are notsample-efﬁcient enough to rely solely on data obtained\\nfrom interactions with the physical world. these simula-\\ntions vary widely in complexity. they might take a few ms\\n(e.g., simulate a move in a chess game) to minutes (e.g.,\\nsimulate a realistic environment for a self-driving car).\\nin contrast with supervised learning, in which train-\\ning and serving can be handled separately by different\\nsystems, in rl all three of these workloads are tightly\\ncoupled in a single application , with stringent latency re-\\nquirements between them. currently, no framework sup-\\nports this coupling of workloads. in theory, multiple spe-\\ncialized frameworks could be stitched together to provide\\nthe overall capabilities, but in practice, the resulting data\\nmovement and latency between systems is prohibitive in\\nthe context of rl. as a result, researchers and practition-\\ners have been building their own one-off systems.\\nthis state of affairs calls for the development of new\\ndistributed frameworks for rl that can efﬁciently support\\ntraining, serving, and simulation. in particular, such a\\nframework should satisfy the following requirements:\\nfine-grained, heterogeneous computations. the dura-\\ntion of a computation can range from milliseconds (e.g.,\\ntaking an action) to hours (e.g., training a complex pol-\\nicy). additionally, training often requires heterogeneous\\nhardware (e.g., cpus, gpus, or tpus).\\nflexible computation model. rl applications require\\nboth stateless and stateful computations. stateless compu-\\ntations can be executed on any node in the system, which\\nmakes it easy to achieve load balancing and movement\\nof computation to data, if needed. thus stateless com-\\nputations are a good ﬁt for ﬁne-grained simulation and\\ndata processing, such as extracting features from images\\nor videos. in contrast stateful computations are a good ﬁt\\nfor implementing parameter servers, performing repeated\\ncomputation on gpu-backed data, or running third-party\\nsimulators that do not expose their state.\\ndynamic execution. several components of rl appli-\\ncations require dynamic execution, as the order in which\\ncomputations ﬁnish is not always known in advance (e.g.,\\nthe order in which simulations ﬁnish), and the results of a\\ncomputation can determine future computations (e.g., the\\nresults of a simulation will determine whether we need to\\nperform more simulations).\\nwe make two ﬁnal comments. first, to achieve high\\nutilization in large clusters, such a framework must handle\\nmillions of tasks per second .\\x03second, such a framework\\nis not intended for implementing deep neural networks\\nor complex simulators from scratch. instead, it should\\nenable seamless integration with existing simulators [ 13,\\n11, 59] and deep learning frameworks [7, 18, 46, 29].\\n\\x03assume 5ms single-core tasks and a cluster of 200 32-core nodes.\\nthis cluster can run (1s=5ms)\\x0232\\x02200 =1:28m tasks/sec.\\nusenix association 13th usenix symposium on operating systems design and implementation    563\\n',\n",
       " 'name description\\nfutures =f:remote (args ) execute function fremotely. f:remote ()can take objects or futures as inputs\\nand returns one or more futures. this is non-blocking.\\nobjects =ray:get(futures ) return the values associated with one or more futures. this is blocking.\\nready futures =ray:wait (futures ;k;timeout )return the futures whose corresponding tasks have completed as soon as either\\nkhave completed or the timeout expires.\\nactor =class :remote (args ) instantiate class class as a remote actor, and return a handle to it. call a method\\nfutures =actor :method :remote (args ) on the remote actor and return one or more futures. both are non-blocking.\\ntable 1: ray api\\n3 programming and computation model\\nray implements a dynamic task graph computation\\nmodel, i.e., it models an application as a graph of depen-\\ndent tasks that evolves during execution. on top of this\\nmodel, ray provides both an actor and a task-parallel\\nprogramming abstraction. this uniﬁcation differentiates\\nray from related systems like ciel, which only pro-\\nvides a task-parallel abstraction, and from orleans [ 14] or\\nakka [1], which primarily provide an actor abstraction.\\n3.1 programming model\\ntasks. atask represents the execution of a remote func-\\ntion on a stateless worker. when a remote function is\\ninvoked, a future representing the result of the task is\\nreturned immediately. futures can be retrieved using\\nray:get()and passed as arguments into other remote func-\\ntions without waiting for their result. this allows the user\\nto express parallelism while capturing data dependencies.\\ntable 1 shows ray’s api.\\nremote functions operate on immutable objects and\\nare expected to be stateless and side-effect free: their\\noutputs are determined solely by their inputs. this implies\\nidempotence, which simpliﬁes fault tolerance through\\nfunction re-execution on failure.\\nactors. anactor represents a stateful computation. each\\nactor exposes methods that can be invoked remotely and\\nare executed serially. a method execution is similar to a\\ntask, in that it executes remotely and returns a future, but\\ndiffers in that it executes on a stateful worker. a handle\\nto an actor can be passed to other actors or tasks, making\\nit possible for them to invoke methods on that actor.\\ntasks (stateless) actors (stateful)\\nfine-grained load balancing coarse-grained load balancing\\nsupport for object locality poor locality support\\nhigh overhead for small updates low overhead for small updates\\nefﬁcient failure handling overhead from checkpointing\\ntable 2: tasks vs. actors tradeoffs.table 2 summarizes the properties of tasks and actors.\\ntasks enable ﬁne-grained load balancing through leverag-\\ning load-aware scheduling at task granularity, input data\\nlocality, as each task can be scheduled on the node stor-\\ning its inputs, and low recovery overhead, as there is no\\nneed to checkpoint and recover intermediate state. in con-\\ntrast, actors provide much more efﬁcient ﬁne-grained up-\\ndates, as these updates are performed on internal rather\\nthan external state, which typically requires serialization\\nand deserialization. for example, actors can be used to\\nimplement parameter servers [ 32] and gpu-based itera-\\ntive computations (e.g., training). in addition, actors can\\nbe used to wrap third-party simulators and other opaque\\nhandles that are hard to serialize.\\nto satisfy the requirements for heterogeneity and ﬂex-\\nibility (section 2), we augment the api in three ways.\\nfirst, to handle concurrent tasks with heterogeneous du-\\nrations, we introduce ray:wait (), which waits for the\\nﬁrstkavailable results, instead of waiting for allresults\\nlikeray:get(). second, to handle resource-heterogeneous\\ntasks, we enable developers to specify resource require-\\nments so that the ray scheduler can efﬁciently manage re-\\nsources. third, to improve ﬂexibility, we enable nested re-\\nmote functions , meaning that remote functions can invoke\\nother remote functions. this is also critical for achiev-\\ning high scalability (section 4), as it enables multiple pro-\\ncesses to invoke remote functions in a distributed fashion.\\n3.2 computation model\\nray employs a dynamic task graph computation\\nmodel [ 21], in which the execution of both remote func-\\ntions and actor methods is automatically triggered by the\\nsystem when their inputs become available. in this sec-\\ntion, we describe how the computation graph (figure 4) is\\nconstructed from a user program (figure 3). this program\\nuses the api in table 1 to implement the pseudocode\\nfrom figure 2.\\nignoring actors ﬁrst, there are two types of nodes in\\na computation graph: data objects and remote function\\ninvocations, or tasks. there are also two types of edges:\\ndata edges and control edges. data edges capture the de-\\n564    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " '@ray.remote\\ndef create_policy():\\n# initialize the policy randomly.\\nreturn policy\\n@ray.remote(num_gpus=1)\\nclass simulator(object):\\ndef __init__(self):\\n# initialize the environment.\\nself.env = environment()\\ndef rollout(self, policy, num_steps):\\nobservations = []\\nobservation = self.env.current_state()\\nfor _ in range(num_steps):\\naction = policy(observation)\\nobservation = self.env.step(action)\\nobservations.append(observation)\\nreturn observations\\n@ray.remote(num_gpus=2)\\ndef update_policy(policy, *rollouts):\\n# update the policy.\\nreturn policy\\n@ray.remote\\ndef train_policy():\\n# create a policy.\\npolicy_id = create_policy.remote()\\n# create 10 actors.\\nsimulators = [simulator.remote() for _ in range(10)]\\n# do 100 steps of training.\\nfor _ in range(100):\\n# perform one rollout on each actor.\\nrollout_ids = [s.rollout.remote(policy_id)\\nfor s in simulators]\\n# update the policy with the rollouts.\\npolicy_id =\\nupdate_policy.remote(policy_id, *rollout_ids)\\nreturn ray.get(policy_id)\\nfigure 3: python code implementing the example in figure 2\\nin ray. note that @ray.remote indicates remote functions and\\nactors. invocations of remote functions and actor methods return\\nfutures, which can be passed to subsequent remote functions or\\nactor methods to encode task dependencies. each actor has an\\nenvironment object self.env shared between all of its methods.\\npendencies between data objects and tasks. more pre-\\ncisely, if data object dis an output of task t, we add a\\ndata edge from ttod. similarly, if dis an input to t,\\nwe add a data edge from dtot. control edges capture\\nthe computation dependencies that result from nested re-\\nmote functions (section 3.1): if task t1invokes task t2,\\nthen we add a control edge from t1tot2.\\nactor method invocations are also represented as nodes\\nin the computation graph. they are identical to tasks\\nwith one key difference. to capture the state dependency\\nacross subsequent method invocations on the same actor,\\nwe add a third type of edge: a stateful edge. if method\\nmjis called right after method mion the same actor,\\nthen we add a stateful edge from mitomj. thus, all\\npolicy1t1create_policyt2update_policya11rollouta12rolloutpolicy2t3update_policyrollout11rollout12a21rollouta22rolloutrollout22a10simulatora20simulator\\n………data\\tedgesstatefuledgesobjecttask/methodcontrol\\tedgesrollout21t0train_policyfigure 4: the task graph corresponding to an invocation of\\ntrain policy.remote() in figure 3. remote function calls and the\\nactor method calls correspond to tasks in the task graph. the\\nﬁgure shows two actors. the method invocations for each actor\\n(the tasks labeled a1ianda2i) have stateful edges between them\\nindicating that they share the mutable actor state. there are con-\\ntrol edges from train policy to the tasks that it invokes. to train\\nmultiple policies in parallel, we could call train policy.remote()\\nmultiple times.\\nmethods invoked on the same actor object form a chain\\nthat is connected by stateful edges (figure 4). this chain\\ncaptures the order in which these methods were invoked.\\nstateful edges help us embed actors in an otherwise\\nstateless task graph, as they capture the implicit data de-\\npendency between successive method invocations sharing\\nthe internal state of an actor. stateful edges also enable\\nus to maintain lineage. as in other dataﬂow systems [ 64],\\nwe track data lineage to enable reconstruction. by explic-\\nitly including stateful edges in the lineage graph, we can\\neasily reconstruct lost data, whether produced by remote\\nfunctions or actor methods (section 4.2.3).\\n4 architecture\\nray’s architecture comprises (1) an application layer im-\\nplementing the api, and (2) a system layer providing high\\nscalability and fault tolerance.\\n4.1 application layer\\nthe application layer consists of three types of processes:\\n\\x0fdriver : a process executing the user program.\\n\\x0fworker : a stateless process that executes tasks\\n(remote functions) invoked by a driver or another\\nusenix association 13th usenix symposium on operating systems design and implementation    565\\n',\n",
       " 'local scheduleractordriverobject store\\nglobal schedulerglobal schedulerobject tabletask tablefunction tableevent logsglobal control store (gcs)local schedulerdriverworkerobject storenode\\nglobal schedulerweb uidebugging toolsprofiling toolserror diagnosislocal schedulerworkerworkerobject storenodenodeapp layersystem layer (backend)figure 5: ray’s architecture consists of two parts: an applica-\\ntionlayer and a system layer. the application layer implements\\nthe api and the computation model described in section 3, the\\nsystem layer implements task scheduling and data management\\nto satisfy the performance and fault-tolerance requirements.\\nworker. workers are started automatically and as-\\nsigned tasks by the system layer. when a remote\\nfunction is declared, the function is automatically\\npublished to all workers. a worker executes tasks\\nserially, with no local state maintained across tasks.\\n\\x0factor : a stateful process that executes, when in-\\nvoked, only the methods it exposes. unlike a worker,\\nan actor is explicitly instantiated by a worker or a\\ndriver. like workers, actors execute methods seri-\\nally, except that each method depends on the state\\nresulting from the previous method execution.\\n4.2 system layer\\nthe system layer consists of three major components: a\\nglobal control store, a distributed scheduler, and a dis-\\ntributed object store. all components are horizontally\\nscalable and fault-tolerant.\\n4.2.1 global control store (gcs)\\nthe global control store (gcs) maintains the entire con-\\ntrol state of the system, and it is a unique feature of our\\ndesign. at its core, gcs is a key-value store with pub-\\nsub functionality. we use sharding to achieve scale, and\\nper-shard chain replication [ 61] to provide fault tolerance.\\nthe primary reason for the gcs and its design is to main-\\ntain fault tolerance and low latency for a system that can\\ndynamically spawn millions of tasks per second.\\nfault tolerance in case of node failure requires a solu-\\ntion to maintain lineage information. existing lineage-\\nbased solutions [ 64,63,40,28] focus on coarse-grained\\nparallelism and can therefore use a single node (e.g., mas-\\nter, driver) to store the lineage without impacting perfor-\\nmance. however, this design is not scalable for a ﬁne-\\ngrained and dynamic workload like simulation. therefore,we decouple the durable lineage storage from the other\\nsystem components, allowing each to scale independently.\\nmaintaining low latency requires minimizing over-\\nheads in task scheduling, which involves choosing where\\nto execute, and subsequently task dispatch, which in-\\nvolves retrieving remote inputs from other nodes. many\\nexisting dataﬂow systems [ 64,40,48] couple these by\\nstoring object locations and sizes in a centralized sched-\\nuler, a natural design when the scheduler is not a bottle-\\nneck. however, the scale and granularity that ray targets\\nrequires keeping the centralized scheduler off the critical\\npath. involving the scheduler in each object transfer is pro-\\nhibitively expensive for primitives important to distributed\\ntraining like allreduce, which is both communication-\\nintensive and latency-sensitive. therefore, we store the\\nobject metadata in the gcs rather than in the scheduler,\\nfully decoupling task dispatch from task scheduling.\\nin summary, the gcs signiﬁcantly simpliﬁes ray’s\\noverall design, as it enables every component in the sys-\\ntem to be stateless . this not only simpliﬁes support for\\nfault tolerance (i.e., on failure, components simply restart\\nand read the lineage from the gcs), but also makes it\\neasy to scale the distributed object store and scheduler in-\\ndependently, as all components share the needed state via\\nthe gcs. an added beneﬁt is the easy development of de-\\nbugging, proﬁling, and visualization tools.\\n4.2.2 bottom-up distributed scheduler\\nas discussed in section 2, ray needs to dynamically\\nschedule millions of tasks per second, tasks which may\\ntake as little as a few milliseconds. none of the clus-\\nter schedulers we are aware of meet these requirements.\\nmost cluster computing frameworks, such as spark [ 64],\\nciel [ 40], and dryad [ 28] implement a centralized sched-\\nuler, which can provide locality but at latencies in the tens\\nof ms. distributed schedulers such as work stealing [ 12],\\nsparrow [ 45] and canary [ 47] can achieve high scale, but\\nthey either don’t consider data locality [ 12], or assume\\ntasks belong to independent jobs [ 45], or assume the com-\\nputation graph is known [47].\\nto satisfy the above requirements, we design a two-\\nlevel hierarchical scheduler consisting of a global sched-\\nuler and per-node local schedulers. to avoid overloading\\nthe global scheduler, the tasks created at a node are sub-\\nmitted ﬁrst to the node’s local scheduler. a local sched-\\nuler schedules tasks locally unless the node is overloaded\\n(i.e., its local task queue exceeds a predeﬁned threshold),\\nor it cannot satisfy a task’s requirements (e.g., lacks a\\ngpu). if a local scheduler decides not to schedule a task\\nlocally, it forwards it to the global scheduler. since this\\nscheduler attempts to schedule tasks locally ﬁrst (i.e., at\\nthe leaves of the scheduling hierarchy), we call it a bottom-\\nup scheduler .\\n566    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " 'global schedulerlocal schedulerglobal schedulerworkerdriverworker…global control        state (gcs)local schedulerworkerworkerworker\\nsubmit tasksschedule tasksloadinfonode 1node nfigure 6: bottom-up distributed scheduler. tasks are submitted\\nbottom-up, from drivers and workers to a local scheduler and\\nforwarded to the global scheduler only if needed (section 4.2.2).\\nthe thickness of each arrow is proportional to its request rate.\\nthe global scheduler considers each node’s load and\\ntask’s constraints to make scheduling decisions. more pre-\\ncisely, the global scheduler identiﬁes the set of nodes that\\nhave enough resources of the type requested by the task,\\nand of these nodes selects the node which provides the\\nlowest estimated waiting time . at a given node, this time\\nis the sum of (i) the estimated time the task will be queued\\nat that node (i.e., task queue size times average task ex-\\necution), and (ii) the estimated transfer time of task’s\\nremote inputs (i.e., total size of remote inputs divided by\\naverage bandwidth). the global scheduler gets the queue\\nsize at each node and the node resource availability via\\nheartbeats, and the location of the task’s inputs and their\\nsizes from gcs. furthermore, the global scheduler com-\\nputes the average task execution and the average transfer\\nbandwidth using simple exponential averaging. if the\\nglobal scheduler becomes a bottleneck, we can instantiate\\nmore replicas all sharing the same information via gcs.\\nthis makes our scheduler architecture highly scalable.\\n4.2.3 in-memory distributed object store\\nto minimize task latency, we implement an in-memory\\ndistributed storage system to store the inputs and outputs\\nof every task, or stateless computation. on each node, we\\nimplement the object store via shared memory . this al-\\nlows zero-copy data sharing between tasks running on the\\nsame node. as a data format, we use apache arrow [2].\\nif a task’s inputs are not local, the inputs are replicated\\nto the local object store before execution. also, a task\\nwrites its outputs to the local object store. replication\\neliminates the potential bottleneck due to hot data objects\\nand minimizes task execution time as a task only read-\\ns/writes data from/to the local memory. this increases\\nthroughput for computation-bound workloads, a proﬁle\\nshared by many ai applications. for low latency, we keep\\nobjects entirely in memory and evict them as needed todisk using an lru policy.\\nas with existing cluster computing frameworks, such\\nas spark [ 64], and dryad [ 28], the object store is limited\\ntoimmutable data . this obviates the need for complex\\nconsistency protocols (as objects are not updated), and\\nsimpliﬁes support for fault tolerance. in the case of node\\nfailure, ray recovers any needed objects through lineage\\nre-execution. the lineage stored in the gcs tracks both\\nstateless tasks and stateful actors during initial execution;\\nwe use the former to reconstruct objects in the store.\\nfor simplicity, our object store does not support dis-\\ntributed objects, i.e., each object ﬁts on a single node. dis-\\ntributed objects like large matrices or trees can be imple-\\nmented at the application level as collections of futures.\\n4.2.4 implementation\\nray is an active open source projectydeveloped at the uni-\\nversity of california, berkeley. ray fully integrates with\\nthe python environment and is easy to install by simply\\nrunning pip install ray . the implementation com-\\nprises\\x1940k lines of code (loc), 72% in c++ for the\\nsystem layer, 28% in python for the application layer. the\\ngcs uses one redis [ 50] key-value store per shard, with\\nentirely single-key operations. gcs tables are sharded\\nby object and task ids to scale, and every shard is chain-\\nreplicated [ 61] for fault tolerance. we implement both\\nthe local and global schedulers as event-driven, single-\\nthreaded processes. internally, local schedulers maintain\\ncached state for local object metadata, tasks waiting for\\ninputs, and tasks ready for dispatch to a worker. to trans-\\nfer large objects between different object stores, we stripe\\nthe object across multiple tcp connections.\\n4.3 putting everything together\\nfigure 7 illustrates how ray works end-to-end with a\\nsimple example that adds two objects aandb, which\\ncould be scalars or matrices, and returns result c. the\\nremote function add() is automatically registered with the\\ngcs upon initialization and distributed to every worker\\nin the system (step 0 in figure 7a).\\nfigure 7a shows the step-by-step operations triggered\\nby a driver invoking add.remote( a;b), where aandbare\\nstored on nodes n1andn2, respectively. the driver sub-\\nmits add( a,b)to the local scheduler (step 1), which for-\\nwards it to a global scheduler (step 2).znext, the global\\nscheduler looks up the locations of add( a,b)’s arguments\\nin the gcs (step 3) and decides to schedule the task on\\nnode n2, which stores argument b(step 4). the local\\nscheduler at node n2checks whether the local object\\nstore contains add( a,b)’s arguments (step 5). since the\\nyhttps://github.com/ray-project/ray\\nznote that n1 could also decide to schedule the task locally.\\nusenix association 13th usenix symposium on operating systems design and implementation    567\\n',\n",
       " 'object store@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)n1driver object tablefunction table@ray.remotedefadd(a, b):return a + bn2worker idan1idbn2global control store (gcs)\\n456local schedulerobject storeidaa128global scheduler79idaaidbb0\\n3local scheduler(a) executing a task remotely\\nlocal scheduleridbb@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)n1driver object tablefunction table@ray.remotedefadd(a, b):return a + bn2worker idan1idbn2global control store (gcs)\\nlocal scheduleridaa1idaaidccidcn2, n142573global scheduleridcc6\\n(b) returning the result of a remote task\\nfigure 7: an end-to-end example that adds aandband returns\\nc. solid lines are data plane operations and dotted lines are\\ncontrol plane operations. (a) the function add() is registered\\nwith the gcs by node 1 ( n1), invoked on n1, and executed\\nonn2. (b) n1gets add() ’s result using ray.get() . the object\\ntable entry for cis created in step 4 and updated in step 6 after\\ncis copied to n1.\\nlocal store doesn’t have object a, it looks up a’s location\\nin the gcs (step 6). learning that ais stored at n1,n2’s\\nobject store replicates it locally (step 7). as all arguments\\nofadd() are now stored locally, the local scheduler in-\\nvokes add() at a local worker (step 8), which accesses the\\narguments via shared memory (step 9).\\nfigure 7b shows the step-by-step operations triggered\\nby the execution of ray.get() atn1, and of add() atn2,\\nrespectively. upon ray.get( idc)’s invocation, the driver\\nchecks the local object store for the value c, using the\\nfuture idcreturned by add() (step 1). since the local\\nobject store doesn’t store c, it looks up its location in the\\ngcs. at this time, there is no entry for c, aschas not\\nbeen created yet. as a result, n1’s object store registers a\\ncallback with the object table to be triggered when c’s\\nentry has been created (step 2). meanwhile, at n2,add()\\ncompletes its execution, stores the result cin the local\\nobject store (step 3), which in turn adds c’s entry to the\\ngcs (step 4). as a result, the gcs triggers a callback\\nton1’s object store with c’s entry (step 5). next, n1\\nreplicates cfrom n2(step 6), and returns ctoray.get()\\n(step 7), which ﬁnally completes the task.\\nwhile this example involves a large number of rpcs,\\n100kb 1mb 10mb 100mb\\nobject size10-510-410-310-210-1mean task latency (s)locality aware\\nunaware(a) ray locality scheduling\\n102030405060 100\\nnumber of nodes0.00.40.81.21.6millions of tasks/s (b) ray scalability\\nfigure 8: (a) tasks leverage locality-aware placement. 1000\\ntasks with a random object dependency are scheduled onto one\\nof two nodes. with locality-aware policy, task latency remains\\nindependent of the size of task inputs instead of growing by 1-2\\norders of magnitude. (b) near-linear scalability leveraging the\\ngcs and bottom-up distributed scheduler. ray reaches 1 million\\ntasks per second throughput with 60 nodes. x2f70;80;90g\\nomitted due to cost.\\nin many cases this number is much smaller, as most tasks\\nare scheduled locally, and the gcs replies are cached by\\nthe global and local schedulers.\\n5 evaluation\\nin our evaluation, we study the following questions:\\n1.how well does ray meet the latency, scalability,\\nand fault tolerance requirements listed in section 2?\\n(section 5.1)\\n2.what overheads are imposed on distributed primi-\\ntives (e.g., allreduce) written using ray’s api? (sec-\\ntion 5.1)\\n3.in the context of rl workloads, how does ray com-\\npare against specialized systems for training, serv-\\ning, and simulation? (section 5.2)\\n4.what advantages does ray provide for rl applica-\\ntions, compared to custom systems? (section 5.3)\\nall experiments were run on amazon web services.\\nunless otherwise stated, we use m4.16xlarge cpu in-\\nstances and p3.16xlarge gpu instances.\\n5.1 microbenchmarks\\nlocality-aware task placement. fine-grain load bal-\\nancing and locality-aware placement are primary beneﬁts\\nof tasks in ray. actors, once placed, are unable to move\\ntheir computation to large remote objects, while tasks can.\\nin figure 8a, tasks placed without data locality awareness\\n(as is the case for actor methods), suffer 1-2 orders of\\nmagnitude latency increase at 10-100mb input data sizes.\\nray uniﬁes tasks and actors through the shared object\\nstore, allowing developers to use tasks for e.g., expensive\\npostprocessing on output produced by simulation actors.\\nend-to-end scalability. one of the key beneﬁts of\\n568    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " '1kb 10kb 100kb 1mb 10mb 100mb 1gb\\nobject size05000100001500020000iops\\n0246810121416\\nthroughput (gb/s)figure 9: object store write throughput and iops. from a\\nsingle client, throughput exceeds 15gb/s (red) for large objects\\nand 18k iops (cyan) for small objects on a 16 core instance\\n(m4.4xlarge). it uses 8 threads to copy objects larger than 0.5mb\\nand 1 thread for small objects. bar plots report throughput with\\n1, 2, 4, 8, 16 threads. results are averaged over 5 runs.\\nthe global control store (gcs) and the bottom-up dis-\\ntributed scheduler is the ability to horizontally scale the\\nsystem to support a high throughput of ﬁne-grained tasks,\\nwhile maintaining fault tolerance and low-latency task\\nscheduling. in figure 8b, we evaluate this ability on an\\nembarrassingly parallel workload of empty tasks, increas-\\ning the cluster size on the x-axis. we observe near-perfect\\nlinearity in progressively increasing task throughput. ray\\nexceeds 1 million tasks per second throughput at 60 nodes\\nand continues to scale linearly beyond 1.8 million tasks\\nper second at 100 nodes. the rightmost datapoint shows\\nthat ray can process 100 million tasks in less than a\\nminute (54s), with minimum variability. as expected, in-\\ncreasing task duration reduces throughput proportionally\\nto mean task duration, but the overall scalability remains\\nlinear. while many realistic workloads may exhibit more\\nlimited scalability due to object dependencies and inher-\\nent limits to application parallelism, this demonstrates the\\nscalability of our overall architecture under high load.\\nobject store performance. to evaluate the perfor-\\nmance of the object store (section 4.2.3), we track two\\nmetrics: iops (for small objects) and write throughput\\n(for large objects). in figure 9, the write throughput from\\na single client exceeds 15gb/s as object size increases.\\nfor larger objects, memcpy dominates object creation\\ntime. for smaller objects, the main overheads are in seri-\\nalization and ipc between the client and object store.\\ngcs fault tolerance. to maintain low latency while\\nproviding strong consistency and fault tolerance, we build\\na lightweight chain replication [ 61] layer on top of redis.\\nfigure 10a simulates recording ray tasks to and reading\\ntasks from the gcs, where keys are 25 bytes and values\\nare 512 bytes. the client sends requests as fast as it can,\\nhaving at most one in-ﬂight request at a time. failures are\\nreported to the chain master either from the client (having\\nreceived explicit errors, or timeouts despite retries) or\\n0 1 2 3 4 5 6 7 8 9 10\\ntime since start (s)103 103104 104latency (μs)write\\nread\\nnode dead(a) a timeline for gcs read and write latencies as viewed from\\na client submitting tasks. the chain starts with 2 replicas. we\\nmanually trigger reconﬁguration as follows. at t\\x194:2s, a chain\\nmember is killed; immediately after, a new chain member joins,\\ninitiates state transfer, and restores the chain to 2-way replication.\\nthe maximum client-observed latency is under 30ms despite\\nreconﬁgurations.\\n0 10000 20000 30000 40000 50000 60000\\nelasped time (seconds)02000400060008000gcs used memory (mb)50 million no-op tasks\\nray, no gcs flush\\nray, gcs flush\\n(b) the ray gcs maintains a constant memory footprint with\\ngcs ﬂushing. without gcs ﬂushing, the memory footprint\\nreaches a maximum capacity and the workload fails to complete\\nwithin a predetermined duration (indicated by the red cross).\\nfigure 10: ray gcs fault tolerance and ﬂushing.\\nfrom any server in the chain (having received explicit\\nerrors). overall, reconﬁgurations caused a maximum\\nclient-observed delay of under 30ms (this includes both\\nfailure detection and recovery delays).\\ngcs ﬂushing. ray is equipped to periodically ﬂush\\nthe contents of gcs to disk. in figure 10b we submit 50\\nmillion empty tasks sequentially and monitor gcs mem-\\nory consumption. as expected, it grows linearly with the\\nnumber of tasks tracked and eventually reaches the mem-\\nory capacity of the system. at that point, the system be-\\ncomes stalled and the workload fails to ﬁnish within a rea-\\nsonable amount of time. with periodic gcs ﬂushing, we\\nachieve two goals. first, the memory footprint is capped\\nat a user-conﬁgurable level (in the microbenchmark we\\nemploy an aggressive strategy where consumed memory\\nis kept as low as possible). second, the ﬂushing mecha-\\nnism provides a natural way to snapshot lineage to disk\\nfor long-running ray applications.\\nrecovering from task failures. in figure 11a, we\\nusenix association 13th usenix symposium on operating systems design and implementation    569\\n',\n",
       " '0 50 100 150 200\\ntime since start (s)0500100015002000throughput (tasks/s)0204060\\nnumber of nodesoriginal tasks\\nre-executed tasks(a) task reconstruction\\n100 200 300 400 500 600\\ntime since start (s)0100200300400500600700throughput (tasks/s)original tasks\\nre-executed tasks\\ncheckpoint tasks\\n(b) actor reconstruction\\nfigure 11: ray fault-tolerance. (a)ray reconstructs lost task\\ndependencies as nodes are removed (dotted line), and recovers\\nto original throughput when nodes are added back. each task\\nis 100ms and depends on an object generated by a previously\\nsubmitted task. (b)actors are reconstructed from their last\\ncheckpoint. at t=200s, we kill 2 of the 10 nodes, causing 400\\nof the 2000 actors in the cluster to be recovered on the remaining\\nnodes ( t=200–270s).\\ndemonstrate ray’s ability to transparently recover from\\nworker node failures and elastically scale, using the\\ndurable gcs lineage storage. the workload, run on\\nm4.xlarge instances, consists of linear chains of 100ms\\ntasks submitted by the driver. as nodes are removed (at\\n25s, 50s, 100s), the local schedulers reconstruct previous\\nresults in the chain in order to continue execution. over-\\nallper-node throughput remains stable throughout.\\nrecovering from actor failures. by encoding actor\\nmethod calls as stateful edges directly in the dependency\\ngraph, we can reuse the same object reconstruction mech-\\nanism as in figure 11a to provide transparent fault tol-\\nerance for stateful computation . ray additionally lever-\\nages user-deﬁned checkpoint functions to bound the re-\\nconstruction time for actors (figure 11b). with minimal\\noverhead, checkpointing enables only 500 methods to be\\nre-executed, versus 10k re-executions without checkpoint-\\ning. in the future, we hope to further reduce actor recon-\\nstruction time, e.g., by allowing users to annotate meth-\\nods that do not mutate state.\\nallreduce. allreduce is a distributed communication\\n10mb 100mb 1gb\\nobject size100101102103104iteration time (milliseconds)openmpi\\nray*\\nray(a) ray vs openmpi\\n+0 +1 +5 +10\\nadded scheduler latency (ms)0100200300400500600700800iteration time (milliseconds)ray ring reduce latency\\n(16 nodes, 100mb) (b) ray scheduler ablation\\nfigure 12: (a) mean execution time of allreduce on 16 m4.16xl\\nnodes. each worker runs on a distinct node. ray* restricts ray\\nto 1 thread for sending and 1 thread for receiving. (b) ray’s low-\\nlatency scheduling is critical for allreduce.\\nprimitive important to many machine learning workloads.\\nhere, we evaluate whether ray can natively support a\\nring allreduce [ 57] implementation with low enough over-\\nhead to match existing implementations [ 53]. we ﬁnd that\\nray completes allreduce across 16 nodes on 100mb in\\n\\x18200ms and 1gb in \\x181200ms, surprisingly outperform-\\ning openmpi (v1.10), a popular mpi implementation,\\nby 1.5\\x02and 2\\x02respectively (figure 12a). we attribute\\nray’s performance to its use of multiple threads for net-\\nwork transfers, taking full advantage of the 25gbps con-\\nnection between nodes on aws, whereas openmpi se-\\nquentially sends and receives data on a single thread [ 22].\\nfor smaller objects, openmpi outperforms ray by switch-\\ning to a lower overhead algorithm, an optimization we\\nplan to implement in the future.\\nray’s scheduler performance is critical to implement-\\ning primitives such as allreduce. in figure 12b, we inject\\nartiﬁcial task execution delays and show that performance\\ndrops nearly 2\\x02with just a few ms of extra latency. sys-\\ntems with centralized schedulers like spark and ciel typ-\\nically have scheduler overheads in the tens of millisec-\\nonds [ 62,38], making such workloads impractical. sched-\\nulerthroughput also becomes a bottleneck since the num-\\nber of tasks required by ring reduce scales quadratically\\nwith the number of participants.\\n5.2 building blocks\\nend-to-end applications (e.g., alphago [ 54]) require a\\ntight coupling of training, serving, and simulation. in this\\nsection, we isolate each of these workloads to a setting\\nthat illustrates a typical rl application’s requirements.\\ndue to a ﬂexible programming model targeted to rl, and\\na system designed to support this programming model,\\nray matches and sometimes exceeds the performance of\\ndedicated systems for these individual workloads.\\n570    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " '4 8 16 32 64\\nnum gpus (v100)01000200030004000500060007000mean images / shorovod + tf\\ndistributed tf\\nray + tffigure 13: images per second reached when distributing the\\ntraining of a resnet-101 tensorflow model (from the ofﬁcial\\ntf benchmark). all experiments were run on p3.16xl instances\\nconnected by 25gbps ethernet, and workers allocated 4 gpus\\nper node as done in horovod [ 53]. we note some measurement\\ndeviations from previously reported, likely due to hardware\\ndifferences and recent tensorflow performance improvements.\\nwe used openmpi 3.0, tf 1.8, and nccl2 for all runs.\\n5.2.1 distributed training\\nwe implement data-parallel synchronous sgd leverag-\\ning the ray actor abstraction to represent model replicas.\\nmodel weights are synchronized via allreduce (5.1) or pa-\\nrameter server, both implemented on top of the ray api.\\nin figure 13, we evaluate the performance of the\\nray (synchronous) parameter-server sgd implementa-\\ntion against state-of-the-art implementations [ 53], us-\\ning the same tensorflow model and synthetic data gen-\\nerator for each experiment. we compare only against\\ntensorflow-based systems to accurately measure the over-\\nhead imposed by ray, rather than differences between the\\ndeep learning frameworks themselves. in each iteration,\\nmodel replica actors compute gradients in parallel, send\\nthe gradients to a sharded parameter server, then read the\\nsummed gradients from the parameter server for the next\\niteration.\\nfigure 13 shows that ray matches the performance of\\nhorovod and is within 10% of distributed tensorflow\\n(indistributed replicated mode). this is due to\\nthe ability to express the same application-level optimiza-\\ntions found in these specialized systems in ray’s general-\\npurpose api. a key optimization is the pipelining of gra-\\ndient computation, transfer, and summation within a sin-\\ngle iteration. to overlap gpu computation with network\\ntransfer, we use a custom tensorflow operator to write\\ntensors directly to ray’s object store.\\n5.2.2 serving\\nmodel serving is an important component of end-to-end\\napplications. ray focuses primarily on the embedded\\nserving of models to simulators running within the same\\ndynamic task graph (e.g., within an rl application on\\nray). in contrast, systems like clipper [ 19] focus on\\nserving predictions to external clients.\\nin this setting, low latency is critical for achieving high\\nutilization. to show this, in table 3 we compare thesystem small input larger input\\nclipper 4400\\x0615 states/sec 290\\x061.3 states/sec\\nray 6200\\x0621 states/sec 6900\\x06150 states/sec\\ntable 3: throughput comparisons for clipper [ 19], a dedicated\\nserving system, and ray for two embedded serving workloads.\\nwe use a residual network and a small fully connected network,\\ntaking 10ms and 5ms to evaluate, respectively. the server is\\nqueried by clients that each send states of size 4kb and 100kb\\nrespectively in batches of 64.\\nserver throughput achieved using a ray actor to serve\\na policy versus using the open source clipper system\\nover rest. here, both client and server processes are co-\\nlocated on the same machine (a p3.8xlarge instance). this\\nis often the case for rl applications but not for the general\\nweb serving workloads addressed by systems like clipper.\\ndue to its low-overhead serialization and shared memory\\nabstractions, ray achieves an order of magnitude higher\\nthroughput for a small fully connected policy model that\\ntakes in a large input and is also faster on a more expensive\\nresidual network policy model, similar to one used in\\nalphago zero, that takes smaller input.\\n5.2.3 simulation\\nsimulators used in rl produce results with variable\\nlengths (“timesteps”) that, due to the tight loop with train-\\ning, must be used as soon as they are available. the task\\nheterogeneity and timeliness requirements make simu-\\nlations hard to support efﬁciently in bsp-style systems.\\nto demonstrate, we compare (1) an mpi implementation\\nthat submits 3nparallel simulation runs on ncores in 3\\nrounds, with a global barrier between roundsx, to (2) a\\nray program that issues the same 3ntasks while concur-\\nrently gathering simulation results back to the driver. ta-\\nble 4 shows that both systems scale well, yet ray achieves\\nup to 1.8\\x02throughput. this motivates a programming\\nmodel that can dynamically spawn and collect the results\\nof ﬁne-grained simulation tasks.\\nsystem, programming model 1 cpu 16 cpus 256 cpus\\nmpi, bulk synchronous 22.6k 208k 2.16m\\nray, asynchronous tasks 22.3k 290k 4.03m\\ntable 4: timesteps per second for the pendulum-v0 simulator\\nin openai gym [ 13]. ray allows for better utilization when\\nrunning heterogeneous simulations at scale.\\nxnote that experts canuse mpi’s asynchronous primitives to get\\naround barriers—at the expense of increased program complexity —we\\nnonetheless chose such an implementation to simulate bsp.\\nusenix association 13th usenix symposium on operating systems design and implementation    571\\n',\n",
       " '5.3 rl applications\\nwithout a system that can tightly couple the training, sim-\\nulation, and serving steps, reinforcement learning algo-\\nrithms today are implemented as one-off solutions that\\nmake it difﬁcult to incorporate optimizations that, for ex-\\nample, require a different computation structure or that\\nutilize different architectures. consequently, with imple-\\nmentations of two representative reinforcement learning\\napplications in ray, we are able to match and even out-\\nperform custom systems built speciﬁcally for these algo-\\nrithms. the primary reason is the ﬂexibility of ray’s pro-\\ngramming model, which can express application-level op-\\ntimizations that would require substantial engineering ef-\\nfort to port to custom-built systems, but are transparently\\nsupported by ray’s dynamic task graph execution engine.\\n5.3.1 evolution strategies\\nto evaluate ray on large-scale rl workloads, we imple-\\nment the evolution strategies (es) algorithm and com-\\npare to the reference implementation [ 49]—a system spe-\\ncially built for this algorithm that relies on redis for mes-\\nsaging and low-level multiprocessing libraries for data-\\nsharing. the algorithm periodically broadcasts a new pol-\\nicy to a pool of workers and aggregates the results of\\nroughly 10000 tasks (each performing 10 to 1000 simula-\\ntion steps).\\nas shown in figure 14a, an implementation on ray\\nscales to 8192 cores. doubling the cores available yields\\nan average completion time speedup of 1.6 \\x02. conversely,\\nthe special-purpose system fails to complete at 2048 cores,\\nwhere the work in the system exceeds the processing\\ncapacity of the application driver. to avoid this issue, the\\nray implementation uses an aggregation tree of actors,\\nreaching a median time of 3.7 minutes, more than twice\\nas fast as the best published result (10 minutes).\\ninitial parallelization of a serial implementation using\\nray required modifying only 7 lines of code. performance\\nimprovement through hierarchical aggregation was easy\\nto realize with ray’s support for nested tasks and actors.\\nin contrast, the reference implementation had several hun-\\ndred lines of code dedicated to a protocol for communi-\\ncating tasks and data between workers, and would require\\nfurther engineering to support optimizations like hierar-\\nchical aggregation.\\n5.3.2 proximal policy optimization\\nwe implement proximal policy optimization (ppo) [ 51]\\nin ray and compare to a highly-optimized reference im-\\nplementation [ 5] that uses openmpi communication prim-\\nitives. the algorithm is an asynchronous scatter-gather,\\nwhere new tasks are assigned to simulation actors as they\\n256 1024 8192\\nnumber of cpus0102030405060708090mean time to solve (minutes)xxxreference es\\nray es(a) evolution strategies\\n8x1 64x8 512x64\\ncpus x gpus0100200300400500mean time to solve (minutes)mpi ppo\\nray ppo (b) ppo\\nfigure 14: time to reach a score of 6000 in the humanoid-\\nv1 task [ 13].(a)the ray es implementation scales well to\\n8192 cores and achieves a median time of 3.7 minutes, over\\ntwice as fast as the best published result. the special-purpose\\nsystem failed to run beyond 1024 cores. es is faster than ppo\\non this benchmark, but shows greater runtime variance. (b)\\nthe ray ppo implementation outperforms a specialized mpi\\nimplementation [ 5] with fewer gpus, at a fraction of the cost.\\nthe mpi implementation required 1 gpu for every 8 cpus,\\nwhereas the ray version required at most 8 gpus (and never\\nmore than 1 gpu per 8 cpus).\\nreturn rollouts to the driver. tasks are submitted un-\\ntil 320000 simulation steps are collected (each task pro-\\nduces between 10 and 1000 steps). the policy update per-\\nforms 20 steps of sgd with a batch size of 32768. the\\nmodel parameters in this example are roughly 350kb.\\nthese experiments were run using p2.16xlarge (gpu) and\\nm4.16xlarge (high cpu) instances.\\nas shown in figure 14b, the ray implementation out-\\nperforms the optimized mpi implementation in all exper-\\niments, while using a fraction of the gpus. the reason\\nis that ray is heterogeneity-aware and allows the user to\\nutilize asymmetric architectures by expressing resource\\nrequirements at the granularity of a task or actor. the ray\\nimplementation can then leverage tensorflow’s single-\\nprocess multi-gpu support and can pin objects in gpu\\nmemory when possible. this optimization cannot be eas-\\nily ported to mpi due to the need to asynchronously gather\\nrollouts to a single gpu process. indeed, [ 5] includes two\\ncustom implementations of ppo, one using mpi for large\\nclusters and one that is optimized for gpus but that is re-\\nstricted to a single node. ray allows for an implementa-\\ntion suitable for both scenarios.\\nray’s ability to handle resource heterogeneity also de-\\ncreased ppo’s cost by a factor of 4.5 [ 4], since cpu-only\\ntasks can be scheduled on cheaper high-cpu instances.\\nin contrast, mpi applications often exhibit symmetric ar-\\nchitectures, in which all processes run the same code and\\nrequire identical resources, in this case preventing the\\nuse of cpu-only machines for scale-out. furthermore,\\nthe mpi implementation requires on-demand instances\\nsince it does not transparently handle failure. assum-\\ning 4\\x02cheaper spot instances, ray’s fault tolerance and\\nresource-aware scheduling together cut costs by 18 \\x02.\\n572    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " '6 related work\\ndynamic task graphs. ray is closely related to\\nciel [ 40] and dask [ 48]. all three support dynamic\\ntask graphs with nested tasks and implement the futures\\nabstraction. ciel also provides lineage-based fault toler-\\nance, while dask, like ray, fully integrates with python.\\nhowever, ray differs in two aspects that have important\\nperformance consequences. first, ray extends the task\\nmodel with an actor abstraction. this is necessary for\\nefﬁcient stateful computation in distributed training and\\nserving, to keep the model data collocated with the com-\\nputation. second, ray employs a fully distributed and de-\\ncoupled control plane and scheduler, instead of relying on\\na single master storing all metadata. this is critical for ef-\\nﬁciently supporting primitives like allreduce without sys-\\ntem modiﬁcation. at peak performance for 100mb on 16\\nnodes, allreduce on ray (section 5.1) submits 32 rounds\\nof 16 tasks in 200ms. meanwhile, dask reports a maxi-\\nmum scheduler throughput of 3k tasks/s on 512 cores [ 3].\\nwith a centralized scheduler, each round of allreduce\\nwould then incur a minimum of \\x185ms of scheduling\\ndelay, translating to up to 2\\x02worse completion time (fig-\\nure 12b). even with a decentralized scheduler, coupling\\nthe control plane information with the scheduler leaves\\nthe latter on the critical path for data transfer, adding an\\nextra roundtrip to every round of allreduce.\\ndataﬂow systems. popular dataﬂow systems, such\\nas mapreduce [ 20], spark [ 65], and dryad [ 28] have\\nwidespread adoption for analytics and ml workloads,\\nbut their computation model is too restrictive for a ﬁne-\\ngrained and dynamic simulation workload. spark and\\nmapreduce implement the bsp execution model, which\\nassumes that tasks within the same stage perform the\\nsame computation and take roughly the same amount of\\ntime. dryad relaxes this restriction but lacks support for\\ndynamic task graphs. furthermore, none of these systems\\nprovide an actor abstraction, nor implement a distributed\\nscalable control plane and scheduler. finally, naiad [ 39]\\nis a dataﬂow system that provides improved scalability\\nfor some workloads, but only supports static task graphs.\\nmachine learning frameworks. tensorflow [ 7] and\\nmxnet [ 18] target deep learning workloads and efﬁ-\\nciently leverage both cpus and gpus. while they\\nachieve great performance for training workloads consist-\\ning of static dags of linear algebra operations, they have\\nlimited support for the more general computation required\\nto tightly couple training with simulation and embedded\\nserving. tensorflow fold [ 33] provides some support for\\ndynamic task graphs, as well as mxnet through its inter-\\nnal c++ apis, but neither fully supports the ability to mod-\\nify the dag during execution in response to task progress,\\ntask completion times, or faults. tensorflow and mxnet\\nin principle achieve generality by allowing the program-mer to simulate low-level message-passing and synchro-\\nnization primitives, but the pitfalls and user experience in\\nthis case are similar to those of mpi. openmpi [ 22] can\\nachieve high performance, but it is relatively hard to pro-\\ngram as it requires explicit coordination to handle hetero-\\ngeneous and dynamic task graphs. furthermore, it forces\\nthe programmer to explicitly handle fault tolerance.\\nactor systems. orleans [ 14] and akka [ 1] are two ac-\\ntor frameworks well suited to developing highly available\\nand concurrent distributed systems. however, compared\\nto ray, they provide less support for recovery from data\\nloss. to recover stateful actors , the orleans developer\\nmust explicitly checkpoint actor state and intermediate re-\\nsponses. stateless actors in orleans can be replicated for\\nscale-out, and could therefore act as tasks, but unlike in\\nray, they have no lineage. similarly, while akka explic-\\nitly supports persisting actor state across failures, it does\\nnot provide efﬁcient fault tolerance for stateless computa-\\ntion(i.e., tasks). for message delivery, orleans provides\\nat-least-once and akka provides at-most-once semantics.\\nin contrast, ray provides transparent fault tolerance and\\nexactly-once semantics, as each method call is logged in\\nthe gcs and both arguments and results are immutable.\\nwe ﬁnd that in practice these limitations do not affect the\\nperformance of our applications. erlang [ 10] and c++ ac-\\ntor framework [ 17], two other actor-based systems, have\\nsimilarly limited support for fault tolerance.\\nglobal control store and scheduling. the concept\\nof logically centralizing the control plane has been pre-\\nviously proposed in software deﬁned networks (sdns)\\n[16], distributed ﬁle systems (e.g., gfs [ 23]), resource\\nmanagement (e.g., omega [ 52]), and distributed frame-\\nworks (e.g., mapreduce [ 20], boom [ 9]), to name a\\nfew. ray draws inspiration from these pioneering efforts,\\nbut provides signiﬁcant improvements. in contrast with\\nsdns, boom, and gfs, ray decouples the storage of\\nthe control plane information (e.g., gcs) from the logic\\nimplementation (e.g., schedulers). this allows both stor-\\nage and computation layers to scale independently, which\\nis key to achieving our scalability targets. omega uses\\na distributed architecture in which schedulers coordinate\\nvia globally shared state. to this architecture, ray adds\\nglobal schedulers to balance load across local schedulers,\\nand targets ms-level, not second-level, task scheduling.\\nray implements a unique distributed bottom-up sched-\\nuler that is horizontally scalable, and can handle dynami-\\ncally constructed task graphs. unlike ray, most existing\\ncluster computing systems [ 20,64,40] use a centralized\\nscheduler architecture. while sparrow [ 45] is decentral-\\nized, its schedulers make independent decisions, limiting\\nthe possible scheduling policies, and all tasks of a job are\\nhandled by the same global scheduler. mesos [ 26] im-\\nplements a two-level hierarchical scheduler, but its top-\\nlevel scheduler manages frameworks, not individual tasks.\\nusenix association 13th usenix symposium on operating systems design and implementation    573\\n',\n",
       " 'canary [ 47] achieves impressive performance by having\\neach scheduler instance handle a portion of the task graph,\\nbut does not handle dynamic computation graphs.\\ncilk [ 12] is a parallel programming language whose\\nwork-stealing scheduler achieves provably efﬁcient load-\\nbalancing for dynamic task graphs. however, with no\\ncentral coordinator like ray’s global scheduler, this fully\\nparallel design is also difﬁcult to extend to support data\\nlocality and resource heterogeneity in a distributed setting.\\n7 discussion and experiences\\nbuilding ray has been a long journey. it started two years\\nago with a spark library to perform distributed training\\nand simulations. however, the relative inﬂexibility of the\\nbsp model, the high per-task overhead, and the lack of an\\nactor abstraction led us to develop a new system. since we\\nreleased ray roughly one year ago, several hundreds of\\npeople have used it and several companies are running it\\nin production. here we discuss our experience developing\\nand using ray, and some early user feedback.\\napi. in designing the api, we have emphasized mini-\\nmalism. initially we started with a basic task abstraction.\\nlater, we added the wait() primitive to accommodate roll-\\nouts with heterogeneous durations and the actor abstrac-\\ntion to accommodate third-party simulators and amortize\\nthe overhead of expensive initializations. while the re-\\nsulting api is relatively low-level, it has proven both pow-\\nerful and simple to use. we have already used this api to\\nimplement many state-of-the-art rl algorithms on top of\\nray, including a3c [ 36], ppo [ 51], dqn [ 37], es [ 49],\\nddpg [ 55], and ape-x [ 27]. in most cases it took us\\njust a few tens of lines of code to port these algorithms to\\nray. based on early user feedback, we are considering\\nenhancing the api to include higher level primitives and\\nlibraries, which could also inform scheduling decisions.\\nlimitations. given the workload generality, special-\\nized optimizations are hard. for example, we must make\\nscheduling decisions without full knowledge of the com-\\nputation graph. scheduling optimizations in ray might\\nrequire more complex runtime proﬁling. in addition, stor-\\ning lineage for each task requires the implementation of\\ngarbage collection policies to bound storage costs in the\\ngcs, a feature we are actively developing.\\nfault tolerance. we are often asked if fault tolerance\\nis really needed for ai applications. after all, due to the\\nstatistical nature of many ai algorithms, one could sim-\\nply ignore failed rollouts. based on our experience, our\\nanswer is “yes”. first, the ability to ignore failures makes\\napplications much easier to write and reason about. sec-\\nond, our particular implementation of fault tolerance via\\ndeterministic replay dramatically simpliﬁes debugging as\\nit allows us to easily reproduce most errors. this is par-\\nticularly important since, due to their stochasticity, ai al-gorithms are notoriously hard to debug. third, fault toler-\\nance helps save money since it allows us to run on cheap\\nresources like spot instances on aws. of course, this\\ncomes at the price of some overhead. however, we found\\nthis overhead to be minimal for our target workloads.\\ngcs and horizontal scalability. the gcs dramati-\\ncally simpliﬁed ray development and debugging. it en-\\nabled us to query the entire system state while debugging\\nray itself, instead of having to manually expose internal\\ncomponent state. in addition, the gcs is also the backend\\nfor our timeline visualization tool, used for application-\\nlevel debugging.\\nthe gcs was also instrumental to ray’s horizontal\\nscalability. in section 5, we were able to scale by adding\\nmore shards whenever the gcs became a bottleneck. the\\ngcs also enabled the global scheduler to scale by sim-\\nply adding more replicas. due to these advantages, we\\nbelieve that centralizing control state will be a key design\\ncomponent of future distributed systems.\\n8 conclusion\\nno general-purpose system today can efﬁciently support\\nthe tight loop of training, serving, and simulation. to ex-\\npress these core building blocks and meet the demands of\\nemerging ai applications, ray uniﬁes task-parallel and\\nactor programming models in a single dynamic task graph\\nand employs a scalable architecture enabled by the global\\ncontrol store and a bottom-up distributed scheduler. the\\nprogramming ﬂexibility, high throughput, and low laten-\\ncies simultaneously achieved by this architecture is partic-\\nularly important for emerging artiﬁcial intelligence work-\\nloads, which produce tasks diverse in their resource re-\\nquirements, duration, and functionality. our evaluation\\ndemonstrates linear scalability up to 1.8 million tasks per\\nsecond, transparent fault tolerance, and substantial perfor-\\nmance improvements on several contemporary rl work-\\nloads. thus, ray provides a powerful combination of ﬂex-\\nibility, performance, and ease of use for the development\\nof future ai applications.\\n9 acknowledgments\\nthis research is supported in part by nsf cise expedi-\\ntions award ccf-1730628 and gifts from alibaba, ama-\\nzon web services, ant financial, arm, capitalone, eric-\\nsson, facebook, google, huawei, intel, microsoft, sco-\\ntiabank, splunk and vmware as well as by nsf grant\\ndge-1106400. we are grateful to our anonymous review-\\ners and our shepherd, miguel castro, for thoughtful feed-\\nback, which helped improve the quality of this paper.\\n574    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " 'references\\n[1] akka. https://akka.io/ .\\n[2] apache arrow. https://arrow.apache.org/ .\\n[3]dask benchmarks. http://matthewrocklin.com/blog/\\nwork/2017/07/03/scaling .\\n[4]ec2 instance pricing. https://aws.amazon.com/ec2/\\npricing/on-demand/ .\\n[5]openai baselines: high-quality implementations of reinforce-\\nment learning algorithms. https://github.com/openai/\\nbaselines .\\n[6]tensorflow serving. https://www.tensorflow.org/\\nserving/ .\\n[7]abadi , m., b arham , p., c hen, j., c hen, z., d avis , a.,\\ndean, j., d evin , m., g hemawat , s., i rving , g., i sard , m.,\\net al .tensorflow: a system for large-scale machine learning.\\ninproceedings of the 12th usenix symposium on operating\\nsystems design and implementation (osdi). savannah, georgia,\\nusa (2016).\\n[8] a garwal , a., b ird, s., c ozowicz , m., h oang , l., l ang -\\nford , j., l ee, s., l i, j., m elamed , d., o shri , g., r ibas ,\\no., s en, s., and slivkins , a. a multiworld testing decision\\nservice. arxiv preprint arxiv:1606.03966 (2016).\\n[9]alvaro , p., c ondie , t., c onway , n., e lmeleegy , k.,\\nhellerstein , j. m., and sears , r. boom analytics: ex-\\nploring data-centric, declarative programming for the cloud. in\\nproceedings of the 5th european conference on computer systems\\n(2010), acm, pp. 223–236.\\n[10] armstrong , j., v irding , r., w ikstr ¨om, c., and\\nwilliams , m. concurrent programming in erlang.\\n[11] beattie , c., l eibo , j. z., t eplyashin , d., w ard, t.,\\nwainwright , m., k ¨uttler , h., l efrancq , a., g reen , s.,\\nvald´es, v., s adik , a., et al .deepmind lab. arxiv preprint\\narxiv:1612.03801 (2016).\\n[12] blumofe , r. d., and leiserson , c. e. scheduling mul-\\ntithreaded computations by work stealing. j. acm 46 , 5 (sept.\\n1999), 720–748.\\n[13] b rockman , g., c heung , v., p ettersson , l., s chneider ,\\nj., s chulman , j., t ang, j., and zaremba , w. openai gym.\\narxiv preprint arxiv:1606.01540 (2016).\\n[14] bykov , s., g eller , a., k liot , g., l arus , j. r., p andya ,\\nr., and thelin , j.orleans: cloud computing for everyone. in\\nproceedings of the 2nd acm symposium on cloud computing\\n(2011), acm, p. 16.\\n[15] carbone , p., e wen , s., f ´ora, g., h aridi , s., r ichter ,\\ns., and tzoumas , k. state management in apache flink:\\nconsistent stateful distributed stream processing. proc. vldb\\nendow. 10 , 12 (aug. 2017), 1718–1729.\\n[16] casado , m., f reedman , m. j., p ettit , j., l uo, j., m cke-\\nown , n., and shenker , s.ethane: taking control of the enter-\\nprise. sigcomm comput. commun. rev. 37 , 4 (aug. 2007), 1–12.\\n[17] charousset , d., s chmidt , t. c., h iesgen , r., and\\nw¨ahlisch , m. native actors: a scalable software platform for\\ndistributed, heterogeneous environments. in proceedings of the\\n2013 workshop on programming based on actors, agents, and de-\\ncentralized control (2013), acm, pp. 87–96.[18] chen, t., l i, m., l i, y., l in, m., w ang , n., w ang , m.,\\nxiao, t., x u, b., z hang , c., and zhang , z. mxnet: a\\nﬂexible and efﬁcient machine learning library for heterogeneous\\ndistributed systems. in nips workshop on machine learning\\nsystems (learningsys’16) (2016).\\n[19] crankshaw , d., w ang , x., z hou , g., f ranklin , m. j.,\\ngonzalez , j. e., and stoica , i. clipper: a low-latency\\nonline prediction serving system. in 14th usenix symposium\\non networked systems design and implementation (nsdi 17)\\n(boston, ma, 2017), usenix association, pp. 613–627.\\n[20] dean, j., and ghemawat , s. mapreduce: simpliﬁed data\\nprocessing on large clusters. commun. acm 51 , 1 (jan. 2008),\\n107–113.\\n[21] dennis , j. b., and misunas , d. p. a preliminary architecture\\nfor a basic data-ﬂow processor. in proceedings of the 2nd an-\\nnual symposium on computer architecture (new york, ny , usa,\\n1975), isca ’75, acm, pp. 126–132.\\n[22] gabriel , e., f agg, g. e., b osilca , g., a ngskun , t., d on-\\ngarra , j. j., s quyres , j. m., s ahay , v., k ambadur , p.,\\nbarrett , b., l umsdaine , a., c astain , r. h., d aniel ,\\nd. j., g raham , r. l., and woodall , t. s. open mpi: goals,\\nconcept, and design of a next generation mpi implementation. in\\nproceedings, 11th european pvm/mpi users’ group meeting\\n(budapest, hungary, september 2004), pp. 97–104.\\n[23] ghemawat , s., g obioff , h., and leung , s.-t. the google\\nﬁle system. 29–43.\\n[24] gonzalez , j. e., x in, r. s., d ave, a., c rankshaw , d.,\\nfranklin , m. j., and stoica , i.graphx: graph processing\\nin a distributed dataﬂow framework. in proceedings of the 11th\\nusenix conference on operating systems design and implemen-\\ntation (berkeley, ca, usa, 2014), osdi’14, usenix associa-\\ntion, pp. 599–613.\\n[25] gu*, s., h olly *, e., l illicrap , t., and levine , s.deep re-\\ninforcement learning for robotic manipulation with asynchronous\\noff-policy updates. in ieee international conference on robotics\\nand automation (icra 2017) (2017).\\n[26] hindman , b., k onwinski , a., z aharia , m., g hodsi , a.,\\njoseph , a. d., k atz, r., s henker , s., and stoica , i.\\nmesos: a platform for ﬁne-grained resource sharing in the data\\ncenter. in proceedings of the 8th usenix conference on net-\\nworked systems design and implementation (berkeley, ca, usa,\\n2011), nsdi’11, usenix association, pp. 295–308.\\n[27] horgan , d., q uan, j., b udden , d., b arth -maron , g.,\\nhessel , m., van hasselt , h., and silver , d. distributed\\nprioritized experience replay. international conference on learn-\\ning representations (2018).\\n[28] isard , m., b udiu , m., y u, y., b irrell , a., and fetterly ,\\nd.dryad: distributed data-parallel programs from sequential\\nbuilding blocks. in proceedings of the 2nd acm sigops/eurosys\\neuropean conference on computer systems 2007 (new york, ny ,\\nusa, 2007), eurosys ’07, acm, pp. 59–72.\\n[29] jia, y., s helhamer , e., d onahue , j., k arayev , s., l ong ,\\nj., g irshick , r., g uadarrama , s., and darrell , t.caffe:\\nconvolutional architecture for fast feature embedding. arxiv\\npreprint arxiv:1408.5093 (2014).\\n[30] jordan , m. i., and mitchell , t. m. machine learning:\\ntrends, perspectives, and prospects. science 349 , 6245 (2015),\\n255–260.\\nusenix association 13th usenix symposium on operating systems design and implementation    575\\n',\n",
       " '[31] leibiusky , j., e isbruch , g., and simonassi , d. getting\\nstarted with storm . o’reilly media, inc., 2012.\\n[32] li, m., a ndersen , d. g., p ark, j. w., s mola , a. j.,\\nahmed , a., j osifovski , v., l ong , j., s hekita , e. j., and\\nsu, b.-y. scaling distributed machine learning with the parame-\\nter server. in proceedings of the 11th usenix conference on op-\\nerating systems design and implementation (berkeley, ca, usa,\\n2014), osdi’14, pp. 583–598.\\n[33] l ooks , m., h erreshoff , m., h utchins , d., and norvig ,\\np.deep learning with dynamic computation graphs. arxiv preprint\\narxiv:1702.02181 (2017).\\n[34] low, y., g onzalez , j., k yrola , a., b ickson , d.,\\nguestrin , c., and hellerstein , j.graphlab: a new frame-\\nwork for parallel machine learning. in proceedings of the twenty-\\nsixth conference on uncertainty in artiﬁcial intelligence (arling-\\nton, virginia, united states, 2010), uai’10, pp. 340–349.\\n[35] malewicz , g., a ustern , m. h., b ik, a. j., d ehnert , j. c.,\\nhorn, i., l eiser , n., and czajkowski , g. pregel: a system\\nfor large-scale graph processing. in proceedings of the 2010 acm\\nsigmod international conference on management of data (new\\nyork, ny , usa, 2010), sigmod ’10, acm, pp. 135–146.\\n[36] mnih, v., b adia , a. p., m irza , m., g raves , a., l illicrap ,\\nt. p., h arley , t., s ilver , d., and kavukcuoglu , k. asyn-\\nchronous methods for deep reinforcement learning. in interna-\\ntional conference on machine learning (2016).\\n[37] mnih, v., k avukcuoglu , k., s ilver , d., r usu, a. a.,\\nveness , j., b ellemare , m. g., g raves , a., r iedmiller ,\\nm., f idjeland , a. k., o strovski , g., et al .human-level\\ncontrol through deep reinforcement learning. nature 518 , 7540\\n(2015), 529–533.\\n[38] murray , d. a distributed execution engine supporting data-\\ndependent control flow . university of cambridge, 2012.\\n[39] murray , d. g., m csherry , f., i saacs , r., i sard , m.,\\nbarham , p., and abadi , m. naiad: a timely dataﬂow system.\\ninproceedings of the twenty-fourth acm symposium on operat-\\ning systems principles (new york, ny , usa, 2013), sosp ’13,\\nacm, pp. 439–455.\\n[40] murray , d. g., s chwarzkopf , m., s mowton , c., s mith ,\\ns., m adhavapeddy , a., and hand, s.ciel: a universal exe-\\ncution engine for distributed data-ﬂow computing. in proceedings\\nof the 8th usenix conference on networked systems design and\\nimplementation (berkeley, ca, usa, 2011), nsdi’11, usenix\\nassociation, pp. 113–126.\\n[41] nair, a., s rinivasan , p., b lackwell , s., a lcicek , c.,\\nfearon , r., m aria , a. d., p anneershelvam , v., s uley -\\nman , m., b eattie , c., p etersen , s., l egg, s., m nih, v.,\\nkavukcuoglu , k., and silver , d. massively parallel meth-\\nods for deep reinforcement learning, 2015.\\n[42] ng, a., c oates , a., d iel, m., g anapathi , v., s chulte , j.,\\ntse, b., b erger , e., and liang , e.autonomous inverted he-\\nlicopter ﬂight via reinforcement learning. experimental robotics\\nix(2006), 363–372.\\n[43] nishihara , r., m oritz , p., w ang, s., t umanov , a., p aul,\\nw., s chleier -smith , j., l iaw, r., n iknami , m., j ordan ,\\nm. i., and stoica , i.real-time machine learning: the missing\\npieces. in workshop on hot topics in operating systems (2017).\\n[44] openai. openai dota 2 1v1 bot. https://openai.com/\\nthe-international/ , 2017.[45] ousterhout , k., w endell , p., z aharia , m., and stoica ,\\ni.sparrow: distributed, low latency scheduling. in proceedings\\nof the twenty-fourth acm symposium on operating systems\\nprinciples (new york, ny , usa, 2013), sosp ’13, acm, pp. 69–\\n84.\\n[46] paszke , a., g ross , s., c hintala , s., c hanan , g., y ang ,\\ne., d evito, z., l in, z., d esmaison , a., a ntiga , l., and\\nlerer , a. automatic differentiation in pytorch.\\n[47] qu, h., m ashayekhi , o., t erei , d., and levis , p.canary:\\na scheduling architecture for high performance cloud computing.\\narxiv preprint arxiv:1602.01412 (2016).\\n[48] rocklin , m. dask: parallel computation with blocked algo-\\nrithms and task scheduling. in proceedings of the 14th python in\\nscience conference (2015), k. huff and j. bergstra, eds., pp. 130\\n– 136.\\n[49] s alimans , t., h o, j., c hen, x., and sutskever , i. evolu-\\ntion strategies as a scalable alternative to reinforcement learning.\\narxiv preprint arxiv:1703.03864 (2017).\\n[50] sanfilippo , s.redis: an open source, in-memory data structure\\nstore. https://redis.io/ , 2009.\\n[51] schulman , j., w olski , f., d hariwal , p., r adford , a.,\\nand klimov , o. proximal policy optimization algorithms. arxiv\\npreprint arxiv:1707.06347 (2017).\\n[52] schwarzkopf , m., k onwinski , a., a bd-el-malek , m.,\\nand wilkes , j.omega: flexible, scalable schedulers for large\\ncompute clusters. in proceedings of the 8th acm european con-\\nference on computer systems (new york, ny , usa, 2013), eu-\\nrosys ’13, acm, pp. 351–364.\\n[53] sergeev , a., and delbalso , m. horovod: fast and\\neasy distributed deep learning in tensorﬂow. arxiv preprint\\narxiv:1802.05799 (2018).\\n[54] silver , d., h uang , a., m addison , c. j., g uez, a.,\\nsifre , l., v andendriessche , g., s chrittwieser , j.,\\nantonoglou , i., p anneershelvam , v., l anctot , m.,\\net al .mastering the game of go with deep neural networks and\\ntree search. nature 529 , 7587 (2016), 484–489.\\n[55] silver , d., l ever , g., h eess , n., d egris , t., w ierstra ,\\nd., and riedmiller , m. deterministic policy gradient algo-\\nrithms. in icml (2014).\\n[56] sutton , r. s., and barto , a. g. reinforcement learning:\\nan introduction . mit press cambridge, 1998.\\n[57] thakur , r., r abenseifner , r., and gropp , w. optimiza-\\ntion of collective communication operations in mpich. the inter-\\nnational journal of high performance computing applications\\n19, 1 (2005), 49–66.\\n[58] tian, y., g ong, q., s hang , w., w u, y., and zitnick , c. l.\\nelf: an extensive, lightweight and ﬂexible research platform\\nfor real-time strategy games. advances in neural information\\nprocessing systems (nips) (2017).\\n[59] todorov , e., e rez, t., and tassa , y. mujoco: a physics\\nengine for model-based control. in intelligent robots and systems\\n(iros), 2012 ieee/rsj international conference on (2012), ieee,\\npp. 5026–5033.\\n576    13th usenix symposium on operating systems design and implementation usenix association\\n',\n",
       " '[60] vandenberg, j., m iller , s., d uckworth , d., h u, h.,\\nwan, a., f u, x.-y., g oldberg , k., and abbeel , p. su-\\nperhuman performance of surgical tasks by robots using iterative\\nlearning from human-guided demonstrations. in robotics and au-\\ntomation (icra), 2010 ieee international conference on (2010),\\nieee, pp. 2074–2081.\\n[61] van renesse , r., and schneider , f. b. chain replication for\\nsupporting high throughput and availability. in proceedings of the\\n6th conference on symposium on opearting systems design &\\nimplementation - volume 6 (berkeley, ca, usa, 2004), osdi’04,\\nusenix association.\\n[62] venkataraman , s., p anda , a., o usterhout , k., g hodsi ,\\na., a rmbrust , m., r echt , b., f ranklin , m., and stoica ,\\ni.drizzle: fast and adaptable stream processing at scale. in\\nproceedings of the twenty-sixth acm symposium on operating\\nsystems principles (2017), sosp ’17, acm.\\n[63] white , t.hadoop: the deﬁnitive guide . o’reilly media, inc.,\\n2012.\\n[64] zaharia , m., c howdhury , m., d as, t., d ave, a., m a, j.,\\nmccauley , m., f ranklin , m. j., s henker , s., and sto-\\nica, i. resilient distributed datasets: a fault-tolerant abstrac-\\ntion for in-memory cluster computing. in proceedings of the 9th\\nusenix conference on networked systems design and implemen-\\ntation (2012), usenix association, pp. 2–2.\\n[65] zaharia , m., x in, r. s., w endell , p., d as, t., a rmbrust ,\\nm., d ave, a., m eng, x., r osen , j., v enkataraman , s.,\\nfranklin , m. j., g hodsi , a., g onzalez , j., s henker , s.,\\nand stoica , i.apache spark: a uniﬁed engine for big data\\nprocessing. commun. acm 59 , 11 (oct. 2016), 56–65.\\nusenix association 13th usenix symposium on operating systems design and implementation    577',\n",
       " ' \\n \\n \\nj r c  t e c h n i c a l  r e p o r t s \\nai watch  \\ndefining artificial  intelligence  \\ntowards an operational  \\ndefinition and taxonomy  \\nof artificial intelligence  \\n \\n \\neur 30117 en  ',\n",
       " ' \\n this publication is a report by the joint research centre (jrc), the european commission’s science and knowledge service. it aims to \\nprovide evidence -based scientific support to the european policymaking process. the scientific output expressed does not imply a policy \\nposition of the european commission. neither the european commission nor any person acting on behalf of the commission is \\nresponsible for the use that might be made of this publication.  \\n \\ncontact information  \\naddress: edificio expo, c/ inca garcilaso 3, sevilla 41092, spain  \\nemail: ec -ai-watch@ec.europa.eu  \\n \\neu science hub  \\nhttps://ec.europa.eu/jrc  \\n \\n \\njrc118163  \\n \\neur 30117 en  \\n \\n \\npdf isbn 978-92-76-17045 -7 issn 1831 -9424  doi: 10.2760/382730  \\n \\n \\nluxembourg: publications office of the european union, 2020  \\n \\n© european union, 2020  \\n \\n \\n \\n \\n \\n \\n \\n \\nthe reuse policy of the european commission is implemented by the commission decision 2011/833/eu of 12 december 2011 on the \\nreuse of commission documents (oj l 330, 14.12.2011, p. 39). except otherwise noted, t he reuse of this document is authorised under \\nthe creative commons attribution 4.0 international (cc by 4.0) licence ( https://creativecommons.org/licenses/by/4.0/ ). this means that \\nreuse is allow ed provided appropriate credit is given and any changes are indicated. for any use or reproduction of photos or other \\nmaterial that is not owned by the eu, permission must be sought directly from the copyright holders.  \\n \\nall content © european union 2020, except: cover image © sdecoret©adobestock, 2018  peshkova©adobestock, 2018  \\n \\nhow to cite this report: samoili, s., lópez  cobo, m., gómez, e., de prato, g., martínez -plumed, f. , and delipetrev, b. , ai watch. defining \\nartificial intelligence. towards an operational definition and taxonomy of artificial intelligence , eur 30117 en, pub lications office of the \\neuropean union, luxembourg, 2020, isbn 978 -92-76-17045 -7, doi:10.2760/382730, jrc118163.  \\n',\n",
       " ' \\ni contents  \\nforeword  ................................ ................................ ................................ ................  1 \\nacknowledgements  ................................ ................................ ................................ ..... 2 \\nabstract  ................................ ................................ ................................ .................  3 \\nexecutive summary  ................................ ................................ ................................ ..... 4 \\n1 introduction  ................................ ................................ ................................ .........  6 \\n2 proposal for a common definition on artificial intelligence  ................................ .....................  7 \\n2.1 ai definitions  ................................ ................................ ................................ .. 7 \\n2.2 ai watch operational definition of ai  ................................ ................................ ........  8 \\n2.2.1  ai taxonomy  ................................ ................................ ...........................  9 \\n2.2.1.1  sources  ................................ ................................ ..........................  9 \\n2.2.1.2  ai watch t axonomy  ................................ ................................ ...........  11 \\n2.2.2  ai keywords  ................................ ................................ .........................  14 \\n2.2.2.1  construction process  ................................ ................................ ..........  14 \\n2.2.2.2  keyword list  ................................ ................................ ...................  15 \\n2.3 collection of ai definitions and subdomains  ................................ ..............................  17 \\n3 ai definitions and subdomains in: policy documents, research and market reports  .........................  29 \\n3.1 policy and institutional perspective: commission  services; national; international  ....................  29 \\n3.1.1  european commission level  ................................ ................................ ........  29 \\n3.1.1.1  high level expert group on artificial intelligence (hleg), 2019  ..........................  29 \\n3.1.1.2  ec coordinated plan on ai, 2018  ................................ ............................  30 \\n3.1.1.3  european ai strategy: ec communication - artificial intelligence for europe, 2018 ..... 31 \\n3.1.1.4  ec jrc flagship report on ai: artificial intelligence. a european perspective, 2018  ..... 32 \\n3.1.2  national level: european union  ................................ ................................ .... 33 \\n3.1.2.1  ai 4 belgium report, 2019  ................................ ................................ ... 33 \\n3.1.2.2  ai national strategy: denmark, 2019  ................................ .......................  34 \\n3.1.2.3  ai national strategy: france. monitoring report, 2019  ................................ ..... 35 \\n3.1.2.4  spanish rdi strategy in artificial intelligence, 2019  ................................ ....... 37 \\n3.1.2.5  ai national strategy: fran ce (villani mission), 2018  ................................ ....... 38 \\n3.1.2.6  ai national strategy: germany, 2018  ................................ .......................  39 \\n3.1.2.7  ai national strategy: sweden, 2018  ................................ .........................  40 \\n3.1.2.8  report of the steering group of the ai programme: finland, 2017  .......................  41 \\n3.1.3  national level: non -eu ................................ ................................ ..............  42 \\n3.1.3.1  australia’s ethic framework, 2019  ................................ ..........................  42 \\n3.1.3.2  us congressional research service, 2019  ................................ ..................  43 \\n3.1.3.3  working paper for ai national strategy: india, 2018  ................................ ....... 44 ',\n",
       " ' \\nii 3.1.3.4  us national defense authorization act, 2018  ................................ ..............  45 \\n3.1.3.5  us department of defense, 2018  ................................ ...........................  46 \\n3.1.3.6  national industrial strategy: united kingdom, 2018; 2017  ...............................  47 \\n3.1.3.7  ai national strategy: japan, 2017  ................................ ...........................  48 \\n3.1.3.8  ai national strategy: china, 2017  ................................ ...........................  49 \\n3.1.3.9  ai national strategy: canada, 2017  ................................ .........................  50 \\n3.1.4  international organisations  ................................ ................................ ........  51 \\n3.1.4.1  oecd, 2019  ................................ ................................ ...................  51 \\n3.1.4.2  unesco, 2019  ................................ ................................ ................  52 \\n3.1.4.3  standict.eu project, 2019  ................................ ................................ .... 53 \\n3.1.4.4  oecd, 2018  ................................ ................................ ...................  54 \\n3.1.4.5  etsi, 2018 ................................ ................................ .....................  55 \\n3.1.4.6  oecd, 2017  ................................ ................................ ...................  56 \\n3.1.4.7  world economic forum, 2017  ................................ ...............................  57 \\n3.1.4.8  iso, 1993; 1995; 2015  ................................ ................................ ....... 58 \\n3.2 research perspective  ................................ ................................ .......................  59 \\n3.2.1  tsinghua university, 2018  ................................ ................................ .........  59 \\n3.2.2  kaplan and haenlein, 2018  ................................ ................................ ........  60 \\n3.2.3  poole et al., 2017; 2010; 1998  ................................ ................................ .... 61 \\n3.2.4  kaplan, 2016  ................................ ................................ ........................  63 \\n3.2.5  stone et al.: ai100, 2016  ................................ ................................ ...........  64 \\n3.2.6  russel and norvig, 2010 (3rd edition); 1995  ................................ .....................  65 \\n3.2.7  bruner, 2009  ................................ ................................ ........................  66 \\n3.2.8  mccarthy, 2007  ................................ ................................ .....................  67 \\n3.2.9  gardner, 1999  ................................ ................................ .......................  68 \\n3.2.10  nakashima, 1999  ................................ ................................ ...................  69 \\n3.2.11  nilsson, 1998  ................................ ................................ .......................  70 \\n3.2.12  neisser et al., 1996  ................................ ................................ .................  71 \\n3.2.13  fogel, 1995  ................................ ................................ .........................  72 \\n3.2.14  wang, 1995  ................................ ................................ .........................  73 \\n3.2.15  albus, 19 91 ................................ ................................ .........................  74 \\n3.2.16  schank, 1991; 1987  ................................ ................................ ................  75 \\n3.2.17  mccarthy, 1988  ................................ ................................ .....................  76 \\n3.2.18  gardner, 1987  ................................ ................................ .......................  77 \\n3.2.19  gardn er, 1983  ................................ ................................ .......................  78 \\n3.2.20  newell and simon, 1976  ................................ ................................ ...........  79 \\n3.2.21  minsky, 1969  ................................ ................................ ........................  80 ',\n",
       " ' \\niii 3.2.22  mccarthy, 1959  ................................ ................................ .....................  81 \\n3.2.23  mccar thy et al., 1955  ................................ ................................ ...............  82 \\n3.3 market perspective  ................................ ................................ .........................  83 \\n3.3.1  cb insights, 2019  ................................ ................................ ...................  83 \\n3.3.2  statista, 2017  ................................ ................................ .......................  84 \\n3.3.3  mckinsey, 2017  ................................ ................................ .....................  85 \\n4 conclusions ................................ ................................ ................................ ........  86 \\nreferences  ................................ ................................ ................................ ............  87 \\nlist of tables  ................................ ................................ ................................ ..........  90 ',\n",
       " ' \\n1 foreword  \\nthis report is published in the context of ai watch, the european commission knowledge service to monitor \\nthe development, uptake and impact of artificial intelligence (ai) for europe, launched in december 2018.  \\nai has become an area of strategic importance with potential to be a key driver of economic development. ai \\nalso has a wide range of potential social implications. as part of its digital single marke t strategy, the \\neuropean commission put forward in april 2018 a european strategy on ai in its communication \"artificial \\nintelligence for europe\" com(2018)237. the aims of the european ai strategy announced in the \\ncommunication are:  \\n● to boost the eu\\'s techn ological and industrial capacity and ai uptake across the economy, both by \\nthe private and public sectors  \\n● to prepare for socio -economic changes brought about by ai  \\n● to ensure an appropriate ethical and legal framework.  \\nsubsequently, in december 2018, the e uropean commission and the member states published a “coordinated \\nplan on artificial intelligence”, com(2018)795, on the development of ai in the eu. the coordinated plan \\nmentions the role of ai watch to monitor its implementation.  \\nai watch monitors europe an union’s industrial, technological and research capacity in ai; ai -related policy \\ninitiatives in the member states; uptake and technical developments of ai; and ai impact. ai watch has a \\neuropean focus within the global landscape. in the context of ai wa tch, the commission works in coordination \\nwith member states. ai watch results and analyses are published on the ai watch portal \\n(https://ec.europa.eu/knowledge4policy/ai -watch_en ). \\nfrom ai watch in -depth analyses we will be able to understand better european union’s areas of strength and \\nareas where investment is needed. ai watch will provide an independent assessment of the impacts and \\nbenefits of ai on growth, jobs, education, and society.  \\nai watch is developed by the joint research centre (jrc) of the european commission in collaboration with \\nthe directorate ‑general for communications networks, content and technology (dg connect). this report \\naddresses the following objectives of ai watch:  developing an overview and analysis of the european ai \\necosystem.  ',\n",
       " \" \\n2 acknowledgements  \\nthe following researchers constitute the panel of experts that provided valuable comments and useful \\ncritiques for this work (in alphabetical order): virginia dignum (umeå university and high level expert group \\non ai), anders jonsson (universitat pompeu fabra), henrik junklewitz (joint research centre's cyber & digital \\ncitizens' security unit), ramón lópez de mántaras (artificial intelligence research institute (iiia -csic)),  josé \\norallo (valencian research institute for artificial intelligence (universitat politècnica de valència)), ignacio \\nsánchez (joint research centre's cyber & digital citizens' security unit). the authors would also like to \\nacknowledge the contributions f rom several colleagues. the authors are grateful to antonio puente and \\nmariana popova (dg cnect) for their comments. in addition, the authors are plenty grateful to alessandro \\nannoni, paul desruelle, gianluca misuraca, stefano nativi and miguel vázquez -prada baillet (jrc -digital \\neconomy unit) for their useful suggestions and support during the whole process.  \\n \\nauthors  \\nsamoili , sofia \\nlópez -cobo , montserrat  \\ngómez , emilia \\nde prato , giuditta  \\nmartínez -plumed , fernando  \\ndelipetrev , blagoj \\n \",\n",
       " ' \\n3 abstract  \\nthis report proposes an operational definition of artificial intelligence to be adopted in the context of ai \\nwatch , the commission knowledge service to monitor the development, uptake and impact of artificial \\nintelligence for europe. the definition , which  will be used as a basis for the ai watch  monitoring activity, is \\nestablished by means of a flexible scientific methodology that allows regular revision. the operational \\ndefinition is constituted by a concise taxonomy and a list of keywords that characteris e the core domains of \\nthe ai research field, and transversal topics such as applications of the former or ethical and philosophical \\nconsiderations , in line with the wider monitoring objective of ai watch . the ai taxonomy is designed to inform \\nthe ai landsc ape analysis and will expectedly detect ai applications in neighbour technological domains such \\nas robotics  (in a broader sense) , neuroscience or internet of things.  the starting point to develop the \\noperational definition is the definition of ai adopted b y the high level expert group on artificial intelligence.  \\nto derive this operational definition we have followed a mixed methodology. on one hand, we apply natural \\nlanguage processing methods to a large set of ai literature. on the other hand, we carry out  a qualitative \\nanalysis on 5 5 key documents including artificial intelligence definitions from three complementary \\nperspectives: policy, research and industry.  \\na valuable contribution of this work is the collection of definitions developed between 1955 an d 2019, and \\nthe summarisation of the main features of the concept of artificial intelligence as reflected in the relevant \\nliterature.  ',\n",
       " ' \\n4 executive summary  \\nthis report proposes a taxonomy for artificial intelligence (ai)  and a list of related keywords,  as an o perational \\ndefinition for ai in the framework of the ai watch , the commission’s knowledge service to monitor the \\ndevelopment, uptake and impact of artificial intelligence for europe. ai watch  aims to monitor the industrial, \\ntechnological and research capac ity, as well as policy initiatives in the member states, uptake and technical \\ndevelopments of ai and its impact. ai watch  has a european focus within the global landscape and covers all \\nmember states. the established operational definition will be used as a basis for the ai watch  monitoring \\nactivity. the ai taxonomy will assist in the mapping of the ai landscape, and it  is expected to detect ai \\napplications in  other technological domains such as robotics  (in a wider sense) , big data, web technologies, \\nhigh performance computing, embedded systems, internet of things, etc.   \\nthe need to establish an operational definition proceeds  from the absence of a mutually agreed definition \\nand taxonomy of ai, which would impede the attainment of the wide monitoring objective of ai watch . it is in \\nthis basis that we propose a multi -perspective analysis to structure the ai taxonomy . in particul ar we provide \\na unique taxonomy that represents and interconnects all the ai subdomains from political, research and \\nindustrial perspective. in this scope, the taxonomy reflects these perspectives and aims to cover the entire ai \\nlandscape, which consists o f economic agents with r&d or industrial ai activities. moreover, c onsidering that \\nai is a dynamic field, we propose an iterative method that can be updated over time to capture the rapid ai \\nevolution, and that provides a taxonomy and a set of keywords. th e method consists of the following steps: (i) \\nqualitative analysis of ai definitions and subdomains emanating from reports with academic, industrial and \\npolicy perspective s, (ii) selection of definition, identification of representative keywords in ai with  a natural \\nlanguage processing method, and taxonomy formation, and (iii) taxonomy and keywords validation.  \\nin the first part of the method , the objective is to collect and analyse the existing definitions and identify the \\nmain subdomains covering all aspec ts in the ai field. in this scope, we conduct a qualitative analysis in a \\nselected set of 29 ai policy and institutional reports (including standardisation efforts , national strategies, and \\ninternational  organisations reports ), 23 relevant research publica tions and 3 market reports, from the \\nbeginning of ai in 1955 until today. ai has been usually described in relation to human intelligence, or \\nintelligence in general , with many definitions refer ring to machines that behave like humans or are capable of \\nactions that require intelligence. since human intelligence is also difficult to define and measure, and \\nalthough there have been different attempts of quantification, the objective definition of something as \\nsubjective and abstract as intelligence, falsely g ives the impression of a precision that cannot be obtained. as \\na consequence, most definitions found in research, policy or market reports are vague and propose an ideal \\ntarget rather than a measurable research concept. the study of the definitions found i n literature leads us to \\nidentify four characteristics that are commonly mentioned in ai: i) perception of the environment and real-\\nworld complexity , ii) information processing : collecting and interpreting inputs , iii) decision making, including \\nreasoning, learning and taking actions; and iv) achievement of pre-defined goals . taking into consideration \\nthese features, we consider the definition proposed by the hleg on ai as the starting point in developing the \\nopera tional definition in ai watch : \"artificial intelligence (ai) systems are software (and possibly also \\nhardwar e) systems designed by humans  that, given a complex goal, act in the physical or digital dimension by \\nperceiving their environment through data acqu isition, interpreting the collected structured or unstructured \\ndata, reasoning on the knowledge, or processing the information, derived from this data and deciding the best \\naction(s) to take to achieve the given goal. ai systems can either use symbolic rul es or learn a numeric model, \\nand they can also adapt their behaviour by analysing how the environment is affected by their previous \\nactions.\" (hleg, 2019) . \\nalthough it may be considered highly technical for different audiences and objectives, it is a very \\ncomprehensive definition , which incorporates the aspects of perception, understanding, interpretation, \\ninteraction, decision making, adaptation to behaviour and achievement of goals, whereas other definitions do \\nnot address them in their entirety. consider ing that the hleg definition is comprehensive, hence highly \\ntechnical and detailed, less specialised definitions can be adopted for studies of different objective, such as \\nenterprise surveys. in this scope, the definitions provided by the ec jrc flagship r eport on ai (2018) and the \\neuropean ai strategy (com(2018) 237 final), or the one to be used in the ai module of the community survey \\non ict usage and e -commerce in enterprises 2021, are suitable alternatives.  \\nregarding the ai subdomains, we found that des pite the multiple facets of ai, and consequently the lack of a \\ncommon definition and taxonomy among research communities, literature or reports, there are a number of \\ncommon topics in the definitions and taxonomies analysed for this study. in particular , in order to establish \\nthe taxonomy, in addition to  the assessment of the aforementioned set of documents, we explored the \\ninformation provided by the official publication of the association for the advancement of artificial ',\n",
       " \" \\n5 intelligence (aaai) (aitopics.org ), and several top ai conferences. the proposed ai taxonomy , as a list of \\nrepresentative core and transversal ai domains  and subdomains , will assist us to classify r&d and industrial \\nagents  and their activities . therefore, it encompass es main theoretical ai scientific areas , and ai related non -\\ntechnological issues  from industrial and r&d ai activities , as well as ethical and philosophical issues. it \\nremains linked  to the hleg definition of ai in the context of ai watch . the proposed taxon omy follows : \\n \\n  ai taxonomy  \\n  ai domain  ai subdomain  \\ncore reasoning  knowledge representation  \\nautomated reasoning  \\ncommon sense reasoning  \\nplanning  planning and scheduling  \\nsearching  \\noptimisation  \\nlearning  machine learning  \\ncommunication  natural language processing  \\nperception  computer vision  \\naudio processing  \\ntransversal  integration and \\ninteraction  multi -agent systems  \\nrobotics and automation  \\nconnected and automated vehicles  \\nservices  ai services  \\nethics and philosophy  ai ethics  \\nphilosophy of ai  \\nsource: authors' elaboration    \\n \\nto complete the operational definition of ai, a  list of keywords representative of the ai subdomains  is \\nestablished based on a part of the techno -economic segments (tes) analytical approach that will provide at a \\nlater stage an overview of the ai landscape worldwide. the keywords are used in text queries to identify \\nactivities and economic agents relevant  to ai, for their further analysis. the list of keywords is the result of a \\nmulti -step process combining a semi -automatic text mining approach, desk research and domain experts' \\ninvolvement. more specifically, the top keywords from a vast collection of  journals in ai are identified though \\ntext mining in the scopus database in three different years , from which the most frequent author’s keywords \\nper year are selected. similarly, the industrial aspect is addressed by extracting keywords from firms’ \\ndescriptio ns. subsequently, the initial list of keywords is reviewed by ai experts and a short selection is made. \\na topic modelling is then performed, so as to detect the most representative topics and terms without the \\ninvolvement of any expert that might induce un intentional bias. the initial list and the list resulting from the \\ntopic modelling step are merged and any redundancies are removed. external domain experts from several ai \\nsubdomains review the list and advise on synonyms that need to be grouped and on ta rgeting subdomains \\nthat may not be sufficiently captured by the initial sources. the taxonomy and list of keywords is then \\nvalidated and finalised.  \\nvaluable contribution s of this work are: the collection of definitions developed between 1955 and 2019; the \\nsummarisation of the main features of the concept of artificial intelligence as reflected in the relevant \\nliterature ; and the development of a replicable process that can provide a dynamic definition and taxonomy of \\nthe ai.    \",\n",
       " ' \\n6 1 introduction  \\nai has become a n area of strategic importance and been identified as a potential key driver of economic \\ndevelopment as underlined in the european strategy on ai (com (2018) 237 on artificial intelligence for \\neurope) and in the related coordinated plan (com(2018)795). sim ilarly, ai has become a clear target for \\nnational governments resulting in the formulation of national ai strategies. ai watch  is the commission \\nknowledge service to monitor the development, uptake and impact of artificial intelligence  (ai) for europe , \\nlaunched in december 2018 . it will monitor industrial, technological and research capacity, policy initiatives in \\nthe member states, uptake and technical developments of ai and its impact. ai watch  has a european focus \\nwithin the global landscape and covers a ll member states.  \\nthe aim of this document  is to establish an operational definition of ai formed by a concise taxonomy and a \\nset of keywords that characterise the core and transversal domains  of ai. the operational definition is  based \\non a concrete  and inclusive definition of ai . such a taxonomy and keywords will assist the  mapping  of the ai \\necosystem of interrelated economic agents, and will allow to describe their technological areas of \\nspecialisation. also , it will expectedly  overlap with other technological domains such as robotics  (in a broader \\nsense) , big data, web technologies, high performance computing, embedded systems, internet of things, etc.  \\nthe operational definition will be used as a basis for the monitoring activity and will serve as  a reference for \\nthe other ai watch  outputs. this objective results from the need to monitor the implementation of the ec \\ncoordinated plan on ai on an annual basis, as reflected in the communication1. \\nthis work has been organised in a three step strategy a s follows:  \\n— review of existing definitions . we review ai definitions found in a selected set of 55 documents: 29 ai \\npolicy and institutional reports, 2 3 relevant research publications and 3 market reports , in order to \\nincorporate academic, industrial and corporate perspectives . \\n— definition selection , taxonomy formation  and representative keywords selection : we then \\nadopt, based on this review, a general definition of ai and we complement this with a taxonomy and \\nkeywords that characterise  the ai domain. the  keywords are extracted based on automatic text analysis \\nof a corpus of ai scientific references, firm -level databases, and industrial activity documents , \\ncomplemented by desk research and domain experts\\' involvement.  \\n— definition  and taxonomy  validation : we validate our approach with a small number of ai experts.  \\nsince ai is a dynamic field, the described  process  is planned to be dynamic . this taxonomy  and keywords \\nbuilding process will be  reviewed and iterated in the future  to capture the rapid evolution of ai . \\nthe rest of the report is organised as follows: section  2 presents the ai definition , together with its \\noperationalisation in the form of a  taxonomy and list of keywords , as well as a description of the process. \\nsection  3 provides detailed information  about the 5 5 documents analysed, including the source, the text of \\nthe definition a nd ai subdomains -when available -, contextual information about the source and the \\ndocument itself, and the date of publication . finally , section  4 presents the conclusions drawn from this study.  \\n                                                 \\n1  footnote 19 of the annex: \"ai watch developed by the joint research centre will contribute to monitoring ai -related development \\nand will provide a number of analyses necessary to support the implementation of the european ai initiative. among others it will \\ndevelop ai indexes addressing all dimensions relevant for policy making. such information will be made available at the ai watch \\nportal https://ec.europa. eu/knowledge4policy/ai -watch_en \". ',\n",
       " ' \\n7 2 proposal for a common definition on artificial i ntelligence  \\nto establish an operational  ai definition  to be adopted in ai watch , composed by  a taxonomy and \\nrepresentative  keywords , we propose a 3 -layer approach  that allows the dynamic update of all the \\naforementioned . this approach consists of the following layers : \\ni. ai definition selection ,  \\nii. taxonomy formation  with core and transversal ai subdomains , \\niii. pertinent keyword selection  for each  subdomain of the taxonomy . \\nin this scope , we consider  55 documents that address the ai domain from different perspectives, \\nacknowledging three complementary approaches under which ai is considered:  \\n— the policy and institutional perspective , which is especially relevant for the objective of this work given \\nthe scope in which the ai definitio n is to be used, focus es on the development of the industry, the \\nresearch capacity, and the impact on society of advanced technologies. this approach considers ai as an \\ninstrument for growth and technological development. we have collected and analysed doc uments from \\nthe european commission, national strategies  and policy documents  (european and non -european) , as \\nwell as  other international institutions such as the oecd, unesco , world economic forum, iso, etc.;  \\n— the research perspective , which is the unders tanding of ai as a research field and its development as a \\ngeneral purpose technology;  \\n— the market perspective , which has a strong focus on industrial development and assessment of the \\neconomic value and future market prospects.  \\nthe simultaneous  consideration of the three approaches provides an overview of the past and current \\nperceptions of ai and how the concept evolves over time. all the collected documents provide a n ai definition, \\nor identify or describe core and transversal ai subdomains, most of the documents present both types of \\ninformation. these were analysed in order to identify the main aspects specified as ai features, as well as the \\ncore and transversal ai subdomains, so as  to propose an operational definition and ta xonomy  that is  useful \\nfor the objectives of ai watch . the thorough investigation of the concept from an ontological perspective and \\nthe analysis of the evolution of ai as a concept and research field remain out of the scope of this study. the \\ndetails of th e explored  definitions  can be found in section  3. table 3 offers a collection of the definitions and \\nai subdomains covered, as provided in the original documents .  \\n2.1 ai definition s \\ndespite the increased interest in  ai by the academia, industry and public institutions, there is no standard \\ndefinition of what ai actually involves. ai has been described  by certain approaches  in relation to human \\nintelligence, or intelligence in general. many definitions refer to machines that beh ave like humans or are \\ncapable of actions that require intelligence (us ndaa, 2019; russel and norvig, 1955; mccarthy, 2007; \\nnilsson, 1998; fogel, 1995; albus, 1991; luger and stubblefield, 1993; winston, 1992; mccarthy, 1988; \\ngardner, 1987; 1983; newell a nd simon, 1976; bellman, 1978; minsky, 1969; mccarthy et al., 1955 ). since \\nhuman intelligence is also difficult to define and measure, and although there have been different attempts \\nof quantification (gardner, 1983; 19 87; neisser et al., 1996 ), the object ive definition of something as \\nsubjective and abstract as intelligence (kaplan, 2016 ) falsely gives the impression of a precision that cannot \\nbe obtained. as a consequence, most definitions found in research, policy or market reports are vague and \\npropose an ideal target rather than a measurable research concept.  \\nthe oversimplification of the concept of intelligence that is needed in order to define, or even develop, ai is \\nillustrated by russel and norvig (1985; 2010) and emphasised by the high level exper t group on a rtificial \\nintelligence  (hleg, 2019) when focusing on rational ai and hence considering benchmark against an ideal \\nperformance. \"a system is rational if it does the “right thing”, given what it knows\" (russel and norvig, 1985; \\n2010 ). \\ntwo activities are especially considered in this study when analysing ai definitions: existing standardisation \\nefforts, and the contribution of the high -level expert group on artificial intelligence.  \\n  ',\n",
       " \" \\n8 standardisation efforts  \\nin order to collect information o n the standardisation of ai and its applications , the international organization \\nfor standardization (iso) is included in the analysis . currently the available ai definitions are found in the \\niso/iec 2382 of 2015, established in 1993 and 1995. in 2018 , in an effort  to update these definitions, two \\nsub committees with six working groups and one study group are formed with the goal to develop 10 ai \\nstandards for iso/iec. the iso/iec jtc1/sc42 is the first international standards committee identifying the \\nentire ai ecosystem. jtc1’s scope for sc42 is to become “a systems integration entity to work with other iso, \\niec and jtc 1 committees looking at ai applications”. until may 2019, three standards are published with a \\ndifferent objective; hence an ai definition  is not included.  \\nthe high -level expert group on artificial intelligence  \\nthe high -level expert group (hleg) on artificial intelligence has been appointed by the european commission \\nwith the main aim to support the implementation of the european ai strategy. this includes the elaboration of \\nrecommendations on future -related policy developments and on ethical, legal and societal issues related to \\nai, including socio -economic challenges. the hleg on ai is composed by 52 representatives from academia, \\ncivil society and industry. the first two outputs of the hleg on ai are the ethics guidelines for trustworthy \\nartificial intelligence2, and a definition of ai3 developed to describe a common understanding of the domain \\nand its capabilities, and serving as a  supporting document for the hleg's deliverables. the hleg definition is \\nconsidered together with the remaining documents analysed in this study.  \\ncommon features in ai definitions  \\ndespite the multiple facets of ai, and consequently the lack of a common def inition, there are a number of \\ncommonalities that we observe in the analysed definitions. this expression of common aspects suggests that \\nthey may be considered as the main features of ai:  \\n— perception of the environment , including  the consideration of the real world complexity (hleg, 2019; \\neuropean ai strategy, 2018; ec jrc flagship report on ai, 2018; tsinghua university, 2018; nakashima, \\n1999; nilsson, 1998; poole et al., 1998; fogel, 1995; wang, 1995; albus, 1991; newell and simon, 1976).  \\n— information pro cessing: collecting and interpreting inputs (in form of data) (hleg, 2019; european ai \\nstrategy, 2018; ec jrc flagship report on ai, 2018; kaplan and haenlein, 2018; tsinghua university, \\n2018; nakashima, 1999; nilsson, 1998; poole et al., 1998; wang, 1995) . \\n— decision making (including reasoning and learning): taking actions, performance of tasks (including \\nadaptation, reaction to changes in the environment) with certain level of autonomy (hleg, 2019; oecd, \\n2019; european ai strategy 2018; ec jrc flagship rep ort on ai 2018; kaplan and haenlein 2018; \\ntsinghua university, 2018; nilsson, 1998; poole mackworth and goebel, 1998; fogel, 1995; iso/iec 2382 -\\n28, 1995; wang, 1995; albus, 1991; newell and simon, 1976).  \\n— achievement of specific goals: this is considered as  the ultimate reason of ai systems (hleg 2019; oecd, \\n2019; european ai strategy , 2018; kaplan and haenlein, 2018; poole at al., 1998; fogel, 1995; albus, \\n1991; newell and simon, 1976).  \\n2.2 ai watch  operational definition  of ai \\nthe proposed ai watch  operational definition is based on a concrete definition  taken as a starting point , and is \\ncomposed by  a concise taxonomy and a set of keywords that characterise the core and transversal domains  \\nof ai. to reach a common understanding o n the concept of ai in the framework  of ai watch , it is important \\nthat the starting point is an inclusive definition , hence covering all technological developments and activities \\ncarried out by all types actors that make up the ai  ecosystem , whether industrial, research, gove rnment \\ninitiatives . taking into consideration the features that many of the explored definitions share (see table 3), as \\nwell as the afore mentioned objective s, we consider the definition proposed by the hleg on ai  as the \\nstarting point for the  develop ment of  the operational definition . although it may be co nsidered highly \\ntechnical for different audience s and objectives , it is a very comprehensive definition which incorporates the \\naspects of perception, understanding, interpretation, interaction, decision making, adaptation to behaviour and \\nachievement of go als, whereas other definitions do not address  them  in their entirety : \\n                                                 \\n2  ec.europa.eu/newsroom/dae/document.cfm?doc_id=58477  \\n3  ec.europa.eu/newsroom/dae/document.cfm?doc_id=56341  \",\n",
       " ' \\n9 hleg definition of ai  \\n\"artificial intelligence (ai) systems are software (and possibly also hardware) systems designed by humans (2) \\nthat, given a complex goal, act in the physical or digital dimension by perceiving their environment through \\ndata acquisition, interpreting the collected structured or unstructured data, reasoning on the knowledge, or \\nprocessing the information, derived f rom this data and deciding the best action(s) to take to achieve the given \\ngoal. ai systems can either use symbolic rules or learn a numeric model, and they can also adapt their \\nbehaviour by analysing how the environment is affected by their previous actio ns.\" \\nother suitable definitions  targeted to alternative  uses \\nconsidering that the hleg definition is comprehensive, hence highly technical and detailed, less specialised \\ndefinitions can be adopted for studies of different objective, such as enterprise surv eys. in this scope, the \\ndefinitions provided  by the ec jrc flagship report on ai (2018) (see detailed reference in subsection  3.1.1.4 ) \\nand the european ai strategy (c om(2018) 237 final, see subsection  3.1.1.3 ) are suitable alternatives : \\nec jrc flagship report on ai  \\n“ai is a generic term that refers to any machine or algorithm that is capable of observing its environment, \\nlearning, and based on the knowledge and experience gained, taking intelligent action or proposing decisions. \\nthere are many different technologies that fall under this broad ai definition. at the moment, ml 4 techniques \\nare the most widely used.”  \\neuropean ai strategy  \\n\"artificial intelligence refers to systems that display intelligent behaviour by analysing their environment and \\ntaking action — with some degree of autonomy — to achieve specific goals. \" \\nthe latter  has been considered by eurostat as the starting point for the development of a definition that will \\nbe included in  the ai module of the community survey on ict usage and e -commerce i n enterprises  2021 \\nupon approval.  \\ncommunity survey on ict usage and e -commerce in enterprises 2021  \\n“artificial intelligence refers to systems that use technologies such as: text mining, computer vision, speech \\nrecognition, natural language generation, machine learning, deep learning to gather and/or use data to predict, \\nrecommend or decide, with varying levels of autonomy, the best action to achieve specific goals.”  \\n2.2.1  ai taxonomy  \\nthe proposed taxonomy addresses political, research and industrial perspectives and aims to cover  and \\nclassify  the ai landscape , which  consists of  economic agents with r&d or industrial ai related activities. \\ntherefore, this taxonomy is able to detect correspondingly a wide range of core ai related scientific \\nsubdomains (e.g. knowledge representation and reasoning, machine learning) and transversal  topics such as \\napplications of the former (e.g. robots, automated vehicles , etc.) or ethical and philosophical considerations . \\nthe taxonomy is presented as a reduced list of abstract high level domains and their related subdomains. \\nthese are meant to  encompass the main theoretical ai branches , as well as ai related non -technological \\nissues. the ai subdomains are represented by a list of keywords (see subsection 2.2.2 ), these will enable us to \\ncapture the ai activities carried out by economic agents, for further analysis of the ai landscape from a \\ntechno -economic perspective.  \\n2.2.1.1  sources  \\nthe ai field allows several classification approaches and correspon ding divisions in specific subdomains or \\ntopics. it should be noted again that  there is no commonly agreed ai taxonomy among research communities, \\nliterature or reports, given the rapid  evolution of this knowledge domain and varied perspectives from which \\nai is considered. for this part of the study , we have analysed existing taxonomies and attempts to disentangle  \\nthe ai knowledge domain. we have explored the following sources:  \\n  \\n                                                 \\n(4)    machine learning  ',\n",
       " ' \\n10 — aitopics5: this website is an official publication of the association for the advancement of artificial \\nintelligence (aaai), presenting in ordered way information about ai. the information gathered covers \\ndifferent dimensions: research (through journals and conference s), ai applications, authors; and different \\ntypes of sources: papers, news, tweets, etc. the documents analysed are tagged -combining machine \\nlearning with subject matter expert knowledge - and classified according to two main dimensions: \\ntechnological and industrial, that is considering the economic sector in which ai is developed and/or used. \\nwe focus on the technology break down provided by this source. the following ai related fields are \\nconsidered by aitopics under ai: assistive technologies, cognitive science, games, human -centered \\ncomputing, machine learning, natural language, representation & reasoning, robots, speech, systems & \\nlanguages, vision, together with other less technology related : challenges,. issues, history, science \\nfiction, the future6.  \\n— specialised conferences: we explore the top ai conferences in order to identify submission groups as \\nproxies of the main current in research sub -fields. the following conference submission groups have been \\nconsidered:  \\no aaai5: ai and the web, applications , cognitive modeling, cognitive systems, computational \\nsustainability and ai, game theory and economic paradigms, game playing and interactive \\nentertainment, heuristic search and optimization, human -ai collaboration, human -computation \\nand crowd sourcing, h umans and ai, knowledge representation and reasoning, machine \\nlearning applications, machine learning methods, multiagent systems, natural language \\nprocessing ( nlp) and knowledge representation, nlp and machine learning, nlp and text \\nmining, planning and s cheduling, reasoning under uncertainty, robotics, search and constraint \\nsatisfaction, vision.  \\no international joint conferences on artificial intelligence (ijcai) : \\n\\uf0a7 2009: agent -based and multi -agent systems, multidisciplinary topics and applications, \\nrobotics  and vision, natural -language processing, knowledge representation, \\nreasoning and logic, constraints, satisfiability, and search, planning and scheduling, \\nuncertainty in ai, machine learning, web and knowledge -based information systems.  \\n\\uf0a7 2018: agent -based a nd multi -agent systems, computer vision, constraints and sat, \\nheuristic search and game playing, humans and ai, knowledge representation and \\nreasoning, machine learning, machine learning applications, multidisciplinary topics \\nand applications, natural lang uage processing, planning and scheduling, robotics, \\nuncertainty in ai.  \\n— documents analysed for this study  (section 3): we also acknowledge the ai subdomains mentioned in the \\npolicy, research and market reports. a summary of the main ai subdomain s listed in all the documents \\nfollow  (subsection  2.3). additionally, we analysed the taxonomy and keywords developed by the working \\ngroup drafting the spanish strategy on ai 7: machine learning, natural language pr ocessing, computer \\nvision and perception, knowledge representation and reasoning, multiagent systems, data science, \\nother.  \\n— moreover, this top -down approach is complemented with a bottom -up approach that converges with the \\ntaxonomy. in the early results of  this approach we used a natural language processing method (topic \\nmodelling) to unbiasedly identify thematic subdomains in a collection of more than 64 thousand \\nindustrial and r&d ai activities. this resulted in the identification of six thematic subdomai ns (machine \\nlearning, computer vision, natural language processing, connected and automated vehicles, robotics, and \\nai services), which have a correspondence in the proposed taxonomy.  \\n  \\n                                                 \\n(5)  aitopics.org  \\n(6)  additionally, some of the documents collected are classified under other main technological fields such as architecture, ente rprise \\napplication, information management, sensing and signal processing, among others.  \\n(5)  aaai 2018  \\n(7)  coordinated by professor ramón lópez de mántaras  (iiia-csic) , who acted also as advisor in this study.  ',\n",
       " \" \\n11 2.2.1.2  ai watch  taxonomy  \\nin accordance to the hleg, ai techniques and sub-disciplines can be grouped under two big strands regarding \\nthe systems' capabilities: (i) reasoning and decision making, (ii) and learning  and perception . the first group of \\ncapabilities includes the transformation of data into knowledge, by transformi ng real world information into \\nsomething understandable and usable by machines, and making decisions following an organised path of \\nplanning, solution searching and optimisation. this strand cover s the ai subdomain s of knowledge \\nrepresentation and reasonin g (usually making use of symbolic rules to represent and infer  knowledge ) and \\nplanning (including planning & scheduling, searching, and optimisation ). the second group of capabilities \\ndevelops in absence of symbolic rules, and involves learning -meaning th e extraction of information, and \\nproblem solving  based on structured or unstructured perceived data (written and oral language, image, sound, \\netc.)-, adaptation and reaction to changes, behavioural prediction, etc. this second strand covers ai sub -fields \\nrelated to learning, communication and perception, such as machine learning, natural language processing, \\nand computer vision.  \\nthe academic approach followed by the hleg is to be complemented by considering the wider monitoring \\nobjective of ai watch , namely to capture and measure the ai landscape that involves multifarious economic \\nagents and complementary approaches, considering also the impact on society. consequently, the taxonomy \\nproposed is based on the main ai domains identified by the hleg and  is expanded to cover additional \\ndimensions:  \\n— the concept of rational agents, as entities that make decisions and act in relation to its environment, \\nincluding interaction with other agents ; \\n— research and industrial developments, and other ai applications s uch as cloud service models offered by \\nservice companies to accelerate ai uptake ; \\n— other noteworthy aspects related to ai, but not necessarily technology related, arise as important subjects \\nin policy documents and the social debate: ethical considerations such as transparency, explainability, \\naccountability, fairness and safety , as well philosophical matters involving the deepest nature of ai and \\nits evolution .  \\ntaking into consideration the above, we propose the following ai domains and subdomains as characterising \\nthe ai field. they are divided into core and transversal domains, the former referring to the fundamental \\ngoals of ai, the latter not specifically related to a particular academic discipline or area of knowledge , but as \\nissues common to a ll the core domains.  \\ntable 1. ai domains and subdomains constituting  one part of  the operational definition of ai  \\n  ai taxonomy  \\n  ai domain  ai subdomain  \\ncore reasoning  knowledge representation  \\nautomated reasoning  \\ncommon sense reasoning  \\nplanning  planning and scheduling  \\nsearching  \\noptimisation  \\nlearning  machine learning  \\ncommunication  natural language processing  \\nperception  computer vision  \\naudio processing  \\ntransversal  integration and \\ninteraction  multi -agent systems  \\nrobotics and automation  \\nconnected and automated vehicles  \\nservices  ai services  \\nethics and philosophy  ai ethics  \\nphilosophy of ai  \\nsource: authors' elaboration    \",\n",
       " ' \\n12 it is noteworthy that the suggested domains and subdomains  are related, and not disjoint, subsets of ai. this \\nensues from the nature of the ai field that embraces intertwined applications and theoretical advancements, \\nwith fuzzy boundaries. for instance, the fact that machine learning is exploited in either compu ter vision , \\naudio processing or  natural language processing does not prevent them from being separate research fields, \\nconsidered by top ai conferences topics and related literature (see subsection 2.2.1.1). at the same time, \\ncomputer vision and natural la nguage processing are in turn embedded in more complex applications, such as \\nvirtual personal assistants  or robotic platforms. following this continuum, we consider theoretical \\nadvancements in one end of the taxonomy and industrial applications in the othe r one. we should also stress \\nthat the defined subdomains may not be fully ai -driven. for instance, while mechanical robots do not always \\nincorporate ai techniques, robotics is considered as a relevant domain impacted by recent developments in ai \\ntechniques . \\nin conclusion , the ai watch  taxonomy is not meant to constitute a  rigid classification , but a comprehensive \\ncollection of areas  that represents ai from our three target perspectives: policy, research and industry.   \\nin the following, we succinctly describe the above domains and subdomains , highlighting their identification  in \\ndifferent ai national strategies and reports.  \\ndomain: reasoning  \\nsubdomains: knowledge representation ; automated reasoning; common sense reasoni ng \\nthe domain of reasoning tackles the way machines transform data into knowledge, or infer facts from data. \\nseveral classifications address knowledge representation and  automated  reasoning as a field of ai, to \\ndescribe the process of justifying (reasoning ) the available data and information, provide solutions and \\nrepresent them efficiently, based on a set of symbolic rules (hleg, 2019; spanish rdi strategy in artificial \\nintelligence, 2019; national strategy : france  monitoring report, 2019 ; cb insights, 2019; ai national strategy: \\ngermany, 2018; working paper for national strategy: india, 2018; etsi, 2018; national strategy: france \\n(villani mission), 2018;  ai national strategy: china, 2017; mccarthy, 2007; nilsson, 1998 ). \\ndomain: planning  \\nsubdomains: planning and scheduling; searching; optimisation  \\nthe main purpose of automated planning concerns the design and execution  of strategies (e.g., an organi sed \\nset of actions) to carry out some activity, and typically performed  by intelligent agents, autonomous robots \\nand unmanned vehicles. unlike classical control and classification problems, the solutions are complex and \\nmust be discovered and optimi sed in the multidimensional space. (hleg, 2019; spanish rdi strategy in \\nartificial intelligence, 2019; national strategy: france monitoring report, 2019 ; cb insights, 2019; ai national \\nstrategy: germany, 2018; mccarthy, 2007 ). \\ndomain: learning  \\nsubdomains:  machine learning (ml)  \\nby learning, we refer to the ability of systems to auto matically learn, decide, predict, adapt and react to \\nchanges, improving from experience, without being explicitly programmed. ml is widely included in the vast \\nmajority of efforts to identify ai categories, as the basic algorithmic approach to achieve ai r egardless the \\ntype of learning, namely reinforcement, supervised, semi -supervised, unsupervised  (hleg, 2019; spanish rdi \\nstrategy in artificial intelligence, 2019; standict.eu project, 2019; national strategy: denmark, 2019; national \\nstrategy: france monitoring report, 2019;  australia’s ethic framework dawson et al., 2019;  us congressional \\nresearch service, 2019; cb insights, 2019; ec jrc flagship report on ai, 2018; ai national strategy: germany, \\n2018; oecd, 2018; tsinghua university, 2018; working pa per for ai national strategy: india, 2018; national \\nindustrial strategy: uk, 2018;  2017;  ai national strategy: france (villani mission), 2018; us department of \\ndefense, 2018; oecd, 2017; mckinsey, 2017; stone et al.: ai100, 2016 ; mccarthy, 2007 ).  \\ndomain: communication  \\nsubdomains:  natural language processing (nlp)  \\nnlp, as the main task of communication, refers to the machine’s ability to identify, process, understand \\nand/or generate information in written and spoken human communications. it is considered as an ai \\nsubdomain from several national strategies and ai experts, encompassing  applications such as  text \\ngeneration, text mining, classification, and machine translation ( hleg, 2019; spanish rdi strategy in artificial \\nintelligence, 2019; national strateg y: denmark, 2019; national strategy: france monitoring report, 2019; cb ',\n",
       " ' \\n13 insights, 2019; ec jrc flagship report on ai, 2018; oecd, 2018; tsinghua university, 2018; working paper for \\nai national strategy: india, 2018; national strategy: france (villani missi on), 2018;  us department of \\ndefense, 2018; ai national strategy: japan, 2017 ; ai national strategy: china, 2017 ; mckinsey, 2017; stone \\net al.: ai100, 2016; mccarthy, 2007 )  \\ndomain: perception  \\nsubdomains:  computer vision; audio processing  \\nperception refers to systems ’ ability to become aware of their environment through the senses : vision, \\nhearing, manipulation. etc ., being vision and hearing the most developed areas in ai. computer vision (cv) \\nrefers to activities that identify human faces and objects in di gital images, as part of object -class detection. it \\nis identified as one of the essential scientific fields with parts belonging to machine perception and, thus, ai. it \\nis usually referred to as image pattern recognition  for specific tasks, or as in a broa der sense as machine \\nvision , with applications on face and body recognition, video content recognition, 3d reconstruction, public \\nsafety and security, health etc.  (hleg, 2019; spanish rdi strategy in artificial intelligence, 2019; national \\nstrategy: denmar k, 2019;  australia’s ethic framework dawson et al., 2019; us congressional research \\nservice, 2019; cb insights, 2019; ec jrc flagship report on ai, 2018;  ai national strategy: germany, 2018; \\ntsinghua university, 2018; working paper for ai national strategy: india, 2018;  oecd, 2018; us department \\nof defense, 2018; ai national strategy: japan, 2017;  oecd, 2017;  mckinsey, 2017; stone et al.: ai100, 2016; \\nmccarthy, 2007).  audio processing refers to ai systems allowing the perception or generation (synth esis) of \\naudio signals, including  speech , but also  other sound material  (e.g. environmental sounds, music) . speech or \\nvoice recognition, audio processing or sound technologies are also often proposed to be archived as an ai \\nsubdivision (ai4belgium report, 2019; com(2018) 237 final; ec jrc flagship report on ai, 2018; oecd, 2017, \\n2018; tsinghua university, 2018; working paper for ai national strategy: india, 2018; ai national strategy: \\njapan, 2017; mccarthy, 2007).  \\ndomain: integration and interaction  \\nsubdomains:  multi -agent systems; robotics and automation; connected and automated vehicles \\n(cavs)  \\nthe transversal domain of integration and interaction addresses t he combination of perception, reasoning, \\naction, learning and interaction with the environme nt, as well as characteristics such as distribution, \\ncoordination, cooperation, autonomy, interaction and integration .. robotics and automation refers to activities \\nrelated to application and research of the technological intelligent tools to assist or sub stitute human activity, \\nor to enable actions that are not humanly possible (e.g. medical robots), to optimize technical limitations, \\nlabour or production costs. the cavs subdomain regards technologies of autonomous vehicles, connected \\nvehicles and driver a ssistance systems, considering all automation levels and all communication technologies \\n(v2x). multi -agent systems, unmanned systems (cavs, drones), as well as robotics and process automation \\n(application programming interface (api), robotic process automa tion for industrial, social and other uses) are \\nalso mentioned as separate intrinsic subdivisions of ai (hleg, 2019;  spanish rdi strategy in artificial \\nintelligence, 2019; unesco, 2019; australia’s ethic framework, 2019; national strategy: denmark, 2019; \\nnational strategy: france monitoring report, 2019; us congressional research service, 2019; cb insights, \\n2019;  ec jrc flagship report on ai, 2018; com(2018) 237 final; ai national strategy: germany, 2018;  \\ntsinghua university, 2018; working paper for ai national strategy: india, 2018; national industrial strategy: \\nuk, 2018; 2017; national strategy: france (villani mission), 2018 ; statista 2017; mckinsey, 2017 ; ai national \\nstrategy: japan, 2017; ai national strategy: china, 2017; stone  et al.: ai100, 2016 ).  \\ndomain: services  \\nsubdomains: ai services  \\nthe transversal domain of ai services refers to any infrastructure, software and platform (e.g., cognitive \\ncomputing, ml frameworks, bots and virtual assistants, etc.) provided as (serverless ) services or applications , \\npossibly in the cloud , which are available off the shelf and executed on demand, reducing the manag ement  of \\ncomplex infrastructures. in this regard, c loud computing services are  often  presented  when describing the ai \\nlandscape (us ndaa, 2019; chinese national strategy, 2017). infrastructure as a service (iaas) is the basis of \\ncloud computing, providing access and management of virtual resources such as servers, storage, operating \\nsystems and networking. subsequently, cloud platfor ms (or platform as a service (paas)) are service products \\nof cloud applications, and can be used within software as a service (saas) architectures, which are cloud \\napplications and adaptive intelligence software  (hleg, 2019; spanish rdi strategy in artificial intelligence, ',\n",
       " ' \\n14 2019; us department of defense, 2018; tsinghua university, 2018; working paper for ai national strategy: \\nindia, 2018 ; ai national strategy: china, 2017 ; statista, 201 7; mckinsey, 2017 ). \\ndomain: e thics & philosophy  \\nsubdomains: ai ethics; philosophy of ai  \\nphilosophical and ethical issues associated with ai are proliferating and rising citizens’ attention and \\ngovernments’ policy interest  as intelligent systems become widespread. the ethics of ai is c onsidered as a \\ntransversal subdomain, as ai advances  and applications  in different areas should ensure compliance with \\nethical principles and values, including applicable regulation.  given the impact on human beings and society , \\nestablish ing trust in ai is the focus of several frameworks and initiatives by policy bodies and institutions \\n(hleg, 2019 ; oecd, 2019; standict.eu project, 2019; national strategy: france monitoring report, 2019; \\naustralia’s ethic framework dawson et al., 2019; ec coordinated acti on plan on ai, 2018; european ai \\nstrategy : ec communication ; national strategy: france (villani mission), 2018; artificial intelligence for \\neurope, 2018 ). \\n2.2.2  ai keywords  \\nin order to fulfil its objective as a monitoring tool, one of the outputs of ai watch  will be to provide an \\noverview of the worldwide landscape of ai. this effort will be conducted by applying the techno -economic \\nsegments (tes) analytical approach developed by the ec jrc to the ai field (samoili s., righi r., cardona m., \\nlópez cobo m., váz quez-prada baillet m., and de prato g., 2020) . this methodology is developed to map \\ntechnological (and non -technological) domains that do not correspond to standard classifications (e.g. \\nindustries, products), and that are pervasive and cross -sectoral. it is conceived as an analytical framework and \\nreplicable methodology  to analyse and describe the dynamics of specific tes ecosystems, by exploiting \\ndifferent types of factual data including non -official heterogeneous sources. the initial stages of the tes \\nanalytical approach are presented in samoili s., righi r., lopez -cobo m., cardona m., and de prato g.  (2019), \\nand a first application to the ai domain is shown in de prato g., lópez cobo., m., samoili s., righi r., vázquez -\\nprada baillet, m., and cardona m. (2019) and samoili et al. (2019). the first step of the tes methodo logy \\naddresses the  defini tion of  a techno -economic segment, e.g. ai, followed by its operationalisation through a \\nlist of keywords. the keywords are used in text queries to identify activities and economic agents relevant to \\nthe technology under study, ai in this case, for further analysis.  \\n2.2.2.1  construction process  \\nthe domains and subdomains  that are  selected as characterising ai  are represented by a list of keywords . \\nthese, as the ai subdomains,  cover different aspects, such as methods, algorithmic approaches , applications, \\nproducts, research areas, etc. , but also  address aspects such as ethics  and philosophy , not as an intrinsic part \\nof ai, but rather as an application of ethical principles and philosophical concerns to ai. the list of keywords is \\nbuilt in a multi -step process combining a semi -automatic text mining approach, desk research and domain \\nexperts\\' involvement:  \\n1. identification of top keywords in the research domain  \\n(a) seed articles: first we conduct a selection of a seed subset of scientific articles wh ere the term \\n\"artificial intelligence\" is present in the title, keywords or abstract of the publication. this first step is \\nrun on all articles available in the scopus database in three  different years ( 2005, 2009 and 2017). \\nthe consideration of the time d imensions allows capturing recently coined terms, as well as others \\nthat are consolidated, or even some that fell into disuse but that were important terms in the past.  \\n(b) expansion to cover articles not triggered by the technology term: in view of expanding the set of \\ninvestigated documents, and not limiting the analysis to the papers containing the keyword \"artificial \\nintelligence\", we consider all articles published in the journals in which the articles identified in step \\n1.(a) are found. in this step, 137 specialised journals are considered, while generalist journals and the \\nones centred in other scientific fields are ignored. for instance, the journal “engineering applications \\nof artificial intelligence” would be selected, while “physics of life reviews” would not, even if the \\nlatter has published some ai related articles.  \\n(c) first draft list of keywords: we consider all papers published in the journals selected in step 1.(b) \\nduring the three  referred years . the selected ai related articles amount to 25  600: 2 907 published \\nin 2005, 12  706 in 2009 and 9  987 in 2017.  the number of different keywords included in these ',\n",
       " \" \\n15 papers  totals 57  850. the first draft list of keywords is composed by a selection from the 300 most \\nfrequent author's keywords  per year, from whic h generic terms are removed . \\n2. identification of keywords in the industrial dimension of the technology  \\nin order to cover terms reflecting the recent industrial developments and ai applications, we also take into \\nconsideration sources of industrial activity.  to that end, we have analysed and extracted relevant terms from \\ncompanies’ activities descriptions. since an equivalent to author's keywords is not available from firms' \\ndescriptions, we obtain the most frequent terms (unigrams, bigrams and trigrams) and manually inspect their \\nrelevancy in order to incorporate them to the draft list built in step 1.  \\n3. initial keyword  selection  \\nthe list of candidate terms, sorted by relevance based on their frequency of occurrence, is then reviewed by \\nin-house  researchers and a short selection is made. terms are grouped when synonyms, very similar terms \\nand different spellings are found, then the groups are reduced to a single term per groups. terms appearing in \\nboth sub -lists are prioritised.  \\n4. selection of keywords through  topic modelling  \\nwe consider the most representative terms from the six ai subdomains identified from topic modelling on a \\ncorpus of 64 thousand documents of r&d and industrial activity. the subdomains are identified by applying \\nsemantic clustering with the latent dirichlet allocation (lda) model, a generative hierarchical mixed -\\nmembership model for discrete data  (blei & laerty, 2009; blei et al., 2003; papadimitriou et al., 2000) . the \\nmodel returns the most probable topics that best represent the corpus , without the involvement of any expert \\nto avoid unintentional bias. only the labelling of topics is done manually. the most relevant keywords of each \\nof the six topics are also considered, and redundancies with terms already included in the list, removed.  \\n5. validation by a panel of experts in several ai subdomains  \\nan in -house pool of researchers made a selection that was reviewed by external domain experts in several ai \\nareas . the advice for improvement targeted the expansion of the frontiers considered, nam ely the inclusion of \\ndomains and related terms not so well captured by the research and industrial sources analysed so far.  \\n6. final review and selection of list of keywords per domain  \\nas a consequence of the review in step 5, areas  such as knowledge represe ntation and reasoning or ai ethics \\nand their corresponding related terms were introduced. the final taxonomy was then depicted and the final \\nkeyword list defined. valuable inputs in this process were: the terms describing the submission groups in top \\nai co nferences, the term frequencies observed in aitopics, and the terms produced by the spanish working \\ngroup on ai responsible for the drafting of the spanish strategy.  \\n2.2.2.2  keyword list  \\ntable 2 presents the keywords identified as most relevant within each ai subdomain comprising the \\ntaxonomy . this list of keywords is designed to map and model ai activities in a broad sense. the keywords are \\npresented grouped in t he broad categories identified in the taxonomy , which , as explained in detail in \\nsubsection  2.2.1 , are not mutually exclusive. this keyword list is intended to  be dynamically updated according \\nto new technological developments in core and transversal domains , and to agree with alternative proposals.  \\nthe rationale for building the list of keywords is to determine, in a practical way, the boundaries of the \\necosystem of economic agents active in ai. in practical terms, the list of keywords will be used taking into \\naccount additional considerat ions. for instance, in order to avoid as much as possible the occurrence of false \\npositives, i.e., the incorrect identification as ai of activities that are not ai related, a  reduced list of intrinsic -ai \\nkeywords is used to query the data sources to identi fy the relevant active agents in the tes ecosystem.  \\nfurthermore, some of the remaining keywords are considered only after conditioning its co-occurrence w ith \\nsome of the core ai terms  (these are the non -intrinsic ai keywords) . examples of intrinsic -ai terms  used as \\nstandalone terms  to identify activities are: deep learning, face recognition, swarm intelligence  and \\nunsupervised learning. terms that are only used in combination with intrinsic -ai terms include, for instance: \\naccountability, classification,  clustering, cognitive system, industrial robot, service robot and  social robot , since \\nthese non -intrinsic terms could be used in a non -ai context . \\n  \",\n",
       " ' \\n16 table 2. most relevant keywords within each ai domain  \\nai domain  ai subdomain  keyword  \\nreasoning  knowledge \\nrepresentation;  \\n \\nautomated reasoning;  \\n \\ncommon sense \\nreasoning  case-based reasoning  inductive programming  \\ncausal inference  information theory  \\ncausal models  knowledge representation & reasoning  \\ncommon -sense reasoning  latent variable models  \\nexpert system  semantic web  \\nfuzzy logic  uncertainty in artificial intelligence  \\ngraphical models    \\nplanning  planning and \\nscheduling;  \\n \\nsearching;  \\n \\noptimisation  bayesian optimisation  hierarchical task network  \\nconstraint satisfaction  metaheuristic optimisation  \\nevolutionary algorithm  planning graph  \\ngenetic algorithm  stochastic optimisation  \\ngradient descent    \\nlearning  machine learning  active learning  feature extraction  \\nadaptive learning  generative adversarial network  \\nadversarial machine learning  generative model  \\nadversarial network  multi -task learning  \\nanomaly detection  neural network  \\nartificial neural network  pattern recognition  \\nautomated machine learning  probabilistic learning  \\nautomatic classification  probabilistic model  \\nautomatic recognition  recommender system  \\nbagging  recurrent neural network  \\nbayesian modelling  recursive neural network  \\nboosting  reinforcement learning  \\nclassification  semi-supervised learning  \\nclustering  statistical learning  \\ncollaborative filtering  statistical relational learning  \\ncontent -based filtering  supervised learning  \\nconvolutional neural network  support vector machine  \\ndata mining  transfer learning  \\ndeep learning  unstructured data  \\ndeep neural network  unsupervised learning  \\nensemble method    \\ncommunication  natural language \\nprocessing  chatbot  natural language generation  \\ncomputational linguistics  machine translation  \\nconversation model  question answering  \\ncoreference resolution  sentiment analysis  \\ninformation extraction  text classification  \\ninformation retrieval  text mining  \\nnatural language understanding    \\nperception  computer vision  action recognition  object recognition  \\nface recognition  recognition technology  \\ngesture recognition  sensor network  \\nimage processing  visual search  \\nimage retrieval    \\naudio processing  computational auditory scene \\nanalysis  sound synthesis  \\nmusic information retrieval  speaker identification  \\nsound description  speech processing  \\nsound event recognition  speech recognition  \\nsound source separation  speech synthesis  ',\n",
       " \" \\n17 ai domain  ai subdomain  keyword  \\nintegration \\nand interaction  multi -agent systems  agent -based modelling  negotiation algorithm  \\nagreement technologies  network intelligence  \\ncomputational economics  q-learning  \\ngame theory  swarm intelligence  \\nintelligent agent    \\nrobotics and \\nautomation  cognitive system  robot system  \\ncontrol theory  service robot  \\nhuman -ai interaction  social robot  \\nindustrial robot    \\nconnected and \\nautomated vehicles  autonomous driving  self-driving car  \\nautonomous system  unmanned vehicle  \\nautonomous vehicle    \\nservices  ai services  ai application  intelligence software  \\nai benchmark  intelligent control  \\nai competition  intelligent control system  \\nai software toolkit  intelligent hardware development  \\nanalytics platform  intelligent software development  \\nbig data  intelligent user interface  \\nbusiness intelligence  internet of things  \\ncentral processing unit  machine learning framework  \\ncomputational creativity  machine learning library  \\ncomputational neuroscience  machine learning platform  \\ndata analytics  personal assistant  \\ndecision analytics  platform as a service  \\ndecision support  tensor processing unit  \\ndistributed computing  virtual environment  \\ngraphics processing unit  virtual reality  \\nai ethics and \\nphilosophy  ai ethics  accountability  safety  \\nexplainability  security  \\nfairness  transparency  \\nprivacy    \\nphilosophy of ai  artificial general intelligence  weak artificial intelligence  \\nstrong artificial intelligence  narrow artificial intelligence  \\nsource: authors' elaboration  \\n  \\n \\n2.3 collection of ai definitions and subdomains  \\ntable 3 presents the keywords identified as most relevant within each ai subdomains comprising the \\noperational definition. the domains included in the summary table are mentioned in the collected docu ments \\nas categories or applications. the documents are ordered in descending chronological order and then by \\nalphabetical order  within each section of : policy and institutional (european commission level, national level \\nand international  organisations ), research and market . for longer descriptions of the ai definitions, \\nexplanations, context, etc., see the individual subsections of section  3.  \\n \",\n",
       " ' \\n18 table 3. summary of definitions and subdomains  or applications  referred to in the collected documents.  \\nsource  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nai reference definition for ai watch  \\nhleg, 2019  “artificial intelligence (ai) systems are software (and possibly also hardware) \\nsystems designed by humans3 that, given a complex goal, act in the physical or \\ndigital dimension by perceiving their environment through data acquisition, \\ninterpreting the collected structured or unstructured data, reasoning on the \\nknowledge, or processing the information, derived f rom this data and deciding the \\nbest action(s) to take to achieve the given goal. ai systems can either use symbolic \\nrules or learn a numeric model, and they can also adapt their behaviour by \\nanalysing how the environment is affected by their previous actio ns.” \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc  \\uf0fc \\uf0fc \\npolicy and institutional approaches  \\neuropean commission level  \\nec coordinated action \\nplan on ai, 2018  “artificial intelligence refers to systems that display intelligent behaviour by \\nanalysing their environment and taking action — with some degree of autonomy — \\nto achieve specific goals.”         \\uf0fc \\neuropean ai strategy : ec \\ncommunication, artificial \\nintelligence for europe, \\n2018  “artificial intelligence (ai) refers to systems that display intelligent behaviour by \\nanalysing their environment and taking actions – with some degree of autonomy – \\nto achieve specific goals.”         \\uf0fc \\nec jrc flagship report on \\nai: artificial intelligence. \\na european perspective, \\n2018  “ai is a generic term that refers to any machine or algorithm that is capable of \\nobserving its environment, learning, and based on the knowledge and experience \\ngained, taking intelligent action or proposing decisions. there are many different \\ntechnologies that fall under this broad ai definition. at the moment, ml techniques  \\nare the most widely used.”   \\uf0fc \\uf0fc \\uf0fc \\uf0fc    \\nnational level: european union  ',\n",
       " ' \\n19 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nai4belgium report, 2019  reference to the european ai strategy definition ( section  3.1.1.3 ): \\n\\'according to the european commission: “ai refers to systems that display \\nintelligent behaviour by analysing their environment and taking actions – with \\nsome degree of autonomy – to achieve specific goals. ai -based systems can be \\npurely software -based, acting in the virtual world (e.g. voice assistants, image \\nanalysis software, search en gines, speech and face recognition systems) or ai can \\nbe embedded in hardware devices (e.g. advanced robot s, autonomous cars, drones \\nor internet of things applications).” \\'   \\uf0fc \\uf0fc \\uf0fc \\uf0fc    \\nai national strategy: \\ndenmark, 2019  \"artificial intelligence is systems based on algorithms (mathematical formulae) \\nthat, by analysing and identifying patterns in data, can identify the most \\nappropriate solution. the vast majority of these systems perform specific tasks in \\nlimited areas, e.g. control, prediction and guidance. the technology can be designed \\nto adapt its behaviour by observing how the environment is influenced by previous \\nactions.\"   \\uf0fc \\uf0fc \\uf0fc \\uf0fc  \\uf0fc  \\nai national strategy: \\nfrance. monitoring report, \\n2019  unofficial translation:  \\na theoretical and practical interdisciplinary field, with objective the understanding \\nof the cognitive and thinking mechanisms, and their imitation by a material and \\nsoftware device, for assistance or substitution purposes of human activities.  \\nthe ai definition used is reported to be the one of russel and norvig, 1995 .  \\uf0fc \\uf0fc \\uf0fc  \\uf0fc   \\uf0fc \\nspanish rdi strategy in \\nartificial intelligence, \\n2019  “ai can be defined as the science and engineering that allows the design and \\nprogramming of machines capable of carrying out tasks that require intelligence. \\nrather than achieving general intelligence, current ai f ocuses on what is known as \\nspecific ai, which is producing very important results in many fields of application \\nsuch as natural language processing or artificial vision; however, from a scientific \\nand basic and applied research point of view, general ai re mains the major \\nobjective to be achieved, that is, creating an ecosystem with intelligent \\nmultitasking systems.”  \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc  \\nai national strategy: \\nfrance (villani mission), \\n2018  \"ai has always been envisioned as an evolving boundary, rather than a settled \\nresearch field. fundamentally, it refers to a programme whose ambitious objective \\nis to understand and reproduce human cognition; creating cognitive processes \\ncomparable to those found in human beings. therefore, we are naturally dealing \\nwith a wid e scope here, both in terms of the technical procedures that can be \\nemployed and the various disciplines that can be called upon: mathematics, \\ninformation technology, cognitive sciences, etc. there is a great variety of \\napproaches when it comes to ai: onto logical, reinforcement learning, adversarial \\uf0fc \\uf0fc \\uf0fc  \\uf0fc   \\uf0fc ',\n",
       " ' \\n20 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nlearning and neural networks, to name just a few.\"  \\nai national strategy: \\ngermany, 2018  \"in highly abstract terms, ai researchers can be assigned to two groups: “strong” \\nand “weak” ai. “strong” ai means that ai systems have the same intellectual \\ncapabilities as humans, or even exceed them. “weak” ai is focused on the solution \\nof specific problems using methods from mathematics and computer science, \\nwhereby the systems developed are capable of self -optimisation. to this end, \\naspects of human intelligence are mapped and formally described, and systems \\nare designed to simulate and support human thinking.\"  \\uf0fc \\uf0fc  \\uf0fc \\uf0fc    \\nnational industrial \\nstrategy: uk, 2018; 2017  - \\n \\uf0fc   \\uf0fc    \\nai national strategy: \\nsweden, 2018  \"there is no one single, clear -cut or generally accepted definition of artificial \\nintelligence, but many definitions. in general, however, ai refers to intelligence \\ndemonstrated by machines.\"         \\uf0fc \\nreport of the steering \\ngroup of the ai \\nprogramme: finland, \\n2017  \"artificial intelligence refers to devices, software and systems that are able to \\nlearn and to make decisions in almost the same manner as people. artificial \\nintelligence allows machines, devices, software, systems and services to function \\nin a sensible way according to the task and situation at hand.\"         \\uf0fc \\nnational level: non -eu \\naustralia’s ethic \\nframework, 2019  \"a collection of interrelated technologies used to solve problems autonomously \\nand perform tasks to achieve defined  objectives without explicit guidance from a \\nhuman being \"   \\uf0fc   \\uf0fc  \\uf0fc  \\nus congressional \\nresearch service, 2019  - \\n \\uf0fc  \\uf0fc \\uf0fc   \\uf0fc ',\n",
       " ' \\n21 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nworking paper for ai \\nnational strategy: india, \\n2018  “ai refers to the ability of machines to perform cognitive tasks like thinking, \\nperceiving, learning, problem solving and decision making. initially conceived as a \\ntechnology that could mimic human intelligence, ai has evolved in ways that far \\nexceed its original conception. with incredible advances made in data collection, \\nprocessing and computation power, intelligent systems can now be deployed to \\ntake over a variety of tasks, enable connectivity and enhance productivity.”  \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc   \\nus national defense \\nauthorization act, 2018  “1. any artificial system that performs tas ks under varying and unpredictable \\ncircumstances without significant human oversight, or that can learn from \\nexperience and improve performance when exposed to data sets.  \\n2. an artificial system developed in computer software, physical hardware, or other \\ncontext that solves tasks requiring human -like perception, cognition, planning, \\nlearning, communication, or physical action.  \\n3. an artificial system designed to think or act like a human, including cognitive \\narchitectures and neural networks.  \\n4. a set of te chniques, including machine learning that is designed to approximate \\na cognitive task.  \\n5. an artificial system designed to act rationally, including an intelligent software \\nagent or embodied robot that achieves goals using perception, planning, reasoning, \\nlearning, communicating, decision -making, and acting.”         \\uf0fc \\nus department of \\ndefense, 2018  - \\n \\uf0fc \\uf0fc \\uf0fc  \\uf0fc  \\uf0fc \\nai national strategy: \\njapan, 2017  - \\n  \\uf0fc \\uf0fc \\uf0fc   \\uf0fc \\nai national strategy: \\nchina, 2017  - \\n\\uf0fc  \\uf0fc  \\uf0fc \\uf0fc  \\uf0fc ',\n",
       " ' \\n22 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nai national strategy: \\ncanada, 2017  - \\n       \\uf0fc \\ninternational organisations  \\noecd, 2019  \"an ai system is a machine -based system that can, for a given set of human -\\ndefined objectives, make predictions, recommendations, or decisions influencing \\nreal or virtual environments. ai systems are designed to operate with varying \\nlevels of autonomy.\"        \\uf0fc  \\nunesco, 2019  - \\n    \\uf0fc   \\uf0fc \\nstandict.eu project, \\n2019  - \\n \\uf0fc     \\uf0fc \\uf0fc \\noecd, 2018  “ai can make business more productive, improve government efficiency and relieve \\nworkers of mundane tasks. it can also address many of our most pressing global \\nproblems, such as climate change and wider access to quality education and \\nhealthcare…this combination of interdisciplinary origins, wavering trajectories, and \\nrecent commercial success make \"artificial intelligence\" a diff icult concept to \\ndefine and measure…the term itself is used interchangeably both as the still -\\nfaraway goal of true machine intelligence and as the currently available \\ntechnology powering today’s hottest startups”   \\uf0fc \\uf0fc \\uf0fc     \\netsi, 2018  “computerized system  that uses cognition to understand information and solve \\nproblems.”  \\nnote 1: iso/iec 2382 -28 \"information technology -- vocabulary\" defines ai as \"an \\ninterdisciplinary field, usually regarded as a branch of computer science, dealing \\nwith models and systems for the performance of functions generally associated \\nwith human intelligence, such as reasoning and learning\".  \\nnote 2: in computer science ai research is defined as the study of \"intelligent \\nagents\": any device that perceives its environment and takes act ions to achieve its \\uf0fc        ',\n",
       " ' \\n23 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\ngoals.  \\nnote 3: this includes pattern recognition and the application of machine learning \\nand related techniques.  \\nnote 4: artificial intelligence is the whole idea and concepts of machines being \\nable to carry out tasks in a way that mimi cs the human intelligence and would be \\nconsidered \"smart\".  \\noecd, 2017  “artificial intelligence (ai) is a term used to describe machines performing human -\\nlike cognitive functions (e.g. learning, understanding, reasoning or interacting). it \\nhas the  potential to revolutionise production as well as contribute to tackling \\nglobal challenges related to health, transport and the environment.”   \\uf0fc  \\uf0fc    \\uf0fc \\nworld economic forum, \\n2017  “artificial intelligence (ai) is the software engine that drives the fourth  industrial \\nrevolution. its impact can already be seen in homes, businesses and political \\nprocesses. in its embodied form of robots, it will soon be driving cars, stocking \\nwarehouses and caring for the young and elderly. it holds the promise of solving \\nsome of the most pressing issues facing society, but also presents challenges such \\nas inscrutable “black box” algorithms, unethical use of data and potential job \\ndisplacement. as rapid advances in machine learning (ml) increase the scope and \\nscale of ai’s dep loyment across all aspects of daily life, and as the technology \\nitself can learn and change on its own, multistakeholder collaboration is required \\nto optimize accountability, transparency, privacy and impartiality to create trust.”  \\n“artificial intelligence  (ai) or self -learning systems is the collective term for \\nmachines that replicate the cognitive abilities of human beings. within the broader \\ntechnological landscape, predictive maintenance in the cognitive era has the \\npotential to transform global product ion systems.”         \\uf0fc \\niso, 1993; 1995; 2015  “branch of computer science devoted to developing data processing systems that \\nperform functions normally associated with human intelligence, such as reasoning, \\nlearning, and self -improvement” (2121393: iso, al : term, abbreviation and \\ndefinition standardized by iso/iec [iso/iec 2382 -1:1993])  \\n“interdisciplinary field, usually regarded as a branch of computer science, dealing \\nwith models and systems for the performance of functions generally associated \\nwith human intelligence, such as reasoning and learning” (2123769: term, \\nabbreviation and definition standardized by iso/iec [iso/iec 2382 -28:1995])  \\n“capability of a functional unit to perform functions that are generally associated \\nwith human intelligence such as re asoning and learning” (2123770: term, \\nabbreviation and definition standardized by iso/iec [iso/iec 2382 -28:1995])         \\uf0fc ',\n",
       " ' \\n24 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\n \\nresearch approach  \\ntsinghua university, \\n2018  “ai machines do not necessarily have to obtain intelligence by thinking like a \\nhuman and that it is important to make ai solve problems that can be solved by a \\nhuman brain. brain science and brainlike intelligence research and machine -\\nlearning represented by deep neural networks represent the two main \\ndevelopment directions of core ai tech nologies, with the latter referring to the use \\nof specific algorithms to direct computer systems to arrive at an appropriate \\nmodel based on existing data and use the model to make judgment on new \\nsituations, thus completing a behavior mechanism…in general,  the artificial \\nintelligence we know today is based on modern algorithms, supported by historical \\ndata, and forms artificial programs or systems capable of perception, cognition, \\ndecision making and implementation like humans.”   \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc  \\uf0fc \\nkaplan and haenlein, \\n2018  “artificial intelligence (ai) —defined as a system’s ability to correctly interpret \\nexternal data, to learn from such data, and to use those learnings to achieve \\nspecific goals and tasks through flexible adaptation.”         \\uf0fc \\npoole et al., 2017; 2010; \\n1998  “artificial intelligence (ai) is the established name for the field we have defined as \\ncomputational intelligence (ci), computational intelligence is the study of the \\ndesign of intelligent agents. an agent is something that acts in an envi ronment —it \\ndoes something. agents include worms, dogs, thermostats, airplanes, humans, \\norganizations, and society. an intelligent agent is a system that acts intelligently: \\nwhat it does is appropriate for its circumstances and its goal, it is flexible to \\nchanging environments and changing goals, it learns from experience, and it \\nmakes appropriate choices given perceptual limitations and finite computation.”  \\n \\n“artificial intelligence, or ai, is the field that studies the synthesis and analysis of \\ncomputation al agents that act intelligently.  \\nan agent is something that acts in an environment; it does something. agents \\ninclude worms, dogs, thermostats, airplanes, robots, humans, companies, and \\ncountries.”         \\uf0fc ',\n",
       " ' \\n25 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nkaplan, 2016  “there is little agreement about what intelligence is. …there is scant reason to \\nbelieve that machine intelligence bears much relationship to human intelligence, at \\nleast so far.”  \\n“there are many proposed definitions on ai …most are roughly aligned around the \\nconcept of creating computer programs or machines capable of behavior we would \\nregard as intelligent if exhibited by humans.”         \\uf0fc \\nstone et al.: ai100, 2016  ““intelligence” remains a complex phenomenon whose varied aspects have \\nattracted the attention of several different fields of study, including psychology, \\neconomics, neuroscience, biology, engineering, statistics, and linguistics. naturally, \\nthe field of ai has benefited from the progress made by all of these allied fields. \\nfor example, the artificial neural network, which has  been at the heart of several \\nai-based solutions was originally inspired by thoughts about the flow of \\ninformation in biological neurons.”   \\uf0fc \\uf0fc \\uf0fc \\uf0fc   \\uf0fc \\nrussel and norvig, 2010 \\n(3rd edition); 1995  four categories of ai are presented and eight definitions of earlier literature.  \\nthe categories are regarding thought processes, reasoning, human and rational \\nbehaviour. for more  detailed  information please refer to subsection  3.2.6 .        \\uf0fc \\nbruner, 2009  “…any and all systems that process information must be governed by specifiable \\n\"rules\" or procedures that govern what to do with inputs. it matters not whether it \\nis a nervous system, or the genetic apparatus that takes instruction from dna and \\nthen reproduces later generations, or whatever. this is the ideal of artificial \\nintelligence (ai), so -called.”         \\uf0fc \\nmccarthy, 2007  “it is the science and engineering of making intelligent machines, especially \\nintelligent computer programs. it is related to the similar task of using computers \\nto understand human intelligence, but ai does not have to confine itself to \\nmethods that are biologically observable.”  \\n“intelligence is the computational part of  the ability to achieve goals in the world. \\nvarying kinds and degrees of intelligence occur in people, many animals and some \\nmachines.”  \\uf0fc \\uf0fc \\uf0fc \\uf0fc    \\uf0fc \\ngardner, 1999  “a biopsychological potential to process information that can be activated in a \\ncultural set ting to solve problems or create products that are of value in a culture.”\\n         \\uf0fc ',\n",
       " \" \\n26 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nnakashima, 1999  “intelligence is the ability to process information properly in a complex \\nenvironment. the criteria of properness are not predefined and hence not available \\nbeforehand. they are acquired as a result of the information processing.”         \\uf0fc \\nnilsson, 1998  “artificial intelligence (ai), broadly (and somewhat circularly) defined, is concerned \\nwith intelligent behavior in artefacts . intelligent behavior,  in turn, involves \\nperception, reasoning, learning, communicating, and acting in complex \\nenvironments.”  \\uf0fc       \\uf0fc \\nneisser et al., 1996  the article introduces in the ai definition the notions of adapting to the \\nenvironment, reasoning, learning etc. through  a human intelligence definition, with \\nmultiple dimensions, due to biologically inspired processes.  \\n“individuals differ from one another in their ability to understand complex ideas, to \\nadapt effectively to the environment, to learn from experience, to en gage in \\nvarious forms of reasoning, to overcome obstacles by taking thought.  \\nconcepts of intelligence are attempts to clarify and organise this complex set of \\nphenomena.”         \\uf0fc \\nfogel, 1995  “any system…that generates adaptive behaviour to meet goals in a range of \\nenvironments can be said to be intelligent.”         \\uf0fc \\nwang, 1995  intelligence is “the ability for an information processing system to adapt to its \\nenvironment with insufficient knowledge and resources.”         \\uf0fc \\nalbus, 1991  “…the ability of a system to act appropriately in an uncertain environment, where \\nappropriate action is that which increases the probability of success, and success \\nis the achievement of behavioral subgoals that support the system’s ultimate \\ngoal.”         \\uf0fc \\nschank, 1991; 1987  “ai suffers from a lack of definition of its scope. one way to attack this problem is \\nto attempt to list some features that we would expect an intelligent entity to have. \\nnone of these features would define intelligence, indeed a being could lack any \\none of them and still be considered intelligent. nevertheless each attribute would \\nbe an integral part of intelligence in its way. ...they are communication, internal \\nknowledge, world knowledge, intentionality, and creativity.”  \\n“ai's primary goal is to bui ld an intelligent machine. the second goal is to find out \\nabout the nature of intelligence.”  \\n“intelligence means getting better over time.”         \\uf0fc \",\n",
       " ' \\n27 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nmccarthy, 1988  \\n “the goal of artificial intelligence (a.i.) is machines more capable than humans at \\nsolving problems and achieving goals requiring intelligence. there has been some \\nuseful success, but the ultimate goal still requires major conceptual advances and \\nis probably far off.  \\nthere are three ways of attacking the goal. the first is to imitate the  human \\nnervous system. the second is to study the psychology of human intelligence. the \\nthird is to understand the common sense world in which people achieve their goals \\nand develop intelligent computer programs. this last one is the computer science \\nappro ach.”        \\uf0fc \\ngardner, 1987  ai “seeks to produce, on a computer, a pattern of output that would be considered \\nintelligent if displayed by a human being”.  \\n \\nschlinger  (1992) mentions that this book also refers that “ai is viewed as a way of \\ntesting a particular theory of how cognitive processes might work. that theory is \\nthe popular information -processing model of cognition. where ai researchers \\ndisagree, according to gardner, is how literally to interpret the thinking metaphor. \\nfor example, some take what john searle calls the \"weak view\" of ai, wherein \\ncomputer programs are simply a means for testing theories of how humans might \\ncarry out cognitive operations. the wea k view of ai is synonymous with modern \\ncognitive psychology.”         \\uf0fc \\ngardner, 1983  “artificial intelligence is commonly defined by referencing definitions of human \\nintelligence, as in minsky’s definition.  \\nin contrast to the standard approach of measuring one kind of intelligence (as in \\nstandard iq tests), gardner (cognitive scientist) offers an eight -dimensional \\ndefinition to disentangle the oversimplification of intelligence\\'s measurement.  \\nin particular, he proposed multiple conceptions of intel ligence, not only logical -\\nmathematical, linguistic, but also spatial, musical, bodily -kinaesthetic, personal.”         \\uf0fc \\nnewell and simon, 1976  “by “general intelligent action” we wish to indicate the same scope if intelligence \\nas we see in human action: that in any real situation behavior appropriate to the \\nends of the system and adaptive to the demands of the environment can occur, \\nwithin some limits of speed and complexity.”         \\uf0fc \\nminsky, 1969  ai is “the science of making machines do things that wou ld require intelligence if \\ndone by men”.         \\uf0fc ',\n",
       " ' \\n28 source  ai definition  \\nreasoning;  \\nplanning \\nlearning  \\ncommunication  \\nperception  \\nintegration and \\ninteraction  \\nservices  \\nethics  and \\nphilosophy  \\nother/ na  \\nmccarthy, 1959  the author, one of the founding father of ai, proposes that common sense \\nreasoning ability is key to ai.  \\n“a program has common sense if it automatically deduces for itself a sufficiently \\nwide class of immediate consequences of anything it is told and what it already \\nknows.”         \\uf0fc \\nmccarthy et al., 1955  “..every aspect of learning or any other feature of intelligence can in principle be so \\nprecisely described that a machine can be made to simulate it. an attempt will be \\nmade to find how to make machines use language, form abstractions and \\nconcepts, solve kinds of problems now reserved for humans, and impro ve \\nthemselves.  \\n \\n…the artificial intelligence problem is taken to be that of making a machine behave \\nin ways that would be called intelligent if a human were so behaving.”         \\uf0fc \\nmarket approach  \\ncb insights, 2019  - \\n\\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc   \\uf0fc \\nstatista, 2017  “artificial intelligence (ai) essentially refers to computing technologies that are \\ninspired by the ways people use their brains and nervous systems to reason and \\nmake decisions, but typically operate quite differently.”      \\uf0fc \\uf0fc  \\uf0fc \\nmckinsey, 2017  - \\n \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc   \\nsource:  authors’  elaboration.  \\n ',\n",
       " \" \\n29 3 ai definitions and subdomains in: policy documents, research and \\nmarket reports  \\n3.1 policy and institutional perspective : commission services; national; \\ninternational  \\n3.1.1  european commission  level \\n3.1.1.1  high level expert group on artificial intelligence (hleg), 2019  \\nsource  hleg definition of ai  \\ntext of the \\ndefinition  “artificial intelligence (ai) systems are software (and possibly also hardware) systems \\ndesigned by humans3 that, given a complex goal, act in the physical or digital \\ndimension by perceiving their environment through data acquisition, interpreting the \\ncollected structured or unstructured data, reasoning on the knowledge, or processing \\nthe information, derived from this data and deciding the best action(s) to take to \\nachieve the given goal. ai systems can either use symbolic rules or learn a numeric \\nmodel, and they can also adapt their behaviour by analysing how the environment is \\naffected by their previous actions.”  \\n \\n3 humans design ai systems directly, but they may also use ai techniques to optimise \\ntheir design.  \\nsubdomains  as a scientific discipline, ai includes several approaches and techniques, such as \\nmachi ne learning (of which deep learning and reinforcement learning are specific \\nexamples), machine reasoning (which includes planning, scheduling, knowledge \\nrepresentation and reasoning, search, and optimization), and robotics (which includes \\ncontrol, percepti on, sensors and actuators, as well as the integration of all other \\ntechniques into cyber -physical systems).  \\ncontext  the high -level expert group (hleg) on artificial intelligence has been appointed by \\nthe european commission, with main aim to support the i mplementation of the \\neuropean ai strategy . this includes the elaboration of recommendations on future -\\nrelated policy development and on ethical, legal and societal issues related to ai, \\nincluding socio -economic challenges.  \\nthe hleg on ai is composed by 52 representatives from academia, civil society and \\nindustry.  \\nthe first two outputs of the hleg on ai are the ethics guidelines for trustworthy \\nartificial intelligence , and the defini tion on ai presented here, developed as a \\nsupporting document for the hleg's deliverables . \\ndate of \\npublication/ \\nrelease  8 april 2019  \\ncomments  this definition builds on the definition used in the ec communication 'artificial \\nintelligence for europe'.  \\na disclaimer warns about the oversimplification undergone for the development of \\nthe definition and the consideration of ai capabilities and research areas.  \\n \",\n",
       " ' \\n30 3.1.1.2  ec coordinated plan on ai, 2018  \\nsource  ec. coordinated plan on ai. com(2018) 795 final and annex  \\ntext of the \\ndefinition  “artificial intelligence refers to systems that display intelligent behaviour by analysing \\ntheir environment and taking action — with some degree of autonomy — to achieve \\nspecific goals. we are using ai on a daily basis, for example to block email spam or \\nspeak with digital assistants.  \\ngrowth in computing power, availabil ity of data and progress in algorithms have \\nturned ai into one of the most important technologies of the 21st century.”  \\nsubdomains  “medicine (...improve diagnoses and develop therapies for diseases for which none \\nexist yet)  \\nenvironment (...reduce energy  consumption by optimising resources; it can contribute \\nto a cleaner environment by lessening the need for pesticides; it can help improve \\nweather prediction and anticipate disasters)  \\nfinance & employment (ai will be the main driver of economic and product ivity \\ngrowth and will contribute to the sustainability and viability of the industrial base in \\neurope)”  \\ncontext  after the adoption of the european ai strategy  in april 2018, the coordinated action \\nplan proposes joint actions for closer and more efficient cooperation between \\nmember states, norway, switzerland and the commission in four key areas: \\nincreasing investment, making more data available, fostering talent and ensuring \\ntrust. its main aim is to foster the development and use of ai in europe.  \\ndate of  \\npublication/ \\nrelease  07 december 2018  \\ncomments  “the commission is increasing investments in ai under the research and innovation \\nframework programme horizon 2020 to eur 1.5 billion in the period 2018 -2020, \\nconstituting a 70% increase compared to 2014 -2017.”  \\n“for the next mff, the commission has proposed to dedicate at least eur 1 billion per \\nyear from horizon europe and the digital europe programme to ai.”  \\nthe definition is the same as in the european ai strategy . \\n ',\n",
       " ' \\n31 3.1.1.3  europe an ai strategy: ec communication - artificial intelligence for europe, 2018  \\nsource  ec communication from the commission to the european parliament, the european \\ncouncil, the council, the european economic and social committee and the \\ncommittee of the regio ns. artificial intelligence for europe. com(2018) 237 final \\n{swd(2018) 137 final}.  \\ntext of the \\ndefinition  “artificial intelligence (ai) refers to systems that display intelligent behaviour by \\nanalysing their environment and taking actions – with some degree of autonomy – to \\nachieve specific goals.  \\nai-based systems can be purely software -based, acting in the v irtual world (e.g. voice \\nassistants, image analysis software, search engines, speech and face recognition \\nsystems) or ai can be embedded in hardware devices (e.g. advanced robots, \\nautonomous cars, drones or internet of things applications).we are using ai on a \\ndaily basis, e.g. to translate languages, generate subtitles in videos or to block email \\nspam.  \\nmany ai technologies require data to improve their performance. once they perform \\nwell, they can help improve and automate decision making in the same domai n. for \\nexample, an ai system will be trained and then used to spot cyber -attacks on the \\nbasis of data from the concerned network or system.”  \\nsubdomains   - \\ncontext  ec ai comm is prepared in order to set a european initiative on ai. in particular the \\naims are (i) to promote eu’s technological and industrial capacity and ai uptake \\nacross the economy, (ii) anticipate socio -economic changes driven by ai and adapt \\naccordi ngly, (iii) form a suitable ethical and legal framework  \\ndate of \\npublication/ \\nrelease  25 april 2018  \\ncomments   \\n \\n  ',\n",
       " ' \\n32 3.1.1.4  ec jrc flagship report on ai: artificial intelligence. a european perspective, 2018  \\nsource  craglia m. (ed.), annoni a., benczur p., bertoldi p., delipetrev p., de prato g., feijoo c., \\nfernandez macias e ., gomez e., iglesias m., junklewitz h, lópez cobo m., martens b., \\nnascimento s., nativi s., polvora a., sanchez i., tolan s., tuomi i., vesnic alujevic l., \\nartificial intelligence - a european perspective, eur 29425 en, publications office, \\nluxembourg, 20 18, isbn 978 -92-79-97217 -1, doi:10.2760/11251, jrc113826  \\ntext of the \\ndefinition  “ai is a generic term that refers to any machine or algorithm that is capable of \\nobserving its environment, learning, and based on the knowledge and experience \\ngained, taking intelligent action or proposing decisions. there are many different \\ntechnologies that fall under this broad ai definition. at the moment, ml techniques \\nare the most widely used.”  \\nsubdomains  machine learning methods; connected and automated vehicles (cavs) ; speech \\nrecognition & nlp; face recognition  \\ncontext   \\ndate of \\npublication/ \\nrelease  2018  \\ncomments   \\n \\n  ',\n",
       " \" \\n33 3.1.2  national level: european union  \\n3.1.2.1  ai 4 belgium report, 2019  \\nsource  ai 4 belgium coalition, ai 4 belgium report  \\ntext of the \\ndefinition  reference to the european ai strategy definition (section  3.1.1.3 ): \\n'according to the european commission: “ai refers to systems that display intelligent \\nbehaviour by analysing their environment and taking actions – with some degree of \\nautonomy – to achieve specific goals. ai -based systems can be purely software -\\nbased, acting in the virtual world (e.g. voice assistants, image analysis software, \\nsearch en gines, speech and face recognition systems) or ai can be embedded in \\nhardware devices (e.g. advanced robot s, au tonomous cars, drones or internet of \\nthings applications).”  ' \\nsubdomains  a structured taxonomy is not presented , although some ai subdomains are \\nmentioned : machine learning, nlp, chatbots, automation.  \\nidentification of application domains: healthcare, environment, mobility, autonomous \\ndriving, smart cities, f raud detection ,  \\ncontext  the report is drafted with manifold objectives: bringing ai to the top of the political \\nagenda and public debate, stimulate a human -centred approach to ai, and providing \\na first version of an overarching belgian ai strategy.  \\nit provides a number of recommendations covering areas such as : education and \\nskills, innovation, data strategy, boost  ai adoption by the private and public sectors.  \\ndate of \\npublication/ \\nrelease  2019  \\ncomments  the report declares the need of an investment of at least eur 1 billion by 2030.  \",\n",
       " ' \\n34 3.1.2.2  ai national strategy: denmark, 2019  \\nsource  danish government: ministry of finance and ministry of industry, business and \\nfinancial affairs. strategy for denmark’s digital growth.  \\nlarosse j. (vanguard initiatives cons ult&creation) for dg cnect. analysis of national \\ninitiatives on digitising european industry. denmark: towards a digital growth \\nstrategy - made . \\ntext of the \\ndefinition  “artificial intelligence is systems based on algorithms (mathematical formulae) that, \\nby analysing and identifying patterns in data, can identify the most appropriate \\nsolution. the vast majority of these systems perform specific tasks in limited areas, \\ne.g. control, prediction and guidance. the technology can be designed to adapt its \\nbehavi our by observing how the environment is influenced by previous actions.  \\nartificial intelligence is used in a number of areas, e.g. search engines, voice and \\nimage recognition, or to support drones and self -driving cars. artificial intelligence \\ncan be a cru cial element to increase productivity growth and to raise the standard of \\nliving in the years to come.”  \\ndanish center for artificial intelligence (dckai), part of t he alexandra institute -center \\nfor artificial intelligence : \\n“artificial intelligence is an experimental science: you use your customer data to build \\na model, but you test the model continuously to see if there are alternative and \\nbetter algorithms. it will be improved, the more it is being used and the larger the \\ndatabase it has.  \\nartificial intelligence requires that you have access to large datasets, which will be \\nprovided by the centre. since denmark consists of mainly small and medium -sized \\ncompanies, you  could fear that they will lose the race, as they do not have the same \\nopportunities for developing new solutions. lack of data does not pose the same \\nproblem for large organisations such as ibm, google and amazon.”  \\nsubdomains  priority areas of ai use are  reported on: healthcare, energy and utilities, agriculture, \\ntransport, with focus also on big data, cybersecurity, cloud technologies.  \\nai applications are mentioned as language understanding, voice and image \\nrecognition, machine learning methods, ethics, cybersecurity, robotics, drones, self -\\ndriving cars.  \\ncontext  national strategy: denmark  \\nthe strategy’s objectives are: (i) to introduce common ethical and human -based \\nprinciples for ai, (ii) to promote denmark’s ai attractiveness through research and \\ndevelopment on ai, (iii) to increase danish businesses growth with ai use and \\ndevelopment, and (iv) improve significantly public services through ai use.  \\ndate of \\npublication/ \\nrelease  march 2019  \\ncomments  three ai institutes in dk:  \\n- the alexandra institute – center for artificial intelligence.  \\n- delta (part of force technology from 01.01.2017)  \\n- danish technological institute (ibiz -center)  \\n \\n1 billion dkk from 2018 to 2025, and afterwards 75 million dkk per year. more \\ninvestment numbers available in the report.  ',\n",
       " ' \\n35 3.1.2.3  ai national strategy: france. monitoring report, 2019  \\nsource  commission des affaires européennes. gattolin a., kern c., pellevat c., ouzoulias p. \\nrapport d\\'information sur la stratégie européenne pour l\\'intelligence artificielle. \\nintelligence artificielle : l\\'urgence d\\'une ambition européenne.  \\ntext of the \\ndefinition  unofficial translations follow : \\n- annexe 3:  \\n\"champ interdisciplinaire théorique et pratique qui a pour objet la compréhension de \\nmécanismes de la cognition et de la réflexion, et leur imitation par un dispositif \\nmatériel et logiciel, à des fins d’assistance ou de substitution à des activités \\nhumaines.  \\nattention : cette publication annule et remplace celle du journal officiel du 22 \\nseptembre 2000.\"  \\na theoretical and practical interdisciplinary field, with the objective of understanding \\nthe cogniti ve and thinking mechanisms, and their imitation by a material and \\nsoftware device, for assistance or substitution purposes of human activities.  \\nattention: this publication cancels and replaces this of the journal officiel of \\nseptember 22nd 2000.  \\n \\n- premièr e partie i.a.:  \\nthe ai definition used is reported to be one of russel and norvig, 1995 : \\n\"…l’étude des méthodes permettant aux ordinateurs de se comporter intelligemment… \\nl’ia inclut des tâches telles que l’appre ntissage, le raisonnement, la planification, la \\nperception, la compréhension du langage et la robotique… ces technologies visent à \\nréaliser par l’informatique des tâches cognitives réalisées traditionnellement par les \\nêtres humains. \" \\n…the study of methods allowing to the computer to behave intelligently…ai includes \\ntasks as learning, reasoning, planning, perception, language comprehension and \\nrobotics…these technologies aim to achieve with computer science cognitive tasks \\nthat are traditionally achieved by human beings.  \\n \\n\" ce qu’on appelle intelligence artificielle est donc plus aujourd’hui un prolongement \\nde l’intelligence humaine qu’une forme autonome d’intelligence. c’est pourquoi \\ncharles -édouard bouée, pdg du cabinet roland berger, préfère parler d’inte lligence \\nhumaine augmentée plutôt que d’intelligence artificielle. \" \\nwhat it is called ai today is more an extension of human intelligence than an \\nautonomous form of intelligence.  \\nthis is why charles -édouard bouée, ceo of roland berger consultancy firm, pr efers to \\ntalk about augmented human intelligence than ai.  \\nsubdomains  the subdomains defined by russel and norvig, 1995 : \\nlearning, reasoning, planning, perception, understanding, language comprehension, \\nrobotics  \\ncontext  monitoring technical report of the french senate to follow the objective set by the \\nnational plan “ai for humanity”.  \\ndate of \\npublication/ \\nrelease  31 january 2019  \\ncomments  annexe 2   (budget) from la stratégie nationale de recherche en intelligence \\nartificielle, 28.11.2018  \\n- from eu: 1’5 billion € in the framework of the h2020 programme until 2020, and \\nfor the next mff 1 billion € per year are proposed in research on ai, as part of the \\nh2020, with objective to release 20 billion € of investments each year over 202 0-\\n2030.  \\n- from france: 1’5 billion € in ai, from which 700 million for research.  \\n- 5’000 researchers in ai, 250 research groups, 35 master degrees specialised in ai, \\n300 start -ups specialised in ai [ ministère de l ʼenseignement sup érieur, de la \\nrecherche et de l ʼinnovation , date accessed 07.03.2019]  \\n ',\n",
       " ' \\n36 six axis of the ai stra tegy: \\n1. interdisciplinary ai institutes  \\n2. attract and keep talents  \\n3. support ai projects (100 million € until 2022. since 2018 22 million € to 61 \\nprojects.)  \\n4. reinforce the computation means (hpc) (170 million € until 2022)  \\n5. reinforce private -public research partnerships (65 million € will be invested by the \\nstate by 2022 to bring the total volume of projects to at least 130 million €, 65 \\nmillions € additional to other programs and institutes.)  \\n6. reinforce bilateral, european, international collabor ations with germany, europe, \\nand the world.  \\n \\n  ',\n",
       " ' \\n37 3.1.2.4  spanish rdi strategy in artificial intelligence, 2019  \\nsource  spanish ministry of science, innovation and universities, spanish rdi strategy in \\nartificial intelligence  \\n \\ntext of the \\ndefinition  “ai can be defined as the science and engineering that allows the desi gn and \\nprogramming of machines capable of carrying out tasks that require intelligence. \\nrather than achieving general intelligence, current ai focuses on what is known as \\nspecific ai, which is producing very important results in many fields of application \\nsuch as natural language processing or artificial vision; however, from a scientific and \\nbasic and applied research point of view, general ai remains the major objective to be \\nachieved, that is, creating an ecosystem with intelligent multitasking systems.”  \\nsubdomains  listing the areas that the spanish academic and scientific communities are active, \\nthe following ai areas are mentioned:  \\nmachine learning, heuristic optimization, planning, automatic deduction, ontologies, \\nlogic and reasoning, big data, natural language processing, artificial vision, robotics, \\nmulti -agent systems, recommender systems, man -machine cooperation, agent -based \\nmodelling.  \\n \\nmoreover the following applications are mentioned in the strategic sectors of:  \\nhealth, agriculture, creativ e industry, industry based on experience, services, energy \\nand environmental sustainability, as part of the ai for society.  \\n \\nai ethics are also among the strategy’s priorities, in order to avoid discrimination.  \\ncontext  ai rdi strategy: spain  \\nthe prioritie s of the strategy are to: (i) achieve organisational structure, (ii) establish \\nstrategic areas, (iii) facilitate knowledge transfer, (iv) plan actions in ai \\neducation/training, (v), develop a digital data ecosystem, (vi) analyse ai ethics.  \\ndate of \\npublica tion/ \\nrelease  2019  \\ncomments   ',\n",
       " \" \\n38 3.1.2.5  ai national strategy: france (villani mission), 2018  \\nsource  parliamentary mission (villani mission): villani c., schoenauer m., bonnet y., berthet c., \\ncornut a. -c., levin f., rondepierre b. for a meaningful artificial intelligence towards a \\nfrench and european strategy (donner un sens à l'intelligence artificielle : pour une \\nstratégie nationale et europée nne).  \\ntext of the \\ndefinition  “ai has always been envisioned as an evolving boundary, rather than a settled \\nresearch field. fundamentally, it refers to a programme whose ambitious objective is \\nto understand and reproduce human cognition; creating cognitive  processes \\ncomparable to those found in human beings. therefore, we are naturally dealing with \\na wide scope here, both in terms of the technical procedures that can be employed \\nand the various disciplines that can be called upon: mathematics, information \\ntechnology, cognitive sciences, etc. there is a great variety of approaches when it \\ncomes to ai: ontological, reinforcement learning, adversarial learning and neural \\nnetworks, to name just a few.”  \\n“...this technology [ai] represents much more than a researc h field: it determines our \\ncapacity to organize knowledge and give it meaning, it increases our decision -making \\ncapabilities and our control over these systems and, most notably, it enables us to \\ncapitilize on the value of data.”  \\n“a meaningful ai finally i mplies that ai should be explainable: explaining this \\ntechnology to the public so as to demystify it —and the role of the media is vital from \\nthis point of view —but also explaining artificial intelligence by extending research into \\nexplicability itself. ai specialists themselves frequently maintain that significant \\nadvances could be made on this subject.”  \\nsubdomains  apis; text data mining (including computer processes that “involve extracting \\nknowledge from texts or databases according to criteria of novelt y or similarity”); \\ncavs; health (pre -diagnosis); robotics; components industry adapted to ai  \\ncontext  this report was assigned as a parliamentary mission by the prime minister é. philippe, \\nand led by c. villani, with aim to create a national strategy that,  among other aims, \\nwill make france a leader in ai. the report analyses different ai aspects: political, \\neconomic, research, employment, ethics, social cohesion. there are separate annexes \\nfor each of the domains of particular interest for france: educatio n, health, \\nagriculture, transport, defense and security.  \\nthe ai definition presented in this fiche is used for the national strategy.  \\ndate of \\npublication/ \\nrelease  29 march 2018  \\ncomments  the french strategy for ai is also called as the “ ai for humanity ” plan. the  world  ai \\nleaders are mentioned:  \\n“the current colossi of artificial intelligence —the united states and china —and the \\nemerging economies in that field (israel, canada and the united kingd om in \\nparticular) have sometimes developed or are still developing in radically different \\nways. france and europe will notnecessarily need to launch their own ‘european style \\ngoogle’ to secure a place on the international stage.  \\nthe united states and china  are at the forefront of this technology and their \\ninvestments far exceed those made in europe. canada, the united kingdom and, \\nespecially, israel hold key positions in this emerging ecosystem. considering that \\nfrance and europe can already be regarded as “cybercolonies” in many aspects, it is \\nessential that they resist all forms of determinism by proposing a coordinated \\nresponse at european level.”  \\nthe role of europe in robotics is discussed as having all the necessary to lead in this \\nsubdomain, “whether i n terms of industrial robotics, for example, or agricultural \\nrobotics.”  \\nbudget: 1.5 billion euros on ai during the next 5 years. more funding details are \\nmentioned in the report.  \\n \\n   \",\n",
       " ' \\n39 3.1.2.6  ai national strategy: germany, 2018  \\nsource  federal government. artificial intelligence strategy.  \\ntext of the \\ndefinition  it is stated that a generally valid or consistently used by a ll stakeholders ai definition \\ndoes not exist. the ai definition used for the federal government’s ai strategy is \\nbased on the following understanding of ai:  \\n“in highly abstract terms, ai researchers can be assigned to two groups: “strong” and \\n“weak” ai. “s trong” ai means that ai systems have the same intellectual capabilities \\nas humans, or even exceed them. “weak” ai is focused on the solution of specific \\nproblems using methods from mathematics and computer science, whereby the \\nsystems developed are capable  of self -optimisation. to this end, aspects of human \\nintelligence are mapped and formally described, and systems are designed to \\nsimulate and support human thinking.”  \\nsubdomains  “weak” ai approach:  \\ndeductive reasoning systems; knowledge -based systems meth ods and software; \\npattern analysis and recognition; robotics (autonomous systems); multimodal human -\\nmachine interaction  \\ncontext  national strategy: germany  \\nthe aims of the strategy are: (i) to promote germany’s and europe’s leading role in \\nai, (ii) ensure a responsible ai development and use, (iii) integrate ai in society. in the \\nframework of science and innovation promotion, an organisation specialised in ai is \\nestablished (german research center of artificial intelligence - dfki).  \\ndate of \\npublication/ \\nrelease  november 2018  \\ncomments  it is mentioned that germany’s government will use ai to solve specific problems, \\nnamely the “weak” approach will be adopted. (for examples of “weak”/ “narrow”, \\n“strong”/ “general” ai see oecd, 2018; mccarty, 2007; gardner, 1987)  \\n \\nbudget:  \\n500 million € in the ai strategy for 2019 and the following years, up to 3 billion € by \\n2025.  \\n100 additional professorships in ai.  \\n \\nin the last 30 years, the german government has provided just €500 million in state \\naid for ai -related resear ch. [handelsblatt, 07.2018 , date accessed 07.03.2019]  \\n ',\n",
       " ' \\n40 3.1.2.7  ai national  strategy: sweden, 2018  \\nsource  government offices of sweden: ministry of enterprise and innovation. national \\napproach to ai (n2018.36).  \\ntext of the \\ndefinition  sweden’s innovation strategy approach to the ai definition is used:  \\n“there is no one single, clear -cut or generally accepted definition of artificial \\nintelligence, but many definitions. in general, however , ai refers to intelligence \\ndemonstrated by machines. vinnova (sweden’s innovation agency) (2018) (artificiell \\nintelligens i svenskt näringsliv och samhälle. (artificial intelligence in swedish \\nbusiness and society). interim report 12 february 2018, reg. n o 2017 -05616.”  \\nmoreover the breadth of the field is recognised, which “encompasses many \\ntechnologies, not least machine learning and deep learning.”  \\nsubdomains   - \\ncontext  national strategy: sweden  \\nthe strategy’s goal is promote the sweden’s role as an a i leader using ai, in order to \\nstrengthen the country’s welfare and competitiveness.  \\ndate of \\npublication/ \\nrelease  2018  \\ncomments   \\n  ',\n",
       " ' \\n41 3.1.2.8  report of the steering group of the ai programme: finland, 2017  \\nsource  ministry of economic affairs and employment. finland’s age of artificial intelligence.  \\ntext of the \\ndefinition  “artificial intelligence refers to devices, software and systems that are able to learn \\nand to make decisions in almost the same manner as people. artificial intelligence \\nallows machines, devices, software, systems and services to function in a sensible \\nway according to the task and situ ation at hand.”  \\nthe absence of a widely accepted definition is stated.  \\nsubdomains  - \\ncontext  second interim report of the steering group of the artificial intelligence programme \\nappointed by the ministry of economic affairs and employment.  \\nthe finnish government is expected to implement the recommendations as \\ngovernment policy.  \\neight key actions are mentioned that are expected to promote finland to leader in ai:  \\n“1. enhancement of business competitiveness through the use of ai  \\n2. effective utilisation o f data in all sectors  \\n3. ensure ai can be adopted more quickly and easily  \\n4. ensure top -level expertise and attract top experts  \\n5. make bold decisions and investments  \\n6. build the world’s best public services  \\n7. establish new models for collaboration  \\n8. ma ke finland a frontrunner in the age of ai”  \\ndate of \\npublication/ \\nrelease  18 december 2017  \\ncomments  us companies and innovation hubs are found to be leading in ai applications.  \\nchinese government is promoting ai development.  \\na swot analysis for finland is provided. it is found that in finland the use of ai: will \\nimprove public sector’s efficiency, society and education will be significantly affected, \\nas well as other sectors. moreover enterprise -driven ecosystems are promoted to \\nimprove ai implementation . ',\n",
       " ' \\n42 3.1.3  national level: non -eu \\n3.1.3.1  australia’s ethic framework, 2019  \\nsource  dawson, d. and schleiger, e., horton, j., mclaughlin, j., robinson, c., qu ezada, g., \\nscowcroft, j., hajkowicz s. artificial intelligence: australia’s ethics framework. data61 \\ncsiro, australia . \\ntext of the \\ndefinition  “a collection of interrelated technologies used to solve problems autonomously and \\nperform tasks to achieve defin ed objectives without explicit guidance from a human \\nbeing.”  \\n“this definition of ai encompasses both recent, powerful advances in ai such as \\nneural nets and deep learning, as well as less sophisticated but still important \\napplications with significant impa cts on people, such as automated decision systems.”  \\nthe categorisation between “narrow” and “general” ai is mentioned. the “narrow ai” \\nperforms specific functions. the “general ai” “is comparable to human intelligence \\nacross a range of fields”.  \\n \\nin the cou ntry’s plan on innovation and science ( innovation and science australia \\n2017, australia 2030: prosperit y through innovation, australian government, \\ncanberra ), ai is defined as follows in the acronyms, abbreviations and glossary part:  \\n“computer systems that are able to perform tasks normally requiring human \\nintelligence.”  \\nsubdomains  algorithms; mechanical s ystems (robots, autonomous vehicles, etc.)  \\n \\nthe following ethical principles that should be applied in ai are mentioned:  \\n1. the benefits of any ai systems are greater that its costs.  \\n2. minimise negative harmful and deceitful outcomes to humans.  \\n3. regulat ory and legal compliance to all relevant obligations, regulations and laws \\nnational and international.  \\n4. peoples’ private data protection.  \\n5. ensure fair treatment of human individuals, communities or groups.  \\n6. for transparency reasons, people will be informed when an algorithm is applied, \\nand which information it uses for decision -making.  \\n7. in the case that an algorithm affects a person, an efficient process should be \\nensured, so that the person can “challenge the use or output of the algorithm”.  \\n8. people and organisations that create and implement an ai algorithm are \\naccountable for its impact.  \\nthese could be considered as potential subdivisions of the ai ethics subdomain.  \\ncontext  governmental discussion paper on ai ethics to ensure a responsible development and \\napplication of ai in australia. the focus is set on “narrow ai”, as “general ai” is not \\nseen as a likely prospect by 2030.  \\ndate of \\npublication/ \\nrelease  4 march 2019  \\ncomments  australia does not presently have an ai national strategy. a technology roadmap, a \\nstandards framework, and a national ethics framework are planned. an au$29.9 \\nmillion investment was announced to promote ai development in australia. currently \\nai and automation are included in the national innovation strategy ( australia 2030: \\nprosperity through innovation, 2017 ), in the victorian all -party parliamentary group \\non artificial intelligence  (vappgai, march 2018), and the digital economy strategy  \\n(september 2017).   \\n  ',\n",
       " ' \\n43 3.1.3.2  us congressional research service, 2019  \\nsource  us congressional research service. artificial intelligence and national security.  \\ntext of the \\ndefinition  the absence of a commonly accepted definition is again stated. among the reasons \\nare the numerous and diverse approaches of research in ai. the report is using ndaa, \\n2018 definition of ai.  \\nsubdomains  narrow ai notion is used, with all current ai systems being assigned to this category. \\nthis includes:  \\nmachine learning, image recognition, iot, autonomous/ human -supervises/semi -\\nautonomous weapon system, robot.  \\nautomated systems are defined as the superset that includes ai, robots and \\nautonomous systems, which intersect each other.  \\ncontext  report prepared for the us congress.  \\ndate of \\npublication/ \\nrelease  30 january 2019  \\ncomments  a us ai national strategy is not yet signed, but on february 2019 an executive order \\nwas signed to establi sh the american ai initiative .  \\nthis is expected to include aims to promote to ai research, r&d and workforce \\ndevelopment, while proposing an international engagement.  \\nolder reports are the following:  \\n- preparing for the future of artificial intelligence . october 2016: recommendations \\non ai regulations, automation, ethics, fairness, security and publicly funded r&d.  \\n- national artificial intelligence research and development strategic plan. october \\n2016: strategic plan outline for publicly funded r&d in ai . \\n- artificial intelligence, automation, and the economy . december 2016: the impact of \\nautomation, the benefits and the costs of ai were studied, in order to provide policy \\nrecommendations.  ',\n",
       " \" \\n44 3.1.3.3  working paper for ai national strategy: india, 2018  \\nsource  national strategy for artificial intelligence #aiforall  \\ntext of the \\ndefinition  “ai refers to the ability of machin es to perform cognitive tasks like thinking, \\nperceiving, learning, problem solving and decision making. initially conceived as a \\ntechnology that could mimic human intelligence, ai has evolved in ways that far \\nexceed its original conception. with incredible  advances made in data collection, \\nprocessing and computation power, intelligent systems can now be deployed to take \\nover a variety of tasks, enable connectivity and enhance productivity.”  \\n \\nthree different ways of categorising ai are also offered:  \\n(a) weak  vs. strong ai: “weak ai describes “simulated” thinking”, namely “a system \\nwhich appears to behave intelligently, but doesn't have any kind of consciousness \\nabout what it's doing”,  \\n(b) narrow vs. general ai: “narrow ai describes an ai that is limited to a single task or \\na set number of tasks”  \\n(c) superintelligence: “often used to refer to general and strong ai at the point at \\nwhich it surpasses human intelligence, if it ever does”.  \\nsubdomains  three main categories of ai technologies are identified:  \\n(i) sense: computer vision; audio processing;  \\n(ii) comprehend: natural language processing; knowledge representation  \\n(iii) act: machine learning; expert systems  \\n \\nvirtual agents, cognitive robotics, speech and identity analytics, recommendation \\nsystems, and data visualisation are presented as ai solutions.  \\ncontext  national strategy: india, discussion paper  \\nhealthcare, agriculture, education, smart cities and infrastructure, smart mobility and \\ntransportation, are identified as the areas that ai would be b eneficial in covering \\nsocietal needs. the report is intended as an initiator of an evolving ai national \\nstrategy.  \\ndate of \\npublication/ \\nrelease  june 2018  \\ncomments   \",\n",
       " ' \\n45 3.1.3.4  us national defense authorization act, 2018  \\nsource  us national defense authorization act for fiscal year 2019 .  \\ntext of the \\ndefinition  in section  238 it is mentioned:  \\n“1. any artificial system that performs tasks under varying and unpredictable \\ncircumstances without significant human oversight, or that can learn from experience \\nand improve performance when exposed to data sets.  \\n2. an artificial system developed in computer software, physical hardware, or other \\ncontext that solves tasks requiring human -like perception, cognition, planning, \\nlearning, communication, or physical action.  \\n3. an artificial system designed to think or act like a human, including cognitive \\narchitectures and neural networks.  \\n4. a set of techniques, in cluding machine learning that is designed to approximate a \\ncognitive task.  \\n5. an artificial system designed to act rationally, including an intelligent software \\nagent or embodied robot that achieves goals using perception, planning, reasoning, \\nlearning, co mmunicating, decision -making, and acting.”  \\nsubdomains  - \\ncontext  federal law that specifies the policies, budget and expenditure of the us department \\nof defense for 2019.  \\ndate of \\npublication/ \\nrelease  3 january 2018  \\ncomments   \\n  ',\n",
       " ' \\n46 3.1.3.5  us department of defense,  2018  \\nsource  us department of defense, govini. artificial intelligence, big data and cloud \\ntaxonomy.  \\ntext of the \\ndefinition   - \\nsubdomains  learning and intelligence: mod eling and simulation, dl, ml, nlp, data mining;  \\nadvanced computing: super -computing, neuromorphic engineering, quantum \\ncomputing;  \\nai systems: virtual reality, computer vision, virtual agents  \\n \\ncloud service models are also mentioned (iaas, paas, saas).  \\ncontext  us department of defense (dod) report to analyse the critical to ai technologies \\ncritical, and the vendor landscape and performance within the 25 sub -segments that \\nare found.  \\ndate of \\npublication/ \\nrelease  2018  \\ncomments  govini is a us big data and analytics firm contracted by the dod. dod considers ai as \\na “technological cornerstone” for its third offset strategy.  ',\n",
       " ' \\n47 3.1.3.6  national industrial strategy: u nited kingdom , 2018; 2017  \\nsource  1 hm government: department for business, energy & industrial strategy,  department \\nfor digital, culture, media & sport. industrial strategy. artificial intelligence sector \\ndeal.  \\n \\n2 hm government: department for business, energy & industrial strategy . industrial  \\nstrategy. building a britain fit for the future.  \\ntext of the \\ndefinition   - \\nsubdomains   machine learning and robotics are mentioned as parts of examples for the uses that \\nthe strategy aims to achieve, without further indications of ai subdomains.  \\ncontex t national strategy: uk  \\nthe strategy’s aims are to position uk as global leader in ai based on ideas, people, \\ninfrastructure, business environment, communities across the uk.  \\ndate of \\npublication/ \\nrelease  1 april 2018  \\n2 november 2017  \\ncomments  budget:  \\n- £20 million in ai applications for the services sector  \\n- £93 million for robotics with multiple uses  \\n- £20 million to stimulate among other ways the ai uptake  \\n- £300 million for ai research funding, £83 million for ai grants, £42 million for the \\nexpansion of the alan turing institute, with £30 million from private funding.  \\n \\n  ',\n",
       " ' \\n48 3.1.3.7  ai national strategy: japan, 2017  \\nsource  strategic council for ai technology. artificial intelligence technology strategy.  \\ntext of the \\ndefinition  - \\nsubdomains  vision; virtual reality (vr); autonomous driving; robots; natural language processing; \\nimage recognition; voice recognition/synthesis; prediction  \\ncontext  national strategy: japan  \\nai is seen a set of valuable services  with a roadmap for its development in three \\nphases: (i) the use and application of data -driven ai, (ii) the public use of ai and data, \\n(iii) the creation of ecosystems through multi -domains connections.  \\na strong focus is set on the data management, the ac ademia -industry collaborations, \\nthe technological and system development and system development for ai start -ups \\nand their matching with large corporations or financial institutions  \\ndate of \\npublication/ \\nrelease  31 march 2017  \\ncomments  japan was among the first countries that developed a national ai strategy. the \\nstrategy presents ai’s development phases for japan. the strategy combines us and \\nchinese aims.  ',\n",
       " ' \\n49 3.1.3.8  ai national strategy: china, 2017  \\nsource  china’s state council. next generation artificial intellig ence development plan (aidp).  \\noriginal report . translated report . \\ntext of the \\ndefinition  - \\nsubdomains  knowledge computing engines and knowledge service technology;  \\ncross -medium analytical reasoning technology;  \\nswarm intelligence technology;  \\nautonomous unmanned systems;  \\nintelligent virtual reality modelling technology;  \\nintelligent computing chips and systems;  \\nnatural language processing technology;  \\nsupport platforms of the aforementioned (autonomous unmanned system support \\nplatforms, ai basic data and se curity detection platforms, etc.)  \\ncontext  national strategy: china  \\ndate of \\npublication/ \\nrelease   20 july 2017  \\ncomments  china shows a significant interest in the foreign ai developments and among the \\nconclusions of the strategy is the focus that is set on achieving world -leading levels \\nin ai and reduce foreign dependence [china state council. made in china 2025].  \\n“ai has become a new focus of international competition. ai is a strategic technology \\nthat will lead in the future; the world’s major developed  countries are taking the \\ndevelopment of ai as a major strategy to enhance national competitiveness and \\nprotect national security…”  \\n“…by 2030, china’s ai theories, technologies, and applications should achieve \\nworldleading levels, making china the world’s primary ai innovation center…”  \\n \\nbudget:  \\n“…the intelligent application of a complete industrial chain and high -end industrial \\nclusters, with ai core industry scale exceeding 1 trillion rmb, and with the scale of \\nrelated industries exceeding 10 trillion rmb .” ',\n",
       " ' \\n50 3.1.3.9  ai national strategy: canada, 2017  \\nsource  pan-canadian artificial intelligence strategy  \\ntext of the \\ndefinition   - \\nsubdomains  - \\ncontext  national strategy: canada.  \\nit has four goals:  \\n1. to increase the number of ai researchers and graduates in canada,  \\n2. to form three ai centres of scientific excellence (alberta machine intelligence \\ninstitute (amii, edmonton), vector institute (toronto), mila (montreal)),  \\n3. to de velop thought leadership on the economic, ethical, policy, and legal \\nimplications of ai,  \\n4. to support canada’s ai research community.  \\n \\npart of the strategy is the collaboration of the canadian institute for advanced \\nresearch (cifar), which leads the stra tegy, with the canadian government and the \\nthree new ai centres of scientific excellence.  \\ndate of \\npublication/ \\nrelease  2017  \\ncomments  canada was the first country that released an ai national strategy.  \\nbudget: $125 -million investment in ai research and innovation in canada.  \\non 7th of june 2018 canada and france published a joint statement on ai. the \\nannouncement included their common aim, namely to encourage the development of \\nai while anticipating any impacts with coordinated efforts. the materialisation of this \\naim would be an in ternational study group consisted of internationally recognised \\nexperts in science, industry and civil society, together with policymakers. it is set to \\nidentify opportunities and challenges ensuing from ai, and provide an inclusive \\nmechanism “for sharing multidisciplinary analysis, foresight and coordination \\ncapabilities in the area of artificial intelligence”.  \\n  ',\n",
       " ' \\n51 3.1.4  international organisations  \\n3.1.4.1  oecd, 2019  \\nsource  oecd, recommendat ion of the council on artificial intelligence, oecd/legal/0449  \\ntext of the \\ndefinition  \"an ai system is a machine -based system that can, for a given set of human -defined \\nobjectives, make predictions, recommendations, or decisions influencing real or virtual \\nenvironments. ai systems are designed to operate with varying levels of autonomy.\"  \\nsubdomains  ethics: inclusive growth, sustainable development and well -being; human -centered \\nvalues and fairness; transparency and explainability; robustness, securi ty and safety; \\naccountability  \\ncontext  under the oecd legal instruments, this document presents a number of \\nrecommendations to promote innovation on ai based on ethical principles and \\nrespecting human rights and democratic values.  \\ndate of \\npublication/ \\nrelease 22 may 2019  \\ncomments   ',\n",
       " ' \\n52 3.1.4.2  unesco, 2019  \\nsource  unesco. principles for ai: towards a humanistic approach? a global conference  \\ntext of the \\ndefinition  - \\nsubdomains  rapid technological advancements in artificial intelligence (ai) – as well as other \\nevolving technologies such as robotics, big data analytics, and the internet of things \\n– are changing the way we learn, work and live together.  \\ncontext  conference on ai principles  \\ndate of \\npublication/ \\nrelease  04 march 2019  \\ncomments  presently no definition is found reported by unesco.  \\n \\n  ',\n",
       " ' \\n53 3.1.4.3  standict.eu project, 2019  \\nsource  supporting european experts presence in international standardisation activities in \\nict (standict.eu). ict standards and ongoing work at international level in the ai field \\n– a landscape analysis   \\ntext of the \\ndefinition  - \\nsubdomains  themes/challenges/areas:  \\npersonalised ai; trustworthiness; ethics; ai secur ity; transparency of autonomous \\nsystems; ai usage; wellbeing metrics; big data; ai foundational standards; ai \\ngovernance; computational approaches; health; transparency of data processing; \\nconceptualisation and specification of domain knowledge  \\ncontext  project funded by h2020 for ict standardisation, ict technical specifications, cloud \\ncomputing, 5g communications, iot, cybersecurity, data technologies.  \\naim: description of the ict standards, ongoing work at international level and \\nlandscape analysis.  \\ndate of \\npublication/ \\nrelease  24 february 2019  \\ncomments  “end of 2018 two sub committees” ( jtc1 sc42 , jtc1 sc27 wg4 ) “with 6 working \\ngroups” (jtc1 sc42 jwg1, jtc1 sc42 wg1, jtc1 sc42 wg2, jtc1 sc42 wg3, jtc1 \\nsc42 wg4, jtc1 sc42 wg5) “and 1 study group” (jtc1 sc42 study group 1) “with \\nthe goal to develop 10 ai standards are active in iso/iec.”  \\nmore details on each expe cted standard: p. 39.  \\n3 standards are published  (2 are stated in the report):  \\n1. iso/iec 20546:2019 information technology -- big data -- overview and \\nvocabulary. iso/iec j tc1/sc42 working groups for standardisation in the area of ai \\npublished on 28.02.2019 the iso/iec 20546:2019 . it requires a fee to be \\ndownloaded, however from the preview it can be seen that it is a n overview and \\nvocabulary only on “ information technology – big data ”, without any mention to ai \\ndefinitions.  \\n2. iso/iec tr 20547 -2:2018 information technology -- big data re ference \\narchitecture -- part 2: use cases and derived requirements  \\nuntil 03.05.2019 the iso/iec wd 22989 on artificial intelligence -- concepts and \\nterminology  standard and/or project under the direct responsibility of iso/iec \\njtc1/sc42  is reported “ under development” , and more specifically in the \\n“preparatory” phase .   \\n3. iso/iec tr 20547 -5:2018 information technology -- big data reference \\narchitecture -- part 5: standards roadmap  \\niso/iec jtc1/sc42 is the first international standards committee  looking at the entire \\nai ecosystem . jtc1’s scope for sc42 is to become a systems integration entity to \\nwork with other iso, iec and jtc 1 committees looking at ai applications .  \\namong the reported community and industrial activities are mentioned (some \\ninvolved in iso/iec jtc1/sc42):  \\n- the multi -stakeholder platform on ict standardisation (msp)  \\n- european ai alliance steered by hig h-level expert group on ai (ai hleg)  \\n- fraunhofer cluster of excellence “cognitive internet technologies” (ccit)  \\n- big fata value association (bdva)  \\nmore projects are mentioned for the development of standards on other aspects of ai \\n(e.g. p7006 - standard for personal data artificial intelligence (ai) agent, p7008 \\nstandard for ethically driven nudging for robotic, intelligent and autonomous \\nsystems, p7010 - wellbeing metrics standard for ethical artificial intelligence and \\nautonomous systems, ieee ethically  aligned design version 2, et. al.)  \\n \\n  ',\n",
       " ' \\n54 3.1.4.4  oecd, 2018  \\nsource  oecd directorate for science, technology and innovation, committee on industry, \\ninnovation and entrepreneurship. identifying and measuring developments in artificial \\nintelligence. dsti/ciie/ wpia(2018)4  \\ntext of the \\ndefinition  “ai is neither science fiction nor a science project. there was universal agreement that \\nartificial intelligence already provides beneficial applications that are used every day \\nby people worldwide. going forward, confer ence participants suggested that the \\ndevelopment and uses of ai systems should be guided by principles that will promote \\nwell-being and prosperity while protecting individual rights and democracy.  \\na consensus emerged that the fast -paced and far -reaching c hanges from ai offer \\ndynamic opportunities for improving the economic and social sectors. ai can make \\nbusiness more productive, improve government efficiency and relieve workers of \\nmundane tasks. it can also address many of our most pressing global problem s, such \\nas climate change and wider access to quality education and healthcare.  \\n… \\nthis combination of interdisciplinary origins, wavering trajectories, and recent \\ncommercial success make \"artificial intelligence\" a difficult concept to define and \\nmeasure.  \\n \\nthe term itself is used interchangeably both as the still -faraway goal of true machine \\nintelligence and as the currently available technology powering today’s hottest \\nstartups” (p.5)  \\nsubdomains  machine learning (including deep learning);  statistics, mathematics and computational \\nmethods;  specific fields and applications such as: text mining; image recognition; \\nbiology machine vision;  speech recognition; machine translation (weak ai or artificial \\nnarrow intelligence) (pp.4 -5) \\ncontext  policy document t hat proposes an approach to identify and measure ai developments \\nin science, technological developments, and software.  \\ndate of \\npublication/ \\nrelease  12 october 2018  \\ncomments  methods used: topic modelling to subdivide ai -codes, and find key development fields \\nand applications.  \\namong other sources used: github, patents, scopus.  ',\n",
       " ' \\n55 3.1.4.5  etsi, 2018  \\nsource  etsi gr eni 004 v.1.1.1. experien tial network intelligence (eni); terminology for main \\nconcepts in eni  \\ntext of the \\ndefinition  “computerized system that uses cognition to understand information and solve \\nproblems.”  \\nnote 1: iso/iec 2382 -28 \"information technology -- vocabulary\" defines ai as \"an \\ninterdisciplinary field, usually regarded as a branch of computer science, dealing with \\nmodels and systems for the performance of functions generally associated with \\nhuman intelligence, such as reasoning and learning\".  \\nnote 2: in computer science ai  research is defined as the study of \"intelligent \\nagents\": any device that perceives its environment and takes actions to achieve its \\ngoals.  \\nnote 3: this includes pattern recognition and the application of machine learning and \\nrelated techniques.  \\nnote 4: a rtificial intelligence is the whole idea and concepts of machines being able \\nto carry out tasks in a way that mimics the human intelligence and would be \\nconsidered \"smart\".  \\nsubdomains  mention of only two fields:  \\n“knowledge reasoning: field of artificial i ntelligence that uses a set of knowledge \\nbases and a given knowledge representation to reason about the information \\navailable  \\nnote: typically, this is used to validate data as well as predict or infer new \\ninformation from existing information.  \\nknowledge re presentation: field of artificial intelligence that represents data and \\ninformation in a form that a computerized system can use.”  \\ncontext  the experiential networked intelligence (eni) etsi industry specification group (isg) \\nof the european telecommunicat ions standards institute (etsi) published a document \\non the main concepts in eni.  \\ndate of \\npublication/ \\nrelease  june 2018  \\ncomments  european telecommunications standards institute (etsi) is the recognized regional \\nstandards body addressing telecommunications, broadcasting and other electronic \\ncommunications networks and services. it is a not -for-profit organization, part of the \\neuropean standards organization (eso).  \\nit uses the iso/iec 2382 -28 ai definitions, and works on the standardised use of ai \\napplications.  \\n  ',\n",
       " ' \\n56 3.1.4.6  oecd, 2017  \\nsource  oecd. science, technology and industry scoreboard 2017. the digital \\ntransformation.  \\ntext of the \\ndefinition  “artificial intelligence (ai) is a term used to describe machines performing human -like \\ncognitive functions (e.g. learning, understanding, reasoning or interacting). it has the \\npotential to revolutionise production as well as contribute to tackling global \\nchallenges related to health, transport and the environment.”  \\nsubdomains  technologies that embed ai; large capacity analysis and storage; information \\ncommunication devices; mobile communication; imaging and sound tech nology; ict \\nsecurity; measurement; high -speed computing and network; medical technology  \\n \\ncontext  policy document with indicators regarding the impact of digital transformation on \\nscience, innovation, the economy, work and society.  \\ndate of \\npublication/ \\nrelease  2017  \\ncomments  global rankings and technological map are available in the report.  \\n ',\n",
       " ' \\n57 3.1.4.7  world economic forum , 2017  \\nsource  world economic forum  \\nwef. 2017. impact of the fourth industrial revolution on supply chains.  \\ntext of the \\ndefinition  “artificial intelligence (ai) i s the software engine that drives the fourth industrial \\nrevolution. its impact can already be seen in homes, businesses and political \\nprocesses. in its embodied form of robots, it will soon be driving cars, stocking \\nwarehouses and caring for the young and elderly. it holds the promise of solving \\nsome of the most pressing issues facing society, but also presents challenges such as \\ninscrutable “black box” algorithms, unethical use of data and potential job \\ndisplacement. as rapid advances in machine learning ( ml) increase the scope and \\nscale of ai’s deployment across all aspects of daily life, and as the technology itself \\ncan learn and change on its own, multistakeholder collaboration is required to \\noptimize accountability, transparency, privacy and impartialit y to create trust.”  \\n“artificial intelligence (ai) or self -learning systems is the collective term for machines \\nthat replicate the cognitive abilities of human beings. within the broader \\ntechnological landscape, predictive maintenance in the cognitive era h as the potential \\nto transform global production systems.”   \\nsubdomains  - \\ncontext  policy conference and white paper on how production and supply chain will be \\naffected by new technological developments, including ai.  \\ndate of \\npublication/ \\nrelease  2017  \\ncomments  prepared in collaboration with the german logistics association bvl international.  \\n \\n  ',\n",
       " ' \\n58 3.1.4.8  iso, 1993; 1995; 2015  \\nsource  iso/iec 2382:2015  \\ntext of the \\ndefinition  “branch of computer science devoted to developing data processing systems that \\nperform functions normally associated with human intelligence, such as reasoning, \\nlearning, and self -improvement” (2121393: iso, al: term, abbreviation and definition \\nstandardized by is o/iec [iso/iec 2382 -1:1993])  \\n“interdisciplinary field, usually regarded as a branch of computer science, dealing with \\nmodels and systems for the performance of functions generally associated with \\nhuman intelligence, such as reasoning and learning” (2123769 : term, abbreviation \\nand definition standardized by iso/iec [iso/iec 2382 -28:1995])  \\n“capability of a functional unit to perform functions that are generally associated \\nwith human intelligence such as reasoning and learning” (2123770: term, \\nabbreviation and  definition standardized by iso/iec [iso/iec 2382 -28:1995])  \\nsubdomains  - \\ncontext  international organization for standardization (iso)  \\ndate of \\npublication/ \\nrelease  2015  \\ncomments  the definitions imply the “general” ai classification; they refer to performance of \\nhuman functions: reasoning, learning etc.  \\n \\n  ',\n",
       " ' \\n59 3.2 research perspective  \\n3.2.1  tsinghua university, 2018  \\nsource  china institute for science and technology policy at tsinghua university. ai \\ndevelopment report.  \\ntext of the \\ndefinition  “ai machines do not necessarily have to obtain intelligence by thinking like a human \\nand that it is important to make ai solve problems that can be solved by a human \\nbrain. brain science and brainlike intelligence research and machine -learning \\nrepresented by deep neural networks represent the two main development directions \\nof core ai technologies, with the latter referring to the use of specific algorithms to \\ndirect co mputer systems to arrive at an appropriate model based on existing data \\nand use the model to make judgment on new situations, thus completing a behavior \\nmechanism.  \\nwhile only limited progress has been made in the first direction, tremendous strides \\nhave be en taken in the second direction so much that machine learning has not only \\nbecome the main paradigm of ai technology but been equated by some with ai \\nitself. in general, the artificial intelligence we know today is based on modern \\nalgorithms, supported by  historical data, and forms artificial programs or systems \\ncapable of perception, cognition, decision making and implementation like humans.”  \\nsubdomains  technical dimensions of ai enterprise identification:  \\n- speech: speech recognition, speech synthesis, speech interaction, speech \\nevaluation, human -machine dialogue, voiceprint recognition  \\n- vision: biometrics (face recognition, iris recognition, fingerprint recognition, vein \\nrecognition, etc.) affective computing, emotion recognition, expression recognitio n, \\nbehavior recognition, gesture recognition, body recognition, video content recognition, \\nobject and scene recognition, mobile vision, optical character recognition (ocr), \\nhandwriting recognition, slam, spatial recognition, 3d reconstruction etc.  \\n- natura l language processing: natural language interaction, natural language \\nunderstanding, semantic understanding, machine translation, text mining (semantic \\nanalysis, semantic computing, classification, clustering), information extraction, \\nhuman -machine interac tion  \\n- basic algorithm and platform: machine learning, deep learning, open source \\nframework, open platform  \\n- basic hardware: chips, lidars, sensors, etc.  \\n- basic enabling technology: cloud computing, big data  \\n \\nproduct and industry dimensions:  \\n- intelligent robotics: industrial robotics, service robotics, personal/ home robotics  \\n- smart driving: intelligent driving, driverless driving, autonomous driving, assisted \\ndriving, advanced driver assistance system (adas), laser radar, ultrasonic radar, \\nmillimetre wave radar, gps positioning, high -precision map, vehicle chip, human -car \\ninteraction, etc.  \\n- drone: consumer drones, professional drones  \\n- ai+: finance, insurance, judiciary administration, entertainment, tourism, healthcare, \\neducation, logistics and warehousing, smart home, smart city, network security, video \\nsurveillance, commerce, human resources, corporate services  \\ncontext  the report captures in multiple dimensions the chinese and worldwide ai ecosystem. \\nit was firstly presented during the wor ld peace forum.  \\ndate of \\npublication/ release  july 2018  \\ncomments  budget:  \\n150 billion dollars by 2030, more than 50 billion euros in ai research by 2025  \\n  ',\n",
       " ' \\n60 3.2.2  kaplan and haenlein, 2018  \\nsource  kaplan, a. and haenlein, m. siri, siri, in my hand: who’s the fairest in the land? on the \\ninterpretations, illustrations, and implications of artificial intelligence  \\ntext of  the \\ndefinition  “artificial intelligence (ai) —defined as a system’s ability to correctly interpret external \\ndata, to learn from such data, and to use those learnings to achieve specific goals \\nand tasks through flexible adaptation.”  \\nsubdomains  - \\ncontext  the article states that ai is different from concepts as iot and big data.  \\nit introduces in the definition the notions of interpretation of the environment \\n(external data), learning, achievement of goals/tasks etc.  \\nrefers to ai through stages: artificial n arrow/general/super intelligence.  \\ndate of \\npublication/ \\nrelease  2018  \\ncomments   \\n  ',\n",
       " ' \\n61 3.2.3  poole et al., 2017; 2010; 1998  \\nsource  poole, d., mackworth, a., and goebel, r. (1998). computational intelligence: a logical \\napproach. oxford university press, new york.  \\n \\npoole, d., mackworth. a. (2010). artificial intelligence f oundations of computer agents  \\n \\npoole , d., mackworth a. (2017). artificial intelligence: foundations of computational \\nagents, second edition  \\ntext of the \\ndefinition  1998: “artificial intelligence (ai) is the established name for the field we have defined \\nas computational intelligence (ci), computational intelligence is the study of the \\ndesign of intelligent agents. an agent is something that acts in an environment —it \\ndoes something. agents include worms, dogs, thermostats, airplanes, humans, \\norganizations, and society. an intelligent agent is a system that acts intelligently: \\nwhat it does is appropriate for its circumstances and its goal, it is flexible to changing \\nenvironments and changing goals, i t learns from experience, and it makes appropriate \\nchoices given perceptual limitations and finite computation.”  \\n \\n2010, 2017: “artificial intelligence, or ai, is the field that studies the synthesis and \\nanalysis of computational agents that act intelligent ly. \\nan agent is something that acts in an environment; it does something. agents include \\nworms, dogs, thermostats, airplanes, robots, humans, companies, and countries.”  \\n“we are interested in what an agent does; that is, how it acts. we judge an agent by \\nits actions…  \\nan agent acts intelligently when:  \\n• what it does is appropriate for its circumstances and its goals, taking into account \\nthe short -term and long -term consequences of its actions  \\n• it is flexible to changing environments and changing goals  \\n• it learns from experience  \\n• it makes appropriate choices given its perceptual and computational limitations”  \\n“a computational agent is an agent whose decisions about its actions can be \\nexplained in terms of computation. that is, the decision can be broken down  into \\nprimitive operations that can be implemented in a physical device. this computation \\ncan take many forms. in humans this computation is carried out in “wetware”; in \\ncomputers it is carried out in “hardware.” although there are some agents that are \\narguably not computational, such as the wind and rain eroding a landscape, it is an \\nopen question whether all intelligent agents are computational.  \\nall agents are limited. no agents are omniscient or omnipotent. agents can only \\nobserve everything about the wo rld in very specialized domains, where “the world” is \\nvery constrained. agents have finite memory. agents in the real world do not have \\nunlimited time to act.”  \\nthe central scientific goal of ai “is to understand the principles that make intelligent \\nbehavio r possible in natural or artificial systems. this is done by:  \\n• the analysis of natural and artificial agents  \\n• formulating and testing hypotheses about what it takes to construct intelligent \\nagents and  \\n• designing, building, and experimenting with computational systems that perform \\ntasks commonly viewed as requiring intelligence.  \\nas part of science, researchers build empirical systems to test hypotheses or to \\nexplore the space of possible designs. these are quite distinct from applications that \\nare built to be useful for an application domain.”  \\n“the definition is not for intelligent thought alone. we are only interested in thinking \\nintelligently insofar as it leads to more intelligent behavior. the role of thought is to \\naffect action.”  \\n“the central e ngineering goal of ai is the design and synthesis of useful, intelligent \\nartifacts. we actually want to build agents that act intelligently. such agents are \\nuseful in many applications.”  \\nsubdomains  - \\ncontext  book \\ndate of \\npublication/ \\nrelease  2017; 2010;  1998  ',\n",
       " ' \\n62 comments  endorsed by mccarthy (among the founders of ai in mccarthy, j. what is artificial \\nintelligence. (2007) ) \\nit equals ai to computational intelligence, and it is focused on the definitions of \\nagents, actions, reaction to the environment, learning....  \\n \\n  ',\n",
       " \" \\n63 3.2.4  kaplan, 2016  \\nsource  kaplan, j. artificial intelligence what everyone needs to know.  \\ntext of the \\ndefinition  “there is little agreement about what intelligence is. …there is scant reason to believe \\nthat machine intelligence bears much relationship to human intelligence, at least so \\nfar.” \\n“there are many proposed definitions on ai …most are roughly aligned around the \\nconcept of creating computer programs or machines capable of behavior we would \\nregard as intelligent if exhibited by humans.”  \\nhe suggests that mccarthy's definition, although sensible, is deeply flawed [section 1 \\ndefining ai, p.1], as it is difficult to define and/or measure human intelligence.  \\n“our cultural predilection for reducing things to numeric measurements that facilitate \\ndirect comparison often creates a false patina of objectivity and precision.”  \\nsubdomains  - \\ncontext  the book offers a definition of ai based on the juxtaposition between human and \\ncomputer intelligence. it is highlighted that the mono -dimensional quantification of \\nhuman intelligence and other simplified approaches to define ai are inadequate.  \\ndate of \\npublication/ \\nrelease  2016  \\ncomments  the author is a lecturer and research affiliate at stanford university.  \\nto disentangle the oversimplification of intelligence's quantification, a proposal was \\nmade by a cognitive scientist  [gardner h., 1999 ] to approach intelligence in eight \\ndimensions.  \",\n",
       " ' \\n64 3.2.5  stone et al.: ai100, 2016  \\nsource  stone, p ., brooks, r., brynjolfsson, e., calo, r., etzioni, o., hager, g., hirschberg, j., \\nkalyanakrishnan, s., kamar, e., kraus, s., leyton -brown, k., parkes, d., press, w., \\nsaxenian, a.l, shah, j., tambe, m., and teller, a. artificial intelligence and life in 20 30. \\none hundred year study on artificial intelligence: report of the 2015 -2016 study \\npanel, stanford university, stanford, ca.  \\ntext of the \\ndefinition  ““intelligence” remains a complex phenomenon whose varied aspects have attracted \\nthe attention of several  different fields of study, including psychology, economics, \\nneuroscience, biology, engineering, statistics, and linguistics. naturally, the field of ai \\nhas benefited from the progress made by all of these allied fields. for example, the \\nartificial neural network, which has been at the heart of several ai -based solutions[1,2] \\nwas originally inspired by thoughts about the flow of information in biological \\nneurons[3].” \\n[1] gerald tesauro, “practical issues in temporal difference learning,” machine \\nlearning, n o. 8 (1992): 257 —77. \\n[2] david silver, aja huang, chris j. maddison, arthur guez, laurent sifre, george van \\nden driessche, julian schrittwieser, ioannis antonoglou, veda panneershelvam, marc \\nlanctot, sander dieleman, dominik grewe, john nham, nal kalchbren ner, ilya \\nsutskever, timothy lillicrap, madeleine leach, koray kavukcuoglu, thore graepel, and \\ndemis hassabis, “mastering the game of go with deep neural networks and tree \\nsearch,” nature 529 (2016): 484 —489. \\n[3] w. mcculloch and w. pitts, w., “a logical c alculus of the ideas immanent in nervous \\nactivity,” bulletin of mathematical biophysics, 5 (1943): 115 —133. \\nsubdomains  trends: large scale machine learning, deep learning, reinforcement learning, robotics, \\ncomputer vision, natural language processing, col laborative systems, crowdsourcing \\nand human computation, algorithmic game theory and computational social choice, \\niot, neuromorphic computing.  \\napplications in domains: transportation, home service robots, healthcare, education, \\nlow-resource communities, public safety and security, employment and workplace, \\nentertainment  \\ncontext  investigation of the ai field, started publishing periodic reports in 2014. analysis of ai \\nimpact on “people, their communities and society”, in view of other fields that can \\naffect the ai evolution (science, engineering, computing systems).  \\ndate of \\npublication/ \\nrelease  september 2016  \\ncomments  policy projections in the report available.  \\nthere is not a definition per se, but a reference to different disciplines interested in \\nand interrelated with ai.  \\n  ',\n",
       " ' \\n65 3.2.6  russel and norvig, 2010 (3rd edition); 1995  \\nsource  russel, s. and norvig, p. artificial intelligence. a modern approach.  \\ntext of the \\ndefinition  in figure 1.1 of the book eight definitions are mentioned:  \\n \\n“eight definitions of ai, laid out along two dimensions. the definitions on top are \\nconcerned with thought processes and reasoning, whereas the ones on the bottom \\naddress behavior. the definitions on the left measure success in  terms of fidelity to \\nhuman performance, whereas the ones on the right measure against an ideal \\nperformance measure, called rationality. a system is rational if it does the “right \\nthing,” given what it knows.  \\n \\nhistorically, all four approaches to ai have b een followed, each by different people \\nwith different methods. a human -centered approach must be in part an empirical \\nscience, involving observations and hypotheses about human behavior. a rationalist \\napproach involves a combination of mathematics and engi neering. the various \\ngroups  have both disparaged and helped each other. let us look at the four \\napproaches in more detail.”  \\n \\nsubdomains  - \\ncontext  leading book in the ai field. introduces the idea of a human -centered approach to ai \\nversus a pragmatic computational approach.  \\ndate of \\npublication/ \\nrelease  1995  \\n2010 (3rd edition http://aima.cs.berkeley.edu/)  \\ncomments  endorsed by mccarthy (among the founders of ai in mccarthy, j. what is artificial \\nintelligence. (2007) ) \\nnorvig is an ai leading researcher, director of research at google inc. he is also an \\naaai fellow and councillor of the association for the advancement of artificial \\nintelligence. he was head of the computational science s division (now the intelligent \\nsystems division) at nasa ames research center, for research and development in \\nthe areas of autonomy and robotics, automated software engineering and data \\nanalysis, neuro -engineering, collaborative systems research, and sim ulation -based \\ndecision -making.  \\n',\n",
       " ' \\n66 3.2.7  bruner, 2009  \\nsource  bruner j. culture, mind and education. contemporary theories of learning.  \\ntext of the \\ndefinition  “…any and all systems that process information must be governed by specifiable \\n\"rules\" or procedures that govern what to do with inputs. it matters not whether it is a \\nnervous system, or the genetic apparatus that takes instruction from dna and then \\nreproduces later generations, or whatever. this is the ideal of artificial intelligence \\n(ai), so -called.”  \\nsubdomains  - \\ncontext  the book chapter offers an ai definition relating it to human intelligence. this \\ndefinition includes the notion of having rules or procedures leading to decisions.  \\ndate of \\npublication/ \\nrelease  2009  \\ncomments   \\n \\n \\n \\n  ',\n",
       " ' \\n67 3.2.8  mccarthy, 2007  \\nsource  mccarthy, j. what is artificial intelligence.  \\ntext of the \\ndefinition  “it is the science and engineering of making intelligent machines, especially intelligent \\ncomputer programs.  it is related to the similar task of using computers to understand \\nhuman intelligence, but ai does not have to confine itself to methods that are \\nbiologically observable.”  \\n“intelligence is the computational part of the ability to achieve goals in the worl d. \\nvarying kinds and degrees of intelligence occur in people, many animals and some \\nmachines.”  \\nsubdomains  branches:  \\nlogical ai; search; pattern recognition; representation; inference; common sense \\nknowledge and reasoning; learning from experience; planni ng; epistemology; ontology; \\nheuristics; genetic programming  \\napplications: game playing; speech recognition; understanding natural language; \\nexpert systems; heuristic classification  \\ncontext  the article uses the notion of the achievement of goals. refers to  different kinds of \\nintelligence. implicit reference to general ai / strong ai.  \\ndate of \\npublication/ \\nrelease  2007  \\ncomments  mccarthy is among the founding fathers of ai.  \\n ',\n",
       " ' \\n68 3.2.9  gardner, 1999  \\nsource  gardner h. intelligence reframed: multiple intelligences for the 21st century, pp.33 -\\n34 \\ntext of the \\ndefinition  “a biopsychological potential to process information that can be activated in a \\ncultural setting to solve problems or create  products that are of value in a culture.”  \\nsubdomains  - \\ncontext  book revisiting the multiple human intelligences.  \\ndate of \\npublication/ \\nrelease  1999  \\ncomments  this book is the revision of the 1983 book.  \\n \\n  ',\n",
       " ' \\n69 3.2.10  nakashima, 1999  \\nsource  h. nakashima. ai as complex information processing. minds and machines, 9:57 –80. \\ntext of the \\ndefinition  “intelligence is the ability to process information properly in a complex environment. \\nthe criteria of properness are not predefined and hence not available beforehand. \\nthey are acquired as a result of the information processing.”  \\nsubdomains  - \\ncontext  the article presents a definition that includes the notions of information p rocessing \\nand complex environment.  \\ndate of \\npublication/ \\nrelease  1999  \\ncomments   \\n ',\n",
       " ' \\n70 3.2.11  nilsson, 1998  \\nsource  nilsson, n.j. artificial intelligence: a new synthesis. morgan kaufmann publishers, inc.  \\ntext of the \\ndefinition  “artificial intelligence (ai), broadly (and somewhat circularly) defined, is concerned \\nwith intelligent behavior in artifacts. intelligent behavior, in turn, involves perception, \\nreasoning, learning, communicating, and acting in complex environments.”  \\nsubdomains  - \\ncontext  the book introduces in the definition the notions of complex environment, reasoning, \\nlearning, communicating etc.  \\ndate of \\npublication/ \\nrelease  1998  \\ncomments  “ai has as one of its long -term goals the development of machines that can do these \\nthings as well as humans can, or possibly, even better. another goal of ai is to \\nunderstand this kind of behavior whether it occurs in machines or in humans or other \\nanimal s.”  \\n \\nendorsed by mccarthy (among the founders of ai in mccarthy, j. what is artificial \\nintelligence. (2007) ). \\n  ',\n",
       " ' \\n71 3.2.12  neisser et al., 1996  \\nsource  neisser u., boodoo g., bouchard t.j., boykin a.w., brody n., ceci s.j., halpern d.f., \\nloehlin j.c., perloff r., sternberg r.j., and urbina s. intelligence: knows and unknowns  \\n \\ntext of the \\ndefinition  on human intelligence:  \\n“individuals differ from one another in their ability to understand complex ideas, to \\nadapt effectively to the environment, to learn from experience, to engage in various \\nforms of reasoning, to overcome obstacles by taking thought.  \\nconcepts of intelligence are attempts to clarify and organise this complex set of \\nphenomena. ” \\nsubdomains  - \\ncontext  the article introduces in the ai definition the notions of adapting to the environment, \\nreasoning, learning etc. a human intelligence definition is used to approach ai, due to \\nbiologically inspired processes. multiple intelligences  approach.  \\ndate of \\npublication/ \\nrelease  1996  \\ncomments  cited among others by yang, 2013  \\n ',\n",
       " ' \\n72 3.2.13  fogel, 1995  \\nsource  d. b. fogel. review of computational intelligence: imitating life. proc. of the ieee, \\n83(11).  \\n \\nevolutionary computation: toward a new philosophy of machine intelligence.  \\ntext of the \\ndefinition  “any sys tem…that generates adaptive behaviour to meet goals in a range of \\nenvironments can be said to be intelligent.”  \\nsubdomains  - \\ncontext  the article includes the notions of adaptive behaviour, environment, and achieving \\ngoals.  \\ndate of \\npublication/ \\nrelease  1995 \\ncomments  he is a pioneer in evolutionary computation.  \\nhe is currently chief scientist at trials.ai, and holds other founding positions at \\nnatural selection, inc., color butler, inc., and effect technologies, inc., the maker of \\nthe patented effectcheck sentiment analysis software tool. advisor for several ai \\ncompanies in the areas of b2b lead generation, logistics, and employee retention, as \\nwell as other areas.  \\n ',\n",
       " ' \\n73 3.2.14  wang, 1995  \\nsource  wang p. on the working definition of intelligence. center for research on concepts \\nand cognition, indiana university.  \\ntext of the \\ndefinition  intelligence  is “the ability for an information processing system to adapt to its \\nenvironment with insufficient knowledge and resources.”  \\nsubdomains  - \\ncontext  technical report.  \\nthe definition includes the notions of information processing, adaptation to the \\nenvironment, and insufficiency of knowledge/resources.  \\ndate of \\npublication/ \\nrelease  1995  \\ncomments   \\n \\n  ',\n",
       " ' \\n74  \\n3.2.15  albus, 1991  \\nsource  j. s. albus. outline for a theory of  intelligence. ieee trans. systems, man and \\ncybernetics, 21(3):473 –509. \\ntext of the \\ndefinition  “…the ability of a system to act appropriately in an uncertain environment, where \\nappropriate action is that which increases the probability of success, and suc cess is \\nthe achievement of behavioral subgoals that support the system’s ultimate goal.”  \\nsubdomains  - \\ncontext  article  \\ndate of \\npublication/ \\nrelease  1991  \\ncomments  from wikipedia:  \\nhe was an american engineer, senior nist fellow and founder and former chie f of \\nthe intelligent systems division of the manufacturing engineering laboratory at the \\nnational institute of standards and technology (nist). albus made contributions to \\ncerebellar robotics, developed a two -handed manipulator system known as the \\nrobocran e (a crane -like variation on the stewart platform idea), among other \\ncontributions.  \\nthe definition includes the notions of environment, actions and achieving goals.  \\n  ',\n",
       " \" \\n75 3.2.16  schank, 1991; 1987  \\nsource  schank r.c. what is ai, anyway? ai magazine, 8 (4), aaai.org  \\nr. schank. where’s the ai? ai magazine, 12(4):38 –49, 1991  \\ntext of the \\ndefinition  “ai suffers from a lack of definition of its scope. one way to attack this problem is to \\nattempt to list some features that we would expect an intelligent entity to have. non e \\nof these features would define intelligence, indeed a being could lack any one of \\nthem and still be considered intelligent. nevertheless each attribute would be an \\nintegral part of intelligence in its way. ...they are communication, internal knowledge, \\nworld knowledge, intentionality, and creativity.”  \\n \\n“ai's primary goal is to build an intelligent machine. the second goal is to find out \\nabout the nature of intelligence.”  \\n \\n“intelligence means getting better over time.”  \\nsubdomains  - \\ncontext  article  \\ndate of \\npublication/ \\nrelease  1987  \\ncomments  roger carl schank is an american artificial intelligence theorist, cognitive \\npsychologist, learning scientist, educational reformer, and entrepreneur. beginning in \\nthe late 1960s, he pioneered conceptual dependency th eory and case -based \\nreasoning, both of which challenged cognitivist views of memory and reasoning.  \\n  \",\n",
       " ' \\n76 3.2.17  mccarthy, 1988  \\nsource  mccarthy, j. the logic and philosophy of art ificial intelligence  \\ntext of the \\ndefinition  “the goal of artificial intelligence (a.i.) is machines more capable than humans at \\nsolving problems and achieving goals requiring intelligence. there has been some \\nuseful success, but the ultimate goal still re quires major conceptual advances and is \\nprobably far off.  \\n \\nthere are three ways of attacking the goal. the first is to imitate the human nervous \\nsystem. the second is to study the psychology of human intelligence. the third is to \\nunderstand the common sens e world in which people achieve their goals and develop \\nintelligent computer programs. this last one is the computer science approach.”  \\nsubdomains  - \\ncontext   \\ndate of \\npublication/ \\nrelease  1988  \\ncomments  mccarthy is among the founding fathers of ai.  \\n \\n \\n  ',\n",
       " ' \\n77 3.2.18  gardner, 1987  \\nsource  gardner, h. the mind\\'s new science: a history of the cognitive revolution. basic books.  \\ntext of the \\ndefinition  ai “seeks to produce, on a computer, a pattern of output that would be considered \\nintelligent if displayed by a human being”.  \\n \\nschlinger  (1992) mentions that this book also refers that “ai is viewed as a way of \\ntesting a particular theory of how cognitive  processes might work. that theory is the \\npopular information -processing model of cognition. where ai researchers disagree, \\naccording to gardner, is how literally to interpret the thinking metaphor. for example, \\nsome take what john searle calls the \"weak v iew\" of ai, wherein computer programs \\nare simply a means for testing theories of how humans might carry out cognitive \\noperations. the weak view of ai is synonymous with modern cognitive psychology.”  \\nsubdomains  - \\ncontext  book \\ndate of \\npublication/ \\nrelease  1987  \\ncomments   \\n  ',\n",
       " \" \\n78 3.2.19  gardner, 1983  \\nsource  gardner, h. frames of mind; the theory of  multiple intelligences. new york, ny: basic \\nbooks.  \\n \\ntext of the \\ndefinition  artificial intelligence is commonly defined by referencing definitions of human \\nintelligence, as in minsky’s definition.  \\nin contrast to the standard approach of measuring one kin d of intelligence (as in \\nstandard iq tests), gardner (cognitive scientist) offers an eight -dimensional definition \\nto disentangle the oversimplification of intelligence's measurement.  \\nin particular, he proposed multiple conceptions of intelligence, not only  logical -\\nmathematical, linguistic, but also spatial, musical, bodily -kinaesthetic, personal.  \\nsubdomains  - \\ncontext  book  \\ndate of \\npublication/ \\nrelease  1983  \\ncomments  this definition of intelligence is more used to approximate the definition of ai in \\nterms of aim and processes.  \\n \\ngardner is a cognitive developmental psychologist, among the pioneers trying to \\nquantify human intelligence in more than one dimension (another is robert \\nsternberg), introducing the notion of multiple intelligences.  \\nbefore his study, human intelligence was mono -semantic and was quantified as such \\nin intelligence quotient (iq) points.  \\nthe multiple intelligences approach is a better fit to the over simplification of one \\nintelligence, and is used to describe why the definition of ai is not easy. (see j. kaplan \\n2016, artificial intelligence what everyone needs to know, section 1 defining ai)  \\n \\n  \",\n",
       " ' \\n79 3.2.20  newell and simon, 1976  \\nsource  newell, a., simon, h. a. co mputer science as empirical enquiry: symbols and search. \\ncommunications of the acm 19, 3:113 –126.  \\ntext of the \\ndefinition  “by “general intelligent action” we wish to indicate the same scope if intelligence as \\nwe see in human action: that in any real situation behavior appropriate to the ends of \\nthe system and adaptive to the demands of the environment can occur, within some \\nlimits of speed and complexity.”  \\nsubdomains  - \\ncontext  article  \\ndate of \\npublication/ \\nrelease  1976  \\ncomments  simon was a pioneer in the field of artificial intelligence, creating with a. newell the \\nlogic theory machine (1956) and the general problem solver (gps) (1959) systems. \\nthe gps system is considered as the first knowledge representation approach [newell \\nand simon, 1961].  \\n \\nnewell was a researcher in computer science and cognitive psychology at the rand \\ncorporation and at carnegie mellon university’s school of computer science, tepper \\nschool of business, and department of psychology.  \\n \\nthey founded an artificial intelligence labo ratory at carnegie mellon university and \\nproduced a series of important programs and theoretical insights throughout the late \\nfifties and sixties.  \\nthe definition includes the notions of real situation, goal (ends of the system), \\nadaptation to the environm ent, and complexity.  \\n \\n \\n \\n  ',\n",
       " ' \\n80 3.2.21  minsky, 1969  \\nsource  minsky, m. l. semantic information processing. cambridge, ma: mit press  \\ntext of the \\ndefinition  ai is “the science of making machines do things that would require intelligence if \\ndone by men”.  \\nsubdomains  - \\ncontext  phd thesis of one of the first cognitive scientists approaching ai as human \\nintelligence.  \\ndate of \\npublication/ \\nrelease  1969  \\ncomments  marvin minsky was toshiba professor of media arts and sciences and donner \\nprofessor of electrical engineering and computer science at mit.  \\nhe was a cofounder of the mit media lab and a consultant for the one laptop per \\nchild project.  \\ndefinition based on g eneral intelligence.  \\n \\n  ',\n",
       " ' \\n81 3.2.22  mccarthy, 1959  \\nsource  mccarthy, j. programs with common sense.  \\ntext of the \\ndefinition  proposes that common sense reasoning ability is key to ai.  \\n“a program has common sense if it automatically deduces for itself a sufficiently \\nwide class of immediate consequences of anything it is told and what it already \\nknows .” \\nsubdomains  - \\ncontext   \\ndate of \\npublication/ \\nrelease  1959  \\ncomments  “probably the first paper on logical ai, i.e. ai in which logic is the method of \\nrepresenting information in computer memory and not just the subject matter of the \\nprogram. it may also be the first paper to propose common sens e reasoning ability as \\nthe key to ai. ” \\n \\nmccarthy is among the founding fathers of ai and it is cited as the one who coined \\nthe term “artificial intelligence”.  \\nai used for deductive reasoning.  \\n  ',\n",
       " ' \\n82 3.2.23  mccarthy et al., 1955  \\nsource  mccarthy, j., minsky, m. l., rochester, n., shannon, c.e. a proposal for the dartmouth \\nsummer research project on artificial intelligence  \\ntext of the \\ndefinition  “..every aspect of learning or any other feature of intelligence can in principle be so \\nprecisely described that a machine can be made to simulate it. an attempt will be \\nmade to find how to make machines use language, form abstractions and concepts, \\nsolve kinds of problems now reserved for humans, and improve themselves.  \\n \\n…the artificial intelligence problem is taken to be tha t of making a machine behave in \\nways that would be called intelligent if a human were so behaving.”  \\nsubdomains  - \\ncontext  founding proposal and conference for initiation of ai studies  \\ndate of \\npublication/ \\nrelease  31 august 1955  \\ncomments  founding fathers  and conference of ai.  \\nai as a machine that does what humans do (strong ai concept)  \\n \\n ',\n",
       " ' \\n83 3.3 market  perspective  \\n3.3.1  cb insights, 2019  \\nsource  cb insights. artificial intelligence trends  \\ntext of the \\ndefinition  - \\nsubdomains  ai trends are reported : \\nconversational agents, cyber threat hunting, drug discovery,  predictive maintenance, \\ne-commerce search, medical imaging & diagnostics, edge computing, facial \\nrecognition, open source frameworks, synthetic training data, back office automation, \\nlanguage translation, anti -counterfeit, check -out free retail, auto claims processing, \\nadvanced healthcare biometrics, clinical trial enrolment, next -gen prosthetics, capsule \\nnetworks, gans, federated learning, network optimization, reinforcement learning, \\nautonomous navigation, cro p monitoring,  \\nwith the  following applications:  \\ncomputer vision, natural language processing/synthesis, predictive intelligence, \\narchitecture, infrastructure  \\ncontext  market report  \\ndate of \\npublication/ \\nrelease  2019  \\ncomments  clustering  method for figure p.3  is not extensively presented . \\nthe trends are reported using the cb insights nextt framework, which is explained \\nas: \\nindustry adoption (y -axis): signals include momentum of startups in the space, \\nmedia attention, customer adoption (pa rtnerships, customer, licensing deals).  \\nmarket strength (x -axis): signals include market sizing forecasts, quality and \\nnumber of investors and capital, investments in r&d, earnings transcript \\ncommentary, competitive intensity, incumbent deal making (m&a, s trategic \\ninvestments).  \\n ',\n",
       " ' \\n84 3.3.2  statista, 2017  \\nsource  statista report. artificial intelligence  \\ntext of the \\ndefinition  “artificial intelligence (ai) essentially refers to computing technologies that are \\ninspired by the ways people use their brains and nervous systems to reason and \\nmake decisions, but typically operate quite differently.”  \\nsubdomains  applications:  \\nautomotive (autonomous driving, cloud computing).  \\nhealthcare (early diagnosis and preventing healthcare, surgical assistance,  recovery \\nand rehabilitation, drug discovery, precision medicine and personal genetics, \\nhealthcare robotics: direct patient care robots(surgical robots, exoskeletons, \\nprosthetics), indirect patient care robots(pharmacy, delivery, disinfection), home \\nhealth care robots).  \\neducation (intelligent tutoring, science simulation, personalised learning, \\nresources/courses, educational games).  \\nfinance (wealth management, insurance, fraud detection, banking, personal finance \\nmanagement).  \\nentertainment (movies, games, advertising, personalised content, music).  \\ncontext  market report with definitions for machine learning, robotics (including \\nsubcategories), artificial neural networks.  \\ndate of \\npublication/ \\nrelease  2017  \\ncomments   \\n  ',\n",
       " ' \\n85 3.3.3  mckinsey, 2017  \\nsource  mckinsey global insti tute. artificial intelligence. the next digital frontier?  \\ntext of the \\ndefinition  - \\nsubdomains  computer vision; natural language; machine learning; autonomous vehicles; smart \\nrobotics; virtual agents  \\ncontext  discussion paper on ai landscape, investment and expenditures in ai  \\ndate of \\npublication/ \\nrelease  june 2017  \\ncomments  the global ai landscape, expenditure and investment are discussed, with analysis by \\ntechnological subcategories, affected sectors in the value chain (leaders, followers, \\nadopters etc.). more detailed information is provided for leading countries.  \\n ',\n",
       " ' \\n86 4 conclusions  \\nthe absence of a formal  commonly agreed ai definition demanded the development of a process to establish \\na reference ai definition, and its subsequent operational isation into  a taxonomy  and representative keywords, \\nwhich  can be adopted in the ai watch  framework  and used in mapping and monitoring activities . the \\nproposed iterative process includes three perspectives : policy and institutional, research , and market , in order \\nto acquire a comprehensive  overview about the ai domain . the ai definition adopted by the high level expert \\ngroup on ai is used as a  baseline  definition . it is selected based on the review of 5 5 relevant documents  \\ncovering ai policy and institutional reports (including standardisation efforts, national strategies, and \\ninternational organisations reports), research publications and market reports . an exhaustive list of the \\ncollected documents can be found in the report.  the p roposed operational definition is composed by a concise \\ntaxonomy characterising the core domains of the ai research field and transversal topics; and a list of \\nkeywords representative of such taxonomy. as ai is a dynamic field, we propose an iterative meth od that can \\nbe updated over time to capture the rapid ai evolution.  \\nwhile the baseline definition will be used as the general ai watch definition of ai, the operational definition \\nhas a more functional use. both the taxonomy and the list of keywords are es sential to identify, map and \\ncharacterise the worldwide ai landscape, one of the monitoring goals of ai watch. the keywords are used in \\nthe initial phase to capture the relevant ai activities and the economic agents behind them.  the main utility of \\nthe tax onomy is to classify ai activities, and will assist in the mapping of the ai landscape and the \\nclassification of economic agents’ areas of specialisation. different uses of the keyword list are possible. a \\nnarrow use of the list, i.e. selecting only intrin sic-ai terms, allows to identify relevant ai activities, with an \\nexpected low  proportion of false positives. when the objective is the categorisation of ai -related activities, a \\nmore comprehensive  list is more suitable , in order to classify activities in t heir corresponding taxonomy \\ndomains.  \\nvaluable contributions of this work are: the collection of definitions developed between 1955 and 2019; the \\nsummarisation of the main features of the concept of artificial intelligence as reflected in the relevant \\nliterature; and the development of a replicable process that can provide a dynamic definition and taxonomy of \\nthe ai.  ',\n",
       " \" \\n87 references  \\nai 4 belgium coalition (2019), ai 4 belgium report  \\nblei, d.m., lafferty, j.d.: topic models. text mining: classification, clustering, and applications 10(71) (2009) \\n34. \\nblei, d.m., ng, a.y., jordan, m.i.: latent dirichlet allocation. journal of machine learning research 3(jan) (2003) \\n993-1022  \\nbruner j. (2009), culture, mind and education. contemporary theories of learning.  \\ncb insights (2019), artificial intelligence trends  \\nchina institute for science and technology policy at tsinghua university (2018), ai development report.  \\nchina’s state council (2017), next generation artificial intelligence development plan (aidp).  \\ncifar ( 2017), pan -canadian artificial intelligence strategy  \\ncommission des affaires européennes. gattolin a., kern c., pellevat c., ouzoulias p. (2019), rapport \\nd'information sur la stratégie européenne pour l'intelligence artificielle. intelligence artificielle : l'urgence d'une \\nambition européenne.  \\ncraglia m. (ed.), annoni a., benczur p., bertoldi p., delipetrev p., de prato g., feijoo c., fernandez macias e., \\ngomez e., iglesias m., junklewitz h, lópez cobo m., martens b., nascimento s., nativi s., polvora a., s anchez i., \\ntolan s., tuomi i., vesnic alujevic l., artificial intelligence - a european perspective, eur 29425 en, \\npublications office, luxembourg, 2018, isbn 978 -92-79-97217 -1, doi:10.2760/11251, jrc113826  \\nd. b. fogel. (1995), evolutionary computation: to ward a new philosophy of machine intelligence.  \\nd. b. fogel. (1995), review of computational intelligence: imitating life. proc. of the ieee, 83(11).  \\ndanish government: ministry of finance and ministry of industry, business and financial affairs (2019), \\nstrategy for denmark’s digital growth.  \\ndawson, d. and schleiger, e., horton, j., mclaughlin, j., robinson, c., quezada, g., scowcroft, j., hajkowicz s. \\n(2019), artificial intelligence: australia’s ethics framework. data61 csiro, australia.  \\nde prato g., lóp ez cobo., m., samoili s., righi r., vázquez -prada baillet, m., and cardona m., the ai techno -\\neconomic segment analysis. selected indicators, eur 29952 en, publications office of the european union, \\nluxembourg, 2019, isbn 978 -92-76-12584 -6, doi:10.2760/5765 86, jrc118071  \\nec communication from the commission to the european parliament, the european council, the council, the \\neuropean economic and social committee and the committee of the regions. artificial intelligence for europe. \\ncom(2018) 237 final {swd(2018 ) 137 final}.  \\nec. coordinated plan on ai. com(2018) 795 final and annex  \\netsi (2018), etsi gr eni 004 v.1.1.1. experiential network intelligence (eni); terminology for main concepts in \\neni \\nfederal government (2018), artificial intelligence strategy.  \\ngardner , h. (1999), intelligence reframed: multiple intelligences for the 21st century, pp.33 -34. \\ngardner, h. (1987), the mind's new science: a history of the cognitive revolution. basic books.  \\ngardner, h. (1983), frames of mind; the theory of multiple intelligen ces. new york, ny: basic books.  \\ngeneral secretariat of scientific policy coordination of the ministry of science, innovation and universities and \\nto the artificial intelligence task force (gtia, grupo de trabajo de inteligencia artificial) (2019), spanish rdi \\nstrategy in artificial intelligence  \\ngovernment offices of sweden: ministry of enterprise and innovation (2018), national approach to ai \\n(n2018.36).  \\nh. nakashima (1999), ai as complex information processing. minds and machines, 9:57 –80. \\nhigh level exper t group on artificial intelligence (2019), a definition of ai: main capabilities and disciplines.  \",\n",
       " \" \\n88 hm government: department for business, energy & industrial strategy (2017) industrial strategy. building a \\nbritain fit for the future.  \\nhm government: department for business, energy & industrial strategy, department for digital, culture, \\nmedia & sport (2018) industrial strategy. artificial intelligence sector deal.  \\niso/iec 2382:2015  \\nj. s. albus. (1991), outline for a theory of intelligence. ieee trans. systems, man and cybernetics, 21(3):473 –\\n509. \\nkaplan, a. and haenlein, m. (2018), siri, siri, in my hand: who’s the fairest in the land? on the interpretations, \\nillustrations, and implications of artificial intelligence.  \\nkaplan, j. (2016), artificial intell igence what everyone needs to know.  \\nlarosse j. (vanguard initiatives consult&creation) for dg cnect (2019), analysis of national initiatives on \\ndigitising european industry. denmark: towards a digital growth strategy - made.  \\nmccarthy, j. (2007) what is art ificial intelligence.  \\nmccarthy, j. (1988), the logic and philosophy of artificial intelligence  \\nmccarthy, j. (1959), programs with common sense.  \\nmccarthy, j., minsky, m. l., rochester, n., shannon, c.e. (1955), a proposal for the dartmouth summer \\nresearch p roject on artificial intelligence  \\nmckinsey global institute (2017, artificial intelligence. the next digital frontier?  \\nminsky, m. l. (1969), semantic information processing. cambridge, ma: mit press  \\nneisser u., boodoo g., bouchard t.j., boykin a.w., brody n., ceci s.j., halpern d.f., loehlin j.c., perloff r., \\nsternberg r.j., and urbina s. (1996), intelligence: knows and unknowns.  \\nnewell, a., simon, h. a. (1976), computer science as empirical enquiry: symbols and search. communications \\nof the acm 19, 3:113 –126. \\nnilsson, n.j. (1998), artificial intelligence: a new synthesis. morgan kaufmann publishers, inc.  \\nniti aayog (2018), national strategy for artificial intelligence #aiforall  \\noecd (2019), recommendation of the council on artificial intelligence, oecd/lega l/0449  \\noecd (2018), directorate for science, technology and innovation, committee on industry, innovation and \\nentrepreneurship. identifying and measuring developments in artificial intelligence. dsti/ciie/ wpia(2018)4  \\noecd (2017), science, technology and i ndustry scoreboard 2017. the digital transformation.  \\npapadimitriou, c.h., raghavan, p., tamaki, h., vempala, s.: latent semantic indexing: a probabilistic analysis. \\njournal of computer and system sciences 61(2) (2000) 217 -235 \\nparliamentary mission (villani  mission): villani c., schoenauer m., bonnet y., berthet c., cornut a. -c., levin f., \\nrondepierre b. (2018), for a meaningful artificial intelligence towards a french and european strategy \\n(donner un sens à l'intelligence artificielle : pour une stratégie n ationale et européenne).  \\npoole, d., mackworth , a. (2017), artificial intelligence: foundations of computational agents, second edition.  \\npoole, d., mackworth, a. (2010), artificial intelligence foundations of computer agents.  \\npoole, d., mackworth, a., and goebel, r. (1998). computational intelligence: a logical approach. oxford \\nuniversity press, new york.  \\nrussel, s. and norvig, p. (2010), artificial intelligence. a modern approach.  \\nsamoili s., righi r., cardona m., lópez cobo m., vázquez -prada baillet m., a nd de prato g., tes analysis of ai \\nworldwide ecosystem in 2009 -2018, eur 30109 en, publications office of the european union, luxembourg, \\n2020, isbn 978 -92-76-16661 -0, doi:10.2760/85212, jrc120106.  \\nsamoili s., righi r., lopez -cobo m., cardona m., and de pr ato g. (2019) unveiling latent relations in the \\nphotonics techno -economic complex system. in: cagnoni s., mordonini m., pecori r., roli a., villani m. (eds) \",\n",
       " ' \\n89 artificial life and evolutionary computation. wivace 2018. communications in computer and informati on \\nscience, vol 900. springer, cham  \\nschank r. (1991), where’s the ai? ai magazine, 12(4):38 –49, 1991  \\nschank r.c. (1987), what is ai, anyway? ai magazine, 8 (4), aaai.org  \\nstandict.eu project (2019), supporting european experts presence in international standardisation activities \\nin ict (standict.eu). ict standards and ongoing work at international level in the ai field – a landscape \\nanalysis  \\nstatista (2017),statista report 2017. artificial intelligence  \\nstone, p., brooks, r., brynjolfsson, e., calo, r., e tzioni, o., hager, g., hirschberg, j., kalyanakrishnan, s., kamar, \\ne., kraus, s., leyton -brown, k., parkes, d., press, w., saxenian, a.l, shah, j., tambe, m., and teller, a. (2016), \\nartificial intelligence and life in 2030. one hundred year study on artifi cial intelligence: report of the 2015 -\\n2016 study panel, stanford university, stanford, ca.  \\nstrategic council for ai technology (2017), artificial intelligence technology strategy.  \\nunesco (2019). principles for ai: towards a humanistic approach? a global co nference  \\nus congressional research service (2019), artificial intelligence and national security.  \\nus department of defense, govini (2018), artificial intelligence, big data and cloud taxonomy.  \\nus national defense (2018) authorization act for fiscal year 20 19. \\nwang p. (1995), on the working definition of intelligence. center for research on concepts and cognition, \\nindiana university.  \\nworld economic forum (2017), wef. 2017. impact of the fourth industrial revolution on supply chains.  ',\n",
       " ' \\n90 list of tables  \\ntable 1. ai domains and subdomains constituting one part of the operational definition of ai  ................. 11 \\ntable 2. most relevant keywords within each ai domain  ................................ ........................... 16 \\ntable 3. summary of definitions and subdomains  or applications referred to in the collected documents.  ...18 ',\n",
       " ' \\n  \\n  \\ngetting in touch with the eu  \\nin person  \\nall over the european union there are hundreds of europe direct information centres. you can find the address of the centre \\nnearest you at: https://europa.eu/european -union/contact_en  \\non the phone  or by email  \\neurope direct is a service that answers your questions about the european union. you can contact this service:  \\n- by freephone: 00 800 6 7 8 9 10 11 (certain operators may charge for these calls),  \\n- at the following standard number: +32 2299969 6, or \\n- by electronic mail via: https://europa.eu/european -union/contact_en  \\nfinding information about the eu  \\nonline  \\ninformation about the european union in all the official languages of the eu is available on the europa website at: \\nhttps://europa.eu/european -union/index_en  \\neu publications  \\nyou can download or orde r free and priced eu publications from eu bookshop at: https://publications.europa.eu/en/publications . \\nmultiple copies of free publications may be obtained by contacting europe direct or your l ocal information centre (see \\nhttps://europa.eu/european -union/contact_en ). ',\n",
       " ' \\n \\n \\nkj-na-30117 -en-n \\ndoi:10.2760/382730  \\nisbn 978-92-76-17045 -7 ',\n",
       " 'artiﬁ  cial intelligence for the real world\\nby thomas h. davenport and rajeev ronanki\\nimages by james wheaton and andrew nguyendon’t start with moon shots.feature artificial intelligence for the real world\\n108 \\u2002harvard business review\\u2002 january–february 2018\\n1264 janfeb18 fea davenport ai_nc.indd   108 1264 janfeb18 fea davenport ai_nc.indd   108 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " 'in 2013, the md anderson cancer center launched \\na “moon shot” project: diagnose and recommend treatment plans for certain forms of cancer using ibm’s watson cognitive system. but in 2017, the project was put on hold after costs topped $62 million—and the system had yet to be used on patients. at the same time, the cancer center’s it group was experimenting with using cognitive\\njanuary–february 2018 \\u2002harvard business review\\u2002 109\\u2002\\n1264 janfeb18 fea davenport ai_nc.indd   109 1264 janfeb18 fea davenport ai_nc.indd   109 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " 'technologies to do much less ambitious jobs, such \\nas making hotel and restaurant recommendations for patients’ families, determining which patients needed help paying bills, and addressing staff   it prob-\\nlems. the results of these projects have been much more promising: the new systems have contributed to increased patient satisfaction, improved fi  nancial \\nperformance, and a decline in time spent on tedious data entry by the hospital’s care managers. despite the setback on the moon shot, md anderson remains committed to using cognitive technology—that is, next-generation artificial intelligence—to enhance cancer treatment, and is currently developing a va-riety of new projects at its center of competency for cognitive computing.\\nthe contrast between the two approaches is rel-\\nevant to anyone planning ai initiatives. our sur-vey of 250 executives who are familiar with their companies’ use of cognitive technology shows that three-quarters of them believe that ai will substan-tially transform their companies within three years. however, our study of 152 projects in almost as \\nmany companies also reveals that highly ambitious moon shots are less likely to be successful than “low- hanging fruit” projects that enhance business pro-cesses. this shouldn’t be surprising—such has been the case with the great majority of new technologies that companies have adopted in the past. but the hype surrounding artifi  cial intelligence has been es-\\npecially powerful, and some organizations have been seduced by it. \\nin this article, we’ll look at the various categories \\nof ai being employed and provide a framework for how companies should begin to build up their cogni-tive capabilities in the next several years to achieve their business objectives. \\nthree types of ai\\nit is useful for companies to look at ai through the lens of business capabilities rather than technologies. broadly speaking, ai can support three important business needs: automating business processes, gain-ing insight through data analysis, and engaging with customers and employees. (see the exhibit “cognitive projects by type. ”)\\nprocess automation.  of the 152 projects we stud-\\nied, the most common type was the automation of dig-ital and physical tasks—typically back-offi   ce adminis-\\ntrative and fi  nancial activities—using robotic process \\nautomation technologies. rpa is more advanced than earlier business-process automation tools, because the “robots” (that is, code on a server) act like a human inputting and consuming information from multiple it systems. tasks include:• transferring data from e-mail and call center systems \\ninto systems of record—for example, updating cus-tomer fi  les with address changes or service additions;• replacing lost credit or atm cards, reaching into \\nmultiple systems to update records and handle customer communications;\\n• reconciling failures to charge for services across \\nbilling systems by extracting information from multiple document types; and\\n• “reading” legal and contractual documents to ex-\\ntract provisions using natural language processing.\\nrpa is the least expensive and easiest to imple-\\nment of the cognitive technologies we’ll discuss here, and typically brings a quick and high return on investment. (it’s also the least “smart” in the sense that these applications aren’t programmed to learn and improve, though developers are slowly add-ing more intelligence and learning capability.) it is particularly well suited to working across multiple back-end systems. \\nat nasa, cost pressures led the agency to launch \\nfour rpa pilots in accounts payable and receivable, it spending, and human resources—all managed by a shared services center. the four projects worked well—in the hr application, for example, 86% of transactions were completed without human inter-vention—and are being rolled out across the organiza-tion. nasa is now implementing more rpa bots, some with higher levels of intelligence. as jim walker, proj-ect leader for the shared services organization notes, “so far it’s not rocket science. ” \\none might imagine that robotic process auto-\\nmation would quickly put people out of work. but across the 71 rpa projects we reviewed (47% of the total), replacing administrative employees was nei-ther the primary objective nor a common outcome. only a few projects led to reductions in head count, and in most cases, the tasks in question had already been shifted to outsourced workers. as technology improves, robotic automation pr ojects are likely to \\nlead to some job losses in the future, particularly in the off  shore business-process outsourcing indus-\\ntry. if you can outsource a task, you can probably automate it.\\ncognitive insight. the second most common \\ntype of project in our study (38% of the total) used algorithms to detect patterns in vast volumes of data and interpret their meaning. think of it as “analytics on steroids. ” these machine-learning applications are being used to:• predict what a particular customer is likely to buy;\\n• identify credit fraud in real time and detect insur-\\nance claims fraud;\\n• analyze warranty data to identify safety or quality \\nproblems in automobiles and other manufactured products;\\n• automate personalized targeting of digital ads; and\\n• provide insurers with more-accurate and detailed \\nactuarial modeling. \\ncognitive insights provided by machine learning \\ndiff er from those available from traditional analytics in brie f\\nthe pr oblem\\ncognitive technolo gies \\nare increasin gly bein g \\nused  to solve busi ness \\nproblems, but man y of the \\nmost ambitious ai projects\\nencounter setbac ks or fail.\\nthe appr oach\\ncom panies should take an\\nincremental rather than a \\ntrans formative a pproach\\nand focus on au gmentin g\\nrather than replac ing \\nhuman ca pabilities.\\nthe pr ocess\\nto get the most out of ai,ﬁ r m\\ns must understand \\nwhich technolo gies \\nperform what t ypes o f \\ntasks, create a prioritized\\nportfolio of pro jects based \\non business needs , and\\ndevelop plans to sca le up \\nacross the compan y.\\n110 \\u2002harvard business review\\u2002 january–february 2018feature artificial intelligence for the real world\\n1264 janfeb18 fea davenport ai_nc.indd   110 1264 janfeb18 fea davenport ai_nc.indd   110 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " 'in three ways: they are usually much more data- \\nintensive and detailed, the models typically are trained on some part of the data set, and the models get better—that is, their ability to use new data to make predictions or put things into categories im-proves over time. \\nversions of machine learning (deep learning, in \\nparticular, which attempts to mimic the activity in the human brain in order to recognize patterns) can perform feats such as recognizing images and speech. machine learning can also make available new data for better analytics. while the activity of data cura-tion has historically been quite labor-intensive, now machine learning can identify probabilistic matches—data that is likely to be associated with the same per-son or company but that appears in slightly diff  erent formats—across databases. ge has used this technol-\\nogy to integrate supplier data and has saved $80 mil-lion in its fi  rst year by eliminating redundancies and \\nnegotiating contracts that were previously managed at the business unit level. similarly, a large bank used this technology to extract data on terms from supplier contracts and match it with invoice numbers, identify-ing tens of millions of dollars in products and services not supplied. deloitte’s audit practice is using cog-nitive insight to extract terms from contracts, which enables an audit to address a much higher proportion of documents, often 100%, without human auditors’ having to painstakingly read through them. \\ncognitive insight applications are typically used to \\nimprove performance on jobs only machines can do—tasks such as programmatic ad buying that involve cognitive projects by type\\nwe studied 152 cognitive technology projects \\nand found that they fell into three categories. \\nrobotics & \\ncognitive \\nautomation \\n71cognitive \\ninsight \\n57cognitive \\nengagement\\n24\\njanuary–february 2018 \\u2002harvard business review\\u2002 111\\u2002\\n1264 janfeb18 fea davenport ai_nc.indd   111 1264 janfeb18 fea davenport ai_nc.indd   111 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " '• internal sites for answering employee questions on \\ntopics including it, employee benefi  ts, and hr policy;\\n• product and service recommendation systems for \\nretailers that increase personalization, engage-ment, and sales—typically including rich language or images; and \\n• health treatment recommendation systems that \\nhelp providers create customized care plans that take into account individual patients’ health status and previous treatments. \\nthe companies in our study tended to use cogni-\\ntive engagement technologies more to interact with employees than with customers. that may change as fi rms become more comfortable turning customer in-\\nteractions over to machines. vanguard, for example, is piloting an intelligent agent that helps its customer service staff   answer frequently asked questions. the \\nplan is to eventually allow customers to engage with the cognitive agent directly, rather than with the hu-man customer-service agents. sebank, in sweden, and the medical technology giant becton, dickinson, in the united states, are using the lifelike intelligent-agent \\navatar amelia to serve as an internal employee help desk for it support. sebank has recently made amelia available to customers on a limited basis in order to test its performance and customer response. \\ncompanies tend to take a conservative approach to \\ncustomer-facing cognitive engagement technologies largely because of their immaturity. facebook, for example, found that its messenger chatbots couldn’t answer 70% of customer requests without human intervention. as a result, facebook and several other firms are restricting bot-based interfaces to certain topic domains or conversation types.\\nour research suggests that cognitive engagement \\napps are not currently threa tening customer service \\nor sales rep jobs. in most of the projects we studied, the goal was not to reduce head count but to handle growing numbers of employee and customer interac-tions without adding staff  . some organizations were \\nplanning to hand over routine communications to machines, while transitioning customer-support per-sonnel to more-complex activities such as handling customer issues that escalate, conducting extended unstructured dialogues, or reaching out to customers before they call in with problems. \\nas companies become more familiar with cogni-\\ntive tools, they are experimenting with projects that combine elements from all three categories to reap the benefi  ts of ai. an italian insurer, for example, de-\\nveloped a “cognitive help desk” within its it organiza-tion. the system engages with employees using deep- learning technology (part of the cognitive insights category) to search frequently asked questions and an-swers, previously resolved cases, and documentation to come up with solutions to employees’ problems. it uses a smart- routing capability (business process au-tomation) to forward the most complex problems to enhance the \\nfeatures, functions, \\nand performance of \\nour products\\nmake better \\ndecisions\\ncreate new \\nproducts\\noptimize internal \\nbusiness operations\\nreduce head count \\nthrough \\nautomationoptimize external \\nprocesses like \\nmarketing and salescapture and apply \\nscarce knowledge \\nwhere neededpursue new marketsfree up workers to \\nbe more creative by \\nautomating tasksthe business benefits of ai\\nwe surveyed 250 executives who were familiar with their companies’ \\nuse of cognitive technologies to learn about their goals for ai initiatives. more than half said their primary goal was to make existing products better. reducing head count was mentioned by only 22%. \\nsource  deloitte 2017 percentage of executives who cite \\nthe following as benefits of ai\\n51%\\n35%\\n32%\\n36%\\n36%\\n22%30%25%\\n25%\\nsuch high-speed data crunching and automation that \\nthey’ve long been beyond human ability—so they’re not generally a threat to human jobs.\\ncognitive engagement.  projects that engage \\nemployees and customers using natural language processing chatbots, intelligent agents, and machine learning were the least common type in our study (ac-counting for 16% of the total). this category includes:• intelligent agents that off  er 24/7 customer service \\naddressing a broad and growing array of issues from password requests to technical support questions—all in the customer’s natural language;\\n112 \\u2002harvard business review\\u2002 january–february 2018feature artificial intelligence for the real world\\n1264 janfeb18 fea davenport ai_nc.indd   112 1264 janfeb18 fea davenport ai_nc.indd   112 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " 'human representatives, and it uses natural language \\nprocessing to support user requests in italian.\\ndespite their rapidly expanding experience with \\ncognitive tools, however, companies face signifi  cant \\nobstacles in development and implementation. on the basis of our research, w e’ve dev eloped a four-step \\nframework for integrating ai technologies that can help companies achieve their objectives, whether the projects are moon shoots or business-process enhancements. \\n1. understanding the technologies \\nbefore embarking on an ai initiative, companies must understand which technologies perform what types of tasks, and the strengths and limitations of each. rule-based expert systems and robotic process automation, for example, are transparent in how they do their work, but neither is capable of learning and improv-ing. deep learning, on the other hand, is great at learn-ing from large volumes of labeled data, but it’s almost impossible to understand how it creates the models it does. this “black box” issue can be problematic in highly regulated industries such as fi  nancial services, \\nin which regulators insist on knowing why decisions are made in a certain way.\\nwe encountered several organizations that wasted \\ntime and money pursuing the wrong technology for the job at hand. but if they’re armed with a good under-standing of the diff  erent technologies, companies are \\nbetter positioned to determine which might best ad-dress specifi  c needs, which vendors to work with, and \\nhow quickly a system can be implemented. acquiring this understanding requires ongoing research and education, usually within it or an innovation group.\\nin particular, companies will need to leverage the \\ncapabilities of key employees, such as data scientists, who have the statistical and big-data skills necessary to learn the nuts and bolts of these technologies. a main success factor is your people’s willingness to learn. some will leap at the opportunity, while oth-ers will want to stick with tools they’re familiar with. strive to have a high percentage of the former.\\nif you don’t have data science or analytics capabili-\\nties in-house, you’ll probably have to build an ecosys-tem of external service providers in the near term. if you expect to be implementing longer-term ai projects, you will want to recruit expert in-house talent. either way, having the right capabilities is essential to progress. \\ngiven the scarcity of cognitive technology tal-\\nent, most organizations should establish a pool of resources—perhaps in a centralized function such as it or strategy—and make experts available to high- priority projects throughout the organization. as needs and talent proliferate, it may make sense to ded-icate groups to particular business functions or units, but even then a central coordinating function can be useful in managing projects and careers.\\n2. creating a portfolio of projects \\nthe next step in launching an ai program is to sys-tematically evaluate needs and capabilities and then develop a prioritized portfolio of projects. in the com-panies we studied, this was usually done in work-shops or through small consulting engagements. we recommend that companies conduct assessments in three broad areas.\\nidentifying the opportunities.  the fi  rst assess-\\nment determines which areas of the business could benefi  t most from cognitive applications. typically, \\nthey are parts of the company where “knowledge”—insight derived from data analysis or a collection of texts—is at a premium but for some reason is not available. • bottlenecks.  in some cases, the lack of cognitive \\ninsights is caused by a bottleneck in the fl  ow of in-\\nformation; knowledge exists in the organization, but it is not optimally distributed. that’s often the case in health care, for example, where knowledge tends to be siloed within practices, departments, or academic medical centers. percentage who cite the \\nfollowing as obstaclesthe challenges of ai\\nexecutives in our survey identiﬁ  ed several factors that can stall or derail \\nai initiatives, ranging from integration issues to scarcity of talent.\\nsource  deloitte 2017it’s hard to integrate \\ncognitive projects \\nwith existing \\nprocesses and systems\\ntechnologies and \\nexpertise are too \\nexpensive\\nmanagers don’t \\nunderstand cognitive \\ntechnologies and how \\nthey work\\nwe can’t get enough \\npeople with expertise \\nin the technology\\ntechnologies are \\nimmature\\ntechnologies have \\nbeen oversold in the \\nmarketplace47%\\n40%\\n37%\\n35%\\n31%\\n18%\\njanuary–february 2018 \\u2002harvard business review\\u2002 113\\u2002\\n1264 janfeb18 fea davenport ai_nc.indd   113 1264 janfeb18 fea davenport ai_nc.indd   113 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " '• scaling challenges.  in other cases, knowledge exists, \\nbut the process for using it takes too long or is expen-sive to scale. such is often the case with knowledge developed by fi  nancial advisers. that’s why many \\ninvestment and wealth management fi  rms now of-\\nfer ai-supported “robo-advice” capabilities that pro-vide clients with cost-eff  ective guidance for routine \\nfi nancial issues. \\nin the pharmaceutical industry, pfizer is tack-\\nling the scaling problem by using ibm’s watson to accelerate the laborious process of drug-discovery research in immuno-oncology, an emerging ap-proach to cancer treatment that uses the body’s immune system to help fight cancer. immuno-oncology drugs can take up to 12 years to bring to market. by combining a sweeping literature review with pfi  zer’s own data, such as lab reports, watson \\nis helping researchers to surface relationships and fi nd hidden patterns that should speed the identi-\\nfi cation of new drug targets, combination therapies \\nfor study, and patient selection strategies for this new class of drugs.\\n• inadequate fi  repower. finally, a company may col-\\nlect more data than its existing human or computer firepower can adequately analyze and apply. for example, a company may have massive amounts of data on consumers’ digital behavior but lack insight about what it means or how it can be strategically applied. to address this, companies are using ma-chine learning to support tasks such as program-matic buying of personalized digital ads or, in the case of cisco systems and ibm, to create tens of thousands of “propensity models” for determining which customers are likely to buy which products. \\ndetermining the use cases.  the second area of \\nassessment evaluates the use cases in which cogni-tive applications would generate substantial value and contribute to business success. start by asking key questions such as: how critical to your overall strategy is addressing the targeted problem? how dif-fi cult would it be to implement the proposed ai solu-\\ntion—both technically and organizationally? would the benefi  ts from launching the application be worth \\nthe eff  ort? next, prioritize the use cases according to \\nwhich off  er the most short- and long-term value, and \\nwhich might ultimately be integra ted into a broader \\nplatform or suite of cognitive capabilities to create competitive advantage. \\nselecting the technology. the third area to as-\\nsess examines whether the ai tools being considered for each use case are truly up to the task. chatbots and intelligent agents, for example, may frustrate some companies because most of them can’t yet match hu-man problem solving beyond simple scripted cases (though they are improving rapidly). other technolo-gies, like robotic process automation that can stream-line simple processes such as invoicing, may in fact slow down more-complex production systems. and while deep learning visual recognition systems can \\nrecognize images in photos and videos, they require lots of labeled data and may be unable to make sense of a complex visual fi  eld. \\nin time, cognitive technologies will transform \\nhow companies do business. today, however, it’s wiser to take incremental steps with the currently available technology while planning for transforma-tional change in the not-too-distant future. you may ultimately want to turn customer interactions over to bots, for example, but for now it’s probably more fea-\\nsible—and sensible—to automate your internal it help desk as a step toward the ultimate goal. \\n3. launching pilots \\nbecause the gap between current and desired ai ca-pabilities is not always obvious, companies should create pilot projects for cognitive applications before rolling them out across the entire enterprise.\\nproof-of-concept pilots are particularly suited to \\ninitiatives that have high potential business value or allow the organization to test diff  erent technologies \\nat the same time. take special care to avoid “injec-tions” of projects by senior executives who have been infl  uenced by technology vendors. just because \\nexecutives and boards of directors may feel pres-sure to “do something cognitive” doesn’t mean you should bypass the rigorous piloting process. injected projects often fail, which can signifi  cantly set back \\nthe organization’s ai program.\\nif your fi  rm plans to launch several pilots, consider \\ncreating a cognitive center of excellence or similar structure to manage them. this approach helps build the needed technology skills and capabilities within the organization, while also helping to move small pi-lots into broader applications that will have a greater impact. pfi  zer has more than 60 projects across the \\ncompany that employ some form of cognitive technol-ogy; many are pilots, and some are now in production.\\nat becton, dickinson, a “global automation” func-\\ntion within the it organization oversees a number of cognitive technology pilots that use intelligent digital agents and rpa (some work is done in partnership with the company’s global shared services organiza-tion). the global automation group uses end-to-end process maps to guide implementation and identify automation opportunities. the group also uses graph-ical “heat maps” that indicate the organizational ac-tivities most amenable to ai interventions. the com-pany has successfully implemented intelligent agents in it support processes, but as yet is not ready to sup-port large-scale enterprise processes, like order-to-cash. the health insurer anthem has developed a sim-ilar centralized ai function that it calls the cognitive capability offi   ce.\\nbusiness-process redesign.  as cognitive tech-\\nnology projects are developed, think through how \\n114 \\u2002harvard business review\\u2002 january–february 2018feature artificial intelligence for the real world\\n1264 janfeb18 fea davenport ai_nc.indd   114 1264 janfeb18 fea davenport ai_nc.indd   114 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " 'workfl  ows might be redesigned, focusing specifi  cally \\non the division of labor between humans and the ai. in some cognitive projects, 80% of decisions will be made by machines and 20% will be made by humans; others will have the opposite ratio. systematic rede-sign of workfl  ows is necessary to ensure that humans \\nand machines augment each other’s strengths and compensate for weaknesses. \\nthe investment fi  rm vanguard, for example, has \\na new “personal advisor services” (pas) offering, which combines automated investment advice with guidance from human advisers. in the new system, cognitive technology is used to perform many of the traditional tasks of investment advising, including constructing a customized portfolio, rebalancing portfolios over time, tax loss harvesting, and tax- efficient investment selection. vanguard’s human advisers serve as “investing coaches, ” tasked with answering investor questions, encouraging healthy fi nancial behaviors, and being, in vanguard’s words, \\n“emotional circuit breakers” to keep investors on plan. advisers are encouraged to learn about be-havioral finance to perform these roles effectively. the pas approach has quickly gathered more than $80 billion in assets under management, costs are lower than those for purely human-based advising, and customer satisfaction is high. (see the exhibit “one company’s division of labor. ”)\\nvanguard understood the importance of work \\nredesign when implementing pas, but many compa-nies simply “pave the cow path” by automating ex-isting work processes, particularly when using rpa technology. by automating established workfl  ows, \\ncompanies can quickly implement projects and achieve roi—but they forgo the opportunity to take full advantage of ai capabilities and substantively improve the process. \\ncognitive work redesign eff  orts often benefi  t from \\napplying design-thinking principles: understanding customer or end-user needs, involving employees whose work will be restructured, treating designs as experimental “fi  rst drafts, ” considering multiple alter-\\nnatives, and explicitly considering cognitive technol-ogy capabilities in the design process. most cognitive projects are also suited to iterative, agile approaches to development.\\n4. scaling up \\nmany organizations have successfully launched cog-nitive pilots, but they haven’t had as much success rolling them out organization-wide. to achieve their goals, companies need detailed plans for scaling up, which requires collaboration between technology experts and owners of the business process being automated. because cognitive technologies typically support individual tasks rather than entire processes, scale-up almost always requires integration with one company’sdivision of labor\\nvanguard, the investment services ﬁ  rm, \\nuses cognitive technology to provide customers with investment advice at a lower cost. its personal advisor services system automates many traditional tasks of investment advising, while human advisers take on higher-value activities. here’s how vanguard redesigned its work processes to get the most from the new system.\\nadviser\\nunderstands investment goals\\ncustomizes an \\nimplementation plan\\nprovides investment analysis \\nand retirement planning\\ndevelops retirement income \\nand social security drawdown strategies\\nserves as a behavioral coachmonitors spending to \\nencourage accountability\\noﬀ ers ongoing wealth and \\nﬁ nancial-planning support \\naddresses estate-planning \\nconsiderations\\nsource  vanguard groupcognitive technology\\ngenerates a ﬁ  nancial plan\\nprovides goals-based \\nforecasting in real time\\nrebalances portfolio to \\ntarget mix\\nminimizes taxes tracks aggregated assets in \\none place\\nengages clients virtually\\njanuary–february 2018 \\u2002harvard business review\\u2002 115\\u2002\\n1264 janfeb18 fea davenport ai_nc.indd   115 1264 janfeb18 fea davenport ai_nc.indd   115 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " 'existing systems and processes. indeed, in our sur-\\nvey, executives reported that such integration was the greatest challenge they faced in ai initiatives.\\ncompanies should begin the scaling-up process by \\nconsidering whether the required integration is even possible or feasible. if the application depends on spe-cial technology that is diffi   cult to source, for example, \\nthat will limit scale-up. make sure your business pro-cess owners discuss scaling considerations with the it organization before or during the pilot phase: an end run around it is unlikely to be successful, even for relatively simple technologies like rpa. \\nthe health insurer anthem, for example, is tak-\\ning on the development of cognitive technologies as part of a major modernization of its existing systems. rather than bolting new cognitive apps onto legacy technology, anthem is using a holistic approach that maximizes the value being generated by the cognitive applications, reduces the overall cost of development and integration, and creates a halo effect on legacy systems. the company is also redesigning processes at the same time to, as cio tom miller puts it, “use cognitive to move us to the next level. ” \\nin scaling up, companies may face substantial \\nchange-management challenges. at one u.s. apparel retail chain, for example, the pilot project at a small subset of stores used machine learning for online product recommendations, predictions for optimal inventory and rapid replenishment models, and—most difficult of all—merchandising. buyers, used to ordering product on the basis of their intuition, felt threatened and made comments like “if you’re going to trust this, what do you need me for?” after the pilot, the buyers went as a group to the chief mer-chandising officer and requested that the program be killed. the executive pointed out that the results were positive and warranted expanding the project. he assured the buyers that, freed of certain merchan-dising tasks, they could take on more high-value work that humans can still do better than machines, such as understanding younger customers’ desires and de-termining apparel manufacturers’ future plans. at the same time, he acknowledged that the merchandisers needed to be educated about a new way of working.\\nif scale-up is to achieve the desired results, fi  rms \\nmust also focus on improving productivity. many, for example, plan to grow their way into productivity—adding customers and transactions without adding staff. companies that cite head count reduction as the primary justifi  cation for the ai investment should \\nideally plan to realize that goal over time through attrition or from the elimination of outsourcing. \\nthe future cognitive company\\nour survey and interviews suggest that managers experienced with cognitive technology are bullish on its prospects. although the early successes are \\nrelatively modest, we anticipate that these technolo-gies will eventually transform work. we believe that companies that are adopting ai in moderation now—and have aggressive implementation plans for the fu-ture—will fi  nd themselves as well positioned to reap \\nbenefi  ts as those that embraced analytics early on. \\nthrough the application of ai, information-inten-\\nsive domains such as marketing, health care, fi  nancial \\nservices, education, and professional services could become simultaneously more valuable and less ex-pensive to society. business drudgery in every indus-try and function—overseeing routine transactions, repeatedly answering the same questions, and ex-tracting data from endless documents—could become the province of machines, freeing up human workers to be more productive and creative. cognitive tech-nologies are also a catalyst for making other data-in-tensive technologies succeed, including autonomous vehicles, the internet of things, and mobile and multi-channel consumer technologies. \\nthe great fear about cognitive technologies is that \\nthey will put masses of people out of work. of course, some job loss is likely as smart machines take over certain tasks traditionally done by  humans. however, \\nwe believe that most workers have little to fear at this point. cognitive systems perform tasks, not entire jobs. the human job losses w e’ve seen were primarily \\ndue to attrition of workers who were not replaced or through automation of outsourced work. most cogni-tive tasks currently being performed augment human activity, perform a narrow task within a much broader job, or do work that wasn’t done by humans in the fi  rst \\nplace, such as big-data analytics.\\nmost managers with whom we discuss the issue \\nof job loss are committed to an augmentation strat-egy—that is, integrating human and machine work, rather than replacing humans entirely. in our survey, only 22% of executives indicated that they considered reducing head count as a primary benefi  t of ai.\\nwe believe that every large company should \\nbe exploring cognitive technologies. there will be some bumps in the road, and there is no room for complacency on issues of workforce displacement and the ethics of smart machines. but with the right planning and development, cognitive technology could usher in a golden age of productivity, work satisfaction, and prosperity. \\n hbr reprint r1801h\\nthomas h. davenport  is the president’s distinguished \\nprofessor of information technology and management \\nat babson college, a research fellow at the mit initiative on the digital economy, and a senior adviser at deloitte analytics. rajeev ronanki  is a principal at deloitte consulting, where he \\nleads the cognitive computing and health care innovation practices. some of the companies mentioned in this article are deloitte clients.further readin g\\n“big idea: the business \\nof artiﬁ  cial intelli gence ”\\nby erik br ynjolfsson and\\nandrew mca fee\\nhbr.org /ai\\n“inside faceboo k’s\\nai worksho p”\\nby scott berinat o\\nhbr.or g/ai\\n“ai can be a \\ntroublesome\\nteammate”\\nby kurt gra y\\nhbr.or g/ai\\n116 \\u2002harvard business review\\u2002 january–february 2018feature artificial intelligence for the real world\\n1264 janfeb18 fea davenport ai_nc.indd   116 1264 janfeb18 fea davenport ai_nc.indd   116 11/28/17   11:07 am 11/28/17   11:07 am',\n",
       " 'review ar ticle\\nhttps:/ / doi.org/10.1038/s41551-018-0305-z1department of biomedical informatics, harvard medical school, boston, ma, usa. 2boston children’s hospital, boston, ma, usa.  \\n*e-mail: isaac_kohane@hms.harvard.eduartificial intelligence is gradually changing the landscape \\nof healthcare and biomedical research. in the aravind eye care system in india, ophthalmologists and computer sci\\n-\\nentists are working together to test and deploy an automated image classification system to screen millions of retinal photographs of diabetic patients\\n1. diabetic retinopathy (dr) affects more than \\n90 million people worldwide and is a leading cause of blindness in \\nadults2. fundus photography is an effective method to monitor the \\nextent of dr and to identify patients who will benefit from early treatments\\n3. however, in many parts of the world, there are too few \\nophthalmologists to read the fundus photographs and to follow up with each diabetic patient\\n4. a team of researchers at google inc. \\nand collaborating institutions showed that an ai system trained on thousands of images can achieve physician-level sensitivity and \\nspecificity in diagnosing referable dr\\n5, as well as in identifying pre -\\nviously unrecognized associations between image patterns in the \\nfundus photograph and cardiovascular risk factors6. the technology \\ngiant is now integrating this ai technology into clinical practice in a chain of eye hospitals in india\\n1, and a related technology devel -\\noped by university of iowa was approved by the us food and drug administration (fda) for detecting moderate-to-severe dr\\n7.\\nai has recently re-emerged into the scientific and public con -\\nsciousness, as new breakthroughs and technologies are announced from technology companies and scientists at a breakneck pace. stripped of its science-fictional ornamentation and aspirations, \\nai is, at its core, a branch of computer science that attempts to \\nboth understand and build intelligent entities, often instantiated as software programs\\n8. ai has a long history that traces its roots \\nback to a conference at dartmouth in 1956, where the term was used for the first time\\n8. the successful development of image clas -\\nsifiers since 2012 has contributed to the recent resurgence of ai9. \\nalthough much progress has been made in the past decades, ai has suffered from an inconsistent and evolving definition as to \\nwhat exactly constitutes ‘real ai’ . it is a well-recognized property \\nof ai research that success in reaching a specific performance goal soon disqualifies that performance as constituting ai, which makes tracking progress difficult. as an illustration, automated route \\nplanners were touted as examples of advanced ai in the 1970s, yet \\nare now so ubiquitous that most people would be surprised to hear them described as ai\\n10. consequently, the successes of ai from the \\n1970s through the 1990s that were once heralded as breakthroughs in medicine, such as the automated interpretation of electrocar\\n-\\ndiograms (ecgs)11, are now regarded as useful but are hardly  \\nconsidered to be examples of true ai.recently, applications of medical-image diagnostic systems \\nhave expanded the frontiers of ai into areas that were previously the domain of human experts. this frontier continues to expand into other areas of medicine, such as clinical practice\\n12, translational \\nmedical research13–16 and basic biomedical research17 (table 1). in \\nthis review article, we focus on the ai applications that could aug -\\nment or change clinical practice, offer a historical perspective on ai in medicine to contextualize recent advancements, summarize the successful application areas, identify the potential societal impact \\narising from the development and deployment of biomedical ai \\nsystems, and suggest future research directions. for a glossary of key terms, see box 1.\\na historical overview of ai in medicine\\nmedicine was identified early as one of the most promising applica -\\ntion areas for ai. since the mid-twentieth century, researchers have proposed and developed many clinical decision support systems\\n18,19. \\nrule-based approaches saw many successes in the 1970s20,21, and \\nhave been shown to interpret ecgs11, diagnose diseases22, choose \\nappropriate treatments23, provide interpretations of clinical reason -\\ning24 and assist physicians in generating diagnostic hypotheses in \\ncomplex patient cases25. however, rule-based systems are costly to \\nbuild and can be brittle, as they require explicit expressions of deci -\\nsion rules and require human-authored updates, just like any text -\\nbook. in addition, it is difficult to encode higher-order interactions among different pieces of knowledge authored by different experts, and the performance of the systems is limited by the comprehen\\n-\\nsiveness of prior medical knowledge26. moreover, it was difficult to \\nimplement a system that integrates deterministic and probabilistic reasoning to narrow down relevant clinical context, prioritize diag\\n-\\nnostic hypotheses, and recommend therapy27.\\nunlike the first generation of ai systems, which relied on the \\ncuration of medical knowledge by experts and on the formulation \\nof robust decision rules, recent ai research has leveraged machine-\\nlearning methods, which can account for complex interactions28, \\nto identify patterns from the data. according to the types of task that they intend to solve\\n28, basic machine-learning algorithms fall \\nroughly into two categories: supervised and unsupervised. supervised machine-learning methods work by collecting a large number of \\n‘training’ cases, which contain inputs (such as fundus photographs) \\nand the desired output labels (such as the presence or absence of dr). by analysing the patterns in all of the labelled input–output pairs, the algorithm learns to produce the correct output for a given input on \\nnew cases\\n29. supervised machine-learning algorithms are designed to artificial intelligence in healthcare\\nkun-hsing\\xa0yu\\u200a \\u200a1, andrew\\xa0l.\\xa0beam1 and isaac\\xa0s.\\xa0kohane1,2*\\nartificial intelligence (ai) is gradually changing medical practice. with recent progress in digitized data acquisition, machine \\nlearning and computing infrastructure, ai applications are expanding into areas that were previously thought to be only the \\nprovince of human experts. in this review article, we outline recent breakthroughs in ai technologies and their biomedical \\napplications, identify the challenges for further progress in medical ai systems, and summarize the economic, legal and social implications of ai in healthcare.\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 719',\n",
       " 'review ar ticle nature biomedical engineeringidentify the optimal parameters in the models to minimize the devia -\\ntions between their predictions for the training cases and the observed \\noutcomes in these cases, with the hope that the identified associa -\\ntions are generalizable to cases not included in the training dataset. the generalizability of the model can be estimated by the test set (fig. 1a). classification, regression and characterization of the similarity \\namong instances of similar outcome labels are among the most widely \\nused tasks of supervised machine-learning models. unsupervised learning infers the underlying patterns in unlabelled data to find sub-clusters of the original data, to identify outliers in the data, or to \\nproduce low-dimensional representations of the data (fig. 1b). note \\nthat the identification of low-dimensional representations for labelled instances could be more effectively achieved in a supervised fashion. machine-learning methods enable the development of ai applications that facilitate the discovery of previously unrecognized patterns in the \\ndata without the need to specify decision rules for each specific task or to account for complex interactions among input features. machine \\nlearning has thus become the preferred framework for building \\n \\nai utilities28,30.\\nthe recent renaissance in ai has to a large extent been driven by \\nthe successful application of deep learning — which involves train -\\ning an artificial neural network with many layers (that is, a ‘deep’ neural network) on huge datasets — to large sources of labelled data. since 2012, deep learning has shown substantial improvements in \\nimage classification tasks\\n9. figure 2 shows a sampling of deep neural \\nnetwork architectures (there are also automated approaches to net -\\nwork architecture design31). the basic architecture of deep neural \\nnetworks consists of an input layer and an output layer, and a num -\\nber of hidden layers in between. perceptron and feedforward neural \\nnetworks are among the simplest designs (fig. 2a,b). autoencoders are used for dimension reduction, whereas sparse autoencoders can \\ngenerate additional useful features (fig. 2c,d). recurrent neural \\nnetworks are useful for handling time-series data (fig. 2e). deep residual neural networks have improved the traditional deep feed\\n-\\nforward neural network by allowing skip connections, avoiding the saturation of model performance\\n32,33 (fig. 2f,g).\\nmany modern neural networks have more than 100 layers. \\nneural networks with many layers can model complex relations \\nbetween the input and output but may require more data, computa -\\ntion time or advanced architecture designs so as to achieve optimal \\nperformance. many types of layers, mathematical operations for the neurons and regularization methods have been designed (table 2). \\nfor example, convolutional layers are useful for extracting spatial \\nor temporal relations, whereas recurrent layers use circular con\\n-\\nnections to model temporal events. also, various initialization and activation functions can enhance model performance. the combi\\n-\\nnation of these components enables neural networks to handle vari -\\nous input data with and without spatial or temporal dependence.\\nmodern neural networks can have tens of millions to hundreds \\nof millions of parameters and take huge amounts of computational \\nresources to train. fortunately, recent advances in computer-pro -\\ncessor design provide the computational power required for deep t able 1 | a non-exhaustive list of current and potential ai \\napplications in medicine\\nbasic biomedical \\nresearchtranslational \\nresearchclinical practice\\nautomated experiments biomarker discovery disease diagnosis\\nautomated data collectiondrug–target prioritizationinterpretation of patient genomes\\ngene function annotation drug discovery t reatment selection\\nprediction of transcription factor binding sitesdrug repurposing automated surgery\\nsimulation of molecular dynamicsprediction of chemical toxicitypatient monitoring\\nliterature mining genetic variant annotationpatient risk stratification for primary preventionbox 1 | a glossary of key terms\\nartificial intelligence. a branch of computer science that at -\\ntempts to both understand and build intelligent entities, often in -\\nstantiated as software programs8.\\ndeep learning. a subfield of the larger discipline of machine \\nlearning. deep learning employs artificial neural networks with \\nmany layers to identify patterns in data32.\\ndimensionality reduction.  the process of reducing the \\nnumber of variables in the data. the raw data can contain a great number of redundant and non-informative variables. for example, nearby pixels of an image may be of similar or identical colour. by reducing the number of variables, statistical analyses can be conducted more effectively and sophisticated \\nmachine-learning models developed without running out of \\ncomputer memory.\\nfeedforward neural network. a type of artificial neural network \\nin which neural layers only connect to the next layer and do not \\nform cycles.\\nfloating-point operations per second (flops). a measure of \\ncomputation performance. in computers, numbers with decimal \\npoints are represented as ‘floating-point numbers’ . flops \\nmeasures the number of floating-point arithmetic operations that a computer system can complete per second; the larger the value, the more powerful the computer system is.graphical processing unit (gpu). computer hardware initially designed to handle computational tasks related to images and to produce outputs to display devices. since modern gpus have many computation cores and can provide fast parallel computation, \\nthey have become the workhorses for training artificial neural \\nnetworks.\\nmachine learning. a field of computer science that uses algorithms \\nto identify patterns in data\\n151.\\nperceptron . a binary classifier developed in the 1950s. it classifies \\nsamples by using the following function: given an input vector x, the output is 1 if w · x +  b >  0, where w and b are two vectors of \\nparameters; otherwise, the output is 0.\\nsupervised machine learning. a type of machine-learning task \\nthat aims at predicting the desired output (such as the presence \\nor absence of dr) on the basis of the input data (such as fundus photographs). supervised machine-learning methods work by identifying the input–output correlation in the ‘training’ phase and by using the identified correlation to predict the correct \\noutput of the new cases.\\nunsupervised machine learning.  a type of machine-learning task \\nthat aims at inferring underlying patterns in unlabelled data. for \\nexample, it can find sub-clusters of the original data, identify outliers \\nin the data, or produce low-dimensional representations of the data.\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 720',\n",
       " 'review ar ticle nature biomedical engineeringlearning. as an illustration, current graphical processing units \\n(gpus) can perform more than 7 trillion floating-point operations per second. any such gpu, which would have ranked among the \\nfastest 100 supercomputers in the world in 2006 (ref. \\n34), is capable \\nof processing hundreds of millions of medical images per day at \\nrelatively low cost35. by harnessing computation power, large datas -\\nets and ‘convolutional’ neural networks (cnns), deep learning has transformed not just medical-image analysis, but the whole field of computer vision. cnns use a special type of layer (that is, a con\\n-\\nvolutional layer) to summarize and transform clusters of pixels in images to extract high-level features. before the advent of cnns, features from the images had to be defined and extracted\\n36, and the \\nperformance of the machine-learning models depended on the qual -\\nity of features. in cnns, a key improvement is that they can operate on the raw image and learn useful features from the training sets, thus simplifying the training process and facilitating the identifica\\n-\\ntion of image patterns. cnns have proven crucial to the success of deep learning in image analysis and are also responsible for the sub\\n-\\nsequent revolution in medical imaging. there is an on-going com -\\nmunity effort to compile neural network applications in biology and medicine37. table 3 summarizes the performance, reproducibility, \\ncomprehensibility, dependency on prior knowledge, development, running costs, update costs and around-the-clock availability for \\nhuman practitioners and for different types of ai approaches.\\nhowever, deep-learning algorithms are extremely ‘data hungry’ \\nfor labelled cases. only recently, large sources of medical data that \\ncan be fed into these algorithms have become widely available, owing \\nto the establishment of many large-scale studies (in particular, the \\ncancer genome atlas\\n38 and the uk biobank39), data-collection plat -\\nforms (such as the broad bioimage benchmark collection40 and the \\nimage data resources41) and the health information technology \\nfor economic and clinical health (hitech) act, signed in 2009. the hitech act provided financial incentives for the adoption \\nof electronic health records (ehrs). in a national survey in 2008, \\nonly 13% of physicians reported having a basic ehr system\\n42; by \\nthe end of 2012, 72% of physicians had adopted some type of ehr system and 40% of physicians reported having capabilities that met \\nthe criteria for a basic system\\n43. the increasing adoption of ehr \\nsystems has not only expedited the collection of large-scale clini -\\ncal data, but also permits smoother integration of ai systems into 05101520\\n05 10 15 20\\nx1b\\n05101520\\n05 10 15 20\\nx1x2\\nx2x2x205101520\\n05 10 15 20 25\\nx1x2clustering\\nanomaly detection\\ndimension reductionclustering\\nalgorithm\\nmodelling\\ndimension\\nreduction\\nalgorithm\\n 0 51 01 52 025\\n20\\n15\\n10\\n5\\n0  0 5101520\\nx1x2x305101520\\n05 10 15 20 25\\nx1\\n05101520\\n05 10 15 20\\nx1a\\ninput\\noutputcollect training, \\nvalidation and \\ntest datasets\\nuse the finalized model \\nto predict the outcomes \\nof cases in the test \\ndatasettraining and \\nvalidation datasettest dataset\\npredictionsuse the training dataset \\nto build the model and \\nthe validation dataset \\nto tune the modeltraining\\ndataset\\nvalidation\\ndataset\\n0.000.250.500.751.00\\n0.00 0.25 0.50 0.75 1.00\\nspecificitysensitivity++\\nmodel\\nestimate the performance\\nof the model bycomparing the predicted\\noutcomes with the observed\\noutcomes in the test dataset\\nfig. 1 |  supervised and unsupervised machine learning. a, general workflow of supervised machine-learning approaches. first, training and test datasets \\nare collected. next, part of the training set is used to build the prediction model, and the other part to tune and validate the model (circular arrow). after the \\nmachine-learning model is finalized (crossed-out circular arrow), the established model is used to generate predictions on the test dataset and the model’s performance is estimated by comparing the predicted outcomes with the observed outcomes for the test dataset. b , unsupervised machine learning includes \\nclustering, anomaly detection and dimensionality reduction. clustering algorithms group data points with similar measurements into clusters. anomaly detection identifies outliers in the dataset. dimensionality reduction reduces the number of random variables used to describe the data; for example, by representing an image with thousands of parameters as a smaller vector of summary features. the resulting summary vector preserves the important information in the raw data; for example, summary vectors from similar images will bear more resemblance than those obtained from irrelevant images.\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 721',\n",
       " 'review ar ticle nature biomedical engineeringthe clinical workflow (fig. 3). conventionally, medical practitio -\\nners collect medical information from the patients, make clinical  \\njudgments and record their diagnoses and treatment plans in the \\nhealth records (fig. 3a). since the 1970s, decision support systems that collect medically relevant information and provide suggestions \\nto clinicians have been developed (fig. 3b). there are a number of \\nways to integrate decision support systems into the clinical work\\n-\\nflow; for instance, decision support systems can actively gather information from patients and ehrs, present suggestions to cli\\n-\\nnicians and store the system outputs in ehrs (fig. 3c). in many proposed fully automated clinical systems, the autonomous tools collect information from the patients, make decisions and output the results into ehrs (fig. 3d) — although such integration has so far been slight. data from ehr systems provide detailed infor\\n-\\nmation about the patients, including clinical notes and laboratory values, enabling the application of natural-language-processing methods to extract codified vocabularies.\\nthe recent confluence of large-scale annotated clinical data \\nacquisition, advancement in machine-learning methods, open-source machine-learning packages, and affordable and rapidly growing computational power and cloud storage has fuelled the \\nrecent exponential growth in ai. this promises to change the land\\n-\\nscape of medical practice in the near term. ai systems have special -\\nist-level performance in many diagnostic tasks5,44, can better predict \\npatient prognosis than clinicians45,46, and can assist in surgical inter -\\nventions47. as machine-learning models continue to advance, there \\nis a growing sense that ai could revolutionize medical practice and \\nredefine the roles of clinicians in the process12.\\nimage-based diagnosis\\ncurrently, automated medical-image diagnosis is arguably the most successful domain of medical ai applications. many medi\\n-\\ncal specialties, including radiology, ophthalmology, dermatology and pathology, rely on image-based diagnoses. in what follows, we summarize recent advances in the application of ai to each of these \\nmedical fields.\\nradiology. diagnostic radiologists use multiple medical-imaging \\nmodalities — the most widely used being x-ray radiography, \\ncomputed tomography, magnetic resonance imaging (mri) and \\npositron-emission tomography — to detect and diagnose dis\\n-\\neases. in each of these approaches, radiologists use a collection of images for disease screening and diagnosis, to identify the cause of illness and to monitor the patient trajectory during the course \\nof a disease\\n48.\\nradiological practice relies primarily on imaging for diagnosis \\nand thus is very amenable to deep-learning techniques, as images often contain a large proportion of the information needed to \\narrive at the correct diagnosis. most radiology departments main\\n-\\ntain a database of historical images in a picture archiving and communication system, which typically provides thousands of examples to train the neural networks. computational approaches for \\nradiology diagnoses have been proposed and implemented since the \\n1960s\\n49. with the help of modern machine-learning methods, many \\nradiology applications of ai, such as the detection of lung nodules using computed tomography images\\n50, the diagnosis of pulmonary \\ntuberculosis and common lung diseases with chest radiography51–54 \\nand breast-mass identification using mammography scans55,56, have \\nreached expert-level diagnostic accuracies. these studies employed a technique known as transfer learning, where well-established deep \\nneural networks trained on millions of natural, non-medical images \\nare borrowed, and then the neural network connections are fine-tuned by using thousands of biomedical images. such a strategy can reduce the number of training samples required to train a neural \\nnetwork with tens of millions of parameters, making it highly effec\\n-\\ntive for medical-image classification where the number of images \\nmay only be in the range of thousands to tens of thousands. for researchers to visualize the neural network models, the relevance \\nof each pixel to the output classes can be investigated. for example, \\nsaliency maps and gradient-weighted class activation maps visual\\n-\\nize the importance of each image region in relation to their classifi -\\ncation and are useful for identifying localized image features6 (fig. \\n4a,b), activation maximization generates images that maximally activate a selected neuron (fig. 4c), and an individual convolution \\nfilter can be visualized by producing synthetic input images that \\nmaximize the filter output (fig. 4d–g). these approaches attempt to make neural network models more interpretable\\n51.a\\nc\\nf\\ngdebinput cell\\noutput cellhidden cell\\nfig. 2 | t he general architecture of artificial neural networks.  \\na, perceptron. given an input vector x from the input cells, the output is 1 \\nif w · x +  b >  0, where w and b are two vectors of parameters; otherwise, \\nthe output is 0. b, a two-layer feedforward neural network. the input layer takes in the data and forwards the data to the cells of the hidden layer. each cell in the hidden layer serves as a function that integrates its inputs and transmits the output of the function into the cells in the next layer. there are no cyclic computations. c, autoencoder. autoencoding is an unsupervised technique that uses neural networks to learn a representation of the input data. an autoencoder is often used for dimensionality reduction. d, sparse autoencoder. an autoencoder with a large number of cells in the hidden layers and a sparsity constraint, which forces most hidden cells to be inactive given the input. this strategy is useful for deriving features for classification tasks. e, recurrent neural network.  a type of neural network that allows connections between the nodes to form directed cycles. it is useful for handling time series. f, deep feedforward neural network. there can be many hidden layers between the input layer and the output layer to model the complex relations between the inputs and the outputs. the last hidden layer connects to the output layer, which generates model outputs. g, deep residual neural network. in this architecture, skip connections are allowed, which in deep neural networks helps avoid performance saturation or degradation.\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 722',\n",
       " 'review ar ticle nature biomedical engineeringmany clinical applications of ai are seeking regulatory approval. \\nfor instance, a deep-learning system for diagnosing cardiovascular \\ndiseases using cardiac mri images was approved by the fda in \\n2018 (refs 57,58). with further validation studies and technology \\ntransfer efforts, we expect that more image-based computer-aided \\ndetection (cad) and diagnostic systems will be put into clinical use \\nin the near term.\\ndermatology. inspection plays an important role in diagnosing \\nmany types of skin lesion. for instance, typical skin melanoma has \\nvisual features that distinguish these lesions from benign moles59. \\nfor the diagnosis of skin melanoma by inspection, dermatologists \\nhave developed rules of thumb, such as the widely known abcde \\nrule. the rule is applied to diagnosing pigmented tumours, where \\ncriterion a refers to the geometrical asymmetry of the tumour, b to irregular borders, c to colour variegation, d to a diameter equal to or more than 6 mm, and e to the enlargement of the surface of the \\nlesion or evolving lesion\\n59,60. with the exception of the e criterion, the \\nother criteria can be assessed from a single photograph of the lesion.\\nfor many years, researchers have attempted to develop auto -\\nmated diagnostic systems that classify photographs of benign and \\nmalignant lesions61,62. recently, convolutional neural networks trained on 129,450 clinical images achieved dermatologist-level \\naccuracy in diagnosing skin malignancy44. the deep-learning  \\nalgorithm outperformed the average dermatologist in a comparison \\nof the algorithm predictions and the assessments by 21 dermatolo -\\ngists on a set of photographic and dermoscopic images. although the training phase of the deep-learning model can be computa\\n-\\ntionally expensive, the finalized diagnostic model can be deployed on mobile devices, potentially improving the accessibility of skin-lesion screening at the expert level globally\\n44.\\nophthalmology. fundus photography is a non-invasive proce -\\ndure that uses retinal cameras to capture images of the retina, optic disc and macula. it can detect and monitor diseases such as dr, glaucoma, neoplasms of the retina and age-related macular degen\\n-\\neration, and plays a vital role in identifying causes of preventable blindness\\n63. in particular, clinical guidelines from the american \\ndiabetes association recommend dr screening for diabetic patients with minimal or no retinopathy every year, and more fre\\n-\\nquent examination for patients with progressing dr64. traditionally, \\nfundus photographs are examined and interpreted by ophthalmolo -\\ngists, which is difficult to scale to the millions of diabetic patients at risk of developing sight-threatening dr\\n65.t able 2 | an overview of the common components of deep neural networks\\ncommon components types function\\nlayers densely connected layer t o operate on the inputs from the previous layer; \\ntoo many densely connected layers can result in \\noverfitting, which could be mitigated by randomly \\nsetting a fraction of inputs to 0 (also called \\ndropout).\\nconvolutional layer t o perform convolution over the input; useful for \\ninputs with spatial or temporal relations.\\npooling layer t o decrease the number of parameters in the neural network, reducing overfitting.\\nrecurrent layer t o allow circular connections between the elements in the neural network; useful for modelling temporal events.\\nembedding layer t o map the input into a dense vector space.\\nnormalization layer t o normalize the amount of activation from the previous layer.\\nnoise layer t o add random noise to the input; useful for reducing overfitting.\\ninitialization functions deterministic t o initialize the values of the cells in the neural network layers to some constants.\\nrandom t o initialize the values of the cells in the neural network layers to some random numbers that follow a certain distribution.\\nactivation functions sigmoid, hyperbolic tangent (tanh), softmax, scaled exponential linear unit (selu), rectified linear units (relu) and otherst o enhance network performance by adding nonlinear factors to the neural network.\\nloss functions mean squared error, mean absolute error, cosine distance, categorical cross-entropy and otherst o evaluate the performance of the neural network; the loss function is a part of the objective function.\\noptimization algorithms stochastic gradient descent, root-mean-square propagation (rmsprop), adagrad, adam and otherst o determine the direction to fine-tune the weights in the neural network\\nregularization methods l1, l2, l1 +  l2 t o prevent large parameters by including the l1 norm (sum of the absolute value), the l2 norm (sum of squares), or the weighted mean of the l1 and l2 norms of parameters into the objective function.\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 723',\n",
       " 'review ar ticle nature biomedical engineeringa team of computer scientists and clinicians recently trained \\nconvolutional neural network models to identify referable dr and \\ndiabetic macular oedema using 128,175 retinal images. in this  retrospective study, the machine-learning model achieved areas under the receiver operating characteristic curve greater than 0.990 in two independent test datasets, which was comparable to the per\\n-a\\nbclinical\\npresentations\\nclinical\\npresentationsehrsdecisions\\nrule-based algorithms/\\nmachine-learning algorithmsclinicians’\\njudgmentsconventional clinical practice\\nconventional decision support systems\\ncclinicians\\nintegrative decision support systemsehrs+\\n+input\\noutputalgorithm\\ndecisions\\nd\\nclinical\\npresentationsdecisionsfully automated clinical system\\nehrsclinical\\npresentationsehrs\\nrule-based algorithms/\\nmachine-learning algorithmsclinicians+input\\noutputalgorithm\\ninput\\noutputalgorithmdecisions\\nfig. 3 | models of information flow in conventional clinical practice, conventional decision support systems, integrative decision support systems and \\nfully automated clinical systems. a, in conventional clinical practice, clinicians collect information from the patients, make clinical decisions using their own judgments, and record their findings in ehrs. b, conventional decision support systems collect information from ehrs and provide suggestions using rule-based algorithms or machine-learning algorithms. clinicians receive the suggestions and make the final decision. c, in integrative decision support systems, the systems can actively request clinically relevant information or gather the data from ehrs, show the results to clinicians, and write them into ehrs automatically. clinicians still need to make the final decision. d, in many proposed fully automated clinical systems, the autonomous systems collect information from the patients, make decisions and output the results to ehrs.t able 3 | c omparisons between human evaluations and different types of ai approaches\\napproaches model \\ncomprehensibilityperformance reproducibility dependency on prior knowledgedevelopment and training costs\\narunning costsaround-the-clock availabilityupdate costs\\nhuman evaluation high moderate or \\nhighmoderate high high high low high\\nrule-based algorithms high moderate or \\nhighhigh high moderate or highlow high high\\nfeature-based machine-learning methodsmoderate or high moderate or highhigh moderate\\nbmoderate low high moderatec\\ndeep artificial neural networkslow or moderate high high low moderate low high low\\nathe estimated cost of training professionals that carry out the clinical tasks (human evaluation) or of developing the automated system (rule-based, feature-based or deep-artificial-neural-network-\\nbased) that performs the tasks. bfor feature-based machine-learning methods, prior knowledge may facilitate the derivation of useful features from the raw data. cwhen the update requires encoding new \\nfeatures, the update cost of feature-based machine-learning methods includes feature engineering and model retraining.\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 724',\n",
       " 'review ar ticle nature biomedical engineeringformance of ophthalmologists5. they also demonstrated that deep \\nlearning can extract previously unrecognized associations between \\nretinal image patterns and age, gender, systolic blood pressure and \\nsmoking status, as well as major adverse cardiac events6, illustrating \\nthe utility of machine learning in eliciting new knowledge from the \\nraw data. another team of researchers showed that the performance \\nof a convolutional neural network exceeded their pre-specified sen -\\nsitivity (85%) and specificity (82.5%); the system was authorized by \\nthe fda for use by healthcare providers to detect diabetic macu -\\nlar oedema and moderate-to-severe dr (early treatment diabetic retinopathy study severity scale, level 35 or higher)\\n7,66.\\npathology. histopathological assessment is the gold standard for \\nthe diagnosis of many cancer types15,67,68. the procedure involves \\nprocessing a biopsy or surgical specimen into tissue slides and \\nstaining the slides with pigments, and then expert pathologists \\ninterpreting the slides under a microscope on the basis of visual \\nevaluation69. however, discrepancies among pathologists have been \\ndocumented69,70, and the process is not easily scalable. moreover, \\nsome quantitative histopathology image features that are barely noticeable by the human eye can predict the survival outcomes of \\ncancer patients\\n45,46,71, indicating the existence of rich yet previously \\nunderutilized information in the pathology slides.with the advent of deep convolutional neural networks, ai can \\nbe useful in the detection of prostate cancer from biopsy speci -\\nmens72, the identification of breast cancer metastasis in lymph \\nnodes72,73 and the detection of mitosis in breast cancer74. for exam -\\nple, machine learning coupled with a system for imaging live-cell \\nbiomarkers can facilitate the risk stratification of prostate and breast cancer patients\\n75. as it is estimated that there will be a net deficit of \\nmore than 5,700 full-time equivalent pathologists by 2030 (ref. 76), \\nan automated system could mitigate this deficit, provide a fast and objective evaluation of the histopathology slides, and improve the \\nquality of care for cancer patients.\\noverall, successful applications in radiology, dermatology, oph\\n-\\nthalmology and pathology leverage the availability of large labelled \\ndata, computation power and deep-learning methods to achieve expert-level diagnostic accuracy\\n77. translating these research results \\ninto clinical applications is not straightforward, yet it has the poten -\\ntial to change current medical practice significantly.\\ngenome interpretation\\nhigh-throughput sequencing methods generate terabytes of raw data for genomic studies. accurate clinical interpretation of these data is key to understanding differences across individuals and \\npaves the way for precision medicine\\n29. however, knowledge about ab c\\nde\\nf g\\nfilter 0 filter 1 filter 2 filter 3 filter 4\\nfilter 5 filter 6 filter 7 filter 8 filter 9\\nfilter 0 filter 1 filter 2 filter 3 filter 4\\nfilter 5 filter 6 filter 7 filter 8 filter 9\\nfilter 0 filter 1 filter 2 filter 3 filter 4\\nfilter 5 filter 6 filter 7 filter 8 filter 9filter 0 filter 1 filter 2 filter 3 filter 4\\nfilter 5 filter 6 filter 7 filter 8 filter 9\\nfig. 4 | example of the interpretation of convolutional neural networks. a, the original image of a coffee mug. b, attention visualization. a gradient-\\nweighted class activation map (grad-cam) of vgg16150 (a neural network with 16 weighted layers that performed well in the image net large scale \\nvisual recognition challenge in 2014) that visualizes the importance of input pixels on the last convolution layer, which summarizes spatial information contained in the image and passes it to the layers that generate the classification. c, activation maximization. an image that maximizes the score for ‘coffee mug’. the same technique can produce the images that maximize the activation of any selected neuron in the convolutional neural networks.  d–g, visualization of the convolution layers in vgg16. any convolution filter could be visualized by generating synthetic input images that maximize the filter output. panel d shows the visualization of 10 filters in the second convolution layer of vgg16. it reveals low-level image patterns, such as colour patches and lines; panel e shows 10 filters in the fourth convolution layer of the same neural network, revealing various linear patterns; panel f shows the patterns that maximize the output of 10 filters in the eighth convolution layer, revealing shape patterns; and panel g shows the patterns for 10 filters in the eleventh convolution layer, revealing complex patterns of shapes and objects. all visualizations were generated by the keras-vis package in python.\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 725',\n",
       " 'review ar ticle nature biomedical engineeringthe human genome is constantly evolving, and it is difficult to \\nsystematically compare a patient’s genome with known cases and controls solely using human curation. deep neural networks can \\nannotate pathogenic genetic variants\\n78 and identify the functions \\nof non-coding dna79 better than conventional methods, such as \\nlogistic regression and support vector machines78. interestingly, \\none neural-network-based approach that transforms the genomic-\\nvariant-calling task into an image classification task achieved bet -\\nter performance than the widely used genome analysis toolkit80,81. \\nsuch computational approaches can also be useful for diagnosing complex diseases with genetic components, such as cancer\\n82.\\nmachine learning for biomarker discovery\\nbiomarker discovery relies on identifying previously unrecognized correlations between thousands of measurements and phenotypes. omics technologies have enabled the high-throughput measure\\n-\\nment of thousands of genes and proteins, and of millions of genomic and epigenomic aberrations\\n29. however, it is almost impossible for \\nresearchers to manually analyse and interpret the vast amount of data gathered from omics approaches. machine-learning methods \\ncan identify the molecular patterns associated with disease status \\nand disease subtypes, account for the high-level interactions among the measurements, and derive omics signatures to predict disease phenotypes\\n83. gene expression, protein abundance levels and dna \\nmethylation profiles can predict the status of a number of diseases, including cancers\\n15,84,85, infectious diseases86 and the risk of down’s \\nsyndrome87. many of the biomarker panels derived from machine \\nlearning have outperformed those selected by experts or by conven -\\ntional statistical methods. a number of them have been approved by the fda and can be routinely used to guide treatment selection\\n84,85,88. \\nnon-omics biomarkers, such as neural excitation signals, could facilitate the development of an interface for prosthetic control\\n89. \\nthe successful deployment of data-driven biomarkers has implica -\\ntions for both clinical management and trial design. nevertheless, the reproducibility of a few biomarkers has been challenged, and it is methodologically fraught to identify robust biomarkers when \\nthe number of measurements or parameters is far larger than the \\nnumber of samples\\n90. with the recent establishment of nationwide \\nbiobanks, standardized high-throughput profiling methods and advanced machine-learning methods, more robust and accurate \\nbiomarkers are expected to arise.\\nclinical outcome prediction and patient monitoring\\nin addition to identifying biomarkers related to clinical phenotypes, \\nthe use of ehrs to predict clinical outcomes shows great promise. bayesian networks can predict mortality, readmission and length \\nof hospital stay by using ehrs from the emergency department\\n91. \\ndata from health insurance claims can be used to predict mortal -\\nity in elderly patients92, patient attributes in the medical notes can \\nbe employed to classify cancer patients with different responses to \\nchemotherapy93, and clinical predictors for the prognosis of patients \\nreceiving thoracic organ transplantation can be identified94. these \\nstudies characterized a number of robust clinical predictors for patient outcomes, and could be used to help guide patients and their \\nphysicians in choosing an individualized treatment strategy.\\npatient monitoring is crucial in intensive care units, operat\\n-\\ning rooms, emergency rooms and cardiac wards where timeli -\\nness in clinical decision-making can be measured in seconds. \\nroutine monitoring devices in these high-acuity contexts gener -\\nate a large amount of data and thus represent a great opportunity for ai-assisted alert systems. by using vital signs and the modified early warning score, a prediction model for cardiac arrest was \\nestablished\\n95. demographics, laboratory results and vital signs can \\nalso be used to predict cardiac arrest, transfer into the intensive \\ncare unit, or death96. in addition, an interpretable machine-learning \\nmodel can assist anaesthesiologists in predicting hypoxaemia events during surgery97. this suggests that, with deep-learning algorithms, \\nraw patient-monitoring data could be better used to avoid informa -\\ntion overload and alert overload while enabling more accurate clini -\\ncal prediction and timely decision-making.\\ninferring health status through wearable devices\\nmodern wearable devices record a plethora of biomedical signals, including heart rate, voice, tremor and limb movement. these bio\\n-\\nlogical signals could be useful for detecting diseases and inferring health conditions. by way of illustration, signs of infectious dis\\n-\\nease and inflammatory responses can be detected early by using heart rate and skin temperature data recorded by wearables\\n98. the \\ninclusion of photoplethysmography sensors in wearables enables the monitoring of cardiovascular diseases, pulmonary diseases, \\nanaemia and sleep apnea\\n99. wearable sensors could also detect \\nand quantify symptoms of patients with parkinson’s disease, such \\nas tremor and impaired hand movement, gait, posture and speech \\npatterns100.\\nalthough personal tracking devices present an opportunity to \\nguide behavioural changes101, the accuracy of the data collected \\nthrough these devices can be variable102,103. in addition, one-third of \\nall us consumers who have owned wearable devices stopped using \\nthem within six months of receiving them, foreshadowing the utility \\nof the devices in fostering long-term behavioural change104,105. more \\nresearch is needed to identify the ways to maximize the effective -\\nness of wearables in the promotion and maintenance of health106.\\nautonomous robotic surgery\\nrobotic systems controlled by ai are routinely used in assembly \\nlines in industry and in many biomedical laboratories107. however, \\nthe development and adoption of autonomous robots in medi -\\ncal interventions has been considerably slower. for many decades, robotic surgery has been synonymous with robotically assisted surgery — systems that facilitate surgical procedures and enable \\nmotions smoother than those achievable by human hands, but that \\nstill require a surgeon for movement control\\n108. for instance, in \\nthe fda-approved da vinci surgical system for minimally invasive operations, surgeons operate the robot from a console\\n109. such sys -\\ntems are designed to translate the surgeon’s hand movements into the movements of instruments inside the patient\\n109 and are therefore \\nnot autonomous.\\nas suturing is one of the most common procedures during \\nsurgery, autonomous knot-tying robots have been developed108. \\nrecently, a supervised autonomous robotic system for suturing an intestinal anastomosis showed, in a laboratory setting, better \\nin vivo suturing quality than surgeons\\n47. this system employed an \\nautonomous suturing algorithm and a plenoptic three-dimensional \\nnear-infrared fluorescent imaging system to perform in vivo open \\nsurgery on pigs. the autonomous system had better consistency of \\nsuturing, higher quality of anastomosis (measured by the pressure at which the anastomosis leaked), and a fewer number of mistakes that required removing the needle from the tissue than hand-sewn \\nsuturing, laparoscopy and robot-assisted surgery with the da vinci \\nsurgical system\\n47. similarly, a number of autonomous robots for \\ncochleostomy have also been proposed110.\\nwith the continuing development of pre-programmed, image-\\nguided and teleoperated surgical robots, more robot-assisted or \\nautomated intervention methods are expected to be incorporated \\nin surgical practice111.\\ntaken together, ai is poised to revolutionize many aspects of \\ncurrent clinical practice in the foreseeable future. ai systems can \\nenhance clinical decision-making, facilitate disease diagnosis, iden -\\ntify previously unrecognized imaging or genomic patterns associ -\\nated with patient phenotypes, and assist in surgical interventions \\nfor various human diseases. ai applications also have the potential to bring clinical expertise to remote regions where specialists are \\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 726',\n",
       " 'review ar ticle nature biomedical engineeringscarce or not available112,113. table 4 summarizes potential clinical \\nintegrations of medical ai systems, stratified by their developmen -\\ntal stages.\\ntechnical challenges in ai developments\\nalthough ai promises to revolutionize medical practice, many \\ntechnical challenges lie ahead. as machine-learning-based meth -\\nods rely heavily on the availability of large amounts of high-quality training data, care must be taken to compile data that is representa\\n-\\ntive of the target patient population. for example, data from dif -\\nferent healthcare environments can contain various types of bias and noise, which may cause a model trained on one hospital’s data to fail to generalize to a different one\\n114. when the diagnostic task \\nhas an imperfect inter-expert agreement, it has been shown that consensus diagnoses could substantially improve the performance \\nof the machine-learning models trained on the data\\n115. adequate \\ndata curation is necessary for handling heterogeneous data. also, \\nobtaining the gold standard of patients’ clinical status requires \\nclinicians to review their clinical notes individually, which is pro -\\nhibitively expensive on a population scale. a silver standard116 that \\nemployed natural-language-processing techniques and diagnostic \\ncodes to impute the true status of the patients has recently been pro -\\nposed117. sophisticated algorithms that can address the idiosyncra -\\nsies and noises of various datasets will enhance the reliability of the prediction models, and hence safety to use them in life-and-death \\n \\ndecisions.\\nseveral high-performing machine-learning models generate \\nresults that are difficult to interpret by unassisted humans. although \\nthese models can achieve better-than-human performance, it is not \\nstraightforward to convey intuitive notions explaining the conclu -\\nsions of the models, to identify model weakness, or to extract addi -\\ntional biological insights from these computational ‘black boxes’ . recent approaches to explain image classification models include visualizing the convolution filters (fig. 4d–g) or the relevance of \\neach image region using saliency maps\\n118 (fig. 4b). however, model \\ninterpretation remains much more challenging for deep neural net -\\nwork models trained on data other than images; this is a focus of \\non-going research effort119.\\nmuch of the recent progress in neural networks has been \\nrestricted to well-defined tasks that do not require integration of \\ndata across multiple modalities. methodologies for applying deep \\nneural networks to general diagnostics (such as the interpretation of signs and symptoms, past medical history, laboratory results and clinical course) and treatment selection are less clear. although deep learning has been successful in image classification, transla\\n-\\ntion, voice recognition120, sound synthesis121 and even neural net -\\nwork design122, clinical diagnostic and treatment tasks often require \\nmore context (for example, patient preferences, values, social sup -\\nport and medical history) than the narrow tasks that deep learning has mastered. additionally, it is unclear how to apply transfer-learn\\n-\\ning methods to integrate insights learned from large non-medical datasets into algorithms for the analysis of multi-modality clinical data. this implies that larger-scale data-collection and data-anno\\n-\\ntation efforts are needed to develop end-to-end ai clinical systems.\\nimplementing a computing environment for collecting, storing \\nand sharing ehrs and other sensitive health data remains a chal -\\nlenge123. privacy-preserving methods can permit secure data sharing \\nthrough cloud services (such as third-party-hosted computing envi -\\nronments)124. to implement such infrastructure widely, however, \\ndevelopment of interoperable applications that meet the standard for the representation of clinical information is required\\n125. deep \\nand smooth data integration across healthcare applications and locations remains spotty and relatively slow. nonetheless, emerging \\napplication-programming interfaces for clinical data are beginning \\nto show significant adoption across multiple ehr vendors, such as the substitutable medical applications and reusable technologies on the fast health interoperability resources platform\\n126,127.\\nalmost all of the reported medical applications of ai have been \\nconducted on retrospective data collected for research and proof of \\nprinciple128. to validate the real-world utility of medical ai systems, \\nprospective clinical studies that evaluate the systems’ performance \\nin clinical settings are needed129. prospective trials will better iden -\\ntify the fragility of ai models in real-world heterogeneous and noisy clinical environments, and point to ways to integrate medical ai into current clinical workflows.\\nsocial, economic and legal challenges\\nas clinical ai systems mature, there will be an inevitable increase in their clinical use and deployment, which will lead to new social, eco\\n-\\nnomic and legal issues130,131. geoffrey hinton — one of the pioneers \\nof neural networks — and many ai researchers envision drastic changes in medical practice\\n114,132. ai is likely to improve the quality \\nof care by reducing human error and decreasing physician fatigue arising from routine clinical tasks. however, it may not necessarily \\nreduce physician workload, as clinical guidelines might suggest that \\nexaminations be carried out more often for at-risk patients. if ai for t able 4 | c linical integration of medical ai at different developmental stages\\nareas where ai \\nperformance is more reliable than that of a human expertareas where ai performance is at the expert levelareas where ai performance is reasonableareas where ai performance is not yet good enoughareas where the nature of the clinician–patient interaction is fundamentally different from that of the ai–patient interaction\\nexamples serum analyser\\n144,145; \\nalert systems (such as drug–drug interaction checkers\\n146,147)assessment of certain radiology images (for example, annotation of cardiovascular mri images\\n57,58 or \\nevaluation of x-ray images for distal radius fracture\\n148); dermoscopic \\nmelanoma diagnosis149; fundus \\nphotograph evaluation for dr5,7ecg reading11surgery; full interaction with patientsemotional support and rapport\\npotential clinical integrationsdelegate to ai ai does the majority of the task, clinicians confirm the diagnosisai does a portion  of the task (such  as screening),  clinicians confirm  the diagnosisclinicians lead the clinical evaluations and intervention, ai assists in routine  sub-tasksclinicians continue to provide the service\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 727',\n",
       " 'review ar ticle nature biomedical engineeringroutine clinical tasks is successfully deployed, it could free up time \\nfor physicians and allow them to concentrate on more sophisticated tasks and more ‘high-touch’ time with their patients. as an illustra\\n-\\ntion, ai could facilitate ophthalmologists in triaging and reading the fundus photographs, enabling them to spend more time in the operating room or discussing treatment plans with their patients. \\nadmittedly, ai could potentially replace some healthcare workers in \\ncarrying out routine tasks, which might in turn reshape the health\\n-\\ncare workforce and alter the current reimbursement framework in healthcare. nonetheless, there is currently little empirical evidence of this kind of impact on the clinical workforce.\\nstate-of-the-art ai applications will not reach their full potential \\nunless they are integrated into clinical workflows\\n133,134. however, \\nresearch has shown that the implementation of ai in healthcare is not trivial. it is widely acknowledged that clinical information \\nsystems result in many unintended consequences, including alert \\nfatigue\\n135, imposition of additional workloads for clinicians, dis -\\nruption of interpersonal (including doctor-to-patient) commu -\\nnication styles, and generation of specific hazards that require a higher level of vigilance to detect\\n136. for example, when a mam -\\nmography cad tool generates a false-negative result, radiologists are more likely to miss the diagnosis than when they are required to interpret the mammography films without cad\\n137. although \\nmany cad models can be adjusted to balance the sensitivity and specificity needed for each clinical use case, it is challenging to \\nidentify the optimal clinical workflow that maximizes the perfor\\n-\\nmance of ai-assisted diagnosis129. the experience of care providers \\nand their patients shows that careful design and implementation \\nare necessary, yet often lacking, to incorporate information sys -\\ntems into clinical settings138,139.\\nfrom a regulatory perspective, clinical ai systems need to be \\ncertified before large-scale deployment. the fda should anticipate \\nan increasing number of premarket-approval submissions (safety \\nand effectiveness evaluations of medical devices that present a potential and unreasonable risk of illness or injury) and 510(k) sub\\n-\\nmissions (premarket submissions made to the fda to demonstrate that a proposed device is at least as safe and effective as a legally marketed device) describing ai systems with direct clinical impact. \\npolicymakers need to set specific criteria for the process of dem\\n-\\nonstrating non-inferiority in 510(k) submissions, such as the vali -\\ndation process and quality and representativeness of the validation \\ndata. machine-learning-based models present a unique challenge to regulatory agencies because the models can evolve rapidly as more \\ndata and user feedback are collected. it is not clear how the updates \\nshould be evaluated. for instance, the new model may be better on average but have worse performance on a subset of patients. the fda announced in april 2018 that it is moving toward a ‘pre-cer\\n-\\ntified approach’ for ai software that learns and improves continu -\\nously140. the proposed approach will first look at the technology \\ndeveloper, rather than primarily at the product141. as such, a clear \\nguideline needs to be made regarding the certification of the teams that develop, revise and update the ai systems\\n129.\\nas ubiquitous data collection becomes more commonplace, con -\\nsensus needs to be reached for a consent framework to guide health-related data sharing. for example, information recorded by mobile sensors\\n142 may contain sensitive information, such as the location \\nof the patients. it is imperative to involve the most representative and broad range of stakeholders when establishing a privacy policy \\nframework for data collection and sharing.\\nai in medicine will inevitably result in legal challenges regarding \\nmedical negligence attributed to complex decision support systems. \\nwhen malpractice cases involving medical ai applications arise, the \\nlegal system will need to provide clear guidance on what entity holds \\nthe liability\\n143. medical professional malpractice insurance needs to \\nbe clear about coverage when healthcare decisions are made in part by an ai system. with the deployment of automated ai for specific clinical tasks, the credentials needed for diagnostic, therapeutic, supportive and paramedical tasks will need to be updated, and the roles of healthcare professionals will continue to evolve as various \\nai modules are incorporated into the standard of care.\\nto address the challenges, ai researchers and medical practitio\\n-\\nners need to work together to prioritize and develop the applica -\\ntions that address crucial clinical needs. hospital administrators \\nwould have to evaluate and mitigate clinical workflow disruption when introducing new ai applications. companies will have to \\ndetermine the right framework within which they can conduct pro\\n-\\nspective clinical trials that evaluate the performance of ai systems \\nin the clinical setting. and insurers should assess the value cre -\\nated by medical ai systems and potentially revise their reimburse -\\nment policy to reduce the cost of healthcare while improving its  \\nquality. multidisciplinary and multi-sector collaborations will be required to facilitate the development and deployment of medical ai applications.\\noutlook\\nai has enhanced clinical diagnosis and decision-making perfor -\\nmance in several medical task domains. how this performance will translate into impact on the landscape of medical practice, includ\\n-\\ning disease detection and treatments, will depend on how nimbly ai applications co-evolve with a healthcare system that is under tremendous financial strain while accommodating rapid advances \\nin molecular and genomic science. clinicians will need to adapt to \\ntheir new roles as information integrators, interpreters and patient supporters, and the medical education system will have to provide them with the tools and methods to do so. who will end up control\\n-\\nling, certifying or profiting from the application of ai is still to be determined, and therefore the balance of regulatory safeguards and market forces to ensure that patients benefit most must be a high \\npriority.\\nreceived: 12 december 2017; accepted: 5 september 2018;  \\npublished online: 3 october 2018\\nreferences\\n 1. simonite, t. google’s ai eye doctor gets ready to go to work in india. \\nwired (6 august 2017).\\n 2. lee, r., wong, t. y . & sabanayagam, c. epidemiology of diabetic retinopathy, diabetic macular edema and related vision loss. eye vis. 2,  \\n17 (2015).\\n 3. lin, d. y ., blumenkranz, m. s., brothers, r. j. & grosvenor, d. m. the sensitivity and specificity of single-field nonmydriatic monochromatic digital fundus photography with remote image interpretation for diabetic retinopathy screening: a comparison with ophthalmoscopy and \\nstandardized mydriatic color photography. am. j. ophthalmol. 134, 204–213 \\n(2002).\\n 4. zheng, y ., he, m. & congdon, n. the worldwide epidemic of diabetic \\nretinopathy. indian j. ophthalmol.  60, 428–431 (2012).\\n 5. gulshan, v . et al. development and validation of a deep learning algorithm \\nfor detection of diabetic retinopathy in retinal fundus photographs. jama \\n316, 2402–2410 (2016).\\n 6. poplin, r. et al. prediction of cardiovascular risk factors from retinal fundus \\nphotographs via deep learning. nat. biomed. eng. 2, 158–164 (2018).\\n 7. abràmoff, m. d., lavin, p . t., birch, m., shah, n. & folk, j. c. pivotal trial \\nof an autonomous ai-based diagnostic system for detection of diabetic retinopathy in primary care offices. npj digit. med. 1, 39 (2018).\\n 8. russell, s. j. & norvig, p . artificial intelligence: a modern approach \\n(prentice hall, new jersey, 2010).\\n 9. krizhevsky, a., sutskever, i. & hinton, g. e. in advances in neural information processing systems  1097–1105 (curran associates,  \\nnevada, 2012).\\n 10. lewis-kraus, g. the great a.i. awakening. the new york times magazine \\n(14 december 2016).\\n 11. kundu, m., nasipuri, m. & basu, d. k. knowledge-based ecg \\ninterpretation: a critical review. pattern recognit. 33, 351–373 (2000).\\n 12. jha, s. & topol, e. j. adapting to artificial intelligence: radiologists and \\npathologists as information specialists. jama 316, 2353–2354 (2016).\\n 13. golub, t. r. et al. molecular classification of cancer: class discovery and class prediction by gene expression monitoring. science  286, 531–537 (1999).\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 728',\n",
       " 'review ar ticle nature biomedical engineering 14. wang, y . et al. gene selection from microarray data for cancer \\nclassification—a machine learning approach. comput. biol. chem. 29,  \\n37–46 (2005).\\n 15. yu, k. h. et al. predicting ovarian cancer patients’ clinical response to platinum-based chemotherapy by their tumor proteomic signatures. j. proteome res.  15, 2455–2465 (2016).\\n 16. yu, k. h. et al. omics analysis system for precision oncology (oasispro): a web-based omics analysis tool for clinical phenotype prediction. bioinformatics  34, 319–320 (2017).\\n 17. check hayden, e. the automated lab. nature  516, 131–132 (2014).\\n 18. miller, r. a. medical diagnostic decision support systems–past, present, and future: a threaded bibliography and brief commentary. j. am. med. inform. assoc.  1, 8–27 (1994).\\n 19. musen, m. a., middleton, b. & greenes, r. a. in biomedical informatics  \\n(eds shortliffe, e. h. & cimino, j. j.) 643–674 (springer, london, 2014).\\n 20. shortliffe, e. computer-based medical consultations: mycin vol. 2 \\n(elsevier, new y ork, 2012).\\n 21. szolovits, p ., patil, r. s. & schwartz, w . b. artificial intelligence in medical diagnosis. ann. intern. med. 108, 80–87 (1988).\\n 22. de dombal, f. t., leaper, d. j., staniland, j. r., mccann, a. p . & horrocks, j. c. computer-aided diagnosis of acute abdominal pain. br. med. j. 2,  \\n9–13 (1972).\\n 23. shortliffe, e. h. et al. computer-based consultations in clinical therapeutics: explanation and rule acquisition capabilities of the mycin system. comput. biomed. res. 8, 303–320 (1975).\\n 24. barnett, g. o., cimino, j. j., hupp, j. a. & hoffer, e. p . dxplain. an evolving diagnostic decision-support system. jama 258, 67–74 (1987).\\n 25. miller, r. a., mcneil, m. a., challinor, s. m., masarie, f. e. jr & myers, j. d. the internist-1/quick medical reference project — status report. western j. med. 145, 816–822 (1986).\\n 26. berner, e. s. et al. performance of four computer-based diagnostic systems. n. engl. j. med. 330, 1792–1796 (1994).\\n 27. szolovits, p . & pauker, s. g. categorical and probabilistic reasoning in medical diagnosis. artif. intell. 11, 115–144 (1978).\\n 28. deo, r. c. machine learning in medicine. circulation  132, 1920–1930 \\n(2015).\\n 29. yu, k. h. & snyder, m. omics profiling in precision oncology. mol. cell. proteomics  15, 2525–2536 (2016).\\n 30. roberts, k. et al. biomedical informatics advancing the national health agenda: the amia 2015 year-in-review in clinical and consumer informatics. j. am. med. inform. assoc. 24, 185–190 (2017).\\n 31. cloud automl\\nalpha (google cloud); https://cloud.google.com/automl/\\n 32. goodfellow, i., bengio, y ., courville, a. & bengio, y . deep learning  1 (mit \\npress, cambridge, 2016).\\n 33. gill, n. s. overview and applications of artificial neural networks. xenonstack  https://www.xenonstack.com/blog/data-science/artificial-neural-\\nnetworks-applications-algorithms/ (2017).\\n 34. top500 list – november 2006 (top500); https://www.top500.org/list/2006/11/\\n 35. beam, a. l. & kohane, i. s. translating artificial intelligence into clinical care. jama 316, 2368–2369 (2016).\\n 36. kamentsky, l. et al. improved structure, function and compatibility for cellprofiler: modular high-throughput image analysis software. bioinformatics  27, 1179–1180 (2011).\\n 37. ching, t. et al. opportunities and obstacles for deep learning in biology and medicine. j. r. soc. interface 15, 20170387 (2018).\\n 38. tomczak, k., czerwinska, p . & wiznerowicz, m. the cancer genome  atlas (tcga): an immeasurable source of knowledge. contemp. oncol.  19, \\n68–77 (2015).\\n 39. sudlow, c. et al. uk biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age. plos med.  12, e1001779 (2015).\\n 40. ljosa, v ., sokolnicki, k. l. & carpenter, a. e. annotated high-throughput microscopy image sets for validation. nat. methods  9, 637 (2012).\\n 41. williams, e. et al. the image data resource: a bioimage data integration and publication platform. nat. methods  14, 775–781 (2017).\\n 42. desroches, c. m. et al. electronic health records in ambulatory care–a national survey of physicians. n. engl. j. med. 359, 50–60 (2008).\\n 43. hsiao, c. j. et al. office-based physicians are responding to incentives and assistance by adopting and using electronic health records. health aff.  32, \\n1470–1477 (2013).\\n 44. esteva, a. et al. dermatologist-level classification of skin cancer with deep neural networks. nature  542, 115–118 (2017).\\n 45. beck, a. h. et al. systematic analysis of breast cancer morphology  uncovers stromal features associated with survival. sci. transl. med. 3, \\n108ra113 (2011).\\n 46. yu, k. h. et al. predicting non-small cell lung cancer prognosis by fully automated microscopic pathology image features. nat. commun.  7,  \\n12474 (2016). 47. shademan, a. et al. supervised autonomous robotic soft tissue surgery. sci. transl. med. 8, 337ra364 (2016).\\n 48. reed, j. c. chest radiology: plain film patterns and differential diagnoses (elsevier health sciences, philadelphia, 2010).\\n 49. lodwick, g. s., haun, c. l., smith, w . e., keller, r. f. & robertson, e. d. computer diagnosis of primary bone tumors: a preliminary report. radiology  80, 273–275 (1963).\\n 50. van ginneken, b., setio, a. a., jacobs, c. & ciompi, f. off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans. in ieee 12th international symposium biomedical imaging (isbi) 286–289 (ieee, 2015).\\n 51. lakhani, p . & sundaram, b. deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks. radiology  284, 574–582 (2017).\\n 52. wang, x. et al. chestx-ray8: hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. preprint at https://arxiv.org/abs/1705.02315 (2017).\\n 53. y ao, l. et al. learning to diagnose from scratch by exploiting dependencies among labels. preprint at https://arxiv.org/abs/1710.10501 (2017).\\n 54. rajpurkar, p . et al. chexnet: radiologist-level pneumonia detection on chest x-rays with deep learning. preprint at https://arxiv.org/abs/1711.05225 (2017).\\n 55. samala, r. k. et al. mass detection in digital breast tomosynthesis: deep convolutional neural network with transfer learning from mammography. med. phys. 43, 6654–6666 (2016).\\n 56. arevalo, j., gonzález, f. a., ramos-pollán, r., oliveira, j. l. & lopez, m. a. g. convolutional neural networks for mammography mass lesion classification. in ieee 37th annual international conference of the engineering in medicine and biology society (embc) 797–800 (ieee, 2015).\\n 57. 510(k) premarket notification (fda, 2017); https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpmn/pmn.cfm?id= k163253\\n 58. marr, b. first fda approval for clinical cloud-based deep learning in healthcare. forbes  (20 january 2017).\\n 59. rigel, d. s., friedman, r. j., kopf, a. w . & polsky, d. abcde—an evolving concept in the early detection of melanoma. arch. dermatol. 141, \\n1032–1034 (2005).\\n 60. thomas, l. et al. semiological value of abcde criteria in the diagnosis of cutaneous pigmented tumors. dermatology  197, 11–17 (1998).\\n 61. ercal, f., chawla, a., stoecker, w . v ., lee, h. c. & moss, r. h. neural network diagnosis of malignant melanoma from color images. ieee trans. biomed. eng.  41, 837–845 (1994).\\n 62. wolf, j. a. et al. diagnostic inaccuracy of smartphone applications for melanoma detection. jama dermatol. 149, 422–426 (2013).\\n 63. panwar, n. et al. fundus photography in the 21st century — a review of recent technological advances and their implications for worldwide healthcare. telemed. j. e. health 22, 198–208 (2016).\\n 64. american diabetes association. 10. microvascular complications and foot care. diabetes care  40, 88–98 (2017).\\n 65. menke, a., casagrande, s., geiss, l. & cowie, c. c. prevalence of and trends in diabetes among adults in the united states, 1988–2012. jama 314, 1021–1029 (2015).\\n 66. abràmoff, m. d. et al. improved automated detection of diabetic retinopathy on a publicly available dataset through integration of deep learning. investigative opthalmology visual sci. 57, 5200–5206 (2016).\\n 67. rorke, l. b. pathologic diagnosis as the gold standard. cancer  79,  \\n665–667 (1997).\\n 68. lakhani, s. r. & ashworth, a. microarray and histopathological analysis of tumours: the future and the past? nat. rev. cancer 1, 151–157 (2001).\\n 69. rubegni, p . et al. automated diagnosis of pigmented skin lesions. int. j. cancer  101, 576–580 (2002).\\n 70. stang, a. et al. diagnostic agreement in the histopathological evaluation of lung cancer tissue in a population-based case-control study. lung cancer  \\n52, 29–36 (2006).\\n 71. yu, k. h. et al. association of omics features with histopathology patterns in lung adenocarcinoma. cell syst. 5, 620–627 (2017).\\n 72. litjens, g. et al. deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis. sci. rep. 6, 26286 (2016).\\n 73. bejnordi, b. e. et al. machine learning detection of breast cancer lymph node metastases. jama 318, 2199–2210 (2017).\\n 74. cireşan, d. c., giusti, a., gambardella, l. m. & schmidhuber, j. in medical image computing and computer-assisted intervention — miccai 2013 (eds \\nmori, k. et al.) 411–418 (springer, berlin, heidelberg, 2013).\\n 75. manak, m. s. et al. live-cell phenotypic-biomarker microfluidic assay for the risk stratification of cancer patients via machine learning. nat. biomed. \\neng.  https://doi.org/10.1038/s41551-018-0285-z (2018).\\n 76. robboy, s. j. et al. pathologist workforce in the united states: i. development of a predictive model to examine factors influencing supply. arch. pathol. lab. med. 137, 1723–1732 (2013).\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 729',\n",
       " 'review ar ticle nature biomedical engineering 77. litjens, g. et al. a survey on deep learning in medical image analysis. med. \\nimage anal. 42, 60–88 (2017).\\n 78. quang, d., chen, y . & xie, x. dann: a deep learning approach for annotating the pathogenicity of genetic variants. bioinformatics  31, 761–763 \\n(2015).\\n 79. quang, d. & xie, x. danq: a hybrid convolutional and recurrent deep neural network for quantifying the function of dna sequences. nucleic acids res. 44, e107 (2016).\\n 80. depristo, m. & poplin, r. deepvariant: highly accurate genomes with deep neural networks. google ai blog https://research.googleblog.com/2017/12/\\ndeepvariant-highly-accurate-genomes.html (2017).\\n 81. poplin, r. et al. creating a universal snp and small indel variant caller with deep neural networks. preprint at https://www.biorxiv.org/content/early/2016/12/14/092890 (2018).\\n 82. kamps, r. et al. next-generation sequencing in oncology: genetic diagnosis, risk prediction and cancer classification. int. j. mol. sci. 18, 308 (2017).\\n 83. he, z. & yu, w . stable feature selection for biomarker discovery. comput. biol. chem. 34, 215–225 (2010).\\n 84. zhang, z. et al. three biomarkers identified from serum proteomic analysis for the detection of early stage ovarian cancer. cancer res. 64, 5882–5890 \\n(2004).\\n 85. wallden, b. et al. development and verification of the pam50-based prosigna breast cancer gene signature assay. bmc med. genomics 8, 54 \\n(2015).\\n 86. sweeney, t. e., wong, h. r. & khatri, p . robust classification of bacterial and viral infections via integrated host gene expression diagnostics. sci. transl. med. 8, 346ra391 (2016).\\n 87. huang, t., hoffman, b., meschino, w ., kingdom, j. & okun, n. prediction of adverse pregnancy outcomes by combinations of first and second trimester biochemistry markers used in the routine prenatal screening of down syndrome. prenat. diagn. 30, 471–477 (2010).\\n 88. mook, s. et al. metastatic potential of t1 breast cancer can be predicted by the 70-gene mammaprint signature. ann. surg. oncol. 17, 1406–1413 \\n(2010).\\n 89. farina, d. et al. man/machine interface based on the discharge timings of spinal motor neurons after targeted muscle reinnervation. nat. biomed. eng. 1, 0025 (2017).\\n 90. altman, r. b. artificial intelligence (ai) systems for interpreting complex medical datasets. clin. pharmacol. ther. 101, 585–586 (2017).\\n 91. cai, x. et al. real-time prediction of mortality, readmission, and length of stay using electronic health record data. j. am. med. inform. assoc. 23, \\n553–561 (2016).\\n 92. makar, m., ghassemi, m., cutler, d. m. & obermeyer, z. short-term mortality prediction for elderly patients using medicare claims data. int. j. mach. learn. comput. 5, 192–197 (2015).\\n 93. ng, t., chew, l. & y ap, c. w . a clinical decision support tool to predict survival in cancer patients beyond 120 days after palliative chemotherapy. j. palliat. med.  15, 863–869 (2012).\\n 94. delen, d., oztekin, a. & kong, z. j. a machine learning-based approach to prognostic analysis of thoracic transplantations. artif. intell. med. 49, 33–42 \\n(2010).\\n 95. churpek, m. m. et al. predicting cardiac arrest on the wards: a nested case-control study. chest  141, 1170–1176 (2012).\\n 96. churpek, m. m. et al. multicenter development and validation of a risk stratification tool for ward patients. am. j. respir. crit. care med. 190, \\n649–655 (2014).\\n 97. lundberg, s. m. et al. explainable machine-learning predictions for the prevention of hypoxaemia during surgery. nat. biomed. eng. https://doi.\\norg/10.1038/s41551-018-0304-0 (2018).\\n 98. li, x. et al. digital health: tracking physiomes and activity using wearable biosensors reveals useful health-related information. plos biol. 15, \\ne2001402 (2017).\\n 99. majumder, s., mondal, t. & deen, m. j. wearable sensors for remote health monitoring. sensors 17, 130 (2017).\\n 100. pastorino, m., arredondo, m., cancela, j. & guillen, s. wearable sensor network for health monitoring: the case of parkinson disease. j. phys. conf. ser. 450, 012055 (2013).\\n 101. mercer, k., li, m., giangregorio, l., burns, c. & grindrod, k. behavior change techniques present in wearable activity trackers: a critical analysis. jmir mhealth uhealth 4, e40 (2016).\\n 102. takacs, j. et al. validation of the fitbit one activity monitor device during treadmill walking. j. sci. med. sport 17, 496–500 (2014).\\n 103. y ang, r., shin, e., newman, m. w . & ackerman, m. s. when fitness trackers don’t ‘fit’: end-user difficulties in the assessment of personal tracking device accuracy. in proceedings of the 2015 acm international  joint conference on pervasive and ubiquitous computing  623–634  \\n(acm, 2015).\\n 104. endeavour partners. inside wearables: how the science of human behavior change offers the secret to long-term engagement. medium  https://blog.endeavour.partners/inside-wearable-how-the-science-of-human-behavior-change-offers-the-secret-to-long-term-engagement-a15b3c7d4cf3 (2017).\\n 105. herz, j. c. wearables are totally failing the people who need them most. wired  (11 june 2014).\\n 106. clawson, j., pater, j. a., miller, a. d., mynatt, e. d. & mamykina, l. no longer wearing: investigating the abandonment of personal health-tracking technologies on craigslist. in proceedings of the 2015 acm international joint conference on pervasive and ubiquitous computing  647–658 (acm, \\n2015).\\n 107. wheeler, m. j. overview on robotics in the laboratory. ann. clin. biochem. 44, 209–218 (2007).\\n 108. moustris, g. p ., hiridis, s. c., deliparaschos, k. m. & konstantinidis, k. m. evolution of autonomous and semi-autonomous robotic surgical systems: a review of the literature. int. j. med. robot. 7, 375–392 (2011).\\n 109. gomes, p . surgical robotics: reviewing the past, analysing the present, imagining the future. robot. comput. integr. manuf.  27, 261–266 (2011).\\n 110. majdani, o. et al. a robot-guided minimally invasive approach for cochlear implant surgery: preliminary results of a temporal bone study. int. j. comput. assist. radiol. surg.  4, 475–486 (2009).\\n 111. elek, r. et al. recent trends in automating robotic surgery. in 2016 ieee 20th jubilee international conference on intelligent engineering systems (ines) 27–32 (ieee, 2016).\\n 112. liew, c. the future of radiology augmented with artificial intelligence: a strategy for success. eur. j. radiol. 102, 152–156 (2018).\\n 113. jones, l., golan, d., hanna, s. & ramachandran, m. artificial intelligence, machine learning and the evolution of healthcare: a bright future or cause for concern? bone joint res. 7, 223–225 (2018).\\n 114. obermeyer, z. & emanuel, e. j. predicting the future — big data, machine learning, and clinical medicine. n. engl. j. med. 375, 1216–1219 (2016).\\n 115. krause, j. et al. grader variability and the importance of reference standards for evaluating machine learning models for diabetic retinopathy. ophthalmology  125, 1264–1272 (2018).\\n 116. rebholz-schuhmann, d. et al. the calbc silver standard corpus for biomedical named entities—a study in harmonizing the contributions from four independent named entity taggers. in lrec 568–573 (2010).\\n 117. kirby, j. c. et al. phekb: a catalog and workflow for creating electronic phenotype algorithms for transportability. j. am. med. inform. assoc. 23, \\n1046–1052 (2016).\\n 118. simonyan, k., vedaldi, a. & zisserman, a. deep inside convolutional networks: visualising image classification models and saliency maps. preprint at https://arxiv.org/abs/1312.6034 (2013).\\n 119. ribeiro, m. t., singh, s. & guestrin, c. “why should i trust you?”: explaining the predictions of any classifier. preprint at https://arxiv.org/abs/1602.04938 (2016).\\n 120. lecun, y ., bengio, y . & hinton, g. deep learning. nature  521, 436–444 \\n(2015).\\n 121. boulanger-lewandowski, n., bengio, y . & vincent, p . modeling temporal dependencies in high-dimensional sequences: application to polyphonic music generation and transcription. preprint at https://arxiv.org/abs/1206.6392 (2012).\\n 122. zoph, b. & le, q. v . neural architecture search with reinforcement learning. preprint at https://arxiv.org/abs/1611.01578 (2016).\\n 123. lee, l. m. & gostin, l. o. ethical collection, storage, and use of public health data: a proposal for a national privacy protection. jama 302, 82–84 \\n(2009).\\n 124. narayan, s., gagné, m. & safavi-naini, r. privacy preserving ehr system using attribute-based infrastructure. in proceedings of the 2010 acm workshop on cloud computing security workshop 47–52 (acm, 2010).\\n 125. dolin, r. h. et al. hl7 clinical document architecture, release 2. j. am. med. inform. assoc.  13, 30–39 (2006).\\n 126. mandl, k. d. & kohane, i. s. escaping the ehr trap—the future of health it. n. engl. j. med. 366, 2240–2242 (2012).\\n 127. mandel, j. c., kreda, d. a., mandl, k. d., kohane, i. s. & ramoni, r. b. smart on fhir: a standards-based, interoperable apps platform for electronic health records. j. am. med. inform. assoc. 23, 899–908 (2016).\\n 128. all eyes are on ai. nat. biomed. eng. 2, 139 (2018).\\n 129. yu, k. h. & kohane i. s. framing the challenges of artificial intelligence in medicine. bmj qual. safety https://doi.org/10.1136/bmjqs-2018-008551 \\n(2018).\\n 130. dignum, v . ethics in artificial intelligence: introduction to the special issue. ethics inf. technol. 20, 1–3 (2018).\\n 131. price, i. & nicholson, w . artificial intelligence in health care: applications and legal implications (univ. michigan law school, 2017).\\n 132. mukherjee, s. a.i. versus m.d. what happens when diagnosis is automated? the new yorker (3 april 2017).\\n 133. del beccaro, m. a., jeffries, h. e., eisenberg, m. a. & harry, e. d. computerized provider order entry implementation: no association with increased mortality rates in an intensive care unit. pediatrics  118, 290–295 \\n(2006).\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 730',\n",
       " 'review ar ticle nature biomedical engineering 134. longhurst, c. a. et al. decrease in hospital-wide mortality rate after \\nimplementation of a commercially sold computerized physician order entry system. pediatrics  126, 14–21 (2010).\\n 135. carspecken, c. w ., sharek, p . j., longhurst, c. & pageler, n. m. a clinical case of electronic health record drug alert fatigue: consequences for patient outcome. pediatrics  131, 1970–1973 (2013).\\n 136. ash, j. s., berg, m. & coiera, e. some unintended consequences of information technology in health care: the nature of patient care information system-related errors. j. am. med. inform. assoc. 11, 104–112 \\n(2004).\\n 137. lehman, c. d. et al. diagnostic accuracy of digital screening mammography with and without computer-aided detection. jama intern. med.  175, 1828–1837 (2015).\\n 138. koppel, r. et al. role of computerized physician order entry systems in facilitating medication errors. jama 293, 1197–1203 (2005).\\n 139. middleton, b. et al. enhancing patient safety and quality of care by improving the usability of electronic health record systems: recommendations from amia. j. am. med. inform. assoc. 20, 2–8 (2013).\\n 140. gottlieb, s. twitter (12 april 2018); https://twitter.com/sgottliebfda/\\nstatus/984378648781312002\\n 141. digital health software precertification (pre-cert) program (fda); https://\\nwww.fda.gov/medicaldevices/digitalhealth/digitalhealthprecertprogram/default.htm\\n 142. estrin, d. & sim, i. open mhealth architecture: an engine for health care innovation. science  330, 759–760 (2010).\\n 143. shortliffe, e. h. computer programs to support clinical decision making. jama 258, 61–66 (1987).\\n 144. armbruster, d. a., overcash, d. r. & reyes, j. clinical chemistry laboratory automation in the 21st century—amat victoria curam (victory loves careful preparation). clin. biochem. rev. 35, 143–153 (2014).\\n 145. rosenfeld, l. a golden age of clinical chemistry: 1948–1960. clin. chem. 46, 1705–1714 (2000).\\n 146. kuperman, g. j. et al. medication-related clinical decision support in computerized provider order entry systems: a review. j. am. med. inform. assoc.  14, 29–40 (2007).\\n 147. glassman, p . a., simon, b., belperio, p . & lanto, a. improving recognition of drug interactions: benefits and barriers to using automated drug alerts. med. care 40, 1161–1171 (2002). 148. fda permits marketing of artificial intelligence algorithm for aiding providers in detecting wrist fractures. https://www.fda.gov/newsevents/newsroom/pressannouncements/ucm608833.htm (fda, 2018).\\n 149. haenssle, h. a. et al. man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists. ann. oncol. 29, 1836–1842 \\n(2018).\\n 150. simonyan, k. & zisserman, a. very deep convolutional networks for large-scale image recognition. preprint at https://arxiv.org/abs/1409.1556 (2014).\\n 151. murphy, k. p . & bach f. machine learning: a probabilistic perspective (mit press, cambridge, 2012).\\nacknowledgements\\nk.-h.y . is supported by a harvard data science postdoctoral fellowship. i.s.k. was \\nsupported in part by the nih grant ot3od025466. figure 4 was generated by using the computational infrastructure supported by the aws cloud credits for research, the microsoft azure research award, and the nvidia gpu grant programme.\\nauthor contributions\\nk.-h.y . conceived and designed the article, performed the literature review and wrote \\nand revised the manuscript. a.l.b. and i.s.k. edited the manuscript. i.s.k. supervised \\nthe work.\\ncompeting interests\\nharvard medical school (k.-h.y .) submitted a provisional patent application on digital pathology profiling to the united states patent and trademark office (uspto).\\nadditional information\\nreprints and permissions information is available at www.nature.com/reprints.\\ncorrespondence should be addressed to i.s.k.\\npublisher’s note: springer nature remains neutral with regard to jurisdictional claims in \\npublished maps and institutional affiliations.\\n© springer nature limited 2018\\nnature biomedic al engineering | vol 2 | october 2018 | 719–731 | www.nature.com/natbiomedeng 731',\n",
       " ' \\n 1 artificial intelligence: the global landscape of ethics guidelines    anna jobin a, marcello ienca a, effy vayena a*    a health ethics & policy lab, eth zurich, 8092 zurich, switzerland  * corresponding author: effy.vayena@hest.ethz.ch    preprint version  © the authors 2019       abstract in the last five years, private companies, research institutions as well as public sector organisations have issued principles and guidelines for ethical ai, yet there is debate about both what constitutes “ethical ai” and which ethical requirements, technical standards and best practices are needed for its realization. to investigate whether a global agreement on these questions is emerging, we mapped and analyzed the current corpus of principles and guidelines on ethical ai. our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted; why they are deemed important; what issue, domain or actors they pertain to; and how they should be implemented. our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.',\n",
       " '  \\n 2 main article introduction artificial intelligence (ai), or the theory and development of computer systems able to perform tasks normally requiring human intelligence, is widely heralded as an ongoing “revolution” transforming science and society altogether1,2. while approaches to ai such as machine learning, deep learning and artificial neural networks are reshaping data processing and analysis3, autonomous and semi-autonomous systems are being increasingly used in a variety of sectors including healthcare, transportation and the production chain4. in light of its powerful transformative force and profound impact across various societal domains, ai has sparked ample debate about the principles and values that should guide its development and use5,6. fears that ai might jeopardize jobs for human workers7, be misused by malevolent actors8, elude accountability or inadvertently disseminate bias and thereby undermine fairness9 have been at the forefront of the recent scientific literature and media coverage. several studies have discussed the topic of ethical ai10–13, notably in meta-assessments14–16 or in relation to systemic risks17,18 and unintended negative consequences like algorithmic bias or discrimination19–21.  national and international organisations have responded to these societal fears by developing ad hoc expert committees on ai, often commissioned with the drafting of policy documents. these include the high-level expert group on artificial intelligence appointed by the european commission, the expert group on ai in society of the organisation for economic co-operation and development (oecd), the advisory council on the ethical use of artificial intelligence and data in singapore, and the select committee on artificial intelligence of the united kingdom (uk) house of lords. as part of their institutional appointments, these committees have produced or are reportedly producing reports and guidance documents on ai. similar efforts are taking place in the private sector, especially among corporations who rely on ai for their business. in 2018 alone, companies such as google and sap have publicly released ai guidelines and principles. declarations and recommendations have also been issued by professional associations and non-profit organisations such as the association of computing machinery (acm), access now and amnesty international. the intense efforts of such a diverse set of stakeholders in issuing ai principles and policies demonstrate not only the need for ethical guidance, but also the ',\n",
       " '  \\n 3 strong interest of these stakeholders to shape the ethics of ai in ways that meet their respective priorities16. notably, the private sector’s involvement in the ai-ethics arena has been called into question for potentially using such high-level soft-policy as a portmanteau to either render a social problem technical16 or to eschew regulation altogether22. beyond the composition of the groups that have produced ethical guidance on ai, the content of this guidance itself is of interest. are these various groups converging on what ethical ai should be, and the ethical principles that will determine the development of ai? if they diverge, what are these differences and can they be reconciled?  to answer these questions, we conducted a scoping review of the existing corpus of guidelines on ethical ai. our analysis aims at mapping the global landscape of existing principles and guidelines for ethical ai and thereby determining whether a global convergence is emerging regarding both the principles for ethical ai and the requirements for its realization. this analysis will inform scientists, research institutions, funding agencies, governmental and inter-governmental organisations and other relevant stakeholders involved in the advancement of ethically responsible innovation in ai.   results our search identified 84 documents containing ethical principles or guidelines for ai (cf. table 1). data reveal a significant increase over time in the number of publications, with 88% having been released after 2016 (cf. si table s1). data breakdown by type and geographic location of issuing organisation (cf. si table s1) shows that most documents were produced by private companies (n=19; 22.6%) and governmental agencies respectively (n=18; 21.4%), followed by academic and research institutions (n=9; 10.7%), inter-governmental or supra-national organisations (n=8; 9.5%), non-profit organisations and professional associations/scientific societies (n=7 each; 8.3% each), private sector alliances (n=4; 4.8%), research alliances (n=1; 1.2%), science foundations (n=1; 1.2%), federations of worker unions (n=1; 1.2%) and political parties (n=1; 1.2%). four documents were issued by initiatives belonging to more than one of the above categories and four more could not be classified at all (4.8% each).   ',\n",
       " \"  \\n 4 table 1- ethical guidelines for ai by country of issuer name of document/website issuer country of issuer artificial intelligence. australia's ethics framework. a discussion paper department of industry innovation and science australia montréal declaration: responsible ai université de montréal canada work in the age of artificial intelligence. four perspectives on the economy, employment, skills and ethics ministry of economic affairs and employment finland tieto’s ai ethics guidelines tieto finland commitments and principles op group finland how can humans keep the upper hand? report on the ethical matters raised by ai algorithms french data protection authority (cnil)  france for a meaningful artificial intelligence. towards a french and european strategy mission villani france ethique de la recherche en robotique cerna (allistene) france ai guidelines deutsche telekom germany sap’s guiding principles for artificial intelligence sap germany automated and connected driving: report federal ministry of transport and digital infrastructure, ethics commission germany ethics policy icelandic institute for intelligent machines (iiim) iceland discussion paper: national strategy for artificial intelligence national institution for transforming india (niti aayog) india l'intelligenzia artificiale al servizio del cittadino agenzia per l'italia digitale (agid) italy the japanese society for artificial intelligence ethical guidelines japanese society for artificial intelligence japan report on artificial intelligence and human society (unofficial translation) advisory board on artificial intelligence and human society (initiative of the minister of state for science and technology policy) japan draft ai r&d guidelines for international discussions institute for information and communications policy (iicp), the conference toward ai network society japan sony group ai ethics guidelines sony japan human rights in the robot age report the rathenau institute netherlands dutch artificial intelligence manifesto special interest group on artificial intelligence (sigai), ict platform netherlands (ipn) netherlands artificial intelligence and privacy the norwegian data protection authority norway discussion paper on artificial intelligence (ai) and personal data - fostering responsible development and adoption of ai personal data protection commission singapore singapore mid- to long-term master plan in preparation for the intelligent information society government of the republic of korea south korea ai principles of telefónica telefonica spain ai principles & ethics smart dubai uae principles of robotics engineering and physical sciences research council uk (epsrc) uk the ethics of code: developing ai for business with five core principles sage uk big data, artificial intelligence, machine learning and data protection information commissioner's office uk deepmind ethics & society principles deepmind ethics & society uk business ethics and artificial intelligence institute of business ethics uk ai in the uk: ready, willing and able? uk house of lords, select committee on artificial intelligence uk artificial intelligence (ai) in health royal college of physicians uk initial code of conduct for data-driven health and care technology uk department of health & social care uk ethics framework - responsible ai machine intelligence garage ethics committee uk the responsible ai framework pricewaterhousecoopers uk uk responsible ai and robotics. an ethical framework. accenture uk uk machine learning: the power and promise of computers that learn by example the royal society uk ethical, social, and political challenges of artificial intelligence in health future advocacy uk unified ethical frame for big data analysis. iaf big data ethics initiative, part a the information accountability foundation uk the ai now report. the social and economic implications of artificial intelligence technologies in the near-term ai now institute usa statement on algorithmic transparency and accountability association for computing machinery (acm) usa ai principles future of life institute usa ai - our approach microsoft usa artificial intelligence. the public policy opportunity intel corporation usa ibm’s principles for trust and transparency ibm usa openai charter openai usa our principles google usa policy recommendations on augmented intelligence in health care h-480.940 american medical association (ama) usa everyday ethics for artificial intelligence. a practical guide for designers & developers ibm usa governing artificial intelligence. upholding human rights & dignity data & society usa intel’s ai privacy policy white paper. protecting individuals’ privacy and data in the artificial intelligence world intel corporation usa introducing unity’s guiding principles for ethical ai – unity blog unity technologies usa digital decisions center for democracy & technology usa science, law and society (sls) initiative the future society usa ai now 2018 report ai now institute usa responsible bots: 10 guidelines for developers of conversational ai microsoft usa preparing for the future of artificial intelligence executive office of the president; national science and technology council; committee on technology usa the national artificial intelligence research and development strategic plan national science and technology council; networking and information technology research and development subcommittee usa \",\n",
       " \"  \\n 5 ai now 2017 report ai now institute usa position on robotics and artificial intelligence the greens (green working group robots) eu report with recommendations to the commission on civil law rules on robotics european parliament eu ethics guidelines for trustworthy ai high-level expert group on artificial intelligence eu ai4people—an ethical framework for a good ai society: opportunities, risks, principles, and recommendations ai4people eu european ethical charter on the use of artificial intelligence in judicial systems and their environment concil of europe: european commission for the efficiency of justice (cepej) eu statement on artificial intelligence, robotics and 'autonomous' systems european commission, european group on ethics in science and new technologies eu artificial intelligence and machine learning: policy paper internet society international report of comest on robotics ethics comest/unesco international ethical principles for artificial intelligence and data analytics software & information industry association (siia), public policy division international iti ai policy principles information technology industry council (iti) international ethically aligned design. a vision for prioritizing human well-being with autonomous and intelligent systems, version 2 institute of electrical and electronics engineers (ieee), the ieee global initiative on ethics of autonomous and intelligent systems international top 10 principles for ethical artificial intelligence uni global union international the malicious use of artificial intelligence: forecasting, prevention, and mitigation future of humanity institute; university of oxford; centre for the study of existential risk; university of cambridge; center for a new american security; electronic frontier foundation; openai international white paper: how to prevent discriminatory outcomes in machine learning wef, global future council on human rights 2016-2018 international privacy and freedom of expression in the age of artificial intelligence privacy international & article 19 international the toronto declaration: protecting the right to equality and non-discrimination in machine learning systems access now ; amnesty international international charlevoix common vision for the future of artificial intelligence leaders of the g7 international artificial intelligence: open questions about gender inclusion w20 international declaration on ethics and data protection in artificial intelligence icdppc international universal guidelines for artificial intelligence the public voice international ethics of ai in radiology: european and north american multisociety statement american college of radiology; european society of radiology; radiology society of north america; society for imaging informatics in medicine; european society of medical imaging informatics; canadian association of radiologists; american association of physicists in medicine international ethically aligned design: a vision for prioritizing human well-being with autonomous and intelligent systems, first edition (ead1e) institute of electrical and electronics engineers (ieee), the ieee global initiative on ethics of autonomous and intelligent systems international tenets partnership on ai n.a. principles for accountable algorithms and a social impact statement for algorithms fairness, accountability, and transparency in machine learning (fatml) n.a. 10 principles of responsible ai women leading in ai n.a.  in terms of geographic distribution, data show a significant representation of more economically developed countries (medc), with the usa (n=20; 23.8%) and the uk (n=14; 16.7%) together accounting for more than a third of all ethical ai principles, followed by japan (n=4; 4.8%), germany, france, and finland (each n=3; 3.6% each). the cumulative number of sources from the european union, comprising both documents issued by eu institutions (n=6) and documents issued within each member state (13 in total), accounts for 19 documents overall. african and south-american countries are not represented independently from international or supra-national organisations (cf. figure 1).  \",\n",
       " '  \\n 6 figure 1- geographic distribution of issuers of ethical ai guidelines by number of documents released \\n figure 1: geographic distribution of issuers of ethical ai guidelines by number of documents released. most ethics guidelines are released in the united states (n=20) and within the european union (19), followed by the united kingdom (14) and japan (4). canada, iceland, norway, the united arab emirates, india, singapore, south korea, australia are represented with 1 document each. having endorsed a distinct g7 statement, member states of the g7 countries are highlighted separately. map created using mapchart.net.  data breakdown by target audience indicates that most principles and guidelines are addressed to multiple stakeholder groups (n=27; 32.1%). another significant portion of the documents is self-directed, as they are addressed to a category of stakeholders within the sphere of activity of the issuer such as the members of the issuing organisation or the issuing company’s employees (n=24; 28.6%). finally, some documents target the public sector (n=10; 11.9%), the private sector (n=5; 6.0%), or other specific stakeholders beyond members of the issuing organisation, namely developers or designers (n=3; 3.6%), ‘organisations’ (n=1; 1.2%) and researchers (n=1; 1.2%). 13 sources (15.5%) do not specify their target audience (cf. si table s1).   eleven overarching ethical values and principles have emerged from our content analysis. these are, by frequency of the number of sources in which they were featured: transparency, justice and fairness, non-maleficence, responsibility, privacy, beneficence, freedom and autonomy, trust, dignity, sustainability, and solidarity (cf. table 2).  \\n',\n",
       " '  \\n 7 table 2 – ethical principles identified in existing ai guidelines ethical principle number of documents included codes transparency 73/84 transparency, explainability, explicability, understandability, interpretability, communication, disclosure, showing justice & fairness 68/84 justice, fairness, consistency, inclusion, equality, equity, (non-)bias, (non-)discrimination, diversity, plurality, accessibility, reversibility, remedy, redress, challenge, access and distribution non-maleficence 60/84 non-maleficence, security, safety, harm, protection, precaution, prevention, integrity (bodily or mental), non-subversion responsibility 60/84 responsibility, accountability, liability, acting with integrity privacy 47/84 privacy, personal or private information beneficence 41/84 benefits, beneficence, well-being, peace, social good, common good freedom & autonomy 34/84 freedom, autonomy, consent, choice, self-determination, liberty, empowerment trust 28/84 trust sustainability 14/84 sustainability, environment (nature), energy, resources (energy) dignity 13/84 dignity solidarity 6/84 solidarity, social security, cohesion  no single ethical principle appeared to be common to the entire corpus of documents, although there is an emerging convergence around the following principles: transparency, justice and fairness, non-maleficence, responsibility, and privacy. these principles are referenced in more than half of all the sources. nonetheless, further thematic analysis reveals significant semantic and conceptual divergences in both how the eleven ethical principles are interpreted and the specific recommendations or areas of concern derived from each. a detailed thematic evaluation is presented in the following.  transparency featured in 73/84 sources, transparency is the most prevalent principle in the current literature. thematic analysis reveals significant variation in relation to the interpretation, ',\n",
       " '  \\n 8 justification, domain of application, and mode of achievement. references to transparency comprise efforts to increase explainability, interpretability or other acts of communication and disclosure (cf. table 2). principal domains of application include data use23–26, human-ai interaction23,27–35, automated decisions26,36–46, and the purpose of data use or application of ai systems24,27,47–51. primarily, transparency is presented as a way to minimize harm and improve ai36–38,44,45,49,52–55, though some sources underline its benefit for legal reasons37,45,46,49,50,52 or to foster trust23,24,29,33,36,37,48,51,52,56–58. a few sources also link transparency to dialogue, participation, and the principles of democracy30,41,49,50,52,59.  to achieve greater transparency, many sources suggest increased disclosure of information by those developing or deploying ai systems36,51,60,61, although specifications regarding what should be communicated vary greatly: use of ai45, source code31,52,62, data use35,47,50,58, evidence base for ai use57, limitations25,33,47,51,58,60,63, laws62,64, responsibility for ai40, investments in ai44,65 and possible impact66. the provision of explanations ‘in non-technical terms’26 or auditable by humans37,60 is encouraged. whereas audits and auditability28,39,44,45,50,59,61,62,67,68 are mainly proposed by data protection offices and npos, it is mostly the private sector that suggests technical solutions27,30,52,59,69,70. alternative measures focus on oversight45,47,48,55,62, interaction and mediation with stakeholders and the public24,32,36,51,61,71 and the facilitation of whistleblowing36,60.  justice, fairness, and equity justice is mainly expressed in terms of fairness23,25,27–29,48,50,58,60,66,72–77, and of prevention, monitoring or mitigation of unwanted bias23,28,33,40,47,52,54,58,64,69,73,74,78–80 and discrimination28,33,36,38,44,45,50,55,56,60,68,81–84, the latter being significantly less referenced than the first two by the private sector. whereas some sources focus on justice as respect for diversity31,38,56,59,65,66,70,72,78,80,85,86, inclusion31,45,47,51,72,80 and equality41,45,51,59,60,72,78, others call for a possibility to appeal or challenge decisions28,35–37,74,79, or the right to redress33,42,45,46,50,68,85 and remedy45,48. sources also emphasize the importance of fair access to ai59,70,87, to data33,37,44,67,83,88–90, and to the benefits of ai37,38,80,91. issuers from the public sector place particular emphasis on ai’s impact on the labor market37,38,55,84,92, and the need to address democratic33,38,59,73 or societal31,48,55,65 issues. sources focusing on the risk of biases within datasets underline the importance of acquiring and processing accurate, complete and diverse data23,28,52,70,93, especially training data27,33,35,38,52,58. ',\n",
       " '  \\n 9  if specified, the preservation and promotion of justice are proposed to be pursued through: (a) technical solutions such as standards50,68,89 or explicit normative encoding28,37,43,67; (b) transparency54,62, notably by providing information36,38,79 and raising public awareness of existing rights and regulation28,59; (c) testing52,58,67,69, monitoring54,56 and auditing39,46,50,67, the preferred solution of notably data protection offices; (d) developing or strengthening the rule of law and the right to appeal, recourse, redress, or remedy37,38,42,45,46,48,68,74,79; (e) via systemic changes and processes such as governmental action42,45,87,92 and oversight94, a more interdisciplinary47,65,85,93 or otherwise diverse58,59,70,85,87,95 workforce, as well as better inclusion of civil society or other relevant stakeholders in an interactive manner28,33,41,46,55,57,58,65,68,69,79,80,86 and increased attention to the distribution of benefits25,33,38,48,63,76.  non-maleficence references to non-maleficence outweigh those to beneficence by a factor of 1.5 and encompass general calls for safety and security80,90,96,97 or state that ai should never cause foreseeable or unintentional harm23,30,33,56,60,79. more granular considerations entail the avoidance of specific risks or potential harms, e.g. intentional misuse via cyberwarfare and malicious hacking51,53,54,78,81,89, and suggest risk-management strategies. harm is primarily interpreted as discrimination38,44,47,48,50,95,98, violation of privacy23,35,44,64,78,98,99, or bodily harm25,30,31,33,56,92,96,100. less frequent characterizations include loss of trust30 or skills44, ‘radical individualism’38, the risk that technological progress might outpace regulatory measures57, negative impacts on long-term social well-being44, on infrastructure44, or on psychological35,56, emotional56 or economic aspects44,56.  harm-prevention guidelines focus primarily on technical measures and governance strategies, ranging from interventions at the level of ai research27,47,64,79,85,101, design23,25,27,32,39,56,58, technology development and/or deployment54 to lateral and continuous approaches33,55,63. technical solutions include in-built data quality evaluations25 or security23 and privacy by design23,27,39, though notable exceptions also advocate for establishing industry standards30,64,102. proposed governance strategies include active cooperation across disciplines and stakeholders33,47,53,62, compliance with existing or new legislation27,31,35,81,95,99, and the need to establish oversight processes and practices, notably ',\n",
       " '  \\n 10 tests36,38,47,74,79, monitoring36,58, audits and assessments by internal units, customers, users, independent third parties, or governmental entities40,48,51,58,81,94,95,98, often geared towards standards for ai implementation and outcome assessment. most sources explicitly mention potential ‘dual-use’8,32,33,38,60,79 or imply that damages may be unavoidable, in which case risks should be assessed40,48,51, reduced40,69,72–74, and mitigated34,35,38,53,63,68, and the attribution of liability should be clearly defined31,37,38,44,82.  responsibility and accountability despite widespread references to ‘responsible ai’43,51,78,83, responsibility and accountability are rarely defined. nonetheless, specific recommendations include acting with ‘integrity’47,52,60 and clarifying the attribution of responsibility and legal liability23,58,78,103, if possible upfront36, in contracts52 or, alternatively, by centering on remedy26. in contrast, other sources suggest focusing on the underlying reasons and processes that may lead to potential harm74,83. yet others underline the responsibility of whistleblowing in case of potential harm36,55,60, and aim at promoting diversity49,92 or introducing ethics into stem education59. very different actors are named as being responsible and accountable for ai’s actions and decisions: ai developers58,60,73,96, designers36,44, ‘institutions’40,42 or ‘industry’69. further disagreement emerged on whether ai should be held accountable in a human-like manner70 or whether humans should always be the only actors who are ultimately responsible for technological artifacts31,32,35,37,52,92.  privacy ethical ai sees privacy both as a value to uphold44,64,75,99 and as a right to be protected27,28,37,38,53. while often undefined, privacy is often presented in relation to data protection23,27,36,53,58,66,71,79,83,98 and data security27,35,64,66,88,98. a few sources link privacy to freedom38,53 or trust74,92. suggested modes of achievement fall into three categories: technical solutions64,80 such as differential privacy74,89, privacy by design25,27,28,79,98, data minimization36,58, and access control36,58, calls for more research47,64,74,98 and awareness64,74, and regulatory approaches25,52,71, with sources referring to legal compliance more broadly27,32,36,58,60,81, or suggesting certificates104 or the creation or adaptation of laws and regulations to accommodate the specificities of ai64,74,88,105.    ',\n",
       " '  \\n 11 beneficence while promoting good (beneficence in ethical terms) is often mentioned, it is rarely defined, though notable exceptions mention the augmentation of human senses86, the promotion of human well-being and flourishing34,90, peace and happiness60, the creation of socio-economic opportunities36, and economic prosperity37,53. similar uncertainty concerns the actors that should benefit from ai: private sector issuers tend to highlight the benefit of ai for customers23,48, though many sources require ai to be shared49,52,76 and to benefit ‘everyone’36,59,65,84, ‘humanity’27,37,44,60,100,102, both of the above48,66, ‘society’34,87, ‘as many people as possible’37,53,99, ‘all sentient creatures’83, the ‘planet’37,72 and the environment38,90. strategies for the promotion of good include aligning ai with human values34,44, advancing ‘scientific understanding of the world’100, minimizing power concentration102 or, conversely, using power ‘for the benefit of human rights’82; working more closely with ‘affected’ people65, minimizing conflicts of interests102; proving beneficence through customer demand48 and feedback58, and developing new metrics and measurements for human well-being44,90.  freedom and autonomy whereas some sources specifically refer to the freedom of expression28,73,82,105 or informational self-determination28,90 and ‘privacy-protecting user controls’58, others generally promote freedom31,69,72, empowerment28,52,99 or autonomy31,33,62,77,81,96. some documents refer to autonomy as a positive freedom, specifically the freedom to flourish36, to self-determination through democratic means38, the right to establish and develop relationships with other human beings38,92, the freedom to withdraw consent67, or the freedom to use a preferred platform or technology73,80. other documents focus on negative freedom, for example freedom from technological experimentation82, manipulation33 or surveillance38. freedom and autonomy are believed to be promoted through transparency and predictable ai38, by not ‘reducing options for and knowledge of citizens’38, by actively increasing people’s knowledge about ai36,52,62, giving notice and consent79 or, conversely, by actively refraining from collecting and spreading data in absence of informed consent30,38,44,55,74.    ',\n",
       " '  \\n 12 trust references to trust include calls for trustworthy ai research and technology50,97,99, trustworthy ai developers and organisations51,60,66, trustworthy ‘design principles’91, or underline the importance of customers’ trust23,52,58,66,74,80. calls for trust are proposed because a culture of trust among scientists and engineers is believed to support the achievement of other organisational goals99, or because overall trust in the recommendations, judgments and uses of ai is indispensable for ai to ‘fulfill its world changing potential’24. this last point is contradicted by one guideline explicitly warning against excessive trust in ai81. suggestions for building or sustaining trust include education33, reliability50,51, accountability56, processes to monitor and evaluate the integrity of ai systems over time51 and tools and techniques ensuring compliance with norms and standards43,63. whereas some guidelines require ai to be transparent37,43,57,58, understandable36,37, or explainable52 in order to build trust, another one explicitly suggests that, instead of demanding understandability, it should be ensured that ai fulfills public expectations50. other reported facilitators of trust include ‘a certificate of fairness’104, multi-stakeholder dialogue64, awareness about the value of using personal data74, and avoiding harm30,56.  sustainability to the extent that is referenced, sustainability calls for development and deployment of ai to consider protecting the environment33,38,46, improving the planet’s ecosystem and biodiversity37, contributing to fairer and more equal societies65 and promoting peace66. ideally, ai creates sustainable systems44,76,90 that process data sustainably43 and whose insights remain valid over time48. to achieve this aim, ai should be designed, deployed and managed with care38 to increase its energy efficiency and minimize its ecological footprint31. to make future developments sustainable, corporations are asked to create policies ensuring accountability in the domain of potential job losses37 and to use challenges as an opportunity for innovation38.  dignity while dignity remains undefined in existing guidelines, safe the specification that it is a prerogative of humans but not robots92, there is frequent reference to what it entails: dignity is intertwined with human rights101 or otherwise means avoiding harm31, forced ',\n",
       " '  \\n 13 acceptance31, automated classification38, and unknown human-ai interaction38. it is argued that ai should not diminish33 or destroy80 but respect82, preserve69 or even increase human dignity36,37. dignity is believed to be preserved if it is respected by ai developers in the first place96 and promoted through new legislation38, through governance initiatives36, or through government-issued technical and methodological guidelines82.  solidarity solidarity is mostly referenced in relation to the implications of ai for the labor market104. sources call for a strong social safety net37,84. they underline the need for redistributing the benefits of ai in order not to threaten social cohesion49 and respecting potentially vulnerable persons and groups33. lastly, there is a warning of data collection and practices focused on individuals which may undermine solidarity in favour of ‘radical individualism’38.  discussion we found a rapid increase in the number and variety of guidance documents for ethical ai, demonstrating the increasing active involvement of the international community. organisations publishing ai guidelines come from a wide range of sectors. in particular the nearly equivalent proportion of documents issued by the public sector (i.e. governmental and inter-governmental organisations) and the private sector (companies and private sector alliances) indicate that the ethical challenges of ai concern both public entities and private enterprises. however, there is significant divergence in the solutions proposed to meet the ethical challenges of ai. further, the relative underrepresentation of geographic areas such as africa, south and central america and central asia indicates that the international debate over ethical ai may not be happening globally in equal measures. medc countries are shaping this debate more than others, which raises concerns about neglecting local knowledge, cultural pluralism and global fairness.  the proliferation of soft-law efforts can be interpreted as a governance response to advanced research into ai, whose research output and market size have drastically increased106 in recent years. our analysis shows the emergence of an apparent cross-stakeholder convergence on promoting the ethical principles of transparency, justice, non-maleficence, responsibility, and privacy. nonetheless, our thematic analysis reveals substantive divergences in relation to four major factors: (i) how ethical principles are interpreted, (ii) ',\n",
       " '  \\n 14 why they are deemed important, (iii) what issue, domain or actors they pertain to, and (iv) how they should be implemented. furthermore, unclarity remains as to which ethical principles should be prioritized, how conflicts between ethical principles should be resolved, who should enforce ethical oversight on ai and how researchers and institutions can comply with the resulting guidelines. these findings suggest the existence of a gap at the cross-section of principles formulation and their implementation into practice which can hardly be solved through technical expertise or top-down approaches.  although no single ethical principle is explicitly endorsed by all existing guidelines, transparency, justice and fairness, non-maleficence, responsibility and privacy are each referenced in more than half of all guidelines. this focus could be indicating a developing convergence on ethical ai around these principles in the global policy landscape. in particular, the prevalence of calls for transparency, justice and fairness points to an emerging moral priority to require transparent processes throughout the entire ai continuum (from transparency in the development and design of algorithms to transparent practices for ai use), and to caution the global community against the risk that ai might increase inequality if justice and fairness considerations are not adequately addressed. both these themes appear to be intertwined with the theme of responsibility, as the promotion of both transparency and justice seems to postulate increased responsibility and accountability on the side of ai makers and deployers.  it has been argued that transparency is not an ethical principle per se, but rather “a proethical condition for enabling or impairing other ethical practices or principles”107. the proethical nature of transparency might partly explain its higher prevalence compared to other ethical principles. it is notable that current guidelines place significant value in the promotion of responsibility and accountability, yet few of them emphasize the duty of all stakeholders involved in the development and deployment of ai to act with integrity. this mismatch is probably associated with the observation that existing guidelines fail to establish a full correspondence between principles and actionable requirements, with several principles remaining uncharacterized or disconnected from the requirements necessary for their realization.   ',\n",
       " '  \\n 15 as codes related to non-maleficence outnumber those related to beneficence, it appears that, for the current ai community, the moral obligation to preventing harm takes precedence over the promotion of good. this fact can be partly interpreted as an instance of the so-called negativity bias, i.e. a general cognitive bias to give greater weight to negative entities108,109. this negative characterization of ethical values is further emphasized by the fact that existing guidelines focus primarily on how to preserve privacy, dignity, autonomy and individual freedom in spite of advances in ai, while largely neglecting whether these principles could be promoted through responsible innovation in ai110.  the issue of trust in ai, while being addressed by less than one third of all sources, tackles a critical ethical dilemma in ai governance: determining whether it is morally desirable to foster public trust in ai. while several sources, especially those produced within the private sector, highlight the importance of fostering trust in ai through educational and awareness-raising activities, a smaller number of sources contend that trust in ai may actually diminish scrutiny and undermine some societal obligations of ai producers111. this possibility would challenge the dominant view in ai ethics that building public trust in ai is a fundamental requirement for ethical governance112.   the relative thematic underrepresentation of sustainability and solidarity suggests that these topics might be currently flying under the radar of the mainstream ethical discourse on ai. the underrepresentation of sustainability-related principles is particularly problematic in light of the fact that the deployment of ai requires massive computational resources which, in turn, require high energy consumption. the environmental impact of ai, however, does not only involve the negative effects of high-footprint digital infrastructures, but also the possibility of harnessing ai for the benefit of ecosystems and the entire biosphere. this latter point, highlighted in a report by the world economic forum113 though not in the ai guidelines by the same institution, requires wider endorsement to become entrenched in the ethical ai narrative. the ethical principle of solidarity is sparsely referenced, typically in association with the development of inclusive strategies for the prevention of job losses and unfair sharing of burdens. little attention is devoted to promoting solidarity through the emerging possibility of using ai expertise for solving humanitarian challenges, a mission that is currently being pursued, among others, by intergovernmental organisations such as the united nations office for project services (unops)114 or the world health ',\n",
       " '  \\n 16 organization (who) and private companies such as microsoft115. as the humanitarian cost of anthropogenic climate change is rapidly increasing116, the principles of sustainability and solidarity appear strictly intertwined though poorly represented compared to other principles.  while numerical data indicate an emerging convergence around the promotion of some ethical principles, in-depth thematic analysis paints a more complicated picture, as there are critical differences in how these principles are interpreted as well as what requirements are considered to be necessary for their realization. results show that different and often conflicting measures are proposed for the practical achievement of ethical ai. for example, the need for ever larger, more diverse datasets to “unbias” ai appears difficult to conciliate with the requirement to give individuals increased control over their data and its use in order to respect their privacy and autonomy. similar contrasts emerge between the requirement of avoiding harm at all costs and that of balancing risks and benefits. furthermore, it should be noted that risk-benefit evaluations will lead to different results depending on whose well-being it will be optimized for by which actors. if not resolved, such divergences and tensions may undermine attempts to develop a global agenda for ethical ai.   despite a general agreement that ai should be ethical, significant divergences emerge within and between guidelines for ethical ai. furthermore, uncertainty remains regarding how ethical principles and guidelines should be implemented. these challenges have implications for science policy, technology governance and research ethics. at the policy level, they urge increased cooperative efforts among governmental organisations to harmonize and prioritize their ai agendas, an effort that can be mediated and facilitated by inter-governmental organisations. while harmonization is desirable, however, it should not come at the costs of obliterating cultural and moral pluralism over ai. therefore, a fundamental challenge for developing a global agenda for ai is balancing the need for cross-national harmonization over the respect for cultural diversity and moral pluralism. this challenge will require the development of deliberative mechanisms to adjudicate disagreement concerning the values and implications of ai advances among different stakeholders from different global regions. at the level of technology governance, harmonization is typically implemented in terms of standardizations. efforts in this direction have been made, among others, by the institute of electrical and electronics engineers ',\n",
       " '  \\n 17 (ieee) through the “ethically aligned designed” initiative117. finally, soft governance mechanisms such as independent review boards (irbs) will be increasingly required to assess the ethical validity of ai applications in scientific research, especially those in the academic domain. however, ai applications by governments or private corporations will unlikely fall under their oversight, unless significant expansions to the irbs’ purview are made.  the international community seems to converge on the importance of transparency, non-maleficence, responsibility, and privacy for the development and deployment of ethical ai. however, enriching the current ethical ai discourse through a better appraisal of critical yet underrepresented ethical principles such as human dignity, solidarity and sustainability is likely to result into a better articulated ethical landscape for artificial intelligence. furthermore, shifting the focus from principle-formulation to translation into practice must be the next step. a global agenda for ethical ai should balance the need for cross-national and cross-domain harmonization over the respect for cultural diversity and moral pluralism. overall, our review provides a useful starting point for understanding the inherent diversity of current principles and guidelines for ethical ai and outlines the challenges ahead for the global community.  limitations this study has several limitations. first, guidelines and soft-law documents are an instance of gray literature, hence not indexed in conventional scholarly databases. therefore, their retrieval is inevitably less replicable and unbiased compared to systematic database search of peer-reviewed literature. following best practices for gray literature review, this limitation has been mitigated by developing a discovery and eligibility protocol which was pilot-tested prior to data collection. although search results from search engines are personalized, the risk of personalization influencing discovery has been mitigated through the broadness of both the keyword search and the inclusion of results. a language bias may have skewed our corpus towards english results. our content analysis presents the typical limitations of qualitative analytic methods. following best practices for content analysis, this limitation has been mitigated by developing an inductive coding strategy which was conducted independently by two reviewers to minimize subjective bias. finally, given the rapid pace of publication of ai guidance documents, there is a possibility that new policy ',\n",
       " '  \\n 18 documents were published after our search was completed. to minimize this risk, continuous monitoring of the literature was conducted in parallel with the data analysis and until april 23, 2019.   methods we conducted a scoping review of the gray literature reporting principles and guidelines for ethical ai. a scoping review is a method aimed at synthesizing and mapping the existing literature118, which is considered particularly suitable for complex or heterogeneous areas of research118,119. given the absence of a unified database for ai-specific ethics guidelines, we developed a protocol for discovery and eligibility, adapted from the preferred reporting items for systematic reviews and meta-analyses (prisma) framework120. the protocol was pilot-tested and calibrated prior to data collection. following best practices for gray literature retrieval, a multi-stage screening strategy involving both inductive screening via search engine and deductive identification of relevant entities with associated websites and online collections was conducted. to achieve comprehensiveness and systematicity, relevant documents were retrieved by relying on three sequential search strategies (cf. figure 2): first, a manual search of four link hub webpages (“linkhubs”)121–124 was performed. 68 sources were retrieved, out of which 30 were eligible (27 after removing duplicates). second, a keyword-based web search of the google.com search engine was performed in private browsing modus, after log-out from personal accounts and erasure of all web cookies and history.125,126 search was performed using the following keywords: [ai principles], [artificial intelligence principles], [ai guidelines], [artificial intelligence guidelines], [ethical ai] and [ethical artificial intelligence]. every link in the first thirty search results was followed and screened (i) for ai principles, resulting in 10 more sources after removing duplicates, and (ii) for articles mentioning ai principles, leading to the identification of 3 additional non-duplicate sources. the remaining google results up to the 200th listings for each google search were followed and screened for ai principles only. within these additional 1020 link listings we identified 15 non-duplicate documents. after identifying relevant documents through the two processes above, we used citation-chaining to manually screen the full-texts and, if applicable, reference lists of all eligible sources in order to identify other relevant documents. 17 additional sources were identified. we continued to monitor the literature in parallel with the data analysis and until april 23, 2019, to retrieve eligible documents that were released after our search was completed. twelve ',\n",
       " '  \\n 19 new sources were included within this extended time frame. to ensure theoretical saturation, we exhausted the citation chaining within all identified sources until no additional relevant document could be identified.  figure 2- prisma-based flowchart of retrieval process \\n flowchart of our retrieval process based on the prisma template for systematic reviews127. we relied on three search strategies (linkhubs, web search and citation chaining) and added the most recent records manually, identifying a total of 84 eligible, non-duplicate documents containing ethical principles for ai.  based on our inclusion/exclusion criteria, policy documents (including principles, guidelines and institutional reports) included in the final synthesis were (i) written in \\n',\n",
       " '  \\n 20 english, german, french, italian, greek; (ii) issued by institutional entities from both the public and the public sectors; (iii) referred explicitly in their title/description to ai or ancillary notions, (iv) expressed a normative ethical stance defined as a moral preference for a defined course of action (cf. si table s2). following full-text screening, 84 sources or parts thereof were included in the final synthesis (cf. si table s1).  content analysis of the 84 sources was independently conducted by two researchers in two cycles of manual coding and one cycle of code mapping within the qualitative data analysis software nvivo for mac v.11.4. during the first cycle of coding, one researcher exhaustively tagged all relevant text through inductive coding128 attributing a total of 3457 codes, out of which 1180 were subsequently discovered to pertain to ethical principles. subsequently, two researchers conducted the code mapping process in order to reduce subjective bias. the process of code mapping, a method for qualitative metasynthesis129, consisted of two iterations of themeing128, whereby categories were first attributed to each code, then categorized in turn (cf. si table s3). for the theming of ethical principles, we relied deductively on normative ethical literature. ethical categories were inspected and assessed for consistency by two researchers with primary expertise in ethics. thirteen ethical categories emerging from code mapping, two of which were merged with others due to independently assessed semantic and thematic proximity. finally, we extracted significance and frequency by applying focused coding, a second cycle coding methodology used for interpretive analysis128, to the data categorized in ethical categories. consistency check was performed both by reference to the relevant ethical literature and a process of deliberative mutual adjustment among the general principles and the particular judgments contained in the policy documents, an analytic strategy known as ‘reflective equilibrium’130.  ',\n",
       " ' \\n 1 references  1. harari, y. n. reboot for the ai revolution. nat. news 550, 324 (2017). 2. appenzeller, t. the ai revolution in science. science (2017). doi:10.1126/science.aan7064 3. jordan, m. i. & mitchell, t. m. machine learning: trends, perspectives, and prospects. science 349, 255–260 (2015). 4. stead, w. w. clinical implications and challenges of artificial intelligence and deep learning. jama 320, 1107–1108 (2018). 5. vayena, e., blasimme, a. & cohen, i. g. machine learning in medicine: addressing ethical challenges. plos med. 15, e1002689 (2018). 6. awad, e. et al. the moral machine experiment. nature 563, 59 (2018). 7. science must examine the future of work. nat. news 550, 301 (2017). 8. brundage, m. et al. the malicious use of artificial intelligence: forecasting, prevention, and mitigation. (future of humanity institute; university of oxford; centre for the study of existential risk; university of cambridge; center for a new american security; electronic frontier foundation; openai, 2018). 9. zou, j. & schiebinger, l. ai can be sexist and racist — it’s time to make it fair. nature 559, 324 (2018). 10. boddington, p. towards a code of ethics for artificial intelligence. (springer international publishing, 2017). 11. bostrom, n. & yudkowsky, e. the ethics of artificial intelligence. in the cambridge handbook of artificial intelligence (eds. frankish, k. & ramsey, w. m.) 316–334 (cambridge university press, 2014). doi:10.1017/cbo9781139046855.020 12. etzioni, a. & etzioni, o. ai assisted ethics. ethics inf. technol. 18, 149–156 (2016). ',\n",
       " ' \\n 2 13. yuste, r. et al. four ethical priorities for neurotechnologies and ai. nat. news 551, 159 (2017). 14. cath, c., wachter, s., mittelstadt, b., taddeo, m. & floridi, l. artificial intelligence and the ‘good society’: the us, eu, and uk approach. sci. eng. ethics 24, 505–528 (2018). 15. zeng, y., lu, e. & huangfu, c. linking artificial intelligence principles. arxiv181204814 cs (2018). 16. greene, d., hoffmann, a. l. & stark, l. better, nicer, clearer, fairer: a critical assessment of the movement for ethical artificial intelligence and machine learning. in (2019). 17. crawford, k. & calo, r. there is a blind spot in ai research. nat. news 538, 311 (2016). 18. altman, m., wood, a. & vayena, e. a harm-reduction framework for algorithmic fairness. ieee secur. priv. 16, 34–45 (2018). 19. bolukbasi, t., chang, k.-w., zou, j., saligrama, v. & kalai, a. man is to computer programmer as woman is to homemaker? debiasing word embeddings. arxiv160706520 cs stat (2016). 20. o’neil, c. weapons of math destruction: how big data increases inequality and threatens democracy. (crown, 2016). 21. veale, m. & binns, r. fairer machine learning in the real world: mitigating discrimination without collecting sensitive data. big data soc. 4, 205395171774353 (2017). 22. wagner, b. ethics as an escape from regulation. from “ethics-washing” to ethics-shopping? in being profiled: cogitas ergo sum\\u2009: 10 years of ‘profiling the european ',\n",
       " ' \\n 3 citizen’ (eds. bayamlioglu, e., baraliuc, i., janssens, l. a. w. & hildebrandt, m.) 84–89 (amsterdam university press, 2018). 23. deutsche telekom. deutsche telekom’s guidelines for artificial intelligence. (2018). 24. ibm. transparency and trust in the cognitive era. ibm (2017). available at: https://www.ibm.com/blogs/think/2017/01/ibm-cognitive-principles/. (accessed: 21st february 2019) 25. initial code of conduct for data-driven health and care technology. gov.uk available at: https://www.gov.uk/government/publications/code-of-conduct-for-data-driven-health-and-care-technology/initial-code-of-conduct-for-data-driven-health-and-care-technology. (accessed: 1st november 2018) 26. diakopoulos, n. et al. principles for accountable algorithms. fatml | principles for accountable algorithms and a social impact statement for algorithms (2016). available at: http://www.fatml.org/resources/principles-for-accountable-algorithms. (accessed: 21st february 2019) 27. telefónica. our artificial intelligence principles. (2018). 28. commission nationale de l’informatique et des libertés (cnil), european data protection supervisor (edps) & garante per la protezione dei dati personali. declaration on ethics and data protection in artificial intelligence. (2018). 29. ibm. everyday ethics for artificial intelligence. a practical guide for designers & developers. (2018). 30. federal ministry of transport and digital infrastructure, ethics commission. bmvi - ethics commission’s complete report on automated and connected driving. (2017). 31. green digital working group. position on robotics and artificial intelligence. (2016). ',\n",
       " ' \\n 4 32. epsrc. principles of robotics. engineering and physical sciences research council uk (epsrc) (2011). available at: https://epsrc.ukri.org/research/ourportfolio/themes/engineering/activities/principlesofrobotics/. (accessed: 21st february 2019) 33. high-level expert group on artificial intelligence. ethics guidelines for trustworthy ai. (2019). 34. dubai. ai principles & ethics. smart dubai (2019). available at: http://www.smartdubai.ae/initiatives/ai-principles-ethics. (accessed: 8th april 2019) 35. dawson, d. et al. artificial intelligence: australia’s ethics framework. (2019). 36. internet society. artificial intelligence & machine learning: policy paper. internet society (2017). available at: https://www.internetsociety.org/resources/doc/2017/artificial-intelligence-and-machine-learning-policy-paper/. (accessed: 21st february 2019) 37. uni global. 10 principles for ethical ai. (2017). 38. european group on ethics in science and new technologies. statement on artificial intelligence, robotics and ‘autonomous’ systems. (2018). 39. information commissioner’s office uk. big data, artificial intelligence, machine learning and data protection. (2017). 40. the public voice. universal guidelines for artificial intelligence. the public voice (2018). available at: https://thepublicvoice.org/ai-universal-guidelines/. (accessed: 21st february 2019) 41. the future society. science, law and society (sls) initiative. the future society (2018). available at: https://web.archive.org/web/20180621203843/http://thefuturesociety.org/science-law-society-sls-initiative/. (accessed: 25th february 2019) ',\n",
       " ' \\n 5 42. association for computing machinery (acm). statement on algorithmic transparency and accountability. (2017). 43. special interest group on artificial intelligence. dutch artificial intelligence manifesto. (2018). 44. ethically aligned design. a vision for prioritizing human well-being with autonomous and intelligent systems. ethically aligned design. a vision for prioritizing human well-being with autonomous and intelligent systems v.2. (2017). 45. access now. the toronto declaration: protecting the right to equality and non-discrimination in machine learning systems. (2018). 46. floridi, l. et al. ai4people—an ethical framework for a good ai society: opportunities, risks, principles, and recommendations. (ai4people). 47. sap. sap’s guiding principles for artificial intelligence (ai). sap (2018). available at: https://www.sap.com/products/leonardo/machine-learning/ai-ethics.html#guiding-principles. (accessed: 19th february 2019) 48. software & information industry association (siia), public policy division. ethical principles for artificial intelligence and data analytics. (2017). 49. koski, o. & husso, k. work in the age of artificial intelligence. (2018). 50. center for democracy & technology. digital decisions. center for democracy & technology available at: https://cdt.org/issue/privacy-data/digital-decisions/. (accessed: 21st february 2019) 51. mi garage. ethics framework - responsible ai. mi garage available at: https://www.migarage.ai/ethics-framework/. (accessed: 22nd february 2019) 52. institute of business ethics. business ethics and artificial intelligence. (2018). ',\n",
       " ' \\n 6 53. asilomar ai principles. future of life institute (2017). available at: https://futureoflife.org/ai-principles/. (accessed: 1st november 2018) 54. pricewaterhousecoopers. the responsible ai framework. pwc available at: https://www.pwc.co.uk/services/audit-assurance/risk-assurance/services/technology-risk/technology-risk-insights/accelerating-innovation-through-responsible-ai/responsible-ai-framework.html. (accessed: 22nd february 2019) 55. whittaker, m. et al. ai now report 2018. (2018). 56. personal data protection commission singapore. discussion paper on ai and personal data -- fostering responsible development and adoption of ai. (2018). 57. royal college of physicians. artificial intelligence (ai) in health. rcp london (2018). available at: https://www.rcplondon.ac.uk/projects/outputs/artificial-intelligence-ai-health.  58. microsoft. responsible bots: 10 guidelines for developers of conversational ai. (2018). 59. villani, c. for a meaningful artificial intelligence. towards a french and european strategy. (mission assigned by the prime minister édouard philippe, 2018). 60. the japanese society for artificial intelligence. the japanese society for artificial intelligence ethical guidelines. (2017). 61. demiaux, v. how can humans keep the upper hand? the ethical matters raised by algorithms and artificial intelligence. (2017). 62. council of europe: cepej. european ethical charter on the use of artificial intelligence in judicial systems and their environment. (2019). 63. american college of radiology et al. ethics of ai in radiology: european and north american multisociety statement. (2019). ',\n",
       " ' \\n 7 64. leaders of the g7. charlevoix common vision for the future of artificial intelligence. (2018). 65. deepmind ethics&society. deepmind ethics & society principles. deepmind (2017). available at: https://deepmind.com/applied/deepmind-ethics-society/principles/. (accessed: 21st february 2019) 66. sony. sony group ai ethics guidelines. (2018). 67. datatilsynet. artificial intelligence and privacy. (the norwegian data protection authority, 2018). 68. wef. white paper: how to prevent discriminatory outcomes in machine learnig. (2018). 69. information technology industry council (iti). iti ai policy principles. (2017). 70. sage. the ethics of code: developing ai for business with five core principles. (2017). 71. op group. commitments and principles. op available at: https://www.op.fi/op-financial-group/corporate-social-responsibility/commitments-and-principles. (accessed: 21st february 2019) 72. tieto. tieto’s ai ethics guidelines. (2018). 73. unity. introducing unity’s guiding principles for ethical ai – unity blog. unity technologies blog (2018). 74. national institution for transforming india (niti aayog). discussion paper: national strategy for artificial intelligence. (2018). 75. house of lords. ai in the uk: ready, willing and able. 183 (2018). 76. the information accountability foundation. unified ethical frame for big data analysis iaf big data ethics initiative, part a. (2015). ',\n",
       " ' \\n 8 77. fenech, m., nika strukelj & olly buston. ethical, social, and political challenges of artificial intelligence in health. (future advocacy, 2019). 78. accenture uk. responsible ai and robotics. an ethical framework. available at: https://www.accenture.com/gb-en/company-responsible-ai-robotics. (accessed: 22nd february 2019) 79. google. our principles. google ai (2018). available at: https://ai.google/principles/. (accessed: 19th february 2019) 80. microsoft. microsoft ai principles. our approach (2017). available at: https://www.microsoft.com/en-us/ai/our-approach-to-ai. (accessed: 1st november 2018) 81. cerna commission de réflexion sur l’éthique de la rechercheen sciences et technologies du numérique d’allistene. éthique de la rechercheen robotique. (allistene, 2014). 82. est, r. van & gerritsen, j. human rights in the robot age: challenges arising from the use of robotics, artificial intelligence, and virtual and augmented reality. (the rathenau institute, 2017). 83. université de montréal. montreal declaration. the declaration - montreal responsible ai (2017). available at: https://www.montrealdeclaration-responsibleai.com/the-declaration. (accessed: 21st february 2019) 84. government of the republic of korea. mid- to long-term master plan in preparation for the intelligent information society. managing the fourth industrial revolution. (2017). 85. crawford, k. et al. the ai now report. the social and economic implications of artificial intelligence technologies in the near-term. (2016). ',\n",
       " ' \\n 9 86. advisory board on artificial intelligence and human society. report on artificial intelligence and human society unofficial translation. (ministry of state for science and technology policy, 2017). 87. executive office of the president; national science and technology council; committee on technology. preparing for the future of artificial intelligence. (2016). 88. intel. artificial intelligence. the public policy opportunity. (2017). 89. royal society. machine learning: the power and promise of computers that learn by example. (royal society (great britain), 2017). 90. ieee global initiative on ethics of autonomous and intelligent systems. ethically aligned design: a vision for prioritizing human well-being with autonomous and intelligent systems, first edition (ead1e). (2019). 91. european parliament. report with recommendations to the commission on civil law rules on robotics. (2017). 92. comest/unesco. report of comest on robotics ethics. unesdoc digital library (2017). available at: https://unesdoc.unesco.org/ark:/48223/pf0000253952. (accessed: 21st february 2019) 93. campolo, a., madelyn sanfilippo, meredith whittaker & kate crawford. ai now 2017 report. (2017). 94. american medical association (ama). policy recommendations on augmented intelligence in health care h-480.940. (2018). available at: https://policysearch.ama-assn.org/policyfinder/detail/ai?uri=%2famadoc%2fhod.xml-h-480.940.xml. (accessed: 21st february 2019) 95. avila, r., ana brandusescu, juan ortiz freuler & dhanaraj thakur. artificial intelligence: open questions about gender inclusion. (2018). ',\n",
       " ' \\n 10 96. the conference toward ai network society. draft ai r&d guidelines for international discussions. (2017). available at: http://www.soumu.go.jp/main_content/000507517.pdf. (accessed: 21st february 2019) 97. national science and technology council; networking and information technology research and development subcommittee. the national artificial intelligence research and development strategic plan. (2016). 98. hoffmann, d. & masucci, r. intel’s ai privacy policy white paper. protecting individuals’ privacy and data in the artificial intelligence world. (2018). 99. partnership on ai. tenets. the partnership on ai (2016). available at: https://www.partnershiponai.org/tenets/. (accessed: 21st february 2019) 100. icelandic institute for intelligent machines (iiim). ethics policy. iiim (2015). available at: http://www.iiim.is/2015/08/ethics-policy/. (accessed: 21st february 2019) 101. latonero, m. governing artificial intelligence. upholding human rights & dignity. (data & society, 2018). 102. openai. openai charter. openai (2018). available at: https://blog.openai.com/openai-charter/. (accessed: 21st february 2019) 103. agenzia per l’italia digitale (agid). l’intelligenzia artificiale al servizio del cittadino. (2018). 104. women leading in ai. 10 principles of responsible ai. (2019). 105. privacy international & article 19. privacy and freedom of expression in the age of artificial intelligence. (2018). 106. shoham, y. et al. the ai index 2018 annual report. (ai index steering committee, human-centered ai initiative, stanford university, 2018). ',\n",
       " ' \\n 11 107. turilli, m. & floridi, l. the ethics of information transparency. ethics inf. technol. 11, 105–112 (2009). 108. rozin, p. & royzman, e. b. negativity bias, negativity dominance, and contagion: personal. soc. psychol. rev. (2016). doi:10.1207/s15327957pspr0504_2 109. bentley, p. j., brundage, m., häggström, o. & metzinger, t. should we fear artificial intelligence?: in-depth analysis. (european parliamentary research service: scientific foresight unit (stoa), 2018). 110. taddeo, m. & floridi, l. how ai can be a force for good. science 361, 751–752 (2018). 111. bryson, j. ai & global governance: no one should trust ai - centre for policy research at united nations university. united nations university. centre for policy research (2018). available at: https://cpr.unu.edu/ai-global-governance-no-one-should-trust-ai.html. (accessed: 21st march 2019) 112. winfield, a. f. t. & marina, j. ethical governance is essential to building trust in robotics and artificial intelligence systems. philos. trans. r. soc. math. phys. eng. sci. 376, 20180085 (2018). 113. wef. harnessing artificial intelligence for the earth. (wef, 2018). 114. lancaster, c. can artificial intelligence improve humanitarian responses? unops (2018). available at: https://www.unops.org/news-and-stories/insights/can-artificial-intelligence-improve-humanitarian-responses. (accessed: 22nd march 2019) 115. microsoft. ai for humanitarian action. microsoft | ai available at: https://www.microsoft.com/en-us/ai/ai-for-humanitarian-action. (accessed: 22nd march 2019) 116. scheffran, j., brzoska, m., kominek, j., link, p. m. & schilling, j. climate change and violent conflict. science 336, 869–871 (2012). ',\n",
       " ' \\n 12 117. ieee. the ieee global initiative on ethics of autonomous and intelligent systems. ieee standards association available at: https://standards.ieee.org/industry-connections/ec/autonomous-systems.html. (accessed: 22nd march 2019) 118. arksey, h. & o’malley, l. scoping studies: towards a methodological framework. int. j. soc. res. methodol. 8, 19–32 (2005). 119. pham, m. t. et al. a scoping review of scoping reviews: advancing the approach and enhancing the consistency. res. synth. methods 5, 371–385 (2014). 120. liberati, a. et al. the prisma statement for reporting systematic reviews and meta-analyses of studies that evaluate health care interventions: explanation and elaboration. plos med. 6, e1000100 (2009). 121. boddington, p. alphabetical list of resources. ethics for artificial intelligence (2018). available at: https://www.cs.ox.ac.uk/efai/resources/alphabetical-list-of-resources/. (accessed: 4th may 2019) 122. winfield, a. alan winfield’s web log: a round up of robotics and ai ethics. alan winfield’s web log (2017). 123. future of life institute. national and international ai strategies. future of life institute (2018). available at: https://futureoflife.org/national-international-ai-strategies/. (accessed: 4th may 2019) 124. future of life institute. summaries of ai policy resources. future of life institute (2018). available at: https://futureoflife.org/ai-policy-resources/. (accessed: 4th may 2019) 125. hagstrom, c., kendall, s. & cunningham, h. googling for grey: using google and duckduckgo to find grey literature. in abstracts of the 23rd cochrane colloquium 10 (suppl): lro 3.6, 40 (cochrane database of systematic reviews, 2015). ',\n",
       " ' \\n 13 126. piasecki, j., waligora, m. & dranseika, v. google search as an additional source in systematic reviews. sci. eng. ethics (2017). doi:10.1007/s11948-017-0010-4 127. moher, d., liberati, a., tetzlaff, j., altman, d. g. & group, t. p. preferred reporting items for systematic reviews and meta-analyses: the prisma statement. plos med. 6, e1000097 (2009). 128. saldaña, j. the coding manual for qualitative researchers. (sage, 2013). 129. noblit, g. w. & hare, r. d. meta-ethnography: synthesizing qualitative studies. (sage, 1988). 130. daniels, n. justice and justification: reflective equilibrium in theory and practice. (cambridge university press, 1996).   ',\n",
       " '  \\n1   supplementary information for  artificial intelligence: the global landscape of ethics guidelines    anna jobin a, marcello ienca a, effy vayena a*    a health ethics & policy lab, eth zurich, 8092 zurich, switzerland  * corresponding author: effy.vayena@hest.ethz.ch    © the authors 2019       this pdf file includes:  tables s1 to s3    ',\n",
       " \"  \\n2  table s1. ethics guidelines for ai by date of publishing (incl. details)  name of docu-ment/website name of guide-lines/principles issuer country of issuer type of issuer date of publish-ing target audience retrieval principles of robotics principles for de-signers, builders and users of robots engineering and phys-ical sciences research council uk (epsrc) uk science founda-tion 1-apr-2011 multiple (public, developers) linkhubs ethique de la re-cherche en robotique préconisations cerna (allistene) france research alliance xx-nov-2014 researchers citation chaining unified ethical frame for big data analysis. iaf big data ethics initiative, part a values for an ethi-cal frame the information ac-countability founda-tion uk npo/charity xx-mar-2015 unspecified citation chaining ethics policy iiim's ethics policy icelandic institute for intelligent machines (iiim) iceland academic and research institu-tion 31-aug-2015 self linkhubs the ai now report. the social and eco-nomic implications of artificial intelligence technologies in the near-term key recommenda-tions ai now institute usa academic and research institu-tion 22-sep-2016 unspecified citation chaining tenets tenets partnership on ai n.a. private sector al-liance 29-sep-2016 self web search results 1-30 preparing for the fu-ture of artificial intel-ligence recommendations in this report executive office of the president; national science and technol-ogy council; commit-tee on technology usa governmental agencies/organi-zations xx-oct-2016 multiple (stake-holders engaged at variouspoints in the produc-tion, use, govern-ance, and assess-ment of ai sys-tems) linkhubs the national artificial intelligence research and development strategic plan r&d strategy national science and technology council; networking and infor-mation technology research and devel-opment subcommittee usa governmental agencies/organi-zations xx-oct-2016 self linkhubs position on robotics and artificial intelli-gence 3. principles // 6. recommendations green position on robotics and artifi-cial intelligence the greens (green working group ro-bots)   eu political party 22-nov-2016 multiple (eu parliament, pu-blic, self) web search results 31-200 principles for ac-countable algorithms and a social impact statement for algo-rithms principles for ac-countable algo-rithms fairness, accountabil-ity, and transparency in machine learning (fatml) n.a. n.a. 24-nov-2016 multiple (devel-opers and prod-uct managers) linkhubs statement on algo-rithmic transparency and accountability principles for algo-rithmic transpar-ency and accounta-bility association for com-puting machinery (acm) usa prof. associa-tion/society 12-jan-2017 multiple (devel-opers, deployers) linkhubs report with recom-mendations to the commission on civil law rules on robot-ics motion for a euro-pean parliament resolution european parliament eu igo/supra-na-tional 27-jan-2017 public sector (lawmakers) linkhubs ai principles ai principles future of life institute usa miscellaneous (mixed crowdsourced, npo) 30-jan-2017 unspecified linkhubs the japanese society for artificial intelli-gence ethical guide-lines the japanese soci-ety for artificial in-telligence ethical guidelines japanese society for artificial intelligence japan prof. associa-tion/society 28-feb-2017 self (incl ai) linkhubs report on artificial intelligence and hu-man society (unoffi-cial translation) 4.1 ethical issues advisory board on artificial intelligence and human society (initiative of the min-ister of state for sci-ence and technology policy) japan governmental agencies/organi-zations 24-mar-2017 multiple (re-searchers, gov-ernment, busi-nesses, public, educators) web search results 31-200 artificial intelligence and machine learn-ing: policy paper guiding principles and recommenda-tions internet society interna-tional npo/charity 18-apr-2017 multiple (policy-makers, other stakeholders in the wider inter-net ecosystem) web search results 31-200 machine learning: the power and promise of computers that learn by example chapter six – a new wave of ma-chine learning re-search the royal society uk prof. associa-tion/society xx-apr-2017 unspecified citation chaining the ethics of code: developing ai for business with five core principles the ethics of code: developing ai for business with five core principles sage uk company 27-jun-2017 self citation chaining automated and con-nected driving: re-port ethical rules for au-tomated and con-nected vehicular traffic federal ministry of transport and digital infrastructure, ethics commission germany governmental agencies/organi-zations xx-jun-2017 multiple (auto-mated & con-nected vehicular traffic) linkhubs \",\n",
       " '  \\n3  mid- to long-term master plan in prepa-ration for the intelli-gent information soci-ety tasks (8-12) government of the republic of korea south korea governmental agencies/organi-zations 20-jul-2017 self (gov) linkhubs draft ai r&d guide-lines for international discussions ai r&d principles institute for infor-mation and communi-cations policy (iicp), the conference to-ward ai network so-ciety japan governmental agencies/organi-zations 28-jul-2017 multiple (sys-tems and devel-opers) linkhubs big data, artificial in-telligence, machine learning and data pro-tection key recommenda-tions information commis-sioner\\'s office uk gov 4-sep-2017 organisations web search results 1-30 report of comest on robotics ethics (only section \"recom-mendations\" taken into account) relevant ethical principles and val-ues comest/unesco interna-tional igo/supra-na-tional 14-sep-2017 unspecified citation chaining ethical principles for artificial intelligence and data analytics ethical principles for artificial intelli-gence and data an-alytics software & infor-mation industry asso-ciation (siia), public policy division interna-tional private sector al-liance 15-sep-2017 private sector (industry organi-zations)  ai - our approach ai - our approach microsoft usa company 7-oct-2017 self web search results 1-30 deepmind ethics & society principles our five core prin-ciples deepmind ethics & society uk company 10-oct-2017 self citation chaining human rights in the robot age report recommendations the rathenau institute nether-lands academic and research institu-tion (gov) 11-oct-2017 public sector (council of eu-rope) citation chaining artificial intelligence. the public policy op-portunity summary of rec-ommendations intel corporation usa company 18-oct-2017 public sector (policy makers) citation chaining iti ai policy princi-ples iti ai policy prin-ciples information technol-ogy industry council (iti) interna-tional private sector al-liance 24-oct-2017 self (members) citation chaining ai now 2017 report recommendations, executive summary ai now institute usa academic and research institu-tion xx-oct-2017 multiple (core public agencies, companies, in-dustry, universi-ties, conferences, other stakehold-ers) citation chaining montréal declaration: responsible ai montréal declara-tion: responsible ai université de mont-réal canada academic and research institu-tion 3-nov-2017 multiple (public, developers, pol-icy makers) linkhubs ethically aligned de-sign. a vision for pri-oritizing human well-being with autono-mous and intelligent systems, version 2 ethically aligned design. a vision for prioritizing hu-man well-being with autonomous and intelligent sys-tems, version 2 institute of electrical and electronics engi-neers (ieee), the ieee global initiative on ethics of autono-mous and intelligent systems interna-tional prof. associa-tion/society 12-dec-2017 unspecified linkhubs how can humans keep the upper hand? re-port on the ethical matters raised by ai algorithms (only sec-tion \"from principles to policy recommen-dations\") from principles to policy recommen-dations french data protec-tion authority (cnil)  france governmental agencies/organi-zations 15-dec-2017 unspecified linkhubs top 10 principles for ethical artificial intel-ligence top 10 principles for ethical artifi-cial intelligence uni global union interna-tional federation/union 17-dec-2017 multiple (unions, workers) linkhubs business ethics and artificial intelligence fundamental val-ues and principles institute of business ethics uk private sector al-liance 11-jan-2018 private sector (users of ai in business) web search results 31-200 ibm’s principles for trust and transpar-ency ibm’s principles for trust and trans-parency  ibm usa company 17-jan-2018 self web search results 1-30 artificial intelligence and privacy recommendations for privacy friendly development and use of ai the norwegian data protection authority norway governmental agencies/organi-zations xx-jan-2018 multiple (devel-opers, system suppliers, organi-sations, end us-ers, authorities) web search results 31-200 the malicious use  of artificial intelligence: forecasting, preven-tion,  and mitigation four high-level recommendations future of humanity institute; university of oxford; centre for the study of existential risk; university of cambridge; center for a new american se-curity; electronic frontier foundation; openai interna-tional miscellaneous (mixed aca-demic, npo) 20-feb-2018 unspecified citation chaining \\nwhite paper: how to prevent discrimina-tory outcomes in ma-chine learning executive summary wef, global future council on human rights 2016-2018 interna-tional npo/charity 12-mar-2018 private sector (companies) citation chaining ',\n",
       " '  \\n4  for a meaningful arti-ficial intelligence. to-wards a french and european strategy \"part 5 — what are the ethics of ai?; part 6 — for inclu-sive and diverse artificial intelli-gence\" mission villani france governmental agencies/organi-zations 29-mar-2018 public sector (french govern-ment/parliament) linkhubs statement on artificial intelligence, robotics and \\'autonomous\\' systems ethical principles and democratic pre-requisites european commis-sion, european group on ethics in science and new technologies eu igo/supra-na-tional xx-mar-2018 public sector (eu commission) linkhubs l\\'intelligenzia artifi-ciale al servizio del cittadino sfida 1: etica agenzia per l\\'italia digitale (agid) italy governmental agencies/organi-zations xx-mar-2018 multiple (govern-ment, schools, healthcare insti-tutions) linkhubs openai charter openai charter openai usa npo/charity(*) 9-apr-2018 self linkhubs ai in the uk: ready, willing and able? (re-port, only section \"an ai code\" taken into account) no title. p. 125: \"… we suggest five overarching princi-ples for an ai code:\" uk house of lords, select committee on artificial intelligence uk governmental agencies/organi-zations 16-apr-2018 public sector (uk govern-ment) linkhubs privacy and freedom of expression in the age of artificial intel-ligence conclusions and recommendations privacy international & article 19 interna-tional npo/charity 25-apr-2018 multiple (states, companies, civil society) citation chaining ai guidelines ai guidelines deutsche telekom germany company 11-may-2018 self web search results 1-30 the toronto declara-tion: protecting the right to equality and non-discrimination in machine learning sys-tems the toronto decla-ration: protecting the right to equality and non-discrimina-tion in machine learning systems access now ; am-nesty international interna-tional miscellaneous (mixed ngo, npo) 16-may-2018 multiple (states, private sector ac-tors) linkhubs discussion paper on artificial intelligence (ai) and personal data - fostering re-sponsible develop-ment and adoption of ai principles for re-sponsible ai personal data protec-tion commission sin-gapore singa-pore governmental agencies/organi-zations 5-jun-2018 multiple (busi-ness; trade asso-ciations and chambers, pro-fessional bodies and interest groups) linkhubs our principles our principles google usa company 7-jun-2018 self web search results 1-30 discussion paper: na-tional strategy for ar-tificial intelligence (only section \"ethics, privacy, security and artificial intelligence. towards a “responsi-ble ai”\") ethics, privacy, se-curity and artificial intelligence. to-wards a “responsi-ble ai” national institution for transforming india (niti aayog) india governmental agencies/organi-zations 8-jun-2018 self (indian gov-ernment) linkhubs charlevoix common vision for the future of artificial intelli-gence charlevoix com-mon vision for the future of artificial intelligence leaders of the g7 interna-tional igo/supra-na-tional 9-jun-2018 self (gov) linkhubs policy recommenda-tions on augmented intelligence in health care h-480.940 policy recommen-dations on aug-mented intelligence in health care h-480.940 american medical as-sociation (ama) usa prof. associa-tion/society 14-jun-2018 self web search results 31-200 artificial intelligence: open questions about gender inclusion proposals w20 interna-tional igo/supra-na-tional 2-jul-2018 public sector (states/countries) web search results 31-200 everyday ethics for artificial intelligence. a practical guide for designers & develop-ers five areas of ethi-cal focus ibm usa company 2-sep-2018 designers web search results 1-30 artificial intelligence (ai) in health key recommenda-tions royal college of phy-sicians uk prof. associa-tion/society 3-sep-2018 multiple (indus-try, doctors, reg-ulators) web search results 31-200 initial code of conduct for data-driven health and care technology 10 principles uk department of health & social care uk governmental agencies/organi-zations 5-sep-2018 developers web search results 31-200 work in the age of ar-tificial intelligence. four perspectives on the economy, employ-ment, skills and ethics (only section \"good application of artificial intelligence technol-ogy and ethics\") values of a good artificial intelli-gence society ministry of economic affairs and employ-ment finland governmental agencies/organi-zations 10-sep-2018 multiple (finnish world of work) linkhubs \\nsap’s guiding princi-ples for artificial intel-ligence sap’s guiding prin-ciples for artificial intelligence sap germany company 18-sep-2018 self web search results 1-30 sony group ai ethics guidelines sony group ai eth-ics guidelines sony japan company 25-sep-2018 self (group) web search results 1-30 ethics framework - responsible ai framework machine intelligence garage ethics com-mittee uk n.a. 28-sep-2018 private sector (start-ups) web search results 31-200 ',\n",
       " '  \\n5  dutch artificial intel-ligence manifesto multidisciplinary challenges special interest group on artificial intelli-gence (sigai), ict platform netherlands (ipn) nether-lands academic and research institu-tion xx-sep-2018 multiple (dutch government, re-searchers)  web search results 31-200 governing artificial intelligence. uphold-ing human rights & dignity recommendations data & society usa research (npo) 10-oct-2018 multiple (compa-nies, researchers, governments, policy makers, un) citation chaining tieto’s ai ethics guidelines tieto’s ai ethics guidelines tieto finland company 17-oct-2018 self web search results 31-200 intel’s ai privacy pol-icy white paper. pro-tecting individuals’ privacy and data in the artificial intelligence world six policy recom-mendations intel corporation usa company 22-oct-2018 public sector (policy makers) web search results 31-200 universal guidelines for artificial intelli-gence universal guide-lines for artificial intelligence the public voice interna-tional mixed (coalition of ngos, icos etc.) 23-oct-2018 multiple (institu-tions, govern-ments) web search results 1-30 declaration on ethics and data protection in artificial intelligence \"… guiding princi-ples …\"  icdppc interna-tional igo/supra-na-tional 23-oct-2018 unspecified web search results 1-30 ai principles of tele-fónica ai principles of te-lefónica telefonica spain company 30-oct-2018 self web search results 1-30 introducing unity’s guiding principles for ethical ai – unity blog unity’s six guiding ai principles are as follows unity technologies usa company 28-nov-2018 self manual in-clusion responsible bots: 10 guidelines for devel-opers of conversa-tional ai guideline microsoft usa company xx-nov-2018 developers manual in-clusion ai now 2018 report recommendations ai now institute usa academic and research institu-tion xx-dec-2018 multiple manual in-clusion ethics of ai in radiol-ogy: european and north american mul-tisociety statement conclusion american college of radiology; european society of radiology; radiology society of north america; soci-ety for imaging infor-matics in medicine; european society of medical imaging in-formatics; canadian association of radiol-ogists; american as-sociation of physicists in medicine interna-tional prof. associa-tion/society 26-feb-2019 self manual in-clusion \\neuropean ethical charter on the use of artificial intelligence in judicial systems and their environment \"the five principles of the ethical char-ter on the use of artificial intelli-gence in judicial systems and their environment\" concil of europe: eu-ropean commission for the efficiency of justice (cepej) eu igo/supra-na-tional xx-feb-2019 multiple (public and private stakeholders) manual in-clusion ethically aligned de-sign: a vision for pri-oritizing human well-being with autono-mous and intelligent systems, first edition (ead1e) general principles institute of electrical and electronics engi-neers (ieee), the ieee global initiative on ethics of autono-mous and intelligent systems interna-tional prof. associa-tion/society 25-mar-2019 multiple (tech-nologists, educa-tors, and policy maker) manual in-clusion artificial intelligence. australia\\'s ethics framework. a discus-sion paper core principles for ai; a toolkit for ethical ai department of indus-try innovation and science australia governmental agencies/organi-zations 5-apr-2019 unspecified manual in-clusion ethics guidelines for trustworthy ai ethical principles in the context of ai systems high-level expert group on artificial in-telligence eu igo/supra-na-tional 8-apr-2019 multiple (all stakeholders) manual in-clusion ethical, social, and po-litical challenges of artificial intelligence in health conclusion future advocacy uk company xx-apr-2019 unspecified manual in-clusion the responsible ai framework operating ai pricewaterhouse-coopers uk uk company n.a. multiple (clients) web search results 31-200 digital decisions vi. solutions part 1: principles center for democracy & technology usa npo/charity n.a. unspecified citation chaining responsible ai and robotics. an ethical framework. our view accenture uk uk company n.a. private sector web search results 1-30 commitments and principles op financial group’s ethical guidelines for artifi-cial intelligence op group finland company n.a. self web search results 31-200 science, law and so-ciety (sls) initiative principles for the governance of ai the future society usa npo/charity n.a. public sector (policy makers) linkhubs ',\n",
       " '  \\n6  10 principles of re-sponsible ai summary of our proposed recom-mendations women leading in ai n.a. n.a. n.a. public sector (na-tional and inter-national policy makers) manual in-clusion ai4people—an ethi-cal framework for a good ai society: op-portunities, risks, principles, and rec-ommendations action points ai4people eu n.a. n.a. unspecified manual in-clusion ai principles & ethics ai principles; ai guidelines smart dubai uae governmental agencies/organi-zations n.a. 2018? self manual in-clusion    ',\n",
       " '  \\n7  table s2. screening and eligibility (details)  screening  sources consid-ered: - types: websites and documents published online or parts thereof such as policy documents, principles, guidelines, recommendations, dedicated webpages, institutional reports and declarations; - issuers: institutions, associations and organizations such as companies, corporations, ngos, npos, aca-demic and professional societies, governmental institutions and affiliated organizations; - language: english, german, french, italian, greek (the languages spoken by the researchers). sources ex-cluded: - types: videos, images, audio/podcasts, books, blog articles, academic articles, journalistic articles, syl-labi, legislation, official standards, conference summaries; - issuers: individual authors; - language: others than those above. eligibility sources in-cluded: - which refer to “artificial intelligence” and/or “ai”, either explicitly in their title or within their descrip-tion (example: uk, house of lords: “ai in the uk: ready, willing and able”); or - which do not contain the above reference in their title but mention “robot” or “robotics” instead and ref-erence ai or artificial intelligence explicitly as being part of robots and/or robotics (example: “principles of robotics”); or - which do not contain the above reference in their title but are thematically equivalent (by referring to “algorithms”, “predictive analytics”, “cognitive computing”, “machine learning”, “deep learning”, “au-tonomous” or “automated” instead (example: “automated and connected driving: report”). - which self-proclaim to be a principle or guideline (including “ethics/ethical”, “principles”, “tenets”, “declaration”, “policy”, “guidelines”, “values” etc.); or - which is expressed in normative or prescriptive language (i.e. with modal verbs or imperatives); or - which is principle- or value-based (i.e. indicating a preference and/or a commitment to a certain ethical vision or course of action). excluded sources: - websites and documents about robotics that do not mention artificial intelligence as being part of ro-bots/robotics; and - websites and documents about data or data ethics that do not mention artificial intelligence as being part of data;    ',\n",
       " '  \\n8  table s3. categorization after themeing and code mapping  question ad-dressed thematic family themes what? ethical principles & values ethical principles i. beneficence  ii. non-maleficence iii. trust iv. transparency & explainability v. freedom and autonomy (incl. consent) vi. privacy vii. justice, fairness & equity viii. responsibility & accountability  ix. dignity x. sustainability xi. solidarity technical and methodological aspects specific functionalities i. feedback & feedback-loop  ii. decision-making data & datasets  i. data origin/input ii. data use iii. metadata iv. algorithms methodological challenges i. methodology ii. metris & measurements iii. tests, testing iv. ambiguity & uncertainty v. accuracy vi. reliability vii. evidence and validation viii. black-box (opacity) ix. data security x. quality (of data/system/etc.) impact   benefits i. ai strengths, advantages ii. knowledge iii. innovation iv. enhancement   risks i. risks ii. malfunction iii. misuse & dual-use iv. deception v. discrimination (duplicate in justice&fairness) vi. surveillance vii. manipulation viii. arms race  impact assessment i. impact ii. goals/purposes/intentions iii. public opinion iv. risk evaluation & mitigation (duplicate in risks) v. monitoring/precaution vi. future of work who? design & development i. industry ii. ai researchers iii. designers iv. developers  users i. end users ii. organisations iii. public sector actors iv. military v. communities ',\n",
       " '  \\n9    specific stakeholders i. ethical and/or auditing committees ii. government iii. policy makers iv. researchers & scientists v. vulnerable groups & minorities how? social engagement i. knowledge commons ii. education & training iii. public deliberation & democratic processes iv. stakeholder involvement & partnerships soft policy i. standards ii. certification iii. best practices iv. whistleblowing economic incentives v. business model & strategy vi. funding & investments vii. taxes/taxation regulation & audits viii. laws & regulation (general) ix. data protection regulation x. ip law xi. human rights treaties xii. other rights & laws xiii. audits & auditing ',\n",
       " 'see discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/334539401\\na brief history of artiﬁcial intelligence: on the past, present, and\\nfutu re of artiﬁcial intelligence\\narticle \\xa0\\xa0 in\\xa0\\xa0calif ornia manag ement r eview · july 2019\\ndoi: 10.1177/0008125619864925\\ncitations\\n1,436reads\\n101,623\\n2 author s:\\nmichael haenlein\\nescp business school\\n68 publica tions \\xa0\\xa0\\xa034,340  citations \\xa0\\xa0\\xa0\\nsee profile\\nandr eas kaplan\\nkühne l ogistics univ ersity\\n98 publica tions \\xa0\\xa0\\xa029,156  citations \\xa0\\xa0\\xa0\\nsee profile\\nall c ontent f ollo wing this p age was uplo aded b y michael haenlein  on 19 june 2021.\\nthe user has r equest ed enhanc ement of the do wnlo aded file.',\n",
       " 'https://doi.org/10.1177/0008125619864925https://doi.org/10.1177/0008125619864925\\ncalifornia management review\\n 1 –10\\n© the regents of the \\nuniversity of california 2019\\narticle reuse guidelines:\\nsagepub.com/journals-permissions \\ndoi: 10.1177/0008125619864925\\njournals.sagepub.com/home/cmr\\n1a brief history of \\nartificial intelligence:\\non the past, present, \\nand future of artificial \\nintelligence\\nmichael haenlein1 and andreas kaplan2\\nsummary\\nthis introduction to this special issue discusses artificial intelligence (ai), commonly defined as “a system’s ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.” it summarizes seven articles published in this special issue that present a wide variety of perspectives on ai, authored by several of the world’s leading experts and specialists in ai. it concludes by offering a comprehensive outlook on the future of ai, drawing on micro-, meso-, and macro-perspectives.\\nkeywords: artificial intelligence, big data, regulation, strategy, machine-based \\nlearning\\nthe world we are living in today feels, in many ways, like a wonderland similar to the one that the british mathematician charles lutwidge dodgson, better known under the name lewis carroll, described in his famous novels. image recognition, smart \\nspeakers, and self-driving cars—all of this is possible due to advances in artificial intelligence (ai), defined as “a system’s ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.”\\n1 established as an academic discipline in the \\n1950s, ai remained an area of relative scientific obscurity and limited practical interest for over half a century. today, due to the rise of big data and improve-ments in computing power, it has entered the business environment and public conversation.\\n1escp europe business school, paris, france\\n2escp europe business school, berlin, germany\\n864925 cmr xxx10.1177/0008125619864925california management reviewa brief history of artificial intelligence: on the past, present, and future of artificial intelligence\\nresearch-article 2019\\n',\n",
       " 'california management review 00(0) 2\\nai can be classified into analytical, human-inspired, and humanized ai \\ndepending on the types of intelligence it exhibits (cognitive, emotional, and social \\nintelligence) or into artificial narrow, general, and super intelligence by its evo-lutionary stage.\\n2 what all of these types have in common, however, is that when \\nai reaches mainstream usage it is frequently no longer considered as such. this phenomenon is described as the ai effect, which occurs when onlookers discount the behavior of an ai program by arguing that it is not real intelligence. as the british science fiction writer arthur clarke once said, “any sufficiently advanced technology is indistinguishable from magic.” yet when one understands the tech-nology, the magic disappears.\\nin regular intervals since the 1950s, experts predicted that it will only take \\na few years until we reach artificial general intelligence—systems that show behavior indistinguishable from humans in all aspects and that have cognitive, emotional, and social intelligence. only time will tell whether this will indeed be the case. but to get a better grasp of what is feasible, one can look at ai from two angles—the road already traveled and what still lies ahead of us. in this editorial, we aim to do just that. we start by looking into the past of ai to see how far this area has evolved using the analogy of the four seasons (spring, summer, fall, and winter), then into the present to understand which challenges firms face today, and finally into the future to help everyone prepare for the challenges ahead of us.\\nthe past: four seasons of ai\\nai spring: the birth of ai\\nalthough it is difficult to pinpoint, the roots of ai can probably be traced \\nback to the 1940s, specifically 1942, when the american science fiction writer isaac asimov published his short story runaround. the plot of runaround—a story about a robot developed by the engineers gregory powell and mike donavan—evolves around the three laws of robotics: (1) a robot may not injure \\na human being or, through inaction, allow a human being to come to harm; (2) a robot must obey the orders given to it by human beings except where such orders would conflict with the first law; and (3) a robot must protect its own existence as long as such protection does not conflict with the first or second laws. asimov’s work inspired generations of scientists in the field of robotics, ai, and computer science—among others the american cognitive scientist marvin minsky (who later co-founded the mit ai laboratory).\\nat roughly the same time, but over 3,000 miles away, the english math-\\nematician alan turing worked on much less fictional issues and developed a code breaking machine called the bombe for the british government, with the purpose of deciphering the enigma code used by the german army in the second world war. the bombe, which was about 7 by 6 by 2 feet large and had a weight of about \\na ton, is generally considered the first working electro-mechanical computer. the powerful way in which the bombe was able to break the enigma code, a task pre-viously impossible to even the best human mathematicians, made turing wonder ',\n",
       " 'a brief history of artificial intelligence: on the past, present, and future of artificial3\\nabout the intelligence of such machines. in 1950, he published his seminal article \\n“computing machinery and intelligence”3 where he described how to create \\nintelligent machines and in particular how to test their intelligence. this turing test is still considered today as a benchmark to identify intelligence of an artificial system: if a human is interacting with another human and a machine and unable to distinguish the machine from the human, then the machine is said to be intelligent.\\nthe word artificial intelligence was then officially coined about six years \\nlater, when in 1956 marvin minsky and john mccarthy (a computer scientist at stanford) hosted the approximately eight-week-long dartmouth summer research project on artificial intelligence (dsrpai) at dartmouth college in new hampshire. this workshop—which marks the beginning of the ai spring and was funded by the rockefeller foundation—reunited those who would later be considered as the founding fathers of ai. participants included the computer scientist nathaniel rochester, who later designed the ibm 701, the first commercial scientific com-puter, and mathematician claude shannon, who founded information theory. the objective of dsrpai was to reunite researchers from various fields in order to create a new research area aimed at building machines able to simulate human intelligence.\\nai summer and winter: the ups and downs of ai\\nthe dartmouth conference was followed by a period of nearly two \\ndecades that saw significant success in the field of ai. an early example is the famous eliza computer program, created between 1964 and 1966 by joseph weizenbaum at mit. eliza was a natural language processing tool able to sim-ulate a conversation with a human and one of the first programs capable of attempting to pass the aforementioned turing test.\\n4 another success story of the \\nearly days of ai was the general problem solver program—developed by nobel prize winner herbert simon and rand corporation scientists cliff shaw and allen newell—that was able to automatically solve certain kind of simple prob-lems, such as the towers of hanoi.\\n5 as a result of these inspiring success stories, \\nsubstantial funding was given to ai research, leading to more and more projects. in 1970, marvin minsky gave an interview to life magazine in which he stated that a machine with the general intelligence of an average human being could be developed within three to eight years.\\nyet, unfortunately, this was not the case. only three years later, in 1973, \\nthe u.s. congress started to strongly criticize the high spending on ai research. in the same year, the british mathematician james lighthill published a report com-missioned by the british science research council in which he questioned the optimistic outlook given by ai researchers. lighthill stated that machines would only ever reach the level of an “experienced amateur” in games such as chess and that common-sense reasoning would always be beyond their abilities. in response, the british government ended support for ai research in all except three universi-ties (edinburgh, sussex, and essex) and the u.s. government soon followed the ',\n",
       " 'california management review 00(0) 4\\nbritish example. this period started the ai winter. and although the japanese \\ngovernment began to heavily fund ai research in the 1980s, to which the u.s. darpa responded by a funding increase as well, no further advances were made in the following years.\\nai fall: the harvest\\none reason for the initial lack of progress in the field of ai and the fact \\nthat reality fell back sharply relative to expectations lies in the specific way in which early systems such as eliza and the general problem solver tried to rep-licate human intelligence. specifically, they were all expert systems, that is, col-lections of rules which assume that human intelligence can be formalized and reconstructed in a top-down approach as a series of “if-then” statements.\\n6 expert \\nsystems can perform impressively well in areas that lend themselves to such for -\\nmalization. for example, ibm’s deep blue chess playing program, which in 1997 was able to beat the world champion gary kasparov—and in the process proved one of the statements made by james lighthill nearly 25 earlier wrong—is such an expert system. deep blue was reportedly able to process 200 million possible moves per second and to determine the optimal next move looking 20 moves ahead through the use of a method called tree search.\\n7\\nhowever, expert systems perform poorly in areas that do not lend them-\\nselves to such formalization. for example, an expert system cannot be easily trained to recognize faces or even to distinguish between a picture showing a muf-fin and one showing a chihuahua.\\n8 for such tasks it is necessary that a system is \\nable to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation—charac-teristics that define ai.\\n9 since expert systems do not possess these characteristics, \\nthey are technically speaking not true ai. statistical methods for achieving true ai have been discussed as early as the 1940s when the canadian psychologist donald hebb developed a theory of learning known as hebbian learning that replicates the process of neurons in the human brain.\\n10 this led to the creation of research on \\nartificial neural networks. yet, this work stagnated in 1969 when marvin minsky and seymour papert showed that computers did not have sufficient processing power to handle the work required by such artificial neural networks.\\n11\\nartificial neural networks made a comeback in the form of deep learning \\nwhen in 2015 alphago, a program developed by google, was able to beat the world champion in the board game go. go is substantially more complex than chess (e.g., at opening there are 20 possible moves in chess but 361 in go) and it was long believed that computers would never be able to beat humans in this game. alphago achieved its high performance by using a specific type of artificial neural network called deep learning.\\n12 today artificial neural networks and deep \\nlearning form the basis of most applications we know under the label of ai. they are the basis of image recognition algorithms used by facebook, speech recognition algorithms that fuel smart speakers and self-driving cars. this harvest of the fruits of past statistical advances is the period of ai fall, which we find ourselves in today.',\n",
       " 'a brief history of artificial intelligence: on the past, present, and future of artificial5\\nthe present: california management review special issue on ai\\nthe discussion above makes it clear that ai will become as much part of \\neveryday life as the internet or social media did in the past. in doing so, ai will \\nnot only impact our personal lives but also fundamentally transform how firms take decisions and interact with their external stakeholders (e.g., employees, cus-tomers). the question is less whether ai will play a role in these elements but more which role it will play and more importantly how ai systems and humans can (peacefully) coexist next to each other. which decisions should rather be taken by ai, which ones by humans, and which ones in collaboration will be an issue all companies need to deal with in today’s world and our articles in this special issue provide insights into this from three different angles.\\nfirst, these articles look into the relationship between firms and employees \\nor generally the impact of ai on the job market. in their article “artificial intelligence in human resources management: challenges and a path forward” tambe, cappelli, and yakubovich analyze how ai changes the hr function in firms. human resource management is characterized by a high level of complexity (e.g., measurement of employee performance) and relatively rare events (e.g., occurrence of recruiting and dismissals), which have serious consequences for both employees and the firm. these characteristics create challenges in the data-generation stage, the machine-learning stage, and the decision-making stage of ai solutions. the authors analyze those challenges, provide recommendations on when ai or humans should take the lead, and discuss how employees can be expected to react to different strategies.\\nanother article that addresses this issue is “the feeling economy: managing \\nin the next generation of ai” by huang, rust, and maksimovic. this article takes a broader view and analyzes the relative importance of mechanical tasks (e.g., repairing and maintaining equipment), thinking tasks (e.g., processing, analyzing, and interpreting information), and feeling tasks (e.g., communicating with peo-ple) for different job categories. through empirical analysis, these authors show that in the future, human employees will be increasingly occupied with feeling tasks since thinking tasks will be taken over by ai systems in a manner similar to how mechanical tasks have been taken over my machines and robots.\\nsecond, the articles in this special issue analyze how ai changes the inter -\\nnal functioning of firms, specifically group dynamics and organizational decision making. in “organizational decision-making structures in the age of ai,” shrestha, ben-menahem, and von krogh develop a framework to explain under which conditions organizational decision making should be fully delegated to ai, hybrid (either ai as an input to human decision making or human decisions as an input to ai systems) or aggregated (in the sense that humans and ai take deci-sions in parallel with the optimal decision being determined by some form of vot-ing). the question of which option should be preferred depends on the specificity of the decision-making space, the size of the alternative set, and decision-making speed as well as the need for interpretability and replicability.',\n",
       " 'california management review 00(0) 6\\nin a similar spirit, metcalf, askay, and rosenberg present artificial swarm \\nintelligence as a tool to allow humans to make better decisions in “keeping \\nhumans in the loop: pooling knowledge through artificial swarm intelligence to improve business decision making.” by taking inspiration from decision making in the animal world (e.g., among flocks of birds or ant colonies), these authors propose a framework to combine explicit and tactic knowledge that suffers less from biases such as herding behavior or the limitations of alternative techniques such as surveys, crowdsourcing, or prediction markets. they show the applicabil-ity of their method to sales forecasting and the definition of strategic priorities.\\nin their article “demystifying ai: what digital transformation leaders can \\nteach you,” brock and wangenheim take a broader perspective and investigate to what extent firms are already using ai in their business and how leaders in ai are different from companies lagging behind. based on a large-scale survey, they identify guidelines of successful ai applications that include a need for data, the requirement to have skilled staff and in-house knowledge, the focus on improv-ing existing business offerings using ai, the importance of having ai embedded in the organization (while, at the same time, engaging with technology partners), and the importance of being agile and having top-management commitment.\\nfinally, the articles in this special issue look into the interaction between a \\nfirm and its customers and specifically the role of ai in marketing. in “understanding the role of artificial intelligence in personalized engagement marketing,” kumar, rajan, venkatesan, and lecinski propose how ai can help in the automatic machine-driven selection of products, prices, website content, and advertising messages that fit with an individual customer’s preferences. they discuss in detail how the associated curation of information through personalization changes branding and customer relationship management strategies for firms in both developed and developing economies.\\nin a similar spirit, overgoor, chica, rand, and weishampel provide a six-\\nstep framework on how ai can support marketing decision making in “letting the computers take over: using ai to solve marketing problems.” this framework—which is based on obtaining business and data understanding, data preparation and modeling, as well as evaluation and deployment of solutions—is applied in three case studies to problems many firms face in today’s world: how to design influencer strategies in the context of word-of-mouth programs,\\n13 how to select \\nimages for digital marketing, and how to prioritize customer service in social media.\\nthe future: need for regulation\\nmicro-perspective: regulation with respect to algorithms and \\norganizations\\nthe fact that in the near future ai systems will increasingly be part of our \\nday-to-day lives raises the question of whether regulation is needed and, if so, \\nin which form. although ai is in its essence objective and without prejudice, it does not mean that systems based on ai cannot be biased. in fact, due to its very ',\n",
       " 'a brief history of artificial intelligence: on the past, present, and future of artificial7\\nnature, any bias present in the input data used to train an ai system persists and \\nmay even be amplified. research has, for example, shown that the sensors used in self-driving cars are better in detecting lighter skin tones than darker ones\\n14 \\n(due to the type of pictures used to train such algorithms) or that decision-sup-port systems used by judges may be racially biased\\n15 (since they are based on the \\nanalysis of past rulings).\\ninstead of trying to regulate ai itself, the best way to avoid such errors is \\nprobably to develop commonly accepted requirements regarding the training and testing of ai algorithms, possibly in combination with some form of warranty, similar to consumer and safety testing protocols used for physical products. this would allow for stable regulation even if the technical aspects of ai systems evolve over time. a related issue is the one of accountability of firms for mistakes of their algorithms or even the need for a moral codex of ai engineers, similar to the one lawyers or doctors are swearing to. what such rules can, however, not avoid is the deliberate hacking of ai systems, the unwanted use of such systems for micro-targeting based on personality traits,\\n16 or the generation of fake news.17\\nwhat makes matters even more complicated is that deep learning, a key \\ntechnique used by most ai systems, is inherently a black box. while it is straight-forward to assess the quality of the output generated by such systems (e.g., the share of correctly classified pictures), the process used for doing so remains largely opaque. such opacity can be intentional (e.g., if a corporation wants to keep an algorithm secret), due to technical illiteracy or related to the scale of application (e.g., in cases where a multitude of programmers and methods are involved).\\n18 \\nwhile this may be acceptable in some cases, it may be less so in others. for exam-ple, few people may care how facebook identifies who to tag in a given picture. but when ai systems are used to make diagnostic suggestions for skin cancer based on automatic picture analysis,\\n19 understanding how such recommendations \\nhave been derived becomes critical.\\nmeso-perspective: regulation with respect to employment\\nin a similar manner as the automation of manufacturing processes has \\nresulted in the loss of blue-collar jobs, the rising use of ai will result in less need for white-collar employees and even high-qualified professional jobs. as men-tioned previously, image recognition tools are already outperforming physicians in the detection of skin cancer and in the legal profession e-discovery technolo-gies have reduced the need for large teams of lawyers and paralegals to exam-ine millions of documents.\\n20 granted, significant shifts in job markets have been \\nobserved in the past (e.g., in the context of the industrial revolution from 1820-1840), but it is not obvious whether new jobs will necessarily be created in other areas in order to accommodate those employees. this is related to both the num-ber of possible new jobs (which may be much less than the number of jobs lost) and the skill level required.\\ninterestingly, in a similar way as fiction can be seen as the starting point of ai \\n(remember the runaround short story by isaac asimov), it can also be used to get a ',\n",
       " 'california management review 00(0) 8\\nglimpse into how a world with more unemployment could look like. the fiction \\nnovel snow crash published by the american writer neal stephenson describes a \\nworld in which people spend their physical life in storage units, surrounded by technical equipment, while their actual life takes place in a three-dimensional world called the metaverse where they appear in the form of three-dimensional avatars. as imaginary as this scenario sounds, recent advancements in virtual reality image processing, combined with the past success of virtual worlds\\n21 (and the fact that \\nhigher unemployment leads to less disposable income), make alternative forms of entertainment less accessible, and make this scenario far from utopian.\\nregulation might again be a way to avoid such an evolution. for example, \\nfirms could be required to spend a certain percentage of the money saved through automation into training employees for new jobs that cannot be automated. states may also decide to limit the use of automation. in france, self-service systems used by public administration bodies can only be accessed during regular working hours. or firms might restrict the number of hours worked per day to distribute the remaining work more evenly across the workforce. all of these may be easier to implement, at least in the short term, than the idea of a universal basic income that is usually proposed as a solution in this case.\\nmacro-perspective: regulation with respect to democracy and peace\\nall this need for regulation necessarily leads to the question “quis custodiet \\nipsos custodes?” or “who will guard the guards themselves?” ai can be used not only by firms or private individuals but also by states themselves. china is cur -\\nrently working on a social credit system that combines surveillance, big data, and ai to “allow the trustworthy to roam everywhere under heaven while mak-ing it hard for the discredited to take a single step.”\\n22 in an opposite move, san \\nfrancisco recently decided to ban facial recognition technology23 and researchers \\nare working on solutions that act like a virtual invisibility cloak and make people undetectable to automatic surveillance cameras.\\n24\\nwhile china and, to a certain extent, the united states try to limit the bar -\\nriers for firms to use and explore ai, the european union has taken the opposite direction with the introduction of the general data protection regulation (gdpr) that significantly limits the way in which personal information can be stored and processed. this will by all likelihood result in the fact that the development of ai will be slowed down in the eu compared with other regions, which in turn raises the question how to balance economic growth and personal privacy concerns. in the end, international coordination in regulation will be needed, similar to what has been done regarding issues such as money laundering or weapons trade. the nature of ai makes it unlikely that a localized solution that only affects some countries but not others will be effective in the long run.\\nthrough the looking glass\\nnobody knows whether ai will allow us to enhance our own intelligence, \\nas raymond kurzweil from google thinks, or whether it will eventually lead us ',\n",
       " 'a brief history of artificial intelligence: on the past, present, and future of artificial9\\ninto world war iii, a concern raised by elon musk. however, everyone agrees \\nthat it will result in unique ethical, legal, and philosophical challenges that will need to be addressed.\\n25 for decades, ethics has dealt with the trolley problem, \\na thought experiment in which an imaginary person needs to choose between inactivity which leads to the death of many and activity which leads to the death of few.\\n26 in a world of self-driving cars, these issues will become actual choices \\nthat machines and, by extension, their human programmers will need to make.27 \\nin response, calls for regulation have been numerous, including by major actors such as mark zuckerberg.\\n28\\nbut how do we regulate a technology that is constantly evolving by itself—\\nand one that few experts, let alone politicians, fully understand? how do we overcome the challenge of being sufficiently broad to allow for future evolutions in this fast-moving world and sufficiently precise to avoid everything being con-sidered as ai? one solution can be to follow the approach of u.s. supreme court justice potter stewart who in 1964 defined obscenity by saying: “i know it when i see it.” this brings us back to the ai effect mentioned earlier, that we now quickly tend to accept as normal was used to be seen as extraordinary. there are today dozens of different apps that allow a user to play chess against her phone. playing chess against a machine—and losing with near certainty—has become a thing not even worth mentioning. presumably, garry kasparov had an entirely different view on this matter in 1997, just a bit over 20 years ago.\\nauthor biographies\\nmichael haenlein is the big data research center chaired professor and \\nassociate dean of the executive phd program at the escp europe business school (email: haenlein@escpeurope.eu).\\nandreas kaplan, professor and dean at escp europe business school berlin, \\ncounts among the top 50 business and management authors worldwide (email: akaplan@escpeurope.eu).\\nnotes\\n 1. andreas m. kaplan and michael haenlein, “siri, siri, in my hand: who’s the fairest in \\nthe land? on the interpretations, illustrations, and implications of artificial intelligence,” business horizons, 62/1 (january/february 2019): 15-25.\\n 2. ibid.\\n 3. alan turing, “computing machinery and intelligence,” mind, lix/236 (1950): 433-460.\\n 4. for those eager to try eliza, see: https://www.masswerk.at/elizabot/.\\n 5. the towers of hanoi is a mathematical game that consists of three rods and a number of disks of different sizes. the game starts with the disks in one stack in ascending order and consists of moving the entire stack from one rod to another, so that at the end the ascending order is kept intact.\\n 6. for more details, see kaplan and haenlein, op. cit.\\n 7. murray campbell, a. joseph hoane jr., and feng-hsiung hsu, “deep blue,” artificial \\nintelligence, 134/1-2 (january 2002): 57-83.\\n 8. matthew hutson, “how researchers are teaching ai to learn like a child,” science, may 24, 2018, https://www.sciencemag.org/news/2018/05/how-researchers-are-teaching-ai-learn-child.\\n 9. kaplan and haenlein, op. cit.',\n",
       " 'california management review 00(0) 10\\n10. donald olding hebb, the organization of behavior: a neuropsychological theory (new york, ny: \\njohn wiley, 1949).\\n11. marvin minsky and seymour a. papert, perceptrons: an introduction to computational geometry \\n(cambridge, ma: mit press, 1969).\\n12. david silver, aja huang, chris j. maddison, arthur guez, laurent sifre, george van den driessche, julian schrittwieser, ioannis antonoglou, veda panneershelvam, marc lanctot, sander dieleman, dominik grewe, john nham, nal kalchbrenner, ilya sutskever, timothy lillicrap, madeleine leach, koray kavukcuoglu, thore graepel, and demis hassabis, “mastering the game of go with deep neural networks and tree search,” nature, 529 (january 27, 2016): 484-489.\\n13. michael haenlein and barak libai, “seeding, referral, and recommendation: creating profitable word-of-mouth programs,” california management review, 59/2 (winter 2017): 68-91.\\n14. benjamin wilson, judy hoffman, and jamie morgenstern, “predictive inequity in object detection,” working paper, february 21, 2017, https://arxiv.org/pdf/1902.11097.pdf.\\n15. julia angwin, jeff larson, surya mattu, and lauren kirchner, “machine bias: there’s software used across the country to predict future criminals. and it’s biased against blacks,” propublica, may 23, 2016, https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\\n16. michal kosinski, david stillwell, and thore graepel, “private traits and attributes are predictable from digital records of human behavior,” proceedings of the national academy of sciences of the united states of america, 110/15 (2013): 5802-5805.\\n17. supasorn suwajanakorn, steven m. seitz, and ira kemelmacher-shlizerman, “synthesizing obama: learning lip sync from audio,” working paper, july 2017, https://grail.cs.washington.edu/projects/audiotoobama/siggraph17_obama.pdf.\\n18. jenna burrell, “how the machine ‘thinks’: understanding opacity in machine learning algorithms,” big data & society, 3/1 (june 2016): 1-12.\\n19. h. a. haenssle, c. fink, r. schneiderbauer, f. toberer, t. buhl, a. blum, a. kalloo, a. ben hadj hassen, l. thomas, a. enk, and l. uhlmann, “man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists,” annals of oncology, 29/8 (august 2018): 1836-1842.\\n20. john markoff, “armies of expensive lawyers, replaced by cheaper software,” the new york times, march 4, 2011, https://www.nytimes.com/2011/03/05/science/05legal.html.\\n21. andreas m. kaplan and michael haenlein, “the fairyland of second life: about virtual social worlds and how to use them,” business horizons, 52/6 (november/december 2009): 563-572.\\n22. “china invents the digital totalitarian state,” the economist, december 17, 2016, https://www.economist.com/briefing/2016/12/17/china-invents-the-digital-totalitarian-state.\\n23. “san francisco bans facial recognition technology,” the new york times, may 14, 2019, https://www.nytimes.com/2019/05/14/us/facial-recognition-ban-san-francisco.html.\\n24. simen thys, wiebe van ranst, and toon goedeme, “fooling automated surveillance cameras: adversarial patches to attack person detection,” working paper, april 18, 2019, https://arxiv.org/abs/1904.08653.\\n25. andreas m. kaplan and michael haenlein, “rulers of the world, unite! the challenges and opportunities of artificial intelligence,” working paper, 2019.\\n26. judith thomson, “killing, letting die, and the trolley problem,” monist: an international quarterly journal of general philosophical inquiry, 59/2 (april 1976): 204-217.\\n27. edmond awad, sohan dsouza, richard kim, jonathan schulz, joseph henrich, azim shariff, jean-francois bonnefon, and iyad rahwan, “the moral machine experiment,” nature, 563 (2018): 59-64.\\n28. mark zuckerberg, “the internet needs new rules. let’s start in these four areas,” the washington post, march 30, 2019, https://www.washingtonpost.com/opinions/mark-zucker -\\nberg-the-internet-needs-new-rules-lets-start-in-these-four-areas/2019/03/29/9e6f0504-521a-11e9-a3f7-78b7525a8d5f_story.html.\\nview publication stats\\n',\n",
       " 'ai education and inclusion  \\n1 \\n  \\na self -determination theory (sdt) design approach for inclusive \\nand diverse artificial intelligence (ai) education  \\n \\n \\nfirst draft  \\n \\nxia, q., chiu, t. k.  f., lee, m., sanusi, i. t., dai, y., & chai, c. s. (2022). a self-\\ndetermination theory (sdt) design approach for inclusive and diverse artificial \\nintelligence (ai) education.  computers & education , 189, 104582.  \\nhttps://doi.org/10.1016/j.compedu.2022.104582  \\n \\n \\nthe introduction of artificial intelligence (ai) as a subject in k -12 education is a new \\nand important global strategic initiative, but there is a serious lack of studies in relation \\nto this initiative that address inclusion and diversity of education. sel f-determination \\ntheory (sdt) can explain student engagement from the needs satisfaction perspective. \\ntherefore, this project aimed to investigate how sdt -based needs support by teachers \\nand student attributes (gender and achievement level) affect ai learni ng at secondary \\nschool level. it adopted a two -study design, with each study using a 2 x 2 between -\\nsubjects factorial design with student needs support from teachers as one factor and one \\nof the student attributes as the other: gender in study 1 and achiev ement level in study  \\n2. in both studies, there were two groups – sdt -based (teacher needs support) and \\ncontrol (without). the analyses revealed that in the sdt -based program, (1) the \\nstudents had a more positive perception of ai learning and felt that thei r needs were \\nsatisfied, and (2) there were non -significant differences in ai learning between boys and \\ngirls and between high and low achievers. the findings suggest that a focus on needs \\nsatisfaction could engage boys and girls, and high and low achievers  in ai learning. as \\nthey become more engaged, they are likely to gain more confidence, feel that the \\ncontent is more relevant, and become intrinsically motivated to pursue further ai \\nlearning.  \\n \\nkeywords: ai education, k -12 education, inclusion, diversity, self -determination \\ntheory , motivation  \\n  ',\n",
       " 'ai education and inclusion  \\n2 \\n nations across the globe are developing strategic initiatives to equip future \\ngenerations with the skills and knowledge needed to thrive in the digital age (touretzky  \\net al., 2019).  among these initiatives  are research and education projects instigated by \\ngovernments, universities, and schools in many countries and regions, including \\naustralia, china, europe, india, singapore, thailand , and the united states,  to \\nintroduce the topic of artificial intelligence (ai) into the formal k –12 curriculum. these \\nprojects , undertaken in response to ai increasingly permeating people’s everyday lives,  \\nhave delivered crucial findings for the development of ai education , provi ding \\nsuggestions for  key content, curriculum framework s, and assessment items.  \\nas ai skills and knowledge  quickly  become integral part s of a holistic \\neducation , it is essential to address the issue of equity (chiu et al., 2021) . unesco \\nstates that a high-quality school education should be designed in a fair and inclusive \\nmanner that enable s all students to acquire and develop the knowledge, skills , and \\nvalues that contribute to a  meaningful and productive li fe (stabback, 2016). in schools, \\nmost of the  engineering curricul um, which forms part of the stem group of subjects  \\n(science, technology, engineering , and mathematics) , has been conducted after formal \\nlessons and outside of normal classroom settings . as most participants have been high -\\nachieving  boys , the subject suffers from a lack of diversity that has created issues  of \\ninclusion  and equity.  \\ninclusion and d iversity , which are important to ensure the success of ai \\neducation (delaine et al, 2016; ibe et al., 2 018),  are primarily achieved by increasing \\nthe motivation and engagement of underrepresented groups in learning (chiu & lim, \\n2020; chiu & mok, 2017; chiu et al., 2020 ; eccles, 2007 ; prince & hadwin, 2013 ). \\nformal school education heavily relies on how teac hers design and deliver learning \\nactivities (kelly, 2009). instructional designs that address inclusion and diversity can ',\n",
       " 'ai education and inclusion  \\n3 \\n motivate student engagement by catering to different needs (chiu & lim, 2020; chiu & \\nmok, 2017; chiu et al., 2020). according to self-determination theory (sdt), student \\nengagement and well -being are promoted by satisfying three basic psychological needs : \\nautonomy, competence , and relatedness. therefore, teachers who se learning activities  \\nsatisfy the se three needs can engage more girls and low -achieving students in learning \\nai. moreover, interdisciplinary research – adding psychological perspectives to \\nengineering education research – advances diverse and inclusive engineering education \\npractices (baillie et al., 2011).  \\nthere have bee n no sdt -based studies into the promotion of inclusion and \\ndiversity in  k-12 ai education  to date . in the literature  on inclusion and diversity in \\ngeneral engineering education, most studies have  suggest ed using female mentors and \\nrole models and adopting more project - and team -based learning styles to engage girls \\nand low -achieving students. the present  study look s at the issue from the different \\nperspective of needs satisfaction  by investigat ing whether having teacher s support  \\nstudent needs  can promote inclusion and diversity in ai education. as teaching ai is \\nnew to schools, more studies are needed to inform researchers, government  officers , and \\npractitioners to design, develop, and evaluate quality learning and teaching activiti es \\n(chiu, 2020, 2021a; chiu et al., 2021; pedró et al., 2019).  \\n \\n \\nliterature review  \\n \\nai education in k –12 \\nai is recognized  as an ever -changing field with a diverse range of topics that \\nextend beyond computational thinking ( chiu et al., 2021 ). not only does ai comprise a \\nvariety of sub -fields , such as natural language processing and neural networks , but it \\nalso explores such broader skills as critical thinking, meaning -making, evaluating , and ',\n",
       " 'ai education and inclusion  \\n4 \\n troubleshooting ( chiu, 2021a; chiu et al., 2021 ). due to the breadth of topics and wide \\nrange of skills in the ai field, it is challenging to design and implement a coherent ai \\ncurriculum for k –12 without deliberate research and planning ( chiu & chai, 2020 ). the \\nfirst study was papert and solomon ’s (1971) explor ation of  young students learn ing ai \\nwith turtle robot s and logo programming. a half -century later , ai teaching has become \\nan emerging area of educational research, with a range of projects  promoting ai \\neducation at the k–12 level  carried out by universities internationally . three examples \\nare as follows. first , a notable collaboration between sensetim e and east china \\nnormal university led to the publication of the first ai textbook series for high school \\nstudents,  fundamentals of artificial intelligence  (sensetime, 2018) . the series is most \\nsuitable for academically competent students or those with str ong engineering \\nbackgrounds, and the content foster s the development of technical knowledge and skills \\nin ai. second , massachusetts institute of technology  (mit)  examined various hands -\\non robot learning activities and focused on the design of the students’ learning process \\n(williams et al., 2019). the mit  study provided insights into the use of robotics in the \\nlearning of ai  but also  raised concerns about gender -biased lesson desig ns, which \\nseemed to favor boys and neglect the interests of girls. third, the chinese university of \\nhong kong collaborate d with local schoolteacher s to develop a set of ai teaching \\nresources for middle schools and examine d the effectiveness of these resour ces on \\nimproving student s’ ai knowledge and attitude s (chiu et al., 2021) . however, t his \\nproject did not investigate whether these resources addressed issues of inclusion and \\ndiversity.  \\ngovernments in  different regions have also initiated national education policies \\nfor ai. chiu and colleagues (2021) reviewed ai education policies in different \\ncountries . korea and the united states ( with the ai4k12  project ) both developed ',\n",
       " 'ai education and inclusion  \\n5 \\n national curriculum standards to guide schools and teachers  to design teaching activities \\nfor ai ; the european union has provided the public (including young children) with \\nfree resources and courses to acquire ai knowledge and skills ; in india, the central \\nboard of secondary education adopted the microsoft k12 ed ucation transformation \\nframework to develop their school curriculum for grade 9 students. these projects have \\nidentified and suggested essential content knowledge and concept s (e.g., ethics, \\nmachine learning, and ai applications) , but have not addressed th e issues surrounding \\nequity and inclusion . in summary, a lthough the work of universities and education \\ndepartments ha s identified key content and activities for teaching ai in schools, there is \\nno k –12 ai program designed with inclusion and diversity as a priority. m ore work is \\nneeded to instill ai education with these essential attributes (chiu et al., 2021; delaine \\net al, 2016; ibe et al., 2018).  \\nhowever, unesco states that a quality education should be designed in a fair \\nand inclusive manner to enables all students to acquire and develop the knowledge, \\nskills and values, which leads to meaningful and productive lives (s tabback, 2016). \\nmore work is needed to cultivate inclusion and diversity in ai education (chiu et al., \\n2021; delaine et al, 2016; ibe et al., 2018).  \\n \\ninclusion and diversity in school engineering education  \\nai is often seen as an engineering discipline. eng ineering education is primarily \\noffered as a subject at  the post-secondary level and mostly to high -achieving male \\nstudents , leaving girls and less  able students underrepresented  (delaine et al, 2016; ibe \\net al., 2018). the subject is thus  relatively lacking in  inclusi on and diversity (dubow et \\nal., 2016) . catching student interest early then following through with that interest at the \\nk–12 level may be the key to inspiring more st udents, particularly from ',\n",
       " 'ai education and inclusion  \\n6 \\n underrepresented group s, to pursue engineering or engineering -related study and/or \\ncareers (delaine et al ., 2016; ibe et al., 2018). the provision of engineering -related \\nlearning activities in schools  has recently increased , with the rising  popularity of stem \\nsubjects . however, without appropriate pedagogies , engagement in these activities may \\nsimply mirror the disparities observed at the post -second ary level ( baillie et al., 2011; \\ndelaine et al ., 2016). accordingly, the teaching of engineering -related subjects, such as \\nai, at the k–12 level represents  a new global trend in education that need s further \\nresearch, particularly regarding inclusion and di versity.  \\nthe l iterature has suggest ed that in schools there are differences in attitudes \\ntoward engineering between girls and boys  and between  students at high and low levels \\nof ability (delaine et al ., 2016;  roehrig et al., 2012). studies have found that girls and \\nless able students have less interest, competence, and confidence in  their engineering \\nskills  and place less intrinsic value on such skills. female engineering majors generally \\npossess fixed mindsets  that engineering activities are des igned for men, which results in \\nunderperformance (heyman et al., 2002). a plausible reason  for this mindset  is \\nstudents ’ perceptions that the teaching and learning activities are not fully inclusive (ibe \\net al., 2018). girls and less  able students feel less supported and comfortable than their \\nhigh-achieving male counterparts when engaging in these  activities. for example, the \\nuse of robot s for learning ai is not gender -neutral and favor s boys , while the heavy \\nemphasis on coding activities may be too challenging for less  able students. moreover, \\nmost engineering -related activities in the k –12 curricula are conducted outside  of the  \\nclassroom setting.  some of the activities are designed to train students to join external \\ncompetition s; in these cases , students who participate in the activities are generally \\nperceived to be high  achieve rs. furthermore, archer et al. (2010) found that school \\nstudents were deterred in the pursuit of stem education by their impression s of the ',\n",
       " 'ai education and inclusion  \\n7 \\n generally high academic standards of university science and engineering students.  these \\nstereotypes produce  negative  attitudes toward engineering that translate into higher \\ndrop-out rates among girls and poor performing students (bøe  et al., 2011 ). it is all too \\noften the case that students are excluded on grounds of their socio -economic \\ncircumstances, gender , or academic ability.  \\nto meet unesco’s sustainable development goals of quality education, good \\nquality k –12 teaching needs to be inclusive and diverse to assist all students, regardless \\nof their socio -economic background, gender , or academic ability, to develop their \\ncapabilities to the fullest (stabback, 2016). every child is different , not all are \\nacademically gifted , and some will do better in one field than in another; but all children \\nshould be supported and encouraged to achieve their potential. therefore, a high-quality \\nai curriculum for k –12 should make space for teachers to recognize each student ’s \\npersonal and c ognitive capacities and to support students’ needs (chiu, 2020, 2021a; \\nchiu & chai, 2020; lennert da silva  & mølstad , 2020). teachers should respect \\ndifferences in the ways  children learn, encourage learning differentiation, and ensure \\nthat the design and delivery  of learning activities are appropriate to their student s’ needs \\nand capabilities. moreover, using interdisciplinary research advances diverse and \\ninclusive enginee ring education practices (baillie et al., 2011), and this project add \\npsychological domain (sdt) to engineering education.  \\n \\nsdt  and student  motivation  \\nsdt  provides a theoretical framework for motivation that has strong \\nimplications for both classroom practice and educational reform policies (ryan & deci, \\n2017 , 2020 ). the theory  posits that all individuals possess three basic psychological \\nneeds —autonomy, re latedness , and competence —that motivate self-initiate d behavior ',\n",
       " 'ai education and inclusion  \\n8 \\n and engage ment  (ryan & deci, 2017 , 2020 ). according to sdt, teacher s can motivate \\nstudent engagement by satisfying their needs.  when their three basic needs are satisfied , \\nstudent s’ motivational orientation can move along a continuum , from amotivation to \\nextrinsic motivation to intrinsic motivation , as students increasingly internalize their \\nmotivation until something intrinsic about the activity drives them. this intrinsic \\nmotivatio n sustain s students’  personal growth and well -being, potentially enhancing \\nlearning outcomes. accordingly, when teaching and learning meet  the need s for \\nautonomy, competence, and relatedness, students with any motivation orientation are \\nmore likely to be i ntrinsically motivated to learn.  \\nteachers can support student needs by encouraging student autonomy \\n(autonomy), providing for learning (competence) , and being involved interpersonally \\n(relatedness) (lietaert et al., 2015; sierens  et al., 2009). autonomy -supportive teachers \\nwill encourage and facilitate students to pursue their own learning goals and endorse \\nstudent s’ choice s of behaviors and learning approaches in the classroom  (assor et al., \\n2002 ; chiu, 2021 b, 2021 c, 2021d ). for example, they allow for choices over learning  \\nactivities and materials , give reason s when choice s are limited , and avoid using \\ncontrolling and demanding language (katz & assor, 2007;  chiu, 2021 b, 2021 c). if \\nstudents make their own decisions based on their personal goals , interest s, and abilit ies, \\nthey feel empowered in learning.  \\ncompetence -support ive teachers will provide clear and specific  guidance for \\nlearning , delineate the boundaries of learning activitie s, express confidence in student s’ \\nabilit ies, give learning -relevant feedback ( chiu, 2021b, 2021c ), and provide well-\\ndesigned learning materials (chiu et al., 2020; chiu & mok, 2017). students will \\ndevelop a sense of mastery  and feel challenged in their learning  and encouraged to \\nactively participate in learning  activities .  ',\n",
       " 'ai education and inclusion  \\n9 \\n relatedness -support ive teachers will develop close and caring teacher –student \\nand student –student relationship s by creating and maintaining warm, affectionate , and \\njoyful learning environments (chiu, 2021 b, 2021 c; skinner et al., 2008). they will \\nprovide students with emotional support (e.g., caring, acceptanc e, and assistance ) \\n(vollet et al., 2017). feeling safe and welcome, and connected to their school and \\nsubjects, and develop ing strong personal networks that can provide help and support, \\nleads students  to greater learning engagement (ryan & deci, 2017; chiu, 2021 b, \\n2021 c). accordingly, students of different genders and ability levels will be more \\nengage d in learning when  their three needs are satisfied.  \\n \\nmethod  \\nresearch design  \\nbased on sdt, student needs support from t eacher s has been widely applied to \\noptimize student learning in the classroom  and online context s (e.g., ruzek et al., 2016; \\nstandage et al., 2005 ; chiu 2021a , 2021b ). however, t o the best of our knowledge, very \\nfew or no sdt -based stud ies have investigate d how needs support promote s inclusion \\nand diversity in ai  (or engineering  more generally ) education. boys and girls  and high \\nand low achievers seem to have different attitudes toward ai learning.  moreover, \\nadding psychological needs to engineer ing education research (interdisciplinary \\nresearch) can advance diverse and inclusive engineering education practices (baillie et \\nal., 2011). the goal of t his project  was to adopt the perspective of needs satisfaction to \\ninvestigate how sdt -based needs support and student attributes (gender or achievement  \\nlevel ) affect ai learning  in a k–12 setting . more specifically, the study examine d \\nwhether needs support from teacher s can improve ai learning —readiness, attitude, \\nconfidence, anxiety, and intrinsic motivation —and cater  to (i) boys and girls  and (ii) ',\n",
       " 'ai education and inclusion  \\n10 \\n strong and weak coding skill  levels . accordingly, the following three research questions \\nwere examined:  \\nrq1: what is the influen ce of needs support from teacher s on ai learning  for \\nstudents of different genders and achievement  levels ? \\nrq2: what is the influence of needs support from teacher s on needs satisfaction \\nfor students of different genders and achievement  levels ? \\nrq3: does needs support from teacher s improve students’ ai learning ? \\n \\nthe findings of this project  could contribute to the design of k–12 engineering \\neducation , bring large numbers of students, regardless of their gender and achievement  \\nlevels , into contact with ai and engineering, and boost the confidence, ease the anxiety, \\nand enhance the attitude and motivation of students toward the subject . more young \\nstudents will then be prepared to grasp opportunities in post-secondary education and \\nthe job market in engineering -related disciplines.  \\nthis project  adopted a two -study design , with each study using a 2 \\uf0b4 2 between -\\nsubjects factorial design with student needs support from  teacher s as one factor and  one \\nof the student attributes as the other: gender in  study 1 and achievement level in study \\n2. this approach is supported by its use in studies with similar goals (e.g., chiu, 2021c; \\ndu et al., 2020; hiemstra et al., 2015; schneider et al., 2018).   \\n \\nstudy 1  \\nparticipants and procedure  \\nthe participants in study 1 were 64 male and 64 female grade 9 students  \\nfrom three  different school s (with a mean age of 14.5 years ), and e ight teachers \\nwith extensive teaching experience in computer science. the teachers  attende d ',\n",
       " 'ai education and inclusion  \\n11 \\n two 3 -hour workshops on sdt -based need s support. the student s were then \\ndivided into two groups : an sdt -based  group  and a control group to be exposed \\nto normal teaching strategies  (“business as usual”) . there were  32 male and 32 \\nfemale students in each group. the student s participated  in a 15-day (42 -hour) \\nsummer ai program . fifteen -minute  pre- and post -test questionnaire s were \\nadministered to the students on the first and last day of the program, respectively . \\neach group was taught by four teachers.  \\n \\nthe ai program  \\nthe ai program was designed using the curriculum framework suggested by \\nchiu (2021a), as shown in figure 1. there were three main topics: what is ai? \\n(knowledge) ; how does ai work? (process) ; and  what are the impacts of ai? (impact). \\nthe students attended  five 1-hour lectures and completed a project in group s of five or \\nsix. the strategies for teacher s to provide  needs support were designed using the sdt -\\nbased studies of c hiu (2021 b, 2021 c). the instructional strategies of the two groups  \\nwere as follows . \\nin the sdt -based  group, to foster autonomy, the teachers took the students’ \\nperspective, embedded autonomy in the learning activities, and used invitational \\nlanguage. the stude nts determined the problem they want ed to study and initiated their \\nown projects. in devising solutions , they decided the form  of their prototype s (e.g., \\napplication, hardware, proposal, or essay) and what tools ( e.g., teachable machine, aiy \\nvoice kit from google, huskylen, or drone) to use. to satisfy the need for competence, \\nthe teachers explained to the students how they  could make progress and achieve the \\ndesired outcomes in structured learning activities. they commu nicated clear \\nexpectations and offered step -by-step guidance. to support relatedness, the teachers ',\n",
       " 'ai education and inclusion  \\n12 \\n supported emotional connections by fostering interpersonal relationships. they formed \\nstudent groups by matching students together with other s who had simila r self -identified \\nproblems  and conduct ing daily teacher –student group meetings. furthermore , the \\nproblem s addressed in student projects  were under the theme “ai for social good ,” with \\nthe students creating solutions to benefit communities.  \\nin the control group, the teachers used the existing —more controlling —teaching \\nstrategies. they told the students what to do  and assigned a specific project topic —a \\nrobot car that can avoid obstacles —to the students . the t eachers allowed the students  to \\nuse a raspberry pi  only as a tool  (less autonomy)  and explained their expectations and \\noffer ed one-off guidance to the students in the first lesson only (less competence) . \\nmoreover, the teachers randomly divided the students into groups, conducted only \\nwhole -class meetings for every lesson , and assigned a project topic that was not for the \\nbenefit  of the wider community (less relatedness).  \\n \\nparticipant questionnaire  \\napart from demographic data, the pre - and post -program questionnaires \\nincluded items collecting data for two categories of variables: ai learning (perceived ai \\nreadiness (aid),  ai confidence (aic),  ai attitude (aiat), ai anxiety (aiax), and \\nintrinsic motivation to learn ai (aiim) ) and needs satisfaction (perceived autonomy, \\ncompetence , and relatedness ). each of the variables was measured using four items \\nrated on a 5-point likert scale (1- strongly disagree; 5 - strongly agree)  and adapted \\nfrom previous studies with acceptable reliability and validity.  \\n  ',\n",
       " 'ai education and inclusion  \\n13 \\n measures of ai learning  \\naird refers to the perce ived level  of comfort in the daily use of various ai \\ntechnologies. students with stronger perception s were more likely to adopt new ai \\napplications in their everyday life. the items were adapted from the studies of chai et \\nal. (2021) and chiu et al. (2021) , with acceptable reliability (α = .89) in similarly aged \\ngroups. the four items were “i prefer to use the most advanced ai technologies ”; “i am \\nconfident that ai technologies will follow my instructions ”; “ai technologies give \\npeople more control over their own lives ”; and “applications and services that use the \\nlatest ai technologies are much more convenient to use.”  \\naicf measures perceived confidence in learning ai content. the items were \\nadapted from the studies of chai et al. (2021) and chiu et al. (2021) , in which they  had \\na reliability of α = .91. the four items were “i am confident that i can succeed if i work \\nhard enough in learning ai ”; “i am certain that i can learn the basic concepts of ai ”; “i \\nam certain that i can understand the most difficult ai resources ”; and “ i am certain that \\ni can design ai applications.”  \\n aiax refers to the perceiv ed anxiety level toward learning ai and was \\nmeasured using items adapted from the study of wang and wang (2019) , in which the  \\nreliability was α = .97. th e items  were “learning to understand all of the special \\nfunctions associated with an ai technique/produ ct makes me anxious ”; “learning to use \\nai techniques/products makes me anxious ”; learning how an ai technique/product \\nworks makes me anxious ”; “learning to interact with an ai technique/product makes \\nme anxious.”  \\naiat measures attitude toward ai. the four items used in this study were \\nadapted from the study of chiu (2017) , in which the reliability was α = .87. the  items \\nwere  “i look forward to using ai in my daily life ”; “i think it would be very wise to use ',\n",
       " 'ai education and inclusion  \\n14 \\n ai in my daily life ”; “i would like to use ai in my learning ”; “i think it would be very \\nwise to use ai in my learning. ” \\naiim was measured by four items adapted from the study of chiu et al. (2021) , \\nin which the  reliability was α = .92. the items were “i enjoy learning ai very much ”; “i \\nfound learning ai fun ”; “i would describe ai learning as very interesting ”; “learning \\nai holds my attention well.”  \\n \\nmeasures of perceived needs support from  teacher s \\nperceived needs support from teacher s measures the student needs satisfaction \\nfor autonomy, relatedness, and competence as facilitated by their teachers  in the \\nprogram . all of the items were adapted from previous studies conducted with british \\nchildren by standage and colleagues (2005) and va lidated for hong kong school \\nstudents by chiu (2021a , 2021b). the four items for perceived autonomy support, with \\nan original reliability of α = . 80, were “when my teacher teach es the program,  i have a \\nsay regarding what skills i want to learn ”; “when my t eacher teaches the program,  i can \\ndecide which activities and tools i want to learn ”; “when my teacher teaches the \\nprogram,  i have some choice in what i want to learn ”; and “ when my teacher teaches \\nthe program,  i feel free to express myself, my opinions, a nd my concerns in ai \\nlearning .” the items for perceived competence support, with an original reliability of α \\n= .84, were “my teacher makes me feel like i am good at learnin g”; “i feel that my \\nteacher likes us to do well ”; “my teacher makes me feel like i am able to do the \\nactivities in clas s”; and “ my teacher makes me feel pretty confident about learning ai. ” \\nthe items for perceived relatedness support, with an original reliability of α = .8 7, were \\n“when learning in the ai program, i feel supported ”; “when learning in the ai ',\n",
       " 'ai education and inclusion  \\n15 \\n program, i feel close”; “when learning in the ai program, i feel valued”; and “when \\nlearning in the ai program, i feel it is relevant  to me .” \\n \\nanaly tical approach and descriptive statistics  \\nto answer rq1, a nalyses of covariance (ancova s) were conducted to assess \\nthe differences between groups in post -program  mean  scores  after accounting for pre -\\nprogram learning scores; to answer rq2, analyses of variance ( anovas ) were \\nconducted to compare needs satisfaction; to answer rq3, paired t-tests were performed \\nto analyze differences between pre - and post -program  scores . table 1 presents the \\ndescriptive statistics for all variables . all variables met the assumption of homogeneity \\nof variance, with levene’s test returni ng p > .05 for all analyses.  \\nto answer rq1, w ith regard to aird, the results of univariate ancovas \\nshowed that  there was a significant main effect of needs support  from teacher s, f(1,12 3) \\n= 23.51, p < .001 , partial \\uf0682 = .16, a significant main effect of gender , f(1, 123) = \\n19.73, p < .001, partial \\uf0682 = .14, and a significant interaction effect, f(1, 123) = 12.45 , p \\n= .001, partial \\uf0682 = .09. the results of f ollow -up analyses indicated  no simple effect for \\nthe sdt -based group, f(1, 61) = .47, p = .50, partial \\uf0682 = .01, a significant simple effect \\nfor the  control  group that boys learned better than girls , f(1, 61) = 26.27 , p < .001 , \\npartial \\uf0682 = .30, no simple effect for boys , f(1, 61) = .61, p = .44 , partial \\uf0682 = .01, and  a \\nsignificant simple effect that girls with sdt -based support learned better than those \\nwithout, f(1, 61) = 19.60 , p < .001 , partial \\uf0682 = .45. \\nthe analyses also revealed that for aicf, there was a significant main effect of \\nneeds support from teacher s, f(1,123) = 20.63 , p < .001 , partial \\uf0682 = .14, a significant \\nmain effect of gender, f(1, 123) = 1 5.24, p < .001, partial \\uf0682 = .11, and a significant \\ninteraction effect, f(1,123) = 7.28, p = .008, partial \\uf0682 = .06. the results of f ollow -up ',\n",
       " 'ai education and inclusion  \\n16 \\n analyses indicated no simple effect for the sdt -based group, f(1, 61) = 1.14, p = .29, \\npartial \\uf0682 = .02, a significant simple effect for the contr ol group that boys learned better \\nthan girls, f(1, 61) = 17.15 , p < .001, partial \\uf0682 = .22, no simple effect for boys, f(1, \\n61) = 1.34, p = .25, partial \\uf0682 = .02, and  a significant simple effect that girls with sdt -\\nbased support learned better than those without, f(1, 61) = 32.27 , p < .001, partial \\uf0682 = \\n.35. \\nwith regard to aiat, the analyses revealed a significant main effect of needs \\nsupport from teacher s, f(1,123) = 23.84, p < .001, partial \\uf0682 = .16, a significant main \\neffect of gender, f(1, 123) = 13.35, p < .001, partial \\uf0682 = .10, and a significant \\ninteraction effect, f(1,123) = 5.72, p = .01, partial \\uf0682 = .04. the results of f ollow -up \\nanalyses indicated no simple effect fo r the sdt -based group, f(1, 61) = .90, p = .35, \\npartial \\uf0682 = .01, a significant simple effect for the control group that boys learned better \\nthan girls, f(1, 61) = 1 4.70, p < .001, partial \\uf0682 = .19, no simple effect for boys, f(1, \\n61) = 2.81, p = .10, partial \\uf0682 = .04, and  a significant simple effect that girls with sdt -\\nbased support learned better than those without, f(1, 61) = 3 4.42, p < .001, partial \\uf0682 = \\n.36. \\nwith regard to aiax, the analyses revealed a significant main effect of needs \\nsupport fro m teacher s, f(1,123) = 4.61, p =.03, partial \\uf0682 = .04, a significant main effect \\nfor gender, f(1, 123) = 20.39 , p < .001, partial \\uf0682 =0.14, and a significant interaction \\neffect, f(1,123) = 6.76, p = .01, partial \\uf0682 = .05. the results of f ollow -up analyses \\nindicated  no simple effect for the sdt -based group, f(1, 61) = 2.03, p = .16, partial \\uf0682 \\n= .03, a significant simple effect for the control group that boys learned better than girls, \\nf(1, 61) = 22.81, p < .001, partial \\uf0682 = .27, no simple effec t for boys, f(1, 61) = .09, p = ',\n",
       " 'ai education and inclusion  \\n17 \\n .77, partial \\uf0682 = .001 , and  a significant simple effect that girls with sdt -based support \\nlearned better than those without, f(1, 61) = 9.61, p = .003, partial \\uf0682 = .14.  \\nwith regard to aiim, the analyses revealed a significant main effect of needs \\nsupport from teacher s, f(1,123) = 26.00 , p < .001 , partial \\uf0682 = .17, a significant main \\neffect of gender, f(1, 123) = 19.29, p < .001, partial \\uf0682 =0.14, and a significant \\ninteraction effect, f(1,123) = 7.54, p = .007, partial \\uf0682 = .06. the results of f ollow -up \\nanalyses indicate d no simple effect for the sdt -based group, f(1, 61) = 1.98, p = .16, \\npartial \\uf0682 = .03, a significant simple effect for the contr ol group that boys learned better \\nthan girls, f(1, 61) = 19.31, p < .001, partial \\uf0682 = .24, no simple effect for boys, f(1, \\n61) = 2.17, p = .15, partial \\uf0682 = .03, and a significant simple effect that girls with sdt -\\nbased support learned better than those without, f(1, 61) = 34.19 , p < .001, partial \\uf0682 = \\n.36. \\nto answer rq2, with regard to perceived needs satisfaction, the analyses \\nrevealed that there was a significant main effect of support for autonom y, f(1,124) = \\n74.78, p < .001, partial \\uf0682 = .38, competence, f(1,124) = 74.30, p < .001, partial \\uf0682 = \\n.38, and relatedness f(1,124) = 50.12, p < .001, partial \\uf0682 = .29. a significant main \\neffect was found for gender in autonomy, f(1,124) = 10.70, p = .001, partial \\uf0682 = .08, \\ncompetence, f(1,124) = 6.33, p = .01, partial \\uf0682 = .05, and relatedness, f(1,124) = 6.69, \\np = .01, partial \\uf0682 = .05. no significant interactio n effect was found for autonomy, \\nf(1,124) = .77, p = .38, partial \\uf0682 = .01, competence, f(1,124) = 2.47, p = .12, partial \\uf0682 \\n= .02, or relatedness, f(1,124) = .292, p = .59, partial \\uf0682 = .02. the results of f ollow -up \\nanalyses showed that the sdt -based grou p perceived greater autonomy, competence, \\nand relatedness than the control group , f(1,12 7) = 69.56, p < .001, f(1,12 7) = 70.50, p \\n< .001, and f(1, 12 7) = 48.21, p < .001, respectively. the analyses also showed that ',\n",
       " 'ai education and inclusion  \\n18 \\n boys perceived greater autonomy, competence, and relatedness than girls , f(1,12 7) = \\n6.75, p = .01, f(1, 12 7) = 3.98, p = .04, and f(1,12 7) = 4.83, p = .03, respectively.  \\nto answer rq3, the analyses reve aled that boys and girls in the sdt -based \\ngroup improved in readiness (boys: t(31) = 8.82, p < .001; girl s: t(31) = 5.71, p < .001), \\nconfidence (boys: t(31) = 6.94, p < .001; girl s: t(31) = 5.79, p < .001), attitude (boys: \\nt(31) = 8.85, p < .001; girl s: t(31) = 6.18, p < .001), and intrinsic motivation to learn ai \\n(boys: t(31) = 8.53, p < .001; girls: t(31) = 8.00, p < .001), and reduced their anxiety \\n(boys: t(31) = 3.00, p = .005; girl s: t(31) = 2.86, p < .001) .  \\nit can be concluded , see table 2, that the sdt -based program did not result in \\nsignificant differences between boys and girls across the measures of  ai learning and \\nperformed significantly better in satisfying the three needs (rq2). r egardless of gender, \\nthe sdt -based program significantly e nhanced students’ perceived ai learning : aird, \\naicf, aiat, aiax, and aiim (rq3) . \\n \\nstudy 2  \\nmethod  \\nparticipants and research procedure  \\nstudy 2 adopted the same research design as study 1, with the  same ai \\nprogram and questionnaire , but with different student participants.  for study 2, \\nthe participants were 127 grade 9 students from three schools , of which  64 were  \\nhigh achievers in coding and 63 were low achievers . the mean age was 14.5 \\nyears. the s tudent participants were given a coding (scratch) pre -task in volving  \\nthe concept s of selection and iteration to complete  in 30 minutes . those who \\ncompleted the task without errors were consider ed high achiever s. following this ',\n",
       " 'ai education and inclusion  \\n19 \\n pre-task, there were  32 high and 32 low achievers in the sdt -based group, and 32 \\nhigh and 31 low achievers in the control group.  \\n \\nresults  \\ntable 3 presents the descriptive statistics for all variables. a ll variables met the \\nassumption of homogeneity of variance, with levene’s  test returning p > .05 for all \\nanalyses.  \\nto answer rq1, with regard to aird, the analyses  showed that there was a \\nsignificant main effect of needs support from teacher s, f(1,12 2) = 12.54 , p = .001, \\npartial \\uf0682 = .09, a significant main effect of achievement , f(1, 12 2) = 27.43 , p < .001, \\npartial \\uf0682 = .18, and a significant interaction effect, f(1, 12 2) = 15.81 , p < .001, partial \\n\\uf0682 = .12. the results of f ollow -up analyses indicated  no simple effect for the sdt -based \\ngroup, f(1, 61) = 3.11, p = .08, partial \\uf0682 = .05, a significant simple effect in the control \\ngroup that high achievers learned better than low achievers , f(1, 60) = 2 9.55, p < .001, \\npartial \\uf0682 = .33, no simple effect for high achievers , f(1, 61) = . 07, p = .80, partial \\uf0682 = \\n.001, and a significant simple effect that low achievers  with sdt -based support learned \\nbetter than those without, f(1, 60) = 25.88 , p < .001, partial \\uf0682 = .30. \\nwith regard to aicf, the analyses  showed that there was a significant main \\neffect of needs support from teacher s, f(1,12 2) = 1 0.75, p = .001, partial \\uf0682 = .08, a \\nsignificant main effect of achievement , f(1, 122) = 2 8.60, p < .001, partial \\uf0682 = .20, and \\na significant interaction effect, f(1, 122) = 1 6.54, p < .001, partial \\uf0682 = .12. the results \\nof follow -up analyses indicated  no simple effect for the sdt -based group, f(1, 61) = \\n1.39, p = .24, partial \\uf0682 = .02, a significant simple effect in the control group that high \\nachievers learned better than low achievers, f(1, 60) = 44.97 , p < .001, partial \\uf0682 = .43, ',\n",
       " 'ai education and inclusion  \\n20 \\n no simple effect for high achievers, f(1, 61) = . 31, p = .58, partial \\uf0682 = .01, and a \\nsignificant simple effect that low achievers with sdt -based support learned better than \\nthose without, f(1, 60) = 2 8.35, p < .001, partial \\uf0682 = .32. \\nwith regard to aiat, the analyses revealed that there was a significant main \\neffect of needs support from teacher s, f(1,122) = 1 1.97, p = .001, partial \\uf0682 = .09, a \\nsignificant main effect of achievement , f(1, 122) = 2 9.25, p < .001, partial \\uf0682 = .19, and \\na significant interaction effect, f(1, 122) = 1 6.97, p < .001, partial \\uf0682 = .12. the results \\nof follow -up analyses indicated  no simple e ffect for the sdt -based group, f(1, 61) = \\n2.99, p = .09, partial \\uf0682 = .05, a significant simple effect in the control group that high \\nachievers learned better than low achievers, f(1, 60) = 36.26 , p < .001, partial \\uf0682 = .38, \\nno simple effect for high achievers, f(1, 61) = . 30, p = .59, partial \\uf0682 = .01, and a \\nsignificant simple effect that low achievers with sdt -based support learned better than \\nthose without, f(1, 60) = 2 6.40, p < .001, partial \\uf0682 = .31. \\nwith regard to aiax , the analyses revealed that there was a significant main \\neffect of needs support from teacher s, f(1,122) = 3.89, p = .05, partial \\uf0682 = .03, a \\nsignificant main effect of achievement , f(1, 122) = 36.12 , p < .001, partial \\uf0682 = .23, and \\na significant interaction effect, f(1, 122) = 20.98 , p < .001, partial \\uf0682 = .15. the results \\nof follow -up analyses indicated  no simple effect for the sdt -based group, f(1, 61) = \\n1.99,  p = .16, partial \\uf0682 = .03, a significant simple effect in the cont rol group that high \\nachievers learned better than low achievers, f(1, 60) = 36.26 , p < .001, partial \\uf0682 = .38, \\nno simple effect for high achievers, f(1, 61) = 4.04, p = .05, partial \\uf0682 = .06, and a \\nsignificant simple effect that low achievers with sdt -based support learned better than \\nthose without, f(1, 60) = 17.71 , p < .001, partial \\uf0682 = .23. ',\n",
       " 'ai education and inclusion  \\n21 \\n with regard to aiim, the analyses revealed that there was a significant main \\neffect of needs suppor t from teacher s, f(1,122) = 1 6.99, p < .001, partial \\uf0682 = .12, a \\nsignificant main effect of achievement , f(1, 122) = 2 6.63, p < .001, partial \\uf0682 = .18, and \\na significant interaction effect, f(1, 122) = 27.06 , p < .001, partial \\uf0682 = .18. the results \\nof follow -up analyses indicated  no simple effect for the sdt -based group, f(1, 61) = \\n.13, p = .72, partial \\uf0682 = .002, a significant simple effect in the control group that high \\nachievers learned better than low achievers, f(1, 60) = 47.13 , p < .001, partial \\uf0682 = .44, \\nno simple effect for high achievers, f(1, 61) = . 89, p = .35, partial \\uf0682 = .01, and a \\nsignificant simple effect that low achievers with sdt -based support learned better than \\nthose without, f(1, 60) = 39.20 , p < .001, partial \\uf0682 = .40. \\nto answer rq2, with regard to perceived needs satisfaction, the analyses \\nrevealed that there was a significant main effect of support for autonomy, f(1,123) = \\n56.58, p < .001, partial \\uf0682 = .32, competence, f(1,123) = 78.22, p < .001, partial \\uf0682 = \\n.38, and relatedness f(1,123) = 38.18, p < .001, partial \\uf0682 = .33. a significant main \\neffect was found for achievement in autonomy, f(1,123) = 11.77, p = .001, partial \\uf0682 = \\n.09, competence, f(1,123) = 15.04, p < .001, partial \\uf0682 = .11, and relatedness, f(1,123) \\n= 59.93, p < .001, partial \\uf0682 = .10. no significant interaction effect was found in \\nautonomy, f(1,123) = 2.47, p = .12, partial \\uf0682 = .02, competence, f(1,123) = 3.49, p = \\n.06, partial \\uf0682 = .03, or relatedness, f(1,123) = . 09, p = .77, partial \\uf0682 = .001. the \\nresults of f ollow -up analyses showed that the sdt -based group perceived greater \\nautonomy, competence, and relatedness than the control group ,  f(1,126) = 51.04, p < \\n.001, f(1,126) = 68.43, p < .001, and f(1, 126) = 54.62 , p < .001, respectively. the \\nanalyses also showed that high achievers perceived greater autonomy, competence, and ',\n",
       " 'ai education and inclusion  \\n22 \\n relatedness than low achievers , f(1,126) = 7.75, p = .006, f(1, 126) = 8.80, p = .004, \\nand f(1,126) = 8.57, p = .004, respectively.  \\nto answer rq3, the analyses revealed that the high and low achievers in the \\nsdt -based group improved their ai  readiness ( high: t(31) = 3.85, p = .001; low: t(31) = \\n8.00, p < .001), confidence ( high: t(31) = 2.90, p = .007; low: t(31) = 7.38, p < .001), \\nattitude ( high: t(31) = 2.80, p = .009; low: t(31) = 6. 56, p < .001), and intrinsic \\nmotivation to learn ai ( high: t(31) = 4.46, p < .001; low: t(31) = 8. 40, p < .001). low \\nachievers , but not high achievers , also eased their ai  anxiety  (high: t(31) = 1.68, p \\n= .103; low: t(31) = 25.40, p < .001),  \\nto summari ze the results of study 2 , see table, 4, the sdt -based program did \\nnot create significant differences between high and low achievers on ai learning (rq1), \\nand performed significantly better in satisfying the three needs (rq2). r egardless of \\ntheir achievement  level , the sdt -based program significa ntly enhanced students’ \\nperceived ai learning , with improvements in  aird, aicf, aiat, and aiim (rq3) . \\nlow achievers also felt less anxious about ai. \\n \\n \\ndiscussion  \\nthis project aimed to create a high-quality ai program for k –12. the two \\nstudies examine d whether an ai program  designed with a needs satisfaction approach \\nwould enhance student ai learning, and whether it  would have the same effects on (1) \\ngirls and boys and (2) high and low achieving students. the result s have  three  major  \\nempirical  implications  and make  two theoretical  contributions . three practical  \\nsuggestions  are also offered . \\n ',\n",
       " 'ai education and inclusion  \\n23 \\n empirical implications  \\nthe first  empirical implication  is that the proposed needs support strategies \\nsatisfied the  students’ three sdt needs  better than normal teaching approaches  (see \\nrq2 in both studies ). the strategies used in this project were adopted from the two \\nsdt -based studies of chiu (2021 b, 2021 c), in which their positive effects were \\nconfirmed in k–12 online and blended learning environments. the present findings  \\nsupport the effectiveness of these strategies for face-to-face classroom teaching . \\ntherefore, the strategies used in the ai program appear to be effective in satisfying \\nstudent needs in the three  teaching scenarios of  face-to-face, online, and blended \\nlearning.   \\nthe second implication is that the sdt -based program improve d student \\nperceived ai learning for both boys and girls , and both high and low achievers, with the \\nonly except ion being  the ai anxiety of high achievers ( see rq3 in both studies ). these \\nfindings confirm that satisfying needs can better engage students in learning ai , which \\nare consistent with most sdt -based studies ( chiu , 2021 b, 2021 c; skinner et al., 2008; \\nvollet et al., 2017 ). according to sdt, w hen all three innate  needs are met, students \\nincreasingly internalize their motivation until they are driven by something intrinsic to \\nthe activity (ryan & deci, 2020). their motivational ori entation can move through a \\ncontinuum , from amotivation to extrinsic motivation to intrinsic motivation . intrinsic  \\nmotivation  acts as a fuel that can better engage students in ai learning. accordingly, \\nwhen teachers can satisfy the need s for autonomy, comp etence, and relatedness in ai \\nteaching , boys and girls , and high and low achievers with any motivation orientation are \\nmore likely to be engaged in learning .  \\nthe third implication is that the sdt -based program was of equal benefit  to girls \\nand boys  and to high and low achieving students at  fostering perceived ai learning, ',\n",
       " 'ai education and inclusion  \\n24 \\n whereas the  program  adopting standard teaching approaches  benefited (i) boys more \\nthan girls and (ii) high more than low achievers  (see rq1 in both studies ). these results  \\nalign with those of studies of learner expertise (e.g., chiu & mok , 2017 ; chiu & lim, \\n2020 ; chiu et al.,  2020 ; leslie et al., 2012; rey & fischer, 2013 ). these studies \\nsuggested that aspects of learning environments , such as materials and teacher –student \\ninteractions , should be designed for student s at different levels of expertise : that is , one \\ndesign does not fit all . a plausible explanation for our finding, therefore, is that an \\ninstructional design  that benefits highly motivated students may be detrimental for less \\nmotivated students  (kalyuga, 2007) . providing n eeds support allowed the students  to \\ndesign their preferred learning path, process , and outcomes.  supporting the need for \\ncompetence provides  less irrelevant information that does not fit the ir academic ability ; \\nsupporting the need for relatedness make s problems more relevant and teacher –student \\ninteraction s more welcoming;  and supporting autonomy has positive effects on support \\nfor competence and relatedness because  the three needs interact  according to sdt  \\n(chiu, 2021b, 2021c; skinner et al., 2008; vollet et al., 2017) . hence , sdt -based \\nteaching encourages  students to create an ai learning  process  that fits their need s and \\nthus generates greater engagement in ai learning .  \\nas an engineering topic,  ai is typically perceived as a subject for boys and high \\nachievers, which reduces the motivation of  girls and students w ho are  weaker in coding  \\n(delaine et al., 2016; ibe et al., 2018) . therefore, a nother  plausible explanation  is that  \\nthe standard teaching  approach  (business as usual) did not challenge this  perception . \\nthe female students and low achievers might have been demotiv ated before th eir ai \\nlearning began , might have felt incompetent in the subject, and might have regarded  ai \\nlearning as irrelevant. therefore, they failed to move through the continuum of \\nmotivation for greater  engagement  (ryan & deci, 2020) . moreover, th is could be ',\n",
       " 'ai education and inclusion  \\n25 \\n explained by the first implication : that the students in the sdt -based program perceived \\nstronger autonomy, competence , and relatedness . girls and low achievers had their \\nneeds supported in the sdt -based  program , but not in the program  delivered with a \\nstandard teaching approach . in the sdt -based program , the needs satisfaction levels  of \\nthese underrepresented students  were the same as those of the boys and high achievers . \\nit appears that the sdt -based program enables all students to internalize their learning \\nexperience for  high-quality motivation, and then find their learning joy ful and relevant , \\ngain a sense of  competen ce, and own the ir own  learning.  \\n \\ntheoretical contributions  \\nthe first and second empirical implications described above  contribute to sdt \\nby presenting more evidence of how needs support from teacher s relates to inclusive \\nand diverse engineering education  in the k–12 setting . most  related studies of k–12 \\neducation have used the three needs to explain the motivation and engagement of \\nstudents of different gender s, achievement  levels,  and cultur es (chiu & mok, 2017; \\nchiu & lim, 2020; standage et al., 2005;  lietaert et al., 2015; roorda et al., 2011) . \\nfurthermore, m ost studies have been conducted in non -engineering domain s, such as \\nphysical education.  for example, boys, western students , and high achievers expect \\nmore autonomy support than girls; and girls, eastern students , and low achievers prefer \\nmore relatedness support  (iyengar & lepper, 1999; ryan & deci, 2020) . the results of \\nthis project confirmed the effectiveness of its  proposed student needs support from \\nteacher strategies to promote inclusive and diverse education in the discipline of \\nengineering, which features serious inequit ies. in other words, this project suggests that \\nsdt can promote well -being in all students, r egardless of their gender and achievement  \\nlevel , in engineering education.  ',\n",
       " 'ai education and inclusion  \\n26 \\n second, this project is built on the corresponding  author’s research into learner \\nexpertise (e.g.,  chiu & mok , 2017 ; chiu & lim, 2020 ; chiu et al.,  2020) . hence, the \\nfindings of this project theoretical ly contribute  to research related to learner expertise  \\nand motivation , such as the kalyuga expertise reversal effe ct (kalyuga, 2007) . these \\nstudies showed that one design does not fit all. for example, well -structured materials, \\nemotional designs , and specific guidance should benefit low achievers but not high \\nachievers. most of these studies looked at diversity issues from the perspective of \\ncognitive science  (i.e., competence in sdt) , such as multiple modalities, mayer’s \\nmultimedia learning  (mayer, 2009) , and emotional multimedia designs . for example , an \\ninstructional design tailored for low achievers may be more helpful for high achievers to \\nmaximize cognitive  capacity in less -structured environments. this project took the new \\nand different angle  of psychological needs to study this issue of learner expertise , with \\nthe findings suggest ing the importance of supporting motivation in students by \\nproviding needs su pport for students with different expertise ( represented by gender and \\nachievement in this project). this suggests that to cater to learner expertise  in building \\nengagement , support ing the  needs for autonomy and relatedness is just as important as \\nsupporting the need for competence, particularly in engineering education.  \\n \\npractical suggestions  \\nthis study offers ai (and general engineering) curriculum coordinators and  \\nteachers three practical suggestions for providing high -quality engineering education.  \\nthe first practical suggestion is to provide teachers with professional development \\ntraining  on supporting student needs. trained teachers will have a better understand ing \\nof their motivational behaviors  (chiu & churchill, 2016 ; chiu et al., 2021 ). hence, to \\nboost their students ’ energy, they are more likely to design classroom s and online ',\n",
       " 'ai education and inclusion  \\n27 \\n learning environments  that support student needs , to connect with their students , and to \\nmake ai learning more relevant. this energy will then serve as a source of engagement \\nfor students of  ai (chiu et al., 2021) . \\nthe second suggestion is for ai curriculum coordinators to design a flexible and \\nrelevant ai curriculum for k –12. this design will empower ai teachers to tailor a \\nprogram to their own classroom s and students . compare d with higher education, k –12 \\nstudents feature greater  learning diversity  within and across schools , and have less self-\\ndirected learning competenc ies (chiu et al., 2021).  for example, a school may need \\nmore than one ai program for different classes at the same grade  level . flexibly and \\nrelevance are very important for k –12 ai education  because  a rigid ai curriculum wi ll \\ndiscourage teachers from design ing for students with different levels of expertise and \\nexperience.  \\nthe third suggestion is to design ai laboratories that support student  needs . in \\nthese laboratories , a range of ai technologies should be provided for students to choose \\ntheir own learning  approach , effective video s should be available for each of the \\ntechnologies  to allow for  self-learning when students have technical problems, and seats \\nand table s should be arranged in such a way to foster informal conversations between \\nstudents and between students and teachers. this style of  physical learning \\nenvironment, which is common in universit ies (e.g., learning common)  but not common \\nin k–12 schools , will further support student needs.  \\n \\nconclusions  and future research  \\nai teaching is new at the k–12 level . this project suggest s that  a focus on needs \\nsatisfaction could engage boys and girls , and high and low achievers in ai learning. as \\nthey become more engaged, they are likely to gain more confiden ce, feel that the ',\n",
       " \"ai education and inclusion  \\n28 \\n content is more relevant , and become intrinsically motivate d to pursue further ai \\nlearning. this is the type of experiences that teachers need to offer to their students \\nthrough engineering learning activities.  \\nfour  limitations of this project  are noted here. first, while the results appear to \\nsupport the effects of needs satisfaction  on student ai learning , more studies are needed \\nto validate the findings. the results could be extended by additional studies of more \\nsupport strategies and other engineering domains , such as computational thinking  \\n(moore et al., 2014) . second, qualitative stud ies would be usef ul to further explor e \\nneeds  support strategies for engineering education. third, this project  did not consider \\nhow teachers design their own ai program s. future research could investigate how \\nteachers design their own programs and how to develop teacher s’ capacities  to address \\ninclusion and diversity  in their curriculum designs  (chiu & churchill, 2016) . fourth,  the \\nprogram analyzed in this project was conducted  during the summer  break  in the period \\naffected by the covid -19 pandemic , and its full effects may therefore not be revealed  \\nin the results.  future studies could adopt a longitudinal research design  and study \\nprograms offered as part of  regular schooling.  \\n \\n \\nreferences  \\narcher, l., dewitt, j., osborne, j., dillon, j., willis, b., & won g, b. (2010). “doing” \\nscience versus “being” a scientist: examining 10/11‐year‐old schoolchildren's \\nconstructions of science through the lens of identity. science education, 94 (4), \\n617-639. https://doi.org/10.1002/sce.20399  \\nassor, a., kaplan, h., & roth, g. (2002). choice is good, but relevance is excellent: \\nautonomy‐enhancing and suppressing teacher behaviours predicting students' \",\n",
       " 'ai education and inclusion  \\n29 \\n engagement in schoolwork. british journal of educational psychology, 72 (2), \\n261-278. https://do i.org/10.1348/000709902158883  \\nbaillie, c., ko, e., newstetter, w., & radcliffe, d. f. (2011). advancing diverse and \\ninclusive engineering education practices through interdisciplinary research and \\nscholarship. journal of engineering education, 100 (1), 6 -13. \\nhttps://10.1002/j.2168 -9830.2011.tb00002.x  \\nbøe, m. v., henriksen, e. k., lyons, t., & schreiner, c. (2011). participation in \\nscience and technology: young people’s achievement‐related choices in late‐\\nmodern societies. studies in science education, 47 (1), 37-72. \\nhttps://doi.org/10.1080/03057267.2011.549621  \\nchai, c. s., lin, p. y., jong, m. s. y., dai, y., chiu, t. k. f., & qin, j. j. (2021). \\nperceptions of and behavioral intentions towards learning artificial intelligence \\nin primary school students. educat ion technology and society , 24(3), 89 -101. \\nchiu t. k. f. (2021a). a holistic approach to artificial intelligence (ai) curriculum for \\nk-12 schools, techtrends, 65 , 796 -807. http://dx.doi.org/10.1007/s11528 -021-\\n00637 -1 \\nchiu t. k. f. (2021b). applying the sel f-determination theory (sdt) to explain \\nstudent engagement in online learning during the covid -19 pandemic. journal \\nof research on technology in education . \\nhttp://dx.doi.org/10.1080/15391523.2021.1891998  \\nchiu t. k. f. (2021c). digital support for student e ngagement in blended learning \\nbased on self -determination theory. computers in human behavior, 124, \\n106909. http://10.1016/j.chb.2021.106909  ',\n",
       " 'ai education and inclusion  \\n30 \\n chiu t. k. f. (2021d). student engagement in k -12 online learning amid covid -19: a \\nqualitative approach from a self -determination theory perspective. interactive \\nlearning environments . http://dx.doi.org/10.1080/10494820.2021.1926289.  \\nchiu, t. k. f. (2020). six key principles in designing ai curriculum for middle schools. \\nassociation for educational communications and t echnology (aect) \\ninternational convention, november 3 -7, jacksonville, florida. retrieved from \\nhttps://members.aect.org/pdf/proceedings/proceedings20/2020i/20_03.pdf  \\nchiu t. k. f., & chai, c. s. (2020). sustainable curriculum planning for artificial \\nintell igence education: a self -determination theory perspective. sustainability, \\n12(14), 5568; https://doi.org/10.3390/su12145568  \\nchiu, t. k. f., chai, c. s., williams, p. j., & lin, t. -j. (2021). teacher professional \\ndevelopment on self -determination theory –based design thinking in stem \\neducation. educational technology & society, 24 (4), 153 –165 \\nchiu, t. k. f., & churchill, d. (2016). adoption of mobile devices in teaching: \\nchanges in teacher beliefs, attitudes and anxiety. interactive learning \\nenvironments, 24 (2), 317 -327. \\nhttp://dx.doi.org/10.1080/10494820.2015.1113709  \\nchiu, t. k. f., jong, m. s. y., & mok, i. a. c. (2020). does learner expertise matter \\nwhen designing emotional multimedia for learners of primary school \\nmathematics? educational technology resear ch and development, 68 , 2305 –\\n2320. https://doi.org/10.1007/s11423 -020-09775 -4 \\nchiu, t. k. f., & lim, c. p. (2020).  strategic use of technology for inclusive education \\nin hong kong: a content -level perspective, ecnu review of education, 3 (4), \\n715-734. http s://doi.org/10.1177/2096531120930861  ',\n",
       " 'ai education and inclusion  \\n31 \\n chiu t. k. f., meng, h., chai c. s., yeung y., king i., & wong s. (2021). creation \\nand evaluation of a pre -tertiary artificial intelligence (ai) curriculum. ieee \\ntransactions on education . http://dx.doi.org/10.1109/te.2 021.3085878  \\nchiu, t. k. f., & mok, i. a. c. (2017). learner expertise and mathematics different \\norder thinking skills in multimedia learning, computers & education, 107 , 147 -\\n164. http://dx.doi.org/10.1016/j.compedu.2017.01.008  \\ndelaine, d. a., williams, d.  n., sigamoney, r., & tull, r. g. (2016). global diversity \\nand inclusion in engineering education: developing platforms toward global \\nalignment. international journal of engineering pedagogy, 6 (1). \\ndu, k., wang, y., ma, x., luo, z., wang, l., & shi, b. (20 20). achievement goals and \\ncreativity: the mediating role of creative self -efficacy. educational psychology, \\n40(10), 1249 -1269. https://doi.org/10.1080/01443410.2020.1806210  \\ndubow, w. m., quinn, b. a., townsend, g. c., robinson, r., & barr, v. (2016). \\nefforts to make computer science more inclusive of women. acm inroads, 7 (4), \\n74-80. http://dx.doi.org/10.1145/2998500  \\neccles, j. s. (2007). where are all the women? gender differences in participation in \\nphysical science and engineering. in s. j. ceci, & w. m.  williams (eds.), why \\naren’t more women in science? top researchers debate the evidence  (pp. 199 -\\n210). washington, dc: american psychological association. \\nhttp://dx.doi.org/10.1037/11546 -016 \\nheyman, g. d., martyna, b., & bhatia, s. (2002). gender and achievement -related \\nbeliefs among engineering students. journal of women and minorities in \\nscience and engineering, 8 (1), 41 -52 \\nhttps://doi.org/10.1615/jwomenminorscieneng.v8.i1.30  ',\n",
       " 'ai education and inclusion  \\n32 \\n hiemstra, d., &  van yperen, n. w. (2015). the effects of strength -based versus \\ndeficit -based self -regulated learning strategies on students’ effort intentions. \\nmotivation and emotion, 39 (5), 656 -668. https://doi.org/10.1007/s11031 -015-\\n9488 -8. \\nibe, n. a., howsmon, r., pen ney, l., granor, n., delyser, l. a., & wang, k. (2018, \\nfebruary). reflections of a diversity, equity, and inclusion working group based \\non data from a national cs education program. in proceedings of the 49th acm \\ntechnical symposium on computer science edu cation  (pp. 711 -716).  \\niyengar, s. s., & lepper, m. r. (1999). rethinking the value of choice: a cultural \\nperspective on intrinsic motivation. journal of personality and social \\npsychology, 76 (3), 349 –366. \\nkalyuga, s. (2007). expertise reversal effect and it s implications for learner -tailored \\ninstruction. educational psychology review, 19 (4), 509 -539. \\nhttps://doi.org/10.1007/s10648 -007-9054 -3 \\nkatz, i., & assor, a. (2007). when choice motivates and when it does not. educational \\npsychology review, 19 (4), 429 -442. https://doi.org/10.1007/s10648 -006-9027 -y \\nkelly, a. v. (2009). the curriculum: theory and practice (6th ed.). london: sage.  \\nlennert da silva, a. l., & mølstad, c. e. (2020). teacher autonomy and teacher \\nagency: a comparative study in brazilian and norwe gian lower secondary \\neducation. the curriculum journal, 31 (1), 115 -131. \\nhttps://doi.org/10.1002/curj.3  \\nleslie, k. c., low, r., jin, p., & sweller, j. (2012). redundancy and expertise reversal \\neffects when using educational technology to learn primary schoo l science. \\neducational technology research and development, 60 (1), 1 -13. \\nhttps://doi.org/ 10.1007/s11423 -011-9199 -0 ',\n",
       " 'ai education and inclusion  \\n33 \\n lietaert, s., roorda, d., laevers, f., verschueren, k., & de fraine , b. (2015). \\nthe gender gap in student engagement: the role of teachers’ autonomy support, \\nstructure, and involvement. british journal of educational psychology, 85 (4), \\n498-518. https://doi.org/10.1111/bjep.12095.  \\nmayer, r.e. (2009). multimedia learning . new york, ny: cambridge press.  \\nmoore, t. j., glancy, a. w., tank, k. m., kersten, j. a., smith, k. a., & stohlmann, \\nm. s. (2014). a framework for quality k -12 engineering education: research \\nand development. journal of pre -college engineering education rese arch (j -\\npeer), 4 (1), article 2. https://doi.org/10.7771/2157 -9288.1069  \\npapert, s., & solomon, c.(1971). twenty things to do with a computer. in studying the \\nnovice programmer (pp. 3 -28). lawrence erlbaum associates, inc..  \\npedró, f., subosa, m., rivas, a., & valverde, p. (2019). artificial intelligence in \\neducation: challenges and opportunities for sustainable development. paris: \\nunesco.  \\nprince, e. j., & hadwin, j. (2013). the role of a sense of school belonging in \\nunderstanding the effectiveness of inclusio n of children with special educational \\nneeds. international journal of inclusive education, 17 (3), 238 -262. \\nhttps://doi.org/10.1080/13603116.2012.676081  \\nrey, g. d., & fischer, a. (2013). the expertise reversal effect concerning instructional \\nexplanations. instructional science, 41 (2), 407 -429. \\nhttps://doi.org/10.1007/s11251 -012-9237 -2 \\nroorda, d.l., koomen, h.m., spilt, j.l., & oort, f.j. (2011). the influence of affective \\nteacher –student relationships on students’ school engagement and achievement: \\na meta -analytic approach. review of educational research, 81 (4), 493 -529. \\nhttps://doi.org/10.3102/0034654311421793  ',\n",
       " \"ai education and inclusion  \\n34 \\n ryan, r.m., & deci, e.l. (2017). self-determination theory: basic psychological needs \\nin motivation development and wellness.  new york, ny: guilford press.  \\nryan, r. m., & deci, e. l. (2020). intrinsic and extrinsic motivation from a self -\\ndetermination theory perspective: definitions, theory, practices, and future \\ndirections. contemporary educational psychology, 61 , 101860. \\nhttps://doi.org/10.1016/j.ced psych.2020.101860  \\nroehrig, g. h., moore, t. j., wang, h. h., & park, m. s. (2012). is adding the e \\nenough? investigating the impact of k‐12 engineering standards on the \\nimplementation of stem integration. school science and mathematics, 112 (1), \\n31-44. http s://doi.org/10.1111/j.1949 -8594.2011.00112.x  \\nruzek, e.a., hafen, c.a., allen, j. p., gregory, a., mikami, a.y., & pianta, r.c. \\n(2016). how teacher emotional support motivates students: the mediating roles \\nof perceived peer relatedness, autonomy support, an d competence. learning and \\ninstruction, 42 , 95-103. https://doi.org/10.1016/j.learninstruc.2016.01.004  \\nschneider, s., nebel, s., beege, m., & rey, g. d. (2018). the autonomy -enhancing \\neffects of choice on cognitive load, motivation and learning with digita l media. \\nlearning and instruction, 58 , 161 -172. \\nhttps://doi.org/10.1016/j.learninstruc.2018.06.006.  \\nsierens, e., vansteenkiste, m., goossens, l., soenens, b., & dochy, f. (2009). the \\nsynergistic relationship of perceived autonomy support and structure in t he \\nprediction of self‐regulated learning. british journal of educational psychology, \\n79(1), 57 -68. https://doi.org/10.1348/000709908x304398.  \\nskinner, e. a., kindermann, t. a., & furrer, c. j. (2008). a motivational perspective \\non engagement and disaffectio n: conceptualization and assessment of children's \\nbehavioral and emotional participation in academic activities in the classroom. \",\n",
       " 'ai education and inclusion  \\n35 \\n educational and psychological measurement, 69 (3), 493 -525. \\nhttps://doi.org/10.1177/0013164408323233  \\nstabback, p. (2016). what makes a quality curriculum?  in-progress reflection no. 2. \\ncurrent and critical issues in curriculum and learning series. \\nibe/2016/wp/cd/02. geneva: unesco international bureau of education \\n(ibe). retrieved january 01, 2020 from \\nhttps://unesdoc.unesco.org/a rk:/48223/pf0000243975.  \\nstandage, m., duda, j.l., & ntoumanis, n. (2005). a test of self‐determination theory \\nin school physical education. british journal of educational psychology, 75 (3), \\n411-433. https://doi.org/10.1348/000709904x22359  \\nsensetime (2018, novemeber 1). fundamentals of artificial intelligence. east china \\nnormal university. retrieved from \\nhttps://www.sensetime.com/en/service/ai_class.html  \\ntouretzky, d., gardner -mccune, c., breazeal, c., martin, f., & seehorn, d. (2019). a \\nyear in k -12 ai education. ai magazine, 40 (4), 88 -90. \\nhttps://doi.org/10.1609/aimag.v40i4.5289.  \\nvollet, j.w., kindermann, t.a., & skinner, e.a. (2017). in peer matters, te achers \\nmatter: peer group influences on students’ engagement depend on teacher \\ninvolvement. journal of educational psychology, 109 (5), 635 -652. \\nhttps://doi.org/10.1037/edu0000172  \\nwang, y. y., & wang, y. s. (2019). development and validation of an artificia l \\nintelligence anxiety scale: an initial application in predicting motivated learning \\nbehavior. interactive learning environments . \\nhttps://doi.org/10.1080/10494820.2019.1674887  ',\n",
       " \"ai education and inclusion  \\n36 \\n williams, r., park, h. w., & breazeal, c. (2019, may 4 -9). a is for artificial \\nintelligence: the impact of artificial intelligence activities on young \\nchildren's perceptions of robots. in the proceedings of the 2019 chi \\nconference on human factors in computing systems, (pp. 1 -11). glasgow, \\nscotland.  \\n  \",\n",
       " 'ai education and inclusion  \\n37 \\n  \\nfigure 1. curriculum framework for k -12 ai, adapted from chiu (2021a)  \\n \\n  \\n',\n",
       " 'ai education and inclusion  \\n38 \\n table 1. descriptive statistics for pre - and post -questionnaires in study 1.  \\n  pre-\\nquestionnaire  post-\\nquestionnaire  \\ngroup  variable  mean  sd mean  sd \\nsdt -based \\nand \\nboys  \\n(n = 32)  ai readiness (aird)  3.51 .75 4.30 .72 \\nai confidence (aicf)  3.56 .78 4.45 .75 \\nai attitude (aiat)  3.69 .81 4.51 .75 \\n ai anxiety (aiax)  2.30 .81 1.80 .82 \\n intrinsic motivation to learn ai \\n(aiim)  3.57 .75 4.48 .75 \\n perceived autonomy  - - 4.34 .47 \\n perceived competence  - - 4.26 .52 \\n perceived relatedness  - - 4.30 .54 \\nsdt -based \\nand \\ngirls  \\n(n = 32)  ai readiness (aird)  2.85 .88 3.78 .85 \\nai confidence (aicf)  2.83 1.11 3.73 .99 \\nai attitude (aiat)  3.02 1.02 3.85 1.04 \\nai anxiety (aiax)  3.01 .99 2.47 1.09 \\n intrinsic motivation to learn ai \\n(aiim)  3.06 1.03 3.88 1.02 \\n perceived autonomy  - - 4.05 .58 \\n perceived competence  - - 4.14 .64 \\n perceived relatedness  - - 4.02 .69 \\ncontrol and  \\nboys  \\n(n = 32)  ai readiness (aird)  3.59 .77 4.17 .68 \\nai confidence (aicf)  3.77 .75 4.27 .72 \\nai attitude (aiat)  3.77 .80 4.23 .71 \\nai anxiety (aiax)  2.36 .97 1.76 .76 \\n intrinsic motivation to learn ai \\n(aiim)  3.70 .73 4.30 .73 \\n perceived autonomy  - - 3.40 .96 \\n perceived competence  - - 3.38 .98 \\n perceived relatedness  - - 3.40 1.11 \\ncontrol and  \\ngirls  \\n(n = 32)  ai readiness (aird)  2.85 .88 2.72 1.04 \\nai confidence (aicf)  2.83 1.11 2.80 1.15 \\nai attitude (aiat)  3.02 1.02 2.93 1.20 \\nai anxiety (aiax)  3.01 1.00 3.24 1.27 \\n intrinsic motivation to learn ai \\n(aiim)  2.72 1.03 2.96 1.19 \\n perceived autonomy  - - 2.90 .61 \\n perceived competence  - - 2.88 .58 \\n perceived relatedness  - - 2.98 .65 \\n \\n  ',\n",
       " 'ai education and inclusion  \\n39 \\n table 2. summary of the results of study 1.  \\nrq1 (ancova)  \\nvariable  interaction effect  sdt -based  control  \\nai readiness (aird)  significant  insignificant1 significant2 \\nai confidence (aicf)  significant  insignificant1 significant2 \\nai attitude (aiat)  significant  insignificant1 significant2 \\nai anxiety (aiax)  significant  insignificant1 significant2 \\nintrinsic motivation to \\nlearn ai (aiim)  significant  insignificant1 significant2 \\nrq2 (anova)   group  gender \\nperceived autonomy  insignificant  significant3 significant4 \\nperceived competence  insignificant  significant3 significant4 \\nperceived relatedness  insignificant  significant3 significant4 \\nrq3 (pair t -tests)  sdt -based (boys)  sdt -based (girls)   \\nai readiness (aird)  significant5 significant6  \\nai confidence (aicf)  significant5 significant6  \\nai attitude (aiat)  significant5 significant6  \\nai anxiety (aiax)  significant5 significant6  \\nintrinsic motivation to \\nlearn ai (aiim)  significant5 significant6  \\nnote: insignificant1 – no significant difference between boys and girls; significant2 – \\nsignificant difference between boys and girls; significant3 – significant difference \\nbetween the sdt -based and control groups; significant4 – significant difference between \\nboys and girls;  significant5 – significant difference between pre - and post - questionnaires \\nfor boys; significant6 – significant difference between pre - and post - questionnaires for \\ngirls.  \\n \\n  ',\n",
       " 'ai education and inclusion  \\n40 \\n table 3. descriptive statistics for pre - and post -questionnaires in study 2.  \\n  pre-\\nquestionnaire  post-\\nquestionnaire  \\ngroup  variable  mean  sd mean  sd \\nsdt -based \\nand low \\nachievers  \\n(n = 32)  ai readiness (aird)  2.45 .84 3.45 .72 \\nai confidence (aicf)  2.51 .95 3.45 .95 \\nai attitude (aiat)  2.51 .73 3.47 .85 \\n ai anxiety (aiax)  3.56 .99 2.60 .92 \\n intrinsic motivation to learn ai \\n(aiim)  2.81 .91 3.84 .87 \\n perceived autonomy  - - 4.06 .85 \\n perceived competence  - - 4.12 .66 \\n perceived relatedness  - - 3.95 .70 \\nsdt -based \\nand high  \\nachievers  \\n(n = 32)  ai readiness (aird)  3.72 .70 4.30 .67 \\nai confidence (aicf)  3.80 .75 4.33 .74 \\nai attitude (aiat)  3.80 .78 4.30 .73 \\nai anxiety (aiax)  2.18 .81 1.88 .64 \\n intrinsic motivation to learn ai \\n(aiim)  3.60 .75 4.30 .68 \\n perceived autonomy  - - 4.34 .74 \\n perceived competence  - - 4.38 .59 \\n perceived relatedness  - - 4.42 .62 \\ncontrol and \\nlow \\nachievers   \\n(n = 31)  ai readiness (aird)  2.48 .84 2.55 .95 \\nai confidence (aicf)  2.46 .98 2.49 .85 \\nai attitude (aiat)  2.46 .76 2.46 .88 \\nai anxiety (aiax)  3.44 .99 3.47 .97 \\n intrinsic motivation to learn ai \\n(aiim)  2.65 .97 2.68 .87 \\n perceived autonomy  - - 2.73 .84 \\n perceived competence  - - 2.70 .85 \\n perceived relatedness  - - 2.81 .91 \\ncontrol and \\nhigh \\nachievers   \\n(n = 32)  ai readiness (aird)  3.65 .72 4.33 .64 \\nai confidence (aicf)  3.79 .74 4.42 .61 \\nai attitude (aiat)  3.82 .78 4.39 .61 \\nai anxiety (aiax)  2.38 .95 1.57 .65 \\n intrinsic motivation to learn ai \\n(aiim)  3.70 .73 4.47 .60 \\n perceived autonomy  - - 3.46 .88 \\n perceived competence  - - 3.46 .85 \\n perceived relatedness  - - 3.37 .92 \\n \\n  ',\n",
       " 'ai education and inclusion  \\n41 \\n table 4. summary of the results of study 2.  \\nrq1 (ancova)  \\nvariable  interaction effect  sdt -based  control  \\nai readiness (aird)  significant  insignificant1 significant2 \\nai confidence (aicf)  significant  insignificant1 significant2 \\nai attitude (aiat)  significant  insignificant1 significant2 \\nai anxiety (aiax)  significant  insignificant1 significant2 \\nintrinsic motivation to \\nlearn ai (aiim)  significant  insignificant1 significant2 \\nrq2 (anova)   group  achievement  \\nperceived autonomy  insignificant  significant3 significant4 \\nperceived competence  insignificant  significant3 significant4 \\nperceived relatedness  insignificant  significant3 significant4 \\nrq3 (pair t -tests)  sdt -based (high \\nachievers)  sdt -based (low \\nachievers)   \\nai readiness (aird)  significant5 significant6  \\nai confidence (aicf)  significant5 significant6  \\nai attitude (aiat)  significant5 significant6  \\nai anxiety (aiax)  significant5 significant6  \\nintrinsic motivation to \\nlearn ai (aiim)  significant5 significant6  \\nnote: insignificant1 – no significant difference between high and low achievers; significant2 – significant \\ndifference between high and low achievers; significant3 – significant difference between the sdt -based \\nand control groups; significant4 – significant difference between high and low achievers; significant5 – \\nsignificant difference between pr e- and post - questionnaires for high achievers; significant6 – significant \\ndifference between pre - and post - questionnaires for low achievers.  \\n \\n \\n ',\n",
       " ' 1 artificial intelligence for decision making in the era of big data – evolution, \\nchallenges and research agenda  \\n(an opinion  paper for international journal of information management)  \\n \\nyanqing duan*  \\nuniversity of bedfordshire  \\nyanqing.duan@beds.ac.uk \\n \\njohn s. edwards  \\naston university  \\nj.s.edwards@aston.ac.uk  \\n \\nyogesh k dwivedi  \\nschool of management, swansea university  \\ny.k.dwivedi@swansea.ac.uk  \\n \\n*- corresponding author  \\n \\nabstract  \\nartificial intelligence (ai) has be en in existence for over six decades and has experienced ai \\nwinters and springs. the rise of super computing power and big data technologies appear to \\nhave empowered ai in recent years. the new generation of ai is rapidly expanding and has again become an attractive topic for research. this paper aims to identify the challenges \\nassociated with the use and impact of revitalised ai based systems for decision making and \\noffer a set of research propositions for information systems (is) researchers. the paper fi rst \\nprovides a view of the history of ai through the relevant papers published in the international journal of information management (ijim). it then discusses ai for decision making in general and the specific issues regarding the interaction and integrat ion of ai to support or \\nreplace human decision makers in particular. to advance research on the use of ai for decision making in the era of big data, the paper offers twelve research propositions for is researchers in terms of conceptual and theoretical development, ai technology -human \\ninteraction, and ai implementation.  \\nkeywords: artificial intelligence; ai; big data; cognitive computing; decision making; \\nexpert system; machine learning; recommender system; research agenda ',\n",
       " ' 2 1. introduction \\nthe rise of artificial intelligence in recent years has attracted numerous controversial \\nremarks. for example, ceo of ibm, ginni rometty, argues that ai technologies  are \\n“technologies to  augment human intelligence …by and large we see a world where this is a \\npartnership between man and machine and this is in fact going to make us better and allow us \\nto do what the human condition is best able to do.”1 . stephen hawking, on the other hand, \\nremarked that “the development of full artificial intelligence could s pell the end of the human \\nrace” (cellan -jones, 2014) , and bill gates has also said that humans should be worried about \\nthe threat posed by artificial intelligence (rawlinson, 2015) . \\nthese very different views from leading experts call for further investigation on how human \\nbeings can co -exist with ai and how to minimise the negative impact of the technology.  \\nthere is no commonly accepted definition of ai. it  is normally referred to  as the ability of a \\nmachine to learn from experience, adjust to new inputs and perform human- like tasks . the \\nterms ai and ai systems were first introduced in the 1950s . since then, ai has experienced \\nits ups (“ai springs”) and downs (“ai winters”). with the rapid advancement of big data \\ntechnologies, e.g. improved computing storage capability and super -fast speed of data \\nprocess ing machines, ai is being revitalised with the availability and power of big data.  \\ntherefore, after years of hope and promise, ai is gaining meaningful traction within top \\ncorporations (bean, 2018) . it is reported that the take -up of ai -enabled systems in \\norganisations is expanding rapidly (miller, 2018a)  and ai is transforming business \\n(daugherty & wilson, 2018) . the new wave of ai systems has improved an organisation’s \\nability to use data to make predictions and has substantially reduced the cost o f making \\npredictions (agrawal, gans, & goldf arb, 2018) . according to gartner’s 2018 technology \\ntrend survey (panetta, 2018) , ai is listed as the no. 1 strategic technology. the ability to use \\nai to enhance decision making, reinvent business models and ecosystems, and remake the customer experience will drive the payoff for digital initiatives through 2025. the  gartner \\nsurvey showed that 59% of organizations are st ill gathering information to build their ai \\nstrategies, while the remainder have already made progress in piloting or adopting ai solutions (panetta, 2018) . \\norganisations that are engaged in using the new generation of ai systems “will find that ai faces the usual obstacles to progress of any unproven and unfamiliar technology,” says whit andrews, vice president and disting uished analyst at gartner (pettey, 2018) . “however, \\nearly ai projects offer valuable lessons and perspectives for enterprise architecture and technology innovation leaders embarking on pilots and more formal ai efforts.” (pettey, 2018) . \\noverall, there are many white papers and reports from leading technology providers and articles in top management magazines, e.g. harva rd business review  and mit sloan \\nmanagement review , that provide corporates with strategic and practical guidelines on how \\nto benefit from ai. however, it appears that there are very limited academic research papers \\nfocusing on understanding the use and im pact of the new generation of ai from the \\ntechnology application perspective with rigorous academic investigation and theorisation. \\n                                                           \\n1 https://www.youtube.com/watch?v=mneqsl1 -izs ',\n",
       " ' 3 moreover, much current academic writing seems ignorant of what happened from 1970 to \\n2000 despite the availability of extens ive publications. \\nthis research position paper aims to understand the challenges associated with the use and impact of the new generation of ai based systems for decision making and identify research opportunities for information systems (is) researchers. the paper first provides a view of the history of ai through the relevant papers published in the international journal of information management (ijim) . it then discusses ai for decision making in general and the \\nspecific issues regarding the interaction and integration of ai techniques to support or replace human decision makers in particular. to advance research on the use of ai for decision \\nmaking in the era of big data, the paper offers twelve research propositions for is \\nresearchers in terms of concep tual and theoretical development, ai technology -human \\ninteraction, and ai implementation.  \\n2. a view of the history of ai through ijim papers  \\nin this section, we present an historical perspective on the history and development of ai based on a review of relevant papers published in the international journal of information management (ijim) , including those under its former title of social science information \\nstudies (ssis) . to achieve this, we carried out full -text searches on the ssis/ijim  archive for \\nthe terms artificial intelligence  and intelligent, plus  the list of 25 more specific terms related \\nto ai shown in table 1. to develop that list, we began with selected terms from the list of categories of papers at ai conferences in cantu -ortiz (2014). we excluded those not specific \\nto ai such as bioinformatics  and planning and scheduling, and added a few other terms such \\nas recommender system  that emerged in the course of our search as alternative keywords in \\nrelevant papers.  \\ntable 1 terms used in the full -text search of the ssis/ijim archive  \\n1. case-based reasoning  \\n2. computer vision \\n3. cognitive computing \\n4. cognitive science  \\n5. data mining  \\n6. data science  \\n7. expert system  \\n8. fuzzy linguistic modeling  \\n9. fuzzy logic  \\n10. genetic algorithm  \\n11. image recognition  \\n12. k-means  \\n13. knowledge -based system  14. logic programming  \\n15. machine learning  \\n16. machine vision \\n17. natural language processing \\n18. neural network  \\n19. pattern recognition  \\n20. recommendation system  \\n21. recommender system  \\n22. semantic network  \\n23. speech recognition  \\n24. support vector machine/svm  \\n25. text mining  \\n \\na preliminary screening removed papers where the term intelligent had nothing to do with ai, \\nand papers where the term that had been found appeared only in a cited reference and the \\ncitation did not refer to any ai aspect. this gave a total of 123 ssis/iji m papers. we \\ncategorised these into those in which ai was a substantive part of the paper (52 in total) and those in which ai was mentioned only in passing (71). the latter category comprised papers ',\n",
       " ' 4 ranging from those mentioning an ai system as just one ty pe of system in a list of those \\nsystems an organization does or might use, or as one example system in the literature review \\npart of a paper, to those in which one of the search terms simply appeared in an author affiliation or as a research interest. we b elieved that even the articles from second category \\nwere worth including in the counts, both as an indication of the visibility of the subject, and because even a single sentence can be of great interest, as we will see shortly.  \\nfig. 1 shows the breakdown of the 52 substantive ai papers and the other 71 that mention ai in passing, in four -year periods from the first mention of ai in passing, by seeger (1983)  \\nwhen discussing the future of information professions, up to the end of 2018. \\n051015202530354045\\n1983 to 1986 1987 to 1990 1991 to 1994 1995 to 1998 1999 to 2002 2003 to 2006 2007 to 2010 2011 to 2014 2015 to 2018\\nyearsnumber of papersin passing\\nsubstantive\\n \\nfig. 1. ai papers published in ssis/ijim by year  \\n \\nas may be seen, the number of papers published remained fairly constant from 1983 to 2010, \\nat roughly two papers per year (57 papers in 28 years). fewer than half of these were \\nsubstantive ai papers. however, the period 2011- 2014 showed a considerable increase, to 24 \\npapers against the previous average of 8.1, and the most recent period, 2015- 2018, shows a \\nlarger increase still, to 42 papers. even more significantly, 25 of those 42 were substantive ai \\npapers, the same number as had appeared from 1983 to 2013 inclusive. this is a very clear indication of the rapid recent growth in research in ai in the era of big data. \\nwe will now look in more detail at the techniques that make the ai systems work, the \\ndomains to which they have been applied, and the changing terminology used to describe them. in order to do this, we look most closely at the 52 substantive papers, though we triangul ate those findings with the other ijim papers and the wider literature. table 2 \\ncategorizes these 52 according to the type of paper; note that six papers fitted into two categories. for techniques, we focus especially on the 22 of the 52 papers that concentrate on a specific example of an ai system (21 pilot studies and one fielded application), as these \\ngive the most precise evidence on the techniques actually in use. while other types of paper ',\n",
       " ' 5 may mention ai techniques, especially review papers, it is oft en not clear whether those other \\npapers are describing systems that had been developed, were being developed, or simply that \\nmight possibly exist someday.  \\ntable 2. substantive ai papers categorized by type  \\ntype of paper  number  \\nconceptual paper  12 \\ntheoretical development  3 \\npilot study/proof of concept  21 \\nfielded application  1 \\nsurvey  7 \\nmanagement/organizational issues  3 \\nreview  11 \\n \\n2.1. techniques  \\nin this section we consider the techniques that comprise the forms of knowledge \\nrepresentation and/or the algorithms used to build the ai systems described. we only include \\nthose techniques mentioned and discussed by name. it is important to note that this does not necessarily measure how widely th ey are used, even in ijim’s research domain, as some \\npapers use terms like knowledge -based system or machine learning without describing the \\nspecific techniques employed.  \\n2.1.1. rule-based inference  \\ndespite that caveat, the most common technique used in the ai sy stems reported is definitely \\nrule-based inference. the very first system described in detail in ijim  (lu & mooney, 1989)  \\nwas a rule- based expert system. in addition, the first mention in ijim of an ai system in \\npractical everyday use was also a rule- based system. this came in a paper by bowonder and \\nmiyake (1992) , discussing information management in japan’s nippon steel corporation. \\nthey noted tha t nippon steel had been the first in the world to use an ai system for blast \\nfurnace control (see yui, watanabe, amano, takarabe, & nakamori, 1989) . \\nnearly all of the ai systems mentioned up to year 2000 use rule -based inference, and this \\nelement of ai techniques remains with us t oday; three of the specific ai systems in articles \\nfrom 2017 and 2018 (araujo & pestana, 2017; kao et al., 2017; rekik, kallel, casillas, & alimi, 2018)  are also rule- based.  \\nthe main change over time is that originally the rules were usually elicited from human experts by a human knowledge engineer, whereas now they are more likely to have been developed using an automated method such as cart (classification and regression tre es) \\n(kao et al., 2017)  or association rule mining (rekik et al., 2018) . ',\n",
       " ' 6 2.1.2. semantic linguistic analysis  \\nalmost as pervasive are the various methods of semantic linguistic analysis. the use of maps \\nto help understand natural language in documents for infor mation retrieval was one of the \\ntechniques identified in a review by wormell (1984) . these soon afterwards became known \\nas semantic networks. more recent systems such as those by tadeusiewicz, ogiela, and \\nogiela (2008)  for medical diagnosis and ogiela and ogiela (2014)  for analysing financial \\ndata use versions of this approach, sometimes with theoretical extensions such as the  latent \\nsemantic analysis used by ahmad and laroche (2017) . \\n2.1.3. bayesian networks  \\nbayesian networks are based on probabilistic inference, with the conditional probabilities associated with each path between nodes in the network adapting in the light of new data, thus encompassing learning. specific use of this term is relatively recent, with papers such as zhao, tang, darlington, austin, and culley (2008)  on evaluat ing information in engineering \\ndocuments and ramírez -noriega, juárez -ramírez, and martínez -ramírez (2017)  using a \\nbayesian network as the design for an intelligent tutoring system. however, it is likely that some of the unspecified inference methods in earl ier expert systems or knowledge -based \\nsystems papers used this approach.  \\n2.1.4. similarity measures  \\nthe concept of identifying examples that are similar or close to a new observation is at the \\nheart of case- based reasoning, which has been an active area for most of the period (tseng, \\nchen, hu, & lin, 2017; zantout & marir, 1999) . similarity measures are the metrics for \\nsimilarity/closen ess. bouakkaz, ouinten, loudcher, and st rekalova (2017)  compare several \\nsimilarity measures for textual analysis, and find that the k -means approach produced the best \\nresults in their experiment.  the k -means approach also has the advantage of being \\nconceptually very simple. it divides a set o f observations into a predetermined number  of \\nclusters (k)  by an iterative process . first a random set of k points are chosen to be  the centres \\nof the clusters, then each observation is assigned to its closest centre. once all observations have been  clust ered, the mean point of each cluster is recalculated and these become the new \\nset of cluster centres. the process is repeated until no observation changes cluster.  \\nsupport vector machines (ragini, anand, & bhaskar, 2018)  are another commonly used \\nsimilarity measure approach; in this case examples are categorized by maximizing the width \\nof the gaps between the clusters . \\n2.1.5. neural networks  \\nneural networks, more precisely artificial neural networks (ann), are intended to mimic the way the human brain works, and are at the forefront of the current expansion in ai even though applications can be found as far back as the 1980s (ford, 1989) . inte restingly, few \\npapers in ijim address specific applications of ann, exceptions including liébana-\\ncabanillas, marinković, and kalinić (2017); mostafa and el -masry (2013) . ann are more \\nlikely to be discussed in general summary and review articles (frias -martinez, magoulas, ',\n",
       " ' 7 chen, & macredie, 2006; gottschalk, filstad, glomseth, & solli -sæther, 2011; yaqoob et al., \\n2016) .  \\n2.1.6. other techniques  \\ntechniques discussed in ijim  that have also been commonly used elsewhere include frame -\\nbased representation (dugdale, 1996) , and genet ic algorithms (lebib, mellah, & drias, 2017) . \\nframes allow richer forms of knowled ge representation than rules, but the inferencing \\nprocess is more complex, so less straightforward and harder to understand. genetic \\nalgorithms mimic the process of darwinian natural selection, with a population of solutions \\nundergoing processes equivalent  to inheritance, reproduction, mutation, and cross -over, until \\nthe best solution emerges. neural networks and genetic algorithms are both examples of techniques inspired by biology: a review of those and others may be found in kar (2016) .  \\n2.2. domains  \\nsome of the domains in which ai systems were being applied, or at least considered, have \\nfeatured throughout the period. this is most likely  because of the potential economic rewards \\nfrom a successful system. these include: manufacturing, such as the 1992 nippon steel \\nexample discussed above and clothes manufacturing (ying, pee, & jia, 2018) ; health care, \\nfrom thornett (2001)  looking at computer support for general practice to kao et al. (2017)  on \\nrisk factors for cardiac arrest survival; and legal practice (du plessis & du toit, 2006) . \\nrecommender/recommendation systems have also been common throughout the period, but \\nwith a change in emphasis. earlier systems tended to tackle major investments such as  \\nproperty (lu & mooney, 1989)  or stocks and shares (dugdale, 1996) , but the ir practical use \\nwas limited. systems addressing higher -volume but lower -value decisions are now in \\neveryday use, and central to the success of organizations such as amazon and netflix, who have capitalized on the big data that they acquire. ijim papers si milarly now cover topics \\nsuch as which books to read (kim, kim, oh, & ryu, 2010) , which videos t o watch (choi, oh, \\nkim, & ryu, 2016)  or which kitchen appliances to purchase (ahmad & laroche, 2017) . \\noften these are offering technical improvements in the methods used. \\nas is fitting given the scope of ssis/ijim, intelligent information retrieval has been a concern \\nsince the earliest days (wormell, 1984) . improvements in natural language understanding \\nhave facilitated progress here, wh ich continues with articles such as those by chung (2014)  \\nand bouakkaz et al. (2017) . \\nsome domains reflect changes in the wider world and its technology, such as the appearance of papers on website quality (heradio, cabrerizo, fernández -amorós, herrera, & herrera -\\nviedma, 2013; rekik et al., 2018) . \\nother domains reflect the technology finally reaching the tipping point for practical usefulness, such as the work of araujo and pestana (2017)  on employee health and well -\\nbeing, and of ragini et al. (2018)  on disaster response and recovery.  \\nin a different direction, mostafa and el -masry (2013)  is the first ijim  paper to use ai as a \\nresearch tool, with various data mining methods being used to analyse a survey about e -',\n",
       " ' 8 government in egypt. other pap ers using ai to analyse results include (liébana -cabanillas et \\nal., 2017; rekik et al., 2018) . \\nnevertheless, some domains remain at the “potential” level.  as far back as 1997, martinsons \\n(1997)  was discussing the potential for using knowledge -based systems in human resource \\nmanagement, and commenting that it “rema ins unrealized” (p.35). many systems have been \\ndeveloped and indeed implemented for job matching and screening applications, but there \\ncontinues to be scepticism about their use. this extends to the latest development; the use of chatbots to respond to que ries from applicants, for example by l’oréal (thibodeau, 2019) ; \\nand use of ai based interviews for london city j obs particularly in financial sectors. this is \\nposing a new challenge to job appli cants as training for ai -based interviews is costing them \\nabout £9k (blunden, 2018) . \\n2.3. terminology  \\nwe can identify three overlapping eras in the ijim literature. broadly speaking, the central \\nterms in each era are r espectively expert systems, knowledge -based systems, and a \\ncombination of artificial intelligence/machine learning/data mining.  \\n2.3.1. expert systems rule! (up to 2000)  \\nthe three systems described in ijim  in detail up to 2000 (dhaliwal & tung, 2000; dugdale, \\n1996; lu & mooney, 1989)  were all expert systems. examining the other ssis/ijim  papers \\nover that period confirms that ai was more or less synonymous with expert systems.  \\nsince 2000, the term expert system has become far less important as a label. it may still be a \\nphrase mentioned in the text, but it does not appear in ijim  paper titles, abstracts or keywords.  \\n2.3.2. knowledge is power -  but only in business and management? (1983 onwards)  \\nthis era overlaps both of the others. the term knowledge -based system (kbs) began to \\nbecome popular with the launch of the uk government’s alvey programme of it research in \\n1982/3, and was used in early ssis  papers (ingwersen, 1984a, 1984b; nicholas & harman, \\n1985) . some saw expert systems as a subset of kbs; others regarded the two terms as \\nequivalent.  \\nthe start of the 21st century saw the term expert systems decline in popul arity in business \\nand management in favour of knowledge -based systems. there were three reasons for this:  \\n1. the bad reputation that some expert systems projects achieved, meaning that “expert \\nsystem” was not an attractive label.  \\n2. an increasing realization tha t the system often served to assist or support a human \\ndecision -maker, rather than as an expert telling the human what to do.  \\n3. a shift in emphasis from “the expert” to “the knowledge”, with the growth in popularity of knowledge management in the late 1990s. \\n \\nironically, systems using the rule -based technology common in early expert systems \\nproliferated in the 21st century. they were simply embedded in other systems, for example as ',\n",
       " ' 9 “wizards” in software packages, and now as an engine powering recommendations , so that \\nthe user would not be confronted with the “cursed” term.  \\nkbs was the most common term in use for an ai system in ijim during the 2000s, and many \\nbusiness/management academics and practitioners still regard it as the most appropriate term \\nto use. a s bimba et al. (2016, p.857)  put it, “a system which represents knowledge is \\nnormally referred to as a knowledge based system.” interestingly, this only seems to be true in business and management. in other domains, especially science and engineering, expert system is still the more common term. web of science lists more than 10,000 publications \\nsince the year 2000 that include the term expert system(s) , as opposed to fewer than 2,000 \\nincluding knowledge -based system(s) . \\n2.3.3. the rise of the intelligent machine -  and data mining (during the 2010s)  \\nduring the 2010s, the term ai has come back into popularity as the overall label. this may in part be the result of the fact that deep learning systems such as multi -layer neural networks do \\nnot produce explanations that humans can understand easi ly, or indeed at all. arguably, \\ntherefore, these systems do not represent knowledge as in the definition in the previous subsection. they certainly do not represent human knowledge.  \\nwithin ai, the terms machine learning and data mining are also in much mor e common use \\nnowadays. in part, this reflects technological developments. machine learning used to be seen as highly -technical  jargon , but the success of machine learning systems widely reported in \\nnews stories such as the alphago system defeating one of t he best human players of the \\ngame go  (koch, 2016)  and ib m’s watson system beating the human champions on the us \\ntv quiz show “jeopardy” (gabbatt, 2011)  has done much to improve its image. data mining \\nis a newer term than any of the others. its original mean ing in the field of economics was \\ntrying various models to see which fitted the data best. the more general usage did not become widespread until the mid -1990s. \\nmore confusingly, these changes also overlap with another area of terminological change, relati ng to the rise of the term analytics. some authors now regard machine learning as a form \\nof analytics (for example lismont, vanthienen, baesens, & lemahieu, 2017) , while some of \\nthe techniques discussed in section 2.1 are now referred to as data mining when in the 1990s they would simply have been called statistical techniques.  \\nit can be argued that there are subtle differences between expert systems, knowledge -based \\nsystems and ai systems, but some of the changes in terminology are surely no more than simply “fashion”. for example, what were  often referred to in the 1980s or 1990s as \\nproduction rules are now called business rules or just rules. similarly, kao et al. (2017)  refer \\nto the cart decision tree approach used to develop their rules as a data mining technique, whereas in the 1990s it would have been referred to as a rule induction algorithm. \\n3. an overview of using ai for decision making  \\nthe promises made to develop machines capable of outperforming humans i n several tasks in \\na few years and the real accomplishments achieved have been reported widely (mccorduck, \\n2004). despite what can now be thought of as excessively optimistic promises for ai ',\n",
       " ' 10 outcomes during the 1950s and 1960s, steady progress has been sus tained over the last four \\ndecades in the main areas of ai (cantu -ortiz, 2014) . \\nusing ai for decision making has been one of the most important applications in ai history. \\nthe roles of ai have been classified in various way s. broadly speaking, ai systems can be \\nused either to support/assist the human decision makers, or to replace them (edwards, duan, & robins, 2000) . more specifically, the early publication by bader, edwards, harris -jones, \\nand hannaford (1988)  identified six roles for knowledge based systems: assistant, critic, \\nsecond opinion, expert consultant, tutor, and automaton. \\nedwards et al. (2000)  conducted  an analysis of expert systems for business decision making \\nat different levels and in different roles based on experiments carried out two decades ago. \\nthe roles of ai (e.g. expert systems) are examined using the three organisational decision making level s, i.e. strategic, tactical and operational decisions. their findings show that:  \\n• expert systems in a replacement role are effective at the operational and tactical decision levels, but have limitations at the strategic level.  \\n• expert systems in a support role can help users make better decisions at all three decision making levels, but their effectiveness can only be fulfilled through their users.  \\n• an expert system acting in a support role does not necessarily save a user’s time, but an expert system in a replacement role does improve the efficiency of decision making.  \\n• the users of expert systems in a support role did not believe that they had learned \\nfrom using the system.  \\nthe role of ai systems, e.g. expert systems, for decision making is also discussed bas ed on \\nthe structure of decisions that is named by simon (1987)  as structured, semi -structured and \\nunstructured decisions. the findings by edwards et al. (2000)  suggest that ai (e.g. expert \\nsystems) can be used to replace human decision makers for structured or semi -structured \\ndecisions, but it would be better to be used as a decision support tool for dealing with unstructured deci sions at the strategic level in organisations.  \\nin a relevant assessment on the potential use of ai in organisations in 1985, lee (1985)  (p.8) \\ncommented “because mechanical inference relies on a stable, fixed semantics, the utility of an idealized, fully integrated, knowledge -based inference system will be limited to \\norganizations in completely stable environments.” and “integrated information systems will only be of use for those aspects of the organization’s ac tivities where semantic stability can \\nbe maintained. this conclusion corresponds to the empirical observations made by gorry and scott -morton (1971) .” this indicates that with the limitations of early ai technologies in \\ndealing with dynamic environments, ai for organisational decision making was more \\neffective in working in stable and familiar conditions.  \\nin a recent joint research with deloitte, davenport (2018) examined 152 ai deployment \\nprojects that are making use of ai-based systems across a wide range of business functions \\nand processes. based on the survey results, davenport categorises ai system applications into \\nthree categories:  ',\n",
       " ' 11 • cognitive process automation: automation of back office administrative and \\nfinancial activities using ‘robotic process automation’.  \\n• cognitive insights: detecting patterns in data and interpreting their meaning using statistically -based machine learning algorithms.  \\n• cognitive engagement: engaging employees and/or customers using natural lang uage \\nprocessing chatbots, intelligent agents and machine learning.  \\nas the progress of ai technology enables researchers to create advanced machines, it is possible for ai to undertake more complex tasks that require cognitive capabilities such as making ta cit judgements, sensing emotion and driving processes which previously seemed \\nimpossible (mahroof, 2019) . as a result, an increasing number of jobs are autonomously \\nperformed by ai systems without human control and supervision (złotowski, yogeeswaran, & bartneck, 2017) . there are many reports on the benefits of ai for decision making because \\nai is believed to be ab le to help organisational employees to reach better decisions, to boost \\nour analytic and decision -making abilities and heighten creativity (wilson & daugherty, \\n2018) . however, “with t he resurgence of ai, a new human -machine symbiosis is on the \\nhorizon and a question remains: how can humans and new artificial intelligences be \\ncomplementary in organizational decision making?” (jarrahi, 2018 p. 579) . \\n4. research propositions for addressing challenges and opportunities  \\nthis section discusses the challenges and research opportunities of ai based systems for \\ndecision making in the era of big data from the use and impact perspective. as ai \\ndevelopment and applications cover a wide range of areas, future research directions can be diverse. to help is researchers in their endeavour to advance our knowledge and understanding on how to maximise the benefit of the new ge neration ai systems for decision \\nmaking, twelve research propositions are offered, based on three areas: conceptual and theoretical development, ai technology -human interaction, and ai implementation. \\n4.1. conceptual and theoretical development  \\n4.1.1. defining the key concepts and terms  \\nai has been applied in many different domains and numerous terms are used to describe ai based systems for decision making, such as: expert systems, knowledge -based systems, \\nintelligent decision support systems, intelligent software age nt systems, intelligent executive \\nsystems, etc. however, as ai is constantly evolving and advancing, names of ai based systems for decision making have changed over the years as shown in our review of ijim  \\npapers in section 2. many names for ai based decis ion systems have disappeared or have \\nbeen replaced with new names. it can be argued that defining ai and its related terms has become a moving target.  \\nto clarify any conceptual confusion and controversy, there is a need to have a systematic review of ai re lated definitions and terms and to re -define them to reflect the new generation \\nof ai in the era of big data. we make the following proposition:  ',\n",
       " ' 12 proposition 1 –  defining ai can be difficult, so it is necessary and beneficial to re -define the \\nconcept of ai and related terms to reflect the changing nature of ai development and \\napplications in the era of big data. \\n4.1.2. understanding, theorising and measuring ai use and impact  \\nwith the rapid increase in ai applications, many claims are made by ai developers and larg e \\ncorporates about its substantial benefits and impact. for example, according to davenport and \\nronanki (2018), a survey of 250 executives who are familiar with their companies’ use of cognitive technology (a term davenport and ronanki explain as “next -generation ai”) shows \\nthat three -quarters of them “believe that ai will substantially transform their companies \\nwithin three years” (p.110). \\nas most similar claims are not substantiated by measurable empirical evidence and rigorous \\nacademic research, it is di fficult to know how, why and to what extent ai systems are being \\nused and impacting on individual and organisational decision making and transforming \\norganisations. this raises a challenge on how to measure the benefits and impact of ai for \\ndecision making  from short to long term, and from social, economic and political \\nperspectives. what would be the implications for future business executives in making strategic decisions?  \\ntherefore, the following proposition is offered:  \\nproposition 2 – measuring the bene fit of ai and its impact is very difficult, but possible. \\ntherefore, there is a need to develop and test theoretically sound and practically feasible ai \\nimpact indicators to measure its benefits. \\noverall, to have a systematic understanding on how and why a i based systems are being \\nused and affecting individual and organisational performance, an appropriate theoretical \\nframework should be developed.  \\nproposition 3 – it is necessary to theorise the use of ai and its impact on decision making, \\ntherefore an inte grated conceptual framework is needed to provide a systematic \\nunderstanding of ai for decision making.  \\n4.2. technology -human interaction \\n4.2.1. the role of ai for decision making \\nfor the early applications of ai in business and management field, edwards (1992)  points out \\nthat the spread of expert systems (representing and applying expert knowledge using ai) into \\nmanagement and administrative applications from the scientific/technical domains of the early systems was very slow. the view put forward in his paper was that for expert systems \\nto be applied to problems in management or administration, the traditional ‘closed- world’ \\npicture of an expert system was usually inadequate. the real manifestation of the expert system’s role (and indeed that of the human exper t) in management involves much more \\nnegotiation and interaction than in scientific/technical domains. the consequences for the \\nresulting system are that it looks much more like the traditional picture of a decision support \\nsystem than a classic standalone expert system.  ',\n",
       " ' 13 in an early published paper in ijim, seeger (1983, p.205)  voiced a concern that is still current \\n“complex progra mmes of the kind developed in the field of artificial intelligence may lead to \\ninformation system designs where the intellectual procedures of information work will be \\nperformed by machines. this could make a significant part of human information input obsolete.”  \\nin the era of ai and big data, miller (2018a)  argues the imperative of a new human -machine \\nsymbiosis and calls for the rethink of “how humans and machines need to work symbiotically to augment and enhance each other’s capabilities.” (page 2).  \\nthere has been an increased interest in examining the role of ai in recent years, i.e. automation or augmentation. some ai practitioners and researchers argue that ai should be used to augment the human judgement rather than automation (miller, 2018a; wilson & daug herty, 2018)  and “ai systems should be designed with the intention of augmenting, not \\nreplacing, human contributions” (jarrahi, 2018 p. 584) , but this assertion should be  further \\nsupported with rigorous research and investigation with empirical evidence on how and why ai is best at providing augmentation in supporting human judgement r ather than decision \\nautomation. \\nwilson and daugherty (2018)  argue that companies that deploy ai mainly to displace \\nemployees will see only short -term productivity gains. what is the evidence for this claim? if \\nthis is true, why and how will using ai for replac ing employees not deliver the long term \\ngains and how can this shortcoming be overcome?  \\nwilson and daugherty (2018)  also claim that companies can benefit from optimizing \\n“collaboration between humans and artificial intelligence” and develop employees’ “fusion \\nskills” that enable them to work effectively at the human -machine interface. however, some \\nai systems don’t have the capability to explain the reasoning process of dec ision making, \\nhow to solve the blackbox issue, i.e. knowing why decisions are made in a certain way \\n(davenport, 2018) and provide explanations to ai users?  to address this issue, miller (2018b)  \\nobserves that t here has been a recent resurgence in the area of explain able ai because  \\nresearchers and practitioners seek to make ai  algorithms more understandabl e. \\nmany previous studies have examined the roles of ai before the era of big data. however, considering the super power of the new generation ai and the overwhelming ly mixed views \\nand debate on the role of ai in decision making, it is imperative that the role of ai should be revisited and redefined, therefore we make the following proposition:  \\nproposition 4 – ai can play multiple roles in decision making, but ai will be mostly accepted \\nby human decision makers as a decision support/augmentation tool rather than as the automation of decision making to replace them.  \\n4.2.2. system design criteria for supporting decision making \\nas the effectiveness of ai systems for decision maki ng can only be realised through its \\nacceptance and use by the end users (edwards et al., 2000) , the system design criteria for ai \\nbased systems has been an issue since the early applications of ai. for example, system design criteria have been an issue since the days of ssis, before it became ijim (pejtersen, \\n1984) . based on our understanding of  the roles of ai, whether for supporting, augmenting, ',\n",
       " ' 14 replacing, or automating decision making, is researchers need to propose the design criteria \\nfrom technology -human inter action perspective for system developers to create ideal ai \\nsystems for human decision makers. for example, what are the ergonomic design issues for developing ai systems that are suitable for decision making? therefore, we make the following proposition:  \\nproposition 5 – the ergonomic design of ai systems is important for their success, but the \\nergonomic issues are different between supporting, augmenting, replacing, or automating systems.  \\n4.2.3. refining and improving ai system performance while in use by decision makers  \\nthe unique strength of human intelligence is its ability to learn and adapt to new environment and challenges. refining and improving performance through continuing learning has been a challenge for advancing ai until the recent advances in deep l earning and big data. deep \\nlearning, as a subset of machining learning, has been one of the essential enablers for the \\nrenewed ai success. can ai systems be refined and improved by deep learning while they \\nare in use by decision makers? this question needs  to be addressed by further research, so we \\nmake the following proposition:  \\nproposition 6 – ai systems performance for decision making can be refined and improved by \\ndeep learning while the systems are in use by decision makers.  \\n4.2.4. ai users’ behaviour issues  \\nwhy do human decision makers accept/reject using ai for decision making? previous \\nresearch show when people use ai as a supporting tool for decision making, different people \\nmay take different attitudes and actions on implementing the decisions recommended  by ai \\nsystem. for example, davenport (2018) and miller (2018) identify  the need for employees to \\nadapt to the smart machines being used to partially or fully automate cognitive work. davenport and kirby (2016)  introduce a model of ‘five ways of stepping’ to help people \\nrenegotiate their relationship to machines and to co -exist with smart machines by aligning \\ntheir contributions in the age of ai.  \\nfor example, senior managers’ attitudes towards using ai can be critical as ransbotham, gerbert, reeves, kiron, and spira (2018)  suggest that scaling ai in the enterprise demands \\nnew ways to engage business experts with technology. considering the importance of users’ beha viour towards using ai, we make the following proposition:  \\nproposition 7 –ai users’ personal traits and knowledge and understanding of ai will significantly affect the use and success of ai.  \\n4.3. ai systems implementation  \\n4.3.1. understanding the critical success fact ors \\nai has been revitalised with big data and is becoming ever more powerful than before. however, while technology advancement may have no limit, its applications may encounter \\nbottlenecks and unprecedented barriers. although there may be many factors aff ecting the ',\n",
       " ' 15 success of ai applications, it is important to identify what are the most critical success factors \\nbased on the empirical evidence collected from the real -world ai applications. these critical \\nsuccess factors will help organisations to be more f ocused by addressing the most critical \\nissues. the critical success factors can also offer valuable guidelines for ai designers and developers in their effort to overcome challenges in order to provide the most effective and acceptable systems for decision  makers.  \\nbased on the work by duan, ong, xu, and mathews  (2012)  before the era of big data, the \\ntechnical challenges related to supporting executive decision making using ai (intelligent software agents in this case) are the agents’ capability to understand a business executive as \\nan individual user with specific doma in of work and information, and to fit the intelligence \\nactivities into the right content and context. they call for alleviating the limitations and \\nbottlenecks of ai applications in terms of representing human intuition and judgement.  \\nfor example, underst anding the technology can be critical for adoption success. davenport \\nand ronanki (2018)  argues that before embarking on an ai initiative, companies must \\nunderstand which technolog ies perform what types of tasks, and the strengths and limitations \\nof each.  \\noverall, factors affecting the use,  impact, success and failure of information systems have \\nbeen studied extensively (dwivedi et al. 2015; 2017ab; hughes et al. 2016; 2017; 2019).  \\nthere has been some work on critical success factors for implementing data mining systems (bole, popovič, žabkar, papa, & jaklič, 2015) , but across the board there is a lack of research \\non identifying the critical success factors affecting the current use of ai and its impact in the era of big data. therefore, the f ollowing proposition is offered:  \\nproposition 8 –  there are a set of critical factors that will significantly affect ai’s success for \\ndecision making.  \\n4.3.2. understanding the synergy of ai and big data  \\nit can be argued that it is big data that has empowered ai f or its current boom and the \\ndomain of cognitive computing will be incomplete without harnessing the benefits of big data analytics (gupta, kar, baabdullah, & al -khowaiter, 2018) . the big data era has added \\ntypes of data that were not previously used in analysis, such as that from social media (martínez -rojas, pardo- ferreira, & rubio -romero, 2018; ragini et al., 2018) . on the other \\nhand, ai makes big data meaningful through cognitive computing because analysis of big data by humans can be extremely time- consuming and thus the utilisation of ai techniques \\nhelp to make sense of big data (gupta et al., 2018) . yet ai is only one of many ways in \\nwhich big data can be used (yaqoob et al., 2016) . thus there is still a strong need to further \\nexplore and understand the synergy of ai and bi g data. more research is needed to establish \\nthe unique advantages obtained by the combination of these technologies and understand how ai can be further improved with the increasing availability of big data with its volume, variety and velocity. therefore, we make the following proposition:  \\nproposition 9 –there is a necessary to fully understand the synergy of ai and big data and its implications for ai research and practice.  ',\n",
       " ' 16 4.3.3. culture and ai applications  \\nculture has been recognised as an important influential factor in technology acceptance by \\nmany studies in the past. does culture, such as national  or organisational culture , and \\npersonal and religious  values , also play a critical role in acceptance/adoption and use of ai \\napplications? for example, gerbert, reeves, ransbotham, kiron, and spira (2018)  examine \\n“why chinese companies approach ai differently”. liu, chan, zhao, and liu (published \\nonline 2018)  also find a significant influence of both organisational and chinese national \\nculture on knowledge management. if culture does play a role, how, why and to what extent \\ndoes it affect the ai success? thus, we formulate the following proposition:  \\nproposition 10 – the acceptance of ai for decision making can be affected by different \\ncultures and personal values. on the other hand, will the wide use of ai for supporting and automating human decision \\nmaking change culture? this is an area that has not been well explored so far, thus requir ing \\nfurther investigation with the following research proposition:  \\nproposition 11 – the acceptance and successful application of ai for decision making may \\nresult in a change of culture in organisations and in individual behaviour. \\n4.3.4. ethical and legal issues  \\nrapid advances in ai are raising serious ethical concerns. remenyi and williams (1996)  was \\nan early example of consideration of the ethics of  an ai system published in ijim  over two \\ndecades ago. ethical and legal concerns surrounding the applications of ai have become a \\nmajor challenge. as this topic has received a substantial amount of attention and debate, a \\nseparate full paper would be more appropriate to this topic. however, as the role of government is critical for addressing the ethical concerns and legal challenges, particularly around responsibility for and explainability of decisions made by an automaton ai system, it is imperative that more research must be carried out on the role of the government in shaping \\nthe future of ai (galston, 2018). how can the government develop adequate policy, regulations, ethical guidance and legal framework to prevent misuses of ai and their potential \\ndisastrous consequences on both individual and societal levels? therefore, this paper m akes \\nthe following proposition:  \\nproposition 12 – government plays a critical role in safeguarding the impact of ai on society.  \\n5. conclusion  \\nas ai has become more popular toda y due to big data, advanced algorithms, and improved \\ncomputing power and storage, ai systems are becoming an embedded element of digital \\nsystem s, and more specifically , are making  a profound impact on human decision making. as \\na result, there is an increas ing demand for information systems researchers to investigate and \\nunderstand the implications of ai for decision making and to contribute to the theoretical advancement and practical success of ai applications. this paper aims  to address this need \\nby analy sing and highlighting the critical challenges and opportunities for is researchers. \\ntwelve research propositions are provided focusing on the use and impact  of ai for decision \\nmaking in terms of: theoretical development, technology -human interaction and ai  ',\n",
       " ' 17 implementation. table 3 provides a summary of research propositions. although the \\npropositions are specifically for research in ai for decision making, most of them can also \\nprovide relevant directions for research on the use and impact of ai in general. \\ntable 3. a summary of research propositions  \\ntheoretical development  technology -human \\ninteraction  ai implementation  \\n1. proposition 1 – defining ai \\ncan be difficult, so it is \\nnecessary and beneficial to \\nre-define the concept of ai \\nand related terms to reflect \\nthe changing nature of ai \\ndevelopment and \\napplications in the era of \\nbig data.  \\n2. proposition 2 – measuring \\nthe benefit of ai and its \\nimpact is very difficult, but \\npossible. therefore, there is \\na need to develop and test \\ntheoretically sound and \\npractically feasible ai \\nimpact indicators to \\nmeasure its benefits.  \\n3. proposition 3 – it is \\nnecessary to theorise the \\nuse of ai and its impact on \\ndecision making, therefore \\nan integrated conceptual \\nframework is needed to \\nprovide a systematic \\nunderstanding of ai for \\ndecision making.  \\n 4. proposition 4 – ai can play \\nmultiple roles in decision \\nmaking, but ai will be \\nmostly accepted by human \\ndecision makers as a \\ndecision \\nsupport/augmentation tool \\nrather than as the \\nautomation of decision \\nmaking to replace them.  \\n5. proposition 5 – the \\nergonomic design of ai \\nsystems is important for \\ntheir success, but the \\nergonomic issues are \\ndifferent between \\nsupporting, augment ing, \\nreplacing, or automating \\nsystems.  \\n6. proposition 6 – ai systems \\nperformance for decision \\nmaking can be refined and \\nimproved by deep learning \\nwhile the systems are in use by decision makers.\\n \\n7. proposition 7 –ai users’ \\npersonal traits and \\nknowledge and \\nunder standing of ai will \\nsignificantly affect the use \\nand success of ai.  8. proposition 8 – there are a \\nset of critical factors that \\nwill significantly affect \\nai’s success for decision \\nmaking.  \\n9. proposition 9 –there is a \\nnecessary to fully \\nunderstand the synergy of \\nai and big data and its \\nimplications for ai \\nresearch and practice.  \\n10. proposition 10 – the \\nacceptance of ai for \\ndecision making can be \\naffected by different \\ncultures and personal \\nvalues.  \\n11. proposition 11 – the \\nacceptance and successful \\napplication of ai for \\ndecision making may result \\nin a change of culture in \\norganisations and in \\nindividual behaviour.  \\n12. proposition 12 – \\ngovernment plays a critical \\nrole in safeguarding the \\nimpact of ai on society.  \\n \\n \\nlike any publication, this opinion paper has certain limitations. first, it only reviews and \\ndiscusses the history of ai through ijim  papers  and so our findings may not be \\ncomprehensive and representative. second, the paper only focuses on identifying the \\nchallenges and opportunities from the applications of ai for decision making; it does not cover issues related to advancing ai techniques and systems. third, as an opinion paper, no primary data was collected or used to support the development of the resea rch propositions. \\n \\nreferences  \\nagrawal, a., gans, j., & goldfarb, a. (2018). prediction machines: the simple economics of \\nartificial intelligence : harvard business press.  ',\n",
       " ' 18 ahmad, s. n., & laroche, m. (2017). analyzing electronic word of mouth: a social \\ncommerce construct. international journal of information management, 37(3), 202-\\n213. doi:10.1016/j.ijinfomgt.2016.08.004  \\naraujo, j., & pestana, g. (2017). a framework for soci al well -being and skills management \\nat the workplace. international journal of information management, 37(6), 718- 725. \\ndoi:10.1016/j.ijinfomgt.2017.07.009 \\nbader, j., edwards, j., harris -jones, c., & hannaford, d. (1988). practical engineering of \\nknowledge -based systems. information and software technology, 30(5), 266 -277.  \\nbean, r. (2018). how big data and ai are driving business innovation in 2018. mit sloan \\nmanagement review, februray 2018.  \\nbimba, a. t., idris, n., al -hunaiyyan, a., mahmud, r. b., abdela ziz, a., khan, s., & chang, \\nv. (2016). towards knowledge modeling and manipulation technologies: a survey. \\ninternational journal of information management, 36 (6), 857- 871. \\ndoi:10.1016/j.ijinfomgt.2016.05.022 \\nblunden, m. (2018, 2 october). graduates are taking £9k courses to help beat ai interviews \\nfor city jobs.  evening standard. retrieved from https://www.standard.co.uk/tech/ai -\\ninterviews -city-jobs-graduates -a3951296.html  \\nbole, u., popovič, a., žabkar, j., papa, g., & jaklič, j. (2015). a case analysis of embryonic \\ndata mining success. international journal of information management, 35(2), 253 -  \\n259. doi: https://doi.org/10.1016/j.ijinfomgt.2014.12.001  \\nbouakkaz, m., ouinten, y., loudcher, s., & strekalova, y. (2017). textual aggregation \\napproaches in olap context: a survey. international journal of information management, 37(6), 684- 692. doi:10.1016/j .ijinfomgt.2017.06.005  \\nbowonder, b., & miyake, t. (1992). creating and sustaining competitiveness: information \\nmanagement strategies of nippon steel corporation. international journal of information management, 12(1), 39 -  56. doi:\\nhttps://doi.org/10.1016/0268-\\n4012(92)90051- q \\ncantu -ortiz, f. j. (2014). advancing artificial intelligence research and dissemination \\nthrough conference series: benchmark, scientific impact and the micai experience. exper t systems with applications, 41(3), 781- 785. \\ndoi:https://doi.org/10.1016/j.eswa.2013.08.008\\n \\ncellan -jones, r. (2014). stephen hawking warns artificial intelligence could end mankind.   \\nretrieved fro m https://www.bbc.co.uk/news/technology -30290540  \\nchoi, i. y., oh, m. g., kim, j. k., & ryu, y. u. (2016). collaborative filtering with facial \\nexpressions for online video recommendation. intern ational journal of information \\nmanagement, 36(3), 397- 402. doi:10.1016/j.ijinfomgt.2016.01.005  \\nchung, w. (2014). bizpro: extracting and categorizing business intelligence factors from \\ntextual news articles. international journal of information management, 34(2), 272-284. doi:10.1016/j.ijinfomgt.2014.01.001  \\ndaugherty, p. r., & wilson, h. j. (2018). human+ machine: reimagining work in the age \\nof ai : harvard business press.  \\ndavenport, t. h., & kirby, j. (2016). only humans need apply: winners and losers in the  age \\nof smart machines : harper business new york, ny.  \\ndavenport, t. h., & ronanki, r. (2018). artificial intelligence for the real world. harvard \\nbusiness review, 96 (1), 108- 116.  \\ndhaliwal, j. s., & tung, l. l. (2000). using group support systems for devel oping a \\nknowledge -based explanation facility. international journal of information \\nmanagement, 20(2), 131- 149. doi:10.1016/s0268- 4012(99)00061- 4 ',\n",
       " ' 19 du plessis, t., & du toit, a. s. a. (2006). knowledge management and legal practice. \\ninternational journal of i nformation management, 26(5), 360 -  371. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2006.06.003  \\nduan, y., ong, v. k., xu, m., & mathews, b. (2012). supporting decision making process \\nwith “ideal”  software agents –what do business executives want? expert systems with \\napplications, 39(5), 5534- 5547.  \\ndugdale, j. (1996). a cooperative problem -solver for investment management. international \\njournal of information management, 16(2), 133 -  147. \\ndoi:https://doi.org/10.1016/0268- 4012(95)00074- 7 \\n \\ndwivedi, y.k., wastell, d., laumer, s., henriksen, h.z., myers, m.d., bunker, d., elbanna, \\na., ravishankar, m.n., & srivastava, s.c. (2015). research on information systems failures and successes: status update and future directions. information systems frontiers , 17(1), 143- 157. \\ndwivedi, y.k., rana, n.p., janssen, m., lal, b., williams, m.d. & clement, r.m. (2017a). \\nan empirical validation of a unified model of electronic government adoption (umega). government information quarterly , 34(2), 211- 230.  \\ndwive di, y.k., rana, n.p.,  jeyaraj, a., clement, m. & williams, m.d. (2017b). re -\\nexamining the unified theory of acceptance and use of technology (utaut): towards a revised theoretical model. information systems frontiers . doi: \\nhttps://doi.org/10.1007/s10796- 017-9774- y \\nedwards, j. s. (1992). expert systems in management and administration- are they really \\ndifferent from decision support systems? european journal of operational research, 61(1-2), 114- 121.  \\nedwards, j. s., duan, y., & robins, p. (2000). an analysi s of expert systems for business \\ndecision making at different levels and in different roles. european journal of information systems, 9(1), 36 -46.  \\nford, n. (1989). from information- management to knowledge -management - the role of \\nrule induction and neural  net machine learning techniques in knowledge \\ngeneration. journal of information science, 15(4 -5), 299- 304.  \\nfrias -martinez, e., magoulas, g., chen, s., & macredie, r. (2006). automated user \\nmodeling for personalized digital libraries. international journal of information \\nmanagement, 26(3), 234- 248. doi:10.1016/j.ijinfomgt.2006.02.006  \\ngabbatt, a. (2011, 17 februrary). ibm computer watson wins jeopardy clash. the guardian. \\nretrieved from \\nhttps://www.theguardian.com/technology/2011/feb/17/ibm -computer -\\nwatson -wins -jeopardy  \\ngerbert, p., reeves, m., ransbotham, s., kiron, d., & spira, m. (2018). global competition \\nwith ai in business: how china differs. mit sloan management review, july 2018.  \\ngorry, a., & scott -morton, m. s. (1971). a framework for information systems. sloan \\nmanagement review, 13(1), 56- 79.  \\ngottschalk, p., filstad, c., glomseth, r., & solli -sæther, h. (2011). information \\nmanagement for investigat ion and prevention of white -collar crime. international \\njournal of information management, 31(3), 226 -  233. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2010.07.002  \\ngupta, s., kar, a. k., baabdullah, a., & al -khowaiter, w. a. a. (2018). big data with \\ncognitive computing: a review for the future. international journal of information management, 42, 78- 89. doi: https://doi.org/10.1016/j.ijinfomgt.2018.06.005\\n \\nhughes, d.l., rana, n.p. & dwivedi, y.k. (2019). elucidation of is project success factors - \\nan interpretive structural modelling approach. annals of operations research, doi: https://doi.org/10.1007/s10479- 019-03146- w  ',\n",
       " ' 20 hughes, d.l., dwivedi, y.k., & rana, n.p. (2017). mapping is failure factors on \\nprince2® stages: an application of interpretive ranking process (irp). \\nproduction planning & control , 28(9), 776- 790. \\nhughes, d.l., dwivedi, y.k., rana, n.p. & simintiras, a.c. (2016). information systems \\nproject failure –analysis of causal links using interpretive structural modelling. \\nproduction planning & control , 27(16), 1313- 1333. \\nheradio, r., cabrerizo, f. j., fernández -amorós, d., herrera, m., & herrera -viedma, e. \\n(2013). a fuzzy linguistic model to evaluate the quality of library 2.0 functionalities. international journal of information management, 33(4), 642 -  654. \\ndoi:https://doi.org/10.1016/ j.ijinfomgt.2013.04.001\\n \\ningwersen, p. (1984a). information technology —which applications? social science \\ninformation studies, 4(2), 185- 196. doi: https://doi.org/10.1016/0143- 6236(84)90075-\\n9 \\ningwe rsen, p. (1984b). psychological aspects of information retrieval. social science \\ninformation studies, 4(2), 83- 95. doi: https://doi.org/10.1016/0143- 6236(84)90068- 1 \\njarrahi, m. h. (2018). artifici al intelligence and the future of work: human- ai symbiosis in \\norganizational decision making. business horizons, 61(4), 577- 586. \\ndoi:https://doi.org/10.1016/j.bushor.2018.03.007  \\nkao, j.- h., chan, t.-c., lai, f., lin, b.- c., sun, w.- z., chang, k.- w., . . . lin, j.- w. (2017). \\nspatial analysis and data mining techniques for identifying risk factors of out -of-\\nhospital cardiac arrest. international journal of information management, 37(1), 1528- 1538. doi:10.1016/j.ijinfomgt.2016.04.008 \\nkar, a. k. (2016). bio inspired computing –a review of algorithms and scope of applications. \\nexpert systems with applications, 59, 20- 32. doi:10.1016/j.eswa.2016.04.018 \\nkim, j. k., kim, h. k., oh, h. y., & ryu, y. u. (2010). a group recommendation system for \\nonline communities. international journal of information management, 30(3), 212 -  \\n219. doi: https://doi.org/10.1016/j.ijinfomgt.2009.09.006\\n \\nkoch, c. (2016). how the computer beat the go master.   retrieved from \\nhttps://www.scientificamerican.com/article/how -the-computer -beat-the-go-master/  \\nlebib, f. z., mellah, h., & drias, h. (2017). enhancing information source selection using a \\ngenetic algorithm and social tagging. international journal of information management, 37(6), 741- 749. doi:10.1016/j.ijinfomgt.2017.07.011  \\nlee, r. m. (1985). on information system semantics: expert vs. decision support systems. \\nsocial science information studies, 5(1), 3 -10. doi:\\nhttps://doi.org/10.1016/0143-\\n6236(85)90002- x \\nliébana- cabanillas, f., marinković, v., & kalinić, z. (2017). a sem -neural network \\napproach for predicting antecedents of m -commerce acceptance. international \\njournal of information management, 37(2), 14 -  24. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2016.10.008  \\nlismont, j., vanthienen, j., baesens, b., & lemahieu, w. (2017). defining analytics maturity \\nindicators: a survey approach. international journal of information management, 37(3), 114- 124. doi:10.1016/j.ijinfomgt.2016.12.003 \\nliu, y., chan, c., zhao, c., & liu, c. (published online 2018). unpacking knowledge \\nmanagement practices in china: do institution, national and organizational culture matter? journal of knowledge management . doi:\\nhttps://doi.org/10.1108/jkm -07-\\n2017- 0260  \\nlu, m. t., & mooney, s. p. (1989). assessing expert system applications -  a case- study. \\ninternational journal of information management, 9(4), 267- 273. doi:10.1016/0268-\\n4012(89)90050- 9 ',\n",
       " \" 21 mahroof, k. (2019). a human- centric perspective exploring the readiness towards smart \\nwarehousing: the case of a large retail distribution warehouse. international journal \\nof information management, 45, 176- 190. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2018.11.008  \\nmartínez -rojas, m., pardo- ferreira, m. d. c., & rubio- romero, j. c. (2018). twitter as a \\ntool for the management and analysis of emergency situations: a systematic literature review. international journal of information management, 43, 196 -  208. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2018.07.008\\n \\nmartinsons, m. g. (1997). human resource management applications of knowledge -based \\nsystems. international journal of information management, 17(1), 35 - 53. \\ndoi:https://doi.org/10.1016/s0268- 4012(96)00041- 2 \\nmiller, s. (2018a). ai: augmentation, mor e so than automation. asian management insights, \\n5(1), 1 -20.  \\nmiller, t. (2018b). explanation in artificial intelligence: insights from the social sciences. \\nartificial intelligence .  \\nmostafa, m. m., & el -masry, a. a. (2013). citizens as consumers: profiling e -government \\nservices’ users in egypt via data mining techniques. international journal of \\ninformation management, 33(4), 627 -  641. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2013.03.007  \\nnicho las, d., & harman, j. (1985). the end- user: an assessment and review of the literature. \\nsocial science information studies, 5(4), 173- 184. doi: https://doi.org/10.1016/0143-\\n6236(85)90026- 2 \\nogiela,  l., & ogiela, m. r. (2014). cognitive systems for intelligent business information \\nmanagement in cognitive economy. international journal of information \\nmanagement, 34(6), 751 - 760. doi: https://doi.org/10.1016/j.ijinfomgt.2014.08.001  \\npanetta, k. (2018). gartner top 10 strategic technology trends for 2018.   retrieved from \\nhttps://ww w.gartner.com/smarterwithgartner/gartner -top-10-strategic -technology -\\ntrends -for-2018/  \\npejtersen, a. m. (1984). design of a computer -aided user -system dialogue based on an \\nanalysis of users' search behaviour. social science information studies, 4(2), 167- 183. \\ndoi:https://doi.org/10.1016/0143- 6236(84)90074- 7 \\npettey, c. (2018). lessons from artificial intelligence pioneers. smart with gartner: digital \\nbusiness.   retrieved from https://www.gartner.com/smarterwithgartner/lessons -from -\\nartificial- intelligence -pioneers/  \\nragini, j. r., anand, p. m. r., & bhaskar, v. (2018). big data  analytics for disaster response \\nand recovery through sentiment analysis. international journal of information management, 42, 13- 24. doi: https://doi.org/10.1016/j.ijinfomgt.2018.05.004\\n \\nramíre z-noriega, a., juárez -ramírez, r., & martínez -ramírez, y. (2017). evaluation \\nmodule based on bayesian networks to intelligent tutoring systems. international journal of information management, 37 (1, part a), 1488 -  1498. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2016.05.007\\n \\nransbotham, s., gerbert, p., reeves, m., kiron, d., & spira, m. (2018). artificial \\nintelligence in business gets real. mit sloan management review, fall 2018.  \\nrawlinson, k. ( 2015). microsoft's bill gates insists ai is a threat.   retrieved from \\nhttps://www.bbc.co.uk/news/31047780  \\nrekik, r., kallel, i., casillas, j., & alimi, a. m. (2018). assessing web sites quality: a \\nsystem atic literature review by text and association rules mining. international \\njournal of information management, 38(1), 201 -  216. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2017.06.007  \",\n",
       " \" 22 remenyi, d.,  & williams, b. (1996). some aspects of ethics and research into the silicon \\nbrain. international journal of information management, 16(6), 401 -  411. \\ndoi:https://doi.org/10.1016/0268- 4012(96)00029- 1 \\nseeger, t. (1983). changes in the occupation and profession of information work: the impact \\nof the new communication technologies. social science information studies, 3(4), \\n199-208. doi: https://doi.org/10.1016/0143- 6236(83)90046- 7 \\nsimon, h. a. (1987). making management decisions: the role of intuition and emotion. \\nacademy of management executive, 1(1), 57 -64. doi:10.5465/ame.1987.4275905 \\ntadeusiewicz, r., ogiela, l., & ogiela, m. r. (2008). t he automatic understanding approach \\nto systems analysis and design. international journal of information management, 28(1), 38 -  48. doi: https://doi.org/10.1016/j.ijinfomgt.2007.03.005\\n \\nthibode au, p. (2019). l'oréal boosts candidate experience with recruitment chatbots.   \\nretrieved from https://searchhrsoftware.techtarget. com/feature/loreal -boosts -\\ncandidate- experience -with-recruitment- chatbots  \\nthornett, a. m. (2001). computer decision support systems in general practice. international \\njournal of information management, 21(1), 39 -  47. \\ndoi:https://doi.org/10.1016/s0268- 4012(00)00049- 9 \\ntseng, s.- s., chen, h.- c., hu, l.- l., & lin, y.- t. (2017). cbr -based negotiation rbac \\nmodel for enhancing ubiquitous resources management. international journal of information management, 37(1), 1539- 1550. doi:10.1016/j.ijinfomgt.2016.05.009 \\nwilson, j., & daugherty, p. r. (2018). collaborative intelligence humans and \\nal are joining forces. harvard business review, 96(4), 115- 123.  \\nwormell, i. (1984). co gnitive aspects in natural language and free -text searching. social \\nscience information studies, 4(2), 131- 141. doi:\\nhttps://doi.org/10.1016/0143-\\n6236(84)90071- 1 \\nyaqoob, i., hashem, i. a. t., gani, a., mokhtar, s., ahmed, e., anuar, n. b., & vasilakos, \\na. v. (2016). big data: from beginning to future. international journal of information management, 36(6, part b), 1231 -  1247. \\ndoi:https://doi.org/10.1016/j.ijinfomgt.2016.07.009\\n \\nying, w., pee, l. g., & jia, s. (2018). social informatics of intelligent manufacturing \\necosystems: a case study of kutesmart. international journal of information \\nmanagement, 42, 102- 105. doi:10.1016/j.ijinfomgt.2018.05.002 \\nyui, k., watanabe, s., amano, s., takarabe, t., & nakamori, t. (1989). application of an \\nexpert system to blast furnace operation. future generation computer systems, 5(1), 137-142. doi: https://doi.org/10.1016/0167- 739x(89)90032- 0\\n \\nzantout, h., & marir, f. (1999). document management systems from current capabilities \\ntowards intelligent information retrieval: an overview. international journal of \\ninfor mation management, 19(6), 471- 484. doi:10.1016/s0268- 4012(99)00043- 2 \\nzhao, y., tang, l. c. m., darlington, m. j., austin, s. a., & culley, s. j. (2008). high value \\ninformation in engineering organisations. international journal of information \\nmanagement, 28(4), 246 - 258. doi: https://doi.org/10.1016/j.ijinfomgt.2007.09.007  \\nzłotowski, j., yogeeswaran, k., & bartneck, c. (2017). can we control it? autonomous \\nrobots threaten human identity, unique ness, safety, and resources. international \\njournal of human- computer studies, 100, 48- 54. \\ndoi:https://doi.org/10.1016/j.ijhcs.2016.12.008  \\n \",\n",
       " 'hal id: hal-03641111\\nhttps://hal.science/hal-03641111\\nsubmitted on 20 jul 2023\\nhal is a multi-disciplinary open access\\narchive for the deposit and dissemination of sci-\\nentific research documents, whether they are pub-\\nlished or not. the documents may come from\\nteaching and research institutions in f rance or\\nabroad, or from public or private research centers.l’archive ouverte pluridisciplinaire hal , est\\ndestinée au dépôt et à la diffusion de documents\\nscientifiques de niveau recherche, publiés ou non,\\némanant des établissements d’enseignement et de\\nrecherche français ou étrangers, des laboratoires\\npublics ou privés.\\nai-generated vs. human artworks. a perception bias\\nt owards artificial intelligence?\\nmartin ragot, nicolas martin, salomé cojean\\nt o cite this version:\\nmartin ragot, nicolas martin, salomé cojean. ai-generated vs. human artworks. a perception bias\\nt owards artificial intelligence?. chi ’20: chi conference on human f actors in computing systems,\\napr 2020, honolulu, united states. \\uffff10.1145/3334480.3382892\\uffff. \\uffffhal-03641111\\uffff',\n",
       " '  \\n1 \\n ai-generated vs. human artworks. a perception bias towards artificial intelligence?  \\nmartin ragota, nicolas martina, & salomé cojeanb \\n \\nairt b<>com  \\n1219, av des champs blancs  \\n35510 cesson -sévigné, france  \\nmartin.ragot@b -com.com , nicolas.martin@b -com.com   \\n \\nblaboratory of psychology lppl (ea 4638)  \\nuniversity of angers  \\n11, boulevard lavoisier  \\nangers, 49045, france  \\nsalome.cojean@univ -grenoble -alpes.fr  \\ndoi: https://doi.org/10.1145/3334480.3382892  \\n \\n \\n \\nabstract  \\nvia generative adversarial networks  (gans) , artificial intelligence (ai)  has influenced  many areas, especially the artistic field , as symbol of a human \\ntask. in human -computer interaction (hci) studies , perception biases against ai, machines , or computers are generally cited. however, exper imental \\nevidence is still lacking. this paper presents a wide -scale experiment in which 565 participants are asked to evaluate paintings ( which were created by \\nhumans or ai) on four dimensions: liking, perceived beauty , novelty , and meaning. a priming effe ct is evaluated using two between -subject \\nconditions: artworks presented as created by an a i, and artworks presented as created by a human artist. finally, the paintings perceived as being \\ndrawn by human are evaluated  significantly more highly  than those perceived as  being  made by ai. thus, using  such a methodology and sample  in an \\nunprecedented way,  the results show a negative bias of perception towards ai and a preference bias towards human systems . \\nauthor keywords  \\narts; artificial intelligen ce; ai;  authorship; bias; can; computational creativity; gan; painting . \\n \\nintroduction  \\nfor many years, technological  progress has wrought profound changes  in the creative industry , as in the field s of music (e.g., [18, 19] ), parametric \\ndesign (e.g., [41]), generative fashion design (e.g., [34]), and paintings (e.g., [23]). this has  given rise to  the emergence of new research fields: \\ncomputational aesthetics [31], attractiveness computing (see chu [14] for a literature review) , creative adversarial networks (can) [23] and \\ncomputational creativity [16]. computational creativity is a generic field of artificial intelligence (ai)  that stud ies both artificial and human creativity \\n[56] and has grown considerably . indeed, in  recent years, ai  and especially its  subfield machine  learning (ml) have gained popularity [38] thanks to ',\n",
       " ' \\n2 \\n research breakthroughs  [37]. in 2014, g oodfellow and collaborators [27] proposed a new ml paradigm to generate synthetic data called  a generative \\nadversarial network (gan)1. artists ha ve appropriated t hese models have been in recent years to the point that they have  becom e a new art market \\n[20]. thus, a first art painting generated by a gan was sold for $432,500 by obvious  [14]2. with the increase in quality and ubiquity of creative \\nsystems  such as gans , studying these creativity support systems  seems to be necessary [17, 29] . evaluatin g the relevance of recently  produced \\nartistic works consists of assessing  the perception of the public towards these artworks . to improve the algorithms,  one approach is to try to  \\nunderstand user perception s. there is also a need to understand  the acceptance of works produced by ai  [16]. currently, this perception seems to be \\nrather negative. indeed, gaut [26] has postulate d a “negative value ” towards machines or computers. co lton [15] is also concerned about the \\nrejection of creative computers. nevertheless, the evidence for such negative bias remains unclear.  it seems crucial to study human perceptions of \\nthese ai -generated artworks . for this purpose, different methodologies exist. first, in many studies , a modified turing test (tt)  is used  to analyze  \\nhumans’  capacity to distinguish human or ai artworks (e.g., [23, 45, 51] ). however, the tt  seems  insufficient.  indeed, this type of test does not  make \\nit possible to  study audience perceptions . this method has also been criticized for encouraging  imitation and pastiches  of existing human artworks \\n[46]. in parallel, to the best of our knowledge, few research ers have studied the differences in public perceptions between ai -generated  or human \\nartworks to understand the potential human bias. in their survey, moffat and kelly [40] found  significant bias against computer -generated music. \\nother researchers have tried to reproduce these results with a small sample but without success [25, 42, 44] . in addition , hong [32] has analyze d the \\ndifferences in perception s of computer art  within focus groups.  for the same piece of art  is more considered to be “art” when it is perceived to be of \\nhuman origin than ai  origin . in the field of art and paintings, elgammal [23] has found conflicting results with a positive bias towards machines. \\ndespite this, the bias against computers is widespread and  often cited [36]: “this suggests that there is much more to investigate about our relation \\nwith artificially generated art ” ([20], p. 159) .  \\nwith increasing exposure to “more high -quality computer generated art ifacts,” the following research questions have becom e “more pressing ” ([17], p. \\n276). art is a symbol of an activity long regarded as a human task. thus, ai  raises important questions in terms of  acceptability  and human -and-\\nmachine  relationships, which must be studied  in the field of hci . can people distinguish computer -generated paintings? do people prefer systems (or \\npaintings ) created  by humans? do people have a negative bias towards ai? finally, we seek to learn  how assumptions about the identity of the \\npainters (ai or human) of the s ame artworks influences their evaluation. t his paper presents a large -scale experiment to assess the existence of a \\npotential human bias towards works generated by ai  by using the technique of priming effect (e.g., [3, 55] ). the priming effect represents the \\ninfluence of a first stimulus (the primer) on the processing of a subsequent stimulus (the target). thus, our study evaluates  the influence of the \\nexposure of the primer (i.e., the declared identity of the painter, ai vs. huma n) on the perception of artistic targets (i.e., ai -generated paintings vs. \\npaintings drawn by humans).  \\n                                                 \\n1 generative adversarial network (gan)  [25] consists in train jointly two separate models: a generator and a discriminator. the generator is train to \\ngenerate the most realistic data (e.g., images, text, signal) and to fool the discriminator. the discriminator is train to discriminate real data (i.e., data \\nfrom the training dataset) and fake data (i.e.,  data from the generator).  \\n \\n2 https:// obvious -art.com/  ',\n",
       " ' \\n3 \\n method  \\nparticipants  \\n565 participants (m = 32.80 years; s.d. = 9.91; 234 females and 331 males) were  involved . the participants were recruited  without specific criteria  \\non amazon mechanical turk  (amt) in order to select more diverse profiles  and obtain  a larger sample  [11]. the reward paid to each worker was $0.75.  \\nmeasures  \\nas amirshahi [1] has recommended with lead subjective tests, many proprieties related to the paintings were studied. inspired by the works of \\nberlyne [5], jordanous [33], and elgammal [23], many dimensions were evaluated: liking (“i like this painting ”), beauty (“this painting looks \\nbeautiful ”), novelty ( “this painting see ms novel ”), and m eaning ( “i perceive the meaning of the painting ”). to evaluate subjective dimension s, \\nquestionnaires with likert scales are used  in this survey. t he optimal number of rating bars seems to be seven [13]. for these four dimensions, \\nparticipants were asked to indicate how much they agreed according to seven -point likert scales (1  = totally disagree; 7 = totall y agree). each likert \\nhad antagonist anchors without labels between.  \\nmaterial  \\nfollowing pasquier [44], the selection of pieces of art  was influenced by their similarity in order  to conceal their authorship . for this purpose, 40 \\nimpressionist -style paintings made by piet mondrian, claude monet, robbie barrat, and the collective obvious were selected3 (see erreur  ! source du \\nrenvoi introuvable.  for examples) .  \\n \\nfigure 1. examples of used art paintings  (human: the stroller  - claude monet ; ai: madame de belamy  - @obvious_art ) \\nprotocol  \\nan online survey was used to control the experimental conditions in this type of study [1]. the participants who accept ed the ta sk on amt were \\nredirected to the survey monkey platform. a mixed -subject design was used; see erreur  ! source du renvoi introuvable. . similar to  [25], \\n                                                 \\n3 due to space limitation , the complete list of paintings  is not presented. please contact the first author for details . \\nportrait human portrait ai\\n',\n",
       " ' \\n4 \\n participants were randomly assigned to one of the two conditions (i.e., human or ai condition, the between -subject variable). thus, participants saw \\none of the two primings and instructions presented in erreur  ! source du renvoi introuvable. . all participants saw portraits and landscapes actually \\nmade by humans and ai (within -subject design).  \\n \\nfigure 2. experimental design  \\n \\nthe artworks were randomly selected from 40 paintings (10 portraits by ai, 10 landscapes by ai, 10 portraits by humans, and 10 landscapes by \\nhumans) to improve the generalization of the results, t o reduce experiment duration , and to avoid the repetition of painting styles.  next, f or each \\npainting, participants ha d to complete  severa l items (i.e., lik ing, perceived  beaut y, novelty,  and meaning). finally , in order to ensure the effectiveness \\nof the priming  of the declared author type (i.e., ai or human), and following  previous stud ies (e.g., [42]), an item of manipulation check was \\nintroduced (i.e., “at the beginning of the study, the identity of the painters was defined. do you remember the identity of t he painters?”).  afterward, it \\nwas explained that the origin of the painting had been manipulated. participant s then had to guess the origin of four paintings (one painting  was \\nrandomly selected from each category). this modified tt was proposed at the end of the study to avoid any bias in evaluation and the priming  effect. \\nlastly, two demographic questions about age  and gender were asked.  \\n \\nai humaninduction\\nbetween-subject \\nvariable\\nlandscape\\nportraitreal author: \\nairandomized order\\nwithin-subject variables\\nlandscape\\nportraitreal author: \\nhuman',\n",
       " ' \\n5 \\n instruction : ai condition  \\n8 paintings created by some artificial intelligence  will be presented. you will be \\nasked to rate them. there are no right or wrong answers. only your opinion \\ncounts. please respond spontaneously according to your feelings.  \\ninstruction : human  condition  \\n8 paintings created by some artists  will be presented. you will be asked to rate \\nthem. there are no right or wrong answers. only your opinion counts. please \\nrespond spontaneously according to your feelings  \\ntable 1: instructions  \\nresults  \\nmixed model analy ses were used  for each dependent variable. thus, t he participant and the paintings4 were considered random factors . the induction \\ncondition was considered a between -subject factor. the type of paintings and the real authors were considered within -subject factors . the statistical \\nanalysis was performed using r [47], lme4 [4], and afex [52]. the effect sizes were based  on [10] (measured as d). \\nparticipants who responded “i don’t know” to the manipulation check were excluded (i.e., 79  out of 565  participants , or 13.98% of the sample ). \\nmoreover, for “human condition” and “ai condition,” 82% and 62%, respectively, of participants remembered their type of induc tion. thus, to control \\nthe effect of this variable, a nswering correctly or incorrectly on this item was introduced as a ra ndom facto r similar to  [1]. \\nthe effects of the induction condition, the type of paintings, and the rea l authors were evaluated on declared liking, perceived beauty, perceived \\nnovelty, and meaning. all descriptive statistics are presented in erreur  ! source du renvoi introuvable. , erreur  ! source du renvoi introuvable. , \\ntable 4, and table 5. \\nconcerning declared liking  (see erreur  ! source du renvoi introuvable. ), the analyses  show a main effect of induction ( f1,481.25  = 17.67, \\np < .001, d = 0.06), the type of painting ( f1,30.74 = 26.69 , p < .001, d = 0.15), and the real authors ( f1,30.74 = 82.44, p < .001, d = 0.25). \\n human  ai \\ninduction  5.12 (1.56) 4.80 (1.66) \\n human  ai \\nreal authors  5.18 (1.44) 4.72 (1.76) \\n land  portrait  \\npainting type  5.35 (1.39)  4.55 (1.74)  \\ntable 2. descriptive statistics for declared linking . land = landscape  \\n                                                 \\n4 to consider the variability between pai ntings, the painting is included as a random factor. thus, the variability in  perception between the paintings is absorbed in the model \\nfitting.  ',\n",
       " ' \\n6 \\n regarding perceived beauty  (see erreur  ! source du renvoi introuvable. ), the analyses  show a main effect of induction ( f1,481.23  = 17.74,  p < .001, \\nd = 0.05), the type of painting ( f1,32.14 = 22.18 , p < .001, d = 0.16), and the real authors ( f1,32.14 = 64.81, p < .001, d = 0.27). \\n human  ai \\ninduction  5.12  \\n(1.53) 4.81 (1.67) \\n human  ai \\nreal authors  5.20 (1.38)  4.71 (1.78)  \\n land  portrait  \\npainting type  5.37 (1.36)  4.54 (1.73)  \\ntable 3. descriptive statistics for perceived beauty.  land = landscape  \\nin terms of perceived novelty  (see table 4), the analyses  show a main effect of induction ( f1,481.28  = 13.31, p < .001, d = 0.11), the type of painting \\n(f1,25.72 = 16.33 , p < .001, d = 0.08), and the real authors ( f1,25.72 = 3.47, p = .074, d = 0.04). \\n human  ai \\ninduction  4.90 (1.46) 4.63 (1.59) \\n human  ai \\nreal authors  4.87 (1.47)  4.63 (1.58)  \\n land  portrait  \\npainting type  4.81 (1.48)  4.70 (1.58)  \\ntable 4. descriptive statistics for perceived novelty. land = landscape  \\nconcerning perceived meaning  (see table 5), the analyses  showed a main effect of induction ( f1,481.34  = 15.09, p < .001, d = 0.13), the type o f \\npainting ( f1,28.81 = 19.61 , p < .001, d = 0.10), and the real authors ( f1,28.81 = 52.96, p < .001, d = 0.16). ',\n",
       " ' \\n7 \\n  human  ai \\ninduction  4.81 (1.56) 4.48 (1.69) \\n human  ai \\nreal authors  4.80 (1.52)  4.47 (1.74)  \\n land  portrait  \\npainting type  4.90 (1.50)  4.37 (1.73)  \\ntable 5. descriptive statistics for perceived meaning. land = landscape  \\nlastly, participants had to distinguish paintings made by humans from generated -ai paintings. the analyses show an effect of the painting type on the \\nrecognition rate ( f1,1717.44  = 17.67, p < .001, ηp2 = 0.34) and the author’s type ( f1,1717.44  = 64.41 , p < .001, ηp2 = 0.34): see table 6. thus, paintings \\ndrawn by humans (compared to ai -generated paintings) and the portraits (compared to the landscapes) are the best -recognized artworks with the \\nlowest percentage of recognition errors . \\ntype of p aintings  \\n/ real authors  recognition rate  \\nlandscape  53 %  \\nportrait  69 %  \\nhuman  66 %  \\nai 56 %  \\ntable 6. recognition rate (in percent) according to painting  type and author type  \\ndiscussion  \\na phase with a  manipulation check was proposed to participants to verify the relevance of the proposed induction.  the r esponses suggest that a large \\nmajority of participants believe d and remember ed their type of induction  (i.e., ai or human condition) . these results see m consistent  with those of \\nfriedman  [25]. in their  first experiment, 83 .87% and 65 .27%, respectively , believe d in the assertion in “human condition” and “ai condition .” unlike \\nin the previous stud ies, here, the use of a large sample (5 65 participants) , combined with the introduction of the answers in the manipulation check  as \\na random factor , resulted in  precis e statistical analy ses. indeed, the results show significant effect s of both the  induced and real author. more \\nspecifically, the artworks presented as ai-generated paintings were significantly less liked and were perceived as less beautiful, novel , and meaningful \\nthan paintings presented as draw n by a human. the same pattern, with significant effect, is also apparent for the real type of authors of the artworks  \\npresented. indeed, ai -generated paintings were less well evaluated (in terms of liking, b eauty, novelty, and meaning) than paintings made by \\nhumans. these results support the first results obtained by moffat and kelly [40] on the perception bias towards computer -generate d music . to the \\nbest of our knowledge, these results had never been replicated  on a large sample, with the previous methodological precautions presented. moreover, \\nthe modified tt, in which  participants have to guess the real author of the paintings, show ed a better recognition of human paintings (66%) than ai -\\ngenerated paintings (56%). the se results are consistent with burnett [12] for composed -computer music and  are opposed to  results of moffat and \\nkelly [40]. in elgammal [23], 75% of respondents  thought that the ai -generated paintings were made by humans. these differences could be \\nexplained by the improvement of the techniques in computational creativity, especially with the emergence of gan. in  parallel, it should be noted that \\nparticipants are better able to identify the origin of the author for portraits (69%) than for landscapes (53%).  similar to boden [8], with a recognition ',\n",
       " ' \\n8 \\n rate close to chance (50%) , people have difficulty distinguishing the type of authors. these results may suggest that the technical proprieties of ai -\\ngenerated paintings are currently more advanced for the generat ion of landscapes  than portraits.  a possible explanation of the existing bias against \\nai-generated paintings could be that participants evaluated  the pieces of art with an intergroup bias. ai may be anthropomorphized and thus \\nconsidered as the out -group [21]. intergroup bias can be defined as  the tendency people have to evaluate their own group (i.e., the in -group) in a \\nmore positive manner than another group (i.e., the out -group) [6, 30] . social changes relative to the out -group may bring a sense of threat and \\nnegative feelings that reinforce the intergroup bias [9, 24, 30] . the aim of the out -group devaluation is to maintain a positive  social identity and \\nsuperiority in some areas of competence [54]. to further explain the existence of a negative perception bias towards ai, several concepts can be cited, \\nsuch as  technophobia ([43]; see [49] for meta -analysis), anxiety towards machines, and reactive devaluation  [50]. ai can be s een as a potential \\nsource of danger because it could replace humans in many areas [43]. to combat this bias, some authors have raised the question of framing \\ninformation  on user perceptions [7, 15, 35, 48, 53] . indeed, “[f]raming  information  might be useful to help humans unders tand an agent who is unlike \\nthem; but this remains to  be tested ” ([36], p. 28:24 ), even if the experimental results seem to be unclear [39]. thus, for lamb ( [36], p. 28:24 ), “a \\nmore subtle question is if humans are biased toward familiar and humanlike forms of creativity ,” which could be linked to the previously mentioned \\nintergroup bias.  \\nfuture works  \\nwithin this paper, a general bias against ai -generated artwork can be highlighted. in future works, the interaction effects across different parameters \\n(e.g., induction and painting type ) may  be explored. moreover, it may be interesting to include a measur e of self -reported expertise in art . hekkert \\nand wieringen [28] have analyzed the differences in the art evaluation among experts and non -experts; they found a c orrelation between perceived \\noriginality and quality  that was  significantly higher among experts than non -experts . in the same way, moffat and kelly [40] have found a bias against \\ncomputers that was significantly higher in musicians than non -musicians. nevertheless, in a modified version of the tt, non -musicians were \\nsurprisingly better th an musicians at recognizing music generated by computers or humans. in parallel, in order to  make our results even more \\ngeneric , the evaluation of a general bias against ai -generated artworks could be made with different styles of paintings (e.g., [23]) or types of art \\n(e.g., music, poem). in this pa per, p ublic perception bias is questioned based on  dichotomic human or ai priming.  however, the frontiers between ai \\nand human -generated artworks may appear more and more faint. for elgammal  [22], ai has even blurred the definition of artists. more generally, this \\nraises the issue of authorship: “can an artificial intell igence make art without artists ?” [2]. an initial  answer could be in the eye or mind of the viewer . \\nconclusion  \\nthe idea of a negative perception bias against machines, computers, and/or ai is wi dely shared, particularly in computational creativity. however, \\nthere has been a lack of experimental proof that demonstrates evidence of this bias. unlike previous studies, the current large -scale experiment with \\n565 participants focused on ai and ai -generated paintings with different methodological precautions  (large sample, randomization, manipulation check \\nas random factor, etc.). in addition to the large sample, the main contribution s of this paper  are the methodological precautions and the robustness of \\nthe results , which  seem to represent significant progress  in the field of hci and computational creativity to demonstrate  the existence of a negative \\nperception bias towards ai  at the expense of human -made systems . thus, depending on the perceived ident ity of the author (human vs. ai), the \\nsame artworks were evaluated differently. moreover, the results show that real artworks made by humans are also evaluated mor e highly than real ai -\\ngenerated artworks . alongside technological advances in ai,  this paper paves the way for other studies to further consider perception bias in \\ncomputational creativity and to analyze the impact of ai on human representations.  ',\n",
       " ' \\n9 \\n acknowledgement  \\nthis study was carried out within b<>com, an institute of research and technology dedicated to digital technologies. it received support from the \\nfuture investments program of the french national research agency (grant no. anr -07-a0-airt).  ',\n",
       " ' \\n10 \\n references  \\n[1] seyed a li amirshahi, gregor uwe hayn -leichsenring, joachim denzler, and christoph redies. 2015. jenaesthetics subjective dataset: analyzing \\npaintings by subjective scores. computer vision - eccv 2014 workshops , springer international publishing, 3 –19. \\n[2] sofian audry and jon ippolito. 2019. can artificial intelligence make art without artists? ask the viewer. arts 8, 1: 35.  \\n[3] john a. bargh, mark chen, and lara burrows. 1996. automaticity of social behavior: direct effects of trait construct and ster eotyp e activation on \\naction. journal of personality and social psychology  71, 2: 230 –244. \\n[4] douglas bates, martin mächler, ben bolker, and steve walker. 2015. fitting linear mixed -effects models using lme4. journal of statistical \\nsoftware  67, 1: 1 –48. \\n[5] d. e. berlyne. 1971. aesthetics and psychobiology . appleton -century -crofts, east norwalk, ct, us.  \\n[6] michael billig and henri tajfel. 1973. social categorization and similarity in intergroup behaviour. european journal of social psychology  3, 1: 27 –\\n52. \\n[7] reuben binns, max van kleek, michael veale, ulrik lyngs, jun zhao, and nigel shadbolt. 2018. “it’s reducing a human being to a  percentage”: \\nperceptions of justice in algorithmic decisions. proceedings of the 2018 chi conference on human factors in computing  systems  - chi ’18 , \\nacm press, 1 –14. \\n[8] margaret a. boden. 2010. the turing test and artistic creativity. kybernetes . \\n[9] marilynn b brewer. 2001. ingroup identification and intergroup conflict. social identity, intergroup conflict, and conflict reductio n 3: 17 –41. \\n[10] marc brysbaert and michaël stevens. 2018. power analysis and effect size in mixed effects models: a tutorial. journal of cognition  1, 1: 9.  \\n[11] michael buhrmester, tracy kwang, and samuel d. gosling. 2011. amazon’s mechanical turk: a new source of inexpensive, yet high -quality, \\ndata? perspectives on psychological science  6, 1: 3 –5. \\n[12] adam burnett, evon khor, philippe pasquier, and arne eigenfeldt. 2012. validation of harmonic progression generator using cla ssical music. \\n126–133. \\n[13] m. y. cai, y. lin, and w. j. zhang. 2016. study of the optimal number of rating bars in the likert scale. proceedings of the 18th international \\nconference on information integration and web -based applications and services - iiwas ’16 , acm press, 193 –198. \\n[14] wei-ta chu, hideto motomura, norimichi tsumura, and toshihiko yamasaki. 2019. a survey on multimedia artworks analysis and attrac tiveness \\ncomputing in multimedia. ite transactions on media technology and applications  7, 2: 60 –67. \\n[15] simon colton. 2008.  creativity versus the perception of creativity in computational systems. aaai spring symposium: creative intelligent \\nsystems . \\n[16] simon colton. 2012. the painting fool: stories from building an automated painter. in j. mccormack and m. d’inverno, eds., computers and \\ncreativity . springer berlin heidelberg, berlin, heidelberg, 3 –38. \\n[17] simon colton, alison pease, and rob saunders. 2018. issues of authenticity in autonomously creative systems. proceedings of the ninth \\ninternational conference on computatio nal creativity, salamanca, spain, june 25 -29, 2018. , 272–279. \\n[18] david cope. 2005. computer models of musical creativity . mit press, cambridge, mass.  \\n[19] david cope and douglas r. hofstadter. 2001. virtual music: computer synthesis of musical style . mit press, cambridge, mass.  \\n[20] antonio daniele and yi -zhe song. 2019. ai + art = human. proceedings of the 2019 aaai/acm conference on ai, ethics, and society  - aies \\n’19, acm press, 155 –161. \\n[21] chad edwards, autumn edwards, brett stoll, xialing lin, and noelle massey. 2019. evaluations of an artificial intelligence instructor’s voice: \\nsocial identity theory in human -robot interactions. computers in human behavior  90: 357 –362. ',\n",
       " ' \\n11 \\n [22] ahmed elgammal. 2019. ai is blurring the definition of artist. american sci entist  107, 1: 18.  \\n[23] ahmed elgammal, bingchen liu, mohamed elhoseiny, and marian mazzone. 2017. can: creative adversarial networks, generating “ar t” by \\nlearning about styles and deviating from style norms. arxiv:1706.07068 [cs] . \\n[24] victoria m esses, l ynne m jackson, and tamara l armstrong. 1998. intergroup competition and attitudes toward immigrants and immigration: \\nan instrumental model of group conflict. journal of social issues  54, 4: 699 –724. \\n[25] ronald s. friedman and christa l. taylor. 2014. exp loring emotional responses to computationally -created music. psychology of aesthetics, \\ncreativity, and the arts  8, 1: 87 –95. \\n[26] berys gaut. 2010. the philosophy of creativity: philosophy of creativity. philosophy compass  5, 12: 1034 –1046.  \\n[27] ian goodfe llow, jean pouget -abadie, mehdi mirza, et al. 2014. generative adversarial networks. arxiv:1406.2661 [cs, stat] . \\n[28] paul hekkert and piet c. w. van wieringen. 1996. beauty in the eye of expert and nonexpert beholders: a study in the appraisa l of art. the \\namerican journal of psychology  109, 3: 389 –407. \\n[29] beth a. hennessey and teresa m. amabile. 2010. creativity. annual review of psychology  61, 1: 569 –598. \\n[30] miles hewstone, mark rubin, and hazel willis. 2002. intergroup bias. annual review of psychology  53, 1: 575 –604. \\n[31] florian hoenig. 2005. defining computational aesthetics. proceedings of the first eurographics conference on computational aesthetics in \\ngraphics, visualization and imaging , eurographics association, 13 –18. \\n[32] joo-wha hong . 2018. bias in perception of art produced by artificial intelligence. human -computer interaction. interaction in context , springer \\ninternational publishing, 290 –303. \\n[33] anna jordanous. 2014. stepping back to progress forwards: setting standards for meta -evaluation of computational creativity. .  \\n[34] wang -cheng kang, chen fang, zhaowen wang, and julian mcauley. 2017. visually -aware fashion recommendation and design with generative \\nimage models. arxiv:1711.02231 [cs] . \\n[35] rené f. kizilcec. 2016. how much information?: effects of transparency on trust in an algorithmic interface. proceedings of the 2016 chi \\nconference on human factors in computing systems - chi ’16 , acm press, 2390 –2395.  \\n[36] carolyn lamb, daniel g. brown, and charles l. a. clarke. 2018. ev aluating computational creativity: an interdisciplinary tutorial. acm comput. \\nsurv.  51, 2: 28:1 –28:34.  \\n[37] yann lecun, yoshua bengio, and geoffrey hinton. 2015. deep learning. nature  521, 7553: 436 –444. \\n[38] jay h. lee, joohyun shin, and matthew j. realff. 2018. machine learning: overview of the recent progresses and implications f or the process \\nsystems engineering field. computers & chemical engineering  114: 111 –121. \\n[39] stephen mcgregor, matthew purver, and  geraint wiggins. 2016. process based evaluation of computer generated poetry. proceedings of the \\ninlg 2016 workshop on computational creativity in natural language generation , association for computational linguistics, 51 –60. \\n[40] david c moffat and marti n kelly. 2006. an investigation into people’s bias against computational creativity in music composition. proceedings of \\nthe 3rd international joint workshop on computational creativity (ecai06 workshop) . \\n[41] danil nagy, damon lau, john locke, et al. 2017 . project discover: an application of generative design for architectural space planning. society \\nfor computer simulation international, 7.  \\n[42] david norton, derrall heath, and dan ventura. 2015. accounting for bias in the evaluation of creative computati onal systems: an assessment \\nof darci. proceedings of the sixth international conference on computational creativity , 31–38. ',\n",
       " ' \\n12 \\n [43] changhoon oh, taeyoung lee, yoojung kim, sohyun park, sae bom kwon, and bongwon suh. 2017. us vs. them: understanding artific ial \\nintelligence technophobia over the google deepmind challenge match. proceedings of the 2017 chi conference on human factors in computing \\nsystems - chi ’17 , acm press, 2523 –2534.  \\n[44] philippe pasquier, adam burnett, and james maxwell. 2016. investigating  listener bias against musical metacreativity. proceedings of the \\nseventh international conference on computational creativity (iccc 2016) , sony csl.  \\n[45] marcus t. pearce and geraint a. wiggins. 2001. towards a framework for the evaluation of machine comp ositions. .  \\n[46] alison pease and simon colton. 2011. on impact and evaluation in computational creativity: a discussion of the turing test an d an alternative \\nproposal. proceedings of aisb ’11: computing and philosophy , society for the study of artificial intelligence and simulation of behaviour, 15 –22. \\n[47] r core team. 2018. r: a language and environment for statistical computing . r foundation for statistical computing, vienna, austria.  \\n[48] emilee rader, kelley cotter, and janghee cho. 2018. explanations  as mechanisms for supporting algorithmic transparency. proceedings of the \\n2018 chi conference on human factors in computing systems  - chi ’18 , acm press, 1 –13. \\n[49] larry d. rosen and phyllisann maguire. 1990. myths and realities of computerphobia: a met a-analysis. anxiety research  3, 3: 175 –191. \\n[50] lee ross. 1995. reactive devaluation in negotiation and conflict resolution. in k. arrow, r. mnookin, l. ross, a. tversky, an d r.b. wilson, eds., \\nbarriers to conflict resolution . new york.  \\n[51] oscar schwart z and benjamin laird. 2019. bot or not. retrieved july 27, 2019 from http://botpoet.com.  \\n[52] henrik singmann, ben bolker, jake westfall, and frederik aust. 2019. afex: analysis of factorial experiments . . \\n[53] rashmi sinha and kirsten swearingen. 2002. th e role of transparency in recommender systems. chi ’02 extended abstracts on human factors in \\ncomputing systems  - chi ’02 , acm press, 830.  \\n[54] henri tajfel and john turner. 2004. an integrative theory of intergroup conflict. in m.j. hatch and m. schultz,  eds., organizational identity: a \\nreader . oxford university press, 56 –65. \\n[55] endel tulving, daniel l. schacter, and heather a. stark. 1982. priming effects in word -fragment completion are independent of recognition \\nmemory. journal of experimental psychol ogy: learning, memory, and cognition  8, 4: 336 –342. \\n[56] geraint a. wiggins. 2006. a preliminary framework for description, analysis and comparison of creative systems. knowledge -based systems  19, \\n7: 449 –458. \\n \\n ',\n",
       " '1 emerging artificial intelligence methods in structural engineering \\nhadi salehi1, rigoberto burgueño1,2 \\n1 department of civil and environmental engineering, michigan state university, east lansing, michigan, usa \\n2 department of mechanical engineering, michigan state university, east lansing, michigan, usa \\nemail: burgueno@msu.edu \\nabstract \\nartificial intelligence (ai) is proving to be an efficient alternative approach to classical modeling \\ntechniques. ai refers to the branch of computer science that develops machines and software with human-\\nlike intelligence. compared to traditional methods, ai offers advantages to deal with problems associated \\nwith uncertainties and is an effective aid to solve such complex problems. in addition, ai-based solutions \\nare good alternatives to determine engineering design parameters when testing is not possible, thus \\nresulting in significant savings in terms of human time and effort spent in experiments. ai is also able to \\nmake the process of decision making faster, decrease error rate s, and increase computational efficiency . \\namong the different ai techniques, machine learning (ml), pattern recognition (pr) , and deep learning \\n(dl) have recently acquired considerable attention and are establishing themselves as a new class of\\nintelligent methods for use in structural engineering . the objective of this review paper is to summarize\\ntechniques concerning applications of the noted ai methods in structural engineering developed over the\\nlast decade. first, a general introduction to ai is presented and the importance of ai in structural\\nengineering is described . thereafter , a review of recent applications of ml, pr, and dl in the field is\\nprovided, and the capability of such methods to address the restrictions of conventional models are\\ndiscussed . further, the advantages of employing such algorithmic methods are discussed in detail. finally ,\\npotential research avenues and emerging trends for employing ml, pr, and dl are presented, and their\\nlimitations are discussed.\\nkeywords: structural engineering, artificial intelligence , machine learning, pattern recognition, deep \\nlearning , soft computing \\n1. introduction\\ncivil engineering is fraught with problems that defy solution via traditional computational techniques. \\nhowever, they can often be solved by an expert with proper training. classical artificial intelligence (ai) \\nhas targeted this class of problems by capturing the essence of human cognition at the highest level. the \\nterm “ ai” was introduced at a workshop held in dartmouth college in 1956 [1]. ai is a computational \\nmethod attempting to simulate human cognition capability through symbol manipulation and \\nsymbolically structured knowledge bases to solve engineering problems that defy solution using \\nconventional methods . ai has been developed based on the interaction of various disciplines; namely, \\ncomputer science, information theory, cybernetics, linguistic, and neurophysiology.  \\nseveral terms referring to artificial intelligence can be found in the literature, and they need to be \\nidentified to further elaborate on the state of the art . one of those terms is machine intelligence (mi). ai \\n© 2018 published by elsevier. this manuscript is made available under the elsevier user license\\nhttps://www.elsevier.com/open-access/userlicense/1.0/version of record: https://www.sciencedirect.com/science/article/pii/s0141029617335526\\nmanuscript_824f38aeb6473dfd4189789143a454f1',\n",
       " '  \\n2 and mi are almost identical terms [2,3] and are often used interchangeably . mi is often considered a \\nsynonym of ai; yet it deals with different types of intelligent problems, e.g., clustering, classifications, \\ncomputer vision, etc. in general, mi refers to machines with human-like intelligent behavior and \\nreasoning, while ai refers to a machine’s ability to mimic the cognitive functions of humans to perform \\ntasks in a smart manner . another important term is cognitive computing (cc), which is inspired by \\nhuman mind’s capabilities [4]. cognitive systems are able to solve problems in a form mimicking humans \\nthinking and reasoning. such systems are based on the ability of machines to measure, reason, and adapt \\nusing learned experience[4,5] . the main characteristics of cc systems are the ir ability to interpret big \\ndata, dynamic training and adaptive learning, probabilistic discovery of relevant patterns. technically, ai \\nrefers to computers and machines that can behave intelligently, while cc concentrates on solving the \\nproblems using humanlike thinking. the most significant difference between ai and cc can be defined in \\nterms of interacting normally with humans. for any ai system, there is an agent that decides what actions \\nneed to be taken. however, cc systems learn, reason, and interact like humans. therefore, it can be \\nconcluded that cc is essentially an ai agent, and as such cc is considered a sub-set of ai . expert \\nsystems, on the other hand, is a branch of ai. as noted, ai is defined as the ability of a machine to mimic \\nintelligent human behavior, seeking to use human-inspired algorithms to solve problems. similarly, an \\nexpert system is defined as a computer program attempting to mimic human experts to solve problems \\ndemanding human/expert knowledge. it follows from the noted definitions that ai includes different \\nbranches such as expert systems, machine learning, pattern recognition, fuzzy logic, etc. \\nin recent years, there has been a growing interest in the use of ai in all engineering domains, and i t \\nhas fueled many visions and hopes. while the civil engineering community h as witnessed an extensive \\ngrowth in the use of different ai branches/methods in its diverse areas , the present study concentrates on \\nthe ai methods that have gained significant attention over the last decade, namely machine learning \\n(ml) , pattern recognition (pr) , and deep learning (dl) with a focus on their application to the structural \\nengineering discipline . the scope of the review is to summarize the theoretical background of the \\nmethods, provide a historical context on their use, summarize the latest research developments, and \\ndiscuss promising paths for future research. \\nthe use of ai in civil engineering has been the topic of previous review articles . adeli et al.  [6] \\npresented a multiparadigm learning technique, where the authors demonstrated that the performance can \\nbe notably enhanced by skillful integration of different ai branches, including neural networks, genetic \\nalgorithms, fuzzy sets, and parallel processing. an extensive study of evolutionary computation, a branch \\nof ai, in the context of structural design was conducted by kicinger et al.  [7]. lio et al. [8] carried out a \\nreview of studies concerning the application of metaheuristics as optimization techniques to address \\nissues faced in the lifetime of a construction or engineering project. a survey on different ai methods \\n(e.g., fuzzy logic, evolutionary computation, neural networks, swarm intelligence, expert systems, etc.) \\nfor civil engineering was conducted by lu et al.  [9]. shahin et al.  [10] studied applications of ai in \\ngeotechnical engineering ; and saka et al. [11] conducted a survey on mathematical and metaheuristic \\nalgorithms in design optimization of steel frame structures . adeli et al.  [12] carried out a review on \\nprogress in the optimization of high-rise buildings; and a survey on the applications and methodologies of \\nthe fuzzy multiple criteria decision-making techniques was conducted by mardani et a l [13]. \\nrecently, a survey on the application of multi-criteria decision making methods for the analysis of \\nsuspension bridges was conducted by garcia-segura et al. [14]; sanchez et al. [15] presented a review on \\nthe applications of artificial neural networks, a branch of ai, for civil infrastructure that includes ',\n",
       " '  \\n3 structural health monitoring, structural system identification, structural design and optimization, etc.; and \\na comprehensive state- of-the-art overview of sustainable structural design in green buildings rating \\nsystems and building codes was conducted by pongiglione et al. [16]. further, a survey on different ai \\nmethods (e.g., artificial neural networks, bayesian, genetic algorithms, case-based reasoning, and fuzzy \\nlogic) for the field of fracture mechanics was performed by khosravani et al. [17], while a literature \\nreview of application of multi-criteria decision analysis for aging-dam management was carried out by \\nmieza et al. [18]. additionally, sierra et al. [19] conducted a review on multi-criteria assessment of the \\nsocial sustainability of infrastructures and zavadskas et al. [20] surveyed the state- of-the-art methods \\napplied to sustainable decision-making in civil engineering, construction, and building technology.  \\nalthough the noted review articles highlighted applications of ai in civil engineering \\nstructures/infrastructure , they mainly focus ed on traditional techniques and do not cover recent methods, \\nsuch as pr, ml, and dl . yet, these intelligent methods have experienced notable developments and \\nincreased use in structural engineering during the last few years. therefore , this review paper presents a \\nbroad perspective of research efforts on the use of such emerging ai methods (i.e., pr, ml, and dl) in \\nstructural engineering during the last decade. due to space limitations , the review emphasis for each \\npaper was on the problem/issue being addressed, the domain and case structure being considered, and the \\nai method being used. the contributions of this review paper are: 1) study and summarize techniques \\nconcerning the applications of pr, ml, and dl in structural engineering over the last decade, 2) identify \\nfuture directions and emerging trends for employing pr, ml, and dl in structural engineering \\napplications, and 3) highlight current limitations of the reviewed ai methods in structural engineering .   \\nthe review paper is structured as follows . section 2 presents the approach followed for selecting the \\nreviewed literature and conducting the content analysis. a general introduction to ai is presented in \\nsection 3, and the significan ce of ai in structural engineering is also described . new ai techniques \\n(namely ml, pr, and dl) are introduced and highlighted in section 4, where the differences of these \\ntechniques are elaborated. section 5 reviews the application of such techniques in structural engineering. \\nfurther, section 6 identifies potential research avenues and emerging trends for using the noted ai \\nmethods in future innovations, while highlighting the current limitations of such methods. finally, \\nconclusions are provided in section 7. \\n2.research method\\nthe present study used content analysis [21] to select the reviewed literature. content analysis is \\ncommonly used to objectively make valid inferences according to collected data with the aim of \\ndisclosing central aspects of previous studies. it further allows for qualitative and quantitative operations. \\nas a result, content analysis is able to provide an inclusive disclosure of ai applications in structural \\nengineering, leading to reliable results from the study.  \\nsample collection was performed in this study through the search and selection of peer-review ed \\narticles. articles were collected from prominent and well-accepted academic databases. the procedure of \\nliterature search and selection for this study can be summarized as follows: \\n\\uf0b7the academic databases web of science , scopus , science direct , asce library , engineering\\nvillage , wiley online library , sage , and emerald  were used for article search and selection.\\n\\uf0b7keywords such as “artificial intelligence ”, “artificial intelligence in civil and structural\\nengineering ”, “pattern recognition structural engineering ”, “machine learning structural',\n",
       " '  \\n4 engineering ”, “deep learning structural engineering ”, “convolutional neural networks \\nstructural engineering ”, and “ computational intelligence ” were used to search the databases. \\nthis resulted in the identification of academic articles concerning the application of ai methods \\nin structural engineering. the time period under review was from 2009 to 2017, which led to the \\nidentification of approximately 430 candidate articles. \\n\\uf0b7the criteria for selecting the identified articles was the application of pattern recognition,\\nmachine learning, and deep learning in structural engineering. in accordance with such criteria, a\\ntwo-round article selection technique was employed. that is, titles, abstract, and keywords of\\nthe noted articles were checked in the first round to ascertain if they me et the criteria. the\\nsecond round consisted of reading and analyzing the entire article, thus ensuring that all of the\\nselected papers were closely related to the review objective. finally, 284 articles were selected\\nand used for the present review.\\nfor the review, qualitative and quantitative analyses were performed to identify the applications of \\nemerging ai methods in structural engineering , the ai algorithms used for such applications , and analyze \\nthe applicability of these algorithms for the noted applications. this approach led to the identification of \\nthe most promising applications of emerging ai techniques and future research directions.    \\n3.overview of artificial intelligence\\nin general, there are two types of machine intelligence: hard computing and soft computing methods. \\nhard computing, which is based on binary logic, crisp systems, and numerical analysis, requires a \\nprecisely stated analytic al model and is capable of producing precise answers. soft computing differs \\nfrom conventional computing in that, unlike hard computing, it can deal with ambiguous and noisy data, \\nincorporates stochastic information, and allows parallel computations. soft computing is based on fuzzy \\nlogic, neural nets, and probabilistic reasoning; where the methods are able to evolve their own programs \\nand yield approximate answers [22] .  \\nsoft computing is commonly considered a synonym of computational intelligence (ci). in fact, ci or \\nsoft computing can be expressed by the capability of a computer  to learn a specific task from sample data \\nor experimental observation. mathematical or conventional modelling are useless in many complex real-\\nlife problems due to factors such as: complexity of the processes for mathematical reasoning, \\nuncertainties during the process, and the stochastic nature of the process. the set of nature- inspired \\ncomputational techniques defining ci provides solutions for such problems [23] . ci uses a combination of \\nsupplementary techniques such as artificial neural networks, fuzzy logic, learning theory, evolutionary \\ncomputing, and probabilistic methods, and is capable of solving and approximating nonlinear problems \\nwhile introducing human knowledge into the areas of computing.  \\nartificial intelligence (ai) is essentially defined as the ability of a machine to mimic intelligent human \\nbehavior, thus seeking to use human-inspired algorithms for approximating conventionally defiant \\nproblems. the main goals of ai research involve knowledge representation, reasoning, automated \\nplanning, learning, natural language processing, perception, robotics, and general intelligence [24–28] . \\nalthough ai and ci/soft computing pursue a similar goal, there is a slight difference between them. \\naccording to bezdek [24], ci is a subset of ai. it is also important to distinguish ai from data science \\nand big data . there is indeed a substantial overlap among these methods. data mining/science is a cross-\\ndisciplinary field used to discover valuable insights and trends in a data set. data mining techniques focus ',\n",
       " '5 on the discovery of unknown properties in an area where there is limited knowledge. the data set, on the \\nother hand, is called big data if it is big in terms of volume (i.e., number of data points or features per data \\npoint), velocity (i.e., large portions of data arriving in a small amount of time for analysis and mining), or \\nvariety (i.e., different types of data such as text, speech, images, etc.). big data thus refers to large or \\ncomplex data sets that are difficult to represent using conventional data processing techniques.  machine \\nlearning, a subfield of ai, is used to design a model to learn the trends, thus focusing on prediction based \\non known properties learned from the training data. deep learning, a subset of machine learning, is a tool \\nthat concentrates on learning the representations and features of the data . figure 1 schematically presents \\nthe noted different intelligent techniques and their correlation. \\nfigure 1.  illustration of the interrelation of different intelligent computational techniques  \\nin the field of structural engineering, there are numerous problems that are influenced by uncertainties , \\ne.g., those related to design, analysis, condition monitoring, construction management, decision making,\\netc. such problems need mathematics, physics, and mechanics calculations to be solved, and their\\nsolution strongly depends on the practitioners’  experience. it can be further said that computers are yet to\\nbe fully utilized for many tasks. this is essentially because of the need for logical reasoning, problems\\ntend to be unique, feasibility constraints, and the need to use prior experiences in the analysis and design\\nprocess. however , ai techniques can be effectively used to enhance these efforts and can also be\\nconsidered to check the general validity of laboratory or field test results. ai methods can also help\\nminimize (and potentially avoid) time-consuming laboratory or field tests to determine design parameters.\\nuncertainties are an unavoidable part of structural engineering problems. for example, in seismic \\ndesign earthquake demands are not known with precision . in structural health monitoring there are \\nuncertainties in the amplitude of the input excitation, measurement noise, and spatial density of \\nmeasurements. many uncertainties also exist in the models used to predict structural response, as well as \\nthose defining constitutive behavior . geotechnical information for foundation design purposes is \\ndetermined with limited information and/or based on laboratory tests with high levels of uncertainty. all \\nof the aforementioned problems can be modeled and treated as uncertainties [29]. ai is able to deal with \\nsuch uncertainty problems. for instance, ai methods have been used to solve uncertainty problems \\ndefined within the context of damage detection and system identification using finite element model \\nupdating [30] . model updating can be used to identify physical parameters (e.g., stiffness of a structural \\ncomponent) for which a reduction in value is taken to indicate damage. however, such reduction may be \\nsimply due to statistical uncertainty. thus, it is of importance to compute the uncertainty of the estimation \\nto distinguish whether the reduction of a parameter is due to actual damage . the use of ai methods can \\n',\n",
       " '  \\n6 also result in significant time and cost savings, as well as increasing computational efficiency in many \\nstructural engineering tasks. \\nmany of the ai branches, such as machine learning (ml), pattern recognition (pr), neural networks, \\nfuzzy logic, evolutionary computation , deep learning (dl) , expert systems, probability theory, \\ndiscriminant analysis, swarm optimization, metaheuristic optimization, and decision trees, have been used \\nin structural engineering. the number of research publications showing the use of these ai methods in \\nstructural engineering over the last decade is presented in figure 2. as can be seen, the use of most \\nmethods has increased during the last decade. nevertheless, the number of studies featuring techniques \\nsuch as evolutionary computation, fuzzy logic, and expert systems has not had a notable change. even \\nthough the use of neural networks has drawn a great attention from researchers, new studies on the use of \\nsuch method has also remained rather constant over the last decade. in contrast, the significant increase in \\nstudies featuring the use of ml and pr is evident. further, deep learning architectures, e.g., convolutional \\nneural networks (cnns), are gaining remarkable attention among the research community over the last \\nfew years. these observations motivated the authors to concentrate this review on ml, pr, and dl, as \\nthey are emerging as the new computational intelligence paradigms in structural engineering. \\nfigure 2.  research publications on the use of different ai branches in structural engineering \\n',\n",
       " '  \\n7 4.emerging ai methods\\nas previously discussed, pattern recognition, machine learning, and deep learning are among the new \\nartificial intelligence methods that are increasingly emerging as reliable and efficient tools in the field of \\nstructural engineering. this section provides technical background on the noted methods and insight \\nregarding the use of such algorithms for structural engineering problems.  \\n4.1. pattern recognition \\npattern recognition (pr) is a technique in which the main goal is to classify objects into a number of \\nclasses or categories. the objects , depending on the applications, could be images, signals, hand writing , \\nspeech, or measurements to be classified [31,32]. in pr, a pattern is represented by a set of features. \\nconcepts from statistical decision theory are used t o establish decision boundaries between pattern \\nclasses. the recognition system in pr consists of two modes, namely learning (training) and classification \\n(testing), as shown in figure 3. in the learning/training mode the proper features for representing the input \\npatterns are discovered by means of the feature extraction/selection module, and the classifier is \\ntrained/calibrated to partition the feature space. in the classification mode the input patterns are assigned \\nto one of the classes using the trained classifier; while the performance of the designed classifier, i.e., \\nclassification error rate, is evaluated by the system evaluation module.  \\nfigure 3.  schematic of a pattern recognition system \\nin general, pr methods can be categorized into two main categories: supervised  pr and unsupervised  \\npr. the supervised  term refers to the condition when a set of labeled training samples are available. \\nwhen there is no prior information regarding the class labels and the training data are not labeled, this is \\nknown as unsupervised  pr, or clustering. these terms are further discussed in the following section. \\nanother difference in pr methods is that of generative  models versus discriminative  models. if the aim is \\nto discover the distribution of patterns in the model, this denotes the generative models in pr. the task \\nfor this case is to find out how the patterns can be modeled in the class. in this regard, the density function \\nneeds to be determined based on training data. on the other hand, the goal in discriminative  pr models is \\nto determine the model that discovers the decision boundary, thus learning the function and parameters of \\nthe decision boundary. generative and discriminative pr models along with the algorithms used are \\nshown in figure 4. \\n',\n",
       " '8 figure 4.  tree structure of generative and discriminative pattern recognition models and algorithms \\n4.2. machine learning \\nmachine learning (ml) is a major subfield of artificial intelligence (ai) (see figure 1) dealing with the \\nstudy, design, and development of algorithms that can learn from the data itself and make predictions \\nusing learned data [33 –36]. in fact, ml refers to the capability of computers to learn without being \\nexplicitly programmed. ml based models can be predictive or descriptive to achieve knowledge from the \\ndata [37,38]. the scope and potential of ml is much more general than other ai methods, although it is a \\nsubset of ai and used in various disciplines ; including computer science, information theory, control \\ncomputational complexity, probability and statistics, financial market, and theory and philosophy [35]. it \\nis of importance to differentiate ml from other similar ai subsets including pattern recognition (pr) and \\ndeep learning (dl). in general, pr and ml are closely related areas, as they fundamentally overlap in \\ntheir scope. however, pr deals with methods for classification tasks, while ml focuses on algorithms \\nutilized for learning. in fact, the major task of pr is recognition of patterns in data and to classify them, \\nand it does not necessarily imply learning. ml systems, on the other hand, are designed to learn by \\nthemselves. further, dl is considered a subset of ml (see figure 1) , in which the system has the ability \\nto learn features from the data. deep learning, in fact, is a tool to learn the representation of data. once \\nthe representation is determined, the ml problem can be solved. indeed, deep learning transforms a \\nproblem/representation with high dimensionality to a lower dimension al representation. depending on the \\nresources of the training dataset, ml can be categorized as supervised, unsupervised, or reinforcement \\nlearning [33,36].   \\n4.2.1. supervised learning \\nthe goal of supervised learning is to build a model/function to accurately predict the unknown target \\noutput of future examples. training samples in supervised learning are labeled and the key characteristic \\nof the learning is the existence of a teacher  that provides a cost or category label for each pattern in a \\ntraining dataset, thus seeking to decrease the added cost for these patterns. if the objective of the ml \\nmodel is to forecast continuous target variables, the task is said to be regression . however, if the aim is to \\npredict discrete target variables the task is known as classification .    \\n',\n",
       " '  \\n9 4.2.2. unsupervised learning \\nthe objective of unsupervised learning is to separate the training dataset into clusters such that the data in \\nall clusters exhibits a high level of proximity. unlike supervised learning, the labels for data are \\nunavailable and there is no explicit teacher. thus, the system itself forms the clusters f rom the input \\npatterns.   \\n4.2.3. reinforcement learning \\nin reinforcement learning, or learning with a critic, no information is given regarding the desired category \\nsignal or explicit goals. reinforcement algorithms are forced to learn optimal goals through trial and \\nerror. in fact, in order to maximize the model’s performance, reinforcement learning allows an agent to \\ndetermine the ideal behavior within a specific context. agents receive a numerical reward as a \\nreinforcement signal encoding the success of an action’s outcome. the goal for the agent is then to learn \\nto select actions maximizing the accumulated reward over time.    \\nfigure 5.  machine learning categories with commonly adopted algorithms \\nrecent research reveals the successful practical applications of ml in different fields, such as: \\ncomputer vision and image processing [39–44], speech recognition [45–50], computational finance [51–\\n53], energy production [54–56], and computational biology [57 –59]. in a machine learning domain an \\nalgorithm has to be developed to solve problems. different methods from various fields have been \\n',\n",
       " '10 adopted for such a purpose [60,61]. therefore, ml enables exploiting the interaction form all these fields, \\nwhich in turn leads to robust solutions using various domains of knowledge. figure 5 illustrates some of \\nmost prominent algorithms used in the ml domain.  \\n4.3. deep learning \\ndeep learning (dl), a branch of machine learning, is composed of networks that can learn unsupervised \\nfrom unstructured/unlabeled data. dl architecture aims to learn the feature representation of the input \\ndata. in fact, dl is based on deep neural networks, i.e., neural networks with more than one hidden layer . \\nin such an architecture, increasing the number of layers results in a deeper network . examples of dl \\narchitectures include convolutional neural networks (cnns), recurrent neural networks (rnns), \\nautoencoders, deep belief nets, etc. among these, cnns are the dl architectures that have gained the \\nmost attention among the structural engineering community during last few years. cnn s are inspired by \\nthe visual cortex of animals [62] . they have been mainly used in computer science and engineering for \\nimage recognition [63 –68]. unlike standard neural networks, cnns are capable of capturing the 2d \\ntopology of pixels, while demanding fewer computations because of a pooling process and sparsely \\nconnected neurons. further, cnns are able to simultaneously extract and learn optimal features from the \\nraw data. recent studies [69,70] have demonstrated that cnns can outperform conventional artificial \\nintelligence methods in both accuracy and speed. generally, cnns leverage the following ideas: local \\nconnectivity, parameter sharing, and pooling/subsampling of hidden units. the network consists of three \\nlayer types, namely convolution, pooling, and fully connected layers. cnns alternate between the \\nconvolutional and pooling layers and the output is a fully-connected layer with a nonlinear classifier , e.g., \\nsoftmax classifier, thus estimating the conditional probability of each class. to introduce nonlinearity in \\nthe cnns, a rectified linear unit (relu) is typically used as a nonlinear activation function. in addition, \\namong the different optimization algorithms, gradient descent algorithms are mainly used to train cnns. \\nthe basic components of cnns are described in the following sub-sections. a schematic of a cnn \\narchitecture for image recognition is presented in figure 6 , where the network consists of three \\nconvolutional layers, three pooling layers, and three fully connected layers . for all layers in the network, \\nrelu is used as the activation function. further, a softmax loss layer is appended to the fully connected \\nlayers for each classification task.  \\nfigure 6.  schematic of a typical cnn architecture \\n',\n",
       " '11 5.applications\\n5.1. pattern recognition \\nduring the last decade, there has been a growing interest in the application of pattern recognition (pr) to \\nstructural engineering for purposes such as structural health monitoring (shm)/damage detection, \\nearthquake engineering and seismic design, structural reliability, structural identification, and \\nperformance evaluation. this activity is illustrated in figure 7 and a listing of works is summarized in \\nchronological order (i.e., date of publication) in table 1 . the applications are classified with respect to the \\ndomain/problem type, the case structure, and the ai method/algorithm used for pr. the classification \\nreveals that the most common use of pr in structural engineering has been for shm and damage \\nidentification. \\ntwo main approaches are commonly considered for damage detection: the inverse approach, known as \\nsystem identification, and the forward approach, which relies on extracting information from the \\nmonitored structure. the computational complexity of the inverse approach, along with the physical \\nimportance of model updating, have motivated researchers to investigate methods from the second type of \\napproach (forward) [71]. therefore, pr is being most frequently utilized in the context of a forward \\napproach for damage detection and shm.  \\naccording to sohn et al.  [72], sensors measuring strain and vibration of a structure produce signals \\nresponding to the variation of environmental and operational conditions. each group of signals can be \\nconsidered as a pattern having a relationship with structural and ambient environments. the change in \\nphysical properties, mainly stiffness, is then reflected on the processed signals or patterns. thus, the \\ninterpretation of signals/patterns can be performed by pr. the idea of using statistical pr for shm was \\nintroduced by farrar et al.  [73,74]. statistical pr can be described as collecting and processing data from \\nsensors mounted on the structure to remove/filter environmental effects. in this context, statistical pattern \\ncomparison and statistical model development methods have been used to evaluate structural condition \\n[75,76] . most of the studies that focus on the application of statistical pr on shm are based on the \\ncombination of time series modeling with a statistical detection method, such as outlier detection. as a \\nresult of using such methodologies only data from the undamaged structure is required in the \\ntraining/calibration phase [77] . sohn et al.  [75,78] casted shm within the context of statistical pr. for \\nthis purpose, they adopted autoregressive models and outlier analysis with the mahalanobis distance \\nmeasure to extract features and construct a reliable statistical model to assess structural conditions of the \\nboat. farrar and sohn [79] studied the applicability of statistical pr for vibration-based shm and \\ndescribed the relevant steps for such process.  worden et al.  [80] adopted the methods of outlier analysis \\nto the problem of damage detection, for which they used the mahalanobis distance in order to detect \\ndamage. further, manson and worden [81–83] studied the effectiveness of statistical pr using auto-\\nassociative neural networks, outlier analysis, and density estimation through numerical and experimental \\ntests for shm of an aircraft wing panel. they proved the applicability of the proposed statistical pr \\ndamage detection approach through these tests . in addition, nair and kiremidjian [84] introduced a time \\nseries algorithm based on an autoregressive moving average model for damage assessment of a \\nbenchmark structure, where they showed that the algorithm was able to identify and localize small to \\nsevere levels of damage. the authors also used a gaussian mixture model to model the feature vectors \\nand incorporated it with a time series-based damage detection algorithm for shm [85]. they concluded \\nthat the proposed framework is useful, especially when several measurements can be used for robust ',\n",
       " '12 damage identification. cheung et al.  [86] also studied the applicability of statistical pr for shm of real-\\nlife structures , namely a bridge, for which they used autoregressive models. these studies have shown \\nthat by using statistical methods a single vibration signal can be analyzed separately from all other signals \\naccumulated in the structure, thus allowing damage detection algorithms to be embedded at the sensor \\nlevel. this results in significant savings in power and computational time, which are essential for the \\nimplementation of a wireless sensor network.    \\nfigure 7.  research publications on the use of machine learning and pattern recognition \\nan shm procedure cast within a statistical pr context is implemented in four phases [75]: (i) \\noperational evaluation, (ii) data acquisition and networking, (iv) feature selection and extraction, and (v) \\nstatistical model development and discrimination. according to the recent literature, several studies \\nconcerning applications of pr in shm have addressed all of these four phases. regarding the operation \\nevaluation phase, numerous techniques have been studied that are either based on linear or non-linear \\nregression models among actions and effects [87], or based on latent variable techniques. posenato et al.  \\n[88] proposed methodologies for model-free data analysis using moving principal component analysis\\n(pca) and robust regression analysis to identify and localize anomalous behavior in civil structures. zhou\\net al.  [89] introduced an approach to reconstruct input to back-propagation neural networks used for\\nmodeling the temperature-caused modal variability with long-term monitoring data. in addition, a\\ntechnique based on symbolic data analysis for classifying the structural behavior of railway bridges was\\ndeveloped by cury et al.  [90]. the method was shown to be efficient to discriminate structural\\nmodifications based on vibration data. further, a data-driven strategy integrating pca, symbolic data, and\\ncluster analysis was proposed by santos et al.  [91], where the method was demonstrated to be effective\\nfor early-damage detection. to take into account the effect of environmental conditions, e.g., temperature,\\nhumidity, dead load redistribution effects, etc., for damage detection of bridge structures, hsu et al.  [92]\\nperformed nonlinear pca using an auto-associative neural network. they showed that the approach is\\ncapable of dealing with both non-increasing features (stiffness) and non-decreasing features (damage\\nindex).\\n',\n",
       " '  \\n13 methods having the ability to extract and fuse information from data in a sensor network are mainly \\nbased on autoregressive models, time frequency analysis, modal analysis, or pca. lautour et al.  [93] \\npresented a damage classification approach using time series analysis and pr, in which artificial neural \\nnetworks (ann) were used to determine the coefficients of the autoregressive models. results suggest \\nthat ann and autoregressive models are efficient tools for damage estimation. additionally, an shm \\nstrategy employing cepstral features as damage sensitive parameters was proposed by balsamo et al.  [94] \\nfor which the squared mahalanobis distance was used. a decentralized damage detection approach using \\nsignal analysis (wavelet transform) based on wireless sensor data was developed by yun et al. [95], while \\nkesavan et al.  [96] proposed a wavelet-based damage diagnosis algorithm based on the combination of \\npca and wavelet transform. results revealed that both approaches were able to consistently detect and \\nquantify damage. further, most works related to statistical model development report the use of a \\nstatistical process control [97,98]. however, some of these methods are based on learning algorithms, i.e., \\nsupport vector machines, neural networks, decision trees, and clustering algorithms [91,99] .  \\nnumerous algorithms, including autoregressive models, artificial neural networks (anns), support \\nvector machine (svm), etc., have been adopted and used for pr in structural engineering discipline. \\nautoregressive models have been extensively considered for feature extraction in numerous studies \\nconcerning the use of pr in structural engineering. kiremidjian et al.  [86,100] used autoregressive \\nmodels for shm of bridge structures. they demonstrated that damage detection algorithms based on pr \\nmethods can effectively detect structural damage. gul et al.  [77] and yao et al. [101] utilized \\nautoregressive models with a mahalanobis distance-based outlier detection algorithm for damage \\ndetection in civil structures. these studies showed the superior performance of the proposed algorithms in \\nterms of identifying damage with high-dimensional data sets. in addition , anns have been widely \\nadopted for structural engineering applications, e.g., shm and damage detection. ng et al.  [102,103] \\nincorporated an ann with a bayesian method for health assessment of a four-story steel frame structure. \\nanns have also been integrated with svm and pca, a method for dimensionality reduction, to develop \\npr-based damage detection techniques in civil structures. as a further example on the application of such \\npr methods in structural engineering, radhika et al. [104] proposed a wavelet-based change detection \\nmethod in which damage buildings are recognized using wavelet-extracted statistical feature and \\nclassification using ann and svm. they proved that the proposed damage classification method was \\naccurate compared to methods employing conventional feature extraction. further, they showed that svm \\noutperformed ann in terms of damage classification accuracy. svm has also been integrated with ann \\nfor supervised learning classification [105] in structural modification assessment using vibration data \\nfrom a bridge structure , and the method was found to be effective for continuous monitoring. as \\npreviously noted, pca has been utilized and adapted for damage detection based on pr. an approach for \\ndamage detection in plate structures using a multi-layer perceptron network, in which pca was utilized to \\nretain the principal features, has been proposed [106]. also, bandara et al.  [107] introduced a frequency \\nresponse based damage detection method using a combination of pr and pca. ramos et al.  [108] \\npresented a methodology employing a bayesian data fusion technique for non-destructive and destructive \\nstructural damage detection. they showed that the proposed method, within the context of pr, is able to \\ndecrease uncertainties for structural parameter estimation.  \\nrecently, perez et al.  [109] introduced a hierarchical nonlinear pca method for damage diagnosis in \\nwind turbine blades. the authors demonstrated the effectiveness of the methodology based on strain \\nmeasurements and pr for shm. further, alavi et al.  [110] proposed a damage assessment approach ',\n",
       " '  \\n14 based on probabilistic neural networks and bayesian decision theory, where they proved that the \\nsupervised classification method can be utilized for shm purposes. in addition, loh et al.  [111] proposed \\nan shm methodology for damage identification and localization based on pca, and investigated the \\napplicability of the proposed pr method on a steel tower structure. salehi et al. [112– 114] presented an \\nimage-based pr approach based on integrating anomaly detection and a bayesian method. they also \\nutilized a nearest neighbor classifier, along with a two-dimensional principal component analysis and a \\ntwo-dimensional linear discriminant analysis (well-established feature extraction techniques), for shm in \\nplate-like structures. additionally, datteo et al.  [115] proposed a statistical pr approach integrating \\nautoregressive models and principal component analysis, and explored the applicability of such approach \\nfor long-time health monitoring of large-scale structures. zhou et al.  [116] also introduced a damage \\ndetection technique using a cosine similarity measure. the authors demonstrated that the presented pr-\\nbased method can be effectively used in the context of shm.  \\nthe research studies noted above indicate the significance of pr in structural engineering. \\nnevertheless, an in-depth analysis of some of the highest cited publications was performed to further \\ninvestigate the ir contributions and limitations. lautour et al.  [117] proposed a damage assessment method \\nusing autoregressive (ar) models in which the computational burden of the approach was lessened by a \\ndimensionality reduction technique (i.e., pca). the authors showed that the ar coefficients form \\nseparable clusters by increasing the number of principal components, leading to good classification \\naccuracy. zhang et al.  [118,119] introduced a structural identification method employing pr and support \\nvector regression (svr). svr was integrated with autoregressive time series analysis for linear and \\nnonlinear structural parameter identification (for damage detection) with vibration data of a five-floor \\nstructure shaking table test. lautour et al. [120]  presented an approach using ann to predict seismic-\\ninduced damage on 2d reinforced concrete frames. relations between parameters that describe the \\nstructure, ground motion, and damage were modeled using ann. laory et al.  [121] developed a \\nmethodology to predict natural frequency responses of a suspension bridge with measurements of \\ntemperature, wind, and traffic loading, within the context of vibration-based shm. multiple linear \\nregression, ann, svr, regression tree, and random forest were used to distinguish changes in natural \\nfrequency due to structural damage and environmental variations, and the method ’s prediction accuracy \\nwas compared. bandara et al.  [107,122] proposed a damage detection method using frequency response \\nfunctions in which ann, pca, and frequency response functions were combined to detect various levels \\nof nonlinearity using identified patterns. the authors applied the algorithm to a three-story structure and \\ndemonstrated the method’s applicability for large amounts of data. tibaduiza et al.  [123] developed an \\nshm method in which pr, feature extraction, and sensor data fusion were examined with different \\ndamage indices. performance of the proposed approach using pca was tested for an aircraft skin panel \\nand turbine blade. the effectiveness of the approach was validated; yet, the effect of environmental and \\noperational conditions on the damage identification method was not considered. as a final example, \\nelwood et al.  [124] proposed an approach based on fuzzy pr for seismic damage detection in concrete \\nstructures. the input to the fuzzy classifier was post-earthquake building damage data to determine the \\nexistence of building damage patterns. it follows that the noted studies highlight the emerging \\napplications of pr in structural engineering. reference  domain  case structures  ai method used  for pr  ',\n",
       " '  \\n15 table 1.  applications of pattern recognition (pr) in structural engineering  [125]  shm  flexible risers  statistical pr based on time series \\nanalysis  \\n[86,100]  shm  bridge structure  autoregressive models  \\n[117] damage detection bookshelf structure autoregressive models with principal \\ncomponent analysis (pca)  \\n[126] failure mechanismfiber -reinforced polymer  \\n(frp) structures  self-organizing map  \\n[127]  seismic damage\\ndetection  frame structure  artificial neural networks  (ann)  \\n[118,119]  structural identification  five-story structure resting on \\nshaking table  support vector regression and \\nautoregressive time series model  \\n[102,103]  shm  four -story steel frame  bayesian method incorporated with \\nann  \\n[128,129]  damage detection  four -story steel frame  artificial immune pr method  \\n[77] shm  steel grid structure and simply \\nsupported steel beam  autoregressive model with \\nmahalanobis distance -based outlier \\ndetection  \\n[120]  shm  reinforced concrete frames  ann  \\n[130]  shm  railroad steel structure  outlier analysis with mahalanobis \\nsquared distance  \\n[131,132]  damage detection  three -story steel frame and a \\nbookshelf structure  nearest neighbor classifier and learning \\nvector quantization  \\n[90] structural modification \\nassessment  bridge structure  clustering techniques (unsupervised \\npr) \\n[89] modeling temperature -\\ncaused modal variability  bridge structure  back -propagation neural networks  \\n[133,134]  damage detection  prestressed reinforced concrete \\nbeams  statistical pr based on the  mahalanobis \\nand eu clidean distance decision \\nfunctions  \\n[135] seismic performancereinforced concrete water \\ntanks  statistical pr  \\n[88] shm  beam structure  principal component analysis and \\nrobust regression analysis  \\n[93] damage detectionthree -story steel frame and a \\nbookshelf structure  artificial neural networks  \\n[136]  shm  simply supported steel beam  statistical pr based on an  \\nautoregressive model  \\n[101] damage detection bridge slab and space truss  statistical pr based on an  \\nautoregressive models  \\n[137] earthquake engineering earthquake risk evaluation  feed -forward multi -layer neural \\nnetwork  \\n[96] damage de tection asce benchmark structure  pca  reference  domain  case structures  ai method used  for pr  ',\n",
       " '  \\n16 [138] damage detection three -story steel structure  statistical pr  \\n[139] damage detection cantilever plate  feed -forward multi -layer neural \\nnetwork  \\n[76] shm  bridge structure  statistical pr  based on a pattern \\ncomparison approach  \\n[140] failure detection posttensioned concrete beam  statistical pr based on a mul tivariate \\noutlier analysis  \\n[98] shm  psc box girder bridge  symbolic clustering method  \\n[141]  shm  bridge structure and simply \\nsupported beam  support vector machines (svm) and \\nneural networks  \\n[142]  shm  bridge structure  sparse representation and fourier \\ndiscriminant method  \\n[91] damage detection bridge structure  principal component analysis (pca) \\nand symbolic data clustering  \\n[143–145] damage detection  bridge structure  supervised statistical pr  \\n[146] performance evaluationpretensioned pres tressed \\nconcrete members  feed -forward neural regression  \\n[147]  shm  cable -stayed bridge structure  pca  and mahalanobis squared distance  \\n[148]  shm  aluminum beams  bayesian approach  \\n[121]  shm  suspension bridge structure  artificial neural networks, support \\nvector regression, random forest, \\nregression tree  \\n[106] damage detection plate structures  multi -layer neural network an d pca  \\n[149] damage detectionthree -story prototype building \\nstructure  unsupervised pr based on an outlier \\nanalysis  \\n[150]  shm  steel reinforced concrete \\nstructure  statistical pr with autoregressive \\nmodels  \\n[107] damage detection two-story frame structur e artificial neural network (ann) wit h \\npca  \\n[151] performance evaluation steel beam structure  statistical pr  \\n[108]  non-destructive \\nevaluation  concrete structure  bayesian fusion model  \\n[104] damage detection building structures  ann  and svm  \\n[105]  structural modification \\nassessment  simply supported steel beam  bayesian decision trees, neural \\nnetwork, and svm  \\n[94,152]  shm  four -story steel frame  statistical pr based on a mahalanobis \\nsquared distanc e \\n[122] damage detection three -story building structure  ann  \\n[153] damage detection steel beams  ann  \\nreference  domain  case structures  ai method used  for pr  ',\n",
       " '17 5.2. machine learning \\nmachine learning (ml) methods have been increasingly adopted over the last decade for modelling real-\\nworld problems concerning structural engineering (see figure 2). this is because of their enormous \\ncapacity to capture relations among input and output data that are nonlinear or complicated to formulate \\nmathematically . the first uses of ml techniques in structural engineering have dealt with problems such \\nas the development of management tools for structural safety [163], and information acquisition for the \\ndesign of steel members [164] . in general, ml methods have been used for shm and damage \\nidentification, optimization, performance evaluation, structural reliability and reliability assessment , and \\nstructural parameter identification (e.g ., modeling material properties of concrete). among these, shm [110]  shm  bridge gusset plate  probabilistic neural networks and \\nbayesian approach  \\n[71,154]  damage detection  cable -stayed bridge structure  statistical pr based on a mahalanobis \\nsquared distance  \\n[124]  seismic damage \\ndetection  concrete structures  fuzzy pr  \\n[112–114] shm  plate -like structures  bayesian method, nearest neighbor, \\ntwo-dimensional principal compone nt \\nanalysis (2dpca), and two -\\ndimensional linear discriminant analysis \\n(2dlda)  \\n[155] risk-based management bridge structures  statistical pr  \\n[156] damage detection cable -stayed bridge structure  multi -layer perceptron neural network  \\n[157]  shm  plate -like structures  k-nearest neighbor method\\n[158] damage detection steel grid structure  artificial neural network (ann) and \\nself-organizing maps (som)  \\n[111] damage detection steel tower structures  principal component analysis (pca)  \\n[123] damage detection aircraft skin panel  pca  \\n[159]  shm  composite cantilever beam  neural network with back propagation \\nbased learning mechanism  \\n[160]  shm  truss bridge and two -story \\nframe structure  pca  and frequency response function  \\n[109] damage detection wind turbine blades  hierarchical nonlinear principal \\ncomponent analysis  \\n[115]  shm  stadium structure  autoregressive models with principal \\ncomponent analysis  \\n[161] damage detection bridge structure  statistical pr  \\n[116] damage detection three -story frame structure  cosine similarity measure  \\n[162]  shm  steel beam  principal component analysis  ',\n",
       " '18 and concrete property modeling are the uses to attain most attention during the last decade. this can be \\nseen in figure 7 and a listing works organized by year of publication is provided in table 2. \\n5.2.1. structural health monitoring and optimization \\nshm involves monitoring of a structure through data collected from sensors, extracting damage sensitive \\nfeatures, and interpreting the extracted features for condition assessment of the structure. significant \\nprogress has been made over the past two decades in the development of shm models for different kinds \\nof structures . the numerous studies carried out in this field can be categorized as model-driven and data-\\ndriven approaches [165 –167]. a model-driven approach uses a numerical model of the structure , e.g., \\nbased on the finite element (fe) method, that correlates inconsistencies between the measured and model-\\ngenerated data for damage detection. although numerous studies have been conducted to develop model-\\ndriven approaches, these methods suffer from several shortcomings. first, the approach is \\ncomputationally inefficient because it requires an iterative analysis of a computer simulation model. \\nsecond, results obtained from the simulation might not be accurate enough for precise evaluation of the \\nstructure. by contrast, in a data-driven approach the model is created through the learning gained from \\nmeasured/sensed data. damage can thus be detected by conducting a comparison among the measured \\ndata and a model. in fact, a data-driven model uses information from previously collected sensor data \\n(i.e., training data). it is worth pointing out that data-driven approaches are beneficial if: (i) large volumes \\nof data exist, (ii) the physical characteristics of the structure are unknown or complicated to model, and \\n(iii) the aim is to decrease the computational effort.\\na data-driven approach commonly adopts techniques from pattern recognition (pr) and machine\\nlearning (ml). ml in the context of shm is expressed as creating knowledge from previous experiences, \\nlearning the model parameters, and then focusing on predicting new input data. different learning \\nschemes, such as supervised and unsupervised learning, have been used in shm applications. algorithms \\nincluding artificial neural networks (anns) [168] , support vector machine (svm) [169] , k-nearest \\nneighbor method ( k-nn) [170], principal component analysis (pca) [123], and low-rank matrix \\ndecomposition [171] are attractive for structural damage identification within the context of ml due to \\ntheir effectiveness and robustness while dealing with insufficient information, noise, and uncertainty. as \\nmentioned before, there has been a growing interest in the use of ml for shm models during the last \\ndecade. as an example, figueiredo et al.  [172] investigated anns, mahalanobis distance, singular value \\ndecomposition techniques, and factor analysis to study environmental variability and its effect on damage \\ndetection in civil structures. they used a three-story frame structure as a case study to obtain time-series \\ndata from accelerometers, and the data was fed into different ml algorithms. they showed that the \\nmahalanobis distance provided the best classification accuracy. dervilis et al. [173] investigated the shm \\nof wind turbine blades using neural networks. yan et al.  [174] reported on the use of a back-propagation \\nneural network and svm for damage assessment in beams mounted on ocean platforms. butcher et al.  \\n[175] examined the use of anns and extreme learning machine methods for shm in mesh-reinforced\\nconcrete structures. the study revealed that these algorith ms can outperform traditional ann methods.\\nliu et al.  [176] studied svm for damage detection of a long span cable-stayed bridge and demonstrated\\nthat svm is more accurate compared to a back-propagation neural network. gui et al.  [169] presented a\\ndata-driven svm approach using optimization algorithms, i.e., grid-search and particle swarm\\noptimization, for damage diagnosis of a three-story frame structure. they proved that a genetic algorithm-\\nbased svm yields a better prediction than other methods. gong et al.  [177] also evaluated the\\napplicability of svm , random forest, and k-nn methods for earthquake-induced damage identification in',\n",
       " '  \\n19 buildings employing images. results showed that the proposed approach was capable of differentiating \\ncollapsed and standing buildings. lederman et al.  [178] used pca along with a kernel regression method , \\nwithin the context of signal processing and ml, for damage quantification and localization in bridges . \\nresults suggested that pca can be effectively used to decrease the dimensionality of the signal, while a \\nkernel regression can be employed to map the signals to the bridge condition. a wavelet svm-based \\nneural network metamodel for reliability analysis was proposed by dai et al.  [179] to expand the \\napplication of wavelet neural network to higher dimensions. the authors used a set of wavelet svm with \\nvarious resolution as the activation function of wavelet neural network, where they tested the applicability \\nof the proposed method on five-story structures, truss string structures, and cylindrical shell roof. further, \\ndiez et al.  [180] presented a clustering-based approach incorporated k-nn, k-means, and fourier \\ntransform for vibration signal processing to detect damage and abnormal behavior in bridge joints. the \\nclustering approach helped to group joints with similar behavior, increasing the shm performance. zheng \\net al.  [181] introduced a probabilistic classification framework using vibration measurements to assess the \\nprobability of barge collision damage on bridge piers, where bayesian inference combined with markov \\nchain monte carlo simulations and pca were used to extract the feature vectors from variations in modal \\nproperties due to damage. results revealed that the approach can be effectively used to determine the \\nprobability of structural damage locations. santos et al.  [182] proposed a hybrid approach based on \\ngaussian mixture models (gmm) to discover the normal state of a bridge, in which the gmm parameters \\nwere estimated through a hybrid method based on an expectation-maximization algorithm. results \\nconfirmed that the proposed algorithm was more stable than other genetic algorithms in terms of damage \\ndetection performance. a model-free damage assessment method based on ann was presented by neves \\net al.  [183] for shm of bridges. the ann was trained with an unsupervised learning algorithm using \\naccelerations from a bridge, the prediction errors were characterized using a gaussian process, and \\ndamage indices were compared with a threshold to identify damage. the noted studies highlight the \\nimportance of ml for data-driven shm and damage assessment techniques.  \\nrecently, a new class of ml methods, namely low-rank matrix decomposition and singular value \\ndecomposition, having the ability of dealing with sparse and incomplete data have been adopted by the \\nshm community. structural response measurements from mounted sensors can be represented as a data \\nmatrix. these measurements possess a low-rank structure and sparsity nature, which can be processed by \\nemerging mathematical tools such as sparse representation and low-rank matrix decomposition. salehi et \\nal. [170] presented a machine learning framework for health monitoring of an aircraft stabilizer based on \\nthe integration of low-rank matrix decomposition and k-nn techniques. they validated the proposed \\napproach through the interpretation of self-powered wireless sensor data generated from a network \\ncommunication protocol using energy-efficient pulse switching technology [184] . the authors further \\nemployed low-rank matrix decomposition and statistical methods for health monitoring and localized \\ndamage identification in plate-like structures, and used a data fusion concept to combine the information \\nobtained from a network of self-powered sensors [185] . nagarajaiah et al.  [171] presented a new \\nparadigm for damage detection based on modelling and harnessing sparse and low-rank data structures . \\nthey demonstrated that the proposed method is able to effectively address structural dynamics, \\nidentification, monitoring, data sensing and management problems. yang et al.  [186,187] also utilized \\nlow-rank matrix decomposition along with nuclear-norm-minimization methods for recovering structural \\nvibration responses from a steel tower and a cable-stayed bridge . the authors developed a global \\ncomputational approach to analyze sparse sets of 2d strain measurements for damage localization. the \\nproposed data-driven approach increased the effectiveness of shm when limited numbers of strain ',\n",
       " '  \\n20 sensors were deployed. the studies discussed in this paragraph show the u se of numerous types of ml \\nalgorithms for assessing structural health; and that under specific circumstances these methods can \\noutperform model-driven approaches while being satisfactorily accurate. \\nwithin the context of optimization, ml has been used for infrastructure maintenance and durability \\nassessment . yepes et al.  [188] proposed a cognitive method for selecting an optimal solution for the \\nmulti-objective optimization of high-strength reinforced concrete beams, where different minkowsky \\nmetrics were used for the optimization task . garcia-segura et al.  [189] presented a reliability-based \\nmethod employing a modified harmonic search algorithm to optimize the design of post-tensioned \\nconcrete box-girder bridges under corrosion attack. the authors demonstrated that lower life-cycle cost is \\ncorrelated to designs with longer corrosion initiation time . the same research group further used multi-\\nobjective harmony search integrated with ann to decrease computational demand for the finite element \\nanalysis of post-tensioned box-girder bridges [190] . mondoro et al.  [155] proposed an approach for \\noptimal risk-based management strategies for bridges in which they considered the uncertainties \\nassociated with hazards, economic, social, and environmental outcomes of failure under traffic loads and \\nhurricanes. chatterjee et al.  [191] employed a multi-objective genetic algorithm for calibration of a neural \\nnetwork model to minimize the root mean squared error and maximum error of the network. results of \\nstructural failure classification for reinforced concrete buildings indicated that the proposed optimization \\nalgorithm outperformed a multi-layer perceptron feed-forward network. the mentioned studies indicate \\nthe wide applicability of ml for structural optimization.    \\n5.2.2. mechanical properties of concrete \\nthe design of concrete structures requires considering several key mechanical properties of the material , \\nsuch as compressive strength, splitting tensile strength, shear strength, and elastic modulus. linear or \\nnonlinear regression models to these material parameters have been proposed to save time and costs \\nassociated with material testing [192,193] . however, the mechanical properties of concrete are known to \\nhave strong nonlinear relations between the constituents and the macroscale material characteristics \\n[167,194]. therefore, the development of reliable models is of interest to explore material mechanical \\nproperties in a way that optimizes cost and time. the potential of ml algorithms has been harnessed to \\nmodel such properties and address the noted issues.  \\nseveral ml algorithms, such as neural networks, genetic programming, fuzzy logic, and support \\nvector machines (svm) have been used to develop accurate models to forecast the mechanical properties \\nof concrete. most significantly, ml algorithms have been used for modeling the properties of self-\\ncompacting concrete [195,196] (e.g., strength, elastic modulus) , as well as modeling the tensile and \\ncompressive strength of normal concrete [197,198]. as an example, yeh et al.  [193] proposed a genetic \\noperation tree composed of an operation tree and a genetic algorithm to generate formulas that predict the \\ncompressive strength of high-performance concrete. cheng et al.  [199] used a genetic weighted pyramid \\noperation tree to construct a model for determining the compressive strength of high-performance \\nconcrete. the obtained model gave better results, using benchmark tests, in comparison to ann, svm, \\nand evolutionary support vector inference models . xu et al.  [200] established an svm-based model to \\nassess the relation between the strength and mechanical properties of concrete obtained from non-\\ndestructive testing. they showed that the proposed method is less computationally demanding, while also \\nproviding high accuracy in its predictions compared to other numerical methods . yan and shi [201] \\ninvestigated the applicability of svm for predicting the elastic modulus of normal and high strength ',\n",
       " '  \\n21 concrete. they discovered that svm has superior performance compared to ann models. yan et al.  \\n[202] developed an svm model with experimental data from the literature and compared the results with\\nempirical design equations. they showed that an svm model is capable of accurately estimating the\\nsplitting tensile strength from compressive strength. parsad et al.  [203] used a neural network to predict\\nthe compressive strength of self-compacting and high performance concrete. an artificial intelligence\\nsystem based on combination of fuzzy logic, weighted svm, and fast messy genetic algorithms was\\ndeveloped by cheng et al. [204] to predict high-performance concrete compressive strength, where results\\nshowed that the method achieved higher performance compared to svm. saridemir [205] used gene\\nexpression programming to determine the splitting tensile strength concrete from its compressive\\nstrength. results showed that the proposed formulations led to the best accuracy and were able to predict\\nsplitting tensile strength similar to experimental results. nedushan [206] introduced an adaptive network-\\nbased fuzzy inference system (anfis) model and an svm for predicting the elastic modulus of normal\\nand high strength concrete , and found that the anfis model outperformed nonlinear regression models\\nand the predictive models in the literature. lee et al. [207] presented a theoretical model using anns to\\npredict the shear strength of slender fiber reinforced polymer reinforced concrete beams, which was\\nshown to perform better than other existing equations. all these studies concluded that ml methods are\\ninfluential tools for evaluating the mechanical properties of concrete without being affected by data\\ncomplexity and incoherence.\\ntable 2.  applications of machine learning (ml) in structural engineering  reference  domain  case structures  ai method used  for ml  ',\n",
       " '  \\n22 [208] damage detection concrete slabs  support vector machine (svm)  \\n[176]  shm  cable -stayed bridge structure  svm \\n[200]  modellin g of concrete \\nstrength  concrete beam  svm  \\n[209]  earthquake \\nengineering  seismic evaluation  bayesian method  \\n[197]  modelling of concrete\\nstrength  concrete beam  svm  \\n[210]  structural reliability \\nanalysis  truss structures  svm -based radial basis function (rbf) \\nnetwork  \\n[211]  seismic damage \\ndetection  buildings with steel moment -\\nframe structure  neural network  \\n[212]  structural \\nidentification  concrete bridge  neural network  \\n[213]  structural \\nidentification  concrete dam  neural network  \\n[198]  prediction of concrete \\nproperties  concrete block with fly ash  support vector regression  \\n[214]  shm  metallic structures  adaboost machine learning  \\n[215,216]  performance \\nevaluation  self-compacting concrete  artificial neural network (ann)  \\n[217]  performance \\nevaluation  concrete dam  ann  and linear regression  \\n[172]  shm  three -story  frame structure  singular value decomposition, \\nmahalanobis distance, aut o-associative \\nneural network, and factor analysis      \\nreference  domain  case structures  ai method used for ml  \\n[218] damage detection  long -span arch bridge \\nstructure  svm  \\n[219] damage detection transmission tower  svm  and rbf neural network  \\n[220] damage detection bridge structure  neural network, svm, and som \\n[221]  performance \\nevaluation  steel beams  linear genetic programming  \\n[222]  performance \\nevaluation  concrete dam  artificial neural network (ann)  \\n[223]  structural \\nidentification  steel -box girder bridge  principal component analysis (pca)  \\n[224]  modeling concrete \\nstrength  concrete cube  svm  \\n[225]  shm  cantilever beam  dynamic bayesian networks  \\n[226]  shm  concrete structural \\ncomponents  svm  \\n[227,228]  prediction of concrete  \\nstrength  concrete with construction \\nand demolishing waste  ann  \\n[168] damage detection beams on ocean platform  neural network  \\n[229]  shm  steel pipes  svm  and adaptive boosting  ',\n",
       " '  \\n23 [195]  prediction of concrete \\nproperties  self-compacting concrete \\nblock  svm  \\n[230]  shm  cantilever concrete beam  svm  \\n[202]  prediction of concrete \\nstrength  cylinder concrete  svm  \\n[231] damage detection steel structures  multi -objective genetic algorithm  \\n[192]  concrete strength \\nsimulations  high performance concrete  ann,svm,  classification and \\nregression tree, linear regression  \\n[232] damage detection steel frame structure  svm  with gaussian kernel  \\n[233]  performance \\nevaluation  concrete dam  support vector regression  \\n[196]  prediction of concrete \\nstrength  self-compacting concrete  least square support vector machine  \\n[234]  prediction of concrete \\nproperties  corroded reinforced concrete  svm  \\n[175]  shm  mesh -reinforced concrete \\nstructure  ann  \\n[235]  earthquake \\nengineering  two-story building  gaussian process  regression  \\n[207]  prediction of shear \\nstrength  fiber reinforced polymer \\nconcrete  ann      \\nreference  domain  case structures  ai method used  for ml  \\n[236]  seismic damage \\nidentification  reinforced concrete slab \\ncolumn frames  multiclass support vector machine and \\nmulti -layer perceptron neural network\\n[178] damage detection bridge structure  kernel regression method and principal \\ncomponent analysis (pca)  \\n[237]  modelling concrete \\nshear strength  reinforced and unreinforced \\nconcrete joints  multivariate adaptive regression splines \\nand symbolic regression  \\n[238]  structural \\nidentification  bridge structure  gaussian process model  \\n[239,240]  structural reliability  truss structure  gaussian process machine learning  \\n[240]  predicting concrete \\ncompressive strength  concrete specimen  support vector regre ssion and adaptive \\nneuro -fuzzy inference  \\n[241] damage detection  bridge structure  svm , regression, random forest  \\n[242]  shm truss structure  least square support vector machine \\nwith a mixed kernel  \\n[169]  shm  three -story  steel frame \\nstructure  svm  \\n[177]  seismic damage \\ndetection  seismic performance  svm, k-nearest neighbor method (k -\\nnn), and random forest \\n[180]  shm  bridge structure  k-nn and k-means clustering',\n",
       " '24 [182] damage detection bridge structure  gaussian mixture models and genetic \\nalgorithm  \\n[190]  bridge design\\noptimization  post-tensioned concrete road \\nbridge struc ture artificial neural network (ann) and \\nharmony search algorithm  \\n[189]  reliability -based \\noptimization  post-tensioned box -girder \\nbridge structure  modified harmony search algorithm  \\n[191] damage detection reinforced concrete buildings  neural network and genetic algorithm  \\n[155]  risk-based \\nmanagement  coastal bridge structure  optimization algorithm  \\n[243]  tensile strength \\nprediction  steel plates  ann  \\n[244] seismic performancesix-story reinforced concrete \\nframe structure  support vector regression  \\n[181] damage detection bridge structure  bayesian inference and markov chain \\nmonte carlo simulation  \\n[183]  shm  bridge structure  ann  \\n[157]  shm  plat-like structures  k-nn\\n[245]  earthquake \\nengineering  seismic performance  svm  and neural networks  \\n[246]  shear capacity \\nestimation  fiber -reinforced polymer \\nconcrete slabs  least square support vector machine  \\n[247] reliability assessment steel -box girder bridge  support vector regression  \\n[248,249]  shm  movable bridge structures  moving principal comp onent analysis \\nand robust regression analysis  ',\n",
       " '  \\n25 reference  domain  case structures  ai method used  for ml  \\n[250] crack categorization reinforced concrete columns  fuzzy logic  \\n[251]  performance \\nevaluation  steel -concret e composite \\nbeams  extreme learning machine models, \\nann, and genetic programming  \\n[252]  predicting concrete \\ncompressive strength  concr ete structures  svm, gaussian processes regression, \\nand ann  \\n[253]  shm  wind turbine systems  affinity propagation clustering  \\n[170]  shm  aircraft wing structure  low-rank matrix decomposition and \\nk-nn\\n[254]  structural parameter \\nidentification  three story structure and \\nthree -span continuous beam  particle swarm optimization  \\n[187]  shm  structural tower and cable -\\nstayed bridge  l1 minimization sparse recovery  \\n[255]  structural parameter \\nidentification  three -story steel frames  independent component analysis  \\n[179]  structural reliability \\nassessment  five-story structures, truss \\nstring structures, and \\ncylindrical shell roof  svm -based neural network  ',\n",
       " '26 5.3. deep learning \\nduring the last few years, there has been a growing interest in the use of deep learning, e.g., convolutional \\nneural networks (cnns) for structural engineering applications, mainly in structural health monitoring \\n(shm). the application of cnns is very new in the field of shm and damage detection. cnns within \\nthe context of shm are defined as learning and extracting optimal features and classification using \\nlearned features. as previously discussed, cnns are primarily designed for two-dimensional signals (e.g., \\nimages, video frames, etc.), thus leading to an efficient image recognition method. therefore, cnns are \\ncategorized and used as vision-based shm techniques in which dataset are images captured at various \\nstates of the structure being monitored.  \\nthe first use of cnns in structural engineering was conducted by sarkar et al.  [260] for characterizing \\ncrack damage on composite materials. further, abdeljaber et al.  [261,262] introduced a vibration-based \\nstructural damage detection approach using one-dimension al cnns. they proved that the method was \\ncapable of learning directly from the measured acceleration data, yielding an accurate approach for health \\nmonitoring of civil structures. however, the proposed system, especially for large civil structure s, \\nsuffered from the fact that a large number of measurement sessions was required to generate the training \\ndata. to overcome this drawback, they proposed a nonparametric damage identification method using \\ncnns that required two measurement sessions to generate the training data [263]. they showed that the \\nshm system was effective in estimating the actual amount of damage. cha et al.  [264] presented a deep \\nlearning network to detect concrete cracks in the tunnels without the need for computing defect features. \\nthey also conducted a comparative study to show how the proposed deep learning-based damage \\nassessment approach was able to detect concrete cracks in a robust manner compared to traditional image \\ndetection methods. gulgec et al.  [265] proposed a structural damage identification method using cnns to \\ndiscover the unknown relation between the measurements and patterns representing damage. lee at al.  \\n[266] also investigated the applicability of deep learning and cnns for structural analysis in a ten bar\\nplanar truss and proved that such techniques are more efficient compared to conventional neural\\nnetworks. all these studies suggest that deep learning/cnns architectures are effective tools for\\nmonitoring structural health, and that these frameworks are establishing themselves as viable methods for\\na new generation of vision-based shm systems.\\n6. discussion and future directions\\nthis study review ed papers published during the last decade concerning the applications of emerging ai \\nmethods , namely, pattern recognition (pr), machine learning (ml), and deep learning (dl), in structural \\nengineering . the papers were thoroughly reviewed to identify the nature of the problem, the ai \\nalgorithms adopted and used, and to assess the methods’ applicability for the given problem. the survey [256,257]  shm  steel plate  svm  \\n[171] shm  reinforced concrete beams  low-rank matrix decomposition  \\n[258]  shm  cable stayed bridge  compressed sensing based random \\nencoding  \\n[186] damage detection plate structure  low-rank matrix decomposition  \\n[259]  shm  aircraft wing structure  low-rank matrix decomposition, k -nn, \\nsvm, and ann  ',\n",
       " '27 showed that pr and ml are being widely used by the structural engineering community for applications, \\nsuch as shm, structural identification, earthquake engineering, etc. yet, the most common use for pr and \\nml has been for shm. the review further indicated that dl architectures have also been utilized for \\nshm and damage identification . it is to be expected that the use of ai in structural engineering will \\nincrease as their potential is better understood and as new methods are developed.  \\nfigure 8.  applications of ml, pr, and dl in structural engineering \\ncurrent and emerging applications of ml, pr and dl in structural engineering are shown in figure 8. \\nthe following sub-sections discuss future directions for ai-based methods, including emerging \\napplications and issues for improving their efficiency and robustness.  \\n6.1. data-driven shm systems with self-powered sensing technology \\nperformance of the noted ai methods for shm applications strongly depends on the amount of data \\ncollected through the monitoring system. wireless sensor networks (wsns) have emerged to overcome \\nthe drawbacks of wires in dense sensor arrays, and have increasingly become an alternative to traditional \\nshm systems. durability monitoring using wsns transforms the way of inspecting structure s to an \\nautomated, rapid, and objective manner. additionally, continuous remote monitoring using wsns for \\nlong periods of time is more economical than conducting periodic field experiments or inspections . \\nrecently, self-powered sensors have evolved to be able to harvest the needed power (for computational, \\nstorage and transmission requirements) from the signal being sensed as well as form ambient vibrations, \\nthus providing a promising alternative to traditional sensor systems. pr, ml, and dl methods can then \\nbe integrated with self-powered wireless sensor networks to present the new type of data-driven shm \\nsystems that are energy-lean. \\n',\n",
       " '  \\n28 data-driven approaches are nowadays combined with empirical models to monitor the state of a \\nstructure. although these approaches enhance performance prediction, they still depend on empirical \\nformula s, which have the previously discussed limitations. however, data-driven approaches for shm \\nsolutions are expected to rely on data collected from embedded/mounted sensors along with artificial \\nintelligence techniques . ml and pr are powerful tools to extract information and develop predictive \\nmodels from large data. furthermore, the increased use of these intelligent methods in structural \\nengineering clearly indicates that these methods are becoming predominant approaches for shm. the \\nincorporation of wsns and the noted ai methods for structural engineering purposes could result in the \\nefficient inspection and assessment of civil structures, as the evaluation can be performed remotely \\nthrough sensors with wireless data transmission capabilities and by interpreting data using pr and ml \\ntechniques. furthermore, ml algorithms are able to learn the complex interrelation among influencing \\nfactors, thus performing predictions without the need for empirical model s, while also being able to \\nimprove on their predictive capability . advancements in self-powered sensors have also promoted the \\ndevelopment of energy-efficient network technologies, such as the pulse switching protocol [184,267] , \\nwhich can be coupled with ml algorithms for shm and damage identification [170,185,259,114]. as a \\nresult of using such an intelligent system, the constraint of a communication power budget for an shm \\nsensor network can be addressed, thus leading to a reliable and efficient shm system.  \\n6.2. vision-based shm systems and computational mechanics \\ndeep learning methods emerged to interpret big data in order to identify implicit features from it, and to \\nclassify the learned features. deep learning-based damage detection techniques have been found to be \\ncomputationally efficient. unlike conventional ml techniques that use hand-crafted features that result in \\nhigh computational complexity, dl and cnns use optimal features learned by the network, thus \\nincreasing the classification accuracy significantly. further, the structure of the dl architecture, \\nspecifically one-dimension al cnns, make their mobile and low-cost hardware implementation quite \\nfeasible. therefore, it is expected that dl will play important role in the future generation of vision-based \\nshm systems, i.e., those based on computer vision techniques [268–270]. another interesting potential \\napplication of ml and dl is in the computational mechanics domain [271]. in computational mechanics, \\nproblem solving rules strongly depends on a n expert’s insight. such rules are valid when certain \\nassumptions hold, thus indicating a limitation of the expert’s ability . to cope with this difficulty, ml and \\ndl can be used to automatically discover the rules required to solve computational mechanics problems \\nsuch as those using the finite element method (fem). dl methods are able to generate implicit rules and \\ndiscover mapping relations among the input-output data. for instance , optimizing numerical quadrature is \\nan essential problem to the fem that requires great amount of computation. however, dl can be used as \\na tool to address such problem. a framework of computational mechanics methods enriched by dl/cnns \\ncan be developed and applied to optimize numerical quadrature in order to compute the fem element \\nmatrices. that is, the number of integration points in the numerical quadrature of the element stiffness \\nmatrix can be minimized for the prescribed range of error predicted thru dl. the dl architecture can also \\nestimate the most accurate result by optimizing the numerical quadrature parameters. \\n6.3. shm systems with iot \\nthe durability of civil infrastructures has nowadays become a big issue g iven the number of structures \\nthat need to be repaired, and concerns on the efficiency of traditional techniques used to manage \\nmaintenance and repair actions. this situation is creating a paradigm shift toward cutting-edge ',\n",
       " '  \\n29 technologies such as the internet of things (iot) [272]. the iot refers to a system in which wsns \\nmounted with intelligent software and local computing power could be effectively used for the monitoring \\nof structures. iot aims to increase machine- to-machine communication thru wireless integrated sensors \\nwith the goal of monitoring devices remotely and efficiently. in this new paradigm, smart devices collect \\ndata, transmit information, and process information collaboratively using cloud computing techniques . \\nsoftware is also needed to extract useful information from the large amount of data that is generated . on \\nthis basis, ml could be integrated with iot for shm purposes [273–275]. ml can thus become an \\nessential tool that can be applied to expand the boundaries of iot. on the other hand, the important issue \\nregarding the shm of structures, such as bridges, is to constantly monitor the installed sensors and to \\ncompare the new data with previous readings. it is, however, a challenging task to visit all monitored \\nbridges given the fact that they are typically geographically distant from each other. thus, a technology \\nthat links all sensors on the bridges to a common recording device is needed. further, it is essential to link \\ncollected information to a centralized monitoring station that could receive all the data from the sensors \\nthrough the internet. the iot and noted artificial intelligence methods could be used to effectively address \\nthe noted difficulties. accordingly , the iot will enable engineers to collect data from several bridges for \\nfurther analysis. ml can then be used for data analysis and interpretation. structural health assessment \\nemploying iot could provide a promising solution for rapid, accurate, and low-cost shm systems. the \\nintegration of shm, iot, and cloud computing can lead to powerful processing of the sensed data \\ncompared to traditional shm systems. in fact, cloud platforms can enable an shm system to store and \\nuse data from smart monitoring devices. the structure ’s health status can then be sent to an internet \\nserver, and data stored on the server can then be monitored remotely from a mobile device and interpreted \\nusing ml. \\n6.4. smart cities with iot \\nthe concept of smart cities has been recently gaining attention in diverse engineering communities, and \\nthe application o f the iot paradigm to smart cities is generating research interest [276–279]. the main \\naim of a smart city is to make better use of public services and to reduce operational costs. in other words, \\nthe goal of a smart city is to make infrastructure smarter in order to use resources efficiently . the \\nachievement of this goal depends on a data provided by the wireless sensor networks deployed in cities. \\nthe iot for a smart city can provide distributed data of structural integrity measurements of monitored \\nstructures using data collected by sensors, where dl architectures, e.g., cnns, can be used as tools to \\ninterpret data and classification [280,281] . the data collated from a city varies so much in format and \\nquality that it is difficult for one given system to effectively process all such data. the fact that every city \\nis unique and has a different set of problems yields the need for smart data interpretation techniques . \\nthus, robust layers for data collection, communication protocols, data storage, etc. need to be built. dl \\ncan then be used as a viable tool for interpreting such large amounts of data. dl can be utilized to train \\nsystems to recognize patterns for large numbers of real-time networks and provide early recognition of \\ndeveloping network performance issues. on the other hand, the big challenge for the smart cities concept \\nis how to deal with the large amount of time series data, a particular form of sequential data, received \\nfrom connected sensors. dl architectures (e.g., cnns) are very efficient in the analysis of sequential \\ndata. dl platforms can thus enable a system to solve optimization problems relating to smart cities and \\nstructures.  \\nthe notion of a smart city is to use sensors within the city’s infrastructures to ensure sustainability, \\nsafety, and efficiency. recent progress in nanotechnology have led to the emergence of a new class of ',\n",
       " '  \\n30 sensors, e.g., self-sensing materials that can provide smart cities with methods to assess and monitor the \\ncondition of the infrastructure. smart concrete, having the ability of enabling any concrete structure with \\nself-sensing capabilities, is one of the most promising technologies [282–284]. such functional property \\nis achieved by correlating the variation on internal strain with the variation of appropriate material \\nproperties, e.g., electrical resistance. sensors fabricated using a cementitious matrix with nanoinclusions \\nof carbon nanotubes can be used for condition assessment of concrete structures and traffic monitoring in \\nsmart cities. consequently, ai methods can be effective in the interpretation of sensor data . other \\nexamples include new developing approaches to detect the first stages of corrosion in concrete structures. \\nthe aim is to monitor the state of concrete during the curing period, leading to concrete structures with \\nincreased lifetime and safety. to accurately monitor the strength and temperature of concrete during \\ncuring, sensors are embedded in the concrete at the time of placement and measurements are \\ncommunicated to smartphones through iot. ai methods such as ml and dl can then be used to interpret \\nthe collected data for structural assessment. \\n6.5. improving the performance of ai methods in structural engineering \\nthe findings that make ai methods such valuable tools have been particularly highlighted. however, it is \\nwell known that all methods and models have limitations. table 3  summarizes some general advantages \\nand disadvantages of pr, ml, and dl for structural engineering applications. further, there are aspects of \\nthe implementation of the noted ai methods that could help enhance the ir performance. first, it is clear \\nthat use of ai methods for solving structural engineering problems is no longer at the initial phase. \\ntherefore, it becomes important to shift from exploratory uses to well targeted and rational \\nimplementation of the diverse algorithmic options, since different ai methods can lead to various levels \\nof performance and accuracy depending on the application. it is thus important that future studies present \\na clear rationale for the chosen ai method(s). another important issue is computational efficiency. \\ncommonly, the performance of an ai method can be defined in terms of accuracy and computational \\nefficiency (i.e., less simulation/computational time). it should be noted that some of the publications \\nstudied in this review indicated the good performance of ai method being used, even though the method \\nwas found to be computationally expensive. hence, it is of importance that future studies consider th is \\nissue such that the ai methods being used result in good accuracy while also being computationally \\nefficient. \\nmeasurement noise, modeling errors, environmental effects, etc., are unavoidable factors that could \\nsignificantly affect data availability. it is thus essential to use ai methods that can effectively interpret \\nincomplete and noisy data, and to assess their performance under these influences. uncertainty analyses \\ncould be used for this purpose. the selection of optimal parameters/hyper-parameters can also \\nsignificantly affect the performance of ai methods. thus, future studies implementing ai techniques \\nshould take into account the noted issue such that optimum algorithmic parameters are chosen. finally, \\nclear presentation of the process by which the dataset is prepared and pre-processed (i.e., training, \\nvalidation, and testing) is essential to properly assess the performance of the implemented ai-based \\nmethodology. \\ntable 3.  comparison of different ai methods for structural engineering applications \\nai methods  ',\n",
       " '  \\n31 7.conclusions\\nthis review paper presented the significance of emerging ai methods for structural engineering \\napplications during the last decade . the survey indicated that among the numerous ai methods, pattern \\nrecognition (pr), machine learning (ml), and deep learning (dl) have been increasingly adapted and \\nused for shm and damage identification, optimization, modeling concrete properties, structural \\nidentification, earthquake engineering, etc . yet, the common use of the noted methods has been for \\ninterpreting sensor data in shm. the survey revealed that ml, pr, and dl algorithmic techniques have \\nthe ability to learn complicated interrelations among the contributing parameters, and thus allow solving a \\ndiversity of problems that are difficult, or not possible, to solve with traditional methods.  \\nbased on the literature survey, potential research avenues for employing pr, ml, and dl were also \\npresented. considering the emerging use of wireless sensor networks (e.g., self-powered sensor \\nnetworks), ml- and pr-based models could become the next generation approach es to conduct non-\\ndestructive structural and material evaluation in shm . this review showed that ml methods are able to \\ndiscover hidden information about the structure ’s performance  by learning the influence of various \\ndamage or degrading mechanisms and the data collected from sensors, leading to reliable and efficient \\nshm frameworks . the literature further suggests that ml and dl techniques could also be applied to the \\ncomputational mechanics domain, such as to optimize processes in the finite element method to enhance \\ncomputational efficiency. these methods can also be used to solve complex problems through the novel \\nconcept of the internet of things (iot). on this basis, ml and dl architectures (e.g., convolutional \\nneural networks) within the context of iot can be used to analyze and interpret complex and big data. \\nfurther, the integration of ml and iot can result in the creation of novel shm systems employing \\ndiverse and noisy sensor data . dl architectures can also be incorporated with iot to develop unique \\nframeworks for use in smart cities. data interpretation systems, which are part of the noted frameworks in \\nsmart cities, can thus be optimized using such intelligent architectures.  \\nfinally , the review was also used to identify general challenges and limitations on the use of ai \\ntechniques . among those limitations is the lack of rational selection of the ai method, disregarding the \\neffect of missing/incomplete and noisy data , discarding considerations for computational efficiency, \\nreporting classification accuracy without exploring alternative solutions to increase performance, and \\ninsufficiency presentation of the process to select optimal parameters for the ai technique. however, it \\nwas concluded that by addressing the noted issues/limitations in future studies, ml, pr, and dl could pattern  recognition  machine learning  deep learning  \\nadvantages  applicable for traditional and \\ndata-driven shm systems  \\ndo not  necessarily need vast \\namount of data  \\ncan be effectively used for  \\nclassification and recognition \\nproblems  applicable for traditional and \\ndata-driven shm systems  \\ncan be integrated with iot for \\nsmart applications  \\napplicable for optimization \\nproblems  \\ndo not  necessarily need vast \\namount of dat a \\ncomputationally efficient  applicable for vision -based \\nshm systems  \\neffective while dealing with \\nlarge amount of dataset  \\napplicable for interpretation \\nof big data in smart cities  \\ncan be integrated with iot \\nfor smart applications  \\ncomputationally efficient  \\ndisadvantages  cannot be directly integrated \\nwith iot for smart and \\nintelligent applications  \\nit does not imply learning  cannot be used for new vision -\\nbased shm systems based on \\nimages  cannot be effectively used \\nfor traditional shm systems  \\nneed vast amount of data \\nfor efficient performance  ',\n",
       " '  \\n32 represent pioneering methods to increase the efficiency of many current structural engineering \\napplications as well as for the creation of innovative uses.  \\nacknowledgments \\nthe research described in this paper was carried out with funding from the u.s. national science \\nfoundation under grant number cns-1405273. \\nreferences \\n[1] russell sj, norvig p, canny jf, malik jm, edwards dd. artificial intelligence: a modern approach. vol. 2.\\nprentice hall upper saddle river; 2003.\\n[2] back t. evolutionary computation: toward a new philosophy of machine intelligence. complexity\\n1997;2:28 –30. doi:10.1002/(sici)1099-0526(199703/04)2:4<28::aid-cplx7>3.0.co;2-2.\\n[3] fadlullah zm, tang f, mao b, kato n, akashi o, inoue t, et al. state-of-the-art deep learning: evolving\\nmachine intelligence toward tomorrow’s intelligent network traffic control systems. ieee commun\\nsurv tutor 2017;19:2432 –55. doi:10.1109/comst.2017.2707140.\\n[4] modha ds, ananthanarayanan r, esser sk, ndirango a, sherbondy aj, singh r. cognitive computing.\\ncommun acm 2011;54:62 –71.\\n[5] noor ak. potential of cognitive computing and cognitive systems. open eng 2015;5:75 –88.\\n[6] adeli h, hung s-l. machine learning: neural networks, genetic algorithms, and fuzzy systems. john wiley\\n& sons, inc.; 1994.\\n[7] kicinger r, arciszewski t, jong kd. evolutionary computation and structural design: a survey of the state-\\nof-the-art. comput struct 2005;83:1943 –78. doi:10.1016/j.compstruc.2005.03.002.\\n[8] liao tw, egbelu p, sarker b, leu s. metaheuristics for project and construction management –a state-of-\\nthe-art review. autom constr 2011;20:491 –505.\\n[9] lu p, chen s, zheng y. artificial intelligence in civil engineering. math probl eng 2012;2012:1 –22.\\ndoi:10.1155/2012/145974.\\n[10] shahin ma. artificial intelligence in geotechnical engineering: applications, modeling aspects, and future\\ndirections. metaheuristics water geotech. transp. eng., elsevier; 2013, p. 169 –204.\\n[11] saka mp, geem zw. mathematical and metaheuristic applications in design optimization of steel frame\\nstructures: an extensive review. math probl eng 2013;2013.\\n[12] aldwaik m, adeli h. advances in optimization of highrise building structures. struct multidiscip optim\\n2014;50:899 –919.\\n[13] mardani a, jusoh a, zavadskas ek. fuzzy multiple criteria decision-making techniques and applications –\\ntwo decades review from 1994 to 2014. expert syst appl 2015;42:4126 –48.\\n[14] penadés-plà v, garcía-segura t, martí jv, yepes v. a review of multi-criteria decision-making methods\\napplied to the sustainable bridge design. sustainability 2016;8:1295.\\n[15] amezquita-sanchez j, valtierra-rodriguez m, aldwaik m, adeli h. neurocomputing in civil infrastructure.\\nsci iran trans c chem chem eng 2016;23:2417.\\n[16] pongiglione m, calderini c. sustainable structural design: comprehensive literature review. j struct eng\\n2016;142:04016139.\\n[17] nasiri s, khosravani mr, weinberg k. fracture mechanics and mechanical fault detection by artificial\\nintelligence methods: a review. eng fail anal 2017;81:270 –93.\\n[18] zamarrón-mieza i, yepes v, moreno-jiménez jm. a systematic review of application of multi-criteria\\ndecision analysis for aging-dam management. j clean prod 2017;147:217 –30.\\n[19] sierra-varela la, yepes v, pellicer e. a review of multi-criteria assessment of the social sustainability\\nof infrastructures. j clean prod 2018.\\n[20] zavadskas ek, antucheviciene j, vilutiene t, adeli h. sustainable decision-making in civil engineering,\\nconstruction and building technology. sustainability 2017;10:14.\\n[21] krippendorff k. content analysis: an introduction to its methodology. sage; 2012.\\n[22] pedrycz w. fuzzy sets in pattern recognition: methodology and methods. pattern recognit 1990;23:121 –46.\\n[23] siddique n, adeli h. computational intelligence: synergies of fuzzy logic, neural networks and evolutionary\\ncomputing. john wiley & sons; 2013.',\n",
       " '33 [24] bezdek j. what is computational intelligence? comput intell imitating life jm zurada rj marks ii cj\\nrobinson eds ieee press 1994:1 –12.\\n[25] artificial intelligence: a new synthesis. elsevier; 1998. doi:10.1016/c2009-0 -27773-7.\\n[26] computational intelligence: a logical approach. choice rev online 1998;35:35-5701-35 –5701.\\ndoi:10.5860/choice.35-5701.\\n[27] kurzweil r. the age of spiritual machines: when computers exceed human intelligence. new york, ny:\\npenguin books; 2000.\\n[28] luger gf. artificial intelligence: structures and strategies for complex problem solving. 6 edition. boston:\\npearson; 2008.\\n[29] yuen k-v. bayesian methods for structural dynamics and civil engineering. john wiley & sons; 2010.\\n[30] lombaert g, moaveni b, he x, conte jp. damage identification of a seven-story reinforced concrete shear\\nwall building using bayesian model updating. proc imac-xxvii 2009:9 –12.\\n[31] duda ro, hart pe, stork dg. pattern classification. 2 edition. new york: wiley-interscience; 2000.\\n[32] theodoridis s, koutroumbas k. pattern recognition. 4th edition. elsevier; 2008.\\n[33] bishop c. pattern recognition and machine learning. springer n y 2007.\\n[34] cherkassky v, mulier fm. learning from data: concepts, theory, and methods. john wiley & sons; 2007.\\n[35] michalski rs, carbonell jg, mitchell tm. machine learning: an artificial intelligence approach. springer\\nscience & business media; 2013.\\n[36] alpaydin e. introduction to machine learning. mit press; 2014.\\n[37] robert c. machine learning, a probabilistic perspective 2014.\\n[38] marsland s. machine learning: an algorithmic perspective. crc press; 2015.\\n[39] tong s, chang e. support vector machine active learning for image retrieval, acm press; 2001, p. 107.\\ndoi:10.1145/500141.500159.\\n[40] sebe n. machine learning in computer vision. vol. 29. springer science & business media; 2005.\\n[41] rosten e, drummond t. machine learning for high-speed corner detection. in: leonardis a, bischof h,\\npinz a, editors. comput. vis. – eccv 2006, vol. 3951, berlin, heidelberg: springer berlin heidelberg;\\n2006, p. 430 –43. doi:10.1007/11744023_34.\\n[42] lézoray o, charrier c, cardot h, lefèvre s. machine learning in image processing 2008.\\n[43] brad ski g, kaehler a. learning opencv: computer vision with the opencv library.  o’reilly media, inc.;\\n2008.\\n[44] di k, li w, yue z, sun y, liu y. a machine learning approach to crater detection from topographic data.\\nadv space res 2014;54:2419 –29. doi:10.1016/j.asr.2014.08.018.\\n[45] duygulu p, barnard k, de freitas jf, forsyth da. object recognition as machine translation: learning a\\nlexicon for a fixed image vocabulary, springer; 2002, p. 97 –112.\\n[46] dede g, sazlı mh. speech recognition with artificial neura l networks. digit signal process 2010;20:763 –8.\\n[47] hinton g, deng l, yu d, dahl g, mohamed a, jaitly n, et al. deep neural networks for acoustic\\nmodeling in speech recognition: the shared views of four research groups. ieee signal process mag\\n2012;29:82 –97. doi:10.1109/msp.2012.2205597.\\n[48] deng l, hinton g, kingsbury b. new types of deep neural network learning for speech recognition and\\nrelated applications: an overview, ieee; 2013, p. 8599 –603. doi:10.1109/icassp.2013.6639344.\\n[49] graves a, mohamed a, hinton g. speech recognition with deep recurrent neural networks, ieee; 2013, p.\\n6645 –9. doi:10.1109/icassp.2013.6638947.\\n[50] deng l, li x. machine learning paradigms for speech recognition: an overview. ieee trans audio speech\\nlang process 2013;21:1060 –89.\\n[51] lebaron b. agent-based computational finance. handb comput econ 2006;2:1187 –233.\\n[52] brabazon a, o’neill m. natural computing in computational finance. vol. 100. springer science & business\\nmedia; 2008.\\n[53] harris t. credit scoring using the clustered support vector machine. expert syst appl 2015;42:741 –50.\\n[54] sharma n, sharma p, irwin d, shenoy p. predicting solar generation from weather forecasts using machine\\nlearning, ieee; 2011, p. 528 –33.\\n[55] marvuglia a, messineo a. monitoring of wind farms’ power curves using machine learning techniques.\\nappl energy 2012;98:574 –83.\\n[56] wan c, xu z, pinson p, dong zy, wong kp. probabilistic forecasting of wind power generation using\\nextreme learning machine. ieee trans power syst 2014;29:1033 –44.\\n[57] needham cj, bradford jr, bulpitt aj, westhead dr. a primer on learning in bayesian networks for\\ncomputational biology. plos comput biol 2007;3:e129.',\n",
       " '  \\n34 [58] ben-hur a, ong cs, sonnenburg s, schölkopf b, rätsch g. support vector machines and kernels for\\ncomputational biology. plos comput biol 2008;4:e1000173.\\n[59] che d, liu q, rasheed k, tao x. decision tree and ensemble learning algorithms with their applications in\\nbioinformatics. softw. tools algorithms biol. syst., springer; 2011, p. 191 –9.\\n[60] reich y. machine learning techniques for civil engineering problems. comput civ infrastruct eng\\n1997;12:295 –310.\\n[61] kanevski m, pozdnoukhov a, timonin v. machine learning for spatial environmental data: theory,\\napplications, and software. epfl press; 2009.\\n[62] ciresan dc, meier u, masci j, maria gambardella l, schmidhuber j. flexible, high performance\\nconvolutional neural networks for image classification. vol. 22, barcelona, spain; 2011, p. 1237.\\n[63] zeiler md, fergus r. visualizing and understanding convolutional networks, springer; 2014, p. 818 –33.\\n[64] simonyan k, zisserman a. very deep convolutional networks for large-scale image recognition. arxiv\\nprepr arxiv14091556 2014.\\n[65] russakovsky o, deng j, su h, krause j, satheesh s, ma s, et al. imagenet large scale visual recognition\\nchallenge. int j comput vis 2015;115:211 –52.\\n[66] szegedy c, liu w, jia y, sermanet p, reed s, anguelov d, et al. going deeper with convolutions, cvpr;\\n2015.\\n[67] he k, zhang x, ren s, sun j. deep residual learning for image recognition, 2016, p. 770 –8.\\n[68] gu j, wang z, kuen j, ma l, shahroudy a, shuai b, et al. recent advances in convolutional neural\\nnetworks. pattern recognit 2017.\\n[69] krizhevsky a, sutskever i, hinton ge. imagenet classification with deep convolutional neural networks,\\n2012, p. 1097 –105.\\n[70] karpathy a, toderici g, shetty s, leung t, sukthankar r, fei-fei l. large-scale video classification with\\nconvolutional neural networks, 2014, p. 1725 –32.\\n[71] santos jp, cremona c, orcesi ad, silveira p. early damage detection based on pattern recognition and data\\nfusion. j struct eng 2016;143:04016162.\\n[72] sohn h, czarnecki ja, farrar cr. structural health monitoring using statistical process control. j struct eng\\n2000;126:1356 –63.\\n[73] farrar cr, sohn h, park gh. a statistical pattern recognition paradigm for structural health monitoring. los\\nalamos national laboratory; 2004.\\n[74] farrar cr, worden k. fundamental axioms of structural health monitoring. struct health monit mach\\nlearn perspect 2005:439 –60.\\n[75] sohn h, farrar cr, hunter nf, worden k. structural health monitoring using statistical pattern recognition\\ntechniques. j dyn syst meas control 2001;123:706 –11.\\n[76] noman as, deeba f, bagchi a. health monitoring of structures using statistical pattern recognition\\ntechniques. j perform constr facil 2012;27:575 –84.\\n[77] gul m, catbas fn. statistical pattern recognition for structural health monitoring using time series\\nmodeling: theory and experimental verifications. mech syst signal process 2009;23:2192 –204.\\n[78] sohn h, farrar c, hunter n, worden k. applying the lanl statistical pattern recognition paradigm for\\nstructural health monitoring to data from a surface-effect fast patrol boat. los alamos national lab., nm\\n(us); 2001.\\n[79] farrar cr, sohn h. pattern recognition for structural health monitoring, 2000.\\n[80] worden k, manson g, fieller nr. damage detection using outlier analysis. j sound vib 2000;229:647 –67.\\n[81] worden k, manson g, allman d. experimental validation of a structural health monitoring methodology:\\npart i. novelty detection on a laboratory structure. j sound vib 2003;259:323 –43.\\n[82] manson g, worden k, allman d. experimental validation of a structural health monitoring methodology:\\npart ii. novelty detection on a gnat aircraft. j sound vib 2003;259:345– 63.\\n[83] manson g, worden k, allman d. experimental validation of a structural health monitoring methodology:\\npart iii. damage location on an aircraft wing. j sound vib 2003;259:365 –85.\\n[84] nair kk, kiremidjian as, law kh. time series-based damage detection and localization algorithm with\\napplication to the asce benchmark structure. j sound vib 2006;291:349 –68.\\n[85] nair kk, kiremidjian as. time series based structural damage detection algorithm using gaussian mixtures\\nmodeling. j dyn syst meas control 2007;129:285 –93.\\n[86] cheung a, cabrera c, sarabandi p, nair k, kiremidjian a, wenzel h. the application of statistical pattern\\nrecognition methods for damage detection to field data. smart mater struct 2008;17:065023.',\n",
       " '  \\n35 [87] lanata f, schoefs f. multi-algorithm approach for identification of structural behavior of complex structures\\nunder cyclic environmental loading. struct health monit 2012;11:51 –67.\\n[88] posenato d, kripakaran p, inaudi d, smith if. methodologies for model-free data interpretation of civil\\nengineering structures. comput struct 2010;88:467 –82.\\n[89] zhou h, ni y, ko j. constructing input to neural networks for modeling temperature-caused modal\\nvariability: mean temperatures, effective temperatures, and principal components of temperatures. eng\\nstruct 2010;32:1747 –59.\\n[90] cury a, crémona c, diday e. application of symbolic data analysis for structural modification assessment.\\neng struct 2010;32:762 –75.\\n[91] santos jp, crémona c, orcesi ad, silveira p. multivariate statistical analysis for early damage detection.\\neng struct 2013;56:273 –85.\\n[92] hsu t, loh c. damage detection accommodating nonlinear environmental effects by nonlinear principal\\ncomponent analysis. struct control health monit 2010;17:338 –54.\\n[93] de lautour or, omenzetter p. damage classification and estimation in experimental structures using time\\nseries analysis and pattern recognition. mech syst signal process 2010;24:1556 –69.\\n[94] balsamo l, betti r, beigi h. a structural health monitoring strategy using cepstral features. j sound vib\\n2014;333:4526 –42.\\n[95] yun gj, lee s-g, carletta j, nagayama t. decentralized damage identification using wavelet signal\\nanalysis embedded on wireless smart sensors. eng struct 2011;33:2162 –72.\\n[96] kesavan kn, kiremidjian as. a wavelet ‐based damage diagnosis algorithm using principal component\\nanalysis. struct control health monit 2012;19:672 –85.\\n[97] mujica l, rodellar j, fernandez a, güemes a. q-statistic and t2-statistic pca-based measures for damage\\nassessment in structures. struct health monit 2011;10:539 –53.\\n[98] cury a, cremona c, dumoulin j. long-term monitoring of a psc box girder bridge: operational modal\\nanalysis, data normalization and structural modification assessment. mech syst signal process 2012;33:13 –\\n37.\\n[99] worden k, staszewski wj, hensman jj. natural computing for mechanical systems research: a tutorial\\noverview. mech syst signal process 2011;25:4 –111.\\n[100] andre j, kiremidjian a, liao y, georgakis ct. structural health monitoring approach for detecting ice\\naccretion on bridge cables using the autoregressive model, taylor & francis; 2016, p. 431 –431.\\n[101] yao r, pakzad sn. autoregressive statistical pattern recognition algorithms for damage detection in civil\\nstructures. mech syst signal process 2012;31:355 –68.\\n[102] lam hf, ng ct. the selection of pattern features for structural damage detection using an extended\\nbayesian ann algorithm. eng struct 2008;30:2762 –70.\\n[103] ng c-t. application of bayesian-designed artificial neural networks in phase ii structural health monitoring\\nbenchmark studies. aust j struct eng 2014;15:27 –36.\\n[104] radhika s, tamura y, matsui m. cyclone damage detection on building structures from pre-and post-\\nsatellite images using wavelet based pattern recognition. j wind eng ind aerodyn 2015;136:23– 33.\\n[105] alves v, cury a, roitman n, magluta c, cremona c. structural modification assessment using supervised\\nlearning methods applied to vibration data. eng struct 2015;99:439 –48.\\n[106] goswami s, bhattacharya p. a scalable neural-network modular-array architecture for real-time multi-\\nparameter damage detection in plate structures using single sensor output. int j comput intell appl\\n2012;11:1250024.\\n[107] bandara rp, chan th, thambiratnam dp. frequency response function based damage identification usin g\\nprincipal component analysis and pattern recognition technique. eng struct 2014;66:116 –28.\\n[108] ramos lf, miranda t, mishra m, fernandes fm, manning e. a bayesian approach for ndt data fusion:\\nthe saint torcato church case study. eng struct 2015;84:120 –9.\\n[109] sierra-pérez j, torres-arredondo ma, güemes a. damage and nonlinearities detection in wind turbine\\nblades based on strain field pattern recognition. fbgs, obr and strain gauges comparison. compos struct\\n2016;135:156 –66.\\n[110] alavi ah, hasni h, lajnef n, chatti k, faridazar f. an intelligent structural damage detection approach\\nbased on self-powered wireless sensor data. autom constr 2016;62:24 –44.\\n[111] loh c-h, huang y-t, hsueh w, chen j-d, lin p-y. visualization and dimension reduction of high\\ndimension data for structural damage detection. procedia eng 2017;188:17 –24.',\n",
       " '36 [112] salehi h, das s, chakrabartty s, biswas s, burgueño r. structural assessment and damage identification\\nalgorithms using binary data, american society of mechanical engineers; 2015, p. v002t05a011-\\nv002t05a011.\\n[113] salehi h, burgueño r, das s, biswas s, chakrabartty s. structural health monitoring from discrete binary\\ndata through pattern recognition. insights innov struct eng mech comput 2016:1840 –5.\\n[114] salehi h, das s, chakrabartty s, biswas s, burgueño r. structural damage identification using image-based\\npattern recognition on event-based binary data generated from self-powered sensor networks. struct control\\nhealth monit 2018:e2135. doi:10.1002/stc.2135.\\n[115] datteo a, lucà f. statistical pattern recognition approach for long-time monitoring of the g. meazza\\nstadium by means of ar models and pca. eng struct 2017;153:317 –33.\\n[116] zhou y-l, wahab ma. cosine based and extended transmissibility damage indicators for structural damage\\ndetection. eng struct 2017;141:175 –83.\\n[117] de lautour or, omenzetter p. classification of damage using time series analysis and statistical pattern\\nrecognition, 2008, p. 1055 –63.\\n[118] zhang j, sato t, iai s, hutchinson t. a pattern recognition technique for structural identification using\\nobserved vibration signals: linear case studies. eng struct 2008;30:1439 –46.\\n[119] zhang j, sato t, iai s, hutchinson t. a pattern recognition technique for structural identification using\\nobserved vibration signals: nonlinear case studies. eng struct 2008;30:1417 –23.\\n[120] de lautour or, omenzetter p. prediction of seismic-induced structural damage using artificial neural\\nnetworks. eng struct 2009;31:600 –6.\\n[121] laory i, trinh tn, smith if, brownjohn jm. methodologies for predicting natural frequency variation of a\\nsuspension bridge. eng struct 2014;80:211 –21.\\n[122] bandara rp, chan th, thambiratnam dp. structural damage detection method using frequency response\\nfunctions. struct health monit 2014;13:418 –29.\\n[123] tibaduiza da, mujica le, rodellar j, güemes a. structural damage detection using principal component\\nanalysis and damage indices. j intell mater syst struct 2016;27:233 –48.\\n[124] elwood e, corotis rb. application of fuzzy pattern recognition of seismic damage to concrete\\nstructures. asce-asme j risk uncertain eng syst part civ eng 2015;1:04015011.\\n[125] riveros ca, utsunomiya t, maeda k, itoh k. damage detection in flexible risers using statistical pattern\\nrecognition techniques. int j offshore polar eng 2008;18.\\n[126] li x, ramirez c, hines el, leeson ms, purnell p, pharaoh m. pattern recognition of fiber-reinforced\\nplastic failure mechanism using computational intelligence techniques, ieee; 2008, p. 2340 –5.\\n[127] alvanitopoulos p, andreadis i, elenas a. a new algorithm for the classification of earthquake damages in\\nstructures, 2008, p. 151 –6.\\n[128] chen b, zang c. artificial immune pattern recognition for structure damage classification. comput struct\\n2009;87:1394 –407.\\n[129] chen b, zang c. artificial immune pattern recognition for damage detection in structural health monitoring\\nsensor networks. vol. 7293, international society for optics and photonics; 2009, p. 72930k.\\n[130] park s, inman dj, yun c-b. an outlier analysis of mfc-based impedance sensing data for wireless\\nstructural health monitoring of railroad tracks. eng struct 2008;30:2792 –9.\\n[131] omenzetter p, de lautour or. classification of damage in structural systems using time series analysis and\\nsupervised and unsupervised pattern recognition techniques. vol. 7647, international society for optics and\\nphotonics; 2010, p. 76474s.\\n[132] de lautour or, omenzetter p. nearest neighbor and learning vector quantization classification for damage\\ndetection using time series analysis. struct control health monit 2010;17:614 –31.\\n[133] ren w, lin y, fang s. structural damage detection based on stochastic subspace identification and\\nstatistical pattern recognition: i. theory. smart mater struct 2011;20:115009.\\n[134] lin y, ren w, fang s. structural damage detection based on stochastic subspace identification and\\nstatistical pattern recognition: ii. experimental validation under varying temperature. smart mater struct\\n2011;20:115010.\\n[135] soroushnia s, tafreshi st, omidinasab f, beheshtian n, soroushnia s. seismic performance of rc elevated\\nwater tanks with frame staging and exhibition damage pattern. procedia eng 2011;14:3076 –87.\\n[136] mosavi aa, dickey d, seracino r, rizkalla sh. time-series models for identifying damage location in\\nstructural members subjected to ambient vibrations. vol. 7650, international society for optics and\\nphotonics; 2010, p. 76502n.',\n",
       " '  \\n37 [137] reddy ta, devi kr, gangashetty sv. multilayer feedforward neural network models for pattern\\nrecognition tasks in earthquake engineering, springer; 2011, p. 154 –62.\\n[138] qiao l, esmaeily a, melhem hg. signal pattern recognition for damage diagnosis in structures. comput\\nciv infrastruct eng 2012;27:699 –710.\\n[139] goswami s, bhattacharya p. pattern recognition for damage detection in aerospace vehicle structures,\\nieee; 2012, p. 178 –82.\\n[140] salamone s, veletzos mj, lanza di scalea f, restrepo ji. detection of initial yield and onset of failure in\\nbonded posttensioned concrete beams. j bridge eng 2011;17:966 –74.\\n[141] cury a, crémona c. pattern recognition of structural behaviors based on learning algorithms and symbolic\\ndata concepts. struct control health monit 2012;19:161 –86.\\n[142] wang z, chen s, lederman g, cerda f, bielak j, garrett j, et al. comparison of sparse representation and\\nfourier discriminant methods: damage location classification in indirect lab-scale bridge structural health\\nmonitoring, 2013, p. 436 –46.\\n[143] cremona c, cury a, orcesi a. supervised learning algorithms for damage detection and long term bridge\\nmonitoring. measurement 2012;4:2.\\n[144] cunha a, caetano e, ribeiro p, müller g. an indirect bridge inspection method incorporating a wavelet-\\nbased damage indicator and pattern recognition n.d.\\n[145] xiao h, lu c, ogai h, roy k. a novel bridge structure damage diagnosis algorithm based on statistical\\npattern recognition, ieee; 2014, p. 775 –80.\\n[146] marti-vargas jr, ferri fj, yepes v. prediction of the transfer length of prestressing strands with neural\\nnetworks. comput concr 2013;12:187 –209.\\n[147] ho h-n, kim k-d, park y-s, lee j-j. an efficient image-based damage detection for cable surface in cable-\\nstayed bridges. ndt e int 2013;58:18 –23.\\n[148] ng c-t. on the selection of advanced signal processing techniques for guided wave damage identification\\nusing a statistical approach. eng struct 2014;67:50 –60.\\n[149] hwang j-h, joo b-c, yoo y-j, park k-t, lee c-h. damage detection of a prototype building structure\\nunder shaking table testing using outlier analysis. vol. 8695, international society for optics and photonics;\\n2013, p. 86953h.\\n[150] mustapha s, hu y, nguyen k, alamdari mm, runcie p, dackermann u, et al. pattern recognition based on\\ntime series analysis using vibration data for structural health monitoring in civil structures. electron j struct\\neng 2015.\\n[151] mcgetrick p, kim c. experimental investigation of a wavelet based drive-by bridge inspection system\\nincorporating pattern recognition. life-cycle struct syst des assess maint manag 2014:333.\\n[152] balsamo l, betti r. data ‐based structural health monitoring using small training data sets. struct control\\nhealth monit 2015;22:1240 –64.\\n[153] hakim s, razak ha, ravanfar s, mohammadhassani m. structural damage detection using soft\\ncomputing method. struct. health monit. vol. 5, springer; 2014, p. 143 –51.\\n[154] heo g, kim c, lee c, hur j, seo s. a damage assessment technique based on a revised statistical pattern-\\nrecognition technique (sprt). ksce j civ eng 2017;21:882 –8.\\n[155] mondoro a, frangopol dm, soliman m. optimal risk-based management of coastal bridges vulnerable to\\nhurricanes. j infrastruct syst 2016;23:04016046.\\n[156] crémona c, da silveira apc, de oliveira martins lc. real ‐time damage detection based on pattern\\nrecognition. struct concr 2016;17:338 –54.\\n[157] vitola j, pozo f, tibaduiza da, anaya m. a sensor data fusion system based on k-nearest neighbor pattern\\nclassification for structural health monitoring applications. sensors 2017;17:417.\\n[158] abdeljaber o, avci o. nonparametric structural damage detection algorithm for ambient vibration response:\\nutilizing artificial neural networks and self-organizing maps. j archit eng 2016;22:04016004.\\n[159] mallik n, wali a, kuri n. damage location identification through neural network learning from optical\\nfiber signal for structural health monitoring, acm; 2016, p. 157 –61.\\n[160] khoshnoudian f, talaei s. a new damage index using frf data, 2d-pca method and pattern recognition\\ntechniques. int j struct stab dyn 2017;17:1750090.\\n[161] bonessio n, benzoni g, lomiento g. a multi-mode approach for multi-directional damage detection in\\nframe structures. eng struct 2017;147:505 –16.\\n[162] shahsavari v, chouinard l, bastien j. wavelet-based analysis of mode shapes for statistical detection and\\nlocalization of damage in beams using likelihood ratio test. eng struct 2017;132:494 –507.',\n",
       " '38 [163] stone j, blockley d, pilsworth b. towards machine learning from case histories. civ eng syst 1989;6:129 –\\n35.\\n[164] arciszewski t, mustafa m, ziarko w. a methodology of design knowledge acquisition for use in learning\\nexpert systems. int j man-mach stud 1987;27:23 –32.\\n[165] khoa nl, zhang b, wang y, chen f, mustapha s. robust dimensionality reduction and damage detection\\napproaches in structural health monitoring. struct health monit 2014;13:406 –17.\\n[166] smarsly k, dragos k, wiggenbrock j. machine learning techniques for structural health monitoring, 2016,\\np. 5–8.\\n[167] taffese wz, sistonen e. machine learning for durability and service-life assessment of reinforced concrete\\nstructures: recent advances and future directions. autom constr 2017;77:1 –14.\\n[168] yan b, cui y, zhang l, zhang c, yang y, bao z, et al. beam structure damage identification based on bp\\nneural network and support vector machine. math probl eng 2014;2014.\\n[169] gui g, pan h, lin z, li y, yuan z. data-driven support vector machine with optimization techniques for\\nstructural health monitoring and damage detection. ksce j civ eng 2017;21:523 –34.\\n[170] salehi h, das s, chakrabartty s, biswas s, burgueño r. a machine-learning approach for damage detection\\nin aircraft structures using self-powered sensor data. in: lynch jp, editor., 2017, p. 101680x.\\ndoi:10.1117/12.2260118.\\n[171] nagarajaiah s, yang y. modeling and harnessing sparse and low ‐rank data structure: a new paradigm for\\nstructural dynamics, identification, damage detection, and health monitoring. struct control health monit\\n2017;24.\\n[172] figueiredo e, park g, farrar cr, worden k, figueiras j. machine learning algorithms for damage detection\\nunder operational and environmental variability. struct health monit 2011;10:559 –72.\\n[173] dervilis n. a machine learning approach to structural health monitoring with a view towards wind turbines\\n2013.\\n[174] yan b, cui y, zhang l, zhang c, yang y, bao z, et al. beam structure damage identification based on bp\\nneural network and support vector machine. math probl eng 2014;2014.\\n[175] butcher jb, day cr, austin jc, haycock pw, verstraeten d, schrauwen b. defect detection in reinforced\\nconcrete using random neural architectures: defect detection in reinforced concrete using random neural\\narchitectures. comput-aided civ infrastruct eng 2014;29:191 –207. doi:10.1111/mice.12039.\\n[176] liu c, liu j, liu l. study on the damage identification of long-span cable-stayed bridge based on\\nsupport vector machine, ieee; 2009, p. 1 –4.\\n[177] gong l, wang c, wu f, zhang j, zhang h, li q. earthquake-induced building damage detection with post-\\nevent sub-meter vhr terrasar-x staring spotlight imagery. remote sens 2016;8:887.\\n[178] lederman g, wang z, bielak j, noh h, garrett j, chen s, et al. damage quantification and localization\\nalgorithms for indirect shm of bridges, 2014.\\n[179] dai h, cao z. a wavelet support vector machine ‐based neural network metamodel for structural\\nreliability assessment. comput civ infrastruct eng 2017;32:344 –57.\\n[180] diez a, khoa nld, alamdari mm, wang y, chen f, runcie p. a clustering approach for structural health\\nmonitoring on bridges. j civ struct health monit 2016;6:429 –45.\\n[181] zheng w, qian f. promptly assessing probability of barge –bridge collision damage of piers through\\nprobabilistic-based classification of machine learning. j civ struct health monit 2017;7:57 –78.\\n[182] santos a, figueiredo e, silva m, santos r, sales c, costa jc. genetic ‐based em algorithm to improve the\\nrobustness of gaussian mixture models for damage detection in bridges. struct control health monit\\n2017;24.\\n[183] neves a, gonzález i, leander j, karoumi r. structural health monitoring of bridges: a model-free ann-\\nbased approach to damage detection. j civ struct health monit 2017;7:689 –702.\\n[184] das s, salehi h, shi y, chakrabartty s, burgueno r, biswas s. towards packet-less ultrasonic sensor\\nnetworks for energy-harvesting structures. comput commun 2017;101:94 –105.\\ndoi:10.1016/j.comcom.2016.11.001.\\n[185] salehi h, burgueño r, das s, biswas s, chakrabartty s. localized damage identification of plate-like\\nstructures with time-delayed binary data from a self-powered sensor network, american society of\\nmechanical engineers; 2017, p. v002t05a008-v002t05a008.\\n[186] yang y, sun p, nagarajaiah s, bachilo sm, weisman rb. full-field, high-spatial-resolution detection of\\nlocal structural damage from low-resolution random strain field measurements. j sound vib 2017;399:75 –\\n85.',\n",
       " '39 [187] yang y, nagarajaiah s. harnessing data structure for recovery of randomly missing structural vibration\\nresponses time history: sparse representation versus low-rank structure. mech syst signal process\\n2016;74:165 –82.\\n[188] yepes v, garcía-segura t, moreno-jiménez j. a cognitive approach for the multi-objective optimization of\\nrc structural problems. arch civ mech eng 2015;15:1024 –36.\\n[189] garcía-segura t, yepes v, frangopol dm, yang dy. lifetime reliability-based optimization of post-\\ntensioned box-girder bridges. eng struct 2017;145:381 –91.\\n[190] garcía-segura t, yepes v, frangopol dm. multi-objective design of post-tensioned concrete road bridges\\nusing artificial neural networks. struct multidiscip optim 2017;56:139 –50.\\n[191] chatterjee s, sarkar s, hore s, dey n, ashour as, shi f, et al. structural failure classification for\\nreinforced concrete buildings using trained neural network based multi-objective genetic algorithm. struct\\neng mech 2017;63:429 –38.\\n[192] chou j-s, tsai c-f, pham a-d, lu y-h. machine learning in concrete strength simulations: multi-nation\\ndata analytics. constr build mater 2014;73:771 –80.\\n[193] yeh i-c, lien l-c. knowledge discovery of concrete material using genetic operation trees. expert syst\\nappl 2009;36:5807 –12.\\n[194] demir f, korkmaz ka. prediction of lower and upper bounds of elastic modulus of high strength concrete.\\nconstr build mater 2008;22:1385 –93.\\n[195] cao yf, wu w, zhang hl, pan jm. prediction of the elastic modulus of self-compacting concrete based on\\nsvm. vol. 357, trans tech publ; 2013, p. 1023 –6.\\n[196] aiyer bg, kim d, karingattikkal n, samui p, rao pr. prediction of compressive strength of self-\\ncompacting concrete using least square support vector machine and relevance vector machine. ksce j civ\\neng 2014;18:1753 –8.\\n[197] chen b-t, chang t-p, shih j-y, wang j-j. estimation of exposed temperature for fire-damaged concrete\\nusing support vector machine. comput mater sci 2009;44:913 –20.\\n[198] bin c, xuemang g, guohua l. prediction of concrete properties based on rough sets and support vector\\nmachine method. j hydroelectr eng 2011;6:045.\\n[199] cheng m-y, firdausi pm, prayogo d. high-performance concrete compressive strength prediction using\\ngenetic weighted pyramid operation tree (gwpot). eng appl artif intell 2014;29:104 –13.\\n[200] xu c, yun s, shu y. concrete strength inspection conversion model based on svm [j]. j luoyang inst\\nsci technol nat sci ed 2008;2:025.\\n[201] yan k, shi c. prediction of elastic modulus of normal and high strength concrete by support vector\\nmachine. constr build mater 2010;24:1479 –85.\\n[202] yan k, xu h, shen g, liu p. prediction of splitting tensile strength from cylinder compressive strength of\\nconcrete by support vector machine. adv mater sci eng 2013;2013.\\n[203] prasad br, eskandari h, reddy bv. prediction of compressive strength of scc and hpc with high volume\\nfly ash using ann. constr build mater 2009;23:117 –28.\\n[204] cheng m-y, chou j-s, roy af, wu y-w. high-performance concrete compressive strength prediction\\nusing time-weighted evolutionary fuzzy support vector machines inference model. autom constr\\n2012;28:106 –15.\\n[205] sarıdemir m. empirical mo deling of splitting tensile strength from cylinder compressive strength of concrete\\nby genetic programming. expert syst appl 2011;38:14257 –68.\\n[206] ahmadi-nedushan b. prediction of elastic modulus of normal and high strength concrete using anfis and\\noptimal nonlinear regression models. constr build mater 2012;36:665 –73.\\n[207] lee s, lee c. prediction of shear strength of frp-reinforced concrete flexural members without stirrups\\nusing artificial neural networks. eng struct 2014;61:99 –112.\\n[208] hirokane m, nomura y, kusunose y. damage detection using support vector machine for\\nintegrity assessment of concrete structures. doboku gakkai ronbunshuu a 2008;64:739 –49.\\ndoi:10.2208/jsceja.64.739.\\n[209] oh ck. bayesian learning for earthquake engineering applications and structural health monitoring.\\ncalifornia institute of technology; 2008.\\n[210] dai h, zhao w, wang w, cao z. an improved radial basis function network for structural reliability\\nanalysis. j mech sci technol 2011;25:2151.\\n[211] gonzález mp, zapico jl. seismic damage identification in buildings using neural networks and modal data.\\ncomput struct 2008;86:416 –26.',\n",
       " '  \\n40 [212] soyoz s, feng mq. long ‐term monitoring and identification of bridge structural parameters. comput\\nciv infrastruct eng 2009;24:82 –92.\\n[213] karimi i, khaji n, ahmadi m, mirzayee m. system identification of concrete gravity dams using artificial\\nneural networks based on a hybrid finite element –boundary element approach. eng struct 2010;32:3583 –91.\\n[214] kim d, philen m. damage classification using adaboost machine learning for structural health monitoring.\\nvol. 7981, international society for optics and photonics; 2011, p. 79812a.\\n[215] siddique r, aggarwal p, aggarwal y. prediction of compressive strength of self-compacting concrete\\ncontaining bottom ash using artificial neural networks. adv eng softw 2011;42:780 –6.\\n[216] uysal m, tanyildizi h. estimation of compressive strength of self compacting concrete containing\\npolypropylene fiber and mineral additives exposed to high temperature using artificial neural network.\\nconstr build mater 2012;27:404 –14.\\n[217] mata j. interpretation of concrete dam behaviour with artificial neural network and multiple linear regression\\nmodels. eng struct 2011;33:903 –10.\\n[218] liu c-c, liu j. damage identification of a long-span arch bridge based on support vector machine.\\nzhendong yu chongjijournal vib shock 2010;29:174 –8.\\n[219] chun-cheng l, jiao l, biao t. damage identification for transmission tower based on support vector\\nmachine and rbf, 2010.\\n[220] li z, burgueño r. using soft computing to analyze inspection results for bridge evaluation and\\nmanagement. j bridge eng 2010;15:430 –8.\\n[221] aminian p, niroomand h, gandomi ah, alavi ah, esmaeili ma. new design equations for assessment of\\nload carrying capacity of castellated steel beams: a machine learning approach. neural comput appl\\n2013;23:119 –31.\\n[222] kao c, loh c. monitoring of long ‐term static deformation data of fei ‐tsui arch dam using artificial\\nneural network ‐based approaches. struct control health monit 2013;20:282 –303.\\n[223] kim h-j, park w, koh h-m, choo jf. identification of structural performance of a steel-box girder bridge\\nusing machine learning technique. vol. 99, international association for bridge and structural engineering;\\n2013, p. 1313 –20.\\n[224] zhang w, song z. prediction of concrete corrosion in sulfuric acid by svm-based method, 2012.\\n[225] bartram g, mahadevan s. system modeling for shm using dynamic bayesian networks. infotech aerosp.\\n2012, 2012, p. 2423.\\n[226] son h, kim c, kim c. automated color model –based concrete detection in construction-site images by\\nusing machine learning algorithms. j comput civ eng 2011;26:421 –33.\\n[227] dantas ata, leite mb, de jesus nagahama k. prediction of compressive strength of concrete containing\\nconstruction and demolition waste using artificial neural networks. constr build mater 2013;38:717 –22.\\n[228] duan z-h, kou s-c, poon c-s. prediction of compressive strength of recycled aggregate concrete using\\nartificial neural networks. constr build mater 2013;40:1200 –6.\\n[229] ying y, garrett jr jh, oppenheim ij, soibelman l, harley jb, shi j, et al. toward data-driven structural\\nhealth monitoring: application of machine learning and signal processing to damage detection. j comput civ\\neng 2012;27:667 –80.\\n[230] satpal sb, khandare y, guha a, banerjee s. structural health monitoring of a cantilever beam using\\nsupport vector machine. int j adv struct eng 2013;5:2.\\n[231] cha y-j, buyukozturk o. modal strain energy based damage detection using multi-objective optimization.\\nstruct. health monit. vol. 5, springer; 2014, p. 125 –33.\\n[232] long j, buyukozturk o. automated structural damage detection using one-class machine learning. dyn. civ.\\nstruct. vol. 4, springer; 2014, p. 117 –28.\\n[233] ranković v, grujović n, divac d, milivojević n. development of support vector regression identification\\nmodel for prediction of dam structural behaviour. struct saf 2014;48:33 –9.\\n[234] yang s, fang cq, yuan zj. study on mechanical properties of corroded reinforced concrete using\\nsupport vector machines. vol. 578, trans tech publ; 2014, p. 1556 –61.\\n[235] alimoradi a, beck jl. machine-learning methods for earthquake ground motion analysis and simulation. j\\neng mech 2014;141:04014147.\\n[236] kia a, sensoy s. classification of earthquake-induced damage for r/c slab column frames using multiclass\\nsvm and its combination with mlp neural network. math probl eng 2014;2014.\\n[237] jeon j, shafieezadeh a, desroches r. statistical models for shear strength of rc beam ‐column joints\\nusing machine ‐learning techniques. earthq eng struct dyn 2014;43:2075 –95.',\n",
       " '  \\n41 [238] wan h-p, mao z, todd md, ren w-x. analytical uncertainty quantification for modal frequencies with\\nstructural parameter uncertainty using a gaussian process metamodel. eng struct 2014;75:577 –89.\\n[239] su g, yu b, xiao y, yan l. gaussian process machine-learning method for structural reliability analysis.\\nadv struct eng 2014;17:1257 –70.\\n[240] motamedi s, shamshirband s, hashim r, petković d, roy c. estimating unconfined compressive strength\\nof cockle shell –cement –sand mixtures using soft computing methodologies. eng struct 2015;98:49 –58.\\n[241] ataei n, padgett je. fragility surrogate models for coastal bridges in hurricane prone zones. eng struct\\n2015;103:203 –13.\\n[242] ghiasi r, torkzadeh p, noori m. a machine-learning approach for structural damage detection using least\\nsquare support vector machine based on a new combinational kernel function. struct health monit\\n2016;15:302 –16.\\n[243] karina cn, chun p, okubo k. tensile strength prediction of corroded steel plates by using machine learning\\napproach. steel compos struct 2017;24:635 –41.\\n[244] mirhosseini rt. seismic response of soil-structure interaction using the support vector regression. struct\\neng mech 2017;63:115 –24.\\n[245] rafiei mh, adeli h. neews: a novel earthquake early warning model using neural dynamic classification\\nand neural dynamic optimization. soil dyn earthq eng 2017;100:417 –27.\\n[246] vu d-t, hoang n-d. punching shear capacity estimation of frp-reinforced concrete slabs using a hybrid\\nmachine learning approach. struct infrastruct eng 2016;12:1153 –61.\\n[247] lu n, noori m, liu y. fatigue reliability assessment of welded steel bridge decks under stochastic truck\\nloads via machine learning. j bridge eng 2016;22:04016105.\\n[248] malekzadeh m, catbas fn. a machine learning framework for automated functionality monitoring of\\nmovable bridges. dyn. civ. struct. vol. 2, springer; 2016, p. 57 –63.\\n[249] catbas fn, malekzadeh m. a machine learning-based algorithm for processing massive data collected from\\nthe mechanical components of movable bridges. autom constr 2016;72:269 –78.\\n[250] senniappan v, subramanian j, papageorgiou ei, mohan s. application of fuzzy cognitive maps for crack\\ncategorization in columns of reinforced concrete structures. neural comput appl 2017;28:107 –17.\\n[251] toghroli a, suhatril m, ibrahim z, safa m, shariati m, shamshirband s. potential of soft computing\\napproach for evaluating the factors affecting the capacity of steel –concrete composite beam. j intell manuf\\n2016:1 –9.\\n[252] omran ba, chen q, jin r. comparison of data mining techniques for predicting compressive strength of\\nenvironmentally friendly concrete. j comput civ eng 2016;30:04016029.\\n[253] häckell mw, rolfes r, kane mb, lynch jp. three-tier modular structural health monitoring framework\\nusing environmental and operational condition clustering for data normalization: validation on an\\noperational wind turbine system. proc ieee 2016;104:1632 –46.\\n[254] chang j, nagarajaiah s. quantum-behaved particle swarm optimization-based structural modal parameter\\nidentification under ambient excitation. int j struct stab dyn 2016;16:1550008.\\n[255] chang j, liu w, hu h, nagarajaiah s. improved independent component analysis based modal\\nidentification of higher damping structures. measurement 2016;88:402 –16.\\n[256] hasni h, alavi ah, lajnef n, abdelbarr m, masri sf, chakrabartty s. self-powered piezo-floating-gate\\nsensors for health monitoring of steel plates. eng struct 2017;148:584 –601.\\n[257] hasni h, alavi ah, jiao p, lajnef n. detection of fatigue cracking in steel bridge girders: a support vector\\nmachine approach. arch civ mech eng 2017;17:609 –22.\\n[258] yang y, nagarajaiah s. robust data transmission and recovery of images by compressed sensing for\\nstructural health diagnosis. struct control health monit 2017;24.\\n[259] salehi h, das s, chakrabartty s, biswas s, burgueño r. a methodology for structural health diagnosis and\\nassessment using machine learning with noisy and incomplete data from self-powered wireless sensors.\\nsens. smart struct. technol. civ. mech. aerosp. syst., spie; 2018.\\n[260] sarkar s, reddy kk, giering m, gurvich mr. deep learning for structural health monitoring: a damage\\ncharacterization application n.d.\\n[261] abdeljaber o, avci o, kiranyaz s, gabbouj m, inman dj. real-time vibration-based structural damage\\ndetection using one-dimensional convolutional neural networks. j sound vib 2017;388:154 –70.\\n[262] avci o, abdeljaber o, kiranyaz s, inman d. structural damage detection in real time: implementation of\\n1d convolutional neural networks for shm applications. struct. health monit. damage detect. vol. 7,\\nspringer; 2017, p. 49 –54.',\n",
       " '  \\n42 [263] abdeljaber o, avci o, kiranyaz ms, boashash b, sodano h, inman dj. 1-d cnns for structural damage\\ndetection: verification on a structural health monitoring benchmark data. neurocomputing 2018;275:1308 –\\n17.\\n[264] cha y, choi w, büyüköztürk o. deep learning ‐based crack damage detection using convolutional\\nneural networks. comput civ infrastruct eng 2017;32:361 –78.\\n[265] gulgec ns, takáč m , pakzad sn. structural damage detection using convolutional neural networks.\\nmodel valid. uncertain. quantif. vol. 3, springer; 2017, p. 331 –7.\\n[266] lee s, ha j, zokhirova m, moon h, lee j. background information of deep learning for structural\\nengineering. arch comput methods eng 2018;25:121 –9.\\n[267] huo q, dong b, biswas s. a pulse switching paradigm for ultra low power cellular sensor networks.\\npervasive mob comput 2014;13:221 –45.\\n[268] cha y, choi w, büyüköztürk o. deep learning ‐based crack damage detection using convolutional\\nneural networks. comput civ infrastruct eng 2017;32:361 –78.\\n[269] cha y-j, choi w. vision-based concrete crack detection using a convolutional neural network. dyn.\\nciv. struct. vol. 2, springer; 2017, p. 71 –3.\\n[270] kong x, li j. vision ‐based fatigue crack detection of steel structures using video feature tracking.\\ncomput civ infrastruct eng 2018.\\n[271] oishi a, yagawa g. computational mechanics enhanced by deep learning. comput methods appl mech\\neng 2017;327:327 –51.\\n[272] atzori l, iera a, morabito g. the internet of things: a survey. comput netw 2010;54:2787 –805.\\n[273] abdelgawad a, yelamarthi k. structural health monitoring: internet of things application, ieee; 2016, p. 1 –\\n4.\\n[274] abdelgawad a, yelamarthi k. internet of things (iot) platform for structure health monitoring. wirel\\ncommun mob comput 2017;2017.\\n[275] tokognon ca, gao b, tian gy, yan y. structural health monitoring framework based on internet of\\nthings: a survey. ieee internet things j 2017;4:619 –35.\\n[276] schaffers h, komninos n, pallot m, trousse b, nilsson m, oliveira a. smart cities and the future internet:\\ntowards cooperation frameworks for open innovation, springer; 2011, p. 431 –46.\\n[277] zanella a, bui n, castellani a, vangelista l, zorzi m. internet of things for smart cities. ieee internet\\nthings j 2014;1:22 –32.\\n[278] perera c, zaslavsky a, christen p, georgakopoulos d. sensing as a service model for smart cities supported\\nby internet of things. trans emerg telecommun technol 2014;25:81 –93.\\n[279] kim t, ramos c, mohammed s. smart city and iot 2017.\\n[280] wang l, sng d. deep learning algorithms with applications to video analytics for a smart city: a survey.\\narxiv prepr arxiv151203131 2015.\\n[281] chin j, callaghan v, lam i. understanding and personalising smart city services using machine learning,\\nthe internet-of -things and big data, ieee; 2017, p. 2050 –5.\\n[282] han b, yu x, ou j. self-sensing concrete in smart structures. butterworth-heinemann; 2014.\\n[283] konsta-gdoutos ms, aza ca. self sensing carbon nanotube (cnt) and nanofiber (cnf) cementitious\\ncomposites for real time damage assessment in smart structures. cem concr compos 2014;53:162 –9.\\n[284] gupta s, gonzalez jg, loh kj. self-sensing concrete enabled by nano-engineered cement-aggregate\\ninterfaces. struct health monit 2017;16:309 –23.',\n",
       " '43 emerging artificial intelligence methods in structural engineering \\nhadi salehi1, rigoberto burgueño1,2 \\n1 department of civil and environmental engineering, michigan state university, east lansing, michigan, usa \\n2 department of mechanical engineering, michigan state university, east lansing, michigan, usa \\nhighlights: \\n\\uf0b7a review of recent applications of emerging artificial intelligence (ai) methods is\\npresented.\\n\\uf0b7the methods of pattern recognition, machine learning, and deep learning are studied.\\n\\uf0b7the advantages of employing novel ai methods in structural engineering are discussed.\\n\\uf0b7potential research avenues for using ai methods in structural engineering are identified.',\n",
       " 'received december 16, 2018, accepted december 28, 2018, date of publication january 1, 2019, date of current version january 29, 2019.\\ndigital object identifier 10.1 109/access.2018.2890507\\nblockchain for ai: review and\\nopen research challenges\\nkhaled salah\\n1, (senior member, ieee), m. habib ur rehman2,\\nnishara nizamuddin1, and ala al-fuqaha3\\n1department of electrical and computer engineering, khalifa university of science and technology, abu dhabi 127788, uae\\n2department of computer science, national university of computer and emerging sciences, lahore 54770, pakistan\\n3nest research lab, computer science department, college of engineering and applied sciences, western michigan university, kalamazoo, mi 49008, usa\\ncorresponding author: khaled salah (khaled.salah@ku.ac.ae)\\nabstract recently, arti\\x1ccial intelligence (ai) and blockchain have become two of the most trending and\\ndisruptive technologies. blockchain technology has the ability to automate payment in cryptocurrency and\\nto provide access to a shared ledger of data, transactions, and logs in a decentralized, secure, and trusted\\nmanner. also with smart contracts, blockchain has the ability to govern interactions among participants\\nwith no intermediary or a trusted third party. ai, on the other hand, offers intelligence and decision-making\\ncapabilities for machines similar to humans. in this paper, we present a detailed survey on blockchain\\napplications for ai. we review the literature, tabulate, and summarize the emerging blockchain applications,\\nplatforms, and protocols speci\\x1ccally targeting ai area. we also identify and discuss open research challenges\\nof utilizing blockchain technologies for ai.\\nindex terms arti\\x1ccial intelligence, machine learning, blockchain, cybersecurity, smart contracts,\\nconsensus protocols.\\ni. introduction\\nblockchain is one the most hyped innovations these days, and\\nit has been gaining a lot of traction as a horizontal technology\\nto be widely adopted in various \\x1celds [1]\\x15[3]. since its incep-\\ntion in 2008, blockchain continued to emerge as a disruptive\\ninnovation that will revolutionize the way we interact, auto-\\nmate payments, trace and track transactions [4]. blockchain\\ncan be highly cost effective in eliminating the need for a\\ncentralized authority to govern and verify interactions and\\ntransactions among several participants. in blockchain, every\\ntransaction is cryptographically signed and veri\\x1ced by all\\nmining nodes which hold a replica of the entire ledger which\\ncontains chained blocks of all transactions. this creates a\\nsecure, synchronized and shared timestamped records that\\ncannot be altered [5]. another prominent \\x1celd that is gaining\\nhuge traction is arti\\x1ccial intelligence(ai) which allows a\\nmachine to have cognitive functions to learn, infer, and adapt\\nbased on data it collects. recent market research predicts\\nthat ai market will grow up to 13 trillion us dollars by the\\nyear 2030.\\nthe massive production and generation of data by sensing\\nsystems, iot devices, social media, and web applications\\nhave contributed to the rise of ai [6]. such data can be utilizedby various machine learning and deep learning techniques [7]\\nto perform variety of analytics. to date, the majority of\\nmachine learning and deep learning methods of ai rely on\\na centralized model for training in which a group of servers\\nrun a speci\\x1cc model against training and validating datasets\\nand many organizations like google, apple, facebook and\\namazon manage the huge volumes of data to make informed\\ndecisions [8]. however, the centralized nature of ai may lead\\nto the possibility of data tampering, as data can be subject\\nto hacking and manipulation as it is managed and stored\\nin centralized manner [9]. moreover, the data provenance\\nand authenticity of the sources generating the data are not\\nguaranteed [10]. this may lead to ai decision outcomes that\\ncan be highly erroneous, risky, and dangerous.\\nthe concept of decentralized ai has been recently emerg-\\ning. decentralized ai is basically a combination of ai and\\nblockchain [8]. the decentralized ai enables to process and\\nperform analytics or decision making on trusted, digitally\\nsigned, and secure shared data that has been transacted and\\nstored on the blockchain, in a distributed and decentral-\\nized fashion, without trusted third parties or intermediaries\\n[8], [9]. ai is known to work with huge volumes of data, and\\nblockchain has now been foreseen as a trusted platform to\\nvolume 7, 20192169-3536 \\n2019 ieee. translations and content mining are permitted for academic research only.\\npersonal use is also permitted, but republication/redistribution requires ieee permission.\\nsee http://www.ieee.org/publications_standards/publications/rights/index.html for more information.10127',\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\nstore such data. the feature of blockchain smart contracts\\ngives the ability to program the blockchain to govern transac-\\ntions among participants involved in decision making or gen-\\nerating and accessing the data [11]. smart contract-based\\nautonomous systems and machines can learn and adapt to\\nchanges over time, and make trusted and accurate decision\\noutcomes that are veri\\x1ced and validated by all mining nodes\\nof the blockchain. such decisions cannot be refuted, and can\\nbe traced, tracked and veri\\x1ced by all participating entities.\\nai techniques that utilize blockchain can offer decentralized\\nlearning to facilitate a trust and secure sharing of knowledge\\nand decision outcomes across a large number of autonomous\\nagents, which can contribute, coordinate, and vote on further\\ndecisions [12], [13].\\nto date, the literature lacks comprehensive reviews and\\nstudies on the role that blockchain plays in the context\\nof ai. existing literature reveals that researchers studied\\nblockchain and ai in isolation, and their applications in\\nvarious vertical domains and businesses [14]\\x15[27]. a couple\\nof studies discussed the integration of ai and blockchain, and\\nthe implications of such integration on the way we live, work,\\ninteract, and transact [9], [28]. the primary contributions of\\nthis paper can be summarized as follows:\\n\\x0fwe give an overview of blockchain basics and key fea-\\ntures and how these features can be leveraged for ai.\\n\\x0fwe discuss how the integration of ai and blockchain\\ncan help in developing a new ecosystem of decentral-\\nized economy. in addition, we outline the key bene\\x1cts\\nbrought by this integration.\\n\\x0fwe present a detailed taxonomy of blockchain plat-\\nforms, architecture and infrastructure types, and con-\\nsensus protocols, along with existing decentralized ai\\napplications.\\n\\x0fwe report and discuss multiple practical use cases of ai\\napplications and implementations utilizing blockchain\\nin different vertical domains.\\n\\x0fwe identify and outline open research challenges in\\nadopting and leveraging blockchain features for future\\nai applications.\\nthe rest of the paper is organized as follows. section ii\\ndiscusses the background of blockchain and ai technolo-\\ngies and how blockchain helps in transforming existing\\nai techniques. section iii presents the detailed taxonomy\\nand section iv describes blockchain applications for ai.\\nvarious open research challenges and issues are categorized\\nin section v. section vi concludes the paper.\\nii. background\\nin this section, we give an overview of blockchain and ai\\nand discuss how blockchain technology can be leveraged to\\ntransform, in many radical ways, ai and its applications.\\na. blockchain\\nblockchain is a distributed, open source, immutable, public\\ndigital ledger which is distributed among networked peers [4].\\nfundamentally, blockchain is a chain of blocks that make upthe ledger. this ledger holds a permanent record of trans-\\nactions and interactions that took place among participants\\naccessing the distributed and decentralized blockchain net-\\nwork [11]. each block contains the details of the transaction\\nand the asset exchanges ( i.e., ether or bitcoin) that took place\\nbetween the users [4], [11]. smart contracts are codes that\\ncan be executed by the blockchain mining nodes. a smart\\ncontract is a self-executing code that can verify the enforce-\\nment of prede\\x1cned terms and conditions [29]. instead of vali-\\ndating digital currencies, as in bitcoin, the blockchain mining\\nnodes execute, verify and store data in blocks. a smart con-\\ntract is triggered by consigning a transaction to its ethereum\\naddress and executing it depending on the input given for\\nthat transaction. ethereum is a blockchain based open source\\ndistributed platform that enables to program smart con-\\ntracts [11]. ethereum uses ether as a currency for making\\npayments for the transactions carried out on the ethereum\\nblockchain. each participant in the ethereum network is iden-\\nti\\x1ced uniquely by an ethereum address (ea).\\nconventional blockchain is a very expensive medium for\\nstoring large amounts of data. for example, storing large\\n\\x1cles or documents on bitcoin blockchain is very expensive\\nas the size limit per block is limited to one megabyte [35].\\nto solve this problem, a decentralized storage medium is used\\nfor storing such data and hashes of the data are linked with\\nthe blockchain blocks or used within the blockchain smart\\ncontract code. among the popular decentralized storage tech-\\nnologies are the interplanetary file system (ipfs) [35],\\nswarm [36], filecoin [37], bigchaindb [38], storj [39],\\nand many others. ipfs is a peer-to-peer, distributed and\\ndecentralized \\x1cle system that is connected across nodes of\\ncomputers that share a common \\x1cle system [35]. it is content-\\naddressable, which means that the contents of ipfs can\\nbe accessed using ipfs hash addresses. moreover, this \\x1cle\\nsystem becomes indisputable, since it works similar to the\\nblockchain network by having a list of nodes, and does\\nnot allow any tampering of \\x1cles. therefore, providing high\\nthroughput and content-addressed block storage model, with\\ncontent-addressed hyperlinks. in addition, due to its decen-\\ntralized nature, there is not a single point of failure i.e., if one\\ndevice gets disconnected, the \\x1cle can still be accessed [35].\\nb. artificial intelligence (ai)\\nthe \\x1celd of ai research de\\x1cnes itself as the study of ``intel-\\nligent agents,'' i.e., any device that perceives its environment\\nand takes actions that maximize its chance of success at\\nsome goal [40]. most ai systems in development today are\\ntypically specialized expert systems that use a database of\\nknowledge to make decisions. however, many researchers\\nare working to build ai systems that can apply truly intel-\\nligent decision making processes to a restricted set of prob-\\nlems, some of which may positively impact our daily lives.\\ntable 1 shows few emerging trends in ai applications such\\nas explainable ai [9], [30], digital twins [31], automated\\nmachine learning [32], hybrid learning models [33], and lean\\nand augmented data learning [34], and the perceived bene\\x1cts\\n10128 volume 7, 2019\",\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\ntable 1. latest trends in ai applications and benefits of using blockchain.\\nfigure 1. an overview of ai systems and features in relation to blockchain and iot-enabled ecosystems.\\nof using blockchain technologies. by integrating ai and\\nblockchain technologies, decentralized ai applications and\\nalgorithms can be developed, with access to an identical view\\nof a secure, trusted, shared platform of data, logs, knowledge,\\nand decisions. such platform can also be used to host a trusted\\ntrail of all records taken by ai algorithms before, during, and\\nafter the learning and decision making process [19].\\nc. how blockchain can transform ai\\nmany shortcomings of ai and blockchain can be addressed\\neffectively by combining both technological eco-\\nsystems [19], [41]. ai algorithms rely on data or informa-\\ntion to learn, infer, and make \\x1cnal decisions. the machine\\nlearning algorithms work better when data are collected from\\na data repository or a platform that is reliable, secure, trusted,and credible. blockchain serves as a distributed ledger on\\nwhich data can be stored and transacted in a way that is\\ncryptographically signed, validated, and agreed on by all\\nmining nodes. blockchain data are stored with high integrity\\nand resiliency, and cannot be tampered with. when smart\\ncontracts are used for machine learning algorithms to make\\ndecisions and perform analytics, the outcome of these deci-\\nsions can be trusted and undisputed. the consolidation of\\nai and blockchain can create secure, immutable, decen-\\ntralized system for the highly sensitive information that\\nai-driven systems must collect, store, and utilize [41]. this\\nconcept results in signi\\x1ccant improvements to secure the\\ndata and information in various \\x1celds, including medical,\\npersonal, banking and \\x1cnancial, trading, and legal data.\\nfigure 1 shows that ai can bene\\x1ct from the availability of\\nmany blockchain platforms for executing machine learning\\nvolume 7, 2019 10129',\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\ntable 2. key features and benefits of blockchain integration with ai.\\nalgorithms and tracing data that are stored on decentralized\\np2p storage systems. these data are typically originated\\nby smart connected products that include variety of sources\\nsuch as iot devices, swarm robots, smart cities, buildings,\\nand vehicles. the features and services of the cloud can be\\nalso harnessed for off-chain machine learning analytics and\\nintelligent decision making, and for data visualization. some\\nof the signi\\x1ccant features (as listed in table 2) of leveraging\\nblockchain for ai can be summarized as follows:\\n\\x0fenhanced data security. information held within\\nblockchain is highly secure. blockchains are very well\\nknown for storing sensitive and personal data in a disk-\\nless environment. blockchain databases hold data that\\nare digitally signed, which means only the ``respective\\nprivate keys'' must be kept secure [42]. this allows ai\\nalgorithms to work on secure data, and thereby ensuring\\nmore trusted and credible decision outcomes.\\n\\x0fimproved trust on robotic decisions. any decision\\nmade by ai agents becomes dysfunctional when it is\\ndif\\x1ccult for consumers or users to understand and trust.\\nblockchain is well known for recording transactions in\\ndecentralized ledgers on a point-by-point basis, making\\nit easier to accept and trust the decisions made, with\\ncon\\x1cdence that the records have not been tampered\\nwith, during the human-involved auditing process [42].\\nrecording the decision making process of an ai sys-\\ntem on a blockchain would increase transparency and\\nit would gain public trust to understand the robotic\\ndecisions [43]. the need for a third party auditor can\\nbe eliminated in a swarm robotic ecosystem, where the\\nconsensus in the swarm can be achieved through an\\nabsolutely decentralized approach [42]\\x15[44].\\n\\x0fcollective decision making. in a robotic swarm\\necosystem, all the agents need to work in coordination\\nto achieve the swarm goal [44]\\x15[46]. the decentralized\\nand distributed decision-making algorithms have been\\nadopted in many robotic applications, without the need\\nfor a central authority. robots take decisions by voting\\nand outcomes are determined by majority rules. each\\nrobot can cast its vote in the form of a transaction,\\nwhere blockchain is public for all robots which can be\\nutilized for veri\\x1ccation of voting results. this process\\nis repeated by all robots until the swarm comes to a\\ndecisive conclusion.\\n\\x0fdecentralized intelligence. for taking smart high level\\ndecisions which involve multiple agents to perform\\ndifferent subtasks that have access to the commontraining data ( e.g.,in case of supervised learning), differ-\\nent individual cybersecurity ai agents can be combined\\nto provide fully coordinated security across the underly-\\ning networks and to solve scheduling issues [45], [47].\\n\\x0fhigh ef\\x1cciency. multiuser business processes, which\\ninvolve multiple stakeholders such as individual users,\\nbusiness \\x1crms, and governmental organizations, are\\ninherently inef\\x1ccient due to multiparty authorization\\nof business transactions. the integration of ai and\\nblockchain technologies enables intelligent decentral-\\nized autonomous agents (or daos) for automatic and\\nfast validation of data/value/asset transfers among dif-\\nferent stakeholders [48].\\niii. taxonomy\\nthis section presents a detailed taxonomic discussion of key\\nconcepts to enable blockchain technologies for ai appli-\\ncations. figure 2 shows the classi\\x1ccation tree of existing\\nworks found in the literature which we categorized in terms\\nof decentralization of ai methodologies and operations,\\nblockchain infrastructure and types, and the underlying con-\\nsensus protocols utilized for distributed decentralized trans-\\naction validations across underlying networks.\\na. decentralized ai applications\\nai applications operate autonomously in order to perform\\ninformed decisions by executing different planning, search,\\noptimization, learning, knowledge discovery, and knowl-\\nedge management strategies. however, the decentralization\\nof ai operations is a complex and challenging task.\\n1) autonomic computing\\none of the key goals of ai applications is to enable fully\\n(or partially) autonomous operations whereby multiple intel-\\nligent agents ( i.e., small computer programs) perceive their\\nconstituent environments, preserve their internal states, and\\nperform speci\\x1ced actions accordingly [49]. in order to oper-\\nate autonomously, modern computing systems need to handle\\nmassive heterogeneity at all verticals including data sources,\\ndevices, data processing systems, data storage systems, and\\napplication interfaces, to name a few. the enablement of\\nmultiagent systems at all verticals does not only facilitate\\nthe handling of heterogeneity but it also helps in establish-\\ning inter-layer and intralayer operability across entire sys-\\ntems [50]. the blockchain architecture can play a vital role by\\nensuring operational decentralization and keeping permanent\\nfootprints of interactions between users, data, applications,\\n10130 volume 7, 2019\",\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\nfigure 2. taxonomy of blockchain for ai.\\ndevices, and systems which leads toward the development of\\nfully decentralized autonomous systems.\\n2) optimization\\nfinding a set of best solutions from all possible solutions\\nis one of the main features of ai-enabled applications and\\nsystems [51]. modern ai applications and systems operate\\nin various environments including pervasive and ubiquitous\\nenvironments ( e.g., edge computing systems), resource-\\nconstrained environments ( e.g., mobile devices/systems),\\ngeographically bounded systems ( e.g., personal area net-\\nworks, wireless local area networks, etc.), and centralized\\nmassively parallel and distributed computing systems ( e.g.,\\ncloud computing systems) [52]. based upon application-level\\nand system-level objectives, the optimization strategies work\\nin constrained or unconstrained environments [53]. these\\nstrategies facilitate \\x1cnding best solutions such as selecting\\nmost relevant data sources in pervasive environments, best\\ncandidate edge or cloud servers for data and application\\nprocessing, or enabling the resource-ef\\x1ccient data man-\\nagement in large-scale distributed computing environments.\\ncurrent optimization strategies are executed with cen-\\ntralized control considering system-wide/application-wide\\noptimization objectives which results in extraneous and\\nirrelevant data processing and inferior system/application\\nperformance [54]. the enablement of decentralized optimiza-\\ntion strategies using blockchain opens a new window ofresearch and development opportunities. the decentralized\\noptimization leads to increased system performance by pro-\\ncessing highly relevant data. the decentralized optimization\\nis also bene\\x1ccial when multiple strategies with different\\noptimization objectives need to be run simultaneously across\\napplications and systems.\\n3) planning\\nai applications and systems execute planning strategies in\\norder to collaborate with other applications and systems\\nand solve complex problems in new environments. planning\\nstrategies help in operational ef\\x1cciency and resilience of ai\\napplications and systems by taking current input state and\\nexecuting different logic and rule-based algorithms to reach\\nprede\\x1cned goals [55]. currently, the centralized planning is\\ncomplicated and time consuming task; therefore, blockchain\\nbased decentralized ai planning strategies are needed to offer\\nmore robust strategies with permanent tracking and prove-\\nnance history. the blockchain is also useful for devising\\ncritical and immutable plans for strategic applications and\\nmission critical systems.\\n4) knowledge discovery and knowledge\\nmanagement\\nmodern ai applications handle large amounts of data streams\\nand require support for centralized big data processing sys-\\ntems. the centralized knowledge discovery and knowledge\\nvolume 7, 2019 10131',\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\nmanagement bene\\x1cts the provisioning of application-wide\\nand system-wide intelligence, however, the applications\\nenable customized knowledge patterns for speci\\x1cc groups of\\nusers, applications, devices, and systems [56]. the decentral-\\nization of knowledge discovery processes and decentralized\\nknowledge management is envisaged to provide personalized\\nknowledge patterns considering the needs of all stakeholders\\nin the system. in addition, the blockchain technologies can\\nfacilitate in secure and traceable knowledge transfer among\\ndifferent stakeholders in ai applications and systems.\\n5) perception\\nintelligent agents and bots in ai applications and systems\\ncontinuously collect, interpret, select, and organize data\\nfrom their ambient environments using centralized perception\\nstrategies which results in monolithic data collection [57].\\nthe decentralized perception strategies can facilitate the col-\\nlection of data from different views. the blockchain based\\ndecentralization facilitates tracing the perception trajectories,\\nsecure transfer of collected data, and immutable data storage.\\nthe decentralized perception strategies are useful because\\nthe applications and systems do not need to collect the data\\nstreams for successful and high quality perceptions repeat-\\nedly. considering the permanent nature of blockchain, only\\nthe footprints of successful perceptions should be stored on\\nblockchain.\\n6) learning\\nthe learning algorithms stay at the heart of ai applications\\nin order to enable automation and knowledge discovery\\nprocesses. learning algorithms vary in terms of supervised,\\nunsupervised, semi-supervised, ensemble, reinforcement,\\ntransfer, and deep learning models. these learning models\\nsolve different machine learning problems from classi\\x1ccation\\nto clustering and regression analysis to frequent pattern min-\\ning. conventional learning models are trained and deployed\\nusing centralized infrastructure to achieve global intelligence.\\nthe decentralized learning models can help in achieving\\nhighly distributed and autonomous learning systems that sup-\\nport fully coordinated local intelligence across all verticals in\\nmodern ai systems [58], [59]. in addition, the blockchain\\nenables immutable and highly secure versioning of learning\\nmodels by maintaining provenance and historical aspects of\\ndata. however, considering the permanent nature of smart\\ncontracts, learning models need to be trained and tested well\\nprior to deployment on blockchain.\\n7) search\\nai applications need to operate in large and sparse search\\nspaces ( i.e.,big datasets or multivariable high dimensional\\ndatastreams); therefore, ef\\x1ccient search strategies become\\nthe essence of ai technologies. the search strategies are\\ndesigned by considering different factors such as complete-\\nness, complexity ( i.e.,time and space), and optimality. these\\nstrategies generally operate on nonlinear data structures\\nsuch as trees and graphs whereby the algorithms start theirexpansion from an initial state and gradually expand until\\n\\x1cnding the required variable or completing the traversals in\\nwhole search spaces. normally, search strategies are imple-\\nmented using large-scale centralized and distributed infras-\\ntructure in order to maximize the operational ef\\x1cciency [60].\\nhowever, their implementation using decentralized infras-\\ntructure needs careful investigation. it is envisaged that\\ninstead of deploying core search strategies, blockchains and\\ndecentralized infrastructure should be used to permanently\\nand securely store successful search traces and traversal\\npaths which could provide optimal search solutions of similar\\noperations in the future.\\n8) reasoning\\nlogic programming is an essential component of ai appli-\\ncations that allows to develop inductive or deductive rea-\\nsoning rules to reach decisions. the centralized reasoning\\nin ai applications leads toward generalized global behavior\\nacross all application components [61]. to handle this issue,\\nblockchain based distributed reasoning strategies are envis-\\naged to facilitate the development of personalized reasoning\\nstrategies which could be more bene\\x1ccial during perception,\\nlearning, and model deployment. in addition, smart con-\\ntract based decentralized distributed reasoning on blockchain\\nensures the availability of unforgettable reasoning processes\\nwhich may help in future executions of similar reasoning\\nstrategies.\\nb. decentralized ai operations\\nai applications generally handle large amounts of data for\\nbetter and versatile decision making. however, centralized\\ndata storage using clouds, data centers, and clusters, becomes\\na major bottleneck for developing highly secure and pri-\\nvacy preserving ai applications. in addition, learning model\\ndevelopment and deployment become tedious in some situa-\\ntions. table 3 shows comparisons of some recent blockchain\\nimplementations that could potentially be adopted for\\nai applications.\\n1) decentralized storage\\nthe centralized data storage becomes highly susceptible in\\nterms of privacy and security when it involves personal and\\nsensitive data about users, locations, activities, health records,\\nand \\x1cnancial information. in addition, large-scale data collec-\\ntion exposes the scaling and capacity related issues of cen-\\ntralized infrastructure where ai applications need to process,\\ntransform, and store big datasets. blockchain-based decen-\\ntralized storage infrastructure facilitate in cryptographically\\nsecure data storage across the participating networks [38],\\n[62]\\x15[64]. in these systems, each node keeps a client-centric\\n(a client could be a user, application, or node performing\\ntransactions on the blockchain) publicly encrypted copy of\\nwhole database in order to ensure data availability for desired\\nclients. the respective clients can mine and use their own data\\nwhenever needed.\\n10132 volume 7, 2019',\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\ntable 3. key features and benefits of blockchain platforms.\\nsharding and swarming are core solutions for decentral-\\nized storage [65]\\x15[67]. sharding is the process of creating\\nlogical partitions of databases whereby each partition is\\nassigned a unique key which is used to access it. the shards\\nare further grouped together and their collected storage is\\nsupported by a group of nodes in the network in the form\\nof swarms. swarms reduce latency in ai applications by\\nenabling parallel data access from multiple nodes in the\\nnetwork. in addition, scalability and reliability of storage\\nincreases because of geographically distributed multiparty\\ndecentralized storage systems. a few emerging decentralized\\ndata storage systems include storj, swarm, sia, filecoin, and\\nipfs which are further reviewed later in section iv-a.\\n2) data management\\nin addition to ef\\x1ccient decentralized storage, ai applications\\nneed to manage the data such that highly relevant, accu-\\nrate, and complete datasets are collected from reliable data\\nsources. traditionally, ai applications run centralized data\\nmanagement schemes which execute across all the nodes\\nin the underlying network [68]. these strategies includedata \\x1cltration, data segmentation, context-aware data storage\\nand routing in underlying networks, temporal data manage-\\nment and intelligent data management schemes. considering\\ndecentralized storage networks and immutability constraints\\nin blockchains, centralized data management becomes hugely\\ninef\\x1ccient because it will not only increase data duplication\\nin case of minor changes in the data but it will also need to\\ntransfer similar datasets repeatedly. in case of big datasets,\\nthis massive data transfer will lead toward quick band-\\nwidth overloading and increased backhaul network traf\\x1cc;\\ntherefore, decentralized data management becomes essen-\\ntial for blockchain based ai applications. the decentralized\\ndata management schemes are envisaged to be deployed at\\nnode levels in the network considering temporal and spatial\\nattributes in the data. in addition, the decentralized data man-\\nagement schemes can put the metadata on the blockchain in\\norder to maintain security and provenance of the data. the\\nactual data could be stored in traditional large-scale storage\\nsystems such as cloud data centers and clusters. in the case\\nof client-centric small datasets, the metadata and actual data\\nare stored on the blockchain and data are managed across\\nvolume 7, 2019 10133',\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\nthe network using token-based incentives for nodes storing\\ndifferent shards or participating in the swarms.\\n3) learning model development\\nlearning plays key role in ai applications to understand\\nthe environment from current data and perform informed\\ndecision making based on new data. normally, learning mod-\\nels are trained and tested before actual deployment in the\\nreal systems. the centralized training is costly because the\\nmodels need to learn from the whole datasets and tend to be\\nprone to over\\x1ctting ( i.e., produce outputs based on memo-\\nrized data), however, modern ai applications need to handle\\ncontinuously evolving data streams. the decentralization of\\nlearning model development process is a feasible approach\\nin order to develop resource-ef\\x1ccient learning models for\\nclient applications [58]. decentralized learning algorithms\\ntake the input datasets from relevant swarms and shards\\nand produce highly personalized learning models for each\\nclient. in addition, blockchain technologies can facilitate the\\nmaintenance of provenance of data as well as immutable\\nhistory of learning models which may evolve over a certain\\nperiod of time. further the decentralized learning models\\ncould become benchmark for similar clients in the blockchain\\nnetwork where the users do not need to train the model from\\nscratch, rather, they can incrementally build their own models\\nby tuning and training new models. once trained ef\\x1cciently,\\nthe learning models could be tested using multiple smart\\ncontracts in decentralized applications.\\n4) model deployment\\nthe real performance of a trained model is assessed after\\ndeployment in production environments. however, the model\\ndeployment is a frequent and iterative process whereby devel-\\nopers need to continuously improve the models and correct\\nthe biases ( i.e., producing a speci\\x1cc set of decisions by\\nignoring rest of possible decisions) in order to produce highly\\neffective and informed decisions. the model deployment in\\ncentralized systems is a straightforward iterative process,\\nhowever, it becomes challenging when deployed in decen-\\ntralized systems [69]. smart contract based model deploy-\\nment addresses these challenges by permanently recording\\nthe changes and maintaining the immutable versioning of dif-\\nferent models. in addition, model sharing between different\\nai applications becomes secure and more trustworthy since\\nthe developers can track the provenance and all footprints of\\nany speci\\x1cc version of a model.\\nc. blockchain types for ai applications\\nblockchain technologies are categorized as permissioned\\n(i.e.,only authorized users can access the blockchain applica-\\ntions in private, consortium, or cloud based settings) or per-\\nmissionless ( i.e.,publicly accessible for all users via the\\ninternet) systems.1) public\\npublic blockchains are known to be permissionless systems\\nwhere users can download the blockchain code into their own\\nsystems, modify it, and use it according to their own require-\\nments [4], [11]. in addition, public blockchains are easily\\naccessible and open for read and write operations by all par-\\nticipants on the network. due to their openness, user identities\\nand transactional privacy information on these blockchain\\nare managed using anonymous and pseudonymous data on\\nthe network. also, these public blockchains use complex\\nprotocols for security and consensus mechanisms. the asset\\nand data transfer at these blockchains use native tokens\\n(i.e.,cryptocurrencies or value pointers) for each public\\nblockchain. public blockchains are widely adopted due\\nto their massive decentralization and openness, however,\\nthe participants ( i.e.,users/validators) on these blockchains\\nare always unidenti\\x1ced. hence, these blockchains are always\\nprone to malicious security attacks which can result in mas-\\nsive value and data theft. public blockchains need consensus\\nof at least 51% validators and use complex mathematics\\nto break security codes which result in large energy con-\\nsumption and are also prone to attack in case the attackers\\ngain control on 51% validators on the network. the transac-\\ntion approval time on public blockchains is relatively longer\\nwhen compared with private and consortium blockchains.\\ntypically, a transaction on public blockchain is approved\\nin 10 minutes or more but this approval time depends on the\\nnumber of participants on the network and the mathematical\\ncomplexity of employed consensus algorithms.\\n2) private\\na private blockchain is managed by a single organiza-\\ntion. unlike public blockchains, the private blockchains are\\ndesigned as permissioned systems where users and partici-\\npants in the systems are pre-approved for read/write opera-\\ntions and are always known within the network [87]. private\\nblockchains are comparatively faster due to known identities\\nof validators and pre-approved participants in the network;\\ntherefore, it requires less complex mathematical operations\\nto validate transactions on the network. in addition, private\\nblockchains can transfer any kind of indigenous data, values,\\nand assets within the network. the approval of transactions\\nand asset transfers are managed using voting or multiparty\\nconsensus algorithms which consume low energy and enable\\nfast transactions. the transaction approval time on private\\nblockchains usually remains lower than one second.\\n3) consortium\\nconsortium blockchains (also known as federated\\nblockchains) are operated by a group of organizations. the\\ngroups are usually formed based on the mutual interests of\\nparticipating organizations [88]. different groups such as\\nbanks, governmental organizations, and private blockchain\\ncompanies offer different types of federated blockchains.\\nlike private blockchains, consortium blockchains operate as\\n10134 volume 7, 2019',\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\npermissioned systems, however, few participants can perform\\nboth read and write operations on the blockchain. usually,\\nall the participants on the network can read the data on the\\nblockchain, however, a few authorized and trusted users can\\nwrite the data on the blockchain. the consortium blockchains\\nare comparatively faster than public blockchains because the\\nparticipants are always pre-approved with known identities.\\nin addition, these blockchains consume less energy because\\nof voting based or multiparty approval based consensus\\nprotocols. a typical transaction on federated blockchains gets\\napproval within one second.\\n4) blockchain-as-a-service (baas)\\ncloud service providers are focusing on blockchain technolo-\\ngies due to massive adoption and acceptance by governments\\nand large enterprises. major cloud vendors like microsoft,\\namazon, and ibm are enabling their environments to develop\\nand test blockchain services for their customers [89], [90].\\nthe emergence of baas is envisaged to bene\\x1ct both pri-\\nvate and consortium blockchain companies whereby their\\nmajor focus remains on value addition through application\\ndevelopment, testing, and deployment without considering\\nunderlying network, storage, and computational infrastruc-\\nture. the enablement of baas not only leads toward new\\ncross-industry public-private consortia but it also helps in\\nleveraging new business opportunities and business-customer\\ninteraction models. developers are also empowered with\\nsingle-click provisioning of baas services in order to write\\nthe smart contracts. since the major cloud vendors already\\noffer a large plethora of cloud services for ai applications,\\nthe integration of baas with ai services is opening a new\\nworld of opportunities for application developers.\\nd. decentralized infrastructure for\\nai applications\\ntraditionally blockchain architectures were designed as\\nlinear infrastructure based on the combination of linked list\\ndata structures and hashing strategies. however, nonlinear\\ninfrastructure based on graph theory and queuing information\\nmodels are also emerging to cater the needs of real-time\\napplications and handle big data.\\n1) linear infrastructure\\nthe single chain based blockchain architectures grow linearly\\nwhereby new blocks are appended at the end of the\\nchain. early decentralized systems operate on single chains,\\nhowever, these systems have multiple issues. single chains\\nscale up slowly and compromise the real-time performance\\nof decentralized applications [4], [11]. in addition, separate\\nsingle chains are required for each business scenario therefore\\nvalue, information, and asset exchange in multiple chains is\\nimpossible. single chain blockchains for ai applications can\\nbe used for single task ai applications performing search,\\noptimization, and learning, or operating autonomously in\\nhomogeneous environments. single chain based blockchains\\ncould be more useful when, instead of executing theai applications using smart contracts, only the performance\\nhistories need to be stored permanently. for example, how\\na deep learning model is producing accurate results when\\napplied to the diagnosis of liver cancer in radiology appli-\\ncations. another example could be the successful search\\nfootprints of remote industrial robots. since ai applica-\\ntions usually operate in unconstrained environments therefore\\nputting whole ai application components on blockchain is\\nnot a feasible choice.\\n2) nonlinear infrastructure\\nnonlinear blockchain architectures are implemented in the\\nform of multichain architectures whereby blockchain topolo-\\ngies are used in the form of parent-child chains, main-side\\nchains, and parallel chains [91]. the multi-chain architectures\\nare not only scalable for real-time performance but also\\nsupport diverse business scenarios and cross-chain value\\ntransfers. in multi-chain architecture one or more chains\\nkeep information about other chains and serve(s) as main\\nchain. rest of the chains serve as side, child, or parallel\\nchains. the child and side chains normally operate similarly,\\nhowever, in child chains, the business scenarios are tightly\\nlinked with parent chains but side chains can totally operate\\nindependently from main chains. the parallel chains operate\\nindependently from other chains. the value transfer between\\ndifferent chains is performed using ``pegging'' approach\\nwhere a two-way peg process is executed for bidirectional\\nvalue transfer at a \\x1cxed exchange rate between chains. the\\nexchange value is represented by native coins or tokens in the\\nblockchain. the detailed discussion on nonlinear blockchains\\nis presented in following studies for interested readers [71].\\nnonlinear blockchains for ai applications facilitate the exe-\\ncution of multiple interrelated or independent ai tasks in\\nthe decentralized applications. in addition, the scalability\\nfeatures allow to execute ai applications in both development\\nand deployment phases in parallel. ai components in pro-\\nduction environment are deployed on the main/parent chain\\nwhile the training and testing applications are deployed on the\\ntestnets or side chains. nonlinear architectures also bene\\x1ct\\nemerging applications such as those using reinforcement and\\nadaptive learning algorithms where the main applications\\nneed to continuously update their performance by retraining\\nthe learning models. in this case, learning models are devel-\\noped on side chains and deployed on main chains.\\ne. the role of consensus protocols for\\nai applications\\nthis subsection presents common consensus protocols and\\nhow they can impact the performance of ai applications on\\nblockchain. table 4 shows different implementations of these\\nprotocols.\\n1) proof or work (pow)\\npow is the pioneer consensus protocol proposed by satoshi\\nnakamoto, an anonymous founder of cryptoccurency and\\ndecentralized distributed ledger technologies. popular public\\nvolume 7, 2019 10135\",\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\ntable 4. consensus protocols used by blockchain platforms.\\nblockchain systems, such as bitcoin and ethereum, validate\\ntransactions after participation of at least 51% nodes on the\\nunderlying network using pow consensus protocol [4], [11].\\nsince the validating nodes operate anonymously and in large\\nquantity, these nodes need to mine the blocks by solving a\\ncomplex and random mathematical problem and break the\\nhash code to read the transactions on the blockchain. the\\nsuccessful nodes transmit the solution on peer-to-peer net-\\nwork to receive the rewards. new transactions and data are\\npermanently added to the blockchain when 51% nodes on\\nthe network successfully solve the mathematical problem.\\nalthough pow proved to be highly adopted consensus proto-\\ncol, in large networks it consumes gigantic amount of energy\\nand increases delay in transaction approvals. ai applications\\nhave high frequency of write operations because the intelli-\\ngent algorithms continuously update the decision structures\\nfor informed decisions. therefore, pow protocols become\\nperformance bottleneck in real-time ai applications. in addi-\\ntion, 51% attack on the underlying network can compromise\\nthe security of ai applications.\\n2) proof of stake (pos)\\npos based consensus protocols solve the high energy con-\\nsumption issue of pow [92]. the pos protocols work by\\nde\\x1cning big stakeholders on the blockchain network and\\nallowing them to create new blocks. these protocols select\\nthe validators based on different criteria ( i.e.,random val-\\nidators, delegated validators, high frequency transacting\\nvalidators, or validators holding coins for longer period).\\npos proved to be energy-ef\\x1ccient when compared with pow\\nand it also indirectly solves the security problem by stopping\\nthe anonymous validators and allowing only those validatorswho own the native currency of the blockchains. however,\\nthe validators have nothing to lose on the blockchain if they\\ndo not validate the transactions; therefore, it may cause delay\\nwhile creating new blocks. pos could be useful for delay-\\ntolerant ai applications but these protocols are not suitable\\nwhen ai applications need to handle streaming data, detect\\nchanges, and performed real-time informed decisions.\\n3) byzantine fault tolerance (bft)\\nbft is the majority voting algorithm that rules out valida-\\ntions from malicious nodes on the blockchain network [81].\\nthe malicious nodes are already part of the blockchain but\\ncontain malicious intent code that can directly/indirectly\\nlead to incorrect validations and corrupt the data stored\\non the blockchain. since all nodes are part of blockchain\\nnetworks, it becomes challenging for bft protocol to \\x1cnd\\nthese malicious nodes. although its implementation is dif\\x1c-\\ncult, bft algorithms are historically used in critical systems\\nsuch as airplane engine systems, large-scale sensory systems,\\nand nuclear systems. different variants of bft protocols\\nare used. simple bft handles fault tolerance as long as at\\nleast two-third non-faulty nodes are present on the network.\\nother bft algorithms handle the fault tolerance by enforcing\\ndigital signatures and restricting communications between\\npeer nodes on the network. considering successful imple-\\nmentations of bft algorithms in critical systems, bft based\\nconsensus could become handy for ai applications.\\n4) proof of activity (poac)\\nthe poac protocol is a hybrid of pow and pos. this\\nprotocol initially works on empty blockchains using\\npow algorithm and solves the 51% attack problem [93].\\n10136 volume 7, 2019',\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\ninitially, poac protocol solves complex mathematical prob-\\nlems and the validators start receiving the rewards which\\nincreases their stake on blockchains. the protocol then\\nenables pos algorithm for validators having acceptable stake\\non the blockchain. poac has been proven to be ef\\x1ccient\\nin terms of security, storage, and network communication.\\ntherefore, it could become handy for ai applications requir-\\ning less data availability and more security.\\n5) proof of burn (pob)\\nthe pob protocol allows the validators only if they spend\\ntheir coins by sending to a public, veri\\x1cable, unspend-\\nable, and invalid address. once the users burn their coins,\\nthey are immediately allowed to create new blocks and get\\nrewarded [94]. pob bene\\x1cts the users by allowing them to\\ninvest initially and create their stake on the blockchain and\\nbecome authorized validators. it also solves the energy con-\\nsumption problem of pow. in addition, coin burning strategy\\nreduces the number of coins on the blockchain; therefore,\\ncoin value increases gradually. coin burning also bene\\x1cts in\\nbalancing the number of coins on the blockchain, spending\\nunsold coins, and paying for transaction fees on the network.\\nai applications can harness pob protocols if they want to\\nincentivize the users in order to maintain the value of under-\\nlying decisions. for example, the applications which need\\nto maintain a speci\\x1cc level of accuracy, a certain number of\\nclusters, or minimum number of objects to be found, can burn\\nthe learning models and search trees in order to maintain the\\nvalue across the blockchain.\\n6) proof of elapsed time (poet)\\ninstead of engaging all users in the validation process, poet\\nprotocols \\x1cnd a leader who can create new blocks on the\\nchain. a poet protocol works by associating a random\\ntimer with each node on the network and the node with\\nminimum expiry is selected as the leader [95]. the leader\\nnode creates the new blocks and transmits its signature to\\nthe whole network. a poet protocol continuously executes\\nthe random leader selection algorithm and \\x1cnds new lead-\\ners all the time. it also enables to \\x1cnd malicious users in\\ncase the same nodes are selected as leaders or the minimum\\ntimer value is frequently assigned to speci\\x1cc nodes. poet\\nsolves the energy consumption problem of pow but due\\nto random timer assignment, ai applications could become\\nslow since the system needs to wait until the expiry of\\ntime. poet could be useful when used with delay-tolerant\\napplications.\\n7) proof of capacity (poc)\\ntraditional pow algorithms become computationally inten-\\nsive because they need to \\x1cnd random nonce values in order\\nto unlock the blocks. the poc protocol, also known as proof\\nof space, works as an alternative protocol by discovering the\\nhard drive space on the nodes of the blockchain network [96].\\ninstead of random generation, it stores all possible nonce\\nvalues on hard drive and \\x1cnds the matching nonce-hash pairsto unlock the blocks. using poc, the nodes with large disk\\nspace get more stake with high probability.\\n8) proof of authority (poa)\\npoa solves high energy consumption issue of pow. poa pro-\\ntocols also solve the problem of dependency in pos whereby\\nvalidators must have monetary stake on the blockchain.\\na poa protocol works by delegating authoritative control to\\nspeci\\x1cc nodes that collectively form the consensus based on\\nmajority votes to create new blocks on the network [100].\\npoa is proved to be energy ef\\x1ccient and minimal delay\\nconsensus protocol but it is more suitable for private networks\\nin order to delegate the validation authority to legitimate\\nstakeholders. therefore, blockchain implementers must con-\\nsider legal identity of validators, a well-de\\x1cned eligibility\\ncriteria to act as validator, and a universal eligibility criteria\\nfor all stakeholders to act as validators. despite their energy\\nef\\x1cciency and cost effectiveness, the security threats to poa\\nalways remain high due to security attacks on validators\\nwho can potentially become a source of attack across the\\nnetwork. however, poa could be used as an alternate con-\\nsensus protocol for those ai applications that are deployed\\non private or consortium networks since all the validators are\\nknown across the system.\\n9) proof of importance (poi)\\npoi protocols are similar to their poa counterpart whereby\\nvalidating nodes are ranked considering frequency of suc-\\ncessful validations. the validators with high frequency get\\nmore importance on the blockchain and their approved trans-\\nactions or blocks over-weigh other validators on the network\\nbecause poi sets the minimum threshold that must be met\\nby nodes for successful validations [101]. since the impor-\\ntance of validators is established considering their previ-\\nous successful validations, a poi protocol ensures high trust\\nbetween participating nodes. therefore, this protocol can be\\nuseful for ai applications on public blockchains. however,\\nin private and consortium networks, poi can lead to serious\\ncon\\x1dicts among stakeholders because important stakeholders\\ncan potentially monopolize the whole network.\\nalthough we discussed the major implementations,\\na thorough study of literature reveals that there are many\\nother consensus protocols that could be potentially used\\nfor ai applications. since these studies are relevantly\\neither new or not widely accepted yet, we do not discuss\\nthese works in this paper. interested readers may explore\\nproof of luck [102], proof of exercise [103], proof of\\nownership [104], proof of vote [105], and proof of retriev-\\nability [106] for further discussions on consensus protocols.\\niv. blockchain-enabled ai applications\\nin this section, we describe works reported in the literature\\non how blockchain can be leveraged in ai to improve the\\nreliability, security, transparency, trust, and management of\\ndata and algorithms in ai applications.\\nvolume 7, 2019 10137',\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\na. decentralized data storage and\\nmanagement with ai\\nthe combination of ai and blockchain technologies has\\npaved the way for many stable systems that support the inter-\\naction of multiple agents; therefore, providing an excellent\\nplatform for safe and secure data management, storage and\\ntransfer. some of the key systems that utilize this combination\\nare discussed in this subsection.\\na decentralized, multiagent approach for vehicle rout-\\ning in a large-scale dynamic environment is proposed in\\n[107] and [108]. this approach is based on environment-\\ncentric coordination mechanism, inspired by ant colonies.\\nthe authors propose an approach where intelligent agents\\nscrutinize the environment on behalf of vehicles and fore-\\ncast a congestion. this anticipatory vehicle information is\\ncollected and distributed in a decentralized fashion. this\\napproach \\x1cts the distributed nature of the traf\\x1cc domain and\\nensures that scalability requirements are more easily met\\nwhen compared to centralized systems. this approach can\\nroute vehicles more ef\\x1cciently by using forecast information;\\nthus, avoiding congested routes and providing better guid-\\nance in rerouting. further, the experimental results of this\\ndecentralized approach indicate a performance improvement\\nof 35% in terms of speed; therefore, helping drivers reach\\ntheir destinations faster [107], [108]. the intelligent approach\\nutilized by multiple agents in a decentralized environment\\nguarantees to not only avoid existing congestions but also to\\nprevent congestions in the near future.\\nthe combination of ai and blockchain technology adds\\nprogressive value to biomedical research and healthcare\\nsector [109]. the authors present a novel, decentralized\\nmodel to assess the value of time and the combined value of\\npersonal data in an ai-moderated healthcare data exchange\\non the blockchain. an overview of ai and blockchain tech-\\nnologies is presented in this paper which may be used to\\naccelerate biomedical analysis, improve predictive analysis\\ntechniques and empower patients with new tools to manage\\nand control their own data and help them monetize their\\nexclusive personal data with incentive bene\\x1cts to undergo\\nperpetual monitoring of their health. an ai-blockchain based\\nsystem can dramatically simplify data acquisition. they allow\\nthe user to upload her/his data directly to the system and\\ngrants permission to use her/his data if it were bought through\\nthe system using transparent pricing formula determined by\\na data value model and it guarantees fair tracking of all\\ndata usage activities. mamoshina et al. [109] discuss various\\npromising machine learning techniques in practice and in\\ndevelopment that include capsule networks, recursive cortical\\nnetworks, and many other advances that are being made in\\nsymbolic learning and natural language processing. however,\\ntechniques such as transfer learning, recurrent neural net-\\nworks, and generative adversarial networks are building up\\nacceptance to be applied to the blockchain based decentral-\\nized personal data marketplaces.\\nthe integrated features of these technologies can play a\\nsigni\\x1ccant role in healthcare assistance too. socially assistiverobots can be employed in elderly care assistance as discussed\\nin [110]. as there is an increasing demand for elder care\\nand a shortage of professional caregivers, socially assistive\\nrobots are one of the most promising technologies that can\\nact as a communication interface and identify the needs of\\nthe elderly or seriously ill patients. these robots aim to\\ncreate a positive user experience, motivate the patients and\\nto improve the quality of life by assisting the patients in\\nregular exercise, reduce stress levels and for personal care-\\ngiving [110]. though ai techniques are ef\\x1ccient classifying\\nand analyzing large datasets in the healthcare sector with the\\navailability of huge volumes of raw medical data from the\\nsensors of connected iot devices, there are severe issues of\\nintegrity in terms of data collection and storage [43]. also,\\nit is a jeopardy to trust a robotic agents' decision or activity\\nin the medical \\x1celd where all medical records need to be\\naccurate and tamper-proof during a critical decision-making\\nprocess. however, the combination of blockchain and ai\\ntechnology could personalize medicine, quadrate treatments\\nand health recommendations based on a patient's medical\\nhistory, genetic lineage, stress levels, geography, atmospheric\\nconditions, past medical conditions and aid in improving\\ntrust on robotic decisions. the information can be securely\\nstored on a distributed, decentralized and immutable patient\\nrecord, as well as a graph-based relationship database, can\\nbe formulated [43] for storing unstructured data and the rela-\\ntionships amongst the data. figure 3 presents an outline of the\\ncombined features of ai and blockchain technologies for the\\nmedical \\x1celd which include various stages such as diagnosis,\\nanalytics, critical decision making and validation of medical\\ntest reports, etc.\\nmachine learning algorithms can use the graph database to\\nextract data, classify patterns and predict future prescriptions.\\nbayesian network, a graph database built on relationships of\\ncause and effect, is an example of machine learning algo-\\nrithms that use graph data to compute latent variables [43].\\nthe vitality of a bayesian network lies in its capability to\\nregulate probabilities and predictions. when applied to health\\ndata, it can make effective predictions between unrelated\\ndata. the relationship of all entities in the healthcare graph\\ndatabase (such as physicians, specialists, medical researchers,\\ndrug manufacturers, patients, etc. and their activities which\\ninclude treatment methods, prescriptions, and intake of drugs\\nby patients) can be recorded on the immutable transaction log.\\nthe importance of handling vast volumes of data, exponen-\\ntial increase in computing power, and tremendous growth in\\npeople's acceptance of connected applications and systems\\nto register actions have become top priorities in ai and\\nmachine learning research [111]. since arti\\x1ccial neural net-\\nworks require large sets of data and high computing power for\\ntraining purposes, a signi\\x1ccant amount of resources to create\\npowerful data centers to acquire large datasets have become\\nessential [40], [112]. woods [111] emphasizes the importance\\nof combining ai techniques and blockchain infrastructure to\\ntackle the security threats faced by the internet, where bots-\\nbots and human-bots interactions have increased, as 52% of\\n10138 volume 7, 2019\",\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\nfigure 3. collective intelligence for decentralized healthcare.\\nthe web traf\\x1cc is generated by bots. due to increased bot traf-\\n\\x1cc, it is estimated that in the near future the bot-bot commu-\\nnications will outpace the human-bot interactions. bots will\\nneed to be able to query each other for identi\\x1ccation and then\\nlook up the history of the data and ratings before interactions.\\nduring an audit process, the query information and data can\\nbe stored on blockchain and a higher level of transparency and\\nsecurity can be achieved [111]. the integration of blockchain\\nand machine learning technologies is a stronger combination\\nthat provides an immutable, strong consensus mechanism,\\nultra-secure decentralized, self-sovereign identity which has\\nthe stupendous potential to rebalance and improve machine\\nlearning algorithms.\\nb. decentralized infrastructure for ai\\nblockchain infrastructure introduced three new characteris-\\ntics to the traditional distributed architectures which include\\ndecentralized and shared control, immutable audit trails, and\\nnative asset exchanges [11]. combined with ai techniques,\\nthis infrastructure provides users with qualitatively new data\\nmodels, shared control of ai training data and models, and\\nleads to improved trustworthiness on data. ai requires huge\\ndata, which is provided by blockchain, to produce better\\ndata models. this subsection discusses existing decentralized\\ninfrastructure and frameworks for ai applications.\\nan open source platform that incentivizes individuals to\\nbuild a distributed and decentralized ai agents thereby cre-\\nating a synergy between distributed ai and decentralized\\nblockchain is carried out by chainintel [113]. chainintel isaimed to deploy and use ai models in decentralized applica-\\ntions (dapps). this platform aims to reinforce and consign\\nthe execution of ai models to various parts of the network,\\nenabling scalable, robust and smart applications. chainintel\\nis currently working to allow distributed ai model execution,\\nwhere some parts of a deep neural network run on local\\ndevices and other parts run on a set of active nodes in the\\nchainintel p2p network [113]. this work aims to incorporate\\nvarious ai features into decentralized applications such as\\nfacial recognition, speech and image recognition, semantic\\nanalysis, disparity identi\\x1ccation, smart homes, smart cities\\nand countless more domains. decentralized networks such\\nas ethereum and ipfs can handle the huge computational\\nresources and data storage respectively, thereby providing a\\nhigh level of privacy and tamper-proof records [44], [113].\\nthis open-source decentralized ai platform aims to phase out\\nmonopolization of ai services provided by big companies in\\nwhich the miner-nodes should be optimized to solve a huge\\nnumber of matrix computations and directs it to be effectively\\ndecentralized.\\nthe energy-based infrastructure can reap huge benediction\\nby combining the ai and blockchain technologies and their\\nfeatures. mylrea and gourisetti [114] have explored how\\nblockchain technology could possibly modernize and auto-\\nmate energy and iot infrastructure toward a stable system.\\nthe author highlights how ai enabled blockchain solutions\\ncan assist in increasing cyber resilience and augmenting the\\nexchange of energy resources in a distributed environment\\nby using encryption techniques and by automating the trans-\\naction. mylrea and gourisetti [114] discuss how ai-enabled\\nvolume 7, 2019 10139',\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\nfigure 4. future energy industry leveraging capabilities of blockchain and ai.\\nblockchain solutions can help to analyze huge datasets gath-\\nered from numerous platforms such as frequency and load\\nchanges, industrial control anomalies and frequency changes,\\nand classify the datasets into weighted relationships, which\\ncan be tracked and automated with the help of blockchain\\ntechnology. arti\\x1ccial neural networks are being employed to\\nanalyze and understand the data patterns whereas blockchain\\nbased smart contracts can be exercised to secure the energy\\ndata and its transactions on the decentralized network.\\nan overall vision for transforming the energy market and\\nutility industries with blockchain, robotics, and ai techniques\\nis presented in figure 4. a key-less signature blockchain\\ninfrastructure (ksbi) is highlighted in this work, as ksbi\\ndiffers from pow and retains integrity of original data and\\nits ability to scale to industrial applications to add one trillion\\ndata items to the blockchain each second, and to verify the\\ndata item from the blockchain within the next second [114].\\noptimization and security issues in the energy grid can be\\nresolved and improved by blockchain by providing a ver-\\ni\\x1cable distributed ledger which helps in improving trans-\\nparency and integrity in the energy delivery sector [114].\\nif implemented successfully, this approach can replace tra-\\nditional energy meters with a dynamic and decentralized\\ndistributed ledger. this disruptive combination may endow\\nstakeholders and investors in renewable energy infrastruc-\\nture with the power to vote, ef\\x1cciently automate the energy-\\nbidding auction, and monitor and deliver services based on\\nthe agreements made on smart contracts in a transparent\\nand distributed environment [114]. yu et al. [115] designed\\na high-performance blockchain platform for smart devices.\\nthis platform enables a stable connection between devices\\nthrough the node-to-node mapping mechanism using tech-\\nnologies such as distributed network architecture, intelligent\\ndevices node mapping, as well as pbft-dpoc consensus\\nalgorithm. yu et al. [115] propose a new delegated proof ofcontribution (dpoc) algorithm to facilitate any node to run\\nas a block producer (bp). in this method, all the candidates\\nneed to contribute their own hardware infrastructure which\\nincludes computing power, storage, and bandwidth, such that\\nall nodes take part in the voting process. the \\x1cnal ranking is\\ndetermined by votes and miner's weight-sum seniority rank-\\ning. during this voting process, many super-nodes and sub-\\nstitute nodes are generated. the super-nodes reach consensus\\nby generating blocks through the pbft algorithm [115] and\\neach block has the digital signature of remaining bp nodes.\\nif a node is found to be dishonest or inactive in the network\\nduring the block veri\\x1ccation process, it is blacklisted and\\nreplaced with a substitute node. this platform tested the\\ntransaction throughput and system delay of the intelligent\\ndevice blockchain and compared it with the performance\\nof public blockchains such as bitcoin and ethereum [115].\\nthe experimental results showed that the intelligent device\\nblockchain has higher transaction throughput and lower trans-\\naction latency than that of bitcoin and ethereum and provided\\nhigher ef\\x1cciency.\\nc. decentralized ai applications\\ndecentralized intelligence and collective decision making\\ncan play the main role in identifying the malicious behavior\\nof byzantine robots. byzantine robots are those that exhibit\\nmalicious or faulty behavior arbitrarily in a swarm envi-\\nronment. strobel et al. [46] propose a proof of concept\\nfor handling security issues in swarm robotic ecosystems\\nusing the blockchain technology. this approach utilizes the\\ndecentralized nature of smart contracts to build a secure\\nswarm systematization mechanism to analyze and exclude\\nthe byzantine members from the swarm. this scheme was\\ndesigned analogous to classical approaches and the behav-\\nior of robots is determined by a probabilistic \\x1cnite state\\nmachine which consists of two phases i.e.,exploration state\\n10140 volume 7, 2019\",\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\nand dissemination state [46]. each robot in the swarm saves a\\ncopy of safety measurement on the blockchain for identifying\\nbyzantine robots.\\nthe blockchain based approach creates a number of voting\\ntransactions sent by the robots to their neighbors in the swarm\\nand all these votes get stored in the blockchain. this approach\\nproved that a blockchain based swarm ecosystem preserves\\nthe integrity of the transactions and provides a direct interface\\nfor securely storing the record of events in a decentralized\\nlog [46]. this approach also demonstrated that the transac-\\ntions can be veri\\x1ced even if some of the swarm members are\\nlost or leave the swarm. in the blockchain based network,\\nkeys that are publicly available are the foremost available\\ninformation for an agent to transfer information in a secure\\nmanner [114]. with respect to swarm robots, a robot can send\\ninformation to a speci\\x1cc robot and only a robot that possesses\\na matching private key will be able to read the message;\\nhence, the possibility of a data breach can be prevented.\\ndigital cryptography of the blockchain ensures that the robots\\nare allowed to use their private keys for encrypting a message.\\nthe other robots can then decrypt the message by using the\\npublic key of the sender [114]. digital signature cryptog-\\nraphy can ensure the information origin authentication and\\nentity authentication between different robots in a swarm and\\nimprove the security during information exchanges.\\nan analysis of a decentralized intelligent transportation\\nsystem with distributed intelligence based on classi\\x1ccation\\ntechniques is discussed in [108]. researchers conducted an\\nexploratory study on a fully distributed architecture to enable\\ncooperative sensing and management in an intelligent trans-\\nportation system [108]. this proposed system envelops the\\nprocess of capturing and managing the road data, thereby\\nenabling services to improve the ef\\x1cciency of transportation\\nsystems. the main contribution of this work comprises of\\ntwo real-world scenarios related to the prediction of traf\\x1cc\\ndata. the \\x1crst one being able of detecting traf\\x1cc congestions\\nand the second one for predicting the pollution level using\\nc4.5 classi\\x1ccation technique.\\nthe ai techniques embedded within the decentralized sys-\\ntem help to predict and respond to critical incidents and events\\nthat may occur in a dynamic transportation environment and\\nprovide a be\\x1ctting solution in a timely manner [108]. the\\nreference architecture of the proposed system makes use\\nof a data distribution platform and collaborative learning\\nnodes connected through gateways to different subsystems\\nto analyze the best traf\\x1cc routes and to deal with congestion\\nproblems. in this work, the prediction of traf\\x1cc congestion\\nand other anomalies are performed using c4.5 classi\\x1ccation\\ntechnique which is used to generate decision trees from a set\\nof training data a framework named 'keel' has been used\\nfor providing basic parametrization which is well known to\\nhandle continuous attribute value ranges, to prune the result\\ndecision trees, and to predict traf\\x1cc congestion and pollution\\nin a city. osaba et al. [108] have performed the experiments\\nbased on real-world situations, with traf\\x1cc congestion pre-\\ndiction in lisbon, portugal and the prediction of pollution inpisa, italy. a complete operation of this collaborative learning\\nunit in a real scenario is showcased with a web application\\nwhich was simulated in a laboratory.\\nintelligent precision farming can utilize the emerging\\ntechnologies and decentralized business models to tackle\\nthe challenges faced by the agricultural sector. the lack of\\nfood security has affected 925 million people worldwide,\\nincluding 42.2 million in the united states alone [116]. with\\nthe advent of applied science, iot technology has gained\\nacceptance across various industries. but due to the their con-\\nstrained resources, underdeveloped standards, and absence\\nof security in design and development of their software\\ncomponents, iot devices remain insecure when connected\\nin a distributed environment and abstain to provide a robust\\nstructure [117]. from an agricultural production perspective,\\niot sensors, ai agents and blockchain technology can be\\nconjointly implemented for crop/variety selection, irrigation\\nmethod selection, reduce costs, predict yield, monitor crop\\nhealth, improve yield, improve crop quality, predict input\\nside demands and output aggregation needs leading to opti-\\nmization of the supply chain and to enhance pro\\x1cts of all\\nstakeholders involved in the agricultural production sector.\\niot sensors can be installed in farming \\x1celds to capture\\ndata and send information in order to optimize production.\\nthese iot sensors can monitor the nutrient levels in soil\\nand the images captured by sensors can help in monitoring\\nthe growth of crops periodically [116]. ai agents, on the\\nother hand, can augment iot devices to improve the agro-\\nsupply chain process via predictive analytics, which helps\\nfarmers to grow crops according to historical weather patterns\\nin any speci\\x1cc region and monitor the crop growth with\\nreal-time data. figure 5 shows the bene\\x1cts and features of\\ncombining ai, iot and blockchain technologies. blockchain\\nensures that everyone involved in the network has access to\\nall transactions; hence, reducing the time spent on logistics of\\nagricultural commodity trading and also reducing food safety\\ncontingency [116]. an intelligent data-driven decision can\\nassist farmers and stakeholders in making optimum decisions\\nfor farming plans to be customized for each farmer based on\\nweather, soil, pest, and crop data on a real-time basis.\\nanother prominent \\x1celd to bene\\x1ct from bringing together\\nblockchain technology and ai is the supply chain industry.\\nwhen incorporated together, both these technologies have the\\npotential to remodel the entire process into an 'autonomous'\\nsupply chain system [118]. blockchain based research for\\nsupply chain industry concentrated on proof of concept exper-\\nimental systems employing a decentralized application plat-\\nform [118]. most of the work in the literature was based on\\npost supply chain management for the detection of counter-\\nfeited products as well as for the proof of delivery of these\\nproducts that may involve multiple transporters. applying\\nai techniques to the blockchain-based business transaction\\n\\x1dows can assist to re\\x1cne the supply chain by automating\\nthe entire process [118]. ai platforms, when consolidated\\nwith blockchain, can capture data from point of sale systems,\\nhistory of purchase information, identify data patterns and\\nvolume 7, 2019 10141\",\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\nfigure 5. intelligent precision farming with blockchain.\\nperform a predictive analysis which includes predicting\\nfuture demand, predicting sales patterns, identifying potential\\nissues in advance, optimizing routes to reach the destination,\\nand handling network traf\\x1cc.\\nwhen uni\\x1ced with blockchain technology and modern\\ncryptography, federated learning can be used to improve the\\nprivacy of users' data by ensuring that data are never stored\\nin the cloud [119]. snips air is an ai-powered voice plat-\\nform that takes advantage of blockchain technology to ensure\\nthat users' data are safe. while existing ai-powered voice\\nassistants are pragmatic, there is a potential risk of placing\\nthe user's personal data at risk, as the conversations with\\nthe voice assistants are stored in the cloud. the technology\\nbehind amazon echo and google home is ai-powered and\\nit stores the history of users' commands and conversations to\\nrespond in a smarter way for future commands [119]. snips\\nair ensures that all the personal details of a user remain well\\nwithin the walls of connected homes instead of storing it on\\nthe cloud and that no one has the access to user's data. the\\nenvirons of snips incentivizes the users using tokens to store\\ntheir encrypted data to its blockchain based system [119].\\nfurther, the data are aggregated by application developers,\\nas the ai training is done on the blockchain network follow-\\ning the concept of decentralized learning. thereby, users need\\nnot have to reveal their personal data or trade-off their privacy.\\nsnips air is aimed to be delivered by 2019 for consumers\\nand it can be an alternative to siri, an intelligent assistant that\\noffers an easier way to get things done on ios applications\\nand stores the conversation data on the cloud [119] and\\nassures that users' data are never at risk.\\nrobotic agents triggered by ai algorithms have been\\nwidely used to explore the deep seabed to \\x1cnd mineral\\nresources, archeological \\x1cndings or to access the underwater\\ntreasures in order to claim ownership or discovery rights\\nby individuals or organizations. these algorithms and tech-\\nniques assist the swarm to identify obstacles, gather and\\nanalyze information on ocean currents, and traverse via the\\nmost ef\\x1ccient path to reach the goal thereby saving energy.\\nferrer [44] and brambilla et al. [45] outline the nature of\\nswarm robots to purview the objective and to record thekey information about the discovery such as the location of\\nthe discovered object, time, date, etc. however, the swarm\\nmay not always be monitored. any malicious attacker may\\ngain access to freely observe and tamper with the emergent\\nbehavior of the swarm, as the swarm ecosystem is designed to\\nexpedite autonomously [120]. however, when swarm agents\\nare powered with blockchain, it can record the discovery\\ndocuments mechanized with cryptographic techniques such\\nas hashing and time-stamping. the documents' hash can be\\nincluded on the blockchain based smart contracts and the dis-\\ncovery report itself can be securely stored in a decentralized\\n\\x1cle system, such as the ipfs. figure 6 shows how blockchain\\ntechnology helps to secure the discovery report generated by\\nocean exploration robots on the ipfs and records its hash\\non the immutable smart contract. this hash will represent\\nthe exact content of the document and can be encoded into\\nthe decentralized network without the document's content\\nbeing exposed [35], [44]. the hash of the document provides\\na secure, immutable and time stamped function about the\\nrecordings of various events during the discovery process and\\nwhen a speci\\x1cc attestation took place following the consensus\\nreceived from all active participants during a transaction in\\na particular time period. proof of existence and proof of\\ndiscovery can be forti\\x1ced by re-computing the hash and\\nby comparing it with the original document hash stored in\\nthe blockchain based smart contract. this technique can be\\nfurther explored to be implemented in various applications\\nsuch as landmine detection, disaster relief missions, and mil-\\nitary rescue operations which have precarious challenges for\\nhumans to work.\\nunsupervised machine learning algorithms and techniques\\nhave been extensively used for medical image analysis to\\nachieve a high level of accuracy [121]. this approach is\\nproved to improve detection of nodules, classi\\x1ccation, and\\nsizing, while also reducing false-positive rates in abnormality\\ndetection [122]. however, cross-institutional sharing of sen-\\nsitive medical data and records becomes a complex pursuit\\nwith the potential to improve the techniques for clinical effec-\\ntiveness and patient's privacy [43], [123]. in a patient-clinic\\necosystem, there is a primary need for developing a robust\\n10142 volume 7, 2019\",\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\nfigure 6. blockhain-based unmanned intelligent ocean bed exploration.\\nsystem where data owners share their information in a secure\\nenvironment and trust the decisions deduced by the ai agents.\\nwith the expeditious advancement in computational power\\nand machine learning algorithms, blockchain technology can\\nhelp facilitate a mechanism to compensate an ai service\\nprovider for the development and execution of novel machine\\nlearning algorithms [122].\\nmachine learning algorithms consume a considerable\\namount of time to diagnose a particular health condition by\\nspeculating on a radiology image or ct scan for instance.\\npeterson et al. [122] recommend that, by utilizing blockchain\\ntechnology, the ai service provider can publish the diag-\\nnostic report images containing information about a single\\ndiagnostic service performed for a patient on the blockchain.\\nfurther, the ai service provider who develops the machine\\nlearning algorithms can be allowed to execute their algo-\\nrithms over the images and publish the ai diagnosis output\\non the blockchain. by doing so, the radiologists at the clinic\\ncould compare his or her diagnoses with the result published\\non the blockchain [122]. the ai service providers can be\\nincentivized only when the diagnosis results match with that\\nof the diagnosis of the radiologists. as the service providers\\nare incentivized for every accurate diagnosis, they are bound\\nto improve the de\\x1cniteness of their machine learning algo-\\nrithms. thereby, blockchain implements an invincible record\\nof the complete diagnosis reports of both ai service providers\\nand hospitals. ai techniques and deep learning algorithms\\nextract high-level, complex abstractions as data representa-\\ntions through a hierarchical learning process [124], uses data\\nsciences and analytics which can be used to deduce the next\\ncourse of actions of the treatment by evaluating outcomes\\nand blockchain can hold the record to improve healthcare\\nservices.\\nrecently, the banking industry has started investing in a\\nwide range set of projects and start-ups providing blockchain\\nbased solutions as this technology provides a high level\\nof safety for storing and transmitting data, distributed andtransparent network infrastructure, decentralization and low\\ncost of operations [125]. banks have increased conducting\\ntests of decentralized asset technology and implementing\\nblockchain in the business process. as blockchain itself holds\\nan immutable ledger that records all transactions in the chain,\\nif a large number of transactions are being processed by\\nthe network, a huge volume of data gets collected and ai\\ntechniques can be used to process and classify the data.\\ntelcoin [125] is a new cryptocurrency based on the ethereum\\nblockchain which will be distributed and accepted by telecom\\noperators, enabling \\x1cnancial payments, remittances, credit,\\nand various \\x1cnancial services on the blockchain. telcoin sug-\\ngests that the combined features of blockchain and machine\\nlearning can contribute to various applications like anticipat-\\ning money laundering as ai is better in pattern classi\\x1ccation\\nand detection of irregularities in large amounts of data can\\nbe handled with blockchain technology. figure 7 presents\\na model of ai and blockchain technology that can be used\\nin the banking and \\x1cnance institutions. another remarkable\\noutcome of combining both technologies is the handling\\nof a \\x1ductuating range of cryptocurrencies where ai tech-\\nniques can help reduce the inherent volatility of cryptocur-\\nrencies [125]. xiong et al. [126] developed a neural network\\nmodel that harnesses the potential of deep learning \\x1cnancial\\ntime series in the presence of strong noise which proved that,\\nwith huge volumes of datasets, ai techniques perform better\\nthan other traditional models. machine learning techniques\\ncan analyze the price and details of various stock exchanges\\nand predict the future forecasts accurately and decentralized\\ncontracts can be used to freeze the price of currency for a\\n\\x1cxed amount of time [125].\\nthe property management sector has begun to explore and\\napprehend the collective potential of blockchain and ai [127].\\nthese technologies can create boundaries by breaking the\\nmonopolistic power of \\x1crms and hotels using blockchain.\\nproblems faced by the property management sector such\\nas inventory management can be managed by blockchain\\nvolume 7, 2019 10143',\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\nfigure 7. combining ai and blockchain for banking and finance.\\nand details on bed stock and hotel capacity can be man-\\naged by learning techniques of ai. the dutch land registry\\ndepartment is considering to consolidate ai and blockchain\\ntechnology into the real estate industry [128]. the land reg-\\nistry department envisions that these new technologies when\\nallied can improve the legal dependence and patronage of\\nbusiness to create a stable process. the dutch government\\nhas already been involved in utilizing the revolutionary ben-\\ne\\x1cts of blockchain in various \\x1celds such as \\x1cnancing, sup-\\nply chain, and logistics industry [129]. this organization\\nnow aims to implement the inherent bene\\x1cts of combining\\nboth technologies where implementation of ai is aimed to\\nconstitute self-learning systems which can predict the out-\\ncome whilst blockchain technology can be used for handling\\nand managing huge volumes of data resources saved and\\nproduced by the land registry department [128].\\nanother remarkable pursuit in the property sector is the\\nacceptance of these technologies by the government of\\nsingapore in a program called 'smart nation,' which attempts\\nto diminish the paramountcy of sellers over investors and buy-\\ners [129]. this is an $73 million worth project that endows the\\nprivate sectors to test all their new innovations and solutions\\nwhich includes technology and building management in the\\nreal estate sector. with big data, property investors and devel-\\nopers can predict the trends of real estate and merchandise\\nmovements. ai techniques can be used for comparative mar-\\nket analysis which helps users to get a thorough knowledge\\nof the investment and blockchain technology-based smart\\ncontracts can help in minimizing the transmission process\\nand improving the transparency of payments, thereby saving\\nmillions of dollars for investors [129].\\nto this point, we discussed early implementations of\\ndecentralized ai applications in various sectors. however,\\npersistent efforts are still needed in order to fully enable\\ndecentralized ai. considering the limitations in current\\nimplementations and our vision of enabling fully decentral-\\nized ai applications and systems, in the next section wediscuss the major open research challenges in this important\\nresearch area.\\nv. open research challenges\\nin this section, we discuss and highlight to-date challenges\\nfor combining ai and blockchain technologies. some of the\\nforeseeable challenges related to the uni\\x1ccation and integra-\\ntion of both technologies are listed below:\\n\\x0fprivacy. public blockchain ledgers enable secure and\\nauthentic data processing, however, collected data are\\npublically accessible and available for all readers. this\\ncan be a point of privacy evasion and concern. in addi-\\ntion, pervasive sensing systems in iot continuously\\ncollect consumers' personal and sensitive data and\\nputting this data on open ledgers could lead towards pri-\\nvacy issues. using private blockchain ledgers, the data\\nprivacy could be ensured by enabling encryption and\\nallowing controlled access of the ledgers. however,\\nsuch private blockchain platforms will limit the access\\nand exposure of the large amount of data that can be\\nnecessary for ai to process and preform accurate and\\ncorrect decision making and analytics.\\n\\x0fscalability and side chains. scalability is one\\nof the major concerns for today's blockchain plat-\\nform. for cryptocurrency blockchain platforms, bitcoin\\nblockchain can perform an average of 4 transactions\\nper seconds, while ethereum can perform an average of\\n12 transactions per second. such performance is really\\nunacceptable when compared with facebook which\\nhandles millions of transactions every second including\\nlikes, posts, and comments. side chains (known also as\\nside channels) are used to accelerate the performance of\\nblockchains, in which transactions are settled between\\nparties in a quick manner outside the main chain, and\\nsettled only once per day on the main chain [91].\\nmany new emerging types of blockchains improve sig-\\nni\\x1ccantly the consensus algorithms of mining nodes.\\n10144 volume 7, 2019\",\n",
       " 'k. salah et al. : blockchain for ai: review and open research challenges\\nfor example, platforms like algorand and iota can\\nprovide substantially better performance than that of\\nethereum and hyperledger blockchains [130], [131].\\nhowever, more work is still needed to improve the scala-\\nbility to be comparable to that of facebook and its likes.\\n\\x0fblockchain security. the decentralized power found in\\nblockchain can suffer from abuses and misuses. though\\nblockchain provides robust schemes for securing iot\\nand predictive analysis, the blockchain systems are\\nvulnerable to cyber-attacks as that of 51% attack [26].\\nthe consensus mechanism depending upon the hashing\\npower of the miner can be compromised, in which the\\ndecentralized platform becomes centralized around a\\nfew mining farms that control consensus and settlement\\n\\x1cnality. this security problem is more evident in pub-\\nlic blockchains such as ethereum and bitcoin. private\\nblockchain platforms suffer less from this problem,\\nas consensus protocols are prede\\x1cned among parties.\\nfurthermore, the execution environment of the mining\\nnodes is not protected, especially for private blockchain\\nplatforms with a few mining nodes as that of hyper-\\nledger, in which the execution outcomes can be tam-\\npered with. to remedy this problem, newly emerging\\nblockchain platforms are equipped with hardware to\\noffer execution in a trusted execution environments\\n(tees), such as intel sgx [132].\\n\\x0fsmart contracts vulnerabilities and deterministic\\nexecution. it is crucial to ensure that the implementa-\\ntion of a smart contract is free of bugs and vulnerabilities\\nand secure against attacks. it is important to safeguard\\nthe code and the information on the network, as they may\\nbe vulnerable to attacks. for example, the smart contract\\nfor the dao which was built on the ethereum platform\\nhad serious code vulnerability and was hacked in 2016.\\nthis resulted in a loss of 3.6 million ethers. there is\\na de\\x1cnite need for blockchain engineering, addressing\\nthis issue posed by smart contract programming and\\nother applications running on blockchain [133]. the\\nvulnerability issues are due to poor and negligent pro-\\ngramming practices in the languages used to write the\\nsmart contracts code (as that of solidity and chaincode).\\ntesting smart contracts for vulnerabilities has become of\\na critical importance, and some tools have been devel-\\noped to assess the security state of a smart contract code\\n[134]\\x15[136]. furthermore, as of today, the execution\\noutcomes of smart contracts are all deterministic and\\ncannot be probabilistic. this can pose a key challenge\\nfor decentralized ai in which ai and machine learning-\\nbased decision making algorithms get executed as smart\\ncontracts by the mining nodes, in which the execution\\noutcome are not usually deterministic, but rather ran-\\ndom, unpredictable and most often approximate. this\\nentails a novel solution to deal with approximate com-\\nputation and to devise consensus protocols for mining\\nnodes for agreeing on results with a particular degree of\\ncertainty, accuracy, or precision, and with data input thatmight be highly \\x1ductuating as that of iot and sensory\\nreadings.\\n\\x0ftrusted oracles smart contracts are designed to be\\ninvoked by external events or outside functions invoked\\nby blockchain participants. smart contracts are not\\ndesigned to automatically trigger events, or initiate\\nretrieval of data on their own. in other words, the con-\\ntracts cannot pull data from the outside world. data and\\nevents have to be pushed to the contracts. to remedy\\nsuch shortcomings, trusted oracles (which are basically\\ntrusted external parties or nodes) are being proposed\\nas alternatives, and used to push events and data to the\\nsmart contracts. oracles add a level of complexity and\\ninsecurity for ensuring and managing trust, in which a\\ncompletely decentralized system becomes centralized\\naround a group of oracles that must be trusted. voting\\namong trusted oracles is typically employed to reach\\nconsensus [137].\\n\\x0fai-speci\\x1cc emerging consensus protocols. existing\\nconsensus protocols considers network and middleware\\nlayers of blockchain systems by enabling different proof\\nof x protocols (as discussed in section iii-e). a large\\nplethora of research opportunities are available for\\nfuture researchers to explore if the application level con-\\nsensus protocols could be designed considering proofs\\nbased on quality of learning models, ef\\x1ccient search\\nstrategies, quality and provenance of data, and quality\\nof optimization.\\n\\x0ffog computing paradigm. fog computing is a newly\\nemerging computing paradigm that allows for localized\\ncomputing and storage close to the source of data being\\ngenerated by customers or iot devices. fog nodes are\\ntypically used to augment the long delay incurred by\\ncomputing and storage at the cloud environment. fog\\nnodes can be thought of as a local small-scale cloud. in\\nthe context of ai and blockchain, future fog nodes have\\nto be equipped with ai and machine learning capabilities\\nas well as enabled with blockchain interface, whereby\\nlocalized management, access, and control of data are\\nperformed by the fog nodes.\\n\\x0flack of standards, interoperability, and regula-\\ntions. to date, blockchain technology standards are yet\\nto be devised. work is in progress by ieee, nist, itu,\\nand many standards bodies to put forward standards\\nfor blockchain interoperability, governance, integration,\\nand architecture [138], [139]. moreover, at local and\\nglobal level, governmental and institutional guidelines,\\nrules, laws, regulations, and policies need to put in place\\nfor blockchain deployment, arbitration, and dispute han-\\ndling, in the context of ai applications and especially\\nfor public blockchain transactions involving \\x1cnancing\\nand automated payments using cryptocurrencies. this\\nentails research directed at devising models and proof\\nof concepts that can play a key role in de\\x1cning the right\\nset of technical standards for blockchain architectural\\nmodels, services, deployment and interoperability.\\nvolume 7, 2019 10145',\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\n\\x0fquantum computing. it is envisaged that future quan-\\ntum computing will have the ability to break public key\\nencryption in which private keys can be determined.\\ncurrent blockchain relies on digital signatures which\\nuse public key encryption. many experts believe that\\nquantum computing may render the underlying security\\nof blockchain breakable by the year 2027 [140], [141].\\nthis entails serious research on quantum-safe and secure\\nblockchain that withstand such breakability, and still\\nguarantees high performance and scalability. also this\\nentails sound migration plans and interoperability with\\nquantum-resilient blockchain platforms.\\n\\x0fgovernance. deploying, constructing, and managing\\na blockchain platform among different participants\\nand stakeholders is a tedious task. even with a pri-\\nvate of consortium blockchain, serious issues arise\\nrelated to the type of blockchain to deploy ( e.g.,\\nhyperledger or ethereum), who administers and trou-\\nbleshoots the blockchain, the deployment location of\\nthe blockchain nodes, who writes the smart contracts,\\nsettlement of disputes, selection of trusted oracles,\\nmechanisms for off-chain activities, deployment of side\\nchannels, regulations and standards to comply with, and\\nmany others. this entails research targeted at devising\\nsound governance models.\\nvi. conclusion\\nin this paper, we surveyed and reviewed the current\\nstate-of-the-art related to the use and applicability of\\nblockchain features for ai. we gave an overview of\\nblockchain and decentralized storage on how blockchain\\ntechnology can enhance and solve key issues related to ai.\\nmoreover, we presented a detailed taxonomic discussion\\nand comparisons of common blockchain implementations\\nin terms of decentralized ai operations, blockchain types\\nand infrastructure, and consensus protocols. an extensive\\nanalysis of blockchain applications for intelligent multi-agent\\nsystems is reviewed with respect to decentralized data man-\\nagement and infrastructure for ai. various features of ai for\\nblockchain applications are also summarized. our literature\\nreview shows that adopting blockchain for ai applications is\\nstill in its infancy, and there exists many research challenges\\nto be addressed and tackled in areas related to privacy, smart\\ncontract security, trusted oracles, scalability, consensus pro-\\ntocols, standardization, interoperability, quantum computing\\nresiliency, and governance.\\nreferences\\n[1] a. maxmen, ``ai researchers embrace bitcoin technology to share medical\\ndata,'' nature , vol. 555, pp. 293\\x15294, mar. 2018.\\n[2] z. baynham-herd, ``enlist blockchain to boost conservation,'' nature ,\\nvol. 548, no. 7669, p. 523, 2017.\\n[3] s. ahmed and n. t. broek, ``blockchain could boost food security,''\\nnature , vol. 550, no. 7674, p. 43, 2017.\\n[4] s. nakamoto, ``bitcoin: a peer-to-peer electronic cash system,''\\ntech. rep., 2008. accessed: jan. 10, 2019. [online]. available:\\nhttps://archive.is/rmbtv\\n[5] m. swan, blockchain: blueprint for a new economy . newton, ma, usa:\\no'reilly media, 2015.[6] m. koch, ``arti\\x1ccial intelligence is becoming natural,'' cell, vol. 173,\\nno. 3, pp. 531\\x15533, 2018.\\n[7] j. schmidhuber, ``deep learning in neural networks: an overview,'' neu-\\nral netw. , vol. 61, pp. 85\\x15117, jan. 2015.\\n[8]nebula ai (nbai)\\x16decentralized ai blockchain whitepaper , nebula ai\\nteam, montreal, qc, canada, 2018.\\n[9] t. n. dinh and m. t. thai, ``ai and blockchain: a disruptive integration,''\\ncomputer , vol. 51, no. 9, pp. 48\\x1553, sep. 2018.\\n[10] y. qi and j. xiao, ``fintech: ai powers \\x1cnancial services to improve\\npeople's lives,'' commun. acm , vol. 61, no. 11, pp. 65\\x1569, 2018.\\n[11] g. wood, ``ethereum: a secure decentralised generalised transaction\\nledger,'' ethereum project yellow paper , vol. 151, pp. 1\\x1532, apr. 2014.\\n[12] h. b. mcmahan, e. moore, d. ramage, s. hampson, and\\nb. a. y. arcas. (2016). ``communication-ef\\x1ccient learning of\\ndeep networks from decentralized data.'' [online]. available:\\nhttps://arxiv.org/abs/1602.05629\\n[13] s. wang, y. yuan, x. wang, j. li, r. qin, and f.-y. wang, ``an overview\\nof smart contract: architecture, applications, and future trends,'' in proc.\\nieee intell. vehicles symp. (iv) , jun. 2018, pp. 108\\x15113.\\n[14] x. zheng, m. zhu, q. li, c. chen, and y. tan. (2018).\\n``finbrain: when \\x1cnance meets ai 2.0.'' [online]. available:\\nhttps://arxiv.org/abs/1808.08497\\n[15] t. baltru²aitis, c. ahuja, and l.-p. morency, ``multimodal\\nmachine learning: a survey and taxonomy,'' ieee trans. pattern\\nanal. mach. intell. , vol. 41, no. 2, pp. 423\\x15443, feb. 2019, doi:\\n10.1109/tpami.2018.2798607.\\n[16] f. fioretto, e. pontelli, and w. yeoh. (2016). ``distributed constraint\\noptimization problems and applications: a survey.'' [online]. available:\\nhttps://arxiv.org/abs/1602.06347\\n[17] k. yeow, a. gani, r. w. ahmad, j. j. p. c. rodrigues, and k. ko,\\n``decentralized consensus for edge-centric internet of things: a review,\\ntaxonomy, and research issues,'' ieee access , vol. 6, pp. 1513\\x151524,\\n2018.\\n[18] t. m. fernández-caramés and p. fraga-lamas, ``a review on the\\nuse of blockchain for the internet of things,'' ieee access , vol. 6,\\npp. 32979\\x1533001, 2018.\\n[19] a. panarello, n. tapas, g. merlino, f. longo, and a. pulia\\x1cto,\\n``blockchain and iot integration: a systematic survey,'' sensors , vol. 18,\\nno. 8, p. e2575, 2018.\\n[20] k. christidis and m. devetsikiotis, ``blockchains and smart contracts for\\nthe internet of things,'' ieee access , vol. 4, pp. 2292\\x152303, 2016.\\n[21] t. neudecker and h. hartenstein, ``network layer aspects of permission-\\nless blockchains,'' ieee commun. surveys tuts. , to be published, doi:\\n10.1109/comst.2018.2852480.\\n[22] w. cai, z. wang, j. b. ernst, z. hong, c. feng, and v. c. m. leung,\\n``decentralized applications: the blockchain-empowered software sys-\\ntem,'' ieee access , vol. 6, pp. 53019\\x1553033, 2018.\\n[23] t. salman, m. zolanvari, a. erbad, r. jain, and m. samaka, ``security\\nservices using blockchains: a state of the art survey,'' ieee commun.\\nsurveys tuts. , to be published, doi: 10.1109/comst.2018.2863956.\\n[24] r. b. uriarte and r. de nicola, ``blockchain-based decentralized\\ncloud/fog solutions: challenges, opportunities, and standards,'' ieee\\ncommun. standards mag. , vol. 2, no. 3, pp. 22\\x1528, sep. 2018.\\n[25] t. t. a. dinh, r. liu, m. zhang, g. chen, b. c. ooi, and j. wang,\\n``untangling blockchain: a data processing view of blockchain systems,''\\nieee trans. knowl. data eng. , vol. 30, no. 7, pp. 1366\\x151385, jul. 2018.\\n[26] x. li, p. jiang, t. chen, x. luo, and q. wen, ``a survey on the security\\nof blockchain systems,'' future gener. comput. syst. , aug. 2017, doi:\\n10.1016/j.future.2017.08.020.\\n[27] z. zheng, s. xie, h.-n. dai, x. chen, and h. wang, ``blockchain\\nchallenges and opportunities: a survey,'' int. j. web grid services , vol.\\n14, no. 4, pp. 352\\x15375, 2018.\\n[28] v. lopes and l. a. alexandre. (2018). ``an overview of blockchain\\nintegration with robotics and arti\\x1ccial intelligence.'' [online]. available:\\nhttps://arxiv.org/abs/1810.00329\\n[29] t. bocek, b. b. rodrigues, t. strasser, and b. stiller, ``blockchains\\neverywhere\\x16a use-case of blockchains in the pharma supply-chain,'' in\\nproc. ifip/ieee symp. integr. netw. service manage. (im) , may 2017,\\npp. 772\\x15777.\\n[30] w. samek, t. wiegand, and k.-r. müller. (2017). ``explainable arti\\x1ccial\\nintelligence: understanding, visualizing and interpreting deep learning\\nmodels.'' [online]. available: https://arxiv.org/abs/1708.08296\\n[31] m. schluse, m. priggemeyer, l. atorf, and j. rossmann, ``experi-\\nmentable digital twins\\x16streamlining simulation-based systems engi-\\nneering for industry 4.0,'' ieee trans. ind. informat. , vol. 14, no. 4,\\npp. 1722\\x151731, apr. 2018.\\n10146 volume 7, 2019\",\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\n[32] m. feurer, k. eggensperger, s. falkner, m. lindauer, and f. hutter,\\n``practical automated machine learning for the automl challenge 2018,''\\ninproc. int. workshop autom. mach. learn. (icml) , 2018, pp. 1\\x1512.\\n[33] c. lv et al., ``hybrid-learning-based classi\\x1ccation and quantitative infer-\\nence of driver braking intensity of an electri\\x1ced vehicle,'' ieee trans.\\nveh. technol. , vol. 67, no. 7, pp. 5718\\x155729, jul. 2018.\\n[34] p. peng, y. tian, t. xiang, y. wang, m. pontil, and t. huang, ``joint\\nsemantic and latent attribute modelling for cross-class transfer learning,''\\nieee trans. pattern anal. mach. intell. , vol. 40, no. 7, pp. 1625\\x151638,\\njul. 2018.\\n[35] j. benet. (2014). ``ipfs-content addressed, versioned, p2p \\x1cle system.''\\n[online]. available: https://arxiv.org/abs/1407.3561\\n[36] j. h. hartman, i. murdock, and t. spalink, ``the swarm scalable storage\\nsystem,'' in proc. 19th ieee int. conf. distrib. comput. syst. , jun. 1999,\\npp. 74\\x1581.\\n[37] protocol labs. (2017). filecoin: a decentralized storage network .\\n[online]. available: https://\\x1clecoin.io/\\x1clecoin.pdf\\n[38] t. mcconaghy et al. , ``bigchaindb: a scalable blockchain\\ndatabase,'' bigchaindb gmbh, berlin, germany, white paper,\\n2016. accessed: jan. 10, 2019. [online]. available: https://www.\\nbigchaindb.com/whitepaper/bigchaindb-whitepaper.pdf\\n[39] s. wilkinson, t. boshevski, j. brandoff, and v. buterin, ``storj a peer-to-\\npeer cloud storage network,'' the whitepaper is storj labs, atlanta, ga,\\nusa, tech. rep., 2014. accessed: jan. 10, 2019. [online]. available:\\nhttps://storj.io/storj.pdf\\n[40] d. marr, ``arti\\x1ccial intelligence\\x16a personal view,'' artif. intell. , vol. 9,\\nno. 1, pp. 37\\x1548, 1977.\\n[41] t. marwala and b. xing. (2018). ``blockchain and arti\\x1ccial intelligence.''\\n[online]. available: https://arxiv.org/abs/1802.04451\\n[42] b. marr. (2018). arti\\x1ccial intelligence and blockchain: 3 major bene\\x1cts\\nof combining these two mega-trends . [online]. available: https://\\nwww.forbes.com/sites/bernardmarr/2018/03/02/arti\\x1ccial-intelligence-\\nand-blockchain-3-major-bene\\x1cts-of-combining-these-two-mega-trends/\\n[43] d. campbell. (2018). combining ai and blockchain to push frontiers\\nin healthcare . [online]. available: http://www.macadamian.com/2018/\\n03/16/combining-ai-and-blockchain-in-healthcare\\n[44] e. c. ferrer. (2016). ``the blockchain: a new framework for robotic\\nswarm systems.'' [online]. available: https://arxiv.org/abs/1608.00695\\n[45] m. brambilla, e. ferrante, m. birattari, and m. dorigo, ``swarm robotics:\\na review from the swarm engineering perspective,'' swarm intell. , vol. 7,\\nno. 1, pp. 1\\x1541, 2013.\\n[46] v. strobel, e. c. ferrer, and m. dorigo, ``managing byzantine robots via\\nblockchain technology in a swarm robotics collective decision making\\nscenario,'' in proc. 17th int. conf. auto. agents multiagent syst. inter-\\nnational foundation for autonomous agents and multiagent systems:\\nstockholm, sweden, jul. 2018, pp. 541\\x15549.\\n[47] s. janson, d. merkle, and m. middendorf, ``a decentralization approach\\nfor swarm intelligence algorithms in networks applied to multi swarm\\npso,'' int. j. intell. comput. cybern. , vol. 1, no. 1, pp. 25\\x1545, 2008.\\n[48] d. magazzeni, p. mcburney, and w. nash, ``validation and veri\\x1ccation of\\nsmart contracts: a research agenda,'' computer , vol. 50, no. 9, pp. 50\\x1557,\\n2017.\\n[49] d. ye, m. zhang, and a. v. vasilakos, ``a survey of self-organization\\nmechanisms in multiagent systems,'' ieee trans. syst., man, cybern.,\\nsyst., vol. 47, no. 3, pp. 441\\x15461, mar. 2017.\\n[50] y. rizk, m. awad, and e. w. tunstel, ``decision making in multiagent\\nsystems: a survey,'' ieee trans. cogn. develop. syst. , vol. 10, no. 3,\\npp. 514\\x15529, sep. 2018.\\n[51] f. fioretto, e. pontelli, and w. yeoh, ``distributed constraint optimization\\nproblems and applications: a survey,'' j. artif. intell. res. , vol. 61,\\npp. 623\\x15698, mar. 2018.\\n[52] m. h. u. rehman, c. s. liew, t. y. wah, and m. k. khan, ``towards\\nnext-generation heterogeneous mobile data stream mining applications:\\nopportunities, challenges, and future research directions,'' j. netw. com-\\nput. appl. , vol. 79, pp. 1\\x1524, feb. 2017.\\n[53] m. h. u. rehman, a. batool, c. s. liew, y.-w. teh, and a. u. r. khan,\\n``execution models for mobile data analytics,'' it prof. , vol. 19, no. 3,\\npp. 24\\x1530, 2017.\\n[54] l. bottou, f. e. curtis, and j. nocedal, ``optimization methods for large-\\nscale machine learning,'' siam rev. , vol. 60, no. 2, pp. 223\\x15311, 2018.\\n[55] m. a. contreras-cruz, j. j. lopez-perez, and v. ayala-ramirez,\\n``distributed path planning for multi-robot teams based on arti\\x1ccial\\nbee colony,'' in proc. ieee congr. evol. comput. (cec) , jun. 2017,\\npp. 541\\x15548.[56] s. j. van zelst, b. f. van dongen, and w. m. p. van der aalst, ``event\\nstream-based process discovery using abstract representations,'' knowl.\\ninf. syst. , vol. 54, no. 2, pp. 407\\x15435, 2018.\\n[57] h. lu, y. li, m. chen, h. kim, and s. serikawa, ``brain intelligence:\\ngo beyond arti\\x1ccial intelligence,'' mobile netw. appl. , vol. 23, no. 2,\\npp. 368\\x15375, 2018.\\n[58] a. b. kurtulmus and k. daniel. (2018). ``trustless machine\\nlearning contracts; evaluating and exchanging machine learning\\nmodels on the ethereum blockchain.'' [online]. available:\\nhttps://arxiv.org/abs/1802.10185\\n[59] h. kim, j. park, m. bennis, and s.-l. kim. (2018). ``on-device federated\\nlearning via blockchain and its latency analysis.'' [online]. available:\\nhttps://arxiv.org/abs/1808.03949\\n[60] m. hatem, e. burns, and w. ruml, ``solving large problems with heuris-\\ntic search: general-purpose parallel external-memory search,'' j. artif.\\nintell. res. , vol. 62, pp. 233\\x15268, jun. 2018.\\n[61] s. banerjee, p. k. singh, and j. bajpai, ``a comparative study on decision-\\nmaking capability between human and arti\\x1ccial intelligence,'' in nature\\ninspired computing . cham, switzerland: springer, 2018, pp. 203\\x15210.\\n[62] h. shafagh, l. burkhalter, a. hithnawi, and s. duquennoy, ``towards\\nblockchain-based auditable storage and sharing of iot data,'' in proc.\\ncloud comput. secur. workshop , 2017, pp. 45\\x1550.\\n[63] s. ali, g. wang, b. white, and r. l. cottrell, ``a blockchain-based\\ndecentralized data storage and access framework for pinger,'' in proc.\\n17th ieee int. conf. on trust, secur. privacy comput. commun./12th\\nieee int. conf. big data sci. eng. (trustcom/bigdatase) , aug. 2018,\\npp. 1303\\x151308.\\n[64] s. cui, m. r. asghar, and g. russello, ``towards blockchain-based\\nscalable and trustworthy \\x1cle sharing,'' in proc. 27th int. conf. comput.\\ncommun. netw. (icccn) , jul./aug. 2018, pp. 1\\x152.\\n[65] l. luu, v. narayanan, c. zheng, k. baweja, s. gilbert, and p. saxena,\\n``a secure sharding protocol for open blockchains,'' in proc. acm\\nsigsac conf. comput. commun. secur. , 2016, pp. 17\\x1530.\\n[66] m. zamani, m. movahedi, and m. raykova, ``rapidchain: scaling\\nblockchain via full sharding,'' in proc. acm sigsac conf. comput.\\ncommun. secur. , 2018, pp. 931\\x15948.\\n[67] k. r. özy\\x19lmaz and a. yurdakul. (2018). ``designing a blockchain-based\\niot infrastructure with ethereum, swarm and lora.'' [online]. available:\\nhttps://arxiv.org/abs/1809.07655\\n[68] h. t. vo, a. kundu, and m. k. mohania, ``research directions in\\nblockchain data management and analytics,'' in proc. edbt , 2018,\\npp. 445\\x15448.\\n[69] l. lai and n. suda. (2018). ``rethinking machine learning devel-\\nopment and deployment for edge devices.'' [online]. available:\\nhttps://arxiv.org/abs/1806.07846\\n[70] t. cui. (2018). achain blockchain whitepaper . [online]. available:\\nhttps://www.achain.com/documents/whitepaper.pdf\\n[71] t. jelurida. (2018). ardor, scalable blokchain, proof of stake\\nconsensus . [online]. available: https://www.jelurida.com/sites/default/\\n\\x1cles/jeluridawhitepaper.pdf\\n[72] microsoft. (2018). azure blockchain workbench documentation .\\n[online]. available: https://docs.microsoft.com/en-us/azure/blockchain/\\nworkbench/\\n[73] blocko . (2018). [online]. available: https://www.blocko.io/\\nplatform.html\\n[74] (2018). chain core white paper . [online]. available: https://chain.com/\\ndocs/1.2/protocol/papers/whitepaper\\n[75] (2018). pencildata . [online]. available: https://pencildata.com/\\n[76] m. hearn, ``corda: a distributed ledger,'' r3, new york, ny, usa, tech.\\nrep. r3cev, 2016.\\n[77] whitepaper, decentralized financial system credits , t. credits, london,\\nu.k., 2018.\\n[78] (2018). elements by blockstream . [online]. available: https://\\nelementsproject.org/elements-code-tutorial/overview\\n[79] (2018). eosio technical white paper . [online]. available: https://\\ngithub.com/eosio/documentation/blob/master/technicalwhitepaper.\\nmd\\n[80] (2018). hydrachain a permissioned distributed ledger based on\\nethereum . [online]. available: https://github.com/hydrachain/\\nhydrachain\\n[81] e. androulaki et al., ``hyperledger fabric: a distributed operating system\\nfor permissioned blockchains,'' in proc. 13th eurosyst. conf. , 2018, p. 30.\\n[82] r. alexander, iota\\x16introduction to the tangle technology: everything\\nyou need to know about the revolutionary blockchain alternative .\\nfeb. 2018.\\nvolume 7, 2019 10147\",\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\n[83] g. greenspan. (2018). multichain private blockchain\\x16white paper .\\n[online]. available: https://www.multichain.com/download/multichain-\\nwhite-paper.pdf\\n[84] t. quorum. (2018). quorum architecture . [online]. available:\\nhttps://github.com/jpmorganchase/quorum-docs/blob/master/quorum\\n_architecture_20171016.pdf\\n[85] (2018). sap leonardo . [online]. available: https://cloudplatform.\\nsap.com/capabilities.html\\n[86] tag: stratis. (2018). stratis blockchain white paper . [online]. available:\\nhttps://stratisplatform.com/\\x1cles/stratis_whitepaper.pdf\\n[87] t. t. a. dinh, j. wang, g. chen, r. liu, b. c. ooi, and k.-l. tan,\\n``blockbench: a framework for analyzing private blockchains,'' in proc.\\nacm int. conf. manage. data , 2017, pp. 1085\\x151100.\\n[88] z. li, j. kang, r. yu, d. ye, q. deng, and y. zhang, ``consortium\\nblockchain for secure energy trading in industrial internet of things,''\\nieee trans. ind. informat. , vol. 14, no. 8, pp. 3690\\x153700, aug. 2018.\\n[89] d. joshi, ``ibm, amazon & microsoft are offering their blockchain\\ntechnology as a service,'' bus. insider , vol. 24, oct. 2017.\\naccessed: jan. 10, 2019. [online]. available: https://www.\\nthewealthadvisor.com/article/ibm-amazon-microsoft-are-offering-their-\\nblockchain-technology-service\\n[90] c. xu, k. wang, and m. guo, ``intelligent resource management in\\nblockchain-based cloud datacenters,'' ieee cloud comput. , vol. 4, no. 6,\\npp. 50\\x1559, nov./dec. 2017.\\n[91] g.-h. hwang, p.-h. chen, c.-h. lu, c. chiu, h.-c. lin, and\\na.-j. jheng, ``in\\x1cnitechain: a multi-chain architecture with distributed\\nauditing of sidechains for public blockchains,'' in proc. int. conf.\\nblockchain . cham, switzerland: springer, 2018, pp. 47\\x1560.\\n[92] s. king and s. nadal, ``ppcoin: peer-to-peer crypto-currency with proof-\\nof-stake,'' tech. rep., aug. 2012. accessed: jan. 10, 2019. [online].\\navailable: https://peercoin.net/assets/paper/peercoin-paper.pdf\\n[93] i. bentov, c. lee, a. mizrahi, and m. rosenfeld, ``proof of activity:\\nextending bitcoin's proof of work via proof of stake [extended abstract]\\ny,''acm sigmetrics perform. eval. rev. , vol. 42, no. 3, pp. 34\\x1537,\\n2014.\\n[94] (2018). slimcoin|a cryprocurrency for long time . [online]. avail-\\nable: https://github.com/slimcoin-project/slimcoin-project.github.io/raw/\\nmaster/whitepaperslm.pdf\\n[95] l. chen, l. xu, n. shah, z. gao, y. lu, and w. shi, ``on security analysis\\nof proof-of-elapsed-time (poet),'' in proc. sss , 2017, pp. 282\\x15297.\\n[96] f. tschorsch and b. scheuermann, ``bitcoin and beyond: a technical sur-\\nvey on decentralized digital currencies,'' ieee commun. surveys tuts. ,\\nvol. 18, no. 3, pp. 2084\\x152123, 3rd quart., 2016.\\n[97] (2018). alfa-enzo white paper . [online]. available: https://www.\\nalfaenzo.io/libs/pdf/whitepaper.pdf\\n[98] (2018). burstcoin wiki white paper . [online]. available: https://\\nburstwiki.org/wiki/main_page\\n[99] nem. (2018). nem technical reference . [online]. available:\\nhttps://nem.io/wp-content/themes/nem/\\x1cles/nem_techref.pdf\\n[100] s. de angelis, l. aniello, r. baldoni, f. lombardi, a. margheri, and\\nv. sassone, ``pbft vs proof-of-authority: applying the cap theo-\\nrem to permissioned blockchain,'' in proc. itasec , 2018, pp. 1\\x1511.\\naccessed: jan. 10, 2019. [online]. available: https://eprints.soton.ac.\\nuk/id/eprint/415083\\n[101] (2018). nem\\x16distributed ledger technology (blockchain) . [online].\\navailable: https://nem.io/\\n[102] m. milutinovic, w. he, h. wu, and m. kanwal, ``proof of luck:\\nan ef\\x1ccient blockchain consensus protocol,'' in proc. 1st workshop syst.\\nsoftw. trusted execution , 2016, p. 2.\\n[103] a. shoker, ``sustainable blockchain through proof of exercise,'' in proc.\\nieee 16th int. symp. netw. comput. appl. (nca) , oct./nov. 2017,\\npp. 1\\x159.\\n[104] s. dramé-maigné, m. laurent, l. castillo, and h. ganem, ``aug-\\nmented chain of ownership: con\\x1cguring iot devices with the help of\\nthe blockchain,'' in proc. 14th eai int. conf. secur. privacy com-\\nmun. netw. (securecomm) . seattle, wa, usa: springer, jun. 2018,\\npp. 1\\x1516.\\n[105] k. li, h. li, h. hou, k. li, and y. chen, ``proof of vote: a high-\\nperformance consensus protocol based on vote mechanism & consortium\\nblockchain,'' in proc. ieee 19th int. conf. high perform. comput. com-\\nmun., ieee 15th int. conf. smart city, ieee 3rd int. conf. data sci. syst.\\n(hpcc/smartcity/dss) , dec. 2017, pp. 466\\x15473.\\n[106] k. d. bowers, a. juels, and a. oprea, ``proofs of retrievability: theory\\nand implementation,'' in proc. acm workshop cloud comput. secur. ,\\n2009, pp. 43\\x1554.[107] r. claes, t. holvoet, and d. weyns, ``a decentralized approach\\nfor anticipatory vehicle routing using delegate multiagent systems,''\\nieee trans. intell. transp. syst. , vol. 12, no. 2, pp. 364\\x15373,\\nfeb. 2011.\\n[108] e. osaba, e. onieva, a. moreno, p. lopez-garcia, a. perallos, and\\np. g. bringas, ``decentralised intelligent transport system with distributed\\nintelligence based on classi\\x1ccation techniques,'' iet intell. transp. syst. ,\\nvol. 10, no. 10, pp. 674\\x15682, dec. 2016.\\n[109] p. mamoshina et al. , ``converging blockchain and next-generation arti-\\n\\x1ccial intelligence technologies to decentralize and accelerate biomedical\\nresearch and healthcare,'' oncotarget , vol. 9, no. 5, pp. 5665\\x155690, 2018.\\n[110] a. lot\\x1c, c. langensiepen, and s. w. yahaya, ``socially assistive robotics:\\nrobot exercise trainer for older adults,'' technologies , vol. 6, no. 1, p. 32,\\n2018.\\n[111] j. woods. (2018). blockchain: rebalancing & amplifying the\\npower of ai and machine learning (ml) . [online]. available:\\nhttps://medium.com/crypto-oracle/blockchain-rebalancing-amplifying-\\nthe-power-of-ai-and-machine-learning-ml-af95616e9ad9\\n[112] s. russell and p. norvig, arti\\x1ccial intelligence: a modern approach .\\nkuala lumpur, malaysia; pearson education, 2016.\\n[113] team chainintel. (2018). distributed decentralized arti\\x1ccial\\nintelligence framework for dapps . [online]. available: https://\\nblog.chainintel.com/distributed-decentralized-arti\\x1ccial-intelligence-\\nframework-for-dapps-75fefdc554c5\\n[114] m. mylrea and s. n. g. gourisetti, ``blockchain for smart grid resilience:\\nexchanging distributed energy at speed, scale and security,'' in proc.\\nresilience week (rws) , sep. 2017, pp. 18\\x1523.\\n[115] s. yu, k. lv, z. shao, y. guo, j. zou, and b. zhang, ``a high performance\\nblockchain platform for intelligent devices,'' in proc. 1st ieee int. conf.\\nhot inf.-centric netw. , shenzhen, china, aug. 2018, pp. 260\\x15261.\\n[116] entefy. (2018). ai and blockchain are taking root in the global\\nagriculture industry . [online]. available: https://www.entefy.com/blog/\\npost/570/ai-and-blockchain-are-taking-root-in-the-global-agriculture-\\nindustry/\\n[117] m. a. khan and k. salah, ``iot security: review, blockchain solutions,\\nand open challenges,'' future gener. comput. syst. , vol. 82, pp. 395\\x15411,\\nmay 2018.\\n[118] aspencore network. (2018). autonomous supply chain will soon\\nbe empowered by iot, ai, and blockchain-here's how . [online].\\navailable: https://iot.eetimes.com/autonomous-supply-chain-will-soon-\\nbe-empowered-by-iot-ai-and-blockchain-heres-how\\n[119] r. wolfson. (2018). blockchain-based ai voice assistant brings\\ndata privacy to smart homes . [online]. available: https://\\nwww.forbes.com/sites/rachelwolfson/2018/09/14/blockchain-based-\\nai-voice-assistant-brings-data-privacy-to-smart-homes/#1f965b3b6b50\\n[120] i. sargeant and a. tomlinson, ``maliciously manipulating a robotic\\nswarm,'' in proc. escs 14th int. conf. embedded syst., cyber-phys.\\nsyst., appl. , 2016, pp. 122\\x15128.\\n[121] y. xu, t. mo, q. feng, p. zhong, m. lai, and e. i.-c. chang, ``deep\\nlearning of feature representation with multiple instance learning for\\nmedical image analysis,'' in proc. ieee int. conf. acoust., speech signal\\nprocess. (icassp) , may 2014, pp. 1626\\x151630.\\n[122] k. peterson, r. deeduvanu, p. kanjamala, and k. boles, ``a blockchain-\\nbased approach to health information exchange networks,'' in proc. nist\\nworkshop blockchain healthcare , vol. 1, 2016, pp. 1\\x1510.\\n[123] y. ge, d. k. ahn, b. unde, h. d. gage, and j. j. carr, ``patient-\\ncontrolled sharing of medical imaging data across unaf\\x1cliated healthcare\\norganizations,'' j. amer. med. inform. assoc. , vol. 20, no. 1, pp. 157\\x15163,\\n2013.\\n[124] m. m. najafabadi, f. villanustre, t. m. khoshgoftaar, n. seliya,\\nr. wald, and e. muharemagic, ``deep learning applications and chal-\\nlenges in big data analytics,'' j. big data , vol. 2, no. 1, p. 1, feb. 2015.\\n[125] telcoin. (2018). how arti\\x1ccial intelligence can support\\nblockchain applications like telcoin . [online]. available:\\nhttps://medium.com/@telcoin/how-arti\\x1ccial-intelligence-can-support-\\nblockchain-applications-like-telcoin-1c5bab8a1a68\\n[126] r. xiong, e. p. nichols, and y. shen. (2015). ``deep learning\\nstock volatility with google domestic trends.'' [online]. available:\\nhttps://arxiv.org/abs/1512.04916\\n[127] memoori. (2018). the innovative startups that could bring ai &\\nblockchain to smart buildings . [online]. available: https://www.\\nmemoori.com/innovative-startups-bring-ai-blockchain-smart-buildings/\\n[128] n. graham. (2018). dutch land registry: how blockchain and\\nai could bene\\x1ct the real estate industry . [online]. available:\\nhttps://www.ethnews.com/author/nathan-graham\\n10148 volume 7, 2019\",\n",
       " \"k. salah et al. : blockchain for ai: review and open research challenges\\n[129] a. couse. (2018). how drones, data and ai are changing the\\nproperty sector . [online]. available: https://www.weforum.org/\\nagenda/2018/01/proptech-drones-data-ai-property-sector/\\n[130] x. boyen, c. carr, and t. haines, ``graphchain: a blockchain-free scal-\\nable decentralised ledger,'' in proc. 2nd acm workshop blockchains,\\ncryptocurrencies, contracts , 2018, pp. 21\\x1533.\\n[131] y. gilad, r. hemo, s. micali, g. vlachos, and n. zeldovich, ``algorand:\\nscaling byzantine agreements for cryptocurrencies,'' in proc. 26th symp.\\noper. syst. princ. , 2017, pp. 51\\x1568.\\n[132] m. brandenburger, c. cachin, r. kapitza, and a. sorniotti.\\n(2018). ``blockchain and trusted computing: problems, pitfalls,\\nand a solution for hyperledger fabric.'' [online]. available:\\nhttps://arxiv.org/abs/1805.08541\\n[133] g. destefanis, m. marchesi, m. ortu, r. tonelli, a. bracciali, and\\nr. hierons, ``smart contracts vulnerabilities: a call for blockchain soft-\\nware engineering?'' in proc. int. workshop blockchain oriented softw.\\neng. (iwbose) , mar. 2018, pp. 19\\x1525.\\n[134] l. luu, d.-h. chu, h. olickel, p. saxena, and a. hobor, ``making\\nsmart contracts smarter,'' in proc. acm sigsac conf. comput. commun.\\nsecur. , 2016, pp. 254\\x15269.\\n[135] p. tsankov, a. dan, d. d. cohen, a. gervais, f. buenzli, and\\nm. vechev. (2018). ``securify: practical security analysis of smart con-\\ntracts.'' [online]. available: https://arxiv.org/abs/1806.01143\\n[136] s. tikhomirov, e. voskresenskaya, i. ivanitskiy, r. takhaviev,\\ne. marchenko, and y. alexandrov, ``smartcheck: static analysis of\\nethereum smart contracts,'' in proc. ieee/acm 1st int. workshop\\nemerg. trends softw. eng. blockchain (wetseb) , may/jun. 2018,\\npp. 9\\x1516.\\n[137] a. stradling and e. voorhees, ``system and method of providing a multi-\\nvalidator oracle,'' u.s. patent 20 180 091 316 a1, mar. 29, 2018.\\n[138] a. anjum, m. sporny, and a. sill, ``blockchain standards for compliance\\nand trust,'' ieee cloud comput. , vol. 4, no. 4, pp. 84\\x1590, jul./aug. 2017.\\n[139] h. kakavand, n. k. de sevres, and b. chilton. (jan. 2017). the\\nblockchain revolution: an analysis of regulation and technol-\\nogy related to distributed ledger technologies . [online]. available:\\nhttps://ssrn.com/abstract=2849251\\n[140] e. o. kiktenko et al. , ``quantum-secured blockchain,'' quantum sci.\\ntechnol. , vol. 3, no. 3, p. 035004, 2018.\\n[141] b. rodenburg and s. p. pappas, ``blockchain and quantum computing,''\\nthe mitre corporation, princeton, nj, usa, tech. rep. mtr170487,\\n2017.\\nkhaled salah received the b.s. degree in\\ncomputer engineering with a minor in computer\\nscience from iowa state university, usa, in 1990,\\nand the m.s. degree in computer systems engi-\\nneering and the ph.d. degree in computer sci-\\nence from the illinois institute of technology,\\nusa, in 1994 and 2000, respectively. he was\\nwith the department of information and computer\\nscience, king fahd university of petroleum and\\nminerals (kfupm), saudi arabia, for 10 years.\\nin 2010, he joined khalifa university, uae, where he is currently teach-\\ning graduate and undergraduate courses in the areas of cloud computing,\\ncomputer and network security, computer networks, operating systems, and\\nperformance modeling and analysis. he is a full professor with the depart-\\nment of electrical and computer engineering, khalifa university. he has\\nauthored or co-authored over 190 publications and holds three patents.\\nhe has been giving a number of international keynote speeches, invited talks,\\ntutorials, and research seminars on the subjects of blockchain, the internet of\\nthings, fog and cloud computing, and cybersecurity. he is a senior member\\nof the ieee. he is a member of the ieee blockchain education committee.\\nhe was a recipient of the khalifa university outstanding research award\\nin 2014 and 2015, the kfupm university excellence in research award\\nof 2008 and 2009, the kfupm best research project award of 2009 and\\n2010, and the departmental awards for distinguished research and teaching\\nin prior years. he serves on the editorial boards for many wos-listed journals\\nincluding the iet communications , the iet networks , elsevier's jnca,\\nwiley's scn, wiley's ijnm, j.ucs, and ajse. he is the track chair of\\nthe ieee globecom 2018 on cloud computing. he is an associate editor\\nof ieee b lockchain newsletter .\\nm. habib ur rehman was an assistant\\nprofessor of computer science with the comsats\\ninstitute of it, wah cantonment, pakistan. his\\nph.d. dissertation was with the department of\\ncomputer systems and technology, university of\\nmalaya, kuala lumpur. he is currently an assis-\\ntant professor of computer science with the fast\\nnational university of computer and emerging\\nsciences, lahore, pakistan. he focuses on big data\\nanalytics, the industrial internet of things, and\\nblockchain technologies. he has authored or co-authored in 25 publications\\nincluding 16 isi-listed journal and magazine articles, three ieee conference\\nproceedings, and two book chapters. his research interests include wide\\nspectrum of application areas including smart cities, blockchain, mobile\\nsocial networks, quanti\\x1ced self, mhealth, and wearable assistive technolo-\\ngies among many others. his key research interests include mobile comput-\\ning, edge-cloud computing, blockchain technologies, the internet of things,\\ndata mining, machine learning, and mobile distributed analytics.\\nnishara nizamuddin received the b.sc. and\\nm.sc. degrees in computer science from vit uni-\\nversity, india, in 2010 and 2016, respectively. she\\nwas a software developer with bosch, india, for\\ntwo years. she is currently a researcher with the\\ndepartment of electrical and computer engineer-\\ning, khalifa university of science technology,\\nuae. she conducts research on projects involv-\\ning blockchain, cloud computing, databases, and\\ncybersecuirty. she has published a number of\\nresearch articles on blockchain applications and infrastructure, ethereum\\nsmart contracts, and cybersecurity.\\nala al-fuqaha received the m.s. degree from\\nthe university of missouri, columbia, in 1999, and\\nthe ph.d. degree in electrical and computer engi-\\nneering from the university of missouri-kansas\\ncity, in 2004. he is currently a full professor and\\nthe director of the nest research lab, computer\\nscience department, western michigan univer-\\nsity. he has authored or co-authored in a num-\\nber of publications and has extensive experience\\nwith many popular private and public blockchain\\nlegers and platforms including iota, algorand, hyeprledger fabric,\\nand ethereum. his research interests include the use of public ledgers\\n(blockchain) in support of the security and privacy of the internet of things\\n(iot) and smart city services, the use of machine learning in general and deep\\nlearning in particular in support of the autonomic management of large-scale\\ndeployments of the iot, and smart city infrastructure and services.\\nvolume 7, 2019 10149\",\n",
       " 'this pdf is a selection from a published volume from the national bureau \\nof economic research\\nvolume title: the economics of artificial intelligence: an agenda\\nvolume authors/editors: ajay agrawal, joshua gans, and avi goldfarb, \\neditors\\nvolume publisher: university of chicago pressvolume isbns: 978-0-226-61333-8 (cloth); 978-0-226-61347-5 (electronic)\\n volume url: http://www.nber.org/books/agra-1\\nconference date: september 13–14, 2017publication date: may 2019\\nchapter title: artificial intelligence, automation, and work\\nchapter author(s): daron acemoglu, pascual restrepochapter url: http://www.nber.org/chapters/c14027chapter pages in book: (p. 197 – 236)',\n",
       " '1978.1 introduction\\nthe last two decades have witnessed major advances in artiﬁ  cial intel-\\nligence (ai) and robotics. future progress is expected to be even more spec-\\ntacular, and many commentators predict that these technologies will trans-form work around the world (brynjolfsson and mcafee 2014; ford 2016; boston consulting group 2015; mckinsey global institute 2017). recent surveys ﬁ  nd high levels of anxiety about automation and other technologi-\\ncal trends, underscoring the widespread concerns about their eff  ects (pew \\nresearch center 2017).\\nthese expectations and concerns notwithstanding, we are far from a sat-\\nisfactory understanding of how automation in general, and ai and robotics in particular, impact the labor market and productivity. even worse, much of the debate in both the popular press and academic circles centers around a false dichotomy. on the one side are the alarmist arguments that the oncom-ing advances in ai and robotics will spell the end of work by humans, while many economists on the other side claim that because technological break-throughs in the past have eventually increased the demand for labor and wages, there is no reason to be concerned that this time will be any diff  erent.\\nin this chapter, we build on acemoglu and restrepo (2016), as well as 8\\nartiﬁ  cial intelligence, \\nautomation, and work\\ndaron acemoglu and pascual restrepo\\ndaron acemoglu is the elizabeth and james killian professor of economics at the massa-\\nchusetts institute of technology and a research associate of the national bureau of economic \\nresearch. pascual restrepo is assistant professor of economics at boston university.\\nwe are grateful to david autor for useful comments. we gratefully acknowledge ﬁ  nancial \\nsupport from toulouse network on information technology, google, microsoft, ibm, and the sloan foundation. for acknowledgments, sources of research support, and disclosure of the authors’ material ﬁ  nancial relationships, if any, please see http:// www .nber .org/ chapter/ c14027.ack.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '198    daron acemoglu and pascual restrepo\\nzeira (1998) and acemoglu and autor (2011) to develop a framework for \\nthinking about automation and its impact on tasks, productivity, and work.\\nat the heart of our framework is the idea that automation and thus ai \\nand robotics replace workers in tasks that they previously performed, and via this channel, create a powerful displacement eff  ect. in contrast to pre-\\nsumptions in much of macroeconomics and labor economics, which main-tain that productivity- enhancing technologies always increase overall labor demand, the displacement eff  ect can reduce the demand for labor, wages, and employment. moreover, the displacement eff  ect implies that increases \\nin output per worker arising from automation will not result in a propor-tional expansion of the demand for labor. the displacement eff  ect causes \\na decoupling of wages and output per worker, and a decline in the share of labor in national income.\\nwe then highlight several countervailing forces that push against the \\ndisplacement eff  ect and may imply that automation, ai, and robotics could increase labor demand. first, the substitution of cheap machines for human labor creates a productivity eff  ect: as the cost of producing automated tasks \\ndeclines, the economy will expand and increase the demand for labor in nonautomated tasks. the productivity eff  ect could manifest itself as an increase in the demand for labor in the same sectors undergoing automa-tion or as an increase in the demand for labor in nonautomating sectors. second, capital accumulation triggered by increased automation (which \\nraises the demand for capital) will also raise the demand for labor. third, automation does not just operate at the extensive margin—replacing tasks previously performed by labor—but at the intensive margin as well, increas-ing the productivity of machines in tasks that were previously automated. this phenomenon, which we refer to as deepening of automation , creates a \\nproductivity eff  ect but no displacement, and thus increases labor demand.\\nthough these countervailing eff  ects are important, they are generally \\ninsuffi   cient to engender a “balanced growth path,” meaning that even if \\nthese eff  ects were powerful, ongoing automation would still reduce the share of labor in national income (and possibly employment). we argue that there is a more powerful countervailing force that increases the demand for labor as well as the share of labor in national income: the creation of new tasks, functions and activities in which labor has a comparative advantage rela-tive to machines. the creation of new tasks generates a reinstatement eff  ect \\ndirectly counterbalancing the displacement eff  ect.\\nindeed, throughout history we have not just witnessed pervasive automa-\\ntion, but a continuous process of new tasks creating employment opportuni-ties for labor. as tasks in textiles, metals, agriculture, and other industries were being automated in the nineteenth and twentieth centuries, a new range of tasks in factory work, engineering, repair, back- offi   ce, management, and \\nﬁ nance generated demand for displaced workers. the creation of new tasks \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    1 9 9\\nis not an autonomous process advancing at a predetermined rate, but one \\nwhose speed and nature are shaped by the decisions of ﬁ  rms, workers, and other actors in society, and might be fueled by new automation technologies. first, this is because automation, by displacing workers, may create a greater pool of labor that could be employed in new tasks. second, the currently most discussed automation technology, ai itself, can serve as a platform to create new tasks in many service industries.\\nour framework also highlights that even with these countervailing forces, \\nthe adjustment of an economy to the rapid rollout of automation tech-nologies could be slow and painful. there are some obvious reasons for this related to the general slow adjustment of the labor market to shocks, for example, because of the costly process of workers being reallocated to new sectors and tasks. such reallocation will involve both a slow process of\\xa0searching for the right matches between workers and jobs, and also the need for retraining, at least for some of the workers.\\na more critical, and in this context more novel, factor is a potential mis-\\nmatch between technology and skills —between the requirements of new \\ntechnologies and tasks and the skills of the workforce. we show that such a mismatch slows down the adjustment of labor demand, contributes to inequality, and also reduces the productivity gains from both automation and the introduction of new tasks (because it makes the complementary \\nskills necessary for the operation of new tasks and technologies more scarce).\\ny et another major factor to be taken into account is the possibility of \\nexcessive automation. we highlight that a variety of factors (ranging from a bias in favor of capital in the tax code to labor market imperfections create a wedge between the wage and the opportunity cost of labor) and will push toward socially excessive automation, which not only generates a direct inef-ﬁ ciency, but also acts as a drag on productivity growth. excessive automa-\\ntion could potentially explain why, despite the enthusiastic adoption of new robotics and ai technologies, productivity growth has been disappointing over the last several decades.\\nour framework underscores as well that the singular focus of the research \\nand the corporate community on automation, at the expense of other types of technologies including the creation of new tasks, could be another factor leading to a productivity slowdown because it forgoes potentially valuable productivity growth opportunities in other domains.\\nin the next section, we provide an overview of our approach without \\npresenting a formal analysis. section 8.3 introduces our formal framework, though to increase readability, our presentation is still fairly nontechnical (and formal details and derivations are relegated to the appendix). section 8.4 contains our main results, highlighting both the displacement eff  ect \\nand the countervailing forces in our framework. section 8.5 discusses the mismatch between skills and technologies, potential causes for slow pro-\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '200    daron acemoglu and pascual restrepo\\nductivity growth and excessive automation, and other constraints on labor \\nmarket adjustment to automation technologies. section 8.6 concludes, and the appendix contains derivations and proofs omitted from the text.\\n8.2 automation, work, and wages: an overview\\nat the heart of our framework is the observation that robotics and current \\npractice in ai are continuing what other automation technologies have done \\nin the past: using machines and computers to substitute for human labor in a widening range of tasks and industrial processes.\\nproduction in most industries requires the simultaneous completion of \\na range of tasks. for example, textile production requires production of ﬁ ber, production of yarn from ﬁ  ber (e.g., by spinning), production of the \\nrelevant fabric from the yarn (e.g., by weaving or knitting), pretreatment (e.g., cleaning of the fabric, scouring, mercerizing and bleaching), dyeing and printing, ﬁ  nishing, as well as various auxiliary tasks including design, planning, marketing, transport, and retail.\\n1 each one of these tasks can be \\nperformed by a combination of human labor and machines. at the dawn of the british industrial revolution, most of these tasks were heavily labor intensive. many of the early innovations of that era\\xa0were aimed at automat-ing spinning and weaving by substituting mechanized processes for the labor of skilled artisans (mantoux 1928).\\n2\\nthe mechanization of us agriculture off  ers another example of machines \\nreplacing workers in tasks they previously performed (rasmussen 1982). in the ﬁ  rst half of the nineteenth century, the cotton gin automated the \\nlabor- intensive process of separating the lint from the cotton seeds. in the second half of the nineteenth century, horse- powered reapers, harvesters, and plows replaced manual labor working with more rudimentary tools such as hoes, sickles, and scythes, and this process was continued with tractors in\\xa0the twentieth century. horse- powered threshing machines and fanning mills\\xa0replaced workers employed in threshing and winnowing, two of the most labor- intensive tasks left in agriculture at the time. in the twentieth century, combine harvesters and a variety of other mechanical harvest-ers improved upon the horse- powered machinery, and allowed farmers to mechanically harvest several diff  erent crops.\\ny et another example of automation comes from the development of the \\n1. see http:// textileguide .chemsec .org/ ﬁ  nd/ get- familiar- with- your- textile- production\\n- processes/.\\n2. it was this displacement eff  ect that motivated luddites to smash textile machines and \\nagricultural workers during the captain swing riots to destroy threshing machines. though \\nthese workers often appear in history books as misguided, there was nothing misguided about their economic fears. they were quite right that they were going to be displaced. of course, had they been successful, they might have prevented the industrial revolution from gaining momentum with potentially disastrous consequences for technological development and our subsequent prosperity.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 0 1\\nfactory system in manufacturing and its subsequent evolution. beginning \\nin the second half of the eighteenth century, the factory system introduced the use of machine tools such as lathes and milling machines, replacing the more labor- intensive production techniques relying on skilled artisans (mokyr 1990). steam power and later electricity greatly increased the oppor-tunities for the substitution of capital for human labor. another important turning point in the process of factory automation was the introduction of machines controlled via punch cards and then numerically controlled machines in the 1940s. because numerically controlled machines were more precise, faster, and easier to operate than manual technologies, they enabled signiﬁ  cant cost savings while also reducing the role of craft workers in manu-\\nfacturing  production. this process culminated in the widespread use of cnc (computer numerical control) machinery, which replaced the numeri-cally controlled vintages (groover 1983). a major new development was the introduction of industrial robots in the late 1980s, which automated many of the remaining labor- intensive tasks in manufacturing, including machin-ing, welding, painting, palletizing, assembly, material handling, and quality  control (ayres and miller 1983; groover et\\xa0al. 1986; graetz and michaels 2015; acemoglu and restrepo 2017).\\nexamples of automation are not conﬁ  ned to industry and agriculture. \\ncomputer software has already automated a number of tasks performed by white- collar workers in retail, wholesale, and business services. software and ai- powered technologies can now retrieve information, coordinate logis-tics, handle inventories, prepare taxes, provide ﬁ  nancial services, translate complex documents, write business reports, prepare legal briefs, and diag-nose diseases. these technologies are set to become much better at these and other tasks during the next years (e.g., brynjolfsson and mcafee 2014; ford 2016).\\nas these examples illustrate, automation involves the substitution of \\nmachines for labor and leads to the displacement of workers from the tasks that are being automated. this displacement eff  ect is not present—or pres-ent only incidentally—in most approaches to production functions and labor demand used in macroeconomics and labor economics. the canoni-cal approach posits that production in the aggregate (or in a sector for that matter) can be represented by a function of the form f (al,bk), where l \\ndenotes labor and k  is capital. technology is assumed to take a “factor- \\naugmenting” form, meaning that it multiplies these two factors of produc-tion as the  parameters a  and b  do in this production function.\\nit might appear natural to model automation as an increase in b, that is, \\nas capital- augmenting technological change. however, this type of techno-logical change does not cause any displacement and always increases labor demand and wages (see acemoglu and restrepo 2016). moreover, as our examples above illustrate, automation is not mainly about the development of more productive vintages of existing machines, but involves the intro-\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '202    daron acemoglu and pascual restrepo\\nduction of new machinery to perform tasks that were previously the domain \\nof human labor.\\nlabor- augmenting technological change, corresponding to an increase \\nin a, does create a type of displacement if the elasticity of substitution \\nbetween capital and labor is small. but in general, this type of technologi-cal change also expands labor demand, especially if capital adjusts over the long run (see acemoglu and restrepo 2016). moreover, our examples make it clear that automation does not directly augment labor; on the contrary, it transforms the production process in a way that allows more tasks to be performed by machines.\\n8.2.1 tasks, technologies, and displacement\\nwe propose, instead, a task- based approach, where the central unit of \\nproduction is a task as in the textile example discussed above.\\n3 some tasks \\nhave to be produced by labor, while other tasks can be produced either by \\nlabor or by capital. also, labor and capital have comparative advantages  in \\ndiff erent tasks, meaning that the relative productivity of labor varies across \\ntasks. our framework conceptualizes automation (or automation at the extensive margin) as an expansion in the set of tasks that can be produced with capital. if capital is suffi   ciently cheap or suffi   ciently productive at the \\nmargin, then automation will lead to the substitution of capital for labor in these tasks. this substitution results in a displacement of workers from the tasks that are being automated, creating the aforementioned displace-ment\\xa0eff  ect.\\nthe displacement eff  ect could cause a decline in the demand for labor and \\nthe equilibrium wage rate. the possibility that technological improvements that increase productivity can actually reduce the wage of all workers is an \\nimportant point to emphasize because it is often downplayed or ignored.\\nwith an elastic labor supply (or quasi- labor supply reﬂ  ecting some labor \\nmarket imperfections), a reduction in the demand for labor also leads to lower employment. in contrast to the standard approach based on factor- augmenting technological changes, a task- based approach immediately opens the way to productivity- enhancing technological developments that simultaneously reduce wages and employment.\\n8.2.2 countervailing eff  ects\\nthe presence of the displacement eff  ect does not mean that automation \\nwill always reduce labor demand. in fact, throughout history, there are \\nseveral periods where automation was accompanied by an expansion of \\n3. see autor, leavy, and murnane (2003) and acemoglu and autor (2011). diff  erent from \\nthese papers that develop a task- based approach focusing on inequality implications of tech-\\nnological change, we are concerned here with automation and the process of capital- replacing tasks previously performed by labor and their implications for wages and employment.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 0 3\\nlabor demand and even higher wages. there are a number of reasons why \\nautomation could increase labor demand.\\n1. the productivity eff  ect. by reducing the cost of producing a subset of \\ntasks, automation raises the demand for labor in nonautomated tasks (autor 2015; acemoglu and restrepo 2016). in particular, automation leads to the substitution of capital for labor because at the margin, capital performs certain tasks more cheaply than labor used to. this reduces the prices of the goods and services whose production processes are being automated, mak-ing households eff  ectively richer, and increasing the demand for all goods and services.\\nthe productivity eff  ect could manifest itself in two complementary ways. \\nfirst, labor demand might expand in the same sectors that are undergoing automation.\\n4 a telling example of this process comes from the eff  ects of the \\nintroduction of automated teller machines (atms) on the employment of bank tellers. bessen (2016) documents that concurrent with the rapid spread of atms—a clear example of automating technology that enabled these new machines to perform tasks that were previously performed more expen-sively by labor—there was an expansion in the employment of bank tellers. bessen suggests that this is because atms reduced the costs of banking and encouraged banks to open more branches, raising the demand for bank tell-ers who then specialized in tasks that atms did not automate.\\nanother interesting example of this process is provided by the dynam-\\nics of labor demand in spinning and weaving during the british industrial revolution as recounted by mantoux (1928). automation in weaving (most notably, john kay’s ﬂ  y shuttle) made this task cheaper and increased the price of yarn and the demand for the complementary task of spinning. later automation in spinning reversed this trend and increased the demand for weavers. in the words of john wyatt, one of the inventors of the spin-ning machine, installing spinning machines would cause clothiers to “then want more hands in every other branch of the trade, viz. weavers, shearmen, scourers, combers, etc.” (quoted in mantoux 1928). this is also probably the reason why the introduction of eli whitney’s cotton gin in 1793, which automated the labor- intensive process of separating the cotton lint from the seeds, appears to have led to greater demand for slave labor in southern plantations (rasmussen 1982).\\nthe productivity eff  ect also leads to higher real incomes and thus to greater \\ndemand for all products, including those not experiencing automation. the greater demand for labor from other industries might then counteract the negative displacement eff  ect of automation. the clearest historical example of this comes from the adjustment of the us and many european economies \\n4. this requires that the demand for the products of these sectors is elastic. acemoglu and \\nrestrepo (2017) refer to this channel as the price- productivity eff  ect because it works by reduc-\\ning the relative price of products that are being automated and restructuring production toward these sectors.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '204    daron acemoglu and pascual restrepo\\nto the mechanization of agriculture. by reducing food prices, mechanization \\nenriched consumers who then demanded more nonagricultural goods (her-rendorf, rogerson, and valentinyi 2013), and created employment oppor-tunities for many of the workers dislocated by the mechanization process in the ﬁ  rst place.\\n5\\nthis discussion also implies that, in contrast to the popular emphasis on \\nthe negative labor market consequences of “brilliant” and highly productive new technologies set to replace labor (e.g., brynjolfsson and mcafee 2014; ford 2016), the real danger for labor may come not from highly productive but from “so- so” automation technologies that are just productive enough to be adopted and cause displacement, but not suffi   ciently productive to \\nbring about powerful productivity eff  ects.\\n2. capital accumulation. as our framework in the next section clariﬁ  es, \\nautomation corresponds to an increase in the capital intensity of produc-tion. the high demand for capital triggers further accumulation of capital (e.g., by increasing the rental rate of capital). capital accumulation then raises the demand for labor. this may have been an important channel of adjustment of the british economy during the industrial revolution and of the american economy in the ﬁ  rst half of the twentieth century in the face of mechanization of agriculture, for in both cases there was rapid capital accumulation (allen 2009; olmstead and rhode 2001).\\nas we discuss in the next section, under some (albeit restrictive) assump-\\ntions often adopted in neoclassical models of economic growth, capital accu-\\nmulation can be suffi   ciently powerful that automation will always increase wages in the long run (see acemoglu and restrepo 2016), though the more robust prediction is that it will act as a countervailing eff  ect.\\n3. deepening of automation.  the displacement eff  ect is created by auto-\\nmation at the extensive margin—meaning the expansion of the set of tasks that can be produced by capital. but what happens if technological improve-ments increase the productivity of capital in tasks that have already been automated? this will clearly not create additional displacement because labor was already replaced by capital in those tasks. but it will generate the same productivity eff  ects we have already pointed out above. these pro-ductivity eff  ects then raise labor demand. we refer to this facet of advances in automation technology as the deepening of automation (or as automa-tion at the intensive margin because it is intensifying the productive use of machines).\\na clear illustration of the role of deepening automation comes from the \\nintroduction of new vintages of machinery replacing older vintages used in already automated tasks. for instance, in us agriculture the replacement of \\n5. acemoglu and restrepo (2017) refer to it as a “scale eff  ect” because in their setting it acted \\nin a homothetic manner, scaling up demand from all sectors, though in general it could take \\na nonhomothetic form.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 0 5\\nhorse- powered reapers and harvesters by diesel tractors increased produc-\\ntivity, presumably with limited additional substitution of workers in agri-cultural tasks.\\n6 in line with our account of the potential role of deepening \\nautomation, agricultural productivity and wages increased rapidly starting in the 1930s, a period that coincided with the replacement of horses by trac-tors (olmstead and rhode 2001; manuelli and seshadri 2014).\\nanother example comes from the vast improvements in the effi   ciency of \\nnumerically controlled machines used for metal cutting and processing (such as mills and lathes), as the early vintages controlled by punched cards were replaced by computerized models during the 1970s. the new computer-ized machines were used in the same tasks as the previous vintages, and so\\xa0the additional displacement eff  ects were probably minor. as a result, the transition to cnc (computer numerical control) machines increased the\\xa0productivity of machinists, operators, and other workers in the industry (groover 1983).\\nthe three countervailing forces we have listed here are central for under-\\nstanding why the implications of automation are much richer than the direct displacement eff  ects might at ﬁ  rst suggest, and why automation need not \\nbe an unadulterated negative force against the labor market fortunes of workers. nevertheless, there is one aspect of the displacement eff  ect that is unlikely to be undone by any of these four countervailing forces: as we show in the next section, automation necessarily makes the production process more capital intensive, reducing the share of labor in national income. intui-tively, this is because it entails the substitution of capital for tasks previously performed by labor, thus squeezing labor into a narrower set of tasks.\\nif, as we have suggested, automation has been ongoing for centuries, with \\nor without powerful countervailing forces of the form listed here, we should have seen a “nonbalanced” growth process with the share of labor in national income declining steadily since the beginning of the industrial revolution. that clearly has not been the case (see, e.g., kuznets 1966; acemoglu 2009). this suggests that there have been other powerful forces making production more labor intensive and balancing the eff  ects of automation. this is what we suggest in the next subsection.\\n8.2.3 new tasks\\nas discussed in the introduction, periods of intensive automation have \\noften coincided with the emergence of new jobs, activities, industries, \\nand tasks. in nineteenth- century britain, for example, there was a rapid expansion of new industries and jobs ranging from engineers, machinists, repairmen, conductors, back- offi   ce workers, and managers involved with \\n6. nevertheless, the move from horse power to tractors contributed to a decline in agricultural \\nemployment via a diff  erent channel: tractors increased agricultural productivity, and because \\nof inelastic demand, expenditure on agricultural products declined (rasmussen 1982).\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '206    daron acemoglu and pascual restrepo\\nthe introduction and operation of new technologies (e.g., landes 1969; \\nchandler 1977; and mokyr 1990). in early twentieth- century america, the mechanization of agriculture coincided with a large increase in employ-ment in new industry and factory jobs (kuznets 1966) among others in the burgeoning industries of farm equipment (olmstead and rhode 2001) and cotton milling (rasmussen 1982). this is not just a historical phenomenon. as documented in acemoglu and restrepo (2016), from 1980 to 2010 the introduction and expansion of new tasks and job titles explains about half of us employment growth.\\nour task- based framework highlights that the creation of new labor- \\nintensive tasks (tasks in which labor has a comparative advantage relative to capital) may be the most powerful force balancing the growth process in the face of rapid automation. without the demand for workers from new factory jobs, engineering, supervisory tasks, accounting, and managerial occupations in the second half of the nineteenth and much of the twenti-eth centuries, it would have been impossible to employ millions of workers exiting the agricultural sector and automated labor- intensive tasks.\\nin the same way that automation has a displacement eff  ect, we can think \\nof the creation of new tasks as engendering a reinstatement eff  ect. in this \\nway, the creation of new tasks has the opposite eff  ect of automation. it always generates additional labor demand, which increases the share of labor in national income. consequently, one powerful way in which tech-nological progress could be associated with a balanced growth path is via the balancing of the impacts of automation by the creation of new tasks.\\nthe creation of new tasks need not be an exogenous, autonomous process \\nunrelated to automation, ai, and robotics for at least two reasons:\\n1. as emphasized in acemoglu and restrepo (2016), rapid automation \\nmay endogenously generate incentives for ﬁ  rms to introduce new labor- intensive tasks. automation running ahead of the creation of new tasks reduces the labor share and possibly wages, making further automation less proﬁ table and new tasks generating employment opportunities for labor \\nmore proﬁ  table for ﬁ  rms. acemoglu and restrepo (2016) show that this equilibrating force could be powerful enough to make the growth process balanced.\\n2. some automation technology platforms, especially ai, may facilitate \\nthe creation of new tasks. a recent report by accenture identiﬁ  ed entirely \\nnew categories of jobs that are emerging in ﬁ  rms using ai as part of their production process (accenture plc 2017). these jobs include “trainers” (to train the ai systems), “explainers” (to communicate and explain the output of ai systems to customers), and “sustainers” (to monitor the performance of ai systems, including their adherence to prevailing ethical standards).\\nthe applications of ai to education, health care, and design may also \\nresult in employment opportunities for new workers. take education. exist-\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 0 7\\ning evidence suggests that many students, not least those with certain learn-\\ning disabilities, will beneﬁ  t from individualized education programs and personalized instruction (kolb 1984). with current technology, it is pro-hibitively costly to provide such services to more than a small fraction of students. applications of ai may enable the educational system to become more customized, and in the process create more jobs for education profes-sionals to monitor, design, and implement individualized education pro-grams. similar prospects exist in health care and elderly care services.\\n8.2.4 revisiting the false dichotomy\\nthe conceptual framework outlined above, which will be further elabo-\\nrated in the next section, clariﬁ  es why the current debate is centered on a false \\ndichotomy between disastrous and totally benign eff  ects of automation.\\nour task- based framework underscores that automation will always \\ncreate a displacement eff  ect. unless neutralized by the countervailing forces, \\nthis displacement eff  ect could reduce labor demand, wages, and employ-ment. at the very least, this displacement eff  ect implies that a falling share of output will accrue to labor. these possibilities push against the benign accounts emphasizing that technology always increases the demand for labor and beneﬁ  ts workers.\\nour framework does not support the alarmist perspectives stressing the \\ndisastrous eff  ects of automation for labor either. rather, it highlights several countervailing forces that soften the impact of automation on labor. more important, as we have argued in the previous subsection, the creation of new labor- intensive tasks has been a critical part of the adjustment process in the face of rapid automation. the creation of new tasks is not just manna from heaven. there are good reasons why market incentives will endogenously lead to the creation of new tasks that gain strength when automation itself becomes more intensive. also, some of the most deﬁ  ning automation tech-nologies of our age, such as ai, may create a platform for the creation of new sets of tasks and jobs.\\nat the root of some of the alarmism is the belief that ai will have very dif-\\nferent consequences for labor than previous waves of technological change. our framework highlights that the past is also replete with automation technologies displacing workers, but this need not have disastrous eff  ects \\nfor labor. nor is it technologically likely that ai will replace labor in all or almost all of the tasks in which it currently specializes. this limited remit of ai can be best understood by contrasting the current nature and ambitions of ai with those of its ﬁ  rst coming under the auspices of “cybernetics.” the intellectual luminaries of cybernetics, such as norbert wiener, envisaged the production of human- level artiﬁ  cial intelligence —computer systems \\ncapable of thinking in a way that could not be distinguished from human intelligence—replicating all human thought processes and faculties (nilsson 2009). in 1965, herbert simon predicted that “machines will be capable, \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '208    daron acemoglu and pascual restrepo\\nwithin twenty years, of doing any work a man can do” (simon 1965, 96). \\nmarvin minsky agreed, declaring in 1967 that “within a generation, i am convinced, few compartments of intellect will remain outside the machine’s realm” (minsky 1967, 2).\\ncurrent practice in the ﬁ  eld of ai, especially in its most popular and prom-\\nising forms based on deep learning and various other “big data” methods applied to unstructured data, eschews these initial ambitions and aims at developing applied artiﬁ  cial intelligence —commercial systems specializing \\nin clearly delineated tasks related to prediction, decision- making, logistics, and pattern recognition (nilsson 2009). though many occupations involve such tasks—and so ai is likely to have a displacement eff  ect in these tasks—there are still many human skills that we still cannot automate, including complex reasoning, judgment, analogy- based learning, abstract problem- solving, and a mixture of physical activity, empathy, and communication skills. this reading of the current practice of ai suggests that the potential for ai and related technological advances to automate a vast set of tasks is limited.\\n8.2.5 flies in the ointment\\nour framework so far has emphasized two key ideas. first, automation \\ndoes create a potential negative impact on labor through the displacement \\neff ect and also by reducing the share of labor in national income. but sec-\\nond, it can be counterbalanced by the creation of new tasks (as well as the productivity eff  ect, capital accumulation and the deepening of automation, which tend to increase the demand for labor, even though they do not gener-ally restore the share of labor in national income to its preautomation levels).\\nthe picture we have painted underplays some of the challenges of adjust-\\nment, however. the economic adjustment following rapid automation can be more painful than the process we have outlined for a number of reasons.\\nmost straightforward, automation changes the nature of existing jobs, \\nand the reallocation of workers from existing jobs and tasks to new ones is a complex and often slow process. it takes time for workers to ﬁ  nd new \\njobs and tasks in which they can be productive, and periods during which workers are laid off   from their existing jobs can create a depressed local or \\nnational labor market, further increasing the costs of adjustment. these eff ects are visible in recent studies that have focused on the adjustment of \\nlocal us labor markets to negative demand shocks, such as autor, dorn, and hanson (2013), who study the slow and highly incomplete adjustment of local labor markets in response to the surge in chinese exports, mian and suﬁ   (2014), who investigate the implications of the collapse in housing prices on consumption and local employment, and perhaps more closely related to our focus, acemoglu and restrepo (2017), who ﬁ  nd employment \\nand wage declines in areas most exposed to one speciﬁ  c type of automation, the introduction of industrial robots in manufacturing.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 0 9\\nthe historical record also underscores the painful nature of the adjust-\\nment. the rapid introduction of new technologies during the british indus-\\ntrial revolution ultimately led to rising labor demand and wages, but this was only after a protracted period of stagnant wages, expanding poverty, and harsh living conditions. during an eighty- year period extending from the beginning of the industrial revolution to the middle of the nineteenth century, wages stagnated and the labor share fell, even as technological advances and productivity growth were ongoing in the british economy, a phenomenon which allen (2009) dubs the “engel’s pause” (previously referred to as the “living standards paradox”; see mokyr [1990]).\\nthere should thus be no presumption that the adjustment to the changed \\nlabor market brought about by rapid automation will be a seamless, costless, and rapid process.\\n8.2.6 mismatch between skills and technologies\\nit is perhaps telling that wages started growing in the nineteenth- century \\nbritish economy only after mass schooling and other investments in human \\ncapital expanded the skills of the workforce. similarly, the adjustment to the large supply of labor freed from agriculture in early twentieth- century america may have been greatly aided by the “high school movement,” which increased the human capital of the new generation of american workers (goldin and katz 2010). the forces at work here are likely to be more general than these examples. new tasks tend to require new skills. but to the extent that the workforce does not possess those skills, the adjustment process will be hampered. even more ominously, if the educational system is not up to providing those skills (and if we are not even aware of the types of new skills that will be required so as to enable investments in them), the adjustment will be greatly impeded. even the most optimistic observers ought to be concerned about the ability of the current us educational system to identify and provide such skills.\\nat stake here is not only the speed of adjustment, but potential produc-\\ntivity gains from new technologies. if certain skills are complementary to new technologies, their absence will imply that the productivity of these new technologies will be lower than otherwise. thus the mismatch between skills and technologies not only slows down the adjustment of employment and wages, but holds back potential productivity gains. this is particularly true for the creation of new tasks. the fact that while there is heightened concerns about job losses from automation, many employers are unable to ﬁ nd workers with the right skills for their jobs underscores the importance \\nof these considerations (deloitte and the manufacturing institute 2011).\\n8.2.7 missing productivity and excessive automation\\nthe issues raised in the previous subsection are important not least because \\na deep puzzle in any discussion of the impact of new technologies is miss-\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '210    daron acemoglu and pascual restrepo\\ning productivity growth—the fact that while so many sophisticated tech-\\nnologies are being adopted, productivity growth has been slow. as pointed out by gordon (2016), us productivity growth since 1974 (with the excep-tion of the period from 1995 to 2004) compares dismally to its postwar per-formance. while the annual rate of labor productivity growth of the us economy averaged 2.7 percent between 1947 and 1973, it only averaged 1.5\\xa0percent between 1974 and 1994. average productivity growth rebounded to 2.8 percent between 1995 and 2004, and then fell again to only 1.3 percent between 2005 and 2015 (syverson 2017). how can we make sense of this?\\none line of attack argues that there is plenty of productivity growth, but it \\nis being mismeasured. but, as pointed out by syverson (2017), the pervasive nature of this slow down, and the fact that it is even more severe in industries that have made greater investments in information technology (acemoglu et\\xa0al. 2014), make the productivity mismeasurement hypothesis unlikely to account for all of the slowdown.\\nour conceptual framework suggests some possible explanations. they \\ncenter around the possibility of “excessive automation,” meaning faster automation than socially desirable (acemoglu and restrepo 2016, 2018a). excessive automation not only creates direct ineffi   ciencies, but may also hold \\nproductivity growth down by wastefully using resources and displacing labor.\\nthere are two broad reasons for excessive automation, both of which we \\nbelieve to be important. the ﬁ  rst is related to the biases in the us tax code, which subsidizes capital relative to labor. this subsidy takes the form of several diff  erent provisions, including additional taxes and costs employ-ers have to pay for labor, subsidies in the form of tax credits and acceler-ated depreciation for capital outlays, and additional tax credit for interest rate deductions in case of debt- ﬁ  nanced investments (aei 2008; tuzel and zhang 2017). all of these distortions imply that at the margin, when a utilitarian social planner would be indiff  erent between capital and labor, the market would have an incentive to use machines, giving an ineffi   cient \\nboost to automation. this ineffi   ciency could translate into slow productivity growth because the substitution of labor for machines worsens the misal-location of capital and labor.\\neven absent such a ﬁ  scal bias, there are natural reasons for excessive auto-\\nmation. labor market imperfections and frictions also tend to imply that the\\xa0equilibrium wage is above the social opportunity cost of labor. thus a social planner would use a lower shadow wage in deciding whether to automate a task than the market, creating another force toward excessive automation. the implications of this type of excessive automation would again include slower productivity growth than otherwise.\\nfinally, it is possible that automation has continued at its historical pace, \\nor may have even accelerated recently, but the dismal productivity growth \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 1 1\\nperformance we are witnessing is driven by a slowdown in the creation of \\nnew tasks or investment in other productivity- enhancing technologies (see acemoglu and restrepo 2016). a deceleration in the creation of new tasks and technologies other than automation would also explain why the period of slow productivity growth coincided with poor labor market outcomes, including stagnant median wages and a decline in the labor share.\\nthere are natural reasons why too much emphasis on automation may \\ncome at the cost of investments in other technologies, including the creation of new tasks. for instance, in a setting where technologies are developed endogenously using a common set of resources (e.g., scientists), there is a natural trade- off   between faster automation and investments in other types of technologies (acemoglu and restrepo 2016). though it is at the moment impossible to know whether the redirection of research resources away from the creation of new tasks and toward automation has played an important role in the productivity slowdown, the almost singular focus in the corporate sector and research community on ai, applications of deep learning, and other big data methods to automate various tasks makes it at least plausible that there may be too much attention devoted to automation at the expense of other technological breakthroughs.\\n8.3 a model of automation, tasks, and the demand for labor\\nin the previous section, we provided an intuitive discussion of how auto-\\nmation in general, and robotics and ai in particular, is expected to impact \\nproductivity and the demand for labor. in this section, we outline a for-mal framework that underlines these conclusions. our presentation will be somewhat informal and without any derivations, which are all collected in the appendix.\\n8.3.1  a task- based framework\\nwe start with a simpliﬁ  ed version of the task- based framework intro-\\nduced in acemoglu and restrepo (2016). aggregate output is produced by \\ncombining the services of a unit measure of tasks x ∈ [n – 1, n ] according \\nto the following cobb- douglas (unit elastic) aggregator\\n(1) lny=\\nn1n\\nlny(x)dx,\\nwhere y denotes aggregate output and y(x) is the output of task x. the \\nfact that tasks run between n – 1 and n enables us to consider changes in \\nthe range of tasks, for example, because of the introduction of new tasks, without altering the total measure of tasks in the economy.\\neach task can be produced by human labor, ℓ(x), or by machines, m(x), \\ndepending on whether it has been (technologically) automated or not. in \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '212    daron acemoglu and pascual restrepo\\nparticular, tasks x  ∈ [n – 1,i ] are technologically automated, so can be \\nproduced by either labor or machines, while the rest are not technologically \\nautomated, so must be produced with labor:\\n(2) y(x)=l(x)(x)+m(x)m(x)i f x n1,i\\nl(x)(x)i fxi,n( .\\nhere, /h9253l(x) is the productivity of labor in task x and is assumed to be increas-\\ning, while /h9253m(x) is the productivity of machines in automated tasks. we \\nassume that /h9253l(x)//h9253m(x) is increasing in x, and thus labor has a comparative \\nadvantage in higher- indexed tasks.7\\nthe threshold i  denotes the frontier of automation possibilities: it \\ndescribes the range of tasks that can be automated using current available \\ntechnologies in ai, industrial robots, various computer- assisted technolo-gies, and other forms of “smart machines.”\\nwe also simplify the discussion by assuming that both the supply of labor, \\nl, and the supply of machines, k, are ﬁ  xed and inelastic. the fact that the \\nsupply of labor is inelastic implies that changes in labor demand impact the share of labor in national income and the wage, but not the level of employ-ment. we outline below how this framework can be easily generalized to accommodate changes in employment and unemployment.\\n8.3.2 types of technological change\\nour framework incorporates four diff  erent types of technological ad-\\nvances. all advances increase productivity, but as we will see with a very \\ndiff erent impact on the demand for labor and wages.\\n1. labor- augmenting technological advances : standard approaches in \\nmacroeconomics and labor economics typically focus on labor- augmenting technological advances. such technological changes correspond to increases (or perhaps an equi- proportionate increase) in the function /h9253\\nl(x) . our anal-\\nysis will show that they are in fact quite special, and the implications of auto-mation and ai are generally very diff  erent from those of labor- augmenting advances.\\n2. automation (at the extensive margin) : we consider automation to be an \\nexpansion of the set of tasks that are technologically automated as repre-sented by the parameter i.\\n7. our theoretical framework builds on zeira (1998) who develops a model where ﬁ  rms \\nproduce intermediates using labor- intensive or capital- intensive technologies. zeira focuses on \\nhow wages aff  ect the adoption of capital- intensive production methods and how this margin \\nampliﬁ  es productivity diff  erences across countries and over time. in contrast, we focus on the \\nimplications of automation—modeled here as an increase in the set of tasks that can be pro-duced by machines, represented by i —for the demand for labor, wages, and employment, and \\nwe also study the implications of the introduction of new tasks. in acemoglu and restrepo (2016), we generalize zeira’s framework in a number of other dimensions and also endogenize the development of automation technologies and new tasks.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 1 3\\n3. deepening of automation (or automation at the intensive margin) : an-\\nother dimension of advances in ai and robotics technology will tend to \\nincrease the productivity of machines in tasks that are already automated, for example, by replacing existing machines with newer, more productive vintages. in terms of our model, this corresponds to an increase in the /h9253\\nm(x) \\nfunction for tasks x < i. we will see that this type of deepening of automa-tion has very diff  erent implications for labor demand than automation (at the extensive margin).\\n4. creation of new tasks : as emphasized in acemoglu and restrepo \\n(2016), another important aspect of technological change is the creation of new tasks and activities in which labor has a comparative advantage. in our model this can be captured in the simplest possible way by an increase in n.\\n8.3.3 equilibrium\\nthroughout, we denote the equilibrium wage rate by w and the equilib-\\nrium cost of machines (or the rental rate) by r . an equilibrium requires \\nﬁ rms to choose the cost- minimizing way of producing each task and labor \\nand capital markets to clear.\\nto simplify the discussion, we impose the following assumption\\n(a1) \\nl(n)\\nm(n1)>w\\nr>l(i)\\nm(i).\\nthe second inequality implies that all tasks in [n – 1,i ] will be produced \\nby machines. the ﬁ  rst inequality implies that the introduction of new \\ntasks—an increase in n —will increase aggregate output. this assumption \\nis imposed on the wage- to-rental rate ratio, which is an endogenous object; the appendix provides a condition on the stock of capital and labor that is equivalent to this assumption (see assumption [a2]).\\nwe also show in the appendix that aggregate output (gdp) in the equi-\\nlibrium takes the form\\n(3) y=bk\\ni\\nn+1in+1l\\nnini\\n,\\nwhere(4) \\nb=exp\\nn1i\\nlnm(x)dx+\\nin\\nlnl(x)dx.\\naggregate output is given by a cobb- douglas aggregate of the capital stock \\nand employment. this resulting aggregate production function in equation (3) is itself derived from the allocation of the two factors of production to tasks. more important, the exponents of capital and labor in this production function depend on the extent of automation, i, and the creation of new tasks, as captured by n.\\ncentral to our focus is not only the impact of new technologies on pro-\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '214    daron acemoglu and pascual restrepo\\nductivity, but also on the demand for labor. the appendix shows that the \\ndemand for labor can be expressed as\\n(5) w=(ni)y\\nl.\\nthis equation is intuitive in view of the cobb- douglas production func-\\ntion in equation(3), since it shows that the wage (the marginal product of labor) is equal to the average product of labor—which we will also refer to as “productivity”—times the exponent of labor in the aggregate production function.\\nequation (5) implies that the share of labor in national income is given by\\n(6) \\nsl=wl\\ny=ni.\\n8.4  technology and labor demand\\n8.4.1 the displacement eff  ect\\nour ﬁ  rst result shows that automation (at the extensive margin) indeed \\ncreates a displacement eff  ect, reducing labor demand as emphasized in sec-\\ntion 8.2, but also that it is counteracted by a productivity eff  ect, pushing \\ntoward greater labor demand.\\nspeciﬁ  cally, from equation (5) we directly obtain\\n(7) dlnw\\ndi=dlnni()\\ndi\\ndisplacement effect <0+dlny/l()\\ndi\\nproductivity effect >0.\\nwithout the productivity eff  ect, automation would always reduce labor \\ndemand because it is directly replacing labor in tasks that were previously \\nperformed by workers. indeed, if the productivity eff  ect is limited, automa-tion will reduce labor demand and wages.\\n8.4.2 counteracting the displacement eff  ect i: the productivity eff  ects\\nthe productivity eff  ect, on the other hand, captures the important idea \\nthat by increasing productivity, automation raises labor demand in the tasks \\nthat are not automated. as highlighted in the previous section, there are two complementary manifestations of the productivity eff  ect. the ﬁ  rst works \\nby increasing the demand for labor in nonautomated tasks in the industries where automation is ongoing. the second works by raising the demand for labor in other industries. the productivity eff  ect shown in equation (7) combines these two mechanisms.\\none important implication of the decomposition in equation (7) is that, in \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 1 5\\ncontrast to some popular discussions, the new ai and robotics technologies \\nthat are more likely to reduce the demand for labor are not those that are brilliant and highly productive, but those that are “so- so”—just productive enough to be adopted but not much more productive or cost- saving than the production processes that they are replacing. interestingly, and related to our discussion on missing productivity, if new automation technologies are so-so, they would not bring major improvements in productivity either.\\nto elaborate further on this point and to understand the productivity \\nimplications of automation technologies better, let us also express the pro-ductivity eff  ect in terms of the physical productivities of labor and machines and factor prices as follows:\\n dlny/l\\n()\\ndi=lnw\\nli()lnr\\nmi()>0.\\nthe fact that this expression is positive, and that new automation technolo-\\ngies will be adopted, follows from assumption (a1). using this expression, the overall impact on labor demand can be alternatively written as\\n(8) dlnw\\ndi=1\\nni\\ndisplacement effect <0+lnw\\nli()lnr\\nmi()\\nproductivity effect > 0.\\nthis expression clariﬁ  es that the displacement eff  ect of automation will \\ndominate the productivity eff  ect and thus reduce labor demand (and wages) \\nwhen /h9253m(i)/ r ≈ /h9253l(i) / w, which is exactly the case when new technologies \\nare so-so—only marginally better than labor at newly automated tasks. in \\ncontrast, when /h9253m(i)/ r >> /h9253l(i) / w , automation will increase productivity \\nsuffi  ciently to raise the demand for labor and wages.\\nturning next to the implications of automation for the labor share, equa-\\ntion (6) implies\\n(9) dsl\\ndi=1<0,\\nso that regardless of the magnitude of the productivity eff  ect, automation \\nalways reduces the share of labor in national income. this negative impact \\non the labor share is a direct consequence of the fact that automation always increases productivity more than the wage, d ln(y /l)\\xa0/di > dlnw\\xa0/ di (itself \\ndirectly following from equation [7], which shows that the impact on wages is given by the impact on productivity minus the displacement eff  ect).\\nthe implications of standard labor- augmenting technological change, \\nwhich corresponds to a (marginal) shift-up of the /h9253\\nl(x) schedule, are very \\ndiff erent from those of automation. labor-augmenting technologies leave \\nthe form of the wage equation (5) unchanged, and increase average output \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '216    daron acemoglu and pascual restrepo\\nper worker, y/l , and the equilibrium wage, w, proportionately, and thus \\ndo not impact the share of labor in national income.8\\n8.4.3 counteracting the displacement eff  ect ii: capital accumulation\\nwe have so far emphasized the displacement eff  ect created by new auto-\\nmation technologies. we have also seen that the productivity eff  ect counter-\\nacts the displacement eff  ects to some degree. in this and the next subsection, \\nwe discuss two additional countervailing forces.\\nthe ﬁ  rst force is capital accumulation. the analysis so far assumed that \\nthe economy has a ﬁ  xed supply of capital that could be devoted to new machines (automation technologies). as a result, a further increase in auto-mation (at the extensive margin) increases the demand for capital and thus the equilibrium rental rate, r. this may be understood as the short- run \\neff ect of automation.\\ninstead, we may envisage the “medium- run” eff  ect as the impact of \\nthese technologies after the supply of machines used in newly automated tasks expands as well. because machines and labor are q- complements, an increase in the capital stock, with the level of employment held constant at l, increases the real wage and reduces the rental rate. equation (8) shows that this change in factor prices makes the productivity eff  ect more powerful and the impact on the wage more likely to be positive.\\nin the limit, if capital accumulation ﬁ  xes the rental rate at a constant \\nlevel (which will be the case, for example, when we have a representative household with exponential discounting and time- separable preferences), the productivity eff  ect will always dominate the displacement eff  ect.\\n9\\ncrucially, however, equation (6) still applies, and thus automation contin-\\nues to reduce the labor share, even after the adjustment of the capital stock.\\n8.4.4   counteracting the displacement eff  ect iii: \\ndeepening of automation\\nanother potentially powerful force counteracting the displacement eff  ect \\nfrom automation at the extensive margin comes from the deepening of auto-\\nmation (or automation at the intensive margin), for example, because of improvements in the performance of already- existing automation technolo-\\n8. a small shift-up of /h9253l(x) does not violate assumption (a1) because at the margin it was \\nstrictly cost- saving to use machines. a larger labor- augmenting technological change may \\nresult in a violation of assumption (a1). at this point, only tasks below an endogenous thresh-old \\ni< i would be automated, and labor- augmenting technologies could also reduce i, increas-\\ning the labor share in national income.\\n9. assuming that production exhibits constant returns to scale, the productivity gains from \\nany technology accrue to both capital and labor. in particular, for any constant returns to scale production function, we have dlny |\\nk,l = sldlnw + (1 – sl)dlnr, where d lny |k,l > 0 denotes \\nthe productivity gains brought by technology holding the use of capital and labor constant, and s\\nl is the labor share. if the rental rate is constant in the long run, then d lnr = 0 and all \\nproductivity gains accrue to the relatively inelastic factor, labor.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 1 7\\ngies or the replacement of such technologies with newer, more productive \\nvintages. this increase in the productivity of machines in tasks that are already automated corresponds in our model to an increase in the function /h9253\\nm(x) in tasks below i.\\nto explore the implications of this type of change in the simplest possible \\nway, let us suppose that /h9253m(x) = /h9253m in all automated tasks, and consider an \\nincrease in the productivity of machines by d ln/h9253m > 0, with no change in \\nthe extensive margin of automation, i. the implications of this change in the productivity of machines on equilibrium wages and productivity can be obtained as\\n dlnw=dlny/l=i\\nn+1() dlnm>0.\\nhence, deepening of automation will tend to increase labor demand and \\nwages, further counteracting the displacement eff  ect. note, however, that \\nas with capital accumulation, in our model this has no impact on the share of labor in national income, as can be seen from the fact that wages and productivity increase by exactly the same amount.\\n8.4.5 new tasks and the comparative advantage of labor\\nmuch more powerful than the countervailing eff  ects of capital accumula-\\ntion and the deepening of automation is the creation of new tasks in which \\nlabor has a comparative advantage. these tasks include both new, more complex versions of existing tasks and the creation of new activities, which are made possible by advances in technology. in terms of our framework, they correspond to increases in n.\\nan increase in n —the creation of new tasks—raises productivity by\\n dlny/l\\ndn\\n=lnr\\nm(n1)lnw\\nl(n)>0,\\nwhich is positive from assumption (a1).\\nmore important for our focus here, the creation of new tasks also in-\\ncreases labor demand and equilibrium wages by creating a reinstatement \\neff ect counter acting the displacement eff  ect. in particular,\\n(10) dlnw\\ndn=lnr\\nm(n1)lnw\\nl(n)\\nproductivity effect>0+1\\nni\\nreinstatement effect>0.\\nin contrast to capital accumulation and the deepening of automation, \\nwhich increase the demand for labor but do not aff  ect the labor share, equa-tion (6) implies that new tasks increase the labor share, that is,\\n ds\\nl\\ndn=1.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '218    daron acemoglu and pascual restrepo\\nthe centrality of new tasks can be understood when viewed from a com-\\nplementary historical angle. automation is not a recent phenomenon. as we \\nalready discussed in section 8.2, the history of technology of the last two cen-turies is full of examples of automation, ranging from weaving and spinning machines to the mechanization of agriculture, as discussed in the previous section. even with capital accumulation and the deepening of automation, if there were no other counteracting force, we would see the share of labor in national income declining steadily. our conceptual framework highlights a major force preventing such a decline—the creation of new tasks in which labor has a comparative advantage.\\nthis can be seen by putting together equations (7) and (10), which yields\\n(11) dlnw=lnr\\nm(n1)lnw\\nl(n)dn\\n +lnw\\nl(i)lnr\\nm(i)di+1\\nnidn di() ,\\nand also from equation (6),\\n dsl=dn di.\\nfor the labor share to remain stable and for wages to increase in tandem \\nwith productivity, as has been the case historically, we need i —capturing \\nthe extensive margin of automation—to grow by the same amount as the range of new tasks, n. when that happens, equilibrium wages grow propor-tionately with productivity, and the labor share, s\\nl, remains constant, as can \\nbe seen from the fact that the ﬁ  rst line of equation (11) is in this case equal to the increase in productivity or gross domestic product (gdp) per worker. indeed, rewriting equation (11) imposing dn = di, we have\\n dlnw=ln\\nl(n)\\nm(n1)lnl(i)\\nm(i)di>0,\\nwhich is strictly positive because of assumption (a1).\\n8.4.6 a false dichotomy: recap\\nwith our conceptual framework exposited in a more systematic manner, \\nwe can now brieﬂ  y revisit the false dichotomy highlighted in the introduc-\\ntion. our analysis (in particular equation [7]) highlights that there is always \\na negative displacement eff  ect on labor resulting from automation. equa-tion (11) reiterates that there is no presumption that this displacement eff  ect \\ncould not reduce overall demand for labor.\\nhowever, several countervailing eff  ects imply that a negative impact from \\nautomation on labor demand is not a forgone conclusion. most important, the productivity eff  ect could outweigh the displacement eff  ect, leading to an expansion in labor demand and equilibrium wages from automation. the \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 1 9\\npresence of the productivity eff  ect as counterweight to the displacement \\ncreated by automation highlights an important conceptual issue, however. \\nin contrast to the emphasis in the popular discussions it is not the brilliant, superproductive automation technologies that threaten labor, but the “so- so” ones that create the displacement eff  ect as they replace labor in tasks \\nthat it previously performed, but do not engender the countervailing pro-ductivity eff  ect.\\nthe productivity eff  ect is supplemented by the capital accumulation \\nthat automation sets in motion and the deepening of automation, which increases the productivity of machines in tasks that have already been auto-mated. but even with these countervailing eff  ects, equation (9) shows that \\nautomation will always reduce the share of labor in national income. all the same, this does not signal the demise of labor either, because the creation of new tasks in which labor has a comparative advantage could counterbal-ance automation, which is our interpretation of why the demand for labor has kept up with\\xa0productivity growth in the past despite several rapid waves of automation.\\nour framework suggests that the biggest shortcoming of the alarmist \\nand the optimist views is their failure to recognize that the future of labor depends on the balance between automation and the creation of new tasks. automation will often lead to a healthy growth of labor demand and wages if it is accompanied with a commensurate increase in the set of tasks in which labor has a comparative advantage—a feature that alarmists seem to ignore. even though there are good economic reasons for why the economy will create new tasks, this is neither a forgone conclusion nor something we can always count on—as the optimists seem to assume. artiﬁ  cial intel-\\nligence and robotics could be\\xa0permanently altering this balance, causing automation to pace ahead of the creation of new tasks with negative conse-quences for labor, at the very least in regard to the share of labor in national income.\\n8.4.7 generalizations\\nmany of the features adopted in the previous subsection are expositional \\nsimpliﬁ  cations. in particular, the aggregate production function (1) can be \\ntaken to be any constant elasticity of substitution aggregate. one impli-\\ncation of this would be that aggregate output in equation (3) would be a constant elasticity aggregate itself. this does not aff  ect any of our main conclusions, including the negative impact of automation on the labor share (see acemoglu and restrepo 2016).\\n10\\nwe also do not need assumption (a1) for any of the results. if the second \\n10. recent work by aghion, jones, and jones (2017) points out, however, that if the elastic-\\nity of substitution between tasks is less than one and there is an exogenous and high saving \\nrate, the\\xa0labor share might asymptote to a positive value even with continuously ongoing auto mation.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '220    daron acemoglu and pascual restrepo\\ninequality in this assumption does not hold, changes in automation tech-\\nnology have no impact on the equilibrium because it is not cost eff  ective to \\nadopt all available automation technologies (for this reason, in the general case, acemoglu and restrepo [2016] distinguish technologically automated tasks from equilibrium automation). given our focus here, there is no loss of generality in making this assumption.\\na ﬁ nal feature that is worth commenting on is the fact that in the aggregate \\nproduction function (1), the limits of integration are n – 1 and n, ensuring \\nthat the total measure of tasks is one. this is useful for several reasons. first, when the introduction of new tasks expands the total measure of tasks, it becomes more challenging to obtain a balanced growth path (see acemoglu and restrepo 2016). second, in this case some minor modiﬁ  cations are nec-essary so that an expansion in the total measure of tasks leads to productiv-ity improvements. in particular, consider the general case where the elastic-ity of substitution between tasks is not necessarily equal to one. if it is greater than one, an increase in n leads to higher productivity, but not nec-essarily when it is less than or equal to one. in this latter case, we then need to introduce direct productivity gains from task variety. for example, in the\\xa0present case where the elasticity of substitution between tasks is equal to one, we could modify (1) to ln y = (1/ n)\\n0nln[n1+/h9251y(i)], where /h9251  ≥ 0 \\nrepresents these productivity gains from task variety and ensures that the qualitative results explicit here continue to apply.\\n8.4.8 employment and unemployment\\nan additional generalization concerns the endogenous adjustment of \\nemployment in the face of new automation technologies. we have so far \\ntaken labor to be supplied inelastically for simplicity. there are two ways in which the level of employment responds to the arrival of new technologies. the ﬁ  rst is via a standard labor supply margin. acemoglu and restrepo \\n(2016) show that the endogenous adjustment of labor supply, including income eff  ects and the substitution of consumption and leisure, links the \\nlevel of employment to the share of labor in national income.\\nthe second possibility is through labor market frictions, for example, as \\nin acemoglu and restrepo (2018a). under appropriate assumptions, the endogenous level of employment in this case is also a function of the share of labor in national income. though both models with and without labor market frictions endogenize employment as a function of the labor share, their normative implications are potentially diff  erent, as we discuss below.\\nfor now, however, the more important implication of such extensions \\nis to link the level of employment (or unemployment) to labor demand. automation, when it reduces labor demand, will also reduce the level of employment (or increase the level of unemployment). moreover, because the supply of labor depends on the labor share, in our framework automation results in a reduction in employment (or an increase in unemployment). as such, our analysis so far also sheds light on (and clariﬁ  es the conditions for) \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 2 1\\nthe claims that new automation technologies will reduce employment. it also \\nhighlights, however, that the fact that automation has been ongoing does not condemn the economy to a declining path of employment. if automation is met by equivalent changes in the creation of new tasks, the share of labor in national income can remain stable and ensure a stable level of employment (or unemployment) in the economy.\\n8.5 constraints and ineffi   ciencies\\neven in the presence of the countervailing forces limiting the displace-\\nment eff  ect from automation, there are potential ineffi   ciencies and con-\\nstraints limiting the smooth adjustment of the labor market and hindering \\nthe productivity gains from new technologies.\\nhere we focus on how the mismatch between skills and technologies not \\nonly increases inequality, but also hinders the productivity gains from auto-mation and new tasks. we then explore the possibility that, concurrent with rapid automation, we are experiencing a slowdown in the creation of new tasks, which could result in slow productivity growth. finally, we examine how a range of factors leads to excessive automation, which not only creates ineffi  ciency but also hinders productivity.\\n8.5.1 mismatch of technologies and skills\\nthe emphasis on the creation of new tasks counterbalancing the potential \\nnegative eff  ects of automation on the labor share and the demand for labor ignores an important caveat and constraint: the potential mismatch between the requirements of new technologies (tasks) and the skills of the workforce. to the extent that new tasks require skilled employees or even new skills to be acquired, the adjustment may be much slower than our analysis so far suggests.\\nto illustrate these ideas in the simplest possible fashion, we follow acemo-\\nglu and restrepo (2016) and assume that there are two types of workers, low- skill with supply l and high- skill with supply h , both of them sup-\\nplied inelastically. we also assume that low- skill workers can only perform tasks below a threshold s ∈ (i,n), while high- skill workers can perform \\nall tasks. for simplicity, we assume that the productivity of both low- skill and high- skill workers in the tasks that they can perform is still given by /h9253\\nl(x).11 low- skill workers earn a wage wl and high- skill workers earn a \\nwage wh.\\n11. we can also introduce diff  erential comparative advantages and also an absolute produc-\\ntivity advantage for high- skill workers, though we choose not to do so to increase transparency \\n(see acemoglu and restrepo 2016). the more restrictive assumption here is that automation happens at the bottom of the range of tasks. in general, automation could take place in the middle range, and its impact would depend on whether automated tasks are competing pre-dominantly against low- skill or high- skill workers (see acemoglu and autor 2011; acemoglu and restrepo 2018b).\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '222    daron acemoglu and pascual restrepo\\nin this simple extension of the framework presented so far, the threshold \\ns can be considered as an inverse measure of the mismatch between new \\ntechnologies and skills. a greater value of s implies that there are plenty of additional tasks for low- skill workers, while a low value of s implies the presence of only a few tasks left that low- skill workers can perform.\\nassuming that in equilibrium w\\nh > wl,12 which implies that low- skill \\nworkers will perform all tasks in the range (i,s), equilibrium wages satisfy\\n wh=y\\nh(ns)a n d  wl=y\\nl(si).\\nthus, the impact of automation on inequality—deﬁ  ned here as the wage \\npremium between high- and low- skill workers—is given by\\n dlnwh/wl\\ndi=1\\nsi>0.\\nthis equation shows that automation increases inequality. this is not sur-\\nprising, since the tasks that are automated are precisely those performed by low- skill workers. but in addition, it also demonstrates that the impact of automation on inequality becomes worse when there is a severe skill mis-match—the threshold s is close to i. in this case, displaced workers will be squeezed into a very small range of tasks, and hence, each of these tasks will receive a large number of workers and will experience a substantial drop in price, which translates into a sharp decline in the wage of low- skill workers. in contrast, when s is large, displaced workers can spread across a larger set of tasks without depressing their wage as much.\\na severe mismatch also aff  ects the productivity gains from automation. \\nin particular, we have\\n dlny/l\\n()\\ndi=lnwl\\nl(i)lnr\\nm(i)>0.\\nthis equation shows that the productivity gains from automation depend \\npositively on wl/r: it is precisely when displaced workers have a high oppor-\\ntunity cost that automation raises productivity. using the fact that r = \\n(y/ k)(i – n + 1), we obtain\\n wl\\nr=si\\nin+1k\\nl.\\na worse mismatch (a lower s) reduces the opportunity cost of displaced \\nworkers further, and via this channel, it makes automation less proﬁ  table. \\nthis is because a severe mismatch impedes reallocation, reducing the pro-\\nductivity gains of freeing workers from automated tasks.\\n12. this is equivalent to [(n – s)/ (s – i)] > (h/ l), so that high- skill workers are scarce relative \\nto the range of tasks that only they can produce.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 2 3\\nequally important are the implications of a skill mismatch for the pro-\\nductivity gains from new tasks. namely,\\n dln(y/l)\\ndn=lnr\\nm(ni)lnwh\\nh(n)>0,\\nwhich depends negatively on wh/r: it is precisely when high- skill workers \\nhave a relatively high wage that the gains from new tasks will be limited. with \\nsimilar arguments to before, we also have\\n wh\\nr=ns\\nin+1k\\nl,\\nwhich implies that in the presence of a worse mismatch (a lower s), the \\nproductivity gains from new tasks will be limited. this is because new tasks \\nrequire high- skill workers who are scarce and expensive when s is low.\\nan important implication of this analysis is that to limit increasing \\ninequality and to best deploy new tasks and harness the beneﬁ  ts of auto-mation, society may need to simultaneously increase the supply of skills. a balanced growth process requires not only automation and the creation of new tasks to go hand- in-hand, but also the supply of high- skill workers to grow in tandem with these technological trends.\\n8.5.2 automation at the expense of new tasks\\nas discussed in section 8.2, a puzzling aspect of recent macroeconomic \\ndevelopments has been the lack of robust productivity growth despite the \\nbewildering array of new technologies. our conceptual framework provides three novel (and at least to us, more compelling) reasons for slow produc-tivity growth. the ﬁ  rst was the skill mismatch discussed in the previous subsection.\\nthe second one, discussed in this subsection, is that concurrent with the \\nrapid introduction of new automation technologies, we may be experiencing a slowdown in the creation of new tasks and investments in other technolo-gies that beneﬁ  t labor.\\nthis explanation comes in two ﬂ  avors. first, we may be running out of \\ngood ideas to create new jobs, sectors, and products capable of expanding the demand for labor (e.g., gordon 2016; bloom et\\xa0al. 2017), even if auto-mation continues at a healthy or accelerating pace. alternatively, the rapid introduction of new automation technologies may redirect resources that were devoted to other technological advances, in particular, the creation of new tasks (see acemoglu and restrepo 2016). to the extent that the recent enthusiasm—or even “frenzy”—about deep learning and some aspects of ai can be viewed as such a redirection, our framework pinpoints a potential powerful mechanism for slower productivity growth in the face of rapid automation.\\nboth explanations hinge on the redirection of research activity from the \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '224    daron acemoglu and pascual restrepo\\ncreation of new tasks to automation—in the ﬁ  rst case exogenously and in \\nthe second for endogenous reasons. recall from our analysis so far that the productivity gains from new tasks in our baseline framework are given by\\n dln(y/l)\\ndn=lnr\\nm(n1)lnw\\nl(n)>0,\\nwhile productivity gains from automation are dln(y/l)\\ndi\\n=lnw\\nl(i)lnr\\nm(i)>0.\\nif the former expression is greater than the latter, then the redirection of \\nresearch eff  ort from the creation of new tasks toward automation, or a lower \\nresearch effi   ciency in creating new tasks, will lead to a slowdown of produc-tivity growth, even if advances in automation are accelerating and being adopted enthusiastically. this conclusion is strengthened if additional eff  ort \\ndevoted to automation at the expense of the creation of new tasks runs into diminishing returns.\\n8.5.3 excessive automation\\nin this subsection, we highlight the third reason for why there may be \\nmodest productivity growth: socially excessive automation (see acemoglu \\nand restrepo 2016, 2018a).\\nto illustrate why our framework can generate excessive automation, we \\nmodify the assumption that the supply of capital, k, is given, and instead suppose that machines used in automation are produced—as intermediate goods—using the ﬁ  nal good at a ﬁ  xed cost r. moreover, suppose that be-\\ncause of subsidies to capital, accelerated depreciation allowances, tax credit for debt- ﬁ  nanced investment or simply because of the tax cost of employing workers, capital receives a marginal subsidy of τ > 0.\\ngiven this subsidy, the rental rate for machines is r(1 – τ), and assump-\\ntion (a1) now becomes\\n \\nl(n)\\nm(n1)>w\\nr(1 )>l(i)\\nm(i).\\nlet us now compute gdp as value added, subtracting the cost of produc-\\ning machines. this gives us\\n gdp=yrk.\\nsuppose next that there is an increase in automation. then we have\\n dgdp\\ndi=dy\\ndik+r(1 )dk\\ndirdk\\ndi,\\nwhich simpliﬁ  es to\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 2 5\\n dgdp\\ndi=lnw\\nli()lnr1()\\nmi()\\nproductivity effect>0rdk\\ndi\\nexcessive automation<0.\\nthe ﬁ  rst term is positive and captures the productivity increase generated by \\nautomation. however, when τ > 0—so that the real cost of using capital is distorted—we have an additional negative eff  ect originating from excessive automation.\\n13 at the root of this negative eff  ect is the fact that subsidies \\ninduce ﬁ  rms to substitute capital for labor even when this is not socially cost- saving (though it is privately beneﬁ  cial because of the subsidy).\\nthis conclusion is further strengthened when there are also labor market \\nfrictions as pointed out in section 8.2. to illustrate this point in the simplest possible fashion, let us assume that there is a threshold j ∈(i,n ) such that, \\nwhen performing the tasks in [i,j ], workers earn rents /h9275 > 0 proportional \\nto their wage in other tasks. in particular, workers are paid a wage w  to \\nproduce tasks in [j,n ], and a wage w(1 + /h9275) to produce tasks in (i,j).\\n14 let \\nla denote the total amount of labor allocated to the tasks in (i,j ), and note \\nthat these are the workers that will be displaced by automation, that is, by a small increase in i. given this additional distortion, assumption (a1) now becomes\\n \\nl(n)\\nm(n1)>w\\nr(1 )>1\\n1+l(i)\\nm(i).\\nthe demand for labor in tasks where workers earn rents is now\\n la=y\\nw(1+)(ji).\\nthe demand for labor in tasks where workers do not earn rents is \\nlla=y\\nw(nj).\\ndividing these two expressions, we obtain the equilibrium condition for la,\\n la\\nlla=1\\n1+ji\\nnj,\\n13. we show in the appendix that k = (y/ r)(i – n + 1), which implies that k increases in i.\\n14. the assumption that there are rents only in a subset of tasks is adopted for simplic-\\nity. the same results apply (a) when there are two sectors and one of the sectors has higher \\nrents/ wages for workers and enables automation and (b) there is an endogenous margin between employment and nonemployment and labor market imperfections (such as search, bargaining, or effi   ciency wages) that create a wedge between wages and outside options. in both cases the automation decisions of ﬁ  rms fail to internalize the gap between the market wage and the\\xa0opportunity cost of labor, leading to excessive automation (see acemoglu and restrepo 2018a).\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '226    daron acemoglu and pascual restrepo\\nwhich implies that the total number of workers earning rents declines with \\nautomation.\\nmoreover, the appendix shows that (gross) output is now given by\\n(12) y=bk\\nin+1in+1la\\njijilla\\nnjnj\\n,\\nand gdp is still given by y – rk. equation (12) highlights that there is now a misallocation of labor across tasks—output can be increased by allocating more workers to tasks (i,j ) where their marginal product is greater (because \\nof the rents they are earning).\\nequation (12) further implies that the impact of automation on gdp is \\ngiven by\\n dgdp\\ndi\\n=lnw(1+)\\nl(i)lnr(1 )\\nm(i)\\nproductivity effect>0rdk\\ndi\\nexcessive \\nautomation<0+ wdla\\ndi\\nexcessive displacement\\n of labor<0.\\nthe new term w /h9275(dla/di) captures the ﬁ  rst- order losses from a decline in \\nemployment in tasks (i,j ). these losses arise because by automating jobs \\nwhere workers earn rents, ﬁ  rms are eff  ectively displacing workers to other \\ntasks in which they have a lower marginal product and earn a strictly lower wage, which increases the extent of misallocation.\\nthe point highlighted here is much more general. without labor market \\nfrictions, automation increases gdp (and net output), so at the very least it is possible to redistribute the gains that it creates to make workers—of diff erent skill levels—better off  . labor market frictions change this picture. \\nin\\xa0the presence of such frictions, ﬁ  rms’ automation decisions do not inter-nalize the fact that the marginal product of labor is above its opportunity cost, or equivalently, do not recognize that there are ﬁ  rst- order losses that \\nworkers will suff  er as a result of automation. consequently, equilibrium \\nautomation could reduce gdp and welfare and there may not be a way to make (all) workers better off  , even with tools for costless redistribution. under these circumstances, a utilitarian planner would choose a lower level of automation than the equilibrium.\\n15\\n8.6 concluding remarks\\ndespite the growing concerns and intensifying debate about the implica-\\ntions of automation for the future of work, the economics profession and popular discussions lack a satisfactory conceptual framework. to us this \\n15. naturally, if the planner could remove the rents, or the labor market frictions underpin-\\nning them, then the equilibrium would be restored to effi   ciency. nevertheless, most sources of \\nrents, including search, bargaining, and effi   ciency wages, would be present in the constrained effi  cient allocations as well.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 2 7\\nlack of appropriate conceptual approach is also the key reason why much \\nof the debate is characterized by a false dichotomy between the view that automation will spell the end of work for humans and the argument that technologies will always tend to increase the demand for labor as they have done in the past.\\nin this chapter, we summarized a conceptual framework that can help \\nunderstand the implications of automation and bridge the opposite sides of this false dichotomy. at the center of our framework is a task- based approach, where automation is conceptualized as replacing labor in tasks that it used to perform. this type of replacement causes a direct displace-ment eff  ect, reducing labor demand. if this displacement eff  ect is not coun-terbalanced by other economic forces, it will reduce labor demand, wages, and employment. but our framework also emphasizes that there are several countervailing forces. these include the fact that automation will reduce the costs of production and thus create a productivity eff  ect, the induced capital accumulation, and the deepening of automation—technological advances that increase the productivity of machines in tasks that have already been automated.\\nour framework also emphasizes that these countervailing forces are gen-\\nerally insuffi   cient to totally balance out the implications of automation. in particular, even if these forces are strong, the displacement eff  ect of automa-tion tends to cause a decline in the share of labor in national income. but we know from the history of technology and industrial development that despite several waves of rapid automation, the growth process has been more or less balanced, with no secular downward trend in the share of labor in national income. we argue this is because of another powerful force: the creation of new tasks in which labor has a comparative advantage, which fosters a countervailing reinstatement eff  ect for labor. these tasks increase the demand for labor and tend to raise the labor share. when they go hand- in-hand with automation, the growth process is balanced and it need not imply a dismal scenario for labor.\\nnevertheless, the adjustment process is likely to be slower and more pain-\\nful than this account of balance between automation and new tasks at ﬁ  rst \\nsuggests. this is because the reallocation of labor from its existing jobs and tasks to new ones is a slow process, in part owing to time- consuming search and other labor market imperfections. but even more ominously, new tasks require new skills. when the education sector does not keep up with the demand for new skills, the mismatch between skills and technologies is bound to complicate the adjustment process and hinder the productivity gains from new technologies.\\nour framework further suggests that there are additional reasons for the \\nproductivity slowdown. at the center of these is a tendency for excessive automation because of the tax treatment of capital investments and labor market imperfections. excessive automation directly reduces productivity, \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '228    daron acemoglu and pascual restrepo\\nbut may have even more powerful indirect eff  ects because it redirects tech-\\nnological improvements away from productivity- enhancing activities that \\nlead to the creation of new tasks to excessive eff  orts at the extensive margin of automation, a picture that receives informal support from the current singular focus on ai and deep learning.\\nwe would like to conclude by pointing out a number of additional issues \\nthat may be important in understanding the full impact of ai and other auto-mation technologies on future prospects of labor. we believe that these issues can be studied using simple extensions of the framework presented here.\\nfirst, we have emphasized the role of the productivity eff  ect in partially \\ncounterbalancing the displacement eff  ect created by automation. however, this countervailing eff  ect works by increasing the demand for products. as we have also seen, automation tends to increase inequality. if, as a conse-quence of this distributional impact, the rise in real incomes resulting from automation ends up in the hands of a narrow segment of the population with much lower marginal propensity to consume than those losing incomes and their jobs, these countervailing forces would be weakened and might operate much more slowly. this imbalance in the distribution of the gains from automation might slow down the creation of new tasks as well.\\nsecond, our analysis highlighted the negative consequences of a short-\\nage of skills for realizing the productivity gains from automation and for inequality. in practice, the problem may be workers acquiring the wrong types of skills rather than a general lack of skills. for example, if ai and other new automation technologies necessitate a mix of numeracy, com-munication, and problem- solving skills diff  erent than those emphasized in current curricula, this would have implications similar to those of a shortage of skills, but it cannot be overcome by just increasing educational spending with current educational practices remaining intact. one important con-sideration in this respect is that there is little concrete information about what types of skills new technologies will complement, underscoring the importance of further empirical work in this area.\\nthird, government policies and labor market institutions may impact not \\njust the speed of automation (and thus whether there is excessive auto-mation), but what types of technologies will receive more investments. to the extent that some uses of ai may complement labor more or generate opportunities for more rapid creation of new tasks, an understanding of the impact of various policies, including support for academic and applied research, and social factors on the path of development of ai is critical.\\nlast but not least, the development and adoption of technologies that re-\\ninstate labor cannot be taken for granted. if we do not ﬁ  nd a way of creating shared prosperity from the productivity gains generated by new technolo-gies, there is a danger that the political reaction to these technologies may slow down or even completely stop their adoption and development. this \\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 2 9\\nunderscores the importance of studying the distributional implications of \\nai and robotics, the political economy reactions to it, and the design of new and improved institutions for creating more broadly shared gains from these new technologies.\\nappendix\\nderivations for the basic model\\nsuppose that assumption (a1) holds. we ﬁ  rst derive the demand for \\n factors:\\n• denote by p(x) the price of task x. assumption (a1) implies\\n(8a.1) p(x)=r\\nm(x)ifx n1,i\\nw\\nl(x)ifxi,n( .\\n• in addition, the demand for task x is given by\\n y(x)=y\\np(x).\\n• thus, the demand for smart machines in task x is\\n k(x)=y\\nrifx n1,i\\n0i f xi,n(,\\nand the demand for labor in task x is\\n (x)=0i f x n1,i\\ny\\nwifxi,n(.\\n•  aggregating the demand for machines from this expression and set-\\nting it equal to the supply of capital, k, we have the following market- \\nclearing condition for capital:\\n k=y\\nr(in+1).\\nsimilarly, aggregating the demand for labor and setting it equal to its inelas-tic supply, l, we obtain the market- clearing condition for labor as\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '230    daron acemoglu and pascual restrepo\\n l=y\\nw(ni).\\n•  rearranging these two equations, the equilibrium rental rate and wage \\ncan be obtained as\\n(8a.2) r=y\\nk(in+1) and w=y\\nl(ni),\\nwhich are the expressions used in the text.\\nwe next turn to deriving the expression for aggregate output.\\n•  because we normalized the price of the ﬁ  nal good to 1 as numeraire, \\nwe have\\n \\nn1n\\nlnp(x)dx=0.\\n• plugging in the expressions for p(x) from equation (8a.1) yields\\n \\nn1i\\nlnrlnm(x)dx+\\nin\\nlnw lnl(x)dx=0.\\n• substituting the expressions for r and w from (8a.2), we obtain\\n \\nn1i\\nlnylnk/(in+1)() lnm(x)dx\\n +\\nin\\nlnylnl/(ni)() lnl(x)dx=0.\\n• this equation can be rearranged as\\n lny=\\nn1i\\nlnk\\nin+1+lnm(x)dx+\\nin\\nlnl\\nn1+lnl(x)dx\\n =\\nn1i\\nlnm(x)dx+\\nin\\nlnl(x)dx\\n +(in+1)lnk\\nin+1+(ni)lnl\\nni,\\nwhich, after taking exponentials on both sides of the equation, yields the \\nexpression for aggregate output in equation (1) in the text.\\nassumption (a1)\\nwe now show that assumption (a1) is equivalent to the capital- labor ratio \\nof the economy taking an intermediate value. in particular, there exist two \\npositive thresholds < such that assumption (a1) holds whenever\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 3 1\\n(a2) k\\nl(,).\\nequation (8a.2) shows that\\n w\\nr=k\\nlni\\nin+1.\\ndeﬁ ne\\n =in+1\\nnil(i)\\nm(i),an d=in+1\\nnil(n)\\nm(ni).\\nthen equation (a2) is equivalent to assumption (a1).\\nderivations in the presence of technology- skill mismatch\\n•  denote by p(x) the price of task x. assumption (a1) together with the \\nfact that wh > wl (see footnote 12) implies\\n p(x)=r\\nm(x)ifx n1,i\\nwl\\nl(x)ifx(i,s)\\nwh\\nl(x)ifxs,n].\\n•  following the same steps as in our baseline model, we obtain the \\nmarket- clearing condition for capital,\\n k=y\\nr(in+1).\\n• the demand for low- skill labor in task x is given by\\n (x)=0i f x n1,i\\ny\\nwlifx(i,s)\\n0i f xs,n]..\\n•  aggregating the demand for low- skill labor and setting it equal to its \\ninelastic supply, l, we obtain the market- clearing condition for low- \\nskill labor as\\n l=y\\nwl(si),\\nwhich implies the expression for wl given in the main text.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '232    daron acemoglu and pascual restrepo\\n• the demand for high- skill labor in task x is given by\\n h(x)=0i f x n1,i\\n0i f x(i,s)\\ny\\nwhifxs,n]..\\n•  aggregating the demand for high- skill labor and setting it equal to \\nits supply, h , we obtain the market- clearing condition for high- skill \\nlabor as\\n h=y\\nwh(ns),\\nwhich implies the expression for wh given in the main text.\\nderivations for the model with distortions\\n•  denote by p(x) the price of task x. the variant of assumption (a1) \\nintroduced in section 8.5 implies\\n p(x)=r(1 )\\nm(x)ifx n1,i\\nw(1+)\\nl(x)ifx(i,j)\\nw\\nl(x)ifxj,n].\\n•  following the same steps as in the model with no distortions, we obtain \\nthe market- clearing condition for capital,\\n k=y\\nr(1 )(in+1).\\n•  the demand for labor in task x is\\n (x)=0i f x n1,i\\ny\\nw(1+)ifx(i,j)\\ny\\nwifxj,n].\\n•  the expression for ℓ(x) implies that the total amount of labor employed \\nin tasks where labor gets rents is\\n la=y\\nw(1+)(ji).\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 3 3\\nthe total amount of labor employed in tasks where labor does not get rents is\\n lla=y\\nw(nj).\\nto derive the expression for (gross) output we proceed as follows:\\n• again from our choice of numeraire, we have\\n \\nn1n\\nlnp(x)dx=0.\\n• plugging in the expressions for p(x) we obtain\\n \\nn1i\\nlnrlnm(x)dx+\\nij\\nlnw+ln(1+)lnl(x)dx\\n +\\njn\\nlnw lnl(x)dx=0.\\n•  substituting for factor prices using the expressions for k, la, and \\nl – la, we obtain\\n \\nn1i\\nlnylnk/(in+1)() lnm(x)dx\\n +\\nij\\nlnylnla/(ji)() lnl(x)dx\\n +\\nij\\nlnyln (lla)/(nj) () lnl(x)dx=0.\\n• this equation can be rearranged as\\n lny=\\nn1i\\nlnk\\nin+1+lnm(x)dx+\\nij\\nlnla\\nji+lnl(x)dx\\n +\\njn\\nlnl\\nnj+lnl(x)dx\\n =\\nn1i\\nlnm(x)dx+\\nin\\nlnl(x)dx+(in+1)lnk\\nin+1\\n +(ji)lnla\\nji+(nj)lnlla\\nnj,\\nwhich yields equation (12) in the text.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '234    daron acemoglu and pascual restrepo\\nreferences\\naccenture plc. 2017. “how companies are reimagining business processes \\nwith it.” https:// sloanreview.mit .edu/ article/ will- ai- create- as-many- jobs- as-it\\n- eliminates/.\\nacemoglu, daron. 2009. introduction to modern economic growth. princeton, nj: \\nprinceton university press.\\nacemoglu, daron, and david autor. 2011. “skills, tasks and technologies: implica-\\ntions for employment and earnings.” handbook of labor economics 4:1043– 171.\\nacemoglu, daron, david autor, david dorn, gordon h. hanson, and brendan \\nprice. 2014. “return of the solow paradox? it, productivity, and employment in us manufacturing.” american economic review: papers & proceedings  104 \\n(5): 394– 99.\\nacemoglu, daron, and pascual restrepo. 2016. “the race between machine and \\nman: implications of technology for growth, factor shares and employment.” american economic review 108 (6): 1488– 542.\\n———. 2017. “robots and jobs: evidence from us labor markets.” nber work-\\ning paper no. 23285, cambridge, ma.\\n———. 2018a. “excessive automation: technology adoption and worker displace-\\nment in a frictional world.” unpublished manuscript.\\n———. 2018b. “low- skill and high- skill automation.” journal of human capital \\n12 (2): 204– 32.\\naghion, philippe, benjamin f . jones, and charles i. jones. 2017. “artiﬁ  cial intelli-\\ngence and economic growth.” nber working paper no. 23928, cambridge, ma.\\nallen, robert c. 2009. “engels’ pause: technical change, capital accumulation, \\nand inequality in the british industrial revolution.” explorations in economic \\nhistory 46 (4): 418– 35.\\namerican enterprise institute (aei). 2008. “taxing capital.” report by the \\namerican enterprise institute. https:// www .aei .org.\\nautor, david h. 2015. “why are there still so many jobs? the history and future \\nof workplace automation.” journal of economic perspectives 29 (3): 3– 30.\\nautor, david h., david dorn, and gordon h. hanson. 2013. “the china syn-\\ndrome: local labor market eff  ects of import competition in the united states.” american economic review 103 (6): 2121– 68.\\nautor, david h., frank levy, and richard j. murnane. 2003. “the skill content of \\nrecent technological change: an empirical exploration.” quarterly journal of economics 118 (4): 1279– 333.\\nayres, robert, and steven m. miller. 1983. robotics: applications and social implica-\\ntions. pensacola, fl: ballinger publishing company.\\nbessen, james. 2016. learning by doing: the real connection between innovation, \\nwages, and wealth. new haven, ct: yale university press.\\nbloom, nicholas, charles i. jones, john van reenen, and michael webb. 2017. \\n“are\\xa0ideas getting harder to find?” nber working paper no. 23782, cam-bridge, ma.\\nboston consulting group. 2015. “the robotics revolution: the next great \\nleap in manufacturing.” https:// www .bcg .com/ en- us/ publications/ 2015/ lean- manufacturing- innovation- robotics- revolution- next- great- leap- manufacturing .aspx.\\nbrynjolfsson, erik, and andrew mcafee. 2014. the second machine age: work, \\nprogress, and prosperity in a time of brilliant technologies . new y ork: w . w . \\nnorton & company.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " 'artiﬁ  cial intelligence, automation, and work    2 3 5\\nchandler, alfred d. 1977. the visible hand: the managerial revolution in american \\nbusiness. cambridge, ma: harvard university press.\\ndeloitte and the manufacturing institute. 2011. “boiling point? the skills gap \\nin u.s. manufacturing.” report. http:// www .themanufacturinginstitute .org/ ~\\n/ media/ a07730b2a798437d98501e798c2e13aa.ashx.\\nford, martin. 2016. the rise of the robots: technology and the threat of a jobless \\nfuture. new y ork: basic books.\\ngoldin, claudia, and larry katz. 2010. the race between education and technology . \\ncambridge, ma: harvard university press.\\ngordon, robert j. 2016. the rise and fall of american growth: the u.s. standard \\nof living since the civil war. princeton, nj: princeton university press.\\ngraetz, georg, and guy michaels. 2015. “robots at work.” cep discussion paper \\nno. 1335, centre for economic performance.\\ngroover, mikell. 1983. cad/ cam: computer- aided design and manufacturing . \\nenglewood cliff  s, nj: prentice hall.\\ngroover, mikell, mitchell weiss, roger n. nagel, and nicholas g. odrey. 1986. \\nindustrial robotics: technology, programming and applications. new y ork: mcgraw- hill.\\nherrendorf, berthold, richard rogerson, and ákos valentinyi. 2013. “two perspec-\\ntives on preferences and structural transformation.” american economic review \\n103 (7): 2752– 89.\\nkolb, david a. 1984. experiential learning: experience as the source of learning \\nand development. englewood cliff  s, nj: prentice hall.\\nkuznets, simon. 1966. modern economic growth. new haven, ct: yale university \\npress.\\nlandes, david. 1969. the unbound prometheus. new y ork: cambridge university \\npress.\\nmantoux, paul. 1928. the industrial revolution in the eighteenth century: an outline \\nof the beginnings of the modern factory system in england. new y ork: harcourt.\\nmanuelli, rodolfo e., and ananth seshadri. 2014. “frictionless technology diff  u-\\nsion: the case of tractors.” american economic review 104 (4): 1368– 91.\\nmckinsey global institute. 2017. “jobs lost, jobs gained: workforce transitions \\nin a time of automation.” report, mckinsey & company. https:// www .mckinsey\\n .com/ mgi/ overview/ 2017-in-review/ automation- and- the- future- of-work/ jobs- lost- jobs- gained- workforce- transitions- in-a- time- of-automation.\\nmian, atif, and amir suﬁ  . 2014. “what explains the 2007– 2009 drop in employ-\\nment?” econometrica 82 (6): 2197– 223.\\nminsky, marvin. 1967. computation: finite and inﬁ  nite machines. englewood cliff  s, \\nnj: prentice- hall.\\nmokyr, joel. 1990. the lever of riches: technological creativity and economic pro-\\ngress. new y ork: oxford university press.\\nnilsson, nils j. 2009. the quest for artiﬁ  cial intelligence: a history of ideas and \\nachievements. cambridge: cambridge university press.\\nolmstead, alan l., and paul w . rhode. 2001. “reshaping the landscape: the \\nimpact and diff  usion of the tractor in american agriculture, 1910– 1960.” jour-nal of economic history 61 (3): 663– 98.\\npew research center. 2017. “automation in everyday life.” online report. http:// \\nwww .pewinternet .org/ 2017/ 10/ 04/ automation- in-everyday- life/.\\nrasmussen, wayne d. 1982. “the mechanization of agriculture.” scientiﬁ  c \\namerican 247 (3): 76– 89.\\nsimon, herbert a. 1965. the shape of automation for men and management. new \\ny ork: harper & row.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " '236    daron acemoglu and pascual restrepo\\nsyverson, chad. 2017. “challenges to mismeasurement explanations for the us \\nproductivity slowdown.” journal of economic perspectives 31 (2): 165– 86.\\ntuzel, selale, and miao ben zhang. 2017. “economic stimulus at the expense of \\nroutine- task jobs.” unpublished manuscript, marshall school of business, uni-\\nversity of southern california.\\nzeira, joseph. 1998. “workers, machines, and economic growth.” quarterly journal \\nof economics 113 (4): 1091– 117.\\nyou are reading copyrighted material published by university of chicago press.  \\nunauthorized posting, copying, or distributing of this work except as permitted under \\nu.s. copyright law is illegal and injures the author and publisher.',\n",
       " \"received april 5, 2020, accepted april 14, 2020, date of publication april 17, 2020, date of current version may 5, 2020.\\ndigital object identifier 10.1 109/access.2020.2988510\\nartificial intelligence in education: a review\\nlijia chen1, pingping chen\\n2,4, (member, ieee), and zhijian lin\\n3, (member, ieee)\\n1school of design, yango university, fuzhou 350015, china\\n2school of advanced manufacturing, science park of fuzhou university, jinjiang 362251, china\\n3school of information, fuzhou university, fuzhou 35008, china\\ncorresponding author: pingping chen (ppchen.xm@gmail.com)\\nthis work was supported in part by the humanities and social science planning funds of fujian province under grant 275 jas19453, and\\nin part by the distinguished scholar grant of educational commission of fujian province.\\nabstract the purpose of this study was to assess the impact of arti\\x1ccial intelligence (ai) on education.\\npremised on a narrative and framework for assessing ai identi\\x1ced from a preliminary analysis, the scope\\nof the study was limited to the application and effects of ai in administration, instruction, and learning.\\na qualitative research approach, leveraging the use of literature review as a research design and approach\\nwas used and effectively facilitated the realization of the study purpose. arti\\x1ccial intelligence is a \\x1celd of\\nstudy and the resulting innovations and developments that have culminated in computers, machines, and\\nother artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability,\\nand decision-making capabilities. the study ascertained that ai has extensively been adopted and used in\\neducation, particularly by education institutions, in different forms. ai initially took the form of computer\\nand computer related technologies, transitioning to web-based and online intelligent education systems,\\nand ultimately with the use of embedded computer systems, together with other technologies, the use of\\nhumanoid robots and web-based chatbots to perform instructors' duties and functions independently or with\\ninstructors. using these platforms, instructors have been able to perform different administrative functions,\\nsuch as reviewing and grading students' assignments more effectively and ef\\x1cciently, and achieve higher\\nquality in their teaching activities. on the other hand, because the systems leverage machine learning and\\nadaptability, curriculum and content has been customized and personalized in line with students' needs,\\nwhich has fostered uptake and retention, thereby improving learners experience and overall quality of\\nlearning.\\nindex terms education, arti\\x1ccial intelligence, leaner.\\ni. introduction\\nas illustrated by henry ford in the analogy, innovation does\\nnot mean working that the society should work only with\\nwhat has been the norm, such as \\x1cnding ways of making\\nhorses faster. sometimes, it is necessary to search beyond\\nthe norm, develop new ways of doing things. instead of\\nmaking horses faster, build the automobile, which will be\\nfaster than the horse and take a person from point a to\\npoint b faster. these principles and approaches have driven\\nthe rapid developments in technology experienced over the\\nyears, particularly in the education sector.\\nthe year is 1950. dr. potter, a tenured professor at a local\\nuniversity shuf\\x1des to a class, a heavy load of papers under\\nhis arm. he has just marked all the papers, after reading\\nthe associate editor coordinating the review of this manuscript and\\napproving it for publication was xiaochun cheng.and assessing the grammar and content of each of the papers\\nhanded in by the 40 students in his class. going through some\\nof the papers, dr. potter felt that the content in there had been\\nplagiarized from other sources, but he had no sure way of\\nascertaining from where the student had copied the content\\nmaterials. fast forward, in 2019, dr. potter now walks into a\\nclass, barely carrying any papers, but having read, \\x1dagged\\nincidents of plagiarism for disciplinary action, and graded\\npapers for an even larger number of students. sometimes,\\nwhen he is off campus, he can dial-in or video conference\\ninto the class and can still perform his duties and responsibil-\\nities leveraging technology. the introduction, advancements,\\nand proliferation of technology, more particularly, arti\\x1ccial\\nintelligence, has made it easier for instructors to dispense\\ntheir duties more effectively and ef\\x1cciently. these techno-\\nlogical innovations have also permeated other sectors of the\\nacademia, fostering effectiveness and ef\\x1cciency.\\n75264this work is licensed under a creative commons attribution 4.0 license. for more information, see https://creativecommons.org/licenses/by/4.0/volume 8, 2020\",\n",
       " \"l. chen et al. : ai in education: a review\\nprior to the introduction of computers and other related\\ntechnologies, instructors and students, engaged in instruc-\\ntions and learning mechanically, or through the pure appli-\\ncation of natural human effort. with the introduction of\\nmicrocomputers, and by extension, personal computers in the\\n1970s, which according to flamm, provided more comput-\\ning power and marked an important transition to electronic\\ncomputers for the mass market [1]. in agreement, campbell-\\nkelly opined that with developments of the electronic com-\\nputers, more particularly, and the availability of the same for\\ndifferent entities across different sectors of the economy, was\\nprecipitated by the developments of personal computers in the\\n1970s [2]. personal computers development made it possible\\nfor individuals and other non-governmental entities to own\\nand use computers for different reasons. these transitions\\nharbingered the proliferation of computers in different sectors\\nof the economy and society.\\nleveraging earlier research into programmed instructions\\nfrom the mid-1900s, developments in computers and related\\ncomputing technologies saw the use of computers in differ-\\nent parts of the education sector, more speci\\x1ccally, different\\ndepartments in educational institutions, such as the develop-\\nment of computer aided instruction and learning (cai/l) in\\nclassroom interactions [3]. later developments in computers\\nand computer-related technologies, including networking, the\\ninternet, the world wide web, and increased processing, com-\\nputing, and other capabilities, including different programs\\nand software packages that are task oriented, have seen the\\nincreased application of computers in different ways in the\\neducation sector. more speci\\x1ccally, in different departments\\nin education institutions.\\ncomputer and information communication technologies\\nhave over the years continued to evolve, leading to the\\ndevelopment of arti\\x1ccial intelligence. arti\\x1ccial intelligence,\\naccording to coppin, is the ability of machines to adapt to\\nnew situations, deal with emerging situations, solve prob-\\nlems, answer questions, device plans, and perform various\\nother functions that require some level of intelligence typ-\\nically evident in human beings [4] (p.4). in another def-\\ninition, whitby de\\x1cned arti\\x1ccial intelligence as the study\\nof intelligence behavior in human beings, animals, and\\nmachines and endeavoring to engineer such behavior into an\\nartifact, such as computers and computer-related technolo-\\ngies [5] (p.1). drawing from these de\\x1cnitions, it is evident\\nthat arti\\x1ccial intelligence is the culmination of computers,\\ncomputer-related technologies, machines, and information\\ncommunication technology innovations and developments,\\ngiving computers the ability to perform near or human-like\\nfunctions. in line with the adoption and use of new tech-\\nnologies in education, arti\\x1ccial intelligence has also been\\nextensively leveraged in the education sector.\\nfor example, devedºi¢ observed that web intelligence\\n(wi) and arti\\x1ccial intelligence (ai) research and develop-\\nment focuses on different elements, including machine learn-\\ning to create distributed intelligence and creating a balance\\nbetween web technology and intelligent agent technology,agent self-organization, learning, and adaptation among other\\naspects of wi and ai that enable it to adapt to its environment\\nand perform intelligent functions, which should be leveraged\\nto foster improvements in the education sector [6] (p.29).\\nindeed, arti\\x1ccial intelligence has been adopted and perme-\\nated various areas of the education sector, or departments in\\neducational institutions. use of arti\\x1ccial intelligence in edu-\\ncation has had a major impact, including improved ef\\x1cciency,\\nglobal learning, customized/personalized learning, smarter\\ncontent, and improved effectiveness and ef\\x1cciency in educa-\\ntion administration among others [7]. arti\\x1ccial intelligence\\ncontinues to develop, and new ways of application in educa-\\ntion emerge.\\na. artificial intelligence in current education\\nthe mention of arti\\x1ccial intelligence brings to mind a super-\\ncomputer, a computer with immense processing capabilities,\\nincluding adaptive behavior, such as inclusion of sensors,\\nand other capabilities, that enable it to have human-like cog-\\nnition and functional abilities, and indeed, which improve\\nthe supercomputers interaction with human beings. indeed,\\ndifferent motion pictures have been made to showcase the\\nabilities of ai, such as in smart buildings, such as the ability to\\nmanage air quality in a building, temperatures, and or playing\\nmusic depending on the sensed mood of the occupants of the\\nspace. within the education sector, there has been increased\\napplication of arti\\x1ccial intelligence, going over and above\\nthe conventional understanding of ai as a supercomputer to\\ninclude embedded computer systems.\\nfor example, embedded into robots, ai, or computers\\nand supporting equipment enable the creation of robots that\\nimprove the learning experience of the student, from the\\nmost basic unit of education, early childhood education.\\nindeed, timms posited that cobots or the application of\\nrobots, working together with teachers or colleague robots\\n(cobots) are being applied to teach children routine tasks,\\nincluding spelling and pronunciation and adjusting to the stu-\\ndents' abilities [7]\\x15[9]. similarly, the web-based and online\\neducation, as enumerated in different studies, has transi-\\ntioned from simply availing materials online or on the web\\nfor students to simply download, study, and do assignments\\nto just pass, to include intelligent and adaptive web-based\\nsystems that learn instructor and learner behavior to adjust\\naccordingly, to enrich the educational experience [6], [11],\\n[18], [19]. arti\\x1ccial intelligence in education, according to\\nchassignol et al. has been incorporated into administration,\\ninstruction or teaching, and learning [11]. these areas, which\\nchassignol et al. identify as the framework for analyzing and\\nunderstanding arti\\x1ccial intelligence in education, will form\\nthe scope of this study.\\nthe application of ai algorithms and systems in education\\nare gaining increased interest year by year. fig. 1 shows\\nthe rising number of papers published in the topics ``ai''\\nand ``education'' from web of science and google scholar\\nsince 2010. note that the papers published in 2015-2019\\naccounted for a large proportion, i.e., 70% of all the papers\\nvolume 8, 2020 75265\",\n",
       " \"l. chen et al. : ai in education: a review\\nfigure 1. papers in web of science and google scholar in the last ten\\nyear with key words ``ai'' and ``education'' .\\nindexed. as education evolves, researchers are trying to apply\\nadvanced ai techniques, i.e., deep learning, data mining, to\\ndeal with complex issues and customize teaching method for\\nindividual student.\\nb. purpose of the study\\nwith the continued application or use of information tech-\\nnology, it is inevitable that it has impacted the education\\nin different ways. this study seeks to assess how the use\\nof ai, in its different forms, in education, has impacted or\\naffected different aspects of education. more particularly,\\nthe study will seek to assess how ai has affected teach-\\ning, learning, and administration and management areas of\\neducation. it is anticipated that the study will ascertain that\\nai has fostered effectiveness and ef\\x1cciency in the perfor-\\nmance of administrative tasks in education, and overall fos-\\ntered improved instructional and learning effectiveness in\\neducation.\\nthis study will bene\\x1ct various stakeholders in the edu-\\ncation sector. it will contribute to the growing study and\\ndevelopment of knowledge, theory, and empirical \\x1cndings\\nthat identify and discuss the different ways in which ai has\\naffected education. it will bene\\x1ct scholars, professionals, and\\npolicy makers, such as administrators, management and lead-\\nership of educational institutions and the education sector,\\nby fostering evidence-based decision-making and manage-\\nment and leadership practices in the sector. the \\x1cndings\\nwill also augment the \\x1cndings by other studies and inform\\ngovernment policy and actions aimed at fostering meaning-\\nful use of information technology, particularly, ai, in the\\neducation sector. for example, with an understanding of\\nthe impact of ai on education sector, and an evaluation of\\nthe exact nature of such impact, including improved instruc-\\ntional and learning effectiveness, the government, working\\nwith educational institutions can develop a policy, strat-\\negy, and initiatives that promote the bene\\x1ccial impact or\\neffects and mitigate the possible adverse effects of ai on\\neducation.c. review strategy\\n1) materials and methods\\nthe study seeks to assess the impact of ai on education.\\nmore particularly, it seeks to ascertain how ai has affected\\neducation, looking at various aspects of education, includ-\\ning administration, instruction, and learning. accordingly,\\nthe study takes a retrogressive approach, entailing assess-\\ning secondary data and materials or studies that have been\\nundertaken. indeed, snyder posited that a systematic or semi-\\nsystematic literature review, a review of secondary data, pro-\\nvides a deeper understanding of the study phenomenon [8].\\nthis approach ensures that the study is premised on empirical\\nor is evidence backed because only studies, including meta-\\nanalysis, that have been conducted on the subject matter, sup-\\nport the identi\\x1ccation, analysis, understanding, and synthesis\\nof the ways in which ai has affected and impacted educa-\\ntion. generally, a qualitative research design, incorporating\\nqualitative content and thematic analysis is used to assess\\nthe different ways. thematic and content analysis entails\\nundertaking a thorough critique of each piece of text and\\nidentifying recurring themes from a review of different texts,\\nwhich then form the basis for inferences and conclusions for\\ndescriptive studies [10]. it is an appropriate research design\\nand strategy considering the aim of this study, to assess the\\nimpact of ai on education.\\n2) search strategy\\nkey words and search strings will be used to search different\\ndatabases, including ebscohost, proquest,web of science.\\nin addition, the key words and search strings are used to\\nsearch google scholar to identify articles from different\\njournals that have focused on researching the impact of ai\\non education. the journals containing the articles are then\\nsearched on scimago and the journals with an h-index of\\n20 and above are included in the study. an h-index is an\\nauthor level measure of scienti\\x1cc productivity in terms of\\npublications and citations and by extension, contribution to\\nscience and scholarly pursuits; and the higher the h-index,\\nthe more reputable the journal and the authors published in\\nthe journal are. a total of more than forty articles, including\\njournal articles, professional publications, and government\\nand institutional reports were selected after the use of an\\neliminative process.\\n3) sampling: exclusion and inclusion criteria\\ninitially, a total of 250 articles, published after 2009 were\\nselected premised on the aforementioned criteria; matching\\nthe search key words and search strings and inclusion in a\\njournal with an h-index of 20 and above. a further review and\\nanalysis of these articles, identifying articles that focused on\\nthe nature of ai and the impact it had on education, together\\nwith the h-index, narrowing down the number of articles for\\nanalysis to thirty, a sample size that was considered suf\\x1ccient\\nto inform conclusions and inferences about the impact of\\nai on education, taking a retrospective approach. further,\\n75266 volume 8, 2020\",\n",
       " \"l. chen et al. : ai in education: a review\\nstudies that had taken a quantitative approach in identifying\\nand assessing the impact of ai on education, while at the\\nsame time, meeting the criteria aforementioned, were given\\npreference.\\nii. artificial intelligence in education\\nfrom a review of the convergence of ai with education as\\ndiscussed by chassignol et al. , the scope of this study will\\ncover the impact of ai on the administration and manage-\\nment, instruction or teaching, and learning functions or areas\\nin the education sector. this section of the report provides an\\noverview and brief discussion of the results of the study from\\na review of various articles that have assessed the nature and\\nimpact of arti\\x1ccial intelligence in the education sector.\\na. nature of artificial intelligence\\narti\\x1ccial intelligence (ai) is conventionally heavily associ-\\nated with computers. however, it is evident, from a review\\nof the various articles, particularly within the context of the\\neducation sector, that while computers may have formed\\nthe basis the development of arti\\x1ccial intelligence, there is\\na gravitation away from the computer alone, the hardware\\nand software, or the equipment, as being arti\\x1ccial intelli-\\ngence. embedded computers, sensors, and other emerging\\ntechnologies have facilitated the transfer of arti\\x1ccial intel-\\nligence to machines and other items, such as buildings and\\nrobots [11]. indeed, chassignol et al. provides a two-faceted\\nde\\x1cnition and description of ai. they de\\x1cne ai as a \\x1celd\\nand a theory. as a \\x1celd of study, they de\\x1cne ai as a study\\narea in computer science whose pursuits are aimed at solving\\ndifferent cognitive problems commonly associated with the\\nhuman intelligence, such as learning, problem solving, and\\npattern recognition, and subsequently adapting [11]. as a the-\\nory, chassignol et al. de\\x1cned ai as a theoretical framework\\nguiding the development and use of computer systems with\\nthe capabilities of human beings, more particularly, intelli-\\ngence and the ability to perform tasks that require human\\nintelligence, including visual perception, speech recognition,\\ndecision-making, and translation between languages [11]\\n(p.17).\\nother scholars and in other studies, the de\\x1cnition of ai\\nprovided brings to the fore near similar elements or character-\\nistics of ai. sharma et al, de\\x1cned ai as machines that have the\\nability to approximate human reasoning [13] (p.1). similarly,\\npokrivcakova, with a de\\x1cnition and description orientated\\nto the education sector, observed that ai is as a results of\\nmany decades of research and development bringing together\\nsystem designers, data scientists, product designers, statisti-\\ncians, linguists, cognitivescientists, psychologists, education\\nexperts and many others to develop education systems with\\nsome level of intelligence and ability to perform different\\nfunctions, including to help teachers and support learners to\\ndevelop their knowledge and \\x1dexible skills for a constantly\\nchanging world [14] (p.138). the author posited that ai uses\\nimproved capabilities of programs and software, such as algo-\\nrithmic machine learning, which provides the machines withan ability to perform different tasks that require human-like\\nintelligence and ability to adapt to the immediate environment\\n[14]. similar observations are made by wartman et al. , who\\nde\\x1cned arti\\x1ccial intelligence as the ability of computers and\\nmachines to mimic human cognition and actions [17].\\ngenerally, arti\\x1ccial intelligence, from these de\\x1cnitions and\\ndescriptions, encompasses the development of machines that\\nhave some level of intelligence, with the ability to perform\\nhuman like functions, including cognitive, learning, decision-\\nmaking, and adapting to the environment. as such, there are\\nspeci\\x1cc characteristics and tenets that come out as key for\\nai. intelligence or machine ability to demonstrate some level\\nof intelligence and perform a wide range of functions and\\ncapabilities that require human-like abilities, comes out as a\\nkey characteristic of ai from this de\\x1cnition and discussion\\nof ai.\\nrecently, ai and machine learning are widely studied to\\nbe applied in mobile devices, which aim to enhance compu-\\ntation quality and create possibilities for new applications,\\nsuch as face unlock, speech recognition, natural language\\ntranslation, and virtual reality. however, machine learning\\nrequires huge computation capability to perform complex\\ntraining and learning. to address this issue, someplatforms\\nfor running computationally ef\\x1cciently were proposed. in\\n2016, qualcomm introduced the snapdragon neural process-\\ning engine to accelerate the execution of neural networks\\nwith their gpu processors. hisilicon proposed the hiai\\nplatform for running neural networks. it should be noted\\nthat android neural networks api was designed to quickly\\nexecute machine learning models on mobile devices [37].\\nthis api brings a lot of utility to the mobile by reducing\\nnetwork latency and complexity. with respect to ai-related\\nlearning network, squeezenet, mobilenet, and shuf\\x1denet\\nare well developed for mobile phones [38]. the technical\\ndevelopment of ai in mobile devices takes mobile education\\nto the higher level, which provides convenience by helping\\nstudent in less time and achieves interactive and personalized\\nlearning. for instance, virtual reality facilitates the learning\\nprocess beyond the learning space to create a global class-\\nroom since ai can connect students to the virtual classroom.\\nin addition, ai-based chatbots provide a personalized online\\nlearning, and also turn instructor into chat conversations. this\\ntechnology can assess the students' level of understanding.\\nb. technical aspects of ai in education\\nai-aided education includes intelligent education, innovative\\nvirtual learning, and data analysis and prediction. major sce-\\nnarios of ai in education and key technologies supporting are\\nlisted in table 1. note that ai-enable education is playing\\na more important role as learning requirements promotes\\n[12]. intelligent education systems provide timely and per-\\nsonalized instruction and feedback for both instructors and\\nlearners. they are designed to improve learning value and\\nef\\x1cciency by multiple computing technologies, especially\\nmachine learning related technologies [18], which are closely\\nrelated to statistics model and cognitive learning theory.\\nvolume 8, 2020 75267\",\n",
       " \"l. chen et al. : ai in education: a review\\ntable 1. techniques for scenarios of ai education.\\nfigure 2. technological structure of ai education.\\nvarious techniques are incorporated into ai system for\\nlearning analysis, recommendation, knowledge understand-\\ning and acquirement, based on machine learning, data mining\\nand knowledge model [39]. ai education system generally\\nconsists of teaching contents, data and intelligent algorithm,\\nwhich can be divided into two parts, i.e., system model\\n(including learner model, teaching model, and knowledge\\nmodel) and intelligent technologies [43]. as shown in fig.2,\\nmodel help to build data map is crucial for improving learn-\\ning, which establishes structures and association rules for\\ncollected education data [44]. model works as a core in ai\\nsystem, with technologies providing power for the system.\\n1) ai education model\\nin ai learning system, learner model is critical for improv-\\ning independent learning capabilities. it is established based\\non behavior data of learners generated from the learning\\nprocess. learners' thinking and capability is analyzed to\\nassess their learning abilities. then knowledge analysis are\\nmapped to obtain learners' knowledge mastery. learner\\nmodeling establishes connections between learning results\\nand various factors including learning materials, resources\\nand teaching behaviors [39]. knowledge model establishesknowledge structure map with detailed learning contents,\\nusually including expert knowledge, rules of making mistakes\\noften made by learners and misunderstanding [44]. combin-\\ning knowledge \\x1celd model and learner model, teaching model\\ndetermines the rules to access knowledge \\x1celd, which enables\\ninstructors to tailor teaching strategies and actions. as edu-\\ncation evolves, learners are likely to behavior positively, take\\nactions or seek for help. ai system can always be prepared\\nto offer aid from tutoring model's built-in teaching theories.\\nuser interface explains learners' performance through multi-\\nple input media (voice, typing and click) and provides output\\n(texts, \\x1cgures, cartoons and agencies). the advanced human-\\nmachine interface provides ai-related functions including\\nnatural language interaction, speech recognition and learners'\\nemotion detection.\\n2) intelligent education technologies\\nmachine learning, learning analytics, and data mining are\\nclosely related technologies for education. at present, two\\ncommunities have evolved based on learning analytics and\\neducational data mining. they overlap in objectives and tech-\\nniques and bene\\x1ct from a variety of disciplines, including\\nmachine learning, data mining, psychometrics of statistics,\\n75268 volume 8, 2020\",\n",
       " \"l. chen et al. : ai in education: a review\\nand data modelling [41]. the \\x1celd of learning analytics is\\nmore focused on learning content management systems and\\nlarge-scale test results. data mining originates from the com-\\nmunity of intelligent tutoring systems, work on very small-\\nscale cognition.\\na: machine learning\\nthe core of machine learning is knowledge discovery, the\\nprocess of parsing based on sampling data set known as\\n``training data'', generating meaningful patterns and a struc-\\ntured knowledge. for instance, machine learning can help\\ncreate recommendations for students as they select classes,\\neven choose universities. it leverages achievements data,\\naspirations, preferences of students to ``match-make'' insti-\\ntutions where they can be best developed. moreover, this\\ntechnology can help instructors gain an understanding of\\nhow every concept is being digested by students [42]. in\\nthis way, instructors can adjust the teaching method to work\\nwell based on students' cumulative records, which may help\\nstudents grasp course material better. in particular, for student\\nassessment, image recognition and prediction of machine\\nlearning can be used to grade student assignments and exams,\\nwith faster and more reliable results than human being. it\\nshould be noted that deep learning, the sub\\x1celd of machine\\nlearning, attracts much attention. this widely used techniques\\nincludes decision tree learning, inductive logic programming,\\nclustering, reinforcement learning and bayesian networks.\\nfrom technique perspective, deep learning emphasizes on\\nincreasingly meaningful representations from learning suc-\\ncessive layers. these layer features are extracted via models\\ncalled neural networks structured in literal layers stacked on\\ntop of each other.\\nb: learning analytics\\nlearning analytics focuses on data from the characteristics\\nof students and knowledge objects from learner model and\\nknowledge \\x1celd model. the concept of learning analytics\\nintroduces new technology, i.e., machine learning, being\\napplied to a non-technical world as education. the purpose is\\nto tailor educational method to the individual learner's need\\nand ability, such as intervening with students at risk or provid-\\ning feedback and instructional content [40]. it uses techniques\\nrelated to machine learning, data visualization, learning sci-\\nences, and semantics. for instance, ai-based competency\\nlearning, which generates critical data from the students, can\\neffectively \\x1cnd insights on the students and predict the critical\\ncompetencies they can pursue, which enables institutions to\\nact proactively. in addition to a competency-based learning,\\nlearning analytics also exploit the versatile capability of ai\\nto learn. with respect to drop-out issues, ai can consider\\nvarious parameters to classify incoming students in likeli-\\nhood of dropping-out generating early warning systems and\\nactionable data for the institutions. the next challenge for\\nlearning analytics is to move out of the comfort zone towards\\na broader scope including interpersonal skills, arts, literature,\\namong others that raise a whole new level of complexity interms of measurement and assessment of competencies or\\nlearning outcomes. a challenge for learning analytics is to\\nbe applied in speci\\x1cc learning contexts, but at the same time\\nneed to be general enough to be used across different courses\\nand institutions. learning analytics will be increasingly used\\nand integrate advanced techniques to support learning for\\nstudents, instructors, administrators, and institutions.\\nc: data mining\\neducational data mining tries to generate systematic and\\nautomated responses to learners. ai-based educational data\\nmining aims for developing inherent association rules, and\\noffering knowledge objects to students to meet their personal\\nneeds. for instance, students' demographic characteristic\\ndata and grading data can be analyzed from a small number\\nof written assignments [44]. it can be achieved by a machine\\nlearning regression method that can be also used to predict\\na student's future performance. furthermore, data mining is\\nbecoming a powerful tool to improve the learning process and\\nknowledge mastery, leading to a better understanding of the\\neducational settings and learners. in other words, data mining\\ncan be seen as pattern discovery and predictive modeling\\napplied in extract hidden knowledge, which allows instructors\\nto make adjustments to improve curriculum development in\\neducational system. one of important applications is that\\ndata mining-based ai can achieve personalized learning from\\nknowledge \\x1celd data, where students perform their own\\nlearning, at their own pace and deciding their own learning\\nmethod aided by ai. ideally, using personalized learning,\\nstudents choose what they're interested in, and instructors\\nadjust teaching course and method to the students' interests\\n[43]. with data mining, ai can build its intelligence (e.g.,\\nusing machine learning) more accurately and outcome is\\nmore reliable.\\nc. the role of ai in education\\ntimms makes an interesting observation, ai is very powerful\\nand has the potential to permeate and heavily cause changes\\nin different sectors of the society, with the education sector\\nbeing one that is likely to be majorly impacted by ai. indeed,\\nfrom the different articles reviewed, it is evident that ai has\\nbeen adopted and applied in the education sector, where it\\nhas fostered improvements in different areas of the sector.\\nmore speci\\x1ccally, within the context of the narrative and\\nframework proposed by chassignol et al. , which also forms\\nthe scope of the study, it is evident that ai has been applied in\\neducation, more particularly in administration and teaching,\\nand subsequently, in\\x1duencing or impact students' learning.\\nan analysis of the scholarly sources selected for the study\\nshowed that ai has indeed been applied in educational insti-\\ntutions in different ways, including in the form of automation\\nof administrative processes and tasks, curriculum and content\\ndevelopment, instruction, and students' learning processes.\\nai has improved ef\\x1cciency in the performance of adminis-\\ntrative tasks, such as reviewing students' work, grading, and\\nproviding feedback on assignments through automation using\\nvolume 8, 2020 75269\",\n",
       " \"l. chen et al. : ai in education: a review\\nweb-based platforms or computer programs. other areas in\\nwhich ai has been applied in the education sector include\\ncurriculum and content development, and instructions lever-\\naging technologies such as virtual reality, web-based plat-\\nforms, robotics, video conferencing, audiovisual \\x1cles, and\\n3-d technology, which have made it possible for students to\\nlearn better. teachers are more effective and ef\\x1ccient and stu-\\ndents have a personalized and richer learning or educational\\nexperience.\\nother important \\x1cndings, from a further scouring of the\\ndifferent sources, is that the application of ai in education,\\nfrom the analysis, presents an opportunity to break the phys-\\nical barriers posed by national and internationally borders\\nbecause learning materials are now domiciled on the inter-\\nnet and the world wide web. learning online or use of\\nweb-based learning platforms means that the material are\\naccessible from anywhere in the world, and leveraging other\\naspects of ai, such as language translation tools, make it\\npossible for students, to learn best within the context of their\\nindividual abilities. indeed, the study \\x1cndings demonstrate\\nthat administration, instruction, and learning is more ef\\x1ccient\\nand effective, which will be illustrated in the section on the\\ndiscussion of the \\x1cndings on the impact of ai in education.\\ndifferent studies discussed and demonstrated the appli-\\ncation of ai in education. chassignol et al. provides an\\noverview and the transitions that have de\\x1cned the application\\nof ai in the education sector. chassignol et al. observed that\\nai, in education, was adopted in the form of computers, and\\ncomputer-related technologies, such as the internet and the\\nworld wide web [11]. there has been evidence of gradual,\\nin tandem with changes in technology in the macro operat-\\ning environment, of transitioning from computers to online\\nand web-based technologies and intelligent or ai systems\\n[11]. ai in the education sector is transitioning from simply\\ncomputers to embedded systems, such as robots or colleague\\nrobots (cobots) that work with instructor or educators or inde-\\npendently, to perform teacher like functions [11]. in agree-\\nment, timms posited that arti\\x1ccial intelligence in education\\n(aied0 is taking different forms but there is evidence of\\ndissociating ai with computers or the focus on understanding\\nand using ai as computers only, to include using computer\\nembedded systems such as in smart classrooms and cobots\\n[7]. ai is no longer computers only or the desktop and other\\ncomputer applications as conventionally understood. it has\\ngone on to include other elements as already demonstrated\\nfrom the presentation of \\x1cndings from other studies.\\nindeed, even from a review of other works, there is evi-\\ndence of ai, in the context of application in the education\\nsector, going over and above the conventional perception\\nof ais as computer systems only. pokrivcakova's de\\x1cnition\\nand description of ai in education provides an overview and\\nsummary of the nature of application of the same in education\\n[14]. pokrivcakova posited that the design and implementa-\\ntion of ai brings together different professionals, including\\nsystem designers, data scientists, product designers, statisti-\\ncians, linguists, cognitive scientists, psychologists, educationexperts and many other professionals [14] (p.138). the impli-\\ncation therefore is that ai, in education, is designed to\\nperform more than just the normal computers and computer-\\nrelated functions. indeed, sharma posited that ai, in its\\nentirety, supersedes the conventional understanding of the\\ndifferent technological applications in education, web-based,\\nonline, distance, and computer-assisted instruction courses\\nand learning.\\nmore speci\\x1cc application of ai in education, as evidenced\\nform the different articles reviewed takes different forms.\\nchassignol et al. highlighted the extensive application of ai\\nin different areas, including content development, teaching\\nmethods, student assessment, and communication between\\nteacher and students [11] (p. 22). for example, according\\nto the study by chassignol et al. ai has been extensively\\napplied in curriculum development and content personal-\\nization, teaching and pedagogical methods, assessment, and\\ncommunication exchanges between teachers and students.\\nchassignol et al. provide examples of different platforms\\nand applications of ai, such as interactive learning envi-\\nronments (iles), which are used to manage performance\\nand provide feedback and exchanges between teachers and\\nstudents; intelligent tutoring systems, such as active math,\\nmathia, why2atlas, comet, and viper which have been\\nused at different levels of the education system to by edu-\\ncators or instructors for different subjects at different levels\\nof education, as well as extensive use in learning assessment\\nto track performance and improve the available pedagogical\\ntools [11]. similar applications are evident in other studies.\\nmaking similar observations and arguments, sharma et al.\\nobserved that ai in education has taken the form of adap-\\ntive learning systems, intelligent tutoring systems, and other\\nsystems that improve the quality of administrative processes,\\ninstructions, and learning [13]. in agreement, pokrivcakova\\nobserved that in education, ai takes the form of intelligent\\nsystems with adaptive capabilities [14]. these tenets andchar-\\nacteristics of the systems enable ai in education to perform a\\nwide range of tasks traditionally or conventionally performed\\nby instructors, while at the same time improving students'\\nlearning experiences through coaching students and cus-\\ntomizing learning to students' expectations and needs [14].\\nmikropoulos and natsis in their article, also describe another\\naspect of ai in instructions, virtual reality (vr) and three\\ndimension (3-d) technology, observing that vr presents\\nimmense opportunities for the learning process, integration of\\nsimulation and 3-d technology because it enables simulation\\nand provides learners with an opportunity for experiential\\nlearning.\\nindeed, it is evident, as the united nations education sci-\\nenti\\x1cc and cultural organization (unesco) observed, that\\nai has permeated various sectors of the society, more particu-\\nlarly, the education sector, as discussed for example, instruc-\\ntions or teaching methods, approaches, and tools [16]. other\\nareas or ways in which ai has been implemented in edu-\\ncation include learning and administration, which has been\\nprecipitated by changes in the general environment. indeed,\\n75270 volume 8, 2020\",\n",
       " \"l. chen et al. : ai in education: a review\\naccording to wartman and combs education is changing\\nin tandem with changes in the employment or professional\\nworld, necessitating the incorporation of ai in instruction\\nand learning [17]. for example, there is heavy use of ai in\\nthe medical profession, which necessitates exposing students\\nto ai through use of the technology in medical education to\\nprepare them for the experiences in the real world [17]. the\\ntrend and arguments identi\\x1ced and presented by wartman and\\ncombs are echoed in other studies and publications, which\\ndemonstrate other applications of ai in education.\\nfurther, from the analysis of the selected articles, another\\ntrend or application of ai in education is in the form of ai\\nin web-based education. for example, kahraman, sagiroglu,\\nand colak, in their study, discussed the development and use\\nof ai in education in the form of adaptive and intelligent\\nweb-based educational systems (aiwbes), which are fast\\nreplacing the simplistic leveraging and use of the internet\\nand the world wide web, what they refer to as the just-\\nput-it-on-the-web approach [18]. aiwbes is the integration\\nof ai principles and technology into web-based learning\\nplatforms, which improves the learners' experiences. indeed,\\nperedo et al. also describe the integration of ai into web-\\nbased platforms. they posited that intelligent web-based edu-\\ncation (iwbe) has emerged as an important component of\\neducation, more so with the proliferation of online education\\nbecause of the power of the platform as a pedagogical tool\\nthat incorporates and leverages ai into web-based education\\n(wbe) as well as other intelligent methods, tools, and theo-\\nries for modelling engineering agent-based systems and tech-\\nnologies [19] (p.14690). iwbe, according to the \\x1cndings of\\ntheir study, involves considering different factors, including\\nlearner's knowledge and skill, learning, performance capa-\\nbilities, and compatibilities, which are then leveraged in the\\ndevelopment and use of a platform that improves teaching-\\nlearning experiences. from their study, peredo et al. therefore\\nconcluded that studying and understanding of different social\\nagents, teachers and students leads, an integral part of the\\niwbe ensures the development and use of robust, intelligent,\\ninteractive, learning, and adaptive ai systems in education,\\nmore particularly on the web, which is accessible from any-\\nwhere in the world [19] (p.14690). evidently, as demon-\\nstrated from the evaluation of the nature of application of ai\\nin education and as enumerated in the report by unesco,\\nai will potentially foster improved access to learning by\\neliminating barriers to learning, automating management and\\nadministrative functions in academic institutions, and opti-\\nmizing instructions and learning, as well as fostering empir-\\nical or evidence-based decisions and initiatives in education\\n[16]. as a virtual platform, it can create a better professional\\nenvironment for instructors and learners. ai as an assessment\\ntool can be used grade paper and exams and free up the\\nteacher's time. moreover, it helps students navigate through\\ndifferent content paths, and personalize learning according\\nto their strengths and weaknesses. tab. 2 shows the different\\nfunctions of ai can work as in education scenarios of admin-\\nistration, instruction and learning. the detailed \\x1cndings ofthe application of ai in education are summarized in the next\\nsubsections.\\n1) ai in education administration\\nin this section, a summary of the \\x1cndings on the application\\nof ai in education, with a particular focus on administrative\\nfunctions is presented. one of the key areas in education,\\nidenti\\x1ced as likely to be impacted by ai, is the performance\\nof different administrative tasks in the education process,\\nsuch as students' assignments and papers reviews, grading,\\nand providing feedback to students. according to sharma\\net al. ai in education, particularly in distance and online\\neducation, where ai has enhanced ef\\x1cciencies in institutional\\nand administrative services [13]. indeed, speci\\x1cc programs,\\nsuch as knewton, ease the burden on instructors because they\\nprovide a platform for feedback to students premised on the\\ninteraction on the platforms. similar positions are evident in\\nother studies and publications, which discuss systems that\\nmake the administrative tasks easier.\\nfor example, rus et al. posited that intelligent tutoring\\nsystems (itss) perform a wide range of functions, including\\ngrading and providing students with feedback on their work\\n[12]. instructors, working with its achieve improved ef\\x1c-\\nciencies in various administrative tasks, as well as their core\\nresponsibilities, providing guidance and instructions to help\\nstudents excel in their studies. the \\x1cndings and arguments by\\nmikropoulos and natsis augment the arguments and \\x1cndings\\nin these studies; leveraging and using ai in education has\\nfostered effectiveness and ef\\x1cciency in the performance of\\nadministrative tasks, such as grading of students' assignments\\n[15]. indeed, a scrutiny of the online learning environment\\ntoday, shows programs that make it possible for instructors\\nto perform various administrative tasks, such as turnitin and\\necree, which give suggestive grading and check plagiarism\\non students' assignments. ai has improved ef\\x1cciencies in the\\nperformance of different administrative tasks that instructors,\\nwould require a lot of time to perform in the absence of ai.\\n2) ai in instruction\\nfrom the analysis of the articles identi\\x1ced and included in the\\nanalysis, one of the key areas that have seen an in\\x1dux of ai\\nsystems, is teaching or instructions. ai has facilitated the cre-\\nation and deployment of systems that are evidently very pow-\\nerful pedagogical tools. these tools have fostered improved\\ninstructional quality. different platforms and applications of\\nai as an instructional tool are discussed and highlighted in the\\nvarious articles evaluated. timms discusses various applica-\\ntions of ai as a pedagogical tool or instructional platforms;\\nsimulation-based instructions, which include using different\\ntechnologies, such as virtual reality to demonstrate or show\\nstudents concepts or practically demonstrate materials, giv-\\ning students an experiential or practical learning experience\\n[7]. the same concept or the application of virtual reality\\nelements as an element of ai in education is discussed in\\nother studies. for example, mikropoulos and natsis highlight\\nthe use of virtual reality as well as including 3-d technology\\nvolume 8, 2020 75271\",\n",
       " 'l. chen et al. : ai in education: a review\\ntable 2. the functions ai provides in educational scenarios.\\nand highly interactive simulation as a pedagogical tool, which\\nhelps students have a better understanding of demonstrated\\nconcepts [15]. similarly, wartman and combs highlight the\\nuse of ai, in the form of virtual reality and simulation in\\nmedical education, which takes medical students through\\npractical aspects of their education, such as operations and\\nunderstanding human anatomy, among other subjects.\\nother studies have also highlighted the integration of ai\\ninto machines or robots and creation of powerful instruc-\\ntional tools and improvement of the quality of the applied\\npedagogical strategies. indeed, timms highlights that another\\nkey form of application of ai in education as an instruction\\ntool is the integration of ai in education principles in robots,\\nthe development and use of robots as teacher assistants and\\ncolleagues, cobots, which can be used to undertake basic and\\neven advanced teaching tasks, such as teaching students to\\nread and pronounce words [7]. indeed, sharma et al. observed\\nthat the integration or the use of ai in education, more\\nparticularly, integration with other technologies and use as\\ninstructional tools, has resulted in the development and use\\nof better teaching tools [13]. on the other hand, pokrivcakova\\nalso highlights the integration of ai into computer programs,\\nand the development and use of chatbots, or online computer-\\nbased robots with conversational and dialogue abilities to\\nanswer routine student queries, and in some instances, dis-\\nseminate instructional materials [14]. ai equips the humanoid\\nor other robots with cognitive and decision-making abilities,\\nas well as dialogue and conversation abilities, and subse-\\nquently, enable their use as instructional and pedagogical\\ntools.further, from the analysis of the articles, other ways of the\\napplication of ai in education were identi\\x1ced. for example,\\nintelligent tutoring systems in different forms are discussed in\\ndifferent studies. for example, rus et al. observe that intel-\\nligent tutoring systems or its equipped with conversational\\nand dialogue abilities, as well integrated with animated con-\\nversational agents, in the form of chatbots or cobots, have fos-\\ntered realization of effectiveness in teaching [12]. the same\\nconcepts are also highlighted in the ai applications in educa-\\ntion discussed by pokrivcakova; computer-assisted language\\nlearning (call), which provides students or learners with\\ncustomized instructions; as well as the writing and trans-\\nlation assistants in language learning [14]. other forms of\\napplication of ai in education, particularly, in instructions to\\nperform teacher or instructor functions are also highlighted.\\nweb-based education platforms integrating ai with instructor\\nabilities are discussed by kahraman et al. and peredo et al. in\\ntheir different publications. kahraman et al. discuss the inte-\\ngration of ai in web-based education, more particularly, the\\nuse of aiwbes in teaching, and incorporating teacher-like\\nfunctions, making the platform a powerful supportive ped-\\nagogical tool [18]. similarly, peredo et al. discuss iwbe or\\nintelligent and adaptive web-based systems, in which teachers\\nare studied and presented as social agents in this system;\\nthe system then seeks to understand and support teachers\\nin the discharge of their mandates, to provide instructions\\nand directions to students, with an objective of ensuring that\\nthe technology, web-based education, used in education is\\nef\\x1ccient and systematic way to improve learner experience\\n[19]. ai has been integrated into different technologies and\\n75272 volume 8, 2020',\n",
       " \"l. chen et al. : ai in education: a review\\napproaches and used as a stand-alone instructional tool or to\\nsupport instructors in the discharge of their teaching mandate.\\n3) ai in learning\\nlearning, which is an integral part of education, is another\\naspect of education that is within the scope of the study. from\\nan evaluation and analysis of the different articles included\\nin the study, different ways in which ai has been adopted\\nand implemented or leveraged in fostering students' learning\\nwere identi\\x1ced. further, speci\\x1cc programs or applications\\nthat leverage ai to improve student learning were identi\\x1ced.\\nan important way in which ai has been applied in improving\\nstudents' learning is the customization and personalization\\nof curriculum and content in line with the learners needs,\\nabilities, and capabilities [15]. other approaches give learners\\na more pleasant and involving or experiential learning experi-\\nence, therefore improving the learners' uptake and retention\\nof information, the foundation of learning [15], [17]. from\\nanother perspective, ai in education has also eliminated some\\nbarriers to access to learning opportunities, such as national\\nand international borders, enabling global access to learning\\nthrough online and web-based platforms [13], [15].\\nfrom the articles, different platforms and applications were\\nidenti\\x1ced. some platforms will foster the customization and\\npersonalization of content and in so doing foster the uptake\\nand retention of information, which improves the learning\\nexperience of the learner. for example, an application such\\nas knewton makes real-time recommendations for students\\npremised on deciphered learning style as adduced by the\\ntechnology using machine learning algorithms, and subse-\\nquently customizes course materials or content to the learn-\\ners' needs [11]. other platforms with similar capabilities\\ninclude cerego, immersive reader, and call, which together\\nwith other platforms, have the potential to improving the\\nlearning experience of learners at all levels of the educa-\\ntion system, from early childhood education to university\\nundergraduate and graduate level [11], [14]. pokrivcakova\\nalso observed that the integration of ai and use of chatbots\\nalso improve the learning experiences of students because\\nthey leverage machine learning algorithm and deliver content\\ncustomized to students learning needs and capabilities [14].\\nthe author also highlights the integration of ai into educa-\\ntion through machine translation tools, adaptive education\\nsystems, and intelligent tutoring systems, which improve\\nthe learners' experience. there are different ways in which\\nai ensures personalization and customization of content to\\nlearners' capabilities and needs.\\non the other hand, as gleaned from other articles, there\\nwere other applications of ai that were found to have a\\nmajor impact on the learners' experiences. for example, the\\napplication and use of simulation-based learning and intelli-\\ngent tutoring systems (its) were demonstrated to encourage\\ndeep learning, which is a way of improving the students'\\nlearning experience [13]. mikropoulos also highlights the\\nsame concept, observing that virtual reality and simulation\\nfosters students improved learning experiences [15]. the useof simulation, virtual reality and other aspects of ai in learn-\\ning was shown to prepare students for futuristic trends with\\nthe gradual gravitation towards keeping pace with the appli-\\ncation of ai in industry [17]. other uses of ai in fostering\\nthe students' learning experience is the use of aiwbes.\\naiwbes is more adaptive and generates content that is based\\non the learner's needs [18] (p.156). for example, according\\nto kahraman et al., interactive problem solving, a component\\nof aiwbes will work with students to offer intelligent help\\nin each of the phases of the problem solving process when\\nstudents are working on such issues[18] (p.159). the same\\ncapabilities of ai in web-based education are highlighted\\nand discussed by peredo et al. , who observed that iwbe\\nor intelligent and adaptive web-based systems, particularly\\nmulti-agent systems (mas) have a learner component, with\\nthe learner integrated as a social agent, in which the sys-\\ntem focuses on understanding learner behavior and adjusting\\naccordingly by generating content relevant to the learners'\\nneeds [19]. evidently, ai integration or adoption and use\\nin education has been focused in improving the learners'\\nexperiences, as well as having a major impact on other aspects\\nof the education process.\\niii. impact of ai in education\\na recap of the objective or purpose of the study; the study\\naims at assessing the impact of ai in education. the eval-\\nuation of the different ways in which ai has been imple-\\nmented in the education, focusing on administration tasks,\\ninstruction, and learning, only partly answers the implied\\nresearch question. sharma et al observed, the use of ai in\\neducation presents an opportunity to majorly revolutionize\\ndifferent aspects of education [13]. an exploration of the uses\\nof ai partly shows how the impact of ai in education. in this\\nsection, a more focused exploration of the actual effects of\\nai on administration, instructions, and learning is explored\\nand explained premised on the \\x1cndings from the articles\\nanalyzed.\\na. education administration\\nai application in education, in its various forms and serv-\\ning different functions, has had a major impact on the per-\\nformance of administrative and management functions in\\neducation. it has enabled instructors or teachers to perform\\ntheir administrative functions, such s as grading and pro-\\nviding feedback to students more effectively. aiwbes pro-\\ngrams have incorporated functions that provide instructors\\nwith grading guides, which make it easier to grade students'\\nwork and provide feedback [14]. similar capabilities and\\nfunctionalities are available on programs, such as knewton,\\nprovide instructors within built functionalities to evaluate\\nperformance, grade, and provide students with feedback to\\nensure continuous improvement in learning [13]. ai has\\nmade the performance of administrative tasks easier and\\nimprove teacher or instructor ef\\x1cciency and effectiveness in\\nproviding instructions and guidance to students. intelligent\\ntutoring systems provide a wide range of functionalities that\\nvolume 8, 2020 75273\",\n",
       " \"l. chen et al. : ai in education: a review\\nenable instructors to perform different administrative tasks,\\nincluding grading and providing feedback [12]. other pro-\\ngrams, such as grammarly, ecree, paperrater, and turnitin\\namong others, which leverage ai also provide instructors\\nwith the functionalities to perform different administrative\\nfunctions, including plagiarism checking, rating and grading,\\nand providing students with feedback on improvement areas.\\nai, has signi\\x1ccantly reduced the paperwork and workload\\non instructors, particularly in the performance of various\\nadministrative functions, thereby enabling them to focus on\\ntheir core mandate, instruction, dissemination of content and\\nmaterials in line with the curriculum in place at the institution\\nor nationally [11], [13]. while this area of education was not\\na focus for many of the articles evaluated, in the articles it was\\ncovered, there was evidence of attainment of improvements\\nin the administrative processes and tasks quality, as well as\\neffectiveness and ef\\x1cciency of the instructors or educators in\\nthe performance of various administrative tasks.\\nb. instruction\\nanother aspect of education that was the focus of this analysis\\nis the use of ai in instructions or by instructors. an analysis\\nof different articles showed rapid uptake and use of ai, in\\ndifferent forms for instructional purposes or as a pedagogical\\ntool by instructors. the use of ai for instructional purposes or\\nas a pedagogical tool has had a major impact on this aspect\\nof education. it has improved effectiveness, ef\\x1cciency, and\\nquality of the work done by instructors as adduced from\\nthe different publications reviewed and analyzed. ef\\x1cciency\\nand quality, within this context, is measured by the delivery\\nof the relevant content in line with the curriculum and in\\nline with the learner speci\\x1cc needs and capabilities, while\\neffectiveness is assessed by the implied uptake and retention\\nor the achievement of learning by the students or the learners.\\nconsidering these operational de\\x1cnitions and description of\\nef\\x1cciency, quality, and effectiveness, the \\x1cndings of the study\\ntherefore indicate ai has fostered the realization of quality,\\neffectiveness, and ef\\x1cciency in instruction or teaching.\\nai has fostered effectiveness of instructions. rus et al.\\nposited that its, which leverage evidence-based or empirical-\\nevidence backed practices, including the extensive use of\\ncognition and learning models, have ensured the optimal\\nuptake and retention of materials or optimized learning\\namong students [12]. indeed, programs, such as deeptu-\\ntor and autotutor, as discussed by rus et al. are learner-\\ncentered programs that foster customization and personalized\\ncontent in line with the learner capabilities and needs, thereby\\nimproving learners experience and fostering the achieve-\\nment of the set learning objectives. the arguments pre-\\nsented by pokrivcakova also demonstrate that ai has fostered\\ninstructional quality and effectiveness because the contempo-\\nrary systems, are technology-based adaptive systems, which\\nmeans that the materials or the content presented is deter-\\nmined by the learners needs, ensuring an optimized learn-\\ning experience [14]. ai ensures improved dissemination of\\ncourse content, starting from curriculum development phaseto actual delivery of content or instructions, more so in online\\nand web-based learning platforms.\\nthe development and use of ai, particularly integration\\nin online and web-based learning platforms, has indeed,\\naccording to mikropoulos and natsis, led to realization of\\nimprovements in instructions because ai has provided for\\ndevelopment and use of better pedagogical tools for these\\nplatforms [15]. the same bene\\x1cts or improvements to learn-\\ning are enumerated in other studies that were evaluated.\\nperedo et al. discuss the importance of adaptive iwebs\\nand instructions premised on observed and learned learner\\nbehavior, which enables the platforms to improve the qual-\\nity of learning and instructional effectiveness because of\\nthe customization capabilities of the ai-backed pedagogical\\nmethods used [19]. the same is highlighted by the study\\nby phobun and vicheanpanya, who observed that unlike\\ncomputer-aided learning (cal) and computer-based train-\\ning (cbt) take a generalized put it all on the web approach\\nand may not address the learning needs of the student\\nunlike its, which customizes, individualizes, and person-\\nalizes learning [20]. the impact of ai on education, more\\nparticularly in improving instructional effectiveness and ef\\x1c-\\nciency, is summed by roll and wylie, who in discussion of\\nthe changes in the ai, particularly in application in education,\\nobserved that ai, particularly tutoring or instructional sys-\\ntems, have been designed with the objective of solving the\\ndifferent challenges eminent in one-on-one teacher-student\\ntutoring, thereby improving the overall quality of instructors'\\nwork [21].\\nfrom the analysis other important themes, or ways in\\nwhich ai has affected the quality of instructors' works were\\nalso identi\\x1ced. some studies highlighted the role of technol-\\nogy in more particularly, ai in fostering academic integrity,\\nusing plagiarism checkers and proctoring and online supervi-\\nsion of students' activities on platforms such as grammarly,\\nturnitin and white smoke among others [23]\\x15[25]. gami-\\n\\x1ccation, leveraging ai for instructional purposes, with sig-\\nni\\x1ccant bene\\x1cts to the instructional quality, which is also an\\nelement of or integrates virtual reality and 3-d technologies,\\nin its different forms was discussed in other studies, which\\nhighlighted the bene\\x1cts of simulation, team-viewer applica-\\ntions, and gami\\x1ccation, closely related to vr and 3-d or even\\nleveraging the technologies to the pursuit of instructional\\neffectiveness and ef\\x1cciency [26], [27]. other studies also\\ndiscussed the bene\\x1cts of expressive humanoid robots with\\ndialogue and conversational capabilities in fostering instruc-\\ntional quality by fostering engagement with learners because\\nof their improved capabilities and human-like appearances\\n[28]\\x15[33].\\nc. learning\\nanother area of education within the scope of this study,\\nwhich has majorly been impacted by the rollout and the\\nuse of ai, is students' learning experiences. indeed, rus\\net al. summing up the effect of ai on learning observed\\nthat its fosters deep learning because working with the\\n75274 volume 8, 2020\",\n",
       " \"l. chen et al. : ai in education: a review\\nconversational agents that form an integral part of the system,\\nwill probe and prod students until the students are able to\\nadequately explain themselves in detail, including the reason-\\ning behind their position, thereby improving the uptake and\\nretention of information [12] (p.43). this and other studies\\nillustratively discuss the numerous bene\\x1cts of ai in students'\\nlearning experiences in different ways. ai enables the track-\\ning of learning progression, including knowledge and under-\\nstanding and uses the \\x1cndings to enhance the capabilities\\nof the system to customize content to the students' needs\\nand capabilities, which motivates students and leverages per-\\nsonal capabilities to enhance uptake and retention [12], [14].\\nfor example, pokrivcakova observed that ai has enabled\\nthe development and use of intelligent learning systems and\\nadaptive content customized for each students learning needs\\nand capabilities, such as intelligent virtual reality and use of\\nthe same in simulation teaching and learning, which has been\\nshown to have a positive impact on learning [14] (p.143). the\\nsame bene\\x1cts of simulation and other related technologies\\nto learning are also discussed by mikropoulos and natsis,\\nwho observed that simulation and other related technolo-\\ngies provide the students with the practical exposure and\\nexperiential learning, which improves the quality of learning,\\nwith the studies reviewed by the researchers in their arti-\\ncle highlighting the key bene\\x1cts of vr, 3-d technology in\\nlearning, including usability, enjoyment, learner enthusiasm,\\nmotivation, and increased interests in students [15] (p.773).\\nother bene\\x1cts of ai and its effect on quality of learn-\\ning are highlighted in other studies, which focused on web-\\nbased platforms. for example, kahraman in discussion of\\nthe important tenets or components of aiwbes, such as\\nadaptive hypermedia, information \\x1cltering, class monitoring,\\nand collaborative learning, among others, observed that they\\nencourage collaboration, interactions, and learning among\\nstudents [18] (p.160). the same bene\\x1cts of web-based plat-\\nforms are highlighted by peredo et al. who discussed the\\nrelationship between aiwbe and improved quality of learn-\\ning because the system adapts and customizes instructions\\nand content to identi\\x1ced and assessed learner behaviors. for\\nexample, studenttracker middleware will work with online\\ninformation about the learner, including completed activities,\\nlearning tracking, time, and other components to adapt the\\npedagogical approaches for the aiwbe [19]. other bene\\x1cts\\nof web-based platforms and demonstrated bene\\x1cts to learning\\ninclude fostering global access to education and affordability\\n[20]. these platforms have generally offered a better learning\\nexperience.\\nother bene\\x1cts of ai to learning, and impact on learn-\\ning are highlighted in other studies. for example, ai has\\nbeen used to encourage and foster honesty and academic\\nintegrity [23], improve studies and learning through the use\\nof revision and writing assistants, such as turnitin tools, such\\nas revision assist and pearson's write-to-learn tools [24],\\n[25], [27]\\x15[29]. other studies have however, highlighted the\\npossible detrimental or adverse effects of ai on learning.\\ncrowe et al. in their study, observed that ai may encouragedishonesty and jeopardize academic integrity because it may\\nfacilitate or enable students to use paper mills and paper\\nchurning sites or platforms [24]. generally though, the ben-\\ne\\x1cts of ai to learning supersede the challenges, as demon-\\nstrated in various other studies analyzed [35], [36].\\nd. performance of instructor and student\\nas intelligent systems, it would be interesting to look at how\\nai will affect the performance of instructor and student. as\\nthe number of students increases in learning institutions, ai\\nsystems will work well in easing the burden on instsructors.\\nai systems help instructors to analyze the syllabus and course\\nmaterial to propose customized content [11]. these systems\\ncan also generate and grade exams after analyzing. this\\nwould eventually free instructors to focus on more pressing\\nissues such as student performance. in individualized teach-\\ning and autonomous learning, ai solutions can better analyze\\nstudying data, in turn helping instructors create personalized\\nlearning plans for each student. human bias is also an emerg-\\ning issue for ai in education. ai solution can grade papers\\nand exams by preset rubrics and benchmarks to break bias\\n[41]. this is can be achieved by computer vision-based ai\\nsystems that read and detect images of handwritten papers.\\napart from reducing bias, such systems also prevent student\\nfrom cheating and plagiarism.\\nby analyzing student data, ai systems has detected learn-\\ning shortcomings of student and address them early in their\\neducation. most students are treated similarly by the conven-\\ntional education system [44]. thus, the same teaching method\\nto all students cannot achieve the best teaching performance.\\nai would help to determine the tailored teaching method\\nfor each student based on their personality, strengths and\\ncomplementary skills. in this way, all students can improve\\nand enjoy the learning performance. while increasing stu-\\ndents' knowledge, it also helps students build up knowledge\\nsystem with improved learning capability, habits and creativ-\\nity. moreover, ai systems predict the career path for each\\nstudent by gathering studying data, which in turn customizes\\nthe university course selection for students. considering the\\nindividual ability and career path, students can obtain better\\ngrades and garnering skills that are applicable in the real\\nworld.\\nbased on the above discussion, ai has great potential\\nin automating and expediting administrative tasks for both\\ninstitutions and instructors [7]\\x15[10]. ai can already auto-\\nmate the grading homework, evaluating essays which allows\\ninstructors to spend more time with students one-on-one. ai\\ndevelopers are creating new ways to grade written paper and\\nexams as well. with respect to learning materials, ai creates\\ncreate customizable learning digital interfaces that apply to\\nstudents of all age ranges and grades. moreover, in learning\\nprocess, ai enables instructor to gain student insight ``based\\non the entire ecosystem of learning tools'' according to nick\\noddson, the creator of brightspace. ai systems tutor a leaner\\nbased on the dif\\x1cculties they're having with class material.\\nin the past, students had a limited window of time in which\\nvolume 8, 2020 75275\",\n",
       " \"l. chen et al. : ai in education: a review\\nthey could resort to their instructors, meaning of\\x1cce hours\\nor hoping they answer their emails [11], [12]. there are now\\nsmart tutoring systems such as carnegie learning that use\\ndata from speci\\x1cc students in order to give them feedback and\\nwork with them directly. ai will soon be able to work as a full-\\n\\x1dedged assistant adapt to a wide variety of learning styles to\\nhelp instructors and students. in speci\\x1cc, it helps instructors\\nand students with their educational needs in just about any\\narea of need.\\niv. discussion of the results\\nfrom the different articles and studies reviewed, it is evi-\\ndent that with technological innovations and advancements,\\ncomputers and computer related technologies, and other inno-\\nvations have encouraged the development of arti\\x1ccial intelli-\\ngence, which has permeated different sectors of the society,\\nand will potentially have a major impact on different indus-\\ntries in which it is used. one of these areas in which ai has\\nbeen applied, and is resulting in a major impact, is the educa-\\ntion sector. as a foundation, and basis for understanding how\\nai has impacted education, a de\\x1cnition and description of\\nai was deemed essential. different tenets and characteristics\\nand nature of ai were gleaned from the different de\\x1cnitions\\nderived from the studies evaluated. a key characteristic and\\ntenet of ai, as the name intimates, is having some level of\\nintelligence, a characteristic that has only been the preserve\\nof human beings until the onset of ai [4], [5], [7], [11],\\n[16], [24], [35]. intelligence gives the ai, computers and\\nby extension, embedded systems, such as robots and facili-\\nties, with human like abilities, including cognition, learning,\\nadaptability, and decision-making functions [6], [13], [16],\\n[19], [22]. the innovations and developments, culminating\\nin the development and use of ai, have accorded the educa-\\ntion sector, more particularly, academic institutions, with an\\nopportunity to leverage and use of ai.\\nindeed, as adduced from the different sources reviewed\\nand analyzed, the uptake and use of ai in education has\\ntaken various forms. ai in education was initially in the\\nform of computers and computer related technologies, used\\nto perform a wide range of administrative tasks, instruction,\\nand to foster learning among students, scope areas deter-\\nmined from the description of ai application in technology\\n[11], [15], [19]. continuous developments and innovations,\\nparticularly, with the transitioning of ai from computers\\nonly, to include embedded systems, as well as online and\\nweb-based platforms, harbingered the development and use\\nof ai in web-based platforms and online platforms, and\\nrobotics, evidenced by the development and use of humanoid\\nrobots (cobots and chatbots), which perform, independently\\nor working with human instructors, educators' duties, includ-\\ning dissemination of learning materials to learners at vari-\\nous levels of education. in addition, from the analysis, and\\nthe descriptions of the platforms provided in the different\\nevaluated articles, it is apparent ai application, in educa-\\ntion, in its different forms, has accorded learners a richerand more rewarding learning experience [19], [22], [25],\\n[31], [34], [35].\\nimplied therefore, and as adduced from the analysis, is\\nthat ai has majorly affected or had a major impact on the\\neducation sector in general, and in particular, in application\\nin particular educational institutions. teachers or instruc-\\ntors using ai or leveraging ai are able to achieve greater\\nef\\x1cciency and effectiveness in the performance of different\\ntasks, including completion of administrative tasks, such as\\nreviewing, grading, and providing feedback to students on\\nsubmitted assignments. in addition, working with ai or the\\ndifferent forms of ai, such as web-based and online intel-\\nligent systems, cobots, and chatbots, teachers are able to\\nachieve improvements in instructional quality. students on\\nthe other hand, because ai uses machine learning as adduced\\nfrom the different studies, are able to have a better and\\nricher learning experience because ai uses machine learning\\nto assess capabilities and needs, and subsequently, with the\\n\\x1cndings of such an analysis, develop and disseminate per-\\nsonalized or customized content, which ensures higher uptake\\nand retention, thereby improving learning.\\nfurther, ai provides students with practical or experiential\\nlearning experiences, particularly when used together with\\nother technologies, such as virtual reality, 3-d, gaming, and\\nsimulation, thereby improving the students' learning experi-\\nences. one study discussed or highlighted the adverse impact\\nof ai, degradation of academic integrity and cheating using\\npaper churning and paper mill services facilitated by ai.\\nmost of the studies analyzed demonstrated and explained the\\ndifferent ways in which ai, including integration, bene\\x1cts,\\nand impact on administration, instruction, and learning when\\nused in education. the positive effects, the pros, outweigh the\\ncons, or the negative effects.\\nai learning is currently considered as education assistant\\nat the early stage, while ai-enable education will play a\\nmore important role as learning requirements changes. it now\\nprovides courses of different dif\\x1cculty based on simple rule\\njudgement and has not reached the best intelligence level in\\nintelligent education. there are education studies for ai sys-\\ntems involving knowledge map and probability model. with\\nincreasingly frequent interaction of the educational process,\\nai systems will generate more and more data to provide a\\nclearer picture of the process of teaching and learning, which\\nenables more accurate information recommendation. aided\\nby learner analytics, machine learning and data mining, ai\\nsystems will provide high-quality contents to teachers and\\nstudents, to support both teaching and learning and make\\nthe whole process measurable. in this stage, users will have\\naccess to multiple approaches to the correct answer to any\\nquestion. in the future, the desirable ai system would shape\\nstudents' imagination and creativity, analyzing their learning\\nstyle and emotional condition and initiative, to improve learn-\\ning capabilities and creativity and stimulate subjective initia-\\ntive. ai systems are likely to be used more widely, which is\\nexpect to thrive on all aspects of students, i.e., personal skill,\\nknowledge mastery, learning ability and career development,\\n75276 volume 8, 2020\",\n",
       " \"l. chen et al. : ai in education: a review\\ninstead of just assisting students in understanding of speci\\x1cc\\nknowledge.\\nv. conclusion\\nthe objective or the purpose of this study was to assess\\nthe impact of ai on education. a qualitative research study,\\nleveraging literature review as a research design and method\\nwas used. journal articles, professional publications, and pro-\\nfessional conference reports were identi\\x1ced and used in an\\nanalysis that facilitated the realization of the study purpose.\\nthe development and use of computers and computer related\\ntechnologies harbingered research and innovations that have\\nled to the development and use of ai in different sectors.\\nparticularly, the development of the personal computers, and\\nlater developments that have increasing the processing and\\ncomputing capabilities, as well as the ability to integrate or\\nembed computer technologies in different machines, equip-\\nment, and platforms, have encouraged the development and\\nuse of ai, which has been shown to have a major impact\\non the sectors it permeates. ai has been extensively adopted\\nand used in the education sector, particularly, in education\\ninstitutions, which were the focus of this study. the analysis\\nfocused on evaluating the impact of ai on administrative,\\ninstruction, and learning aspect of education, with a focus\\non assessing how ai has been applied and the effects it\\nhas had.\\nai in education initially took the form of computers and\\ncomputer-related systems, and later, the form of web-based\\nand online education platform. embedded systems have made\\nit possible to use robots, in the form of cobots or humanoid\\nrobots as teacher colleagues or independent instructors, as\\nwell as chatbots to perform teacher or instructor-like func-\\ntions. the use of these platforms and tools have enabled\\nor improved teacher effectiveness and ef\\x1cciency, resulting\\nin richer or improved instructional quality. similarly, ai\\nhas provided students with improved learning experiences\\nbecause ai has enabled the customization and personaliza-\\ntion of learning materials to the needs and capabilities of\\nstudents. overall, ai has had a major impact on education,\\nparticularly, on administration, instruction, and learning areas\\nof the education sector or within the context of individual\\nlearning institutions.\\nreferences\\n[1] k. flamm, creating the computer: government, industry, and high tech-\\nnology . washington, dc, usa: brookings institution press, 1988.\\n[2] m. campbell-kelly, computer, student economy edition: a history of the\\ninformation machine . evanston, il, usa: routledge, 2018.\\n[3] m. m. l. cairns ``computers in education: the impact on schools and\\nclassrooms,'' in life schools classrooms . singapore: springer, 2017,\\npp. 603\\x15617.\\n[4] b. coppin, arti\\x1ccial intelligence illuminated . boston, ma, usa:\\njones and bartlett, 2004.\\n[5] b. whitby, arti\\x1ccial intelligence: a beginner's guide . oxford, u.k.:\\noneworld, 2008.\\n[6] v. devedºic, ``web intelligence and arti\\x1ccial intelligence in education,''\\neduc. technol. soc. , vol. 7, no. 4, pp. 29\\x1539, 2004.\\n[7] m. j. timms, ``letting arti\\x1ccial intelligence in education out of the box:\\neducational cobots and smart classrooms,'' int. j. artif. intell. edu. , vol. 26,\\nno. 2, pp. 701\\x15712, jan. 2016.[8] h. snyder, ``literature review as a research methodology: an overview and\\nguidelines,'' j. bus. res. , vol. 104, pp. 333\\x15339, nov. 2019.\\n[9] y. fang, p. chen, g. cai, f. c. m. lau, s. c. liew, and g. han, ``outage-\\nlimit-approaching channel coding for future wireless communications:\\nroot-protograph low-density parity-check codes,'' ieee veh. technol.\\nmag. , vol. 14, no. 2, pp. 85\\x1593, jun. 2019.\\n[10] m. vaismoradi, h. turunen, and t. bondas, ``content analysis and\\nthematic analysis: implications for conducting a qualitative descriptive\\nstudy,'' nursing health sci. , vol. 15, no. 3, pp. 398\\x15405, mar. 2013.\\n[11] m. chassignol, a. khoroshavin, a. klimova, and a. bilyatdinova, ``arti-\\n\\x1ccial intelligence trends in education: a narrative overview,'' procedia\\ncomput. sci. , vol. 136, pp. 16\\x1524, jan. 2018.\\n[12] v. rus, s. d'mello, x. hu, and a. graesser, ``recent advances in conver-\\nsational intelligent tutoring systems,'' ai mag. , vol. 34, no. 3, pp. 42\\x1554,\\nsep. 2013.\\n[13] r. c. sharma, p. kawachi, and a bozkurt, ``the landscape of arti\\x1ccial\\nintelligence in open, online and distance education: promises and con-\\ncerns,'' asian j. distance educ. , vol. 14, no. 2, pp. 1\\x152, 2019.\\n[14] s. pokrivcakova, ``preparing teachers for the application of ai-powered\\ntechnologies in foreign language education,'' j. lang. cultural edu. , vol. 7,\\nno. 3, pp. 135\\x15153, dec. 2019.\\n[15] t. a. mikropoulos and a. natsis, ``educational virtual environments:\\na ten-year review of empirical research (1999\\x152009),'' comput. edu. ,\\nvol. 56, no. 3, pp. 769\\x15780, apr. 2011.\\n[16] (2019). united nations education scienti\\x1cc and cultural organi-\\nzation (unesco). how can arti\\x1ccial intelligence enhance educa-\\ntion? [online]. available: https://en.unesco.org/news/how-can-arti\\x1ccial-\\nintelligence-enhance-education\\n[17] s. a. wartman and c. d. combs, ``medical education must move from the\\ninformation age to the age of arti\\x1ccial intelligence,'' acad. med. , vol. 93,\\nno. 8, pp. 1107\\x151109, aug. 2018.\\n[18] h. t. kahraman, s. sagiroglu, and i. colak, ``development of adaptive and\\nintelligent web-based educational systems,'' in proc. 4th int. conf. appl.\\ninf. commun. technol. , oct. 2010, pp. 1\\x155.\\n[19] r. peredo, a. canales, a. menchaca, and i. peredo, ``intelligent web-\\nbased education system for adaptive learning,'' expert syst. appl. , vol. 38,\\nno. 12, pp. 14690\\x1514702, nov. 2011.\\n[20] p. phobun and v. j. , ``adaptive intelligent tutoring systems for e-learning\\nsystems,'' procedia-social behav. sci. , vol. 2, no. 2, pp. 4064\\x154069,\\n2010.\\n[21] i. roll and r. wylie, ``evolution and revolution in arti\\x1ccial intelligence\\nin education,'' int. j. artif. intell. edu. , vol. 26, no. 2, pp. 582\\x15599,\\nfeb. 2016.\\n[22] surjandy, w. suparta, a. trisetyarso, c. h. kang, and b. s. abbas, ``ward-\\ning off the plagiarism with the applications (case study at bina nusantara\\nuniversity student and faculty member),'' in proc. int. conf. inf. commun.\\ntechnol. (icoiact) , mar. 2018, pp. 511\\x15514.\\n[23] h. sutton, ``minimize online cheating through proctoring, consequences,''\\nrecruiting retaining adult learners , vol. 21, no. 5, pp. 1\\x155, jan. 2019.\\n[24] d. crowe, m. lapierre, and m. kebritchi, ``knowledge based arti\\x1ccial\\naugmentation intelligence technology: next step in academic instructional\\ntools for distance learning,'' techtrends , vol. 61, no. 5, pp. 494\\x15506,\\njul. 2017.\\n[25] r. f. murphy, ``arti\\x1ccial intelligence applications to support\\nk\\x151 2 teachers and teaching,'' rand corp., santa monica, ca,\\nusa, tech. rep. pe135, 2019, doi: 10.7249/pe315.\\n[26] s. kiesler, r. e. kraut, k. r. koedinger, v. aleven, and b. m. mclaren,\\n``gami\\x1ccation in education: what, how, why bother,'' academic exchange\\nquarterly , vol. 15, no. 2, pp. 1\\x155, 2011.\\n[27] n. t. le, s. strickroth, s. gross, and n. pinkwart, ``a review of ai-\\nsupported tutoring approaches for learning programming,'' in advanced\\ncomputational methods for knowledge engineering . heidelberg,\\ngermany: springer, 2013.\\n[28] m. saerbeck, t. schut, c. bartneck, and m. d. janse, ``expressive robots\\nin education: varying the degree of social supportive behavior of a robotic\\ntutor,'' in proc. 28th int. conf. hum. factors comput. syst. (chi) , 2010,\\npp. 1613\\x151622.\\n[29] w. u. weiguo, ``research progress of humanoid robots for mobile oper-\\nation and arti\\x1ccial intelligence,'' j. harbin inst. technol. , vol. 47, no. 7,\\npp. 1\\x1519, 2015.\\n[30] t. belpaeme, j. kennedy, a. ramachandran, b. scassellati, and f. tanaka,\\n``social robots for education: a review,'' sci. robot. , vol. 3, no. 21,\\naug. 2018, art. no. eaat5954.\\nvolume 8, 2020 75277\",\n",
       " \"l. chen et al. : ai in education: a review\\n[31] c. w. chang, j. h. lee, p. y. chao, c. y. wang, and g. d. chen, ``explor-\\ning the possibility of using humanoid robots as instructional tools for\\nteaching a second language in primary school,'' j. educ. technol. soc. ,\\nvol. 13, no. 2, pp. 13\\x1524, 2015.\\n[32] s. serholt, c. a. basedow, w. barendregt, and m. obaid, ``comparing\\na humanoid tutor to a human tutor delivering an instructional task to\\nchildren,'' in proc. ieee-ras int. conf. humanoid robots , nov. 2014,\\npp. 1134\\x151141.\\n[33] a. jones and g. castellano, ``adaptive robotic tutors that support self-\\nregulated learning: a longer-term investigation with primary school chil-\\ndren,'' int. j. social robot. , vol. 10, no. 3, pp. 357\\x15370, jan. 2018.\\n[34] a. jones, s. bull, and g. castellano, ```i know that now, i'm going to learn\\nthis next' promoting self-regulated learning with a robotic tutor,'' int. j.\\nsocial robot. , vol. 10, no. 4, pp. 439\\x15454, 2018.\\n[35] j. p. rowe, l. r. shores, b. w. mott, and j. c. lester, ``integrating\\nlearning, problem solving, and engagement in narrative-centered learning\\nenvironments,'' int. j. artif. intell. educ. , vol. 21, nos. 1\\x152, pp. 115\\x15133,\\n2011.\\n[36] s. d'mello, b. lehman, j. sullins, r. daigle, r. combs, k. vogt, and\\na. graesser, ``a time for emoting: when affect-sensitivity is and isn't\\neffective at promoting deep learning,'' in proc. int. conf. intell. tutoring\\nsyst. berlin, germany: springer, jun. 2010.\\n[37] a. ignatov, r. timofte, w. chou, k. wang, m. wu, t. hartley, and\\nl. van gool, ``ai benchmark: running deep neural networks on android\\nsmartphones,'' in proc. eccv workshops , 2018, pp. 288\\x15314.\\n[38] j. hu, l. shen, and g. sun, ``squeeze-and-excitation networks,'' in proc.\\nconf. comput. vis. pattern recognit. (cvpr) , 2018, pp. 7132\\x157141.\\n[39] s. nunn, j. t. avella, t. kanai, and m. kebritchi, ``learning analytics\\nmethods, bene\\x1cts, and challenges in higher education: a systematic lit-\\nerature review,'' online learn. , vol. 20, no. 2, pp. 1\\x1517, jan. 2016.\\n[40] t. yi-shan and d. gasevic, ``learning analytics in higher education\\x16\\nchallenges and policies: a review of eight learning analytics policies,''\\ninproc. 7th int. learn. anal. knowl. conf. mar. 2017, pp. 233\\x15242.\\n[41] j. estevez, g. garate, and m. graña, ``gentle introduction to arti\\x1ccial\\nintelligence for high-school students using scratch,'' ieee access , vol. 7,\\npp. 179027\\x15179036, 2019.\\n[42] d. ku£ak, v. juri£i¢, and g. dambi¢, ``machine learning in education-a\\nsurvey of current research trends,'' in proc. 29th int. daaam symp. , 2018,\\npp. 406\\x15410.\\n[43] y. kim, t. soyata, and r. f. behnagh, ``towards emotionally aware\\nai smart classroom: current issues and directions for engineering and\\neducation,'' ieee access , vol. 6, pp. 5308\\x155331, 2018.\\n[44] global development of ai-based education , deloitte res., deloitte china,\\ndeloitte company, 2019.\\n[45] p.-h. lin, a. wooders, j. t.-y. wang, and w. m. yuan, ``arti\\x1ccial intel-\\nligence, the missing piece of online education?'' ieee eng. manag. rev. ,\\nvol. 46, no. 3, pp. 25\\x1528, sep. 2018.\\nlijia chen received the b.s. and m.s. degrees\\nin \\x1cne arts and designs from jiangxi normal uni-\\nversity, jiangxi, china, in 2011 and 2014, respec-\\ntively. she is currently an assistant professor\\nwith yango university. her researches include art,\\ndesign, education, and the advanced digital tech-\\nniques. she has published more than 20 journals\\nin the related design and art \\x1celds.\\npingping chen (member, ieee) received the\\nph.d. degree in electronic engineering, xiamen\\nuniversity, china, in 2013. from may 2012 to\\nseptember 2012, he was a research assistant in\\nelectronic and information engineering with the\\nhong kong polytechnic university, hong kong.\\nfrom january 2013 to january 2015, he was a\\npostdoctoral fellow with the institute of network\\ncoding, chinese university of hong kong, hong\\nkong. he is currently a professor with fuzhou\\nuniversity, china. his primary research interests include arti\\x1ccial intelli-\\ngence, wireless communication, and computer communions.\\nzhijian lin (member, ieee) received the b.s.,\\nm.s., and ph.d. degrees in communication engi-\\nneering from xiamen university, xiamen, china,\\nin 2008, 2011, and 2017, respectively. in 2016, he\\nwas a visiting scholar with the university of nc\\nstate, raleigh, nc, usa. he is currently working\\nas an assistant professor with the department of\\nelectronic and information engineering, fuzhou\\nuniversity, china. his current research interests\\ninclude d2d communications, d2d caching, and\\nnoma.\\n75278 volume 8, 2020\",\n",
       " 'müller, vincent c. and bostrom, nick (2016), ‘future progress in artificial intelligence: \\na survey  of expert opinion’, in vincent c. müller (ed.), fundamental issues of artificial  \\nintelligence (synthese library ; berlin: springer ), 553-571.\\n[a short version of this paper appeared as (2014) ‘future progress in artificial intelli-\\ngence: a poll among experts’, ai matters, 1 (1), 9-1 1.]  \\nhttp://www.sophia.de \\nhttp://orcid.org/0000-0 002-4 144-4 957  \\n future progress in artificial intelligence: \\na survey of expert opinion \\nvincent c. müller  a,b & nick bostrom  a \\na) future of humanity institute, department of philosophy & oxford martin school,\\nuniversity of oxford. b)anat olia college/act, thessaloniki  \\nabstract:  there is, in  some  quarters, concern  about high– level machine \\nintelligence and superintelligent ai coming up in a few decades, bring-\\ning with it significant risks for humanity . in other quarters, these issues \\nare ignored or considered science fiction . we wanted to clarify what the \\ndistribution of opinions actually is, what probability the best experts \\ncurrently assign to high– level machine intelligence coming up within a \\nparticular time –frame , which risks they see with that development , and \\nhow fast they see these  developing . we thus designed a  brief questio n-\\nnaire and distributed it to four groups of experts  in 2012/2013 . the \\nmedian estimate of respondents was for a one in two  chance that high-\\nlevel machine intelligence will be developed around  2040- 2050, rising \\nto a nine in ten chance by 2075 . experts expect that systems will move \\non to superintelligence in less than 30  years thereafter . they estimate \\nthe chance  is about one in three that this development turns out to be \\n‘bad’ or ‘extremely bad’ for hu manity . \\n1.introduction\\nartificial intelligence began with the “… conjecture that every aspect of learning or \\nany other feature of intelligence can in principle be so precisely described that a ma-\\nchine can be made to simulate it. ” (mccarthy, minsky, roch ester, & shannon, 1955, \\np. 1) and moved swiftly from this vision to grand promises for general human -level ai \\nwithin a few  decades . this vision of general ai has now become merely a long -term \\nguiding idea for most current ai research, which focuses on spe cific scientific and e n-\\ngineering problems and maintains a distance to the cognitive sciences. a small minor i-\\nty believe the moment has come to pursue general ai directly as a technical aim with the traditional methods – these typically use the label ‘ artifi cial general intelligence’ \\n(agi) (see adams et al., 2012) . ',\n",
       " 'future progress in artificial intelligence: a poll among experts 2/19 \\n if general ai were to be achieved, this might also lead to superintelligence: “we can tentatively define a superintelligence as any intellect that greatly exceeds the cognitive per-formance of humans in virtually all domains of interest.” (bostrom, 2014 ch. 2). one idea how superintelligence might come about is that if we humans could create artificial general intelligent ability at a roughly human level, then this creation could, in turn, create yet higher intelligence, which could, in turn, create yet higher intelligence, and so on … so we might generate a growth well beyond human ability and perhaps even an ac-celerating rate of growth: an ‘intelligence explosion’. two main questions about this development are when to expect it, if at all (see bostrom, 2006; hubert  l. dreyfus, 2012; kurzweil, 2005) and what the impact of it would be, in particular which risks it might entail, possibly up to a level of existential risk for humanity (see bostrom, 2013; müller, 2014a). as hawking et al. say “success in creating ai would be the biggest event in human history. unfortunately, it might also be the last, unless we learn how to avoid the risks.” (hawking, russell, tegmark, & wilczek, 2014; cf. price, 2013). so, we decided to ask the experts what they predict the future holds – knowing that predictions on the future of ai are often not too accurate (see armstrong, sotala, & o heigeartaigh, 2014) and tend to cluster around ‘in 25 years or so’, no matter at what point in time one asks.1   2. questionnaire 2.1. respondents the questionnaire was carried out online by invitation to particular individuals from four different groups for a total of ca. 550 participants (see appendix 2). each of the participants got an email with a unique link to our site to fill in an online form (see appendix 1). if they did not respond within 10 days, a reminder was sent, and another 10 days later, with the note that this is the last reminder. in the case of eetn (see below) we could not obtain the individual email addresses and thus sent the request and reminders to the members’ mailing list. responses were made on a single web page with one ‘submit’ button that only allowed submissions through these unique links, thus making non–invited responses extremely unlikely. the groups we asked were: 1. pt–ai: participants of the conference on “philosophy and theory of ai”, thessaloniki october 2011, organized by one of us (see müller, 2012, 2013).                                                              1 there is a collection of predictions on http://www.neweuropeancentury.org/siai-fhi_ai_predictions.xls  2 a further, more informal, survey was conducted in august 2007 by bruce j klein (then of novamente and the singularity institute) “… on the time–frame for when we may see greater–than–human level ai”, with a few numerical results and interesting comments, archived on ',\n",
       " 'future progress in artificial intelligence: a poll among experts 3/19 \\n participants were asked in november 2012, i.e. over a year after the event. the total of 88 participants include a workshop on “the web and philoso-phy” (ca. 15 people), from which a number of non–respondents came. a list of participants is on: http://www.pt–ai.org/2011/registered–participants 2. agi: participants of the conferences of “artificial general intelligence” (agi 12) and “impacts and risks of artificial general intelligence” (agi impacts 2012), both oxford december 2012. we organized agi–impacts (see müller, 2014b) and hosted agi 12. the poll was announced at the meeting of 111 participants (of which 7 only for agi–impacts) and carried out ca. 10 days later. the conference site is at: http://www.winterintelligence.org/oxford2012/ 3. eetn: members of the greek association for artificial intelligence (eetn), a professional organization of greek published researchers in the field, in april 2013. ca. 250 members. the request was sent to the mailing list. the site of eetn: http://www.eetn.gr/  4. top100: the 100 ‘top authors in artificial intelligence’ by ‘citation’ in ‘all years’ according to microsoft academic search (http://academic.research.microsoft.com) in may 2013. we reduced the list to living authors, added as many as necessary to get back to 100, searched for professional e–mails on the web and sent notices to these.   the questionnaire was sent with our names on it and with an indication that we would use it for this paper and nick bostrom’s new book on superintelligence (bostrom, 2014) – our request email is in appendix 1. given that the respondent groups 1 and 2 attended conferences organized by us, they knew whom they were responding to. in groups 3 and 4 we would assume that the majority of experts would not know us, or even of us. these differences are reflected in the response rates. these groups have different theoretical-ideological backgrounds: the partici-pants of pt–ai are mostly theory–minded, mostly do not do technical work, and of-ten have a critical view on large claims for easy progress in ai (herbert dreyfus was a keynote speaker in 2011). the participants of agi are committed to the view that ai research should now return from technical details to ‘artificial general intelligence’ – thus the name agi. the vast majority of agi participants do technical work. the eetn is a professional association in greece that accepts only published researchers from ai. the top100 group also works mostly in technical ai; its members are sen-ior and older than the average academic; the usa is strongly represented. several individuals are members of more than one of these four sets and they were unlikely to respond to the same questionnaire more than once. so, in these cases, we sent the query only once, but counted a response for each set – i.e. we knew which ',\n",
       " 'future progress in artificial intelligence: a poll among experts 4/19 \\n individuals responded from the individual tokens they received (except in the case of eetn). 2.2. response rates 1) pt–ai: 49% 43 out of 88 2) agi: 65% 72 out of 111 3) eetn: 10% 26 out of 250 4) top100: 29% 29 out of 100 total: 31% 170 out of 549 2.3. methodology in this field, it is hard to ask questions that do not require lengthy explanations or generate resistance in certain groups of potential respondents (and thus biased results). it is not clear what constitutes ‘intelligence’ or ‘progress’ and whether intelligence can be measured or at least compared as ‘more’ or ‘less’ as a single dimension. further-more, for our purposes we need a notion of intelligence at a level that may surpass humans or where technical intelligent systems might contribute significantly to re-search – but ‘human–level intelligence’ is a rather elusive notion that generates re-sistance. finally, we need to avoid using terms that are already in circulation and would thus associate the questionnaire with certain groups or opinions, like “artificial intelligence”, “singularity”, “artificial general intelligence” or “cognitive system”. for these reasons, we settled for a definition that a) is based on behavioral ability, b) avoids the notion of a general ‘human–level’ and c) uses a newly coined term. we put this definition in the preamble of the questionnaire: “define a ‘high–level machine intelligence’ (hlmi) as one that can carry out most human professions at least as well as a typical human.” (we still had one expert writing back to us that they could not say what a ‘typical human’ is – though they could be convinced to respond, after all.) in hindsight, it may have been preferable to specify what we mean by ‘most’ and wheth-er we think of ‘most professions’ or of ‘the professions most working people do’. one merit of our behavioral question is that having hlmi in our sense very likely implies being able to pass a classic turing test. to achieve a high response rate, we tried to have few questions with simple choices and eventually settled for four questions, plus three on the respondents. we tried to choose questions that would allow us to compare our results with those of ear-lier questionnaires – see below. in order to improve on the quality of predictions, we tried to ‘prime’ respondents into thinking about what is involved in reaching hlmi before asking when they expect this. we also wanted to see whether people with a preference for particular approach-es to hlmi would have particular responses to our central questions on prediction (e.g. whether people who think that ‘embodied systems’ are crucial expect longer than ',\n",
       " 'future progress in artificial intelligence: a poll among experts 5/19 \\n average time to hlmi). for these two purposes, we inserted a first question about contributing research approaches with a list to choose from – the options that were given are an eclectic mix drawn from many sources, but the particular options are not of much significance. 2.4. prior work a few groups have recently made attempts to gauge opinions. we tried to phrase our questions such that the answers can be compared to these earlier questionnaires. no-table are:  1. (michie, 1973, p. 511f): “an opinion poll taken last year among sixty-seven british and american computer scientists working in, or close to, the ma-chine intelligence field”. 2. questions asked live during the 2006 ai@50 conference at dartmouth col-lege through a wireless voting device (vcm participated (see müller, 2007)). despite a short report on the conference in (moor, 2006), the results were not published, but thankfully we were able to acquire them from the organ-izers james h. moor and carey e. heckman – we publish a selection below. 3. (baum, goertzel, & goertzel, 2011): participants of agi 2009, not anony-mous, on paper, 21 respondents, response rate unknown.2 4. (sandberg & bostrom, 2011): participants of winter intelligence conference 2011, anonymous, on paper, 35 respondents, 41% response rate. 1. the reference by the famous ai researcher donald michie is very brief (all the de-tails he gives are in the above quote) but of great of historical interest: 1972/3 were turning years for ai with the publication of hubert dreyfus’ “what computers can’t do” (hubert l. dreyfus, 1972), the “lighthill debates” on bbc tv (with michie, mccarthy and r. gregory) and the influential “lighthill report” (lighthill, 1973). michie’s poll asked for the estimated number of years before “computing exhibiting intelligence at adult human level” and michie’s graph shows 5 data points: \\n                                                             2 a further, more informal, survey was conducted in august 2007 by bruce j klein (then of novamente and the singularity institute) “… on the time–frame for when we may see greater–than–human level ai”, with a few numerical results and interesting comments, archived on https://web.archive.org/web/20110226225452/http://www.novamente.net/bruce/?p=54.  ',\n",
       " 'future progress in artificial intelligence: a poll among experts 6/19 \\n years percentage 5 0% 10 1% 20 17% 50 19% >50 25% he also asked about “significant industrial spin-off”, “contributions to brain studies” and “contributions from brain studies to machine intelligence”. michie adds “of those responding to a question on the risk of ultimate ‘takeover’ of human affairs by intelligent machines, about half regarded it as ‘negligible’, and most of the remainder as ‘substantial’, with a view voting for ‘overwhelming’.” (michie, 1973, p. 512). 2. ai@50 hosted many prominent ai researchers, including all living participants of the 1956 dartmouth conference, a set of darpa-funded graduate students, plus a few theoreticians. the participants were asked 12 multiple choice questions on day one, 17 on day two and another 10 on day three. we select three results from day one here: 3.) the earliest that machines will be able to simulate learning and every other aspect of human intelligence:  within 10 years 6 5% between 11 and 25 years 3 2% between 26 and 50 years 14 11% more than 50 years 50 41% never 50 41% totals 123 100%    5.) the earliest we will understand the basic operations (mental steps) of the human brain sufficiently to create machine simulation of human thought is: today (we already understand enough) 5 6% within the next 10 years 11 12% within the next 25 years 9 10% within the next 50 years 19 21% within the next 100 years or more 26 29% never (we will never understand enough) 19 21% totals 89 100%    6.) the earliest we will understand the architecture of the brain (how its organi-zational control is structured) sufficiently to create machine simulation of hu-man thought is: within 10 years 12 11% ',\n",
       " 'future progress in artificial intelligence: a poll among experts 7/19 \\n between 11 and 25 years 15 14% between 26 and 50 years 24 22% more than 50 years 44 40% never 15 14% totals 110 100%  3. baum et al. asked for the ability to pass a turing test, a third grade school year ex-am [i.e. for 9 year olds] and do nobel prize level research. they assume that all and only the intelligent behavior of humans is captured in the turing test. the results they got for the 50% probability point were: 2040 (turing test), 2030 (third grade), and 2045 (nobel).  4. sandberg and bostrom’s first question was quite similar to our 2nd (see below): “assuming no global catastrophe halts progress, by what year would you assign a 10%/50%/90% chance of the development of human–level machine intelligence?” the median estimate of when there will be 50% chance of human–level machine in-telligence was 2050. so, despite significant overlap with agi 2009, the group asked by sandberg and bostrom in 2011 was a bit more guarded in their expectations. we think it is worthwhile to make a new attempt because the prior ones asked specific groups and small samples, sometimes have methodological problems, and we also want to see how the answers change over time, or do not change – which is why tried to use similar questions. as explained below, we also think it might be worth-while to repeat our questionnaire at a later stage, to compare results. 3.  questions & responses 3.1. research approaches “1. in your opinion, what are the research approaches that might contribute the most to the development of such hlmi?” [selection from list, more than one selection pos-sible.] − algorithmic complexity theory − algorithms revealed by computational neuroscience − artificial neural networks − bayesian nets − cognitive science − embodied systems − evolutionary algorithms or systems − faster computing hardware − integrated cognitive architectures ',\n",
       " 'future progress in artificial intelligence: a poll among experts 8/19 \\n − large–scale datasets − logic–based systems − robotics − swarm intelligence − whole brain emulation − other method(s) currently known to at least one investigator − other method(s) currently completely unknown − no method will ever contribute to this aim  cognitive science 47.9% integrated cognitive architectures 42.0% algorithms revealed by computational neuroscience 42.0% artificial neural networks 39.6% faster computing hardware 37.3% large-scale datasets 35.5% embodied systems 34.9% other method(s) currently completely unknown 32.5% whole brain emulation 29.0% evolutionary algorithms or systems 29.0% other method(s) currently known to at least one investigator 23.7% logic-based systems 21.3% algorithmic complexity theory 20.7% no method will ever contribute to this aim 17.8% swarm intelligence 13.6% robotics 4.1% bayesian nets 2.6%  the percentages here are over the total of responses. there were no significant differ-ences between groups here, except that ‘whole brain emulation’ got 0% in top100, but 46% in agi. we did also not find relevant correlations between the answers given here and the predictions made in the following questions (of the sort that, for example, people who think ‘embodied systems’ crucial would predict later onset of hlmi).  ',\n",
       " 'future progress in artificial intelligence: a poll among experts 9/19 \\n   3.2. when hlmi? “2. for the purposes of this question, assume that human scientific activity continues without major negative disruption. by what year would you see a (10% / 50% / 90%) probability for such hlmi to exist?” – for each of these three probabilities, the re-spondents were asked to select a year [2012–5000, in one-year increments] or check a box marked ‘never’.  results sorted by groups of respondents: pt-ai median mean st. dev. 10% 2023 2043 81 50% 2048 2092 166 90% 2080 2247 515 agi median mean st. dev. 10% 2022 2033 60 50% 2040 2073 144 90% 2065 2130 202 eetn median mean st. dev. 00%\\r10%\\r20%\\r30%\\r40%\\r50%\\r60%\\rbayesian nets\\rrobotics\\rswarm intelligence\\rno method will ever contribute to this algorithmic complexity theory\\rlogic-based systems\\rother method(s) currently known to at evolutionary algorithms or systems\\rwhole brain emulation\\rother method(s) currently completely embodied systems\\rlarge-scale datasets\\rfaster computing hardware\\rartiﬁcial neural networks\\ralgorithms revealed by computational integrated cognitive architectures\\rcognitive science\\r',\n",
       " 'future progress in artificial intelligence: a poll among experts 10/19 \\n 10% 2020 2033 29 50% 2050 2097 200 90% 2093 2292 675 top100 median mean st. dev. 10% 2024 2034 33 50% 2050 2072 110 90%: 2070 2168 342 all median mean st. dev. 10%: 2022 2036 59 50%: 2040 2081 153 90%: 2075 2183 396  results sorted by percentage steps: 10% median mean st. dev. pt-ai 2023 2043 81 agi 2022 2033 60 eetn 2020 2033 29 top100 2024 2034 33 all 2022 2036 59 50% median mean st. dev. pt-ai 2048 2092 166 agi 2040 2073 144 eetn 2050 2097 200 top100 2050 2072 110 all 2040 2081 153 90% median mean st. dev. pt-ai 2080 2247 515 agi 2065 2130 202 eetn 2093 2292 675 top100 2070 2168 342 all 2075 2183 396  ',\n",
       " 'future progress in artificial intelligence: a poll among experts 11/19 \\n clicks of the ‘never’ box. these answers did not enter in to the averages above. never no. % 10% 2 1.2 50% 7 4.1 90% 28 16.5  \\n  for the 50% mark, the overall median is 2040 (i.e. half of the respondents gave a year earlier than 2040 and half gave a year later than 2040) but the overall mean (average) is 2081. the median is always lower than the mean here because there cannot be out-liers towards ‘earlier’ but there are outliers towards ‘later’ (the maximum possible se-lection was 5000, then ‘never’). 3.3. from hlmi to superintelligence “3. assume for the purpose of this question that such hlmi will at some point exist.  how likely do you then think it is that within (2 years / 30 years) thereafter there will be machine intelligence that greatly surpasses the performance of every human in most professions?” – respondents were asked to select a probability from a drop-down menu in 1% increments, starting with 0%.  \\n0\\r0.1\\r0.2\\r0.3\\r0.4\\r0.5\\r0.6\\r0.7\\r0.8\\r0.9\\r1\\r\\n2000\\r2050\\r2100\\r2150\\r2200\\r2250\\r2300\\rproportion of  experts with 10% 50% 90% conﬁdence of  hlmi by that date\\r\\n10%\\r50%\\r90%\\r',\n",
       " 'future progress in artificial intelligence: a poll among experts 12/19 \\n for all respondents:  median mean st. dev. within 2 years 10% 19% 24 within 30 years 75% 62% 35  median estimates on probability of superintelligence given hlmi in different groups of respondents:  2 years 30 years pt-ai 10% 60% agi 15% 90% eetn 5% 55% top100 5% 50%  experts allocate a low probability for a fast takeoff, but a significant probability for superintelligence within 30 years after hlmi. 3.4. the impact of superintelligence “4. assume for the purpose of this question that such hlmi will at some point exist.  how positive or negative would be overall impact on humanity, in the long run?  please indicate a probability for each option. (the sum should be equal to 100%.)” – respondents had to select a probability for each option (in 1% increments). the addi-tion of the selection was displayed; in green if the sum was 100%, otherwise in red. the five options were: “extremely good – on balance good – more or less neutral – on balance bad – extremely bad (existential catastrophe)”.  % pt-ai agi eetn top100 all extremely good 17 28 31 20 24 on balance good 24 25 30 40 28 more or less neutral 23 12 20 19 17 on balance bad 17 12 13 13 13 extremely bad  (existential catastrophe) 18 24 6 8 18  percentages here are means, not medians as in the other tables. there is a notable difference here between the ‘theoretical’ (pt-ai and agi) and the ‘technical’ groups (eetn and top100). 3.5. respondents statistics we then asked the respondents 3 questions about themselves: ',\n",
       " 'future progress in artificial intelligence: a poll among experts 13/19 \\n 1. “concerning the above questions, how would you describe your own exper-tise?” (0 = none, 9 = expert) − mean 5.85 2. “concerning technical work in artificial intelligence, how would you describe your own expertise?” (0 = none, 9 = expert) − mean 6.26 3. “what is your main home academic discipline?” (select from list with 8 op-tions: biology/physiology/neurosciences – computer science – engineering [non cs] – mathematics/physics – philosophy – psychology/cognitive sci-ence – other academic discipline – none.) [absolut numbers.] a. biology/physiology/neurosciences 3 b. computer science 107 c. engineering (non cs) 6 d. mathematics/physics 10 e. philosophy 20 f. psychology/cognitive science 14 g. other academic discipline 9 h. none 1 and we finally invited participants to make a comment, plus a possibility to add their name, if they wished. (we cannot reproduce these here; but they are on our site, see below). a number of comments concerned the difficulty of formulating good ques-tions, much fewer the difficulty of predicting. 4. evaluation 4.1. selection-bias in the respondents? one concern with the selection of our respondents is that people who think hlmi is unlikely, or a confused idea, are less likely to respond (though we pleaded otherwise in the letter, see below). here is a characteristic response from a keynote speaker at pt-ai 2011: “i wouldn’t think of responding to such a biased questionnaire. … i think any discussion of imminent super–intelligence is misguided. it shows no understand-ing of the failure of all work in ai. even just formulating such a questionnaire is bi-ased and is a waste of time.” (hubert dreyfus, quoted with permission). so, we tried to find out what the non-respondents think. to this end, we made a random selection of non-respondents from two groups (11 for pt-ai and 17 from top100) and pressured them via personal email to respond, explaining that this would help us understand bias. the two groups were selected because agi appears already biased in the oppo-site direction and eetn appears very similar to top100 but for eetn we did not ',\n",
       " 'future progress in artificial intelligence: a poll among experts 14/19 \\n have the data to show us who responded and who did not. we got one additional re-sponse from pt-ai and two from top100 in this way.  for question 2 “… by what year would you see a (10% / 50% / 90%) probabil-ity for such hlmi to exist?” we compared the additional responses to the responses we already had from the same respective group (pt-ai and top100, respectively). we found the following differences:  10% 50% 90%  mean median mean median mean median pt-ai -12 +8 -9 +55 -2 +169 top100 -19 -9 -47 -25 -138 -40  the one additional respondent from pt-ai expected hlmi earlier than the mean but later than the median, while the two respondents from top100 (last row) ex-pected hlmi earlier than mean and median. the very small sample forbids confident judgment, but we found no support for the worry that the non-respondents would have been biased towards a later arrival of hlmi. 4.2. lessons and outlook we complement this paper with a small site on http://www.pt-ai.org/ai-polls/. on this site, we provide a) the raw data from our results [anonymous unless the partici-pants decided to put their name on their responses], b) the basic results of the ques-tionnaire, c) the comments made, and d) the questionnaire in an online format where anyone can fill it in. we expect that that online questionnaire will give us an interest-ing view of the ‘popular’ view of these matters and on how this view changes over time. in the medium run, it be interesting to do a longitudinal study that repeats this exact questionnaire. we leave it to the reader to draw their own detailed conclusions from our results, perhaps after investigating the raw data. let us stress, however, that the aim was to ‘gauge the perception’, not to get well-founded predictions. these results should be taken with some grains of salt, but we think it is fair to say that the results reveal a view among experts that ai systems will probably (over 50%) reach overall human ability by 2040-50, and very likely (with 90% probability) by 2075. from reaching human ability, it will move on to superintelligence in 2 years (10%) to 30 years (75%) ',\n",
       " 'future progress in artificial intelligence: a poll among experts 15/19 \\n thereafter. the experts say the probability is 31% that this development turns out to be ‘bad’ or ‘extremely bad’ for humanity. so, the experts think that superintelligence is likely to come in a few decades and quite possibly bad for humanity – this should be reason enough to do research into the possible impact of superintelligence before it is too late. we could also put this more modestly and still come to an alarming conclusion: we know of no compelling reason to say that progress in ai will grind to a halt (though deep new insights might be needed) and we know of no compelling reason that superintelligent systems will be good for humanity. so, we should better investigate the future of superintelligence and the risks it poses for humanity. 5. acknowledgements toby ord and anders sandberg were helpful in the formulation of the questionnaire. the technical work on the website form, sending mails and reminders, database and initial data analysis was done by ilias nitsos (under the guidance of vcm). theo gantinas provided the emails of the top100. stuart armstrong made most graphs for presentation. the audience at the pt-ai 2013 conference in oxford provided helpful feedback. mark bishop, carl shulman, miles brundage and daniel dewey made detailed comments on drafts. we are very grateful to all of them. 6. references adams, s., arel, i., bach, j., coop, r., furlan, r., goertzel, b., . . . sowa, j. f. (2012). mapping the landscape of human-level artificial general intelligence. ai magazine, 33(1), 25-42.  armstrong, s., sotala, k., & o heigeartaigh, s. (2014). the errors, insights and lessons of famous ai predictions – and what they mean for the future. journal of experimental and theoretical artificial intelligence, 26(3 - special issue ‘risks of general artificial intelligence’, ed. v. müller), 317-342.  baum, s. d., goertzel, b., & goertzel, t. g. (2011). how long until human-level ai? results from an expert assessment. technological forecasting & social change, 78(1), 185-195.  bostrom, n. (2006). how long before superintelligence? linguistic and philosophical investigations, 5(1), 11-30.  bostrom, n. (2013). existential risk prevention as global priority. global policy, 4(1), 15-31.  bostrom, n. (2014). superintelligence: paths, dangers, strategies. oxford: oxford university press. dreyfus, h. l. (1972). what computers still can\\'t do: a critique of artificial reason (2 ed.). cambridge, mass.: mit press. dreyfus, h. l. (2012). a history of first step fallacies. minds and machines, 22(2 - special issue \"philosophy of ai\" ed. vincent c. müller), 87-99.  ',\n",
       " 'future progress in artificial intelligence: a poll among experts 16/19 \\n hawking, s., russell, s., tegmark, m., & wilczek, f. (2014). transcendence looks at the implications of artificial intelligence - but are we taking ai seriously enough? the independent, 01.05.2014.  kurzweil, r. (2005). the singularity is near: when humans transcend biology. london: viking. lighthill, j. (1973). artificial intelligence: a general survey artificial intelligence: a paper symposion. london: science research council. mccarthy, j., minsky, m., rochester, n., & shannon, c. e. (1955). a proposal for the dartmouth summer research project on artificial intelligence.   retrieved october 2006, from http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html michie, d. (1973). machines and the theory of intelligence. nature, 241(23.02.1973), 507-512.  moor, j. h. (2006). the dartmouth college artificial intelligence conference: the next fifty years. ai magazine, 27(4), 87-91.  müller, v. c. (2007). is there a future for ai without representation? minds and machines, 17(1), 101-115.  müller, v. c. (2014a). editorial: risks of general artificial intelligence. journal of experimental and theoretical artificial intelligence, 26(3 - special issue ‘risks of general artificial intelligence’, ed. v. müller), 1-5.  müller, v. c. (ed.). (2012). theory and philosophy of ai (minds and machines,  vol. 22/2- special volume): springer. müller, v. c. (ed.). (2013). theory and philosophy of artificial intelligence (sapere,  vol. 5). berlin: springer. müller, v. c. (ed.). (2014b). risks of artificial general intelligence (journal of experimental and theoretical artificial intelligence,  vol. (26/3) special issue): taylor & francis. price, h. (2013). cambridge, cabs and copenhagen: my route to existential risk. the new york times, 27.01.2013. http://opinionator.blogs.nytimes.com/2013/01/27/cambridge-cabs-and-copenhagen-my-route-to-existential-risk/?_php=true&_type=blogs&_r=0 sandberg, a., & bostrom, n. (2011). machine intelligence survey. fhi technial report, 2011(1). http://www.fhi.ox.ac.uk/research/publications/  7. appendices 1. questionnaire 2. letter sent to participants  ',\n",
       " 'future progress in artificial intelligence: a poll among experts 17/19 \\n appendix 1: online questionnaire               \\n large-scale datasets\\n logic-based systems\\n robotics\\n swarm intelligence\\n whole brain emulation\\n other method(s) currently known to at least one investigator\\n other method(s) currently completely unknown\\n no method will ever contribute to this aim10%50%90%year reached:\\n-\\n-\\n-never:\\nwithin 2 yearswithin 30 yearsprobability:\\n-%\\n-%extremely goodon balance goodmore or less neutralon balance badextremely bad (existential catastrophe)\\n- %\\n- %\\n- %\\n- %\\n- %questionnaire: future progress in artificial intelligence(http://www.fhi.ox.ac.uk/) (http://www.futuretech.ox.ac.uk)this brief questionnaire is directed towards researchers in artificial intelligence or the theory ofartificial intelligence. it aims to gauge how people working in the field view progress towards itsoriginal goals of intelligent machines, and what impacts they would associate with reachingthese goals.contribution to this questionnaire is by invitation only. if the questionnaire is filled in withoutsuch an invitation, the data will be disregarded.answers  will  be  anonymized.  results  will  be  made  publicly  available  on  the  site  of  the  programme  on  the  impacts  of  future  technology:http://www.futuretech.ox.ac.uk (http://www.futuretech.ox.ac.uk) .thank you for your time!vincent c. müller (http://www.sophia.de) & nick bostrom (http://www.nickbostrom.com/)university of oxfordseptember 2012a. the future of aidefine a \"high-level machine intelligence\" (hlmi) as one that can carry out most human professions at least as well as a typical human.1. in your opinion, what are the research approaches that might contribute the most to the development of such hlmi?:\\n algorithmic complexity theory\\n algorithms revealed by computational neuroscience\\n artificial neural networks\\n bayesian nets\\n cognitive science\\n embodied systems\\n evolutionary algorithms or systems\\n faster computing hardware\\n integrated cognitive architectures2. assume for the purpose of this question that human scientific activity continues without major negative disruption. by what year wouldyou see a 10%/50%/90% probability for such hlmi to exist?\\n   3. assume for the purpose of this question that such hlmi will at some point exist. how likely do you then think it is that within (2 years / 30years) thereafter, there will be machine intelligence that greatly surpasses the performance of any human in most professions? 4. assume for the purpose of this question that such hlmi will at some point exist. how positive or negative would be the overall impact onhumanity, in the long run? please indicate a probability for each option. (the sum should be equal to 100%.) \\n total: 0%questionnaire: future progress in artiﬁcial intelligence | phil...http://www.pt-ai.org/questionnaire-future-progress-artiﬁcial-in...\\n1 of 226.11.12 10:29  oez',\n",
       " 'future progress in artificial intelligence: a poll among experts 18/19 \\n  \\n 0 = none\\n 1\\n 2\\n 3\\n 4\\n 5\\n 6\\n 7\\n 8\\n 9 = expert1. concerning the above questions, how would you describe your own expertise?:\\n 0 = none\\n 1\\n 2\\n 3\\n 4\\n 5\\n 6\\n 7\\n 8\\n 9 = expert2. concerning technical work in artificial intelligence, how would you describe your own expertise?:b. about you\\n 3. what is your main home academic discipline?:\\n biology/physiology/neurosciences\\n computer science\\n engineering (non cs)\\n mathematics/physics\\n philosophy\\n psychology/cognitive science\\n other academic discipline\\n none 4. add a brief comment, if you like (<250 words). these comments may be published. please indicate whether you would like your name tobe included with the comment. (the answers above will remain anonymous in any case.):\\ntotal word count : 0please include my name with the comment (leave this field empty if you wish to remain anonymous):\\ncaptchathis question is for testing whether you are a human visitor and to prevent automated spam submissions.\\nwhat code is in the image?: *\\nenter the characters shown in the image.\\nsubmitquestionnaire: future progress in artiﬁcial intelligence | phil...http://www.pt-ai.org/questionnaire-future-progress-artiﬁcial-in...\\n2 of 226.11.12 10:29  oez',\n",
       " \"future progress in artificial intelligence: a poll among experts 19/19 \\n  appendix 2: letter to participants (here top100)  dear professor [surname], given your prominence in the field of artificial intelligence we invite you to express your views on the future of artificial intelligence in a brief questionnaire. the aim of this exercise is to gauge how the top 100 cited people working in the field view pro-gress towards its original goals of intelligent machines, and what impacts they would associate with reaching these goals. the questionnaire has 4 multiple choice questions, plus 3 statistical data points on the respondent and an optional 'comments' field. it will only take a few minutes to fill in. of course, this questionnaire will only reflect the actual views of researchers if we get nearly everybody to express their opinion. so, please do take a moment to respond, even (or especially) if you think this exercise is futile or misguided. answers will be anonymous. results will be used for nick bostrom's forthcoming book “superintelligence: paths, dangers, strategies” (oxford university press, 2014) and made publicly available on the site of the programme on the impacts of future tech-nology: http://www.futuretech.ox.ac.uk.  please click here now: [link]  thank you for your time!  nick bostrom & vincent c. müller university of oxford \",\n",
       " 'proceedings of machine learning for healthcare 2016 jmlr w&c track volume 56\\ndoctor ai: predicting clinical events\\nvia recurrent neural networks\\nedward choi, mohammad taha bahadori mp2893,bahadori@gatech.edu\\ncollege of computing\\ngeorgia institute of technology\\natlanta, ga, usa\\nandy schuetz, walter f. stewart schueta1,stewarwf@sutterhealth.org\\nresearch development & dissemination\\nsutter health\\nwalnut creek, ca, usa\\njimeng sun jsun@cc.gatech.edu\\ncollege of computing\\ngeorgia institute of technology\\natlanta, ga, usa\\nabstract\\nleveraging large historical data in electronic health record (ehr), we developed doctor ai, a\\ngeneric predictive model that covers observed medical conditions and medication uses. doctor\\nai is a temporal model using recurrent neural networks (rnn) and was developed and applied\\nto longitudinal time stamped ehr data from 260k patients and 2,128 physicians over 8 years.\\nencounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to rnn\\nto predict (all) the diagnosis and medication categories for a subsequent visit. doctor ai assesses\\nthe history of patients to make multilabel predictions (one label for each diagnosis or medication\\ncategory). based on separate blind test set evaluation, doctor ai can perform di\\x0berential diagnosis\\nwith up to 79% recall@30, signi\\x0ccantly higher than several baselines. moreover, we demonstrate\\ngreat generalizability of doctor ai by adapting the resulting models from one institution to another\\nwithout losing substantial accuracy.\\n1. introduction\\na common challenge in healthcare today is that physicians have access to massive amounts of\\ndata on patients, but little time nor tools. intelligent clinical decision support anticipates the\\ninformation at the point of care that is speci\\x0cc to the patient and provider needs. electronic health\\nrecords (ehr), now commonplace in u.s. healthcare, represent the longitudinal experience of both\\npatients and doctors. these data are being used with increasing frequency to predict future events.\\nwhile predictive models have been developed to anticipate needs, most existing work has focused on\\nspecialized predictive models that predict a limited set of outcomes. however, day-to-day clinical\\npractice involves an unscheduled and heterogeneous mix of scenarios and needs di\\x0berent prediction\\nmodels in the hundreds to thousands. it is impractical to develop and deploy specialized models\\none by one.\\nleveraging large historical data in ehr, we developed doctor ai, a generic predictive model\\nthat covers observed medical conditions and medication uses. doctor ai is a temporal model using\\nrecurrent neural networks (rnn) and was developed and applied to longitudinal time stamped\\nehr data. in this work, we are particularly interested in whether historical ehr data may be\\nused to predict future physician diagnoses and medication orders. applications that accurately\\nc\\r2016.',\n",
       " 'forecast could have many uses such as anticipating the patient status at the time of visit and\\npresenting data a physician would want to see at the moment. the primary goal of this study was\\nto use longitudinal patient visit records to predict the physician diagnosis and medication order of\\nthe next visit. as a secondary goal we predicted the time to the patients next visit. predicting the\\nvisit time facilitates guidance of whether a patient may be delayed in seeking care.\\nthe two tasks addressed in this work are di\\x0berent from sequence labeling tasks often seen in\\nnatural language processing applications, e.g., part-of-speech tagging. our proposed model, doctor\\nai, performs multilabel prediction (one for each disease or medication category) over time while\\nsequence labeling task predicts a single label at each step. the key challenge was \\x0cnding a \\rexible\\nmodel that is capable of performing the multilabel prediction problem. the two main classes of\\ntechniques have been proposed in dealing with temporal sequences: 1) continuous-time markov\\nchain based models (nodelman et al., 2002; lange et al., 2015; johnson and willsky, 2013), and 2)\\nintensity based point process modeling techniques such as hawkes processes (liniger, 2009; zhu,\\n2013; choi et al., 2015). however, both classes are expensive to compute, especially for nonlinear\\nsettings. furthermore, they often make strong assumptions about the data generation process which\\nmight not be valid for ehr data. our modeling strategy was to develop a generalized approach\\nto representing patient temporal healthcare experience to predict all the diagnoses, medication\\ncategories and visit time. we used recurrent neural network (rnn), considering that rnns have\\nbeen particularly successful for representation learning in sequential data, e.g. graves (2013);\\ngraves and jaitly (2014); sutskever et al. (2014); kiros et al. (2014); zaremba and sutskever\\n(2014). in particular, we make the following main contributions in this paper:\\n\\x0fwe demonstrate how rnns can be used to represent the patient status and predict diagnosis,\\nmedication order and visit time. the trained rnn is able to achieve above 64% recall@10 and\\n79% recall@30 for diagnosis prediction, showing potential to serve as a di\\x0berential diagnosis\\nassistance.\\n\\x0fwe propose an initialization scheme for rnns using skip-gram embeddings (mikolov et al.,\\n2013) and show that it improves the performance of the rnn in both accuracy and speed.\\n\\x0fwe empirically con\\x0crm that rnn models possess great potential for transfer learning across\\ndi\\x0berent medical institutions. this suggests that health systems with insu\\x0ecient patient data\\ncan adopt models learned from larger datasets of other health systems to improve prediction\\naccuracy on their smaller population.\\n2. related work\\nin this section, we brie\\ry review the common approaches to modeling multilabel event sequences\\nwith special focus on the models that have been applied to medical data. there are two main\\napproaches to modeling multilabel event sequences: with or without discretization (binning) of\\ntime.\\ndiscretization. when the time axis is discretized, the point process data can be converted\\nto binary time series (or time series of count data if binning is coarse) and analyzed via time\\nseries analysis techniques (truccolo et al., 2005; bahadori et al., 2013; ranganath et al., 2015).\\nhowever, this approach is ine\\x0ecient as it produces long time series whose elements are mostly zero.\\nfurthermore, discretization of time introduces noise in the time stamps of visits. finally, these\\napproaches are often not able to model the duration until next event. thus, it is advantageous not\\nto discretize the data both in terms of modeling and computation.\\n2',\n",
       " \"continuous-time models. among the continuous-time models, there are two main techniques:\\ncontinuous-time markov chain based models (foucher et al., 2007; johnson and willsky, 2013;\\nlange, 2014; liu et al., 2013) and their extension using baysian networks (nodelman et al., 2002;\\nweiss et al., 2012) and intensity function modeling techniques such as cox and hawkes processes\\n(liniger, 2009; zhou et al., 2013; linderman and adams, 2014; choi et al., 2015).\\nintensity function modeling techniques have been shown to have computational advantages over\\nthe continuous-time markov chain based models. moreover, modeling multilabel marked point\\nprocesses with continuous-time markov chains expands their state-space and make them even more\\nexpensive. however, hawkes processes only depend linearly on the past observation times; while\\nthere are limited classes of non-linear hawkes process (zhu, 2013), the temporal dynamics can\\nbe more complex. finally, hawkes processes are known to have a \\rat loss function near optimal\\nvalue of the parameters which renders the gradient-based learning algorithms ine\\x0ecient (veen and\\nschoenberg, 2008). in this paper we address these challenges by designing a recurrent neural\\nnetwork which has been shown to be successful in learning complex sequential patterns.\\ndisease progression models. there have been active research in modeling the temporal pro-\\ngression of diseases (mould, 2012). generally, most works can be divided into two groups: works\\nthat focus on a speci\\x0cc disease and works that focus on a broader range of diseases.\\nspeci\\x0cc-purpose progression modeling: there have been many studies that focus on modeling\\nthe temporal progression of a speci\\x0cc disease based on either intensive use of domain-speci\\x0cc\\nknowledge (de winter et al., 2006; ito et al., 2010; tangri et al., 2011) or taking advantage of\\nadvanced statistical methods (liu et al., 2013; jackson et al., 2003; sukkar et al., 2012; zhou et al.,\\n2012). speci\\x0ccally, studies have been conducted on alzheimer's disease (ito et al., 2010; zhou et al.,\\n2012; sukkar et al., 2012), glaucoma (liu et al., 2013), chronic kidney disease (tangri et al., 2011),\\ndiabetes mellitus (de winter et al., 2006), and abdominal aortic aneurysm (jackson et al., 2003)\\ngeneral-purpose progression modeling: recently, wang et al. (2014); choi et al. (2015); ran-\\nganath et al. (2015) proposed more general approaches to modeling the progression of wider range\\nof diseases. as discussed earlier, choi et al. (2015) used hawkes process, and ranganath et al.\\n(2015) discretized time in order to model multiple patients and multiple diseases. wang et al.\\n(2014) proposed a graphical model based on markov jump process to predict the stage progression\\nof chronic obstructive pulmonary disease (copd) and its co-morbid diseases.\\none of the main challenges in using these algorithms is scalability. the datasets used in previous\\nworks typically contain up to a few thousands of patients and a few hundreds of codes. even the\\nlargest dataset used by ranganath et al. (2015) contains 13,180 patients and 8,722 codes, which\\nis signi\\x0ccantly smaller than our dataset described in table 1. need for domain-speci\\x0cc knowledge\\nis also a big challenge. for example, wang et al. (2014) not only used a smaller dataset (3,705\\npatients and 264 codes) but also used co-morbidity information to improve the performance of their\\nalgorithm. such expert knowledge is di\\x0ecult to obtain from typical ehr data.\\ndeep learning models for ehr. researchers have recently begun attempting to apply neural\\nnetwork based methods (or deep learning) to ehr to utilize its ability to learn complex patterns\\nfrom data. previous studies such as phenotype learning (lasko et al., 2013; che et al., 2015;\\nhammerla et al., 2015) or representation learning (choi et al., 2016b,a; miotto et al., 2016), however,\\nhave not fully addressed the sequential nature of ehr. lipton et al. (2016) is especially related\\nto our work in that both studies use rnn for sequence prediction. however, while lipton et al.\\n(2016) uses regular times series of real-valued variables collected from icu patients to predict\\ndiagnosis codes, we use discrete medical codes ( e.g. diagnosis, medication, procedure) extracted\\n3\",\n",
       " \"table 1: basic statistics of the the clinical records dataset.\\n# of patients 263,706 total # of codes 38,594\\navg. # of visits 54.61 total # of 3-digit dx codes 1,183\\navg. # of codes per visit 3.22 # of top level rx codes 595\\nmax # of codes per visit 62 avg. duration between visits 76.12 days\\nfrom longitudinal patient visit records. also, in each visit we make a prediction about predict\\ndiagnosis, medication order in the next visit and and the time to next visit.\\n3. cohort\\npopulation and source of data. the source population for this study was primary care patients\\nfrom sutter health palo alto medical foundation. sutter health is a large primary care and\\nmultispecialty group practice that has used an epic systems corporation ehr for more than a\\ndecade. the dataset was extracted from a density sampled case-control study for heart failure.\\nthe dataset consists of de-identi\\x0ced encounter orders, medication orders, problem list records and\\nprocedure orders.\\ndata processing. as inputs, we use icd-9 codes, medication codes, and procedure codes. we\\nextracted icd-9 codes from encounter records, medication orders, problem list records and proce-\\ndure orders. generic product identi\\x0cer (gpi) medication codes and cpt procedure codes were\\nextracted from medication orders and procedure orders respectively. all codes were timestamped\\nwith the patients visit time. if a patient received multiple codes in a single visit, those codes were\\ngiven the same timestamp. we excluded patients that made less than two visits. the resulting\\ndataset consists of 263,706 patients who made on average 54.61 visits per person.\\ngrouping medical codes. there are more about 11,000 unique icd-9 codes and 18,000 gpi\\nmedication codes in the dataset, many of which are very granular. for example, pulmonary tuber-\\nculosis (icd-9 code 011) is divided into 70 subcategories (icd-9 code 011.01, 011.02, ..., 011.95,\\n011.96). simply knowing that a patient is likely to have pulmonary tuberculosis is enough to\\nincrease the doctor's awareness of the severity of the clinical situation. therefore, to predict di-\\nagnosis and medication order, we grouped codes into higher-order categories to reduce the feature\\nset and information overload. for the diagnosis codes, we use the 3-digit icd-9 codes, yielding\\n1183 unique codes. for the medication codes, we use the generic product identi\\x0cer drug class,\\nwhich groups the medication codes into 595 unique groups. the label yiwe use in the following\\nsections represents the 1,778-dimensional vector (i.e., 1183 + 595) for the grouped diagnosis codes\\nand medication codes.\\n4. methods\\nthis section describes the rnn model for multilabel point processes. we will also describe how we\\npredict diagnosis, medication order and visit time using the rnn model.\\nproblem setting. for each patient, the observations are drawn from a multilabel point process in\\nthe form of ( ti;xi) fori= 1;:::;n . each pair represents an event, such as an ambulatory care visit,\\nduring which multiple medical codes such as icd-9 diagnosis codes, procedure codes, or medication\\ncodes are documented in the patient record. the multi-hot label vector xi2f0;1gprepresents the\\nmedical codes assigned at time ti, wherepdenotes the number of unique medical codes. at each\\ntimestamp, we may extract higher-level codes for prediction purposes and denote it by yi, see the\\ndetails in section 3. the number of events for each patient may di\\x0ber.\\n4\",\n",
       " 'figure 1: this diagram shows how we have applied rnns\\nto solve the problem of forecasting of next visits\\' time and\\nthe codes assigned during each visit. the \\x0crst layer simply\\nembeds the high-dimensional input vectors in a lower dimen-\\nsional space. the next layers are the recurrent units (here\\ntwo layers), which learn the status of the patient at each\\ntimestamp as a real-valued vector. given the status vector,\\nwe use two dense layers to generate the codes observed in\\nthe next timestamp and the duration until next visit.\\n𝒙\"𝒙#$\"𝒙#𝒚&\\'𝑑)\\'𝒚&#*\"𝑑)#*\"\\n𝒉\"\",𝑑\"𝒉\"\\'𝒉\"-𝒉#$\"\",𝑑#$\"𝒉#$\"\\'𝒉#$\"-𝒚&#𝑑)#𝒉#-𝒉#\\'𝒉#\",𝑑#𝒙#\\ngated recurrent units preliminaries. speci\\x0ccally, we implemented our rnn with gated re-\\ncurrent units (gru). although long short term memory (lstm) (hochreiter and schmidhuber,\\n1997; graves et al., 2009) has drawn much attention from many researchers, gru has recently\\nshown to have similar performance as lstm, while employing a simpler architecture (chung et al.,\\n2014). in order to precisely describe the network used in this work, we reiterate the mathematical\\nformulation of gru as follows:\\nzi=\\x1b(wzxi+uzhi\\x001+bz)\\nri=\\x1b(wrxi+urhi\\x001+br)\\n~hi= tanh( whxi+ri\\x0euhhi\\x001+bh)\\nhi=zi\\x0ehi\\x001+ (1\\x00zi)\\x0e~hi\\nwhere ziandrirespectively represent the update gate and the reset gate, ~hithe intermediate\\nmemory unit, hithe hidden layer, all at timestep ti. a detailed description of gru is provided in\\nappendix a.\\ndescription of neural network architecture. our goal is to learn an e\\x0bective vector repre-\\nsentation for the patient status at each timestamp ti. using e\\x0bective patient representations, we\\nare interested in predicting diagnosis and medication categories in the next visit yi+1and the time\\nduration until the next visit di+1=ti+1\\x00ti. finally, we would like to perform all these steps\\njointly in a single supervised learning scheme. we use rnn to learn such patient representations,\\ntreating the hidden layer as the representation for the patient status and use it for the prediction\\ntasks.\\nthe proposed neural network architecture (figure 1) receives input at each timestamp tias\\nthe concatenation of the multi-hot input vector xiof the multilabel categories and the duration di\\nsince the last event. in our datasets, the input dimension is as large as 40 ;000. thus, the next\\nlayer projects the input to a lower dimensional space. then, we pass the lower dimensional vector\\nthrough rnn (implemented with gru in our study). we can also stack multiple layers of rnn\\nto increase the representative power of the network. finally, we use a softmax layer to predict the\\ndiagnosis codes and the medication codes, and a recti\\x0ced linear unit (relu) to predict the time\\nduration until next visit.\\nfor predicting the diagnosis codes and the medication codes at each timestep ti, a softmax layer\\nis stacked on top of the gru, using the hidden layer hias the input: byi+1= softmax( wcode>hi+\\nbcode). for predicting the time duration until the next visit, a recti\\x0ced linear unit (relu) is placed\\non top of the gru, again using the hidden layer hias the input: bdi+1= max( wtime>hi+btime;0).\\nthe objective of training our model is to learn the weights wfz;r;h;codeg,ufz;r;hg,bfz;r;h;codeg,wtime\\nandbtime. the values of all w\\'s and u\\'s were initialized to orthonormal matrices using singular\\n5',\n",
       " \"value decomposition of matrices generated from the normal distribution (saxe et al., 2013). the\\ninitial value of wtimewas chosen from the uniform distribution between \\x000:1 and 0:1. all b's and\\nbtimewere initialized to zeros. the joint loss function consists of the cross entropy for the code\\nprediction and the squared loss for the time duration prediction, as described below for a single\\npatient:\\nl(w;u;b;wtime;btime) =n\\x001x\\ni=1\\x1a\\x10\\nyi+1log(byi+1) + (1\\x00yi+1) log(1\\x00byi+1)\\x11\\n+1\\n2kdi+1\\x00bdi+1k2\\n2\\x1b\\nas mentioned above, the multi-hot vectors xiof almost 40,000 dimensions are \\x0crst projected to a\\nlower dimensional space, then put into the gru. we employed two di\\x0berent approaches for this:\\n(1) we put an extra layer of a certain size between the multi-hot input xiand the gru, and call\\nit the embedding layer. we denote the weight matrix between the multi-hot input vector and the\\nembedding layer as wemb. then we learn the weight wembas we train the entire model. (2) we\\ninitialize the weight wembwith a matrix generated by skip-gram algorithm (mikolov et al., 2013),\\nthen re\\x0cne the weight wembas we train the entire model. this can be seen as using the pre-trained\\nskip-gram vectors as the input to the rnn and \\x0cne-tuning them with the joint prediction task.\\nthe brief description of learning the skip-gram vectors from the ehr is provided in appendix b.\\nthe \\x0crst and second approach can be formulated as follows:\\nh(1)\\ni= [tanh( xi>wemb+bemb); di] (1)\\nh(1)\\ni= [xi>wemb; di] (2)\\nwhere [\\x01;\\x01] is the concatenation operation used for appending the time duration to the multi-hot\\nvector h(1)\\nito make it an input vector to the gru.\\n5. results\\nwe now describe the details of our experiments in the proposed rnn approach to forecasting the\\nfuture clinical events. the source code of doctor ai is publicly available at https://github.com/\\nmp2893/doctorai .\\n5.1 experiment setup\\nfor training all models including the baselines, we used 85% of the patients as the training set\\nand 15% as the test set. we trained the rnn models for 20 epochs ( i.e., 20 iterations over the\\nentire training data) and then evaluated the \\x0cnal performance against the test set. to avoid\\nover\\x0ctting, we used dropout between the gru layer and the prediction layer ( i.e.code prediction\\nand time duration prediction). dropout was also used between gru layers if we were using a multi-\\nlayer gru. we also applied norm-2 regularization on both wcodeandwtime. both regularization\\ncoe\\x0ecients were set to 0.001. the size of the hidden layer hiof the gru was set to 2000 to\\nguarantee a su\\x0ecient expressive power. after running sets of preliminary experiments where we\\ntried the size from 100 to 2000, we noticed that the code prediction performance started to saturate\\naround 1600\\x181800. all models were implemented with theano (bastien et al., 2012) and trained\\non a machine equipped with two nvidia tesla k80 gpus.\\nwe train total four di\\x0berent variation of doctor ai as follows,\\n\\x0frnn-1 : rnn with a single hidden layer initialized with a random orthogonal matrix for\\nwemb.\\n6\",\n",
       " \"\\x0frnn-2 : rnn with two hidden layers initialized with a random orthogonal matrix for wemb.\\n\\x0frnn-1-ir : rnn using a single hidden layer initialized embedding matrix wembwith the\\nskip-gram vectors trained on the entire dataset.\\n\\x0frnn-2-ir : rnn with two hidden layers initialized embedding matrix wembwith the skip-\\ngram vectors trained on the entire dataset. dataset.\\n5.2 evaluation metrics\\nthe performance of algorithms in predicting diagnoses and medication codes was evaluated using\\nthe top-k recall de\\x0cned as:\\ntop-krecall =# of true positives in the top kpredictions\\n# of true positives\\ntop-k recall mimics the behavior of doctors conducting di\\x0berential diagnosis, where doctors list\\nmost probable diagnoses and treat patients accordingly to identify the patient status. therefore,\\na machine with a high top-k recall translates to a doctor with an e\\x0bective diagnostic skill. this\\nmakes top-k recall an attractive performance metric for our problem.\\nwe select the maximum k to be 30 to evaluate the performance of the models not only for\\nsimple cases but also for complex cases. near 50.7% of the patients have been assigned with more\\nthan 10 diagnosis and medication codes at least once. since it is those complex cases that are of\\ninterest to predict and analyze, we choose k to be large enough (i.e., 3 times of the mean).\\ncoe\\x0ecient of determination ( r2) was used to evaluate the predictive performance of re-\\ngression and forecasting algorithms. it compares the accuracy of the prediction with respect to the\\nsimple prediction by mean of the target variable.\\nr2= 1\\x00p\\ni(yi\\x00byi)2\\np\\ni(yi\\x00yi)2\\nbecause time to the next visit can be highly skewed, we measure the r2performance of the\\nalgorithms in predicting log( di) to lower the impact of anomalous long durations in the performance\\nmetric. in the same spirit, we train all models to predict the logarithm of the time duration between\\nvisits.\\n5.3 baselines\\nwe compare our model against several baselines as described below. some of the existing techniques\\nbased on continuous-time markov chain and latent space models were not scalable enough to be\\ntrained using the entire dataset in a reasonable amount of time; thus comparison is not feasible.\\nfrequency baselines. we compare our algorithms against simple baselines that are based on\\nexperts' intuition about the dynamics of events in clinical settings. the \\x0crst baseline uses a patient's\\nmedical codes in the last visit as the prediction for the current visit. this baseline is competitive\\nwhen the status of a patient with a chronic condition stabilizes over time. we enhanced this\\nbaseline using the top- kmost frequent labels observed in visits prior to the current visits. in the\\nexperiments we observe that the baseline of top- kmost frequent labels is quite competitive.\\nlogistic and neural network time series models. a common way to perform prediction\\ntask is to use xi\\x001to predict the codes in the next visit xiusing logistic regression or multilayer\\nperceptron (mlp). to enhance the baseline further, we can use the data from ltime lags before\\n7\",\n",
       " 'table 2: accuracy of algorithms in forecasting future medical activities. embedding matrices wemb\\nof both rnn-1 (using one hidden layer) and rnn-2 (using two hidden layers) are initialized with\\nrandom orthogonal vectors. embedding matrices wembof both rnn-1-ir (using one hidden layer)\\nand rnn-2-ir (using two hidden layers) are initialized with skip-gram vectors trained on the entire\\ndataset.\\ndx only recall @ k rx only recall @ k dx,rx,time recall @ k\\nalgorithms k= 10k= 20k= 30k= 10k= 20k= 30k= 10k= 20k= 30r2\\nlast visit 29.17 13.81 26.25 |\\nmost freq. 56.63 67.39 71.68 62.99 69.02 70.07 48.11 60.23 66.00 |\\nlogistic 43.24 54.04 60.76 45.80 60.02 68.93 36.04 46.32 52.53 0.0726\\nmlp 46.66 57.38 64.03 47.62 61.72 70.92 38.82 49.09 55.74 0.1221\\nrnn-1 63.12 73.11 78.49 67.99 79.55 85.53 53.86 65.10 71.24 0.2519\\nrnn-2 63.32 73.32 78.71 67.87 79.47 85.43 53.61 64.93 71.14 0.2528\\nrnn-1-ir 63.24 73.33 78.73 68.31 79.77 85.52 54.37 65.68 71.85 0.2492\\nrnn-2-ir 64.30 74.31 79.58 68.16 79.74 85.48 54.96 66.31 72.48 0.2534\\nand aggregate them xi\\x001+xi\\x002+;+xi\\x00lfor some duration lto create the features for prediction\\nofxi. similarly, we can have a model that predicts the time until next visit using recti\\x0ced linear\\nunits (relu) as the output activation. we set the lag l= 5 so that the logistic regression and\\nmlp can use information from maximum \\x0cve past visits. the details of mlp design are described\\nin appendix c.\\n5.4 prediction performance\\ntable 2 compares the results of di\\x0berent algorithms with rnn based doctor ai. we report the\\nresults in three settings: when we are interested in (1) predicting only diagnosis codes (dx), (2)\\npredicting only medication codes (rx), and (3) jointly predicting dx codes, rx codes, and the time\\nduration to next visit. the results con\\x0crm that the proposed approach is able to outperform the\\nbaseline algorithms by a large margin. note that the recall values for the joint task are lower than\\nthose for dx code prediction or rx code prediction because the hypothesis space is larger for the\\njoint prediction task.\\nthe superior performance of rnn based approaches can be attributed to the e\\x0ecient represen-\\ntation that they learn for patients at each visit (bengio et al., 2013; schmidhuber, 2015). rnns\\nare able to learn succinct feature representations of patients by accumulating the relevant informa-\\ntion from their history and the current set of codes, which outperformed hand-picked features of\\nfrequency baselines.\\ntable 2 con\\x0crms that learning patient representation with rnn is easier with the input vec-\\ntors that are already e\\x0ecient representations of the medical codes. the rnn trained with the\\nskip-gram vectors (denoted by rnn-ir) consistently outperforms the rnn that learns the weight\\nmatrix wembdirectly from the data, with only one exception, the medication prediction recall@30,\\nalthough the di\\x0berences are insigni\\x0ccant. the results also con\\x0crm that having multiple layers when\\nusing rnn improves its ability to learn more e\\x0ecient representations. the results also indicate that\\na single layer rnn might have enough representative power to capture the dynamics of medications,\\nand adding more layers may not improve the performance.\\n8',\n",
       " \"the results also indicate that our approach signi\\x0ccantly improves the accuracy of predicting\\nthe time duration until the next visit compared to the baselines. however, the absolute value of\\nr2metric shows that accurate prediction of time intervals remains as a challenge. we believe\\nachieving signi\\x0ccantly better time prediction without extra features should be di\\x0ecult because the\\ntiming of a clinical visit can be a\\x0bected by many personal factors such as \\x0cnancial status, location\\nof residence, means of transportation, and life style, to name a few. thus, without such sensitive\\npersonal information, which is rarely included in the ehr, accurate prediction of time intervals\\nshould be unlikely.\\n5.5 understanding the behavior of the network\\nto study the applicability of our model in a real-world setting where patients have varying length\\nof medical records, we conducted an additional experiment to study the relationship between the\\nlength of the patient medical history and the prediction performance. to this end, we selected\\n5,800 patients from the test set who had more than 100 visits. we used the best performing model\\nto predict the diagnosis codes at visits at di\\x0berent times and found the mean and standard error of\\nrecall across the selected patients. figure 2a shows the result of the experiment. we believe that\\nthe increase in performance can be due to two reasons: (1) rnn is able to learn a better estimate\\nof the patient status as it sees longer patient records and (2) visits are correlated with poor health.\\nthose with high visit count are more likely to be severely ill, and therefore their future is easier to\\npredict.\\nanother experiment was conducted to understand the behavior of the network by giving syn-\\nthetic inputs. we chose hypertension (icd-9 code 401.9) as an example of a frequently observed\\ndiagnosis, and klinefelter's syndrome (icd-9 code 758.7) as an example of an infrequent diagnosis.\\nwe created two synthetic patients who respectively have 200 visits of 401.9 and 758.7. then we\\nused the best performing model to predict the diagnosis codes for the next visits. figure 2b shows\\ncontrasting patterns: when the input is one of the frequent codes such as hypertension, the network\\nquickly learns a more speci\\x0cc set of output codes as next disease. when we select an infrequent\\ncode like klinefelter's syndrome as the input, the network's output is more diverse and mostly the\\nfrequently observed codes. the top 30 codes after convergence shown in table 4 in appendix d\\ncon\\x0crm the disparity of the diversity of the predicted codes for the two cases.\\n5.6 knowledge transfer across hospitals\\nas we observed from the previous experiments, the dynamics of clinical events are complex, which\\nrequires models with a high representative power. however, many institutions have not yet col-\\nlected large scale datasets, and training such models could easily lead to over\\x0ctting. to address\\nthis challenge, we resort to the recent advances in domain adaptation techniques for deep neural\\nnetworks (mesnil et al., 2012; bengio, 2012; yosinski et al., 2014; ho\\x0bman et al., 2014).\\na di\\x0berent dataset, mimic ii, which is a publicly available clinical dataset collected from icu\\npatients over 7 years of observation, was chosen to conduct the experiment. this dataset di\\x0bers\\nfrom the sutter dataset in that it consists of demographically and diagnostically di\\x0berent patients.\\nthe number of patients who made at least two visits is 2,695, and the number of unique diagnosis\\ncode (3-digit icd-9 code) is 767, which is a subset of the sutter dataset. from the dataset, we\\nextracted sequences of 3-digit icd-9 codes. we chose 2,290 patients for training, 405 for testing.\\nwe chose the 2-layer rnn with 1000 dimensional hidden layer, and performed two experiments:\\n1) we trained the model only on the mimic ii dataset. 2) we initialized the coe\\x0ecients of the\\nmodel with the values learned from the 3-digit icd-9 sequences of the sutter data, then we re\\x0cned\\n9\",\n",
       " \"5102030405060708090100\\nnumber of visits0.50.550.60.650.70.750.80.85recalltop-10\\nsetop-10\\nmeantop-20\\nsetop-20\\nmeantop-30\\nsetop-30\\nmean(a)\\n0 50 100 150 200\\ntimestamp012345678910logarithm of perplexity (bits)hypertension\\nklinefelter syndrom (b)\\nfigure 2: characterizing behavior of the trained network: (a) prediction performance of doctor ai\\nas it sees a longer history of the patients. (b) change in the perplexity of response to a frequent\\ncode (hypertension) and an infrequent code (klinefelter's syndrome).\\nfigure 3: the impact of pre-training\\non improving the performance on smaller\\ndatasets. in the \\x0crst experiment, we \\x0crst\\ntrain the model on a small dataset (red\\ncurve). in the second experiment, we pre-\\ntrain the model on our large dataset and\\nuse it for initializing the training of the\\nsmaller dataset. this procedure results in\\nmore than 10% improvement in the per-\\nformance.\\n0 5 10 15 200.30.350.40.450.50.550.60.65\\nnumber of epochsrecall @30\\n  \\nwithout pretraining pretrained on sutter dataset\\nthe coe\\x0ecients with the mimic ii dataset. figure 3 shows the vast improvement of the prediction\\nperformance induced by the knowledge transfer from the sutter data.\\n6. conclusion\\nin this work, we proposed doctor ai system, which is a rnn-based model that can learn e\\x0ecient\\npatient representation from a large amount of longitidinal patient records and predict future events\\nof patients. we tested doctor ai on a large real-world ehr datasets, which achieved 79.58% re-\\ncall@30 and signi\\x0ccantly outperformed many baselines. we have also shown that the patient's visit\\ncount and the rarity of medical codes highly in\\ruence the performance. we have also demonstrated\\nthat knowledge learned from one hospital could be adapted to another hospital. the empirical anal-\\nysis by a medical expert con\\x0crmed that doctor ai not only mimics the predictive power of human\\ndoctors, but also provides diagnostic results that are clinically meaningful.\\none limitation of doctor ai is that, in medical practice, incorrect predictions can sometimes\\nbe more important than correct predictions as they can degrade patient health. also, although\\ndoctor ai has shown that it can mimic physicians' average behavior, it would be more useful to\\nlearn to perform better than average. we set as our future work to address these issues so that\\ndoctor ai can provide practical help to physicians in the future.\\n10\",\n",
       " 'references\\nmohammad taha bahadori, yan liu, and eric p xing. fast structure learning in generalized\\nstochastic processes with latent factors. in kdd , pages 284{292, 2013.\\nfr\\x13 ed\\x13 eric bastien, pascal lamblin, razvan pascanu, james bergstra, ian j. goodfellow, arnaud\\nbergeron, nicolas bouchard, and yoshua bengio. theano: new features and speed improvements.\\ndeep learning and unsupervised feature learning nips 2012 workshop, 2012.\\nyoshua bengio. deep learning of representations for unsupervised and transfer learning. unsuper-\\nvised and transfer learning challenges in machine learning , 7:19, 2012.\\nyoshua bengio, aaron courville, and pierre vincent. representation learning: a review and new\\nperspectives. pattern analysis and machine intelligence, ieee transactions on , 35(8):1798{\\n1828, 2013.\\nzhengping che, david kale, wenzhe li, mohammad taha bahadori, and yan liu. deep compu-\\ntational phenotyping. in proceedings of the 21th acm sigkdd international conference on\\nknowledge discovery and data mining , pages 507{516. acm, 2015.\\nedward choi, nan du, robert chen, le song, and jimeng sun. constructing disease network and\\ntemporal progression model via context-sensitive hawkes process. in icdm , 2015.\\nedward choi, mohammad taha bahadori, elizabeth searles, catherine co\\x0bey, and jimeng sun.\\nmulti-layer representation learning for medical concepts. in kdd , 2016a.\\nyoungduk choi, chill i chiu, and david sontag. learning low-dimensional representations of\\nmedical concepts. in amia cri , 2016b.\\njunyoung chung, caglar gulcehre, kyunghyun cho, and yoshua bengio. empirical evaluation of\\ngated recurrent neural networks on sequence modeling. arxiv preprint arxiv:1412.3555 , 2014.\\nwillem de winter, joost dejongh, teun post, bart ploeger, richard urquhart, ian moules, david\\neckland, and meindert danhof. a mechanism-based disease progression model for comparison of\\nlong-term e\\x0bects of pioglitazone, metformin and gliclazide on disease processes underlying type\\n2 diabetes mellitus. journal of pharmacokinetics and pharmacodynamics , 33(3):313{343, 2006.\\nyohann foucher, magali giral, jean-paul soulillou, and jean-pierre daures. a semi-markov model\\nfor multistate and interval-censored data with multiple terminal events. application in renal\\ntransplantation. statistics in medicine , 26(30):5381{5393, 2007.\\nalex graves. generating sequences with recurrent neural networks. arxiv preprint arxiv:1308.0850 ,\\n2013.\\nalex graves and navdeep jaitly. towards end-to-end speech recognition with recurrent neural\\nnetworks. in icml , pages 1764{1772, 2014.\\nalex graves, marcus liwicki, santiago fern\\x13 andez, roman bertolami, horst bunke, and j\\x7f urgen\\nschmidhuber. a novel connectionist system for unconstrained handwriting recognition. pami ,\\n2009.\\n11',\n",
       " \"nils yannick hammerla, james fisher, peter andras, lynn rochester, richard walker, and\\nthomas pl\\x7f otz. pd disease state assessment in naturalistic environments using deep learning.\\ninaaai , pages 1742{1748, 2015.\\nsepp hochreiter and j\\x7f urgen schmidhuber. long short-term memory. neural computation , 1997.\\njudy ho\\x0bman, sergio guadarrama, eric s tzeng, ronghang hu, je\\x0b donahue, ross girshick,\\ntrevor darrell, and kate saenko. lsda: large scale detection through adaptation. in advances\\nin neural information processing systems , pages 3536{3544, 2014.\\nkaori ito, sima ahadieh, brian corrigan, jonathan french, terence fullerton, thomas tensfeldt,\\nalzheimer's disease working group, et al. disease progression meta-analysis model in alzheimer's\\ndisease. alzheimer's & dementia , 6(1):39{53, 2010.\\nchristopher h jackson, linda d sharples, simon g thompson, stephen w du\\x0by, and elisabeth\\ncouto. multistate markov models for disease progression with classi\\x0ccation error. jrss-d , 2003.\\nmatthew j johnson and alan s willsky. bayesian nonparametric hidden semi-markov models. the\\njournal of machine learning research , 14(1):673{701, 2013.\\nnorman m keith, henry p wagener, and nelson w barker. some di\\x0berent types of essential\\nhypertension: their course and prognosis. the american journal of the medical sciences , 197\\n(3):332{343, 1939.\\nryan kiros, ruslan salakhutdinov, and richard s zemel. unifying visual-semantic embeddings\\nwith multimodal neural language models. arxiv preprint arxiv:1411.2539 , 2014.\\njohanna kuusisto, keijo koivisto, l mykk\\x7f anen, eeva-liisa helkala, matti vanhanen, t h\\x7f anninen,\\nk py\\x7f or\\x7f al\\x7f a, paavo riekkinen, and markku laakso. essential hypertension and cognitive function.\\nthe role of hyperinsulinemia. hypertension , 22(5):771{779, 1993.\\njane lange. latent continuous time markov chains for partially-observed multistate disease\\nprocesses . phd thesis, 2014.\\njane m lange, rebecca a hubbard, lurdes yt inoue, and vladimir n minin. a joint model\\nfor multistate disease processes and random informative observation times, with applications to\\nelectronic medical records data. biometrics , 71(1):90{101, 2015.\\nthomas a lasko, joshua c denny, and mia a levy. computational phenotype discovery using\\nunsupervised feature learning over noisy, sparse, and irregular clinical data. plos one , 8(6):\\ne66341, 2013.\\nscott linderman and ryan adams. discovering latent network structure in point process data. in\\nicml , pages 1413{1421, 2014.\\nthomas josef liniger. multivariate hawkes processes . phd thesis, diss., eidgen\\x7f ossische technische\\nhochschule eth z\\x7f urich, nr. 18403, 2009, 2009.\\nzachary c lipton, david c kale, charles elkan, and randall wetzell. learning to diagnose with\\nlstm recurrent neural networks, 2016.\\n12\",\n",
       " 'yu-ying liu, hiroshi ishikawa, mei chen, gadi wollstein, joel s schuman, and james m rehg.\\nlongitudinal modeling of glaucoma progression using 2-dimensional continuous-time hidden\\nmarkov model. in medical image computing and computer-assisted intervention{miccai 2013 ,\\npages 444{451. 2013.\\ngr\\x13 egoire mesnil, yann dauphin, xavier glorot, salah rifai, yoshua bengio, ian j goodfellow,\\nerick lavoie, xavier muller, guillaume desjardins, david warde-farley, et al. unsupervised\\nand transfer learning challenge: a deep learning approach. icml unsupervised and transfer\\nlearning , 27:97{110, 2012.\\ntomas mikolov, ilya sutskever, kai chen, greg s corrado, and je\\x0b dean. distributed represen-\\ntations of words and phrases and their compositionality. in nips , 2013.\\nriccardo miotto, li li, brian a kidd, and joel t dudley. deep patient: an unsupervised repre-\\nsentation to predict the future of patients from the electronic health records. scienti\\x0cc reports ,\\n6(26094), 2016.\\ndr mould. models for disease progression: new approaches and uses. clinical pharmacology &\\ntherapeutics , 92(1):125{131, 2012.\\nuri nodelman, christian r shelton, and daphne koller. continuous time bayesian networks. in\\nuai, pages 378{387. morgan kaufmann publishers inc., 2002.\\nrajesh ranganath, adler perotte, no\\x13 emie elhadad, and david m blei. the survival \\x0clter: joint\\nsurvival analysis with a latent time series. in uai, 2015.\\nandrew m saxe, james l mcclelland, and surya ganguli. exact solutions to the nonlinear dy-\\nnamics of learning in deep linear neural networks. arxiv preprint arxiv:1312.6120 , 2013.\\nj\\x7f urgen schmidhuber. deep learning in neural networks: an overview. neural networks , 61:85{117,\\n2015.\\nvictor j stevens, carol a rouzer, vincent m monnier, and anthony cerami. diabetic cataract\\nformation: potential role of glycosylation of lens crystallins. pnas , 75(6):2918{2922, 1978.\\nra\\x0cd sukkar, edward katz, yanwei zhang, david raunig, and bradley t wyman. disease pro-\\ngression modeling using hidden markov models. in embc , 2012.\\nilya sutskever, oriol vinyals, and quoc vv le. sequence to sequence learning with neural networks.\\ninnips , pages 3104{3112, 2014.\\nnavdeep tangri, lesley a stevens, john gri\\x0eth, hocine tighiouart, ognjenka djurdjev, david\\nnaimark, adeera levin, and andrew s levey. a predictive model for progression of chronic\\nkidney disease to kidney failure. jama , 305(15):1553{1559, 2011.\\nwilson truccolo, uri t eden, matthew r fellows, john p donoghue, and emery n brown. a\\npoint process framework for relating neural spiking activity to spiking history, neural ensemble,\\nand extrinsic covariate e\\x0bects. journal of neurophysiology , 93(2):1074{1089, 2005.\\nalejandro veen and frederic p schoenberg. estimation of space{time branching process models in\\nseismology using an em{type algorithm. jasa , 103(482):614{624, 2008.\\n13',\n",
       " 'xiang wang, david sontag, and fei wang. unsupervised learning of disease progression models.\\ninkdd , 2014.\\njeremy weiss, sriraam natarajan, and david page. multiplicative forests for continuous-time\\nprocesses. in advances in neural information processing systems , pages 458{466, 2012.\\njason yosinski, je\\x0b clune, yoshua bengio, and hod lipson. how transferable are features in deep\\nneural networks? in advances in neural information processing systems , pages 3320{3328, 2014.\\nwojciech zaremba and ilya sutskever. learning to execute. arxiv preprint arxiv:1410.4615 , 2014.\\njiayu zhou, jun liu, vaibhav a narayan, and jieping ye. modeling disease progression via fused\\nsparse group lasso. in kdd , pages 1095{1103, 2012.\\nke zhou, hongyuan zha, and le song. learning social infectivity in sparse low-rank networks\\nusing multi-dimensional hawkes processes. in aistats , pages 641{649, 2013.\\nlingjiong zhu. nonlinear hawkes processes . phd thesis, new york university, 2013.\\nappendices\\nappendix a. description of gated recurrent units\\nxihi-1hihi~rizielement-wise multiplicationelement-wise additionwrwzuruzwhuh1-zizivalues are directly propagatedvalues are modified by weights\\nfigure 4: architecture of gru\\nwe \\x0crst reiterate the mathematical formulation of gru so that the reader can see figure 4 and\\nthe formulations together.\\nzi=\\x1b(wzxi+uzhi\\x001+bz)\\nri=\\x1b(wrxi+urhi\\x001+br)\\n~hi= tanh( whxi+ri\\x0euhhi\\x001+bh)\\nhi=zi\\x0ehi\\x001+ (1\\x00zi)\\x0e~hi\\nfigure 4 depicts the architecture of the gru, where xi,ziandrirespectively represent the input,\\nupdate gate and the reset gate, ~hithe intermediate memory unit, hithe hidden layer, all at\\ntimestepti.wh;wz;wr;uh;uz;urare the weight matrices to be learned. note that the bias\\nvectors bh;bz;brare omitted in figure 4.\\nthe outstanding di\\x0berence between the classical rnn (elman network) and gru is that the\\nprevious hidden layer hi\\x001and the current input xido not directly change the value of the current\\n14',\n",
       " 'hidden layer hi. instead, they change the values of both gates zi,riand the intermediate memory\\nunit ~hi. then the current hidden layer hiis updated by ~hiandzi. due to the \\x1bfunction, both\\ngates ziandrihave values between 0 and 1. therefore if the reset gate riis close to zero, the\\nintermediate memory unit ~hiwill disregard the past values of the hidden layer hi\\x001. if the update\\ngateziis close to one, the current hidden layer hiwill disregard the current input xi, and retain\\nthe value from the previous timestep hi\\x001.\\nsimply put, the reset gate allows the hidden layer to drop any information that is not useful\\nin making a prediction, and the updated gate controls how much information from the previous\\nhidden layer should be propagated to the current hidden layer. this characteristic of gru is\\nespecially useful as it is not easy to identify information essential to predicting the future diagnosis,\\nmedication or the time duration until the next visit.\\nappendix b. learning the skip-gram vectors from the ehr\\nlearning e\\x0ecient representations of medical codes ( e.g. diagnosis codes, medication codes, and\\nprocedure codes) may lead to improved performance of many clinical applications. we speci\\x0ccally\\nused skip-gram mikolov et al. (2013) to learn real-valued multidimensional vectors to capture the\\nlatent representation of medical codes from the ehr.\\nwe processed the private dataset so that diagnosis codes, medication codes, procedure codes\\nare laid out in a temporal order. if there are multiple codes at a single visit, they were laid out in a\\nrandom order. then using the context window size of 5 to the left and 5 to the right, and applying\\nskip-gram, we were able to project diagnosis codes, medication codes and procedure codes into the\\nsame lower dimensional space, where similar or related codes are embedded close to one another.\\nfor example, hypertension, obesity, hyperlipidemia all share similar values compared to pneumonia\\nor bronchitis. the trained skip-gram vectors are then plugged into rnn so that a multi-hot vector\\ncan be converted to vector representations of medical codes.\\nappendix c. details of the training procedure of multilayer perceptron\\nwe use a multilayer perceptron with a hidden layer of width 2,000. we apply l2regularization to\\nall of the weight matrices. the activation functions in the \\x0crst and output layers are selected to be\\ntanh and softmax functions respectively. for prediction of time intervals, we used recti\\x0ced linear\\nunits.\\nappendix d. case study\\nthe detailed results are shown in table 3. to take a closer look at the performance of doctor ai,\\nin table 3 (in appendix d) we list the predicted, true, and historical diagnosis codes for \\x0cve visits\\nof di\\x0berent patients. the blue items represent the correct predictions. the results are promising\\nand show that, given the history of the patient, the doctor ai can predict the true diagnostic\\ncodes. the results highly mimic the way a human doctor will interpret the disease predictions from\\nthe history. for all \\x0cve of the cases shown in table 3, the set of predicted diseases contain most,\\nif not all of the true diseases. for example, in the \\x0crst case, the top 3 predicted diseases match\\nthe true diseases. a human doctor would likely predict similar diseases to the ones predicted with\\ndoctor ai, since old myocardial infarction and chronic ischemic heart disease can be associated\\nwith infections and diabetes (stevens et al., 1978).\\n15',\n",
       " 'in the fourth case, visual disturbances can be associated with migraines and essential hyper-\\ntension (keith et al., 1939). further, essential hypertension may be linked to cognitive function\\n(kuusisto et al., 1993), which plays a role in anxiety disorders and dissociative and somatoform dis-\\norders. regarding codes that are guessed incorrectly with the fourth case, they can still be plausible\\ngiven the history. for example, cataracts, and disorders of refraction and accommodation could\\nhave been guessed based on a history of visual disturbances, as well as strabismus and disorders of\\nbinocular eye movements. allergic rhinitis could have been guessed, because there was a history\\nof allergic rhinitis. in summary, doctor ai is able to very accurately predict the true diagnoses in\\nthe sample patients. the results are promising and should motivate future studies involving the\\napplication of doctor ai on di\\x0berent datasets exhibiting other populations of patients.\\n16',\n",
       " 'table 3: comparison of the diagnoses by doctor ai and the true future diagnoses.\\npredicted true history\\nicd9 description icd9 description icd9 description\\n412\\nv58\\n414\\n272\\n250\\n585\\n428\\n285\\nv04\\nv76old myocardial infarction\\nencounter for other and unspeci\\x0ced procedures\\nother forms of chronic ischemic heart disease\\ndisorders of lipoid metabolism\\ndiabetes mellitus\\nchronic kidney disease (ckd)\\nheart failure\\nother and unspeci\\x0ced anemias\\nneed for prophylactic vaccin. and inocul. against certain diseases\\nspecial screening for malignant neoplasms414\\n412\\nv58other forms of chronic ischemic heart disease\\nold myocardial infarction\\nencounter for other and unspeci\\x0ced procedures465\\n250\\n366\\nv58\\n362acute upper respiratory infec. of multiple or unspec. sites\\ndiabetes mellitus\\ncataract\\nencounter for other and unspeci\\x0ced procedures\\nother retinal disorders\\nv07\\n477\\n780\\n401\\n786\\n493\\n300\\n461\\n530\\n719need for isolation and other prophylactic measures\\nallergic rhinitis\\ngeneral symptoms\\nessential hypertension\\nsymptoms involving respiratory system\\nasthma\\nanxiety, dissociative and somatoform disorders\\nacute sinusitis\\ndiseases of esophagus\\nother and unspeci\\x0ced disorders of jointv07\\n401\\n786\\n782need for isolation and other prophylactic measures\\nessential hypertension\\nsymptoms involving respiratory system\\nsymptoms involving skin and other integumentary tissue782\\n477\\nv07\\n564\\n401symptoms involving skin and other integumentary tissue\\nallergic rhinitis\\nneed for isolation and other prophylactic measures\\nfunctional digestive disorders, not elsewhere classi\\x0ced\\nessential hypertension\\n453\\nv58\\n719\\nv12\\nv43\\n729\\n715\\n733\\n726\\n451other venous embolism and thrombosis\\nencounter for other and unspeci\\x0ced procedures\\nother and unspeci\\x0ced disorders of joint\\npersonal history of certain other diseases\\norgan or tissue replaced by other means\\nother disorders of soft tissues\\nosteoarthrosis and allied disorders\\nother disorders of bone and cartilage\\nperipheral enthesopathies and allied syndromes\\nphlebitis and thrombophlebitis715\\nv12\\n719\\nv58osteoarthrosis and allied disorders\\npersonal history of certain other diseases\\nother and unspeci\\x0ced disorders of joint\\nencounter for other and unspeci\\x0ced procedures453\\n956\\nv43other venous embolism and thrombosis\\ninjury to peripheral nerve(s) of pelvic girdle and lower limb\\norgan or tissue replaced by other means\\n477\\n780\\n300\\n401\\n346\\n366\\nv43\\n367\\n368\\n272allergic rhinitis\\ngeneral symptoms\\nanxiety, dissociative and somatoform disorders\\nessential hypertension\\nmigraine\\ncataract\\norgan or tissue replaced by other means\\ndisorders of refraction and accommodation\\nvisual disturbances\\ndisorders of lipoid metabolism401\\n780\\n346\\n300essential hypertension\\ngeneral symptoms\\nmigraine\\nanxiety, dissociative and somatoform disorders782\\n477\\n692\\n368\\n378symptoms involving skin and other integumentary tissue\\nallergic rhinitis\\ncontact dermatitis and other eczema\\nvisual disturbances\\nstrabismus and other disorders of binocular eye movements\\n428\\n427\\n272\\n401\\n786\\n185\\n250\\n414\\n788\\n424heart failure\\ncardiac dysrhythmias\\ndisorders of lipoid metabolism\\nessential hypertension\\nsymptoms involving respiratory system\\nmalignant neoplasm of prostate\\ndiabetes mellitus\\nother forms of chronic ischemic heart disease\\nsymptoms involving urinary system\\nother diseases of endocardium250\\n402\\n428\\n272\\n427diabetes mellitus\\nhypertensive heart disease\\nheart failure\\ndisorders of lipoid metabolism\\ncardiac dysrhythmias466\\n428\\n786\\n785\\n250acute bronchitis and bronchiolitis\\nheart failure\\nsymptoms involving respiratory system\\nsymptoms involving cardiovascular system\\ndiabetes mellitus',\n",
       " \"table 4: comparison of the diagnoses by doctor ai for a frequent and an infrequent disease code after 200 time step.\\nhypertension klinefelter's syndrome\\nicd9 description icd9 description\\n401 essential hypertension 272 disorders of lipoid metabolism\\n272 disorders of lipoid metabolism v70 general medical examination\\n786 symptoms involving respiratory system and other chest symptoms v04 need for prophylactic vaccination and inoculation against certain diseases\\nv06 need for prophylactic vaccination and inoculation against combinations of diseases 730 osteomyelitis, periostitis, and other infections involving bone\\n790 nonspeci\\x0cc \\x0cndings on examination of blood 780 general symptoms\\nv76 special screening for malignant neoplasms 783 symptoms concerning nutrition, metabolism, and development\\nv04 need for prophylactic vaccination and inoculation against certain diseases 295 schizophrenic disorders\\nv70 general medical examination v76 special screening for malignant neoplasms\\n780 general symptoms 141 malignant neoplasm of tongue\\n276 disorders of \\ruid, electrolyte, and acid-base balance v06 need for prophylactic vaccination and inoculation against combinations of diseases\\n782 symptoms involving skin and other integumentary tissue 250 diabetes mellitus\\n268 vitamin d de\\x0cciency 782 symptoms involving skin and other integumentary tissue\\n719 other and unspeci\\x0ced disorders of joint 786 symptoms involving respiratory system and other chest symptoms\\n427 cardiac dysrhythmias 208 leukemia of unspeci\\x0ced cell type\\n380 disorders of external ear 401 essential hypertension\\n250 diabetes mellitus 790 nonspeci\\x0cc \\x0cndings on examination of blood\\n599 other disorders of urethra and urinary tract 280 iron de\\x0cciency anemias\\nv72 special investigations and examinations 607 disorders of penis\\n789 other symptoms involving abdomen and pelvis 281 other de\\x0cciency anemias\\n729 other disorders of soft tissues v03 need for prophylactic vaccination and inoculation against bacterial diseases\\n682 other cellulitis and abscess 332 parkinson's disease\\nv03 need for prophylactic vaccination and inoculation against bacterial diseases 255 disorders of adrenal glands\\n724 other and unspeci\\x0ced disorders of back 799 other ill-de\\x0cned and unknown causes of morbidity and mortality\\nv58 encounter for other and unspeci\\x0ced procedures and aftercare 244 acquired hypothyroidism\\n278 overweight, obesity and other hyperalimentation v58 encounter for other and unspeci\\x0ced procedures and aftercare\\nv82 special screening for other conditions 151 malignant neoplasm of stomach\\nv65 other persons seeking consultation 294 persistent mental disorders due to conditions classi\\x0ced elsewhere\\n585 chronic kidney disease (ckd) v72 special investigations and examinations\\n274 gout 344 other paralytic syndromes\\nv49 other conditions in\\ruencing health status 146 malignant neoplasm of oropharynx\",\n",
       " 'reprint h 04bm0\\npublished on hbr.org\\nm\\nay 10, 2018\\narticletechnology\\n10 promising ai\\napplications in health\\ncare\\nby brian kalis, matt collier and richard fu\\nthis article is made available to you with compliments of investtk for your personal use. further posting, copying, or distribution is not permitted.\\n',\n",
       " 'technology\\n1\\n0 promising ai\\napplications in health\\ncare\\nby brian kalis, matt collier and richard fu\\nmay 10, 2018\\npeter dazeley/getty images\\nthere’s a lot of excitement right now about how artificial intelligence (ai) is going to change health\\ncare. and many ai technologies are cropping up to help people streamline administrative and clinical\\nhealth care processes. according to venture capital firm rock health, 121 health ai and machine\\nlearning companies raised $2.7 billion in 206 deals between 2011 and 2017.\\n2 copyright © 2018  harvard business school publishing corporation. all rights reserved.',\n",
       " 'the field  of health ai is seemingly wide—covering wellness to diagnostics to operational technologies\\n—but it is also narrow in that health ai applications typically perform just a single task. we\\ninvestigated the value of 10 promising ai applications and found that they could create up to $150\\nbillion in annual savings for u.s. health care by 2026.\\nwe identified  these specific  ai applications based on how likely adoption was and what potential\\nexists for annual savings. we found ai currently creates the most value in helping frontline clinicians\\nbe more productive and in making back-end processes more efficient—but not yet in making clinical\\ndecisions or improving clinical outcomes. clinical applications are still rare.\\nlet’s take a look at a few examples of ai on the frontline of care. ai has demonstrated its aptitude for\\nimproving the efficiency of image analysis by quickly and accurately flagging specific anomalies for a\\nradiologist’s review. in 2011, researchers from nyu langone health found that this type of automated\\nanalysis could find and match specific  lung nodules (on chest ct images) between 62% to 97% faster\\nthan a panel of radiologists. our findings  suggest such ai-generated efficiencies  in image analysis\\ncould create $3 billion in annual savings by giving radiologists more time to focus on reviews that\\nrequire greater interpretation or judgement.\\nanother area is ai-assisted robotic surgery. in orthopedic surgery, a form of ai-assisted robotics can\\nanalyze data from pre-op medical records to physically guide the surgeon’s instrument in real-time\\n3 copyright © 2018  harvard business school publishing corporation. all rights reserved.',\n",
       " 'during a procedure. it can also use data from actual surgical experiences to inform new surgical\\ntechniques. a study of 379 orthopedic patients across nine surgical sites found that an ai-assisted\\nrobotic technique created by mazor robotics resulted in a five-fold  reduction in surgical\\ncomplications compared to when surgeons operated alone. when applied properly to orthopedic\\nsurgery, our analysis found ai-assisted robotic surgery could also generate a 21% reduction in\\npatients’ length of stay in the hospital following surgery, as a result of fewer complications and\\nerrors, and create $40 billion in annual savings.\\nai techniques are also being applied to the costly problem of dosage errors—where our findings\\nsuggest ai could generate $16 billion in savings. in 2016, a ground breaking trial in california found\\nthat a mathematical formula developed with the help of ai had correctly determined the correct dose\\nof immunosuppressant drugs to administer to organ patients. determining the dose has traditionally\\ndepended on a combination of guidelines and educated guesswork—and dosing errors make up 37%\\nof all preventable medical errors. while this type of ai technique is nascent, the example is powerful\\nconsidering that the correct dose is critical to making sure a graft is not rejected after an organ\\ntransplant.\\nusing ai to aid clinical judgement or diagnosis still remains in its infancy, but some results are\\nemerging to illustrate the possibility. in 2017, a group at stanford university tested an ai algorithm\\nagainst 21 dermatologists on its ability to identify skin cancers. the clinical findings, as reported by\\nnature last year, “achieve performance on par with all tested experts …demonstrating an artificial\\nintelligence capable of classifying skin cancer with a level of competence comparable to\\ndermatologists.” our findings suggest ai could yield $5 billion in annual savings by doing a\\npreliminary diagnosis before a patient enters the emergency department.\\nwe’re also starting to see potential of ai-powered virtual nurse assistants in helping patients. for\\nexample, sensely’s “molly” is an ai-powered nurse avatar being used by ucsf and the uk’s nhs to\\ninteract with patients, ask them questions about their health, assess their symptoms, and direct them\\nto the most effective  care setting. our findings  estimate ai-powered nurse assistants could save $20\\nbillion annually by saving 20% of the time nurses spend on patient maintenance tasks.\\nai also holds promise for helping the health care industry manage costly back-office problems and\\ninefficiencies. activities that have nothing to do with patient care consume over half (51%) of a\\nnurse’s workload and nearly a fifth (16%) of physician activities. ai-based technologies, such as\\nvoice-to-text transcription, can improve administrative workflows and eliminate time-consuming\\nnon-patient-care activities, such as writing chart notes, filling  prescriptions, and ordering tests. we\\nestimate that these applications could save the industry $18 billion annually.\\nfor example, while beth israel deaconess medical center garnered attention for an ai-enabled cancer\\nscreen, its first  foray into ai was more prosaic: using it to reduce hospital readmission rates and\\nidentify possible no-shows. using machine learning, technologists at beth israel medical center\\n4 copyright © 2018  harvard business school publishing corporation. all rights reserved.',\n",
       " 'developed an application to predict which patients are likely to be no shows or lapse on treatment so\\nthey can intervene ahead of time.\\nerrors and fraud are a similarly expensive problem for health care organizations and also for insurers.\\nfraud detection has traditionally relied on a combination of computerized (rules-based) and manual\\nreviews of medical claims. it’s a time-consuming process that hinges on being able to quickly spot\\nanomalies after the incident occurs in order to intervene. health insurers are experimenting with ai-\\nsupported data mining, coupled with ai-based neural networks (which mimic the processes of the\\nhuman brain, but much more quickly) to search medicare claims for patterns associated with medical\\nreimbursement fraud. we estimated that ai could create $17 billion in annual savings by improving\\nthe speed and accuracy of fraud detection in medicare claims.\\nbeyond fraudulent activity, the litany of data breaches, such as wannacry or petya, over the past few\\nyears has made cybersecurity a major concern for health care organizations. health care breaches are\\nestimated to cost organizations $380 per patient record. using ai to monitor and detect abnormal\\ninteractions with proprietary data could create $2 billion in annual savings by reducing health record\\nbreaches.\\nas ai technologies become more prevalent, health care organizations will have to invest in those that\\ndeliver the most value. uses of ai for clinical judgement still remains in its infancy and will need time\\nto fully take root in a meaningful way. but the ai applications that can deliver the most value today\\n(ai-assisted surgery, virtual nurse, administrative workflow) should be prioritized and invested in, so\\nhealth care providers and insurers are free to focus on better care.\\nbrian kalis l eads digital health for accenture.\\nmatt collier l eads health strategy consulting globally for accenture strategy.\\nrichard fu is a coa uthor of accenture’s research report on artificial intelligence.\\n5 copyright © 2018  harvard business school publishing corporation. all rights reserved.',\n",
       " 'resource\\nclinically applicable ai system for accurate\\ndiagnosis, quantitative measurements, andprognosis of covid-19 pneumonia using computedtomography\\ngraphical abstract\\nhighlights\\ndai system that can diagnose covid-19 pneumonia using\\nct scans\\ndprediction of progression to critical illness\\ndpotential to improve performance of junior radiologists to thesenior level\\ndcan assist evaluation of drug treatment effects with ctquantiﬁcationauthors\\nkang zhang, xiaohong liu, jun shen, ...,tianxin lin, weimin li, guangyu wang\\ncorrespondence\\nkang.zhang@gmail.com (k.z.),\\nhejx@vip.163.com (j.h.),lintx@mail.sysu.edu.cn (t.l.),weimi003@yahoo.com (w.l.),\\nwangguangyu@mail.tsinghua.edu.\\ncn (g.w.)\\nin brief\\nzhang et al. present an ai-based system,\\nbased on hundreds of thousands ofhuman lung ct scan images, that can aidin distinguishing patients ncp versusother common pneumonia and can helpto predict the prognosis of covid-19patients.\\nzhang et al., 2020, cell 181, 1423–1433\\njune 11, 2020 ª2020 elsevier inc.\\nhttps://doi.org/10.1016/j.cell.2020.04.045 ll\\nian update to this article is included at the end\\n',\n",
       " 'resource\\nclinically applicable ai system for accurate\\ndiagnosis, quantitative measurements, and prognosisof covid-19 pneumonia using computed tomography\\nkang zhang,1,14,15, *xiaohong liu,2,14jun shen,3,14zhihuan li,4,5,14ye sang,6,14xingwang wu,7,14yunfei zha,8,14\\nwenhua liang,9,14chengdi wang,4,14ke wang,2linsen ye,10ming gao,3zhongguo zhou,1liang li,8jin wang,10\\nzehong yang,3huimin cai,5jie xu,1lei yang,5wenjia cai,5wenqin xu,1shaoxu wu,3wei zhang,3shanping jiang,3\\nlianghong zheng,5,11xuan zhang,2li wang,8liu lu,5,11jiaming li,5,11haiping yin,12winston wang,1oulan li,5\\ncharlotte zhang,5liang liang,6tao wu,6ruiyun deng,1,11kang wei,1yong zhou,1ting chen,2johnson yiu-nam lau,13\\nmanson fok,1jianxing he,9,*tianxin lin,3,*weimin li,4,*and guangyu wang2,*\\n1faculty of medicine, macau university of science and technology, macau, china\\n2department of computer science and technology & bnrist, tsinghua university, beijing, china\\n3departments of urology, radiology, emergency medicine, and respiratory medicine, sun yat-sen memorial hospital, sun yat-sen\\nuniversity, guangzhou, china\\n4center for translational innovations and department of respiratory and critical care medicine, west china hospital, west china school of\\nmedicine, sichuan university, chengdu, china\\n5guangzhou regenerative medicine and health guangdong laboratory, guangzhou, china\\n6the first college of clinical medical science, china three gorges university, yichang, china\\n7department of radiology, the first afﬁliated hospital of anhui medical university, hefei, china\\n8department of radiology, department of infection prevention and control, renmin hospital, wuhan university, wuhan, china\\n9department of thoracic surgery/oncology, the first afﬁliated hospital of guangzhou medical university, china state key laboratory and\\nnational clinical research center for respiratory disease, guangzhou, china\\n10department of radiology, and liver disease center, sun yat-sen third afﬁliated hospital, sun yat-sen university, guangzhou, china\\n11guangzhou kangrui ai technology co. and guangzhou huiborui biological pharmaceutical technology co., ltd, guangzhou, china\\n12the first people’s hospital of yunnan province, kunmin, china\\n13department of applied biology and chemical technology, hong kong polytechnic university, hong kong, china\\n14these authors contributed equally\\n15lead contact\\n*correspondence: kang.zhang@gmail.com (k.z.), hejx@vip.163.com (j.h.), lintx@mail.sysu.edu.cn (t.l.), weimi003@yahoo.com (w.l.),\\nwangguangyu@mail.tsinghua.edu.cn (g.w.)\\nhttps://doi.org/10.1016/j.cell.2020.04.045\\nsummary\\nmany covid-19 patients infected by sars-cov-2 virus develop pneumonia (called novel coronavirus pneu-\\nmonia, ncp) and rapidly progress to respiratory failure. however, rapid diagnosis and identiﬁcation of high-risk patients for early intervention are challenging. using a large computed tomography (ct) database from3,777 patients, we developed an ai system that can diagnose ncp and differentiate it from other commonpneumonia and normal controls. the ai system can assist radiologists and physicians in performing a quickdiagnosis especially when the health system is overloaded. signiﬁcantly, our ai system identiﬁed importantclinical markers that correlated with the ncp lesion properties. together with the clinical data, our ai system\\nwas able to provide accurate clinical prognosis that can aid clinicians to consider appropriate early clinical\\nmanagement and allocate resources appropriately. we have made this ai system available globally to assistthe clinicians to combat covid-19.\\nintroduction\\nthe outbreak of the 2019 novel coronavirus (sars-cov-2)\\nbegan in early december of 2019 ( munster et al., 2020; wang\\net al., 2020 ). the infection has a mean incubation period of\\n5.2 days and causes fever, cough, and other ﬂu-like symptoms.\\nit can affect multiple tissues and organ systems, and collectively\\nthe viral-induced disease is termed covid-19. many affectedpatients develop pneumonia (called novel coronavirus pneu-\\nmonia, ncp) and progress rapidly into severe acute respiratoryfailure with a very poor prognosis and high mortality ( guan\\net al., 2020; huang et al., 2020a ). person-to-person transmission\\nhas been established ( chan et al., 2020; phan et al., 2020; rothe\\net al., 2020; zhu et al., 2020 ), and the world health organization\\n(who) has declared covid-19 to be pandemic. studies have\\nshown that over 60% of patients died once they progressed\\nll\\ncell181, 1423–1433, june 11, 2020 ª2020 elsevier inc. 1423',\n",
       " 'into the severe or critical illness stage ( guan et al., 2020; huang\\net al., 2020a ). therefore, identifying risk factors and parameters\\nthat can allow the creation of an accurate prognosis predictive\\nmodel and hopefully lead to improved clinical outcomes are crit-ical in the planning of early intervention and intense monitoring in\\nsuch a pandemic.\\ncurrently, an individual with fever, cough, and ﬂu symptoms\\nwould be screened ﬁrst by clinical assessments, laboratorytests, and a chest x-ray to rule out pneumonia. if viral pneumonia\\nis diagnosed, being able to diagnose ncp is of paramount\\nimportance for obvious public health reasons. a covid-19 diag-nosis is conﬁrmed by a positive molecular pcr test. chest\\ncomputed tomography (ct) is an important tool in the diagnosis\\nof lung diseases including pneumonia. ct scanning procedurehas a faster turnaround time than a molecular diagnostic test\\nperformed in a standard laboratory, can provide more detailed\\ninformation related to the pathology, and is better for the quan-titative measurement of lesion size and the extent or severity oflung involvement, which may have prognostic implications ( shi\\net al., 2020 ). as seasonal ﬂu also causes viral pneumonia, it is\\nalso important to differentiate ncp from the common ﬂu or othertypes of pneumonia such as viral pneumonia and bacterial pneu-\\nmonia. therefore, an accurate ct-based artiﬁcial intelligence (ai)\\nsystem may have the potential to assist in the early diagnosis forplanning, monitoring and treatment, and establishing the refer-\\nence for longitudinal follow ups ( huang et al., 2020b; xie\\net al., 2020 ).\\nrecent new and exciting advances in the applications of ai in\\nmany healthcare areas ( esteva et al., 2019; gulshan et al., 2016;\\nli et al., 2018; norgeot et al., 2019; poplin et al., 2018; ravizzaet al., 2019; ting et al., 2017; topol, 2019 ) have inspired innova-\\ntions in the development of novel ai-based radiological diag-\\nnostic technology. chen ( chen et al., 2020 ) reviewed various\\nquantitative models of thin-section ct of the chest and showedeffectiveness of quantitative tools in both accurate diagnosis and\\nlongitudinal follow-up. another study showed that deep learning\\nalgorithms helped to identify head ct abnormalities that canassist the clinical triage process ( chilamkurthy et al., 2018 ).\\nrecent studies demonstrated the potential of integrating ai\\ninto both the eye and childhood-disease diagnostic systemsand found that it signiﬁcantly improved clinical diagnostic efﬁ-ciency and accuracy ( burlina et al., 2017; kermany et al., 2018;\\nlong et al., 2017; van grinsven et al., 2016 ). therefore, with a\\nmore accurate tool in ct scans, we hypothesized that an ai sys-tem can be established to accurately diagnose ncp, and this will\\nassist radiologists and clinicians in the management of patients\\nwith symptoms suggestive of covid-19 ncp.\\nanother urgent need is to identify the patients with higher risks\\nof developing acute respiratory failure so that they can be moni-\\ntored closely earlier and receive intervention treatment early.otherwise, such patients will have a higher chance of eventually\\ndeveloping multi-organ failure associated with high mortality\\n(yang et al., 2020 ). as lesion characteristics, including number,\\nsize, and density of lesions and also the overall lung paren-chyma, are indicators of lung damage and remaining lung\\nreserve, we also tested the hypothesis as to whether an ai sys-\\ntem can be established using both clinical data and ct parame-ters to generate an accurate clinical prognostic model, allowingclinicians to plan for early monitoring and management of these\\npatients. accordingly, we have constructed a large ct dataset\\non ncp and other common pneumonia and normal controls,\\nand we developed an ai diagnostic system for assisting the ac-curate diagnosis for application in an epidemic area and two\\nnon-epidemic areas in china. we also provided prognosis indi-\\ncations for patients with ncp by using a combination of ctand clinical parameters, with an aim to provide another tool toassist physicians ( figure 1 ).\\nresultspatient characteristics and image datasets\\na large ct dataset encompassing patient cohorts from the chinaconsortium of chest ct image investigation (cc-ccii) was con-\\nstructed, which consisted of a total of 617,775 ct images from\\n4,154 patients. ct images from 3,777 patients were employedto train and test our ai systems for differentiating ncp from other\\ncommon pneumonia and normal controls ( figures 1 and s1;\\ntable s1 ). the common pneumonia group consisted of viral\\npneumonia, bacterial pneumonia, and mycoplasma pneumonia,\\nall of which are the most common causes of pneumonia in china.\\nour ai covid-19 diagnostic system consisted of two modelsincluding a lung-lesion segmentation model and a diagnosisanalysis model (figures 1 ands2). we constructed a segmenta-\\ntion network trained with 4,695 manually segmented slices from\\nncp patients and common pneumonia patients. for the classiﬁ-cation model, 361,221 ct images from 2,246 patients including\\n752 ncp patients, 797 common pneumonia patients, and 697\\nnormal control patients were used for training ( table s1 ). our\\nai system performance of diagnosis prediction was also tested\\nin one retrospective cohort and three prospective pilot studies\\nconsisting of one in an epidemic area and two in non-epidemicareas in china. in addition, we have tested our ai diagnostic per-formance internationally using ct data generated outside china.\\nfor the ct quantitative and correlation analysis with clinical pa-\\nrameters, 843 hospital-admitted ncp patients with clinical meta-data were included. of these, 456 hospitalized patients with\\ncomprehensive ct images and clinical outcome information\\nwere subject to a prognosis prediction and survival analysisand the establishment of a clinical prognosis estimation\\n(figure 1 ).\\nlung-lesion segmentation\\na two-stage segmentation framework for accurately segmenting\\nlung lesions from normal lung ﬁelds and background on raw ctslices with processing-time efﬁciency and accuracy was con-\\nstructed ( figure s2 ). a total of 4,695 ct slice images were manu-\\nally annotated at the pixel level into seven classes, includingbackground, lung ﬁeld, consolidation (cl), ground-glass opacity(ggo), pulmonary ﬁbrosis, interstitial thickening, and pleural\\neffusion.\\nto study our ai system performance on ct slice segmenta-\\ntion, several classic semantic segmentation tools as the back-\\nbone of our segmentation framework were tested, including\\nu-net ( ronneberger et al., 2015 ), drunet ( devalla et al.,\\n2018 ), fcn ( long et al., 2015 ), segnet ( badrinarayanan et al.,\\n2017 ), and deeplabv3 ( chen et al., 2017 ). we evaluated systemll\\n1424 cell181, 1423–1433, june 11, 2020resource',\n",
       " 'performance with two evaluation metrices including dice coefﬁ-\\ncient (dc) and pixel accuracy (pa) by a ﬁve-fold cross-validation\\ntest ( table s3 ). we adopt deeplabv3 as the backbone for sub-\\nsequent analyses for its better segmentation performance.compared to human experts, our segmentation network ob-tained smoother and clearer lesion segmentation boundaries\\nand archived a high accuracy ( figures 2 ands3).\\naccurate diagnosis of ncp\\nto distinguish ncp from other common pneumonia and normalcontrols, we employed a diagnostic system based on a lung-\\nlesion segmentation model and a diagnosis analysis model.\\nthe diagnosis classiﬁcation took the lung-lesion map as an inputgenerated by segmentation networks and utilized the normalizedct volumes for further diagnosis prediction. while real-world\\noriginal scans contained noises and varied for different devices\\nand human operations, our approach provided better general-ization and interoperability during clinical implementations\\ninstead of end-to-end black-box networks.\\nwe used a total of 40,880 slices from 260 patients including\\n83 ncp patients, 91 common pneumonia patients, and 86\\nnormal controls to test our diagnosis classiﬁer model as an in-ternal validation ( table s1 ). our system was able to differentiate\\nncp from other two classes (other common pneumonia and\\nnormal controls) with 92.49% accuracy, 94.93% sensitivity,\\n91.13% speciﬁcity, and an area under the receiver operatingcharacteristic (auroc) of 0.9797 (95% ci: 0.9665–0.9904) onan internal validation dataset. the overall performance for\\nthree-way classiﬁcation obtained 92.49% accuracy and an\\nauroc of 0.9813 (95% conﬁdence interval [ci]: 0.9691–0.9902) ( figures 3 a and 3b).\\nai system performance evaluation in independent\\nchinese and international cohorts\\nto address regional variations and general applicability of our aidiagnostic system, our ai system performance was tested in fourother different regions using different datasets. speciﬁcally, our\\nai performance was tested in a retrospective study in an external\\ncohort from an epidemic area in hubei, china (city of yichang). inaddition, we also tested our ai system performance in three\\nother regions in a prospective fashion, with one cohort from\\nthe epicenter hubei, china (city of wuhan) and two cohortsfrom other non-epidemic areas in china (city of hefei and city\\nof guangzhou).\\na\\nb\\nfigure 1. our proposed ai framework for ncp diagnosis and prognosis prediction\\n(a) a large ct dataset was constructed using the data from cc-ccii (532,506 ct images from ncp, common pneumonia, and normal controls). the ncp\\ndiagnosis system consisted of two models: a lung-lesion segmentation model and a diagnosis prediction model. we ﬁrst trained a segmentation network with\\n4,695 manually segmented images from ncp and common pneumonia patients. the diagnosis classiﬁer took as input the previous lung-lesion map andgenerated probability of three classes: ncp, common pneumonia, and normal controls with classiﬁcation networks. a number of prospective pilot stud ies were\\nalso conducted to test our ai performance for clinical application.(b) ai-assisted clinical prognosis estimation based on ct quantitative parameters and clinical metadata. a system for risk factor evaluation and ka plan-meier\\ncurve analysis for severe or critical illness as deﬁned in the text was also implemented.see also figures s1, s2 , and s7andtable s1 .ll\\ncell181, 1423–1433, june 11, 2020 1425resource',\n",
       " 'in a retrospective study in the city of yichang, hubei prov-\\nince, china, 155 ncp patients, 36 common pneumonia pa-\\ntients, and 17 normal controls who underwent ct imaging\\nwere enrolled in this study ( table s1 ). our ai diagnostic system\\narchived 90.70% accuracy, 92.15% sensitivity, 85.92% speci-\\nﬁcity, and auroc of 0.9805 (95% ci: 0.9662–0.9899) for ncp\\nversus all other groups and an accuracy of 89.92% and aurocof 0.9805 (95% ci: 0.9662–0.9899) for the overall three-wayclassiﬁcation (ncp, common pneumonia, and normal controls)\\n(figures 3 c and 3d).\\nthe ﬁrst prospective pilot study was conducted in wuhan, hu-\\nbei province, china (the epicenter) from january 25 to march 18,\\n2020 ( table s1 ). our ai diagnostic system achieved 91.20% ac-\\ncuracy, 94.03% sensitivity, 88.46% speciﬁcity, and auroc of0.9610 (95% ci: 0.9403–0.9785) for ncp versus all other groups\\ntogether and an accuracy of 91.20% and auroc of 0.9741\\n(95% ci: 0.9583–0.9856) for the overall three-way classiﬁcation(ncp, common pneumonia, and normal controls) in this pro-\\nspective study cohort ( figures 4 a and 4b).\\na second prospective pilot study was conducted in a non-\\nepidemic region in hefei, anhui province, china, from february2 to march 25, 2020 ( table s1 ). our ai diagnostic system\\narchived 90.32% accuracy, 94.74% sensitivity, 89.19% speci-\\nﬁcity, and auroc of 0.9700 (95% ci: 0.9500–0.9872) for ncpversus all other groups together and an accuracy of 91.76%\\nand auroc of 0.9776 (95% ci: 0.9630–0.9899) for the overall\\nthree-way classiﬁcation (ncp, common pneumonia, and normalcontrols) in this second study prospective cohort ( figures 4 c\\nand 4d).\\na\\nb\\ncfigure 2. performance of our ai system on\\na lesion segmentation task shown inthree examples\\nleft column: original ct slices from three ncp\\npatients; middle column, manually segmentedct slices; right column, ai-based automatedsegmented ct slices.row (a) a ct slice with mild ncp lesions deﬁnedas small ground-glass opacities (ggo) of bilaterallung involvement.row (b) a ct slice with intermediate ncp lesions.bilateral and predominantly peripheral lesions ofggo.row (c) a ct slice with severe ncp lesions.bilateral and peripheral mixed lesions of ggo andconsolidation shadows.\\nthe severity level deﬁnitions are as follows: mild,\\ndeﬁned as less than three ggo lesions of size lessthan 3 cm; intermediate, deﬁned as a lesion areamore than 25% of the entire lung ﬁeld; severe,deﬁned as a lesion area more than 50% of theentire lung ﬁeld.see also figure s3 andtable s2 .\\nthe third prospective pilot study was\\nconducted in another non-epidemic re-gion in guangzhou, guangdong province(china) from february 8 to march 27,\\n2020 ( table s1 ). our ai diagnostic system\\narchived 84.78% accuracy, 90.00%\\nsensitivity, 84.15% speciﬁcity, and auroc of 0.9512 (95% ci:\\n0.9124–0.9820) for ncp versus all other groups together and\\nan accuracy of 89.67% and auroc of 0.9755 (95% ci:0.9545–0.9896) for the overall three-way classiﬁcation (ncp,\\ncommon pneumonia, and normal controls) ( figure 4 e and 4f).\\nto validate our ai system’s general applicability outside china,\\nwe obtained ct images from an open source and additional data\\nfrom our collaborators in ecuador ( table s1 ). our ai diagnostic\\nsystem achieved 84.11% accuracy, 86.67% sensitivity,82.26% speciﬁcity, and auroc of 0.905 (95% ci: 0.8421–0.9612) for ncp versus all other groups together and an accu-\\nracy of 85.05% and auroc of 0.9381 (95% ci: 0.8944–\\n0.9742) for the overall three-way classiﬁcation ( figures s5 a\\nand s5b). together, these ﬁve studies conﬁrmed the high perfor-\\nmance, accuracy, and general applicability of the ai diagnostic\\nsystem both within china and internationally.\\nevaluation of drug treatment effects on ai-based\\nlesion quantitative measurementswe also evaluated the effect of drug treatment on lesion size andvolume changes using our ai-generated quantitative measure-\\nments. ncp patients undergoing three different drug treatment\\ntrials were analyzed. the enrollment criteria included aconﬁrmed ncp diagnosis by a positive viral pcr test and no\\nother prior treatment history. we quantiﬁed lung lesions (ggo\\nand total lesion volumes) on ct scans and compared the differ-ences between pre-treatment and post-treatment results for\\nthree administered experimental drugs. the ct scans demon-\\nstrated quantitative lesion changes, indicating the potential ofll\\n1426 cell181, 1423–1433, june 11, 2020resource',\n",
       " 'our ai system in the evaluation of drug treatment efﬁcacy in an\\nobjective quantitative way ( figure s4 ).\\ncomparison of the ai system against practicing\\nradiologists\\nan independent test dataset of 18,392 ct slice images from 150\\npatients, including 40 ncp patients, 80 common pneumonia pa-tients, and 30 normal control patients, was used to compare the\\nai system’s performance with practicing radiologists in classi-\\nfying ncp versus other pneumonia. we employed eight radiolo-gists in two groups to participate in the study: four radiologists inthe junior group with 5 to 15 years of clinical experience, and\\nfour radiologists in the senior group with 15 to 25 years of\\nclinical experience. ground truth was established based on aconsensus from an independent group of four senior radiologists\\nwith 25 or more years of clinical experience.\\nwe then compared the performance between our ai system\\nand radiologists on differentiating ncp from other common\\npneumonia and normal controls. our ai system performance\\nwas overall superior to that of junior radiologists and comparableto mid-senior radiologists ( figures 5 a and 5b). we used pre-\\ndicted errors, based on penalty scores ( figures 5 c and s5c),\\nto create a metric to evaluate and compare performance be-\\ntween our ai system and the radiologists. our ai system yieldeda weighted error of 9.29% compared to a range of weighted er-\\nrors by the experts ranging from 7.14% to 19.15% with a mean of\\n13.55% ( figure 5 c).\\nto investigate whether our ai system could help junior radiol-\\nogists to improve their diagnostic performance, each junior radi-ologist was given diagnosis probability on each patient by the ai\\nsystem and was asked to make a diagnosis with the assistance\\nof the ai-generated results. to avoid a potential memorization\\nbias, the follow-up ai-assisted diagnostic test by junior radiolo-gists was performed 2 weeks after the initial test. the perfor-\\nmance was signiﬁcantly improved compared to the previous\\none and was comparable to that of the senior radiologists(figure 5 ).\\nlung-lesion features and correlations with key clinical\\nparametersthe ratio of total lesions (named lesions), cl, or ggo to an\\nentire lung ﬁeld was chosen as three lesion indicators (fea-\\ntures). the correlations analysis between quantitative lesionfeatures and clinical parameters were performed, and key\\nclinical and biochemical markers were determined. spear-\\nman’s and pearson’s correlations were employed to studythe association between quantitative lesion features on a ct\\nscan and clinical parameters. c-reactive protein (crp), age,\\nserum lactic dehydrogenase (l dh), highest body temperature\\n(tmax), and neutrophil-to-lymphocyte ratio showed highlypositive correlations with the lesion features. by contrast, de-\\ngree of blood oxygen saturation, lymphocyte count, albumin,\\nblood platelets, and na\\n+showed highly negative correlations\\nwith the lesion features ( figures 6 a–6d and s6a–s6e). we\\nalso designed a composite score (c-score) system using inter-\\nnational guidelines to evaluate co rrelations between the lesion\\nfeatures and degree of lung and liver organ damage (see\\nstar methods for more details), which showed a positiveb\\nd cafigure 3. performance of our ai system in\\nidentifying ncp patients from patientswith other common types of pneumoniaand normal controls\\n(a–d)receiver operating characteristics (roc)\\ncurves and normalized confusion matrices ofmulticlass classiﬁcations. the blue curve denotedmacro-average area under the curve (auc) of one(ncp) versus other two classes, including com-mon pneumonia (cp) and normal controls(normal). ci, conﬁdence interval.(a and b )ai system performance on internal vali-\\ndation data. (a) roc curves. (b) normalizedconfusion matrix. for three-way classiﬁcation:accuracy = 92.49%, auroc = 0.9813 (95% ci:0.9691–0.9902). for ncp versus the rest: accu-\\nracy = 92.49%, sensitivity = 94.93%, speciﬁcity =\\n91.13%, auroc = 0.9797 (95% ci: 0.9665–0.9904).(c and d )ai performance on independent external\\nvalidation data in yichang (hubei, china). (c) roccurves. (d) normalized confusion matrix. for athree-way classiﬁcation: accuracy = 89.92%,auroc = 0.9805 (95% ci: 0.9662–0.9899). forncp versus the rest: accuracy = 90.70%, sensi-tivity = 92.51%, speciﬁcity = 85.92%, auroc =0.9712 (95% ci: 0.9516–0.9855).see also figure s5 .ll\\ncell181, 1423–1433, june 11, 2020 1427resource',\n",
       " 'correlation between the lesion size and degree of organ dam-\\nage ( figure 6 e). together, these data suggest lung lesions\\ncould not only directly correlate with the respiratory systemfunction, but also with the clinical parameters of other organ\\nsystems, suggesting the interconnectivity between lung le-\\nsions and the health of other major organs and potentialconcomitant advancement of damages contributing to multi-\\nple organ failures. obviously, we would like to emphasize\\nthat our current data only showed the correlation of thesechanges without any direct knowledge of the exact underlyingpathogenetic mechanisms (e.g., secondary to respiratory fail-\\nure or/and direct viral involvement).\\nprognostic factors and development of a prognostic\\nmodel for critical illness\\nnext, the clinical and radiological features that contributed to theprogression to critical illness were further analyzed to develop an\\nai-assisted model to estimate the clinical prognosis. a c-scoreab\\nd\\nfecfigure 4. performance of the ai system in\\nprospective pilot studies in four indepen-dent chinese cohorts\\n(a–f)roc curves and normalized confusion\\nmatrices of multiclass classiﬁcations. the bluecurve denoted macro-average auc of one (ncp)versus other two classes, including commonpneumonia (cp) and normal controls (normal).(a and b )ai system performance on a cohort from\\nan epidemic area in china (city of wuhan). (a) roccurves. (b) normalized confusion matrix. forthree-way classiﬁcation: accuracy = 91.20%,auroc = 0.9741 (95% ci: 0.9583–0.9856). forncp versus the rest: accuracy = 91.20%, sensi-tivity = 94.03%, speciﬁcity = 88.46%, auroc =0.9610 (95% ci: 0.9403–0.9785).\\n(c and d )ai system performance on a cohort from\\na non-epidemic area in china (city of hefei). (c)roc curves. (d) normalized confusion matrix. forthree-way classiﬁcation: accuracy = 91.76%,auroc = 0.9776 (95% ci: 0.9630–0.9899). forncp versus the rest: accuracy = 90.32%, sensi-tivity = 94.74%, speciﬁcity = 89.19%, auroc =0.9700 (95% ci: 0.9500–0.9872).(e and f )ai system performance on a cohort from\\na non-epidemic area in china (city of guangzhou).(e) roc curves. (f) normalized confusionmatrix. for three-way classiﬁcation: accuracy =89.67%, auroc = 0.9755 (95% ci: 0.9545–0.9896). for ncp versus the rest: accuracy =84.78%, sensitivity = 90.00%, speciﬁcity =84.15%, auroc = 0.9512 (95% ci:0.9124–0.9820).\\nbased on quantitative lung-lesion fea-\\ntures extracted by the ai system and clin-\\nical parameters (e.g., age, albumin, bloodoxygen saturation, crp) was created and\\napplied to predict the clinical outcome\\ndeﬁned by the progression (time fromthe initial hospital admission) to severeor critical illness (deﬁned by death or the\\nclinical need for mechanical ventilation or to be transferred to\\nthe icu). we implemented light gradient boosting machine(lightgbm) and cox proportional-hazards (coxph) regression\\nmodels for prognosis prediction. for interpreting the effects\\nand relative contributions of the lung-lesion features and clinicalparameters on prognosis prediction, we implemented an\\nexplainer shapley additive explanation (shap) ( lundberg\\net al., 2018a and2018b ).\\nas expected, the lesion features were identiﬁed as the most\\nsigniﬁcant contributors in the clinical prognosis estimation. in\\naddition, clinical parameters relating to respiratory function (ox-\\nygen saturation index and respiratory rate) and general clinicalcharacteristics (age, the body temperature on admission, and\\ntmax) also contributed to the prediction of progression to severe\\nor critical illness requiring an icu admission. interestingly, addi-tional prognostic markers were also identiﬁed, including liver\\nbiochemistry markers (albumin, serum ldh, indirect bilirubin),\\ncoagulation markers (thrombin time, activated partialll\\n1428 cell181, 1423–1433, june 11, 2020resource',\n",
       " 'thromboplastin time (aptt), platelet count), electrolyte and acid-\\nbase balance (na+,k+, hco 3-), and markers of inﬂammation\\n(crp, lymphocyte count, neutrophil count) ( figures 7 c and 7d;\\ntable s4 ), suggesting the overall health of other tissues or or-\\ngans and systemic homeostasis also played an important role\\nin determining the clinical prognosis of these patients in terms\\nof their evolving into severe/critical illness status.\\nauroc curves were then generated to measure the impact\\nof the ncp lesions and clinical metadata on progression to crit-ab\\nd\\nfe\\ngcfigure 5. comparisons of diagnostic per-\\nformance between our ai model and prac-ticing radiologists\\n(a and b) the performance of our ai system and\\neight practicing radiologists (four junior level andfour senior level). roc curve for diagnosis of ncpversus other classes. filled dots denote junior andsenior radiologists’ performances, while the hol-low dots denote the performance of junior groupwith ai assistance. dashed lines linked the pairedperformance values of each junior radiologist.(c) weighted error results based on penalty scores(see figure s5 ).\\n(d–g) confusion matrices of multiclass classiﬁ-cation. (d) confusion matrix of the mean diag-nostic performance of four junior radiologists.\\n(e) confusion matrix of the mean diagnostic\\nperformance of four junior radiologists with aiassistance. (f) confusion matrix of the meandiagnostic performance of four senior radiologists.(g) the ai system demonstrated performancecomparable to that of senior practicing radiolo-gists. accuracy = 90.71%, sensitivity = 92.50%,speciﬁcity = 90.00%, auroc = 0.9756 (95% ci:0.9496–0.9948).\\nical illness. lung-lesion features alone\\ngave an area under the curve (auc) of\\n0.8479. when combined with clinical\\nmetadata, the performance of our modelimproved signiﬁcantly to an auc of\\n0.9093 (95% ci: 0.8775–0.9369), with a\\nspeciﬁcity of 80.00% and sensitivity of86.71% ( figures 7 a and 7b).\\nkaplan-meier curves using a c-score\\nwere generated based on these lunglesion and clinical parameters ( fig-\\nure s6 f). based on the current size\\nof the database, we stratiﬁed the pa-tients into two groups: the high-riskgroup with a c-score of r0.5 and\\nthe low-risk group with a c-score\\nof < 0.5. the high-risk group (158 ob-servations with 133 events) had a\\nmuch lower survival probability\\ncompared to the low-risk group (274observations with 37 events) with a\\nhighly signiﬁcant statistical difference\\nin medium survival (p < 0.001, log-rank test; figure 7 e). these results\\nsuggest that a combination of lung lesions and clinical\\nmetadata can contribute signiﬁcantly to the prognosis pre-\\ndiction. it is also important to note that the curves willalso provide estimates as to the time in days that critical\\ncare demands will be needed. certainly, with a larger data-\\nbase in the future, our ai system may be able to provide aneven more reﬁned clinical prognostic model stratiﬁed into\\nmore groups with different levels of risks that are associated\\nwith different clinical prognoses.ll\\ncell181, 1423–1433, june 11, 2020 1429resource',\n",
       " 'discussion\\nin this study, we described an ai system for the diagnosis of\\ncovid-19 pneumonia based on chest ct images. the perfor-\\nmance of our ai system was comparable to that of practicing ra-\\ndiologists with signiﬁcant clinical experience and could assistand improve the performance of junior radiologists. this ai effortis driven by the desire to develop a system for rapid diagnosis of\\nncp to assist radiologists and clinicians in combating this\\npandemic. such an ai system can also ease the signiﬁcant de-mand for diagnostic expertise when the health system is over-\\nloaded in a pandemic situation or in remote areas. at present,\\nour ai system is designed to assist radiologists and cliniciansas an efﬁcient ﬁrst reading and/or screening tool as this may\\nreduce patient waiting time, shortening diagnostic workﬂow\\ntime and therefore lessoning a radiologist’s overall workloadand allowing them to respond quickly and more effectively in\\nan emergency situation. the precise measurement of the\\ndifferent lung damage parameters in the ct scan will also allowan objective and quantitative measurement of the diseaseseverity and has the potential to provide an objective and quan-\\ntitative evaluation of the efﬁcacy of a drug treatment, including\\nantivirals and other immunomodulators, on the lung lesions.\\nthe correlation of the lesion features in the ct scans as evalu-\\nated by our ai system and the clinical and biochemical evidence of\\ndisease severity based on other organ systems’ laboratory pa-rameters highlighted the pathogenesis interlink involving different\\norgans of covid-19. from a pathogenetic mechanistic perspec-tive, our study can only show the correlation, and it remains to be\\ndetermined through other pathogenesis studies whether this\\ninterlink is established directly through viral infection of these or-gans and/or secondary respiratory failures. the higher correlation\\nwith the lung lesions with outcomes compared to that of other clin-\\nical parameters did highlight the importance of lung damage asthe key parameter in the overall prognostic implications. the as-sociation of age and outcome is consistent with recent reports\\nthat older age is a signiﬁcant risk factor for poor outcomes ( huang\\net al., 2020a ). the identiﬁcation of the other parameters including\\ncrp, serum sodium concentration, serum albumin, and platelet\\ncount as prognostic factors is consistent with the prognostic fac-\\ntors seen in patients with multi-organ failure. an increased crplevel may reﬂect the heightened systemic acute inﬂammation re-\\nﬂected in the severity of pulmonary inﬂammation, consistent with\\nthe prominent lung inﬂammation as observed in ct scans andpostmortem studies. the association with liver and renal\\nbiochemistry with prognosis may be another reﬂection of the\\nmulti-organ failure observed in patients with severe or criticalcovid-19, although whether there is direct viral involvement ofthese organs cannot be addressed in this study.\\nthe development of a clinical prognostic model based on our\\nai system utilizing ct parameters and clinical data was an impor-tant advancement toward the use of ai as assisting clinical man-\\nagement. based on our database, we were able to identify a\\nc-score of r0.5 as the high-risk group in terms of the eventual\\nprogression into severe or critical illness resulting in icu admis-\\nsion, mechanical ventilation, or death. importantly, an estimated\\nab c\\nde\\nfigure 6. the correlation of lung-lesion features with clinical parameters\\n(a–c) linear regression analysis comparing the volume lesion ratio and three correlated clinical parameters, including (a) age, (b) crp, and (c) alb umin.\\n(d) correlation of three ct quantiﬁcation features (volume ratio of ggo, cl, and total lesion) with clinical parameters. see star methods for details.\\n(e) the correlations of the volume ratio of lesion and the c-scores for lung function and liver functions graded by physicians. all p values remained st atistically\\nsigniﬁcant after the holm-bonferroni adjustment. ldh, lactic dehydrogenase.see also figure s6 .ll\\n1430 cell181, 1423–1433, june 11, 2020resource',\n",
       " 'a\\nc\\neb\\nd\\nfigure 7. risk factors and clinical prognosis analysis for progression to severe or critical illness\\n(a) the roc curves for a binary classiﬁcation of progression to critical illness stratiﬁed by lesion features and the combination of lesion features a nd clinical\\nmetadata.(b) corresponding normalized confusion matrix: sensitivity = 80.00%, speciﬁcity = 86.71%, auroc = 0.9093 (95% ci: 0.8775–0.9369).(c and d) illustration of features contributing to progression to critical illness by shap values. (c) the relative contributions of ct and clinical p arameters for\\nprognosis prediction. features on the right of the risk explanation bar pushed the risk higher, and features on the left pushed the risk lower. (d) the r elative\\ncontribution of each of the ct or clinical parameters to predict the risk of progression to severe or critical illness.\\n(e) when the patients were stratiﬁed into high-risk (c-score r0.5) and low-risk (c-score < 0.5) groups, kaplan-meier curves of progression to critical illness\\nshowed a distinct difference in survival probability in this cohort. aptt, activated partial thromboplastin time; c-reactive protein, crp; ground -glass opac-\\nity, ggo.see also figures s4, s6 , and s7andtable s4 .ll\\ncell181, 1423–1433, june 11, 2020 1431resource',\n",
       " 'time to this progression can also be provided. this information\\nwill assist clinicians in planning monitoring and allocating re-\\nsources in the icu, and in case of an epidemic, it will allow the\\nhealthcare system to have a few more days to react to the de-mand of resources.\\nin summary, an ai system that can accurately diagnose ncp\\nand assist radiologists and physicians has been developed. agood correlation between the ncp lung lesions as reviewed byct parameters and the clinical and biochemical markers of mul-\\ntiple organs was observed, highlighting that multi-organ failure\\nwere observed in covid-19. together with the clinical prog-nostic estimation function, this ai system can assist radiologists\\nand physicians such as emergency room (er) physicians and\\npulmonologists to accurately diagnose patients rapidly, andwith the prognostic estimation generated, it can assist the physi-\\ncians in determining the subset of patients that will require close\\nmonitoring and early intervention and/or support as needed andthe estimated timing of these needs.\\nas this ai system may be of help to physicians and healthcare\\nsystems globally to better manage their patients during this\\npandemic, we are opening up this ai system to all radiologistsand clinicians and hope that this can assist their management of\\npatients, and the data that they input may further perfect our ai\\nsystem, which we hope can evolve as a versatile tool for the globalcommunity to combat covid and other emerging viral infections.\\nfor an example of the clinical deployment, see figure s7 .\\nstar+methods\\ndetailed methods are provided in the online version of this paper\\nand include the following:\\ndkey resources table\\ndresource availability\\nblead contact\\nbmaterials availability\\nbdata and code availability\\ndexperimental model and subject details\\nbhuman subjects\\nbexperimental data\\ndmethods details\\nbimage labeling and quality control\\nbai versus radiologists comparison\\nbprospective pilot studies\\nbdiagnosis system and network architectures\\nbevaluation of drug treatment effects\\nblung-lesion features and clinical parameters\\nbprognosis analysis\\ndquantification and statistical analysis\\nsupplemental information\\nsupplemental information can be found online at https://doi.org/10.1016/j.\\ncell.2020.04.045 .\\nacknowledgments\\nwe thank many physicians in china who generously donated their time and\\nexpertise for this project. we thank drs. roberto hidalgo and daniel recaldein guayaquil, ecuador for providing de-identiﬁed ct images from ncp pa-\\ntients, other common pneumonia patients, and normal patients. we thankmembers of zhang, lin, and wang groups for their assistance and helpful dis-cussions. we thank many volunteers and physicians for grading ct imagesand medical records. this study was funded by the national key researchand development program of china (2019yfb1404804); national naturalscience foundation of china (grants 61906105, 61872218, 61721003,61673241, 81871890, and 91859203); a macao fdct grant (0035/2020/a);guangzhou regenerative medicine and health guangdong laboratory(2020gzr110306001); a kunmin science and technology grant (2020-1-h-\\n003); special item for prevention and control of covid-19 science and tech-\\nnology, guangdong province; tencent charity foundation; the three specialitems of sun yat-sen university for novel coronavirus, the keyareas research and development program of guangdong (grant no.2018b010109006); and the guangdong provincial clinical research centerfor urinary diseases, recruitment program of leading talent in guangdongprovince (2016lj06y375).\\nauthor contributions\\nx.l., j.s., z.l., y.s., x.w., y.c., w liang, c.w., k. wang, l. ye, m.g., z.z., l.\\nli., j.w., z.y., h.c., j.x., l. yang, w.c., w.x., s.w., w.z., s.j., l.z., x.z., l.w.,l. lu., j.l., h.w., w.w., o.l., c.z., l. liang., t.w., r.d., k. wei, y. zhou, t.c.,m.f., j.y.-n.l., j.h., t.l., w. li, g.w., and k.z. collected and analyzed thedata. k.z. and g.w. conceived and supervised the project and wrote themanuscript with assistance from t.l., m.f., and j.y.-n.l. all authors dis-\\ncussed the results and reviewed the manuscript.\\ndeclaration of interests\\nthe authors declare no competing interests.\\nreceived: march 4, 2020\\nrevised: april 6, 2020accepted: april 23, 2020published: may 4, 2020; corrected online: august 15, 2020\\nreferences\\nbadrinarayanan, v., kendall, a., and cipolla, r. (2017). segnet: a deep convo-\\nlutional encoder-decoder architecture for image segmentation. ieee trans.pattern anal. mach. intell. 39, 2481–2495 .\\nburlina, p.m., joshi, n., pekala, m., pacheco, k.d., freund, d.e., and bressler,\\nn.m. (2017). automated grading of age-related macular degeneration from co-lor fundus images using deep convolutional neural networks. jama ophthal-mol. 135, 1170–1176 .\\nchan, j.f., yuan, s., kok, k.h., to, k.k., chu, h., yang, j., xing, f., liu, j., yip,\\nc.c., poon, r.w., et al. (2020). a familial cluster of pneumonia associated withthe 2019 novel coronavirus indicating person-to-person transmission: a studyof a family cluster. lancet 395, 514–523 .\\nchen, l.-c., papandreou, g., schroff, f., and adam, h. (2017). rethinking\\natrous convolution for semantic image segmentation. arxiv:170605587 .\\nchen, a., karwoski, r.a., gierada, d.s., bartholmai, b.j., and koo, c.w.\\n(2020). quantitative ct analysis of diffuse lung disease. radiographics40, 28–43 .\\nchilamkurthy, s., ghosh, r., tanamala, s., biviji, m., campeau, n.g., venugo-\\npal, v.k., mahajan, v., rao, p., and warier, p. (2018). deep learning algorithmsfor detection of critical ﬁndings in head ct scans: a retrospective study. lancet392, 2388–2396 .\\ndavidson-pilon, c. (2019). lifelines: survival analysis in python. journal of\\nopen source software 4, 1317, 10.21105/joss.01317 .\\ndevalla, s.k., renukanand, p.k., sreedhar, b.k., subramanian, g., zhang, l.,\\nperera, s., mari, j.m., chin, k.s., tun, t.a., strouthidis, n.g., et al. (2018).drunet: a dilated-residual u-net deep learning network to segment opticll\\n1432 cell181, 1423–1433, june 11, 2020resource',\n",
       " 'nerve head tissues in optical coherence tomography images. biomed. opt.\\nexpress 9, 3244–3265 .\\nefron, b. (1979). bootstrap methods: another look at the jackknife. ann. stat.\\n7, 1–26 .\\nesteva, a., robicquet, a., ramsundar, b., kuleshov, v., depristo, m., chou,\\nk., cui, c., corrado, g., thrun, s., and dean, j. (2019). a guide to deeplearning in healthcare. nat. med. 25, 24–29 .\\nforce, a.d.t., ranieri, v.m., rubenfeld, g.d., thompson, b.t., ferguson,\\nn.d., caldwell, e., fan, e., camporota, l., and slutsky, a.s. (2012). acute res-piratory distress syndrome: the berlin deﬁnition. jama 307, 2526–2533 .\\nguan, w.j., ni, z.y., hu, y., liang, w.h., ou, c.q., he, j.x., liu, l., shan, h.,\\nlei, c.l., hui, d.s.c., et al.; china medical treatment expert group for covid-19 (2020). clinical characteristics of coronavirus disease 2019 in china.n. engl. j. med. 382, 1708–1720 .\\ngulshan, v., peng, l., coram, m., stumpe, m.c., wu, d., narayanaswamy, a.,\\nvenugopalan, s., widner, k., madams, t., cuadros, j., et al. (2016). develop-ment and validation of a deep learning algorithm for detection of diabetic reti-nopathy in retinal fundus photographs. jama 316, 2402–2410 .\\nhuang, c., wang, y., li, x., ren, l., zhao, j., hu, y., zhang, l., fan, g., xu, j.,\\ngu, x., et al. (2020a). clinical features of patients infected with 2019 novel co-ronavirus in wuhan, china. lancet 395, 497–506 .\\nhara, k., kataoka, h., and satoh, y. (2017). learning spatio-temporal fea-\\ntures with 3d residual networks for action recognition. arxiv:170807632 .\\nhara, k., kataoka, h., and satoh, y. (2018). towards good practice for action\\nrecognition with spatiotemporal 3d convolutions. in proceedings of the 24thinternational conference on pattern recognition (icpr). https://doi.org/10.\\n1109/icpr.2018.8546325 .\\nhuang, p., liu, t., huang, l., liu, h., lei, m., xu, w., hu, x., chen, j., and liu,\\nb. (2020b). use of chest ct in combination with negative rt-pcr assay for\\nthe 2019 novel coronavirus but high clinical suspicion. radiology 295, 22–23 .\\nke, g., meng, q., finley, t., wang, t., chen, w., ma, w., ye, q., and liu, t.-y.\\n(2017). lightgbm: a highly efﬁcient gradient boosting decision tree. proceed-ings of advances in neural information processing systems (nip 2017),,3146–3154 .\\nkermany, d.s., goldbaum, m., cai, w., valentim, c.c.s., liang, h., baxter,\\ns.l., mckeown, a., yang, g., wu, x., yan, f., et al. (2018). identifying medicaldiagnoses and treatable diseases by image-based deep learning. cell 172,\\n1122–1131.e9 .\\nli, z., he, y., keel, s., meng, w., chang, r.t., and he, m. (2018). efﬁcacy of a\\ndeep learning system for detecting glaucomatous optic neuropathy basedon color fundus photographs. ophthalmology 125, 1199–1206 .\\nlong, j., shelhamer, e., and darrell, t. (2015). fully convolutional networks for\\nsemantic segmentation. proceedings of the ieee conference on computervision and pattern recognition, 3431–3440 .\\nlong, e., lin, h., liu, z., wu, x., wang, l., jiang, j., an, y., lin, z., li, x., chen,\\nj., et al. (2017). an artiﬁcial intelligence platform for the multihospital collabo-rative management of congenital cataracts. nat. biomed. eng. 1, 1–8 .\\nlundberg, s.m., erion, g.g., and lee, s.-i. (2018a). consistent individualized\\nfeature attribution for tree ensembles. arxiv:180203888 .\\nlundberg, s.m., nair, b., vavilala, m.s., horibe, m., eisses, m.j., adams, t.,\\nliston, d.e., low, d.k., newman, s.f., kim, j., and lee, s.i. (2018b). explain-able machine-learning predictions for the prevention of hypoxaemia duringsurgery. nat. biomed. eng. 2, 749–760 .\\nmunster, v.j., koopmans, m., van doremalen, n., van riel, d., and de wit, e.\\n(2020). a novel coronavirus emerging in china - key questions for impactassessment. n. engl. j. med. 382, 692–694 .\\nnorgeot, b., glicksberg, b.s., and butte, a.j. (2019). a call for deep-learning\\nhealthcare. nat. med. 25, 14–15 .paszke, a., gross, s., massa, f., lerer, a., bradbury, j., chanan, g., killeen,\\nt., lin, z., gimelshein, n., antiga, l., et al. (2019). pytorch: an imperative style,high-performance deep learning library. adv. neural inf. process. syst.,8024–8035 .\\npedregosa, f., varoquaux, g., gramfort, a., michel, v., thirion, b., grisel, o.,\\nand vanderplas, j. (2011). scikit-learn: machine learning in python. the journalof machine learning research 12, 2825–2830 .\\nphan, l.t., nguyen, t.v., luong, q.c., nguyen, t.v., nguyen, h.t., le, h.q.,\\nnguyen, t.t., cao, t.m., and pham, q.d. (2020). importation and human-to-human transmission of a novel coronavirus in vietnam. n. engl. j. med.382, 872–874 .\\npoplin, r., varadarajan, a.v., blumer, k., liu, y., mcconnell, m.v., corrado,\\ng.s., peng, l., and webster, d.r. (2018). prediction of cardiovascular risk fac-\\ntors from retinal fundus photographs via deep learning. nat. biomed. eng. 2,\\n158–164 .\\nravizza, s., huschto, t., adamov, a., bo ¨hm, l., bu ¨sser, a., flo ¨ther, f.f., hinz-\\nmann, r., ko ¨nig, h., mcahren, s.m., robertson, d.h., et al. (2019). predicting\\nthe early risk of chronic kidney disease in patients with diabetes using real-world data. nat. med. 25, 57–59 .\\nronneberger, o., fischer, p., and brox, t. (2015). u-net: convolutional net-\\nworks for biomedical image segmentation. proceedings of the internationalconference on medical image computing and computer-assisted interven-tion, 234–241 .\\nrothe, c., schunk, m., sothmann, p., bretzel, g., froeschl, g., wallrauch, c.,\\nzimmer, t., thiel, v., janke, c., guggemos, w., et al. (2020). transmission of2019-ncov infection from an asymptomatic contact in germany. n. engl. j.\\nmed. 382, 970–971 .\\nshi, h., han, x., jiang, n., cao, y., alwalid, o., gu, j., fan, y., and zheng, c.\\n(2020). radiological ﬁndings from 81 patients with covid-19 pneumonia in\\nwuhan, china: a descriptive study. lancet infect. dis. 20, 425–434 .\\nsinger, m., deutschman, c.s., seymour, c.w., shankar-hari, m., annane, d.,\\nbauer, m., bellomo, r., bernard, g.r., chiche, j.d., coopersmith, c.m., et al.\\n(2016). the third international consensus deﬁnitions for sepsis and septicshock (sepsis-3). jama 315, 801–810 .\\nting, d.s.w., cheung, c.y., lim, g., tan, g.s.w., quang, n.d., gan, a.,\\nhamzah, h., garcia-franco, r., san yeo, i.y., lee, s.y., et al. (2017). develop-ment and validation of a deep learning system for diabetic retinopathy andrelated eye diseases using retinal images from multiethnic populations withdiabetes. jama 318, 2211–2223 .\\ntopol, e.j. (2019). high-performance medicine: the convergence of human\\nand artiﬁcial intelligence. nat. med. 25, 44–56 .\\nvan grinsven, m.j., van ginneken, b., hoyng, c.b., theelen, t., and sa ´nchez,\\nc.i. (2016). fast convolutional neural network training using selective datasampling: application to hemorrhage detection in color fundus images. ieeetrans. med. imaging 35, 1273–1284 .\\nwang, c., horby, p.w., hayden, f.g., and gao, g.f. (2020). a novel coronavi-\\nrus outbreak of global health concern. lancet 395, 470–473 .\\nxie, x., zhong, z., zhao, w., zheng, c., wang, f., and liu, j. (2020). chest ct\\nfor typical 2019-ncov pneumonia: relationship to negative rt-pcr testing.radiology, 200343 .\\nyang, x., yu, y., xu, j., shu, h., xia, j., liu, h., wu, y., zhang, l., yu, z., fang,\\nm., et al. (2020). clinical course and outcomes of critically ill patients withsars-cov-2 pneumonia in wuhan, china: a single-centered, retrospective,observational study. lancet respir. med. s2213-2600(20)30079-5. https://\\ndoi.org/10.1016/s2213-2600(20)30079-5 .\\nzhu, n., zhang, d., wang, w., li, x., yang, b., song, j., zhao, x., huang, b.,\\nshi, w., lu, r., et al.; china novel coronavirus investigating and researchteam (2020). a novel coronavirus from patients with pneumonia in china,2019. n. engl. j. med. 382, 727–733 .ll\\ncell181, 1423–1433, june 11, 2020 1433resource',\n",
       " 'star+methods\\nkey resources table\\nresource availability\\nlead contact\\nfurther information and requests for resources should be directed to the lead contact, kang zhang ( kang.zhang@gmail.com ). all ct\\nimages data and metadata and codes generated in this study are available from the lead contact.\\nmaterials availability\\nthis study did not generate new unique reagents.\\ndata and code availability\\nchest ct images and clinical metadata and codes are deposited into the china national center for bioinformation at the website(http://ncov-ai.big.ac.cn/download?lang=en ).\\nexperimental model and subject details\\nhuman subjects\\nct images were collected from cohorts from the china consortium of chest ct image investigation (cc-ccii), which consists of sun\\nyat-sen memorial hospital and third afﬁliated hospital of sun yat-sen university, the ﬁrst afﬁliated hospital of anhui medical uni-versity, west china hospital, nanjing renmin hospital, yichang central people’s hospital, renmin hospital of wuhan university.\\nhuman subjects were deemed clinically appropriate for a chest ct scan during the management of the patients by the clinicians.\\nthe inﬂuence (or association) of age or gender were not taken into the exclusion criteria. institutional review board (irb)/ethics com-mittee approvals were obtained in all the institutions and consent was obtained from all participants. the work was conducted in\\ncompliance with the chinese cdc policy on reportable infectious diseases and the chinses health and quarantine law and in\\ncompliance with patient privacy regulations in china, and was adherent to the tenets of the declaration of helsinki.\\nexperimental data\\nthe cc-ccii contained a total of 617,775 ct slices of 6752 ct scans from 4154 patients. the study sample size was estimated by a\\nstandard ai training and validation approach. patients were randomly assigned to a training set (80%), an internal validation set (10%)or a test set (10%). we used a total of 444,034 ct slices of 2,778 patients from the cc-ccii for training and internal validation of the ai\\ndiagnosis system, including 164,241 slices from 917 ncp patients, 183,933 slices from 983 pneumonia patients and 95,860 slices\\nfrom 878 normal controls. of these, ncp diagnosis was given when a patient had pneumonia with a conﬁrmed reverse-transcriptase–pcr. the common pneumonia group include viral pneumonia (including adenoviral, inﬂuenza, and parainﬂuenza pneumonia), bac-\\nterial pneumonia, and mycoplasma pneumonia, all of which together are the most common causes of pneumonia, which were diag-\\nnosed based on standard clinical, radiological, culture/molecular assay results. we matched lesion severity levels between ncp andother common pneumonia by lesion volume ratio measurements ( figure s5d ). all cohorts had viral pneumonia as a part of other\\ncommon pneumonia diagnosis. the percentages of viral pneumonia were as following: initial training/validation/testing cohort,\\n48%; external validation cohort (city of yichang), 27%; prospective cohort 1 (city of hefei), 36%; prospective cohort 2 (city ofguangzhou), 38%; international cohort, 15%. ct scans from each patient were put into the corresponding dataset based on the pa-reagent or resource source identifier\\ndeposited data\\nct images and clinical data and codes this paper http://ncov-ai.big.ac.cn/download?lang=en\\nsoftware and algorithms\\npytorch v1.2 paszke et al., 2019 https://pytorch.org\\ndeeplabv3 chen et al., 2017 https://github.com/pytorch/vision\\n3d resnet hara et al., 2018 https://github.com/kenshohara/3d-resnets-pytorch\\nlifelines v0.24.0 davidson-pilon, 2019 https://github.com/camdavidsonpilon/lifelines\\nlightgbm v2.2.3 ke et al., 2017 https://github.com/microsoft/lightgbmll\\ne1cell181, 1423–1433.e1–e4, june 11, 2020resource',\n",
       " 'tient assignment. we excluded patients without corresponding non-contrast ct scans. scan sets without serial information or\\ncontaining any motion artifacts or signiﬁcant image resolution reductions were also excluded from the study. details of patient char-\\nacteristics and the inclusion and exclusion criteria are given in figure s1. for the ct quantitative and correlation analysis with clinical\\nparameters, 843 admitted ncp patients with clinical metadata were included. all the ct scans and clinical metadata used in our anal-ysis were collected from patients at the time of hospital admission. of these, 456 hospitalized patients with clinical outcome infor-\\nmation were used in the prognosis estimation analysis. the endpoint in the study was deﬁned as ‘‘severe or critical illness’’ which\\nmeans admission to intensive care unit (icu), on mechanical ventilation or death.\\nmethods details\\nimage labeling and quality control\\nto train and evaluate our semantic segmentation framework, a subset of 2,879 ct slices from ncp patients and a set of 1816 ct\\nslices from other pneumonia patients were manually segmented at the pixel level. the annotation was done via polygons. the seg-\\nmentation labels were selected as relevant pathological features for distinguishing ncp and other common pneumonia. the anno-tation included lung ﬁeld, and ﬁve commonly seen categories of lesions including cl, ggo, pulmonary ﬁbrosis, interstitial thickening\\nand pleural effusion. there were 4,406 consolidation lesions, 10,544 ground-glass opacities and a total of 2,571 other three types of\\nlesions annotated ( table s2 ). the segmentations were annotated and reviewed by ﬁve senior radiologists with 15 to 25 years of\\nexperience.\\nfor the analysis of ct images from cc-ccii, all radiographs were initially screened for quality control by removing all low quality or\\nunreadable scans. for all ct images, each image went through a tiered grading system consisting of two layers of trained graders of\\nincreasing expertise for veriﬁcation and correction of image labels. each image imported into the database started with a labelmatching the diagnosis of the patient. this ﬁrst tier of graders who were radiologists with 5 to 15 years of clinical practice experience\\nconducted initial quality control and excluded images containing severe artifacts or signiﬁcant image resolution reductions. the pres-\\nence or absence of lung lesions in ct images were recorded. the second tier of ﬁve independent radiologists with at least 25 years ofclinical practice experience veriﬁed the true labels for each image randomly selected from 10% of all images, this group of senior\\nradiologists also served on the consensus committee for the ground truth adjudicator in ai versus radiologist comparison.\\nai versus radiologists comparison\\nfor comparing the performance of our ai system with experienced practicing radiologists, an independent dataset which consisted\\nof a total of 18,392 slices from 150 patients including 40 ncp patients, 80 common pneumonia patients and 30 normal controls wereemployed (table s1). eight practicing radiologists were enrolled to participate in the ai comparison study and were allocated into two\\ngroups: junior group, with 5 to 15 years of clinical experience; and senior group with 15 to 25 years of clinical experience. a weighted\\nerror based on penalty score was used to evaluate our ai system and the experts to reﬂect clinical performance. we set the misdiag-\\nnosing ncp to normal with a score of 2, as it may cause the most severe outcome as compared to misdiagnosing ncp as ‘‘othercommon pneumonia,’’ which had a score of 1. in addition, the scores of misdiagnosing the rest of classes were set as 1.\\nwe further conducted a study to investigate the impact of the ai diagnostic system in aiding the performance of the four junior\\nradiologists. during this re-reading of the same ct four weeks after the initial reading, the ai system readout was provided to theradiologists with lesion labeling of each slice and a ﬁnal diagnostic probability at a patient level (three-way classiﬁcations) and the\\nradiologist were asked to make a diagnosis again to access the impact of our ai system on the radiologists diagnosis and compared\\nwith the ground truth from the senior radiologists\\nprospective pilot studies\\nin the ﬁrst prospective pilot study conducted in wuhan (hubei), we enrolled 201 consecutive ncp, 144 common pneumonia patients\\nand 64 normal controls. we performed this study from jan 25\\nthto march 25th, 2020. similarly, the second prospective pilot study was\\nconducted in a non-epidemic central region in china with 41 consecutive ncp, 128 common pneumonia patients and 73 normal con-\\ntrols (hefei from feb 2nd to march 25th). the third prospective pilot study was conducted in another region in southern china with 20\\nconsecutive ncp, 57 common pneumonia patients and 63 normal controls (guangzhou from feb 8thto march 27th,table s1 ).\\nto further validate our ai system outside china, we also obtained ct images from a cohort of patients from ecuador and data from\\nan open source website ( https://radiopaedia.org/encyclopaedia/cases/all?lang=us ). this international cohort consisted of 40 ncp\\npatients, 52 cp patients, and 10 normal controls.\\nthis project was approved by the irb of the respective institutions. enrollment criteria included a diagnosis of viral pneumonia on\\nclinical symptoms and signs, and standard laboratory tests. the ct screening was performed in all participants as a part of clinical\\nmanagement. a conﬁrmative diagnosis of ncp was made by a molecular pcr test ( table s1 ).\\ndiagnosis system and network architectures\\nwe constructed a computer-aided diagnosis (cad) system for detecting covid-19 patients which consisted of two models, the ﬁrst\\nlung-lesion segmentation model and the second diagnosis prediction model. the lung-lesion segmentation model took a raw ctscan as the input and produced a lung-lesion map as the output by segmentation networks, in which it generated one out of sevenll\\ncell181, 1423–1433.e1–e4, june 11, 2020 e2resource',\n",
       " 'classes at a pixel level, including background, lung ﬁelds, ﬁve lesions including cl, ggo, pulmonary ﬁbrosis, interstitial thickening\\nand pleural effusion. the entire scan of a patient was then cropped and transformed into a normalized ct volume map based on the\\nlung-segmentation model. the diagnosis prediction model took the normalized lung-lesion ct volume map and produced a ﬁnal pre-\\ndiction on whether a patient is normal, with ncp or other common pneumonia by classiﬁcation networks.segmentation networks\\nas a ct scan usually consisted of many slices, ranging from around 50 (5mm) to 200 (1mm) in thickness, which was challenging for\\nreal-time application in clinical practice. to achieve the requirement of real-time segmentation, we constructed a fast and accuratesegmentation framework to segment the lung ﬁled and lesions in the ct slice. we formulated our segmentation framework as a two-stage segmentation scheme which enabled the model to focus on the medically meaningful regions of input image which will reduce\\ncomputation cost signiﬁcantly (see figure s2a for more details).\\nin the ﬁrst stage, we down sampled the input image from 512 3512 to 128 3128 level and segmented the lung (lung ﬁeld and le-\\nsions) from the image, as the patterns of lung can be learned at a relatively low resolution. in the second stage, we ﬁrst calculated the\\nbounding box with the lung ﬁeld segmentation results. the bounding box was slightly larger than the lung ﬁeld and contained all key\\nregions with pathological features. next, the key region from the original input image was cropped and resized to a 256 3256 level as\\nthe input for the second stage segmentation model, which segmented all segmentation classes from the cropped image. the results\\nfrom the second stage segmentation were transferred to the coordinates of the original input image to form a ﬁnal segmentation\\nmask. this method increased segmentation framework efﬁciency and was model agnostic, therefore it could be applied to any imagesegmentation models.\\nthe two-stage segmentation framework with different backbones was adopted, in which we chose a range of classic semantic\\nsegmentation models to conduct extensive experiments, including u-net, drunet, fcn, segnet and deeplabv3. all images for\\ntraining and evaluating semantic segmentation model were resized to 512 3512 to balance the computation cost and accuracy.\\nbatch normalization was utilized to accelerate the training procedure. the annotated labels were highly imbalanced, with lung ﬁeld\\ntook up the majority of the labels. to solve this problem, we used the pixel-level weighted binary cross-entropy and dice loss as the\\nloss function for optimization. during training, sgd optimizer was employed with an initial learning rate at 0.01, momentum at 0.9 andweight decay at 0.0001. the learning rate decays by a factor of 0.9 for every 5 epochs. the training batch size is 4.\\nclassiﬁcation networks\\nthe segmentation results of ct slices in a ct scan were stacked vertically to form a volume. the lung ﬁled region was then croppedfrom the volume and normalized to 64 31283128 for depth, height and width respectively. then the normalized volume is converted\\ninto one-hot representation for each pixel, deriving a tensor 7 36431283128. the 3d classiﬁcation network took the tensor as input\\nand output the diagnosis probability of three categories: ncp, cp and normal controls.\\nthe detailed structure of the 3d classiﬁcation network was shown in figure s2b , adapted from 3d resnet-18 ( hara et al., 2017 ).\\nthe network used multiple 3d convolutional blocks with residual connections to continuously extract local and global contextual fea-\\ntures, and the ﬁnal predictions were calculated with a fully connected layer followed with a softmax activation function. for the three-\\nway diagnosis decision, the model output the class with the maximum probability. the 3d classiﬁcation network is trained with crossentropy loss between ﬁnal predictions and ground truth labels. during training, we used adam optimizer with an initial learning rate at\\n0.001. the learning rate decays by a factor of 0.1 for every 10 epochs. the training epoch is 20 in total. the training batch size is 8. the\\nwhole training, validation and testing procedures were also conducted with pytorch (v.1.2.0) on nvidia geforce 1080ti graphicalprocessing units ( paszke et al., 2019 ).\\nevaluation of drug treatment effects\\nwe evaluated the effect of drug treatment on lesion size and volume changes using our ai-based quantitative measurements. ncppatients undergoing three different experimental drug treatment in observation trials were analyzed. drug 1, drug 2 and drug 3 group\\nenrolled 12, 8 and 22 ncp patients respectively. the enrollment criteria included a conﬁrmed ncp diagnosis by a positive viral pcr\\ntest, and no other prior treatment history. we quantiﬁed lung lesions (ggo and total lesions volumes) on ct scans and compared thedifferences between pre-treatment and after treatment of the three experimental drugs. dependent t test for paired samples was\\nused for statistical analysis ( figure s4 ).\\nlung-lesion features and clinical parameters\\nclinical records of covid-19 patients which consisted of patients’ demographics and clinical data, including vital signs, symptoms\\nand signs, as well as imaging studies and laboratory tests results on initial hospital admission and follow ups were manually anno-tated. laboratory tests consisted of comprehensive blood biochemical analysis, blood gas analysis, liver and renal biochemistry in-\\ndexes, cardiac function tests, coagulation tests, and certain serum protein levels and activities, including lactate dehydrogenase\\n(ldh) and c-reactive protein (crp), etc.\\nto investigate the correlations between ct quantitative features and clinical parameters, pearson’s and spearman’s correlation\\ntests were performed. three volume-level quantitative features were used, including ggo to lung volume ratio, cl to lung volume\\nratio, total lesion (ggo + cl) to lung volume ratio, since they were common lesions for the progressive stage of ncp patients. a cor-\\nrelation analysis between lung-lesion features and lung and liver damage assessment were conducted using a composite score sys-tem, as lung and liver functions were highly relevant to outcomes of covid-19 patients based on previous study and internationalll\\ne3cell181, 1423–1433.e1–e4, june 11, 2020resource',\n",
       " 'guidelines ( force et al., 2012; singer et al., 2016 ). we identiﬁed and quantiﬁed clinical parameters (including age, tmax, rr, platelet,\\nna+, albumin, ast, ldh, crp) that were highly correlated with lung lesions by a linear regression analysis. the resultant correlations\\nwere regarded as signiﬁcant when pvalues was < 0.05 after correction with the holm-bonferroni method.\\nprognosis analysis\\nfor an ncp prognostic and risk factor analyses, we denoted the ‘‘severe/critical illness’’ as the endpoint of the prognosis of covid-\\n19 patients. the status of ‘‘severe/critical illness’’ was deﬁned and recorded as admission to an intensive care unit (icu), the use ofmechanical ventilation, or death. ct lesion features (only volume quantitative features) and clinical metadata features were used for aprognostic prediction with gradient boosting decision tree algorithm (gbdt) as the classiﬁer. the gbdt is a tree-based ensemble\\nmodel, as each node in the tree can be converted to if-then rules that are easily understandable, and the gbdt with default pa-\\nrameters by python package lightgbm was employed ( ke et al., 2017 ). a shap method was used to display the impact of relevant\\nrisk factors on prognostic prediction for critical illness. shap is a value explainable tool for tree-based models, which could efﬁciently\\nand exactly compute local explanations and global explanations. the performance of a local explanation of shap for prognosis pre-\\ndiction with interpretability was also investigated. as an example, two patients from the critical illness and the non-critical illnessgroup were used to show the effects of lung-lesion features and clinical parameters as the input risk factors for prognosis prediction\\n(figure s7a andfigure s7b ). we used a ﬁve-fold cross-validation scheme for prognostic prediction. for each fold, we calculated a\\nprobability (c-score) for each patient in the test dataset (20%) using coefﬁcient estimates from the training and validation dataset(70%:10%). using a cut-off score of the c-score of 0.5, we were able to classify patients into high-risk group (c-score of r0.5)\\nand low-risk group (c-score of < 0.5). with this stratiﬁcation, the median survival times for the two groups were calculated by the\\nkaplan-meier estimator and a log-rank test. the importance of each parameter for prognostic estimation were also estimated by\\nﬁtting a multi-variable cox proportional hazards model on ct quantitative lesion features and clinical parameters.\\nquantification and statistical analysis\\nwe evaluated semantic segmentation model performance with two evaluation metrices including pixel accuracy (pa) and dice co-\\nefﬁcient (dc). the pa is the percentage of pixels that are classiﬁed correctly. the dc is twice the area of overlap between the pre-\\ndicted segmentation and the ground truth divide by the sum of areas of the predicted segmentation and the ground truth. roc andauc were used to assess model performance for each classiﬁcation task. conﬁdence intervals (ci) of auc were computed using\\nbootstrapping approach with nonparametric, unstratiﬁed resampling of 1000 times ( efron.,1979 ). sensitivity, speciﬁcity and accu-\\nracy were determined by the selected operating point. the operating point between a low false negative diagnostic rate (sensitivity)and a low positive rate (1 /c0speciﬁcity) were set at different thresholds accordingly. pearson’s and spearman’s correlation tests with\\nholm-bonferroni method were employed for the statistical analyses. the training, validation and testing procedures of deep learning\\nmodels were conducted with pytorch (v.1.2.0). we used the python scikit-learn library for data analysis and the python matplotlib and\\nseaborn libraries to plot graphs. the python package lightgbm and lifelines were employed for prognostic prediction. the measure-ments of sensitivity, speciﬁcity, and accuracy were calculated by python scikit-learn library ( pedregosa et al., 2011 ).ll\\ncell181, 1423–1433.e1–e4, june 11, 2020 e4resource',\n",
       " 'supplemental figures\\nfigure s1. stard diagram describing the ct dataset used for our ai system from cc-ccii, related to figure 1\\nthe exclusion criteria were also considered.ll\\nresource',\n",
       " 'figure s2. illustration of network architectures of the proposed ai diagnostic system, related to figure 1\\n(a) two-stage segmentation module for acceleration. in the ﬁrst stage, we down-sampled the input image to a 128 3128 level and segmented the lung ﬁeld from\\nthe image, as the patterns of lung ﬁelds were easily learned at a relatively low resolution. in the second stage, we ﬁrst calculated the bounding box wit h the lung\\nﬁeld segmentation results. the key region was cropped from the original input image and resized it to a 256 3256 level as the input for the second stage\\nsegmentation model.(b) the 3d classiﬁcation networks used in our covid-19 diagnosis system. for more details see star methods .ll\\nresource',\n",
       " 'figure s3. segmentation examples of our model for lesion segmentation task, related to figure 2\\nupper row, original ct slices of ﬁve types of lesions; middle row, manually segmented ct slices; lower column, ai-based automated segmented ct slices . the\\nﬁve columns represented ct slice with lesions of ground-glass opacity (ggo), consolidation, pulmonary ﬁbrosis, interstitial thickening, and pleu ral effusion (from\\nleft to right).ll\\nresource',\n",
       " 'figure s4. evaluation of drug treatment effects by ai-based lesion quantitative measurements, related to star methods\\ncomparative measurements of ground glass opacities (ggo) and total lesion (lesion) volume ratio before and after a drug treatment in three prelimina ry drug\\ntreatment observation trials (drug 1, 2 and 3).(a and b) bar graphs comparing lesion volume changes before and after treatment by three drugs.(c-e) image examples of lesion changes before treatment (left panels) and after treatment (right panels). the ncp total lesion area in the example sli ce of each\\npatient was quantiﬁed as a horizonal bar. a typical image with lesions and corresponding ai segmentation was presented for each drug treatment. for th ea i\\nsegmentation color code, blue, purple and green represented ggo, consolidation (cl) and pulmonary ﬁbrosis, respectively. (c) a representative pat ient from the\\ndrug 1 group. (d) a representative patient from the drug 2 group. (e) a representative patient from the drug 3 group. a t test was used to measure statisti cal\\nsigniﬁcance comparing before and after a treatment. the lesion change comparison before and after treatment was no statistically signiﬁcant in the d rug 1 group,\\nwhereas it was signiﬁcant in the drug 2 group (p = 0.0345) and the drug 3 (p = 0.00056).ll\\nresource',\n",
       " 'figure s5. evaluation and diagnostic performance of the ai system, related to figure 3\\n(a and b) ai performance in an independent international cohort. receiver operating characteristic curves (roc) and normalized confusion matrix of the model for\\ndetecting ncp patients from common pneumonia (cp) and normal controls. for three-way classiﬁcation: accuracy = 85.05%, auroc = 0.9381 (95% ci: 0.894 4-\\n0.9742). for ncp versus the rest: accuracy = 84.11%, sensitivity = 86.67%, speciﬁcity = 82.26%, auroc = 0.9050 (95% ci: 0.8421-0.9612).(c) penalty scoring matrix.(d) a distribution plot of the severity index (lesion volume ratios) between ncp patients and common pneumonia patients, which represented a severit y level\\ncomparison between the two disease groups. the distribution difference between these two groups was evaluated by a statistical measurement of jacca rd\\nsimilarity (js), which was the intersection divided by the union of distribution of two samples. the js of the lesion ratios for cp and ncp patients was o f 0.939,\\nsuggesting that the distributions of severity levels were similarly matched and would not generate a bias in diagnosis analysis.ll\\nresource',\n",
       " 'figure s6. the correlation of lung-lesion features with clinical parameters and progression of disease, related to figure 6\\n(a-e) linear regression analysis comparing the volume lesion ratio and ﬁve correlated clinical parameters, including (a) serum lactate dehydrogen ase (ldh), (b)\\nna+, (c) respiratory rate, (d) maximum body temperature, and (e) serum aspartate aminotransferase (ast). p-values were adjusted with the holm-bonferroni\\nmethod.\\n(f) a density plot of the c-score for the prognosis prediction model used in star methods.ll\\nresource',\n",
       " 'figure s7. illustration of our ai system for diagnosis and clinical prognosis estimation of covid-19 patients during clinical deployment,\\nrelated to figure 7\\n(a and b) examples of clinical prognosis estimation. we selected two patients from the critical illness and the non-critical illness group to show int erpretability of\\nthe effects of lung-lesion features and clinical parameters as the input risk factors for prognosis prediction. the effects of input from lung-lesio n features and\\nclinical parameters for risk prediction. pink features pushed the risk higher (to the right) and blue features pushed the risk lower (to the left). (a) a patient from the\\ncritical illness group. (b) a patient from the non-critical illness group.(c) our system provided lesion segmentation of ct images and quantitative analysis of all the lesion types.ll\\nresource',\n",
       " 'update\\ncell\\nvolume 182, issue 5, 3 september 2020, page 1360\\n https://doi.org/10.1016/j.cell.2020.08.029doi:',\n",
       " 'correction\\nclinically applicable ai system for accurate\\ndiagnosis, quantitative measurements, and prognosisof covid-19 pneumonia using computed tomography\\nkang zhang, *xiaohong liu, jun shen, zhihuan li, ye sang, xingwang wu, yunfei zha, wenhua liang, chengdi wang,\\nke wang, linsen ye, ming gao, zhongguo zhou, liang li, jin wang, zehong yang, huimin cai, jie xu, lei yang,\\nwenjia cai, wenqin xu, shaoxu wu, wei zhang, shanping jiang, lianghong zheng, xuan zhang, li wang, liu lu,jiaming li, haiping yin, winston wang, oulan li, charlotte zhang, liang liang, tao wu, ruiyun deng, kang wei,yong zhou, ting chen, johnson yiu-nam lau, manson fok, jianxing he, *tianxin lin, *weimin li, *and guangyu wang *\\n*correspondence: kang.zhang@gmail.com (k.z.), hejx@vip.163.com (j.h.), lintx@mail.sysu.edu.cn (t.l.), weimi003@yahoo.com (w.l.),\\nwangguangyu@mail.tsinghua.edu.cn (g.w.)\\nhttps://doi.org/10.1016/j.cell.2020.08.029\\n(cell 181, 1423–1433.e1–e11; june 11, 2020)\\nit was recently brought to our attention that our paper was missing information regarding when the patient chest computed tomog-\\nraphy (ct) scans were obtained and that there were some discrepancies in the clinical metadata, associated with the very large im-\\nage dataset, that we made publicly available through the china national center for bioinformation ( http://ncov-ai.big.ac.cn/\\ndownload?lang=en ). all of the chest ct and clinical metadata used in our prognostic analysis were collected from patients at the\\ntime of hospital admission, and we have now added this statement to the star methods section of our paper. we believe that\\nthe errors in the clinical metadata were introduced when the chest ct images, clinical metadata, and codes were transferred tothe web server, and we have now corrected the errors manually. although these corrections do not alter any of the conclusions\\nmade in the paper, we do apologize for these errors and any confusion that they may have caused.\\nll\\n1360 cell182, 1360, september 3, 2020 ª2020 elsevier inc.',\n",
       " '1\\nthe roadmap to 6g – ai empowered\\nwireless networks\\nkhaled b. letaief, wei chen, yuanming shi, jun zhang, and ying-jun angela zhang\\nabstract —the recent upsurge of diversiﬁed mobile applica-\\ntions, especially those supported by artiﬁcial intelligence (ai), is\\nspurring heated discussions on the future evolution of wireless\\ncommunications. while 5g is being deployed around the world,\\nefforts from industry and academia have started to look beyond\\n5g and conceptualize 6g. we envision 6g to undergo an unprece-\\ndented transformation that will make it substantially different\\nfrom the previous generations of wireless cellular systems. in\\nparticular, 6g will go beyond mobile internet and will be required\\nto support ubiquitous ai services from the core to the end\\ndevices of the network. meanwhile, ai will play a critical role\\nin designing and optimizing 6g architectures, protocols, and\\noperations. in this article, we discuss potential technologies for\\n6g to enable mobile ai applications, as well as ai-enabled\\nmethodologies for 6g network design and optimization. key\\ntrends in the evolution to 6g will also be discussed.\\ni. i ntroduction\\nthe wireless communications industry is one of the few\\nindustry sectors that have kept a fast growing trend with\\ncreative features for a number of decades. the current 4g lte\\nnetworks have led to the thriving of mobile internet, enabling\\nvarious innovative applications, such as mobile shopping and\\npayment, smart home/city, mobile gaming, etc. the great suc-\\ncess of mobile internet has in turn been a driving force behind\\nthe evolution of wireless technologies. the upcoming 5g net-\\nwork will support a wide range of services, including embb\\n(enhanced mobile broadband), urllc (ultra-reliable and low-\\nlatency communications), and mmtc (massive machine-type\\ncommunications) [1], [2]. according to a cisco forecast,\\nmajor operators will embark on a signiﬁcant investment in\\n5g networks during the next one or two years.\\nwhile 5g is still at an initial stage, to maintain the sus-\\ntainability and competitiveness of wireless communication\\nsystems, it is time for both the industry and academia to\\nthink about what 6g will be. there are already initiatives\\ndescribing the roadmap towards 6g [3], [4], [5] along with\\nthe emerging trends and requirements, as well as various\\nenabling techniques and architectures, e.g., terahertz band\\ncommunications [6].\\nin contrast to previous generations, 6g will be transfor-\\nmative and will revolutionize the wireless evolution from\\nkhaled b. letaief is with hong kong university of science and tech-\\nnology; wei chen is with tsinghua university; yuanming shi is with\\nshanghaitech university; jun zhang is with the hong kong polytechnic\\nuniversity; ying-jun angela zhang is with the chinese university of hong\\nkong.\\nthis work has been submitted to the ieee for possible publication.\\ncopyright may be transferred without notice, after which this version may\\nno longer be accessible.“connected things” to “connected intelligence” with more\\nstringent requirements speciﬁed as follows.\\n\\x0fvery high data rates, up to 1 tbps;\\n\\x0fvery high energy efﬁciency, with the ability to support\\nbattery-free iot devices;\\n\\x0ftrusted global connectivity;\\n\\x0fmassive low-latency control (less than 1 msec end-to-end\\nlatency);\\n\\x0fvery broad frequency bands (e.g., 73ghz-140ghz and\\n1thz-3thz);\\n\\x0fubiquitous always-on broadband global network cov-\\nerage by integrating terrestrial wireless with satellite\\nsystems;\\n\\x0fconnected intelligence with machine learning capability\\nand ai networking hierarchy.\\n6g will also require the support of three new service types\\nbeyond the embb, urllc, and mmtc services supported by\\n5g, as described below.\\ncomputation oriented communications (coc): new\\nsmart devices call for distributed and in-network computation\\nto enable the key functionalities of ai-empowered 6g, such as\\nfederated learning and edge intelligence. instead of targeting\\nclassical quality of service (qos) provisioning, coc will\\nﬂexibly choose an operating point in the rate-latency-reliability\\nspace depending on the availability of various communications\\nresources to achieve a certain computational accuracy.\\ncontextually agile embb communications (caec): the\\nprovision of 6g embb services is expected to be more agile\\nand adaptive to the network context, including communication\\nnetwork context such as link congestion and network topology;\\nphysical environment context such as surrounding location and\\nmobility; and social network context such as social neighbor-\\nhood and sentiments.\\nevent deﬁned urllc (edurllc): in contrast to the\\n5g urllc application scenario (e.g., virtual reality and in-\\ndustrial automation) where redundant resources are in place\\nto offset many uncertainties, 6g will need to support urllc\\nin extreme or emergency events with spatially and temporally\\nchanging device densities, trafﬁc patterns, and spectrum and\\ninfrastructure availability.\\ninspired by these trends, in this article, we attempt to\\nconceptualize 6g as an intelligent information system that is\\nboth driven by and a driver of the modern ai technologies. a\\nroadmap for 6g is depicted in fig. 1, which is plotted based\\non the strategic plans of various standard bodies and is also\\nprojected based on the 5g status. key performance indicators\\n(kpis) and service types are also illustrated. meanwhile, a\\npotential network architecture for 6g is shown in fig. 2.arxiv:1904.11686v2  [cs.ni]  19 jul 2019',\n",
       " '2\\n2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2030 2031 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 \\nstandard rquirement \\nspectrum\\ntechnology \\n5g trial \\nrel10 rel11 rel12 rel13 rel14 rel15 rel16 rel17 5g evolution(beyond 5g)\\n6g study 6g specifications 6g product \\nlte-advanced lte-b lte-c3gpp \\nituimt new spectrum, vision requirement 5g evaluation 6g vision 6g requirements 6g evaluation \\nwrc-12 wrc-15 wrc-18/19 \\nsig vision/kpi/scope/timeline \\ncollaborati \\nve research fp9: horizon europe \\nbeyond 5g: ict 20 \\n5g key technology full 6g poc, 5g services \\nhw,sw functions demos 6g testbeds poc market \\nresearch on spectrum \\nbelow 6ghz \\nlow/high-frequency candidate bands kpis evaluations \\nkey technologies system design enhanced technologies \\n5g technology r&d trial \\n5g product r&d \\ntrial deployment(china plans commercial 5g in 2020)intelligence \\n level \\ncoc \\ncoc\\ncaec edurllc \\nfig. 1. the roadmap of 6g.\\nwe envision that ai will greatly enhance the situational\\nawareness of the network operators, and enable close-loop\\noptimization to support the new service types as mentioned\\nabove. as such, 6g will unleash the full potential of mobile\\ncommunications, computing, and control in a host of exciting\\napplications, including smart cities, connected infrastructure,\\nwearable computers, autonomous driving, ua vs [7], seamless\\nvirtual and augmented reality, internet of things, space-air-\\nground integrated networks [8], and a lot more.\\nthis article is a humble attempt to provide a forward-\\nlooking research roadmap for 6g. the rest of the article is\\norganized as follows. in section ii, a vision on 6g archi-\\ntecture will be presented. in section iii, we will show how\\n6g leverages the advent of ai to enable its key features.\\nvarious ai applications of 6g will be given in section iv. to\\nmeet the expected stringent requirements of such applications,\\nhardware-aware communications will be embraced in 6g, as\\ndiscussed in section v. finally, section vi concludes the\\narticle.\\nii. t hearchitecture of 6g n etworks\\nin this section, we introduce a potential architecture for\\n6g as shown in fig. 2, in which network intelligentization,\\nsubnetwork evolution, and intelligent radio are embraced.\\na. from network softwarization to network intelligentization\\nwe envision that 6g will take network softwarization to a\\nnew level, namely, towards network intelligentization. in 5g,\\nthe “non-radio” aspect has become more and more important,\\nand has been the key driver behind the recent efforts on “soft-\\nwarization”. more speciﬁcally, two key 5g technologies are\\nsoftware-deﬁned networking (sdn) and network functions\\nvirtualization (nfv), which have moved modern communica-\\ntions networks towards software-based virtual networks. they\\nalso enable network slicing, which can provide a powerful\\nvirtualization capability to allow multiple virtual networks to\\nbe created atop a shared physical infrastructure.\\nnevertheless, as the network is becoming more complex\\nand more heterogeneous, softwarization is not going to be\\nsufﬁcient for beyond 5g networks. in particular, to support\\nai-based applications, the network entities have to support di-\\nverse capabilities, including communications, content caching,computing, and even wireless power transfer. furthermore,\\n6g will embrace new radio access interfaces such as thz\\ncommunications and intelligent surfaces. it will also need to\\nsupport more advanced internet of things (iot) functionalities\\nincluding sensing, data collection, analytics, and storage. all\\nof the aforementioned challenges call for an architecture that is\\nﬂexible, adaptive, and more importantly, intelligent. existing\\ntechnologies, such as sdn, nfv , and network slicing will\\nneed to be further improved to meet these challenges. by\\nenabling fast learning and adaptation, ai-based methods will\\nrender network slicing a lot more versatile in 6g systems.\\nthe design of the 6g architecture shall follow an “ai native”\\napproach where intelligentization will allow the network to\\nbe smart, agile, and able to learn and adapt itself according\\nto the changing network dynamics. it will evolve into a\\n“network of subnetworks,” allowing more efﬁcient and ﬂexible\\nupgrades, and a new framework based on intelligent radio and\\nalgorithm-hardware separation to cope with the heterogeneous\\nand upgradable hardware capabilities. both of these two\\nfeatures will exploit ai techniques, as further illustrated in\\nthe following subsections.\\nb. a network of subnetworks – local vs global evolution\\ngiven its expected ultra-high heterogeneity, one key feature\\nof 6g will be its capability to exploit a ﬂexible subnetwork-\\nwide evolution to effectively adapt to the local environments\\nand user demands, thereby resulting in a “network of sub-\\nnetworks”. particularly, local subnetworks in 6g may evolve\\nindividually to upgrade themselves. the local evolution may\\nhappen in a few neighboring cells or even in a single cell\\nin order to ﬂexibly apply cutting-edge developments on new\\nwaveforms, coding, and multi-access protocols in subnetworks\\nwithout extensive time-consuming tests. since there is no\\nneed to rebuild the whole system, the evolution cost can be\\nsubstantially reduced. to achieve this goal, we need to address\\nthe following three challenges:\\n1) each subnetwork should collect and analyze its local\\ndata, which may include wireless environments, user\\nrequests, mobility patterns, etc. and then exploit ai\\nmethods to upgrade itself locally and dynamically.\\n2) when the local phy or mac protocols are changed, the\\ninter-subnetwork interaction is expected to maintain new',\n",
       " '3\\nencoding modulation channel demodulation decodings x yy = hx + z\\ns\\ncomputing \\nnode\\ncomputing \\nnoderesource pool\\nchannelyy = hx + z\\nx\\ns\\nxy = hx + zy\\ncomputing \\nnodecomputing \\nnode\\nrb 9\\nrb 10\\nrb 4rb 5rb 7\\nrb 8 protocol cooperation\\ninterferencelearning\\nai central \\ncontrol node\\nalgorithm  domaindevice\\npreference\\nplain\\nprotocol\\nlayer\\nplain\\ncpugpufpgaasic\\nsupervised\\nlearning\\nunsupervised\\nlearning\\nsemi -supervised\\nlearning\\nreinforcement\\nlearning\\npopular \\ncontentsreinforcement \\nlearningdnn -based\\ncoderfading \\nchannel dnn -based\\ndecoderuser 2dnn -based\\ndecoderuser 1\\nai-os layer\\ncoding\\n caching\\n computing\\nhardware\\ndescription\\nlanguageestimate\\nhardware\\ncapacity\\nco-design\\nantenna\\nphase\\nshifter\\nadc\\nhardwarealgorithm -hardware \\nseparation architecture\\nrb 1\\nrb 2rb 3resource block (rb) 2\\nresource block (rb) nresource block (rb) 1\\n      \\n          \\n          \\n  \\n      \\n    \\n            \\ncould\\nserversnon-iid\\ndatadistributed \\nnn\\nnon-iid\\ndatadistributed \\nnn\\nnon-iid\\ndatadistributed \\nnnuser 2user 1\\nuser 3\\ntraining\\ndrl \\nagent\\nenvironmentfeedback\\nreward , utility , \\nthroughput\\nresource management , \\ncoding , ...decisionresource availability\\nradio condition\\ntraffic characteristics\\nfig. 2. the architecture of 6g.\\ninter-subnetwork coordination. one possible solution is\\nto adopt game and learning approaches in 6g, which can\\nassure the convergence of the subnetworks upgrades.\\n3) the local evolution of 6g requires a relatively stable\\ncontrol plane to support the evolution in the “network\\nof subnetworks” level. one possible solution relies on\\nthe “learning from scratch” method developed in alpha\\nzero [9]. the control plane of 6g should evaluate each\\nupgrade of subnetworks, and then implement a network-\\nlevel learning process to identify the best strategy for\\neach subnetwork, accounting for its local environments\\nand user behaviors.\\nin summary, the local evolution of subnetworks substantially\\nspeeds up the deployment of novel physical and mac layer\\nprotocols, and can better adapt to the spatially and tempo-\\nrally varying radio environments and user demands. with the\\nsubnetwork-wide upgrades, we envision a smooth evolution\\nfrom 5g to 6g and beyond.\\nc. towards intelligent radio (ir)\\nthe emerging hardware revolutions, e.g., in the rf and\\ncircuit systems, will drive 6g to track and fully exploit the fast\\nupgrade of the device-level and base-station level hardware.\\nwe envision that an algorithm-hardware separation architec-\\nture will become essential in 6g. particularly, a transceiver\\nalgorithm will be able to automatically estimate the capability\\nof the transceiver hardware over which the protocol runs, then\\nconﬁgures itself based on the hardware capability.\\nthis is in contrast to the systems from 1g to 5g where\\nthe devices and transceiver algorithms are jointly designed.\\nconventionally, the hardware capabilities, e.g., the number\\nof antennas, rf chains, and phase shifters, the resolution\\nand sampling rates of adcs, as well as, the computation\\nabilities of decoders, etc., have remained quasi-static in the\\nprevious cellular generations. however, the recent state-of-\\nthe-art circuits and antennas advances are speeding up andsigniﬁcantly improving the hardware capabilities, which make\\nit possible for the 6g bs and handset to be diversiﬁed and\\nupgradable within 6g. in other words, 6g will not be operating\\nunder the conventional joint design, which fails in allowing\\nagile adaptation to a diversiﬁed and upgradable hardware.\\nto overcome the shortcoming of joint hardware-algorithm\\ndesign and reap the beneﬁt of the algorithm-hardware separa-\\ntion architecture, we present an operating system (os) between\\nthe device hardware and the transceiver algorithms, where\\nwe can regard a transceiver algorithm as a software running\\nover the os. the os is capable of not only estimating the\\ncapabilities of local rf chains, phase shifters, adcs, and\\nantennas, etc., but also measuring their analog parameters\\nautomatically. based on the hardware information and ai\\nmethods, the os will then be capable of conﬁguring its own\\ntransceiver algorithms via an interface language. we shall refer\\nto this framework as intelligent radio (ir). in contrast to the\\nlearning based intelligent phy layer surveyed in subsection\\niii-c, ir is a much broader concept relying on the algorithm-\\nhardware separation architecture. in table i, we compare key\\nfeatures of ir, software-deﬁned radio (sdr), and cognitive\\nradio. owing to mitola’s milestone works [10], ir can be\\nregarded as a further extension, in which the cutting edge\\nai techniques are deeply involved. the conventional modu-\\nlation/coding modules are replaced by deep neural networks,\\nwhich can in an intelligent way adapt to the environment and\\nhardware. ir also takes into account the protocols over layer 3,\\nwhich are self-upgradable to support various ai applications.\\nby exploiting ir, 6g is expected to evaluate the contri-\\nbutions of various hardware components and identify their\\nbottlenecks. in return, the bottleneck analysis helps the de-\\nvice manufactures in optimizing the budget allocation of the\\nhardware costs. as a result, the application of ir will help 6g\\nenjoy a much reduced implementation time and a signiﬁcant\\nreduction in the cost of new algorithms and hardware in\\nboth the phy and mac layers, thereby speeding up its own',\n",
       " '4\\ntable i\\nthe comparison of software defined radio (sdr), c ognitive radio (cr), and intelligent radio (ir).\\nsdr cr ir\\nfrequency band fixed adapt to environment adapt to environment and hardware\\nspectrum sharing fixed opportunistic ai-enabled\\nhardware capability pre-claimed pre-claimed online estimated\\nhardware upgradability no no yes\\nphy tx/rx module modulation/coding/detection/estimation modulation/coding/detection/estimation deep neural networks\\nmultiple access predetermined sensing based distributed ml based\\nprotocols over layer 3 fixed fixed self-upgradable\\nmain steam apps v oice, data multimedia, data ai, in-network computation\\nevolution.\\niii. ai-e nabled technologies for 6g\\nthe unprecedented transformation of wireless networks will\\nmake 6g substantially different from the previous generations,\\nas it will be characterized by a high degree of heterogeneity in\\nmultiple aspects, such as network infrastructures, radio access\\ntechnologies, rf devices, computing and storage resources,\\napplication types, etc. in addition, the wide range of new ap-\\nplications will mandate an intelligent use of communications,\\ncomputing, control, and storage resources from the network\\nedge to the core, and across multiple radio technologies\\nand network platforms. last but not least, the volume and\\nvariety of data generated in wireless networks are growing\\nsigniﬁcantly. this opens up great opportunities for data-driven\\nnetwork planning and operation to achieve real-time additivity\\nto dynamic network environments.\\nin this section, we advocate ai as an indispensable tool to\\nfacilitate intelligent learning, reasoning, and decision making\\nin 6g wireless networks.\\na. big data analytics for 6g\\nthe ﬁrst natural application of ai is big data analytics.\\nthere are four types of analytics that can be applied to 6g\\nsystems, namely descriptive analytics, diagnostic analytics,\\npredictive analytics, and prescriptive analytics. descriptive\\nanalytics mine historical data to get insights on network per-\\nformance, trafﬁc proﬁle, channel conditions, user perspectives,\\nand etc.. it greatly enhances the situational awareness of\\nnetwork operators and service providers. diagnostic analytics\\nenable autonomous detection of network faults and service\\nimpairments, identify the root causes of network anomalies,\\nand ultimately improve the reliability and security of 6g\\nwireless systems. predictive analytics use data to predict future\\nevents such as trafﬁc patterns, user locations, user behavior\\nand preference, content popularity, and resource availabil-\\nity. prescriptive analytics take advantage of the predictions\\nto suggest decision options for resource allocation, network\\nslicing and virtualization, cache placement, edge computing,\\nautonomous driving, etc. for example, by predicting, antic-\\nipating, and inferring future user demands through big data\\nanalytics, the notion of proactive caching has recently emerged\\nto signiﬁcantly relieve peak trafﬁc loads from the wireless core\\nnetwork.b. ai-enabled closed-loop optimization\\ntraditional methodologies for wireless network optimiza-\\ntion may not be applicable in 6g systems due to the following\\nreasons. first, 6g wireless systems will be extremely dynamic\\nand complex due to the scale, density, and heterogeneity of\\nthe network. modeling such systems is very hard, if not\\nimpossible. as such, traditional optimization approaches that\\nrely heavily on mathematically convenient models will no\\nlonger be adequate. hence, the second major application of\\nai in 6g wireless systems is automated and closed-loop\\noptimization. problems in wireless networks are traditionally\\nsolved by applying sets of rules derived from system analysis\\nwith prior domain knowledge and experience. for example,\\nin traditional network optimization problems, the objective\\nfunctions are assumed to be available in nice algebraic forms,\\nallowing an optimizer to evaluate a solution by simple cal-\\nculation. however, in the complex 6g network environment,\\nthe mapping between a decision and its effect on the physical\\nsystem is cost prohibitive to deﬁne and may not be analyt-\\nically available. recent advances in ai technologies, such\\nas reinforcement learning and deep reinforcement learning\\n(drl), can establish a feedback loop between the decision\\nmaker and the physical system, so that the decision maker can\\niteratively reﬁne its action based on the system’s feedback to\\nreach optimality eventually. for example, [11] recently applied\\ndrl to address several emerging issues in communication and\\nnetworking, including adaptive modulation, wireless caching,\\ndata ofﬂoading, and so on, as shown in fig. 2.\\nc. intelligent wireless communication\\nai technologies will play a critical role in end-to-end\\noptimization of the full chain of the physical layer signal\\nprocessing, from the transmitter to the receiver. the end-to-\\nend communication system suffers from a wide variety of\\nimpairments, including hardware impairments such as am-\\npliﬁer distortion, quadrature imbalance, local oscillator and\\nclock harmonic leakage, and the channel impairments such as\\nfading and interference. meanwhile, the number of factors and\\nparameters to be controlled will continue to increase. with\\nthis level of complexity, end-to-end optimization has never\\nbeen practical in today’s wireless systems. instead, existing\\napproaches divide the full chain into multiple independent\\nblocks, each with a simpliﬁed model that does not accurately\\nor holistically capture the features of real-world systems.\\nai technologies open up the possibilities to learn the best\\nway to communicate over combinations of hardware and chan-',\n",
       " '5\\nnel effects. we envision an “intelligent phy layer” paradigm\\nin 6g, where the end-to-end system is capable of self learning\\nand self optimization by combining advanced sensing and\\ndata collection, ai technologies, and domain-speciﬁc signal\\nprocessing approaches.\\niv. 6g for ai a pplications\\nwith the ubiquitousness of smart mobile gadgets and the\\nrevival of artiﬁcial intelligence, various ai-empowered mobile\\napplications are emerging. in this section, we present how 6g\\nwill handle mobile ai applications.\\na. trends and challenges\\nai has achieved remarkable successes in many application\\ndomains, e.g., computer vision, natural language processing,\\nand autonomous driving. ai tasks are computationally in-\\ntensive and mostly trained, developed, and deployed at data\\ncenters with custom-designed servers. given the fast growth\\nof smart mobile gadgets and internet of things devices, it is\\nexpected that a large number of intelligent applications will\\nbe deployed at the edge of wireless networks in the near\\nfuture. as such, the 6g wireless network will be designed\\nto leverage advanced wireless communications and mobile\\ncomputing technologies to support ai-enabled applications\\nat various edge mobile devices with limited communication,\\ncomputation, hardware and energy resources. notably, the\\ncapacity and latency of wireless links are the key bottlenecks\\nof mobile ai applications due to three reasons. first, to protect\\nprivacy, some ai applications require data to be kept at the\\nmobile devices instead of being uploaded to the cloud during\\nthe model training process. this has stimulated the recent\\nresearch interest for on-device distributed training, i.e., feder-\\nated learning [12], where frequent communications among the\\ncomputing devices are needed for model updates. secondly, to\\novercome the resource limitation of edge devices, on-device\\ndistributed computing provides new opportunities by pooling\\nthe computation and storage resources of multiple mobile\\ndevices. in this case, data shufﬂing is a key component for\\nexchanging the computed intermediate values among mobile\\ndevices to enable on-device distributed inference [13]. last\\nbut not least, the heterogeneous mixture of the cloud, edge\\nand end computing devices provides a dispersed computing\\nenvironment for both training and inference of deep neural\\nnetworks.\\nto enable ubiquitous and diversiﬁed mobile ai services,\\n6g is expected to provide ﬂexible platforms for develop-\\ning advanced communication and computation technologies.\\nmoreover, it will provide a holistic way to optimize across\\nthe communication, computation, and storage resources to\\nspan the functionalities of modern ai across the end-devices,\\nnetwork edges, and cloud data centers.\\nb. communication for distributed machine learning\\nlarge-scale distributed machine learning is needed for mo-\\nbile ai applications in 6g, for which communication becomes\\nthe key bottleneck for scaling up distributed training and\\nglobal model \\nupdate \\nlocal model \\nupdate \\nfig. 3. over-the-air computation for on-device distributed federated learning.\\nmap \\nreduce node \\nmap map \\nreduce reduce node 1 node 2 \\n e 1\\ndataset \\nsplit \\nmachine \\nlearning tasks \\nshuffle shuffle dataset \\nplacement \\nfig. 4. on-device distributed inference via wireless mapreduce.\\ndistributed inference over the cloud, network edge, and end-\\ndevices.\\ncommunication-efﬁcient distributed training : the\\ngrowing computation and storage power of devices provides\\nopportunities for on-device distributed training by processing\\ndata locally. however, communicating over the volatile wire-\\nless channel becomes the signiﬁcant bottleneck for distributed\\ntraining on mobile devices. to strengthen data privacy and\\nsecurity, federated learning [12] allows the training data to\\nbe kept at each device, thereby learning a shared global\\nmodel from distributed mobile devices. however, the limited\\nbandwidth becomes the main bottleneck for global model\\naggregation from locally updated models computed at each\\nmobile device. the over-the-air computation can be exploited\\nto enable low-latency global model aggregation via exploit-\\ning the superposition property of a wireless multiple-access\\nchannel, as shown in fig. 3.\\ncommunication-efﬁcient distributed inference : in 6g,\\nintelligent services will span from cloud data centers to end-\\ndevices and iot devices, e.g., self-driving cars, drones, and\\nauto-robots. as such, it is of prime importance to design ultra-\\nlow latency, ultra-low power and low-cost inference processes.\\nto overcome stringent computation, bandwidth, storage, power',\n",
       " '6\\nfig. 5. a hardware-efﬁcient hybrid beamforming structure with ﬁxed phase\\nshifters. the base station and user are equipped with 144 and 16 antennas,\\nrespectively, and 4 rf chains. the fully- and partially-connected structures\\nrequire 576 and 144 adaptive phase shifters, respectively, while the new\\nstructure only requires 30 ﬁxed phase shifters in the ﬁrst simulation. the\\nsecond simulation shows that 15 phase shifters are already sufﬁcient for the\\nnew structure.\\nand privacy constraints on individual devices, increasing re-\\nsearch interests are moving towards leveraging the dispersed\\ncomputing resources across the cloud, network edge and end-\\ndevices of 6g networks through the lens of mobile edge\\ncomputing [14]. for example, for a deep neural network, the\\ninitial features can be extracted on the end devices, which are\\nthen sent to the edge and cloud computing devices for further\\nprocessing. however, with the heterogeneity in the computing\\ncapabilities and communication bandwidths among the com-\\nputing devices, it becomes extremely challenging to allocate\\nthe operations of the neural networks to the computing devices\\nso that the latency and energy are optimized. fig. 4 demon-\\nstrates the on-device distributed inference process, where each\\ndevice locally computes the intermediate values based on the\\nmap function using the local data. the intermediate values are\\nfurther shufﬂed across the devices assisted by a central radio\\naccess points. the inference process will be accomplished\\nby collecting all the required intermediate values to construct\\nthe prediction results. a joint optimization of the uplink and\\ndownlink communication strategy was thus developed in [13]\\nfor shufﬂing the locally computed intermediate values across\\nmobile devices.\\nv. h ardware -aware communications for 6g\\nas new radio access technologies emerge, and iot de-\\nvices become more pervasive, hardware constraints will play\\ncritical roles when designing 6g networks. on one hand,\\nas radio communication is moving towards millimeter-wave\\nbands, and possibly terahertz bands, the high cost and power\\nconsumption of hardware components will signiﬁcantly affect\\nthe transceiver architecture and algorithm design. on the other\\nhand, iot devices have limited storage, energy source, and on-\\ndevice computing power. such resource-constrained platforms\\ncall for a holistic design of communication, sensing, and\\ninference. in this section, we present a new design paradigm\\nfor 6g, namely hardware-aware communications , and dis-\\ncuss three promising new design principles. for performance-\\ncritical scenarios, the objective is to develop hardware-efﬁcient\\ntransceivers that are also algorithm friendly, which calls for\\nhardware-algorithm co-design . for iot-like application sce-\\nnarios, application-aware communications will be essential.meanwhile, intelligent communications is needed to effec-\\ntively adapt to heterogeneous hardware constraints.\\na. hardware-algorithm co-design\\nthe desire to communicate at ever higher data rates will\\nnever stop. to reach terabytes per second data rates, it is\\ninevitable to operate at higher and higher frequency bands. the\\nmajor obstacle is from the hardware perspective. very large\\nscale antenna arrays are needed to overcome the increased\\npathloss and other propagation phenomena, which will bring\\na large number of hardware components, including signal\\nmixers, adcs/dacs, power ampliﬁers, etc. the high cost and\\npower consumption of these components at the mmwave and\\nthz band make it difﬁcult to adopt conventional transceiver\\nstructures, which in turn will affect the design of signal\\nprocessing algorithms. to effectively design such complex\\nsystems, collaboration among the hardware and algorithm\\ndomains will be needed, i.e., hardware-algorithm co-design\\nshould be advocated. the target is to develop hardware-\\nefﬁcient transceiver structures that are also algorithm friendly:\\nsuch structures should employ few of the costly hardware\\ncomponents, and they should be able to leverage existing\\nsignal processing algorithms.\\ncase study: consider mmwave hybrid beamforming as\\nan example, which is a cost-effective approach for providing\\neffective beamforming gains. it requires a small number of\\nrf chains, and thus can signiﬁcantly reduce hardware cost\\nand power consumption. however, a large number of phase\\nshifters are still needed for existing hardware structure. phase\\nshifters at mmwave bands are still very expensive, and thus\\ntheir number needs to be reduced. a new hardware-efﬁcient\\nhybrid structure was recently proposed in [15], as shown in\\nfig. 5. it only requires a small number of phase shifters,\\neach with a ﬁxed phase. as such, hardware modiﬁcation\\nis only in the analog network, basic design principles for\\nhybrid beamforming can still be applied. as shown in fig.\\n5, this new structure can approach the performance of the\\nfully digital beamforming, with much fewer phase shifters than\\nother hybrid beamforming structures.\\nb. application-aware communications for iot devices\\nthanks to the recent development of iot technologies,\\nintelligent mobile applications will thrive, and many of them\\nare powered by specialized low-cost, low-power devices.\\nsuch devices will handle basic sensing and simple on-device\\nprocessing tasks, while relying on proximate edge servers\\nor remote cloud data centers for computation-intensive pro-\\ncessing. thus, effective communications between devices and\\nservers will be essential. rather than serving as a bit pipe\\nfor traditional data services and focusing on maximizing data\\nrates, wireless communications for iot applications should di-\\nrectly serve speciﬁc applications. an integrated consideration\\nof communication, sensing, and inference will be critical to\\novercome the hardware limitations, as illustrated below.\\njoint sampling, communication, and inference: iot devices\\nhave serious challenges. these include, 1) limited computing\\npower to process the collected data; 2) their limited energy',\n",
       " '7\\nwill constrain their ability to collect data samples; 3) they do\\nnot have enough storage to store all the data; and 4) they\\ncannot afford to always send data to the server. by jointly\\noptimizing sampling, communication, and local processing,\\nand accounting for the state of local processors, storage,\\nand channel states, the overall performance can be improved.\\nthe integration with edge computing will play an important\\nrole, and joint edge-device processing techniques should be\\ndeveloped.\\nc. intelligent communications for heterogeneous hardware\\nconstraints\\nwireless networks are getting more and more heteroge-\\nneous, with various types of access points and mobile ter-\\nminals, which differ signiﬁcantly in hardware settings. such\\nheterogeneity has started from 4g lte networks, and with the\\ndeployment of advanced techniques such as massive mimo,\\nthe situation will further develop through 5g, and into 6g.\\nthis trend will complicate the communication protocol and al-\\ngorithm design, which may subsequently degrade the commu-\\nnication efﬁciency. recently, adopting machine learning tech-\\nniques to develop communication systems has demonstrated\\nits effectiveness, and such approaches have the potential of\\nleading to general purpose intelligent communications that\\ncan adapt to heterogeneous hardware constraints. a particular\\napproach is illustrated as follows.\\ntransfer learning for different hardware constraints: one\\ncomplication brought by hardware heterogeneity is the ex-\\ncessive effort to redesign the system for different hardware\\nsettings. for example, different transceiver architectures have\\nbeen proposed for mmwave systems, including analog beam-\\nforming, hybrid beamforming, and 1-bit digital beamforming.\\nthe conventional approach relies on hand-crafted design for\\neach of them, which is very inefﬁcient. these different types of\\ntransceivers will face the same problems as those in mmwave\\nchannels, and thus an algorithm well designed for one may\\nalso shed light on the design for another. transfer learning is\\na promising technique that can help to transfer the design of\\none architecture to others.\\nvi. c onclusions\\nthis article has presented an ai empowered architecture,\\nas well as ai-centric communication techniques, for 6g net-\\nworks. new features of the 6g evolution were identiﬁed, and\\nenabling technologies were discussed. while a partial picture\\nwas presented, we hope our discussion will spur interests\\nand further investigations on the future evolution of cellular\\nnetworks.\\nreferences\\n[1] k. chen, t. zhang, r. d. gitlin, and g. fettweis, “ultra-low latency\\nmobile networking,” ieee network , pp. 1–7, 2018.\\n[2] j. andrews, s. buzzi, w. choi, s. hanly, a. lozano, a. soong, and\\nj. zhang, “what will 5g be?,” ieee j. sel. areas commun. , vol. 32,\\npp. 1065–1082, jun. 2014.\\n[3] k. david and h. berndt, “6g vision and requirements: is there any\\nneed for beyond 5g?,” ieee veh. technol. mag. , vol. 13, pp. 72–80,\\nsep. 2018.[4] e. c. strinati, s. barbarossa, j. l. gonzalez-jimenez, d. kt ´enas,\\nn. cassiau, and c. dehos, “6g: the next frontier,” arxiv preprint\\narxiv:1901.03239 , 2019.\\n[5] f. tariq, m. khandaker, k.-k. wong, m. imran, m. bennis, and\\nm. debbah, “a speculative study on 6g,” arxiv:1902.06700 , 2019.\\n[6] y . xing and t. s. rappaport, “propagation measurement system and\\napproach at 140 ghz-moving to 6g and above 100 ghz,” in proc. ieee\\nglobal communications conf. (globecom) , pp. 1–6, dec. 2018.\\n[7] o. esraﬁlian, r. gangula, and d. gesbert, “learning to communicate\\nin ua v-aided wireless networks: map-based approaches,” ieee internet\\nof things j. , to appear, 2019.\\n[8] n. kato, z. md. fadlullah, f. tang, b. mao, s. tani, a. okamura, and\\nj. liu, “optimizing space-air-ground integrated networks by artiﬁcial\\nintelligence,” ieee wireless commun. , pp. 1–8, 2019.\\n[9] d. silver, j. schrittwieser, k. simonyan, i. antonoglou, a. huang,\\na. guez, t. hubert, l. baker, m. lai, a. bolton, et al. , “mastering\\nthe game of go without human knowledge,” nature , vol. 550, no. 7676,\\np. 354, 2017.\\n[10] j. mitola and g. q. maguire, “cognitive radio: making software radios\\nmore personal,” ieee pers. commun. , vol. 6, pp. 13–18, aug. 1999.\\n[11] n. c. luong, d. t. hoang, s. gong, d. niyato, p. wang, y . liang, and\\nd. i. kim, “applications of deep reinforcement learning in communica-\\ntions and networking: a survey,” corr , vol. abs/1810.07862, 2018.\\n[12] b. mcmahan, e. moore, d. ramage, s. hampson, and b. a. y arcas,\\n“communication-efﬁcient learning of deep networks from decentralized\\ndata,” in proc. int. conf. artiﬁcial intell. stat. (aistats) , vol. 54,\\npp. 1273–1282, 2017.\\n[13] k. yang, y . shi, and z. ding, “low-rank optimization for data shufﬂing\\nin wireless distributed computing,” in proc. ieee int. conf. acoustics\\nspeech signal process. (icassp) , calgary, alberta, canada, 2018.\\n[14] y . mao, c. you, j. zhang, k. huang, and k. b. letaief, “a survey\\non mobile edge computing: the communication perspective,” ieee\\ncommun. surveys tuts. , vol. 19, pp. 2322–2358, fourth quarter, 2017.\\n[15] x. yu, j. zhang, and k. b. letaief, “a hardware-efﬁcient analog network\\nstructure for hybrid precoding in millimeter wave systems,” ieee j. sel.\\ntopics signal process. , vol. 12, pp. 282–297, may 2018.\\nkhaled b. letaief [s’85-m’86-sm’97-f’03]\\n(eekhaled@ust.hk) received his ph.d. degree from purdue\\nuniversity. from 1990 to 1993, he was a faculty member at\\nthe university of melbourne, australia. he has been with\\nhkust since 1993 where he was dean of engineering, and\\nis now the new bright professor of engineering. from 2015\\nto 2018, he joined hbku in qatar as provost. he is an isi\\nhighly cited researcher and a recipient of many distinguished\\nawards. he has served in many ieee leadership positions\\nincluding comsoc president (at present), vice-president for\\ntechnical activities, and vice-president for conferences.\\nwei chen [s’05-m’07-sm’13] (wchen@tsinghua.edu.cn)\\nreceived his b.s. and ph.d. degrees from tsinghua university.\\nhe was a visiting ph.d. student at hkust from 2005 to\\n2007. he is currently a tenured professor at the department\\nof electronic engineering, tsinghua university.\\nyuanming shi [s’13-m’15] (shiym@shanghaitech.edu.cn)\\nreceived his b.s. degree from tsinghua university and the\\nph.d. degree from the hong kong university of science and\\ntechnology. he is currently a tenured associate professor\\nat the school of information science and technology,\\nshanghaitech university.\\njun zhang [s’06-m’10-sm’15] (jun-\\neie.zhang@polyu.edu.hk) received his ph.d. degree from the\\nuniversity of texas at austin. he is currently an assistant\\nprofessor at the hong kong polytechnic university.\\nying-jun angela zhang [s’00-m’05-sm’10]\\n(yjzhang@ie.cuhk.edu.hk) received her ph.d. degree from\\nthe hong kong university of science and technology. she is',\n",
       " '8\\nnow an associate professor at the department of information\\nengineering, the chinese university of hong kong.',\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t1\\tmetrics for explainable ai:  challenges and prospects  robert r. hoffman institute for human and machine cognition [rhoffman@ihmc.us] shane t. mueller michigan technological university [shanem@mtu.edu] gary klein macrocognition, llc [gary@macrocognition.com] jordan litman institute for human and machine cognition [jlitman@ihmc.us]   abstract the question addressed in this paper is: if we present to a user an ai system that explains how it works, how do we know whether the explanation works and the user has achieved a pragmatic understanding of the ai? in other words, how do we know that an explanainable ai system (xai) is any good? our focus is on the key concepts of measurement. we discuss specific methods for evaluating: (1) the goodness of explanations, (2) whether users are satisfied by explanations, (3) how well users understand the ai systems, (4) how curiosity motivates the search for explanations, (5) whether the user's trust and reliance on the ai are appropriate, and finally, (6) how the human-xai work system performs. the recommendations we present derive from our integration of extensive research literatures and our own psychometric evaluations.   1 introduction  for decision makers who rely upon artificial intelligence (ai), analytics and data science, explainability is an issue. if a computational system relies on a simple statistical model, decision makers can understand it and convince executives who have to sign off on a system that it is reasonable and that seems fair. they can justify the analytical results to shareholders, regulators, etc.  but for machine learning and deep net systems, they can no longer do this. there is a need for ways to explain the computational system to the decision maker so that they know that their full process is going to be reasonable.   ___________________________________________________________________________ this material is approved for public release. distribution is unlimited. this material is based on research sponsored by the air force research lab (afrl) under agreement number fa8650-17-2-7711. the u.s. government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation thereon. the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of afrl or the u.s. government. \",\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t2\\t... current efforts face unprecedented difficulties: contemporary models are more complex and less interpretable than ever; [ai is] used for a wider array of tasks, and are more pervasive in everyday life than in the past; and [ai is] increasingly allowed to make (and take) more autonomous decisions (and actions). justifying these decisions will only become more crucial, and there is little doubt that this field will continue to rise in prominence and produce exciting and much needed work in the future (biran and cotton, 2017, p. 4).  this quotation brings into relief the importance of \"explainable ai\" (xai.) a proposed regulation before the european union (goodman and flaxman, 2016) prohibits \"automatic processing\" unless user\\'s rights are safeguarded. users have a \"right to an explanation\" concerning algorithm-created decisions that are based on personal information. future laws may restrict ai, which represents a challenge to industry.  expert systems researchers have previously implemented methods for explanation (clancey, 1984, 1986; mckeown & swartout, 1987; moore & swartout, 1990). in a sense, explanation is what and intelligent tutoring systems were (and are) all about (forbus & feltovich, 2001; poulson & richardson, 1988; psotka,  massey & mutter, 1988; ritter & feurzeig, 1988; sleeman & brown, 1982). ai systems are receiving considerable attention in the recent popular press (alang, 2017; bornstein, 2016; champlin, bell & schocken, 2017; harford, 2014; hawkins, 2017; kuang, 2017; pavlus, 2017; pinker, 2017; schwiep, 2017; voosen, 2017; weinberger, 2017). reporting and opinion pieces have discussed social justice, equity, and fairness issues that are implicated by ai (e.g., felten, 2017).   the goals of explanation involve answering questions such as, \"how does it work?\" and \"what mistakes can it make?\" and “why did it just do that?” the question addressed in this paper is: if we present to a user an ai system that explains how it works, how do we go about measuring whether or not it works, whether it works well, and whether the user has achieved a pragmatic understanding? our focus in this paper is on the key concepts of measurement for the evaluation of xai systems and human-machine performance.   1.1 key measurement concepts  the concept or process of explanation or understanding has been explored in one way or another by scholars and scientists of all schools and specializations, spanning all of human civilization.  to say that the pertinent literature is enormous is an understatement. in modern times, the concept is a focus in philosophy of science, psychology (cognitive, developmental, social, organizational), education and training, team science, and human factors.   while explainable ai is only now gaining widespread visibility, [there is a] continuous history of work on explanation and can provide a pool of ideas for researchers currently tackling the task of explanation (biran and cotton, 2017, p. 4).   ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t3\\tkey concepts include causal reasoning and abductive inference, comprehension of complex systems, counterfactual reasoning, and contrastive reasoning. for reviews of the literature, see miller (2017) and hoffman, klein and mueller (2018).  a conceptual model of the xai explaining process is presented in figure 1. this diagram highlights four major classes of measures. initial instruction in how to use an ai system will enable the user to form an initial mental model of the task and the ai system. subsequent experience, which can include system-generated explanations, would enable to participant to refine their mental model, which should lead to better performance and appropriate trust and reliance.   \\n  figure 1.  a conceptual model of the process of explaining, in the xai context.   by hypothesis, explanations that are good and are satisfying to users enable users to develop a good mental model. in turn, their good mental model will enable them to develop appropriate trust in the ai and perform well when using the ai. to evaluate this model of the explanation process, a number of types of measures are required (miller, 2017). in the remainder of this report we detail each of the four classes of measures and offer specific methodological suggestions.   2 explanation goodness and satisfaction  the property of \"being an explanation\" is not a property of statements, it is an interaction. what counts as an explanation depends on what the learner/user needs, what knowledge the user (learner) already has, and especially the user\\'s goals. this leads to a consideration of function and context of the ai system (software, algorithm, tool), that is, why does a given user need an \\n',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t4\\texplanation? in the various pertinent literatures, this is expressed in terms of the different kinds of questions that a user might have. these “triggers” for explanation are listed in table 1.       table 1.  triggers and goals.   triggers   user/learner’s goal how do i use it?  achieve the primary ask goals how does it work? feeling of satisfaction at having achieved an understanding of the system, in general (global understanding) what did it just do? feeling of satisfaction at having achieved a understanding of how the system made a particular decision (local understanding) what does it achieve? understanding of the system\\'s functions and uses what will it do next? feeling of trust based on the observability and predictability of the system how much effort will this take? feeling of effectiveness and achievement of the primary task goals what do i do if it gets it wrong? desire to avoid mistakes how do i avoid the failure modes? desire to mitigate errors what would it have done if x were different? resolution of curiosity at having achieved an understanding of the system why didn’t it do z? resolution of curiosity at having achieved an understanding of the local decision  thus, the seeking of an explanation can tacitly be an expression of a need for a certain kind of explanation, to satisfy certain user purposes of user goals.    2.1 explanation goodness looking across the scholastic and research literatures on explanation, we find assertions about what makes for a good explanation, from the standpoint of statements as explanations,. there is a general consensus on this; factors such as clarity and precision. thus, one can look at a given explanation and make an a priori (or decontextualized) judgment as to whether or not it is \"good.\" appendix a presents a goodness checklist that can be used by xai researchers to either try and design goodness into the explanations that their xai system generates, or to evaluate the a priori goodness of the explanations that an xai system generates. in a proper experiment, the researchers who complete the checklist, with reference to some particular ai-generated ',\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t5\\texplanation, would not be the ones who created the xai system under study. using the goodness checklist, those independent judges ask, are the researchers right in claiming that their explanations are good?     2.2 explanation satisfaction  while an explanation might be deemed good in the manner described above, it may at the same time not be adequate or satisfying to users-in-context. explanation satisfaction is defined as the degree to which users feel that they understand the ai system or process being explained to them. compared to goodness, as we defined it above, satisfaction is a contextualized, a posteriori judgment of explanations.   based on our review of the psychological literature on explanation, including theoretical and empirical work by muir (1987, 1994) and by cahour and forzy (2009), we identified several key attributes of explanations: understandability, feeling of satisfaction, sufficiency of detail, completeness, usefulness, accuracy, and trustworthiness. these terms were incorporated into an initial pool of likert scale items that we constructed for review and evaluation.   standard practice in psychometrics involves assuring that a scale is internally consistent or reliable (evaluated primarily by the method of cronbach's alpha, which is based on inter-item covariance). for the xai context, it is immediate importance to determine the validity of an explanation satisfaction scale.   2.3 scale validation: content validity  psychometric theory describes several methods for evaluating validity, all of which ultimately refer to the question, does the scale measure what it is intended to measure? two distinct kinds of validity are immediately pertinent to the development of a scale of explanation satisfaction. these are described in table 2.  table 2.  types of validity that are immediately pertinent to an evaluation of the satisfaction scale.  surface (i.e., “face”) validity   this is a judgment that the items appear to measure what they are intended to measure because they refer literally and explicitly to the conceptual measurables that the instrument is supposed to measure. for example, a questionnaire item that asks you to rate how smart you think you are compared to the average person would have surface validity as a measure of self-perceived intelligence since it refers explicitly to the concept of intelligence, and asks for a rating that treats intelligence as a scalar variable. (setting aside for now the fact that the rating might be biased.) construct validity  \",\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t6\\tconstruct validity is the analysis of the test in terms of some theoretical framework, or the reliance on an accepted theoretical framework in the construction of the test and the individual items. \"[it] reflects the degree to which the measurement instrument spans the domain of the construct’s theoretical definition; it is the extent to which a measurement instrument captures the different facets of a construct\" (rungtusanatham, 1998, p.10). thus, the measurements fall on a measurement scale that is interpreted as a measure of the theoretical concept (hoffman, 2010).  these aspects of validity can be evaluated by having domain experts make judgments as to whether the scale items are meaningful and measurable indicators of the relevant psychological construct, and consistent with the accepted theoretical framework for the construct. we conducted a validation study with the cooperation of participants and attendees at a recent darpa-sponsored meeting of xai researchers. the participants could express their judgments by rating the degree to which each scale item is essential to measuring the construct.  participants were asked to evaluate the scale using the content validity ratio (cvr) method (lawshe, 1975). the cvr is useful for quantitatively assessing the strength of each scale item with a small group of raters. the scale that was presented to participants is presented in table 3.  table 3. the cvr version of the explanation satisfaction scale.  for each item listed below, please indicate whether you believe that the item is:  • essential for measuring explanation satisfaction,  • useful but not essential, or  • not necessary for measuring explanation satisfaction.   indicate your response by circling the appropriate number.   essential useful but not essential not necessary 1. i understand this explanation of how the [software, algorithm, tool] works. 1 2 3 2. this explanation of how the [software, algorithm, tool] works is satisfying. 1 2 3 3. this explanation of how the [software, algorithm, tool] works has sufficient detail. 1 2 3 4. this explanation of how the [software, algorithm, tool] works contains irrelevant details. 1 2 3 5. this explanation of how the [software, algorithm, tool] works seems complete. 1 2 3 6. this explanation of how the [software, algorithm, tool] works tells me how to use it. 1 2 3 7. this explanation of how the [software, algorithm, tool] works is useful to my goals. 1 2 3 ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t7\\t8. this explanation of says how accurate the [software, algorithm, tool] is. 1 2 3 9. this explanation lets me judge when i should trust and not trust the [software, algorithm, tool] 1 2 3  in order to get reasonably stable psychometric estimates for evaluating the items\\' communality, a rule of thumb (in the psychometric literature) is that one wants 5-10 respondents. at the darpa pi meeting we received responses from 35 domain practitioners.  six of the participants identified as software engineers, four self-identified as graduate students (primarily in computer science or engineering), one as a test pilot, and three did not specify their profession. fifteen individuals self-identified as computer scientists (ph.d. and bs/ms degrees). three participants self-identified as psychologists. the remaining 21 participants self-identified as researchers, professors, or research managers (fields including computer science, engineering, psychology, and mathematics).  in keeping with recommendations on using the cvr method for item selection (davis, 1992; gilbert & prion, 2016; lynn, 1986), items that are rated as either \"essential\" or \"useful\" by more than 50% of the professionals were selected for further analysis; items that did not meet this criteria were dropped from further consideration. for each selected item, the cvr was calculated by dividing the number of respondents who rated the item as \"essential\" or \"useful\" to the total number of participants.  cvr ratios are calculated for each item separately, by dividing the number of raters who rated an item as either \"essential\" or \"useful\" to the total number of participants. the resulting ratio values for all scale items are aggregated and transformed to a scale that ranges between −1 (perfect disagreement) and +1 (perfect agreement), with cvr values above zero indicating that over half of our domain professionals judged the item to be a highly valid indicator of es as a psychological construct.  the average cvr for all participants who self-identified as having ph.d. degrees was 0.43. the cvr for the computer scientists was 0.60. the average cvr for the self-identified \"researchers\" was 0.43, and for \"others\" was 0.57. according to ayre and scally (2014) the critical value of the average cvr should be 0.50 or greater. given our relatively large sample size, we take our results (positive cvrs in the range of 0.43 to 0.60) to indicate reasonably high agreement as to the validity of the scale items.  many participants reported that they found item number 4 to be confusing. this is the only item that would be reverse scored (i.e., an explanation would be unsatisfying if it contained irrelevant details). for this reason, we recalculated the critical values after dropping this scale item. all other items were rated as either \"essential\" or \"useful\" measures of explanation satisfaction. it is interesting to note the computer scientists and electrical engineers collectively showed higher agreement than the psychologists. this seems to be due to the high ratings given to scale item number 7 by the individuals who self-identified as psychologists. they appear to have been emphasizing the importance of the goal relevance of explanations.  ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t8\\twe assessed the internal consistency of the es scale. cronbach\\'s alpha was 0.86; es items had item-total correlations ranging from 0.41 to 0.76 and an average inter-item correlation of 0.71, indicative of excellent internal consistency reliability, especially for such a brief scale that is very easy to administer and score (comrey, 1988; cortina, 1993; streiner, 2003).    2.4 scale validation: discriminant validity  our next step was to test the discriminant validity of the es scale, that is, does it differentiate between relatively good and poor explanations. the scale resulting from the cvr analysis was subjected to analysis of its discriminant validity using three test cases (how does a cruise control work? how do computers predict hurricanes? how do cell phones find directions?). for each test case, a small group of experts were employed to generate what they felt were \"good\" explanations, and the researchers themselves developed what they felt were \"bad\" versions. the \"bad\" versions were sparse, had irrelevant details, and some incorrect statements. the materials are presented in appendix b. eight volunteers (students and junior researchers at ihmc) were asked to use the explanation satisfaction scale to rate “good” and “bad” explanations. we calculated a 2 (explanation quality: “good” vs. “bad”) x 2 (object to be explained) mixed model anova, for which the scale ratings were treated as a repeated measure. the main effect for ratings of explanation quality was only marginally significant [f (1,6) = .455; p < .08], but the size of the effect was quite large (cohen’s d = 1.5, equivalent to a r2 = .36) indicating that, in general, scale ratings corresponded to higher values being awarded to good explanations (m = 42.75; sd = 3.40) and lower values being given for bad explanations (m = 30.00; sd = 11.46). no statistically significant effect was found for giving repeated scale ratings or for the interaction with explanation quality. in conclusion, results from the content validity analysis and discriminant validity analysis show that the es scale is valid. the explanation satisfaction scale is presented in appendix c. like the explanation goodness checklist (appendix a), the explanation satisfaction scale was based on the literatures in cognitive psychology, philosophy of science, and other pertinent disciplines regarding the features that make explanations good. thus, the explanation satisfaction scale is very similar to the explanation goodness checklist. however, the application context for the two scales is quite different. • the explanation goodness checklist is intended to be used by researchers or their xai systems that have created explanations. the explanation goodness checklist is intended for use as an independent evaluation of explanations by other researchers. the reference is to the properties of explanations.  • explanation satisfaction is an evaluation of explanations by users. the explanation satisfaction scale is for collecting judgments by research participants after they have worked with the xai system that is being explained, and have been the beneficiaries of one or more explanations.  ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t9\\t3. measuring mental models  a methodology is needed for eliciting, representing, and analyzing users\\' mental models of intelligent systems or decision aid systems. in cognitive psychology, \"mental models\" are representations or expressions of how a person understands some sort of event, process, or system (klein and hoffman, 2008). in the xai context, a mental model is basically a user’s understanding of the ai system.   3.1 users\\' models of the computer (\"mental models\") versus the computer\\'s models of users (\"user models\")  in current parlance, the user\\'s \"mental model\" is distinguished from what is called a \"user model.\" the latter is a computer model of a user\\'s mental model. the ai employs user models to adapt its operations and interactions. user models might consist of formalisms, such as production rules and semantic networks, which may represent a person’s preferences and emulate some aspects of his or her knowledge and reasoning about some situation. user models for intelligent tutoring systems were aimed at understanding a learner\\'s understanding so as to tailor instructional materials and exercises (see for instance, lesgold, et al., 1992). user models are also referenced in the design of human-machine systems (see for instance, carberry, 1990; harris and helander, 1984; may, barnard, and blandford, 1993). user models for ai and expert systems were aimed at emulating human cognition and thereby replicating performance on various tasks (see for instance, anderson et al., 1990; clancey, 1984, 1986). mental models, including the person’s beliefs and conceptual processes, may be represented as computational cognitive models using similar formalisms.   in this report, we do not review attempts to automatically generate user models (that is, formal instantiations of mental models). friedman, forbus and sherin (2017) present present a computational cognitive model that creates and evaluates models based on fragmentary and inconsistent information. their formalism is predicate calculus, and the assertion is that the system is capable of abductive inference, that is, inference to a best explanation. our focus is on methods for eliciting information about users\\' mental models.  3.2 empirical assertions  there is a large body of research by experimental psychologists on mental models (e.g., carroll, 1984; gentner and gentner, 1983; greeno, 1977; johnson-laird, 1980, 1989; kintsch, miller & poulson, 1974). praetorious and duncan (1988) present an elegant treatment of methodology for eliciting mental models. staggers and norco (1992) provide a good summary of the conceptual and theoretical issues.   there is a consensus that mental models can be inferred from empirical evidence. people may not be able to tell you “everything” about their understanding, and they may not be able to tell it well.  but with adequate scaffolding by some method of guided task reflection, people can tell you how they understand an event or system, they can describe their knowledge of it, and the concepts and principles that are involved. there is sufficient evidence to conclude that different ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t10\\tmethods for eliciting mental models can converge (evans, et al., 2001; van der veer, & melguzio, 2003).  for many people, mental imagery is involved in reasoning and dynamical and complex systems (e.g., bogacz & trafton, 2004). this assertion is supported by studies showing that diagrams can contribute significantly to the understanding of dynamic and complex systems (e.g., clement, 2004; glenberg and langston, 1992; heiser & tversky, 2004; johnson-laird, 1983; klein & hoffman, 2008; qin & simon, 1992; zhang & wickens, 1987).  these ideas pertain directly to how people understand machines, spanning simple devices, process control systems, complex computational systems, and intelligent systems (bainbridge, 1979, 1988; de kleer and brown, 1983; goodstein, andersen and olsen, 1988; moray, 1987; mueller & klein, 2011; rasmussen, 1986; rasmussen,  pejtersen, & goodstein,  1994; samurcay and hoc, 1996; staggers and norcio, 1993; williams, hollan, and stevens, 1983; young, 1983).   3.3 overview of mental model elicitation methods  referring again to the historical differences between concepts of user models, cognitive models, and mental models, there are associated differences in how models of human cognition are elicited and represented. there are also differences in the emphasis placed on elicitation methods. for example, some of the work on user and cognitive models focuses on formal methods and languages for modeling beliefs and/or problem solving (e.g., procedural rules), these are researchers’ computational models of what a user’s mental model might be (see for instance, clancey, 1986; johnson-laird, 1983; de kleer, doyle, steele, and sussman, 1977; doyle, et al., 2002; moray, 1983; schaffernicht and groesser, 2011).   table 4 lists some methods that have been used to elicit mental models in fields such as cognitive psychology, knowledge acquisition for expert systems, instructional design, and educational computing. table 5 lists some strengths and weaknesses of various methods.  \\t ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t11\\ttable 4. some methods that can be used to elicit mental models.  method illustrative references  think-aloud problem solving task, in which participants think aloud during a task.   reports by pjtersen and goodstein (1994) and williams, hollan and stevens, (1983) are good illustrations of the task to elicit mental models specifically of devices. see also beach, 1992; ericsson and simon, 1984; gentner and stevens, 1983; greeno, 1983; rasmussen, pejtersen & goodstein, 1994; ward, et al., in press. think-aloud task with concurrent question answering. gentner and gentner, 1983; williams, hollan and stevens, 1983 task reflection or retrospection task, in which participants describe their reasoning after conducting a task (e.g., fault diagnosis). the retrospection can be based, for example, on a replay of their task performance such as in a video. fryer (1939) provides a clear and succinct presentation of a method that combines retrospection with likert scale questionnaire to quantify participants’ reasoning.  see also frederick, 2005; lippa, klein & shalin, 2008; praetorious & duncan, 1988 structured interview, essentially retrospection task with question-answering. friedman, forbus & sherin, 2017; fryer, 1939 card sorting task (also \"pathfinder\"), based on the semantic similarity among a set of domain concepts. the review article by van der veer & melguzio (2003) highlights this method. see also chi, feltovich & glaser, 1981; st.-cyr and burns, 2002; evans, et al., 2001; van der veer & melguzio, 2003 nearest neighbor task, in which participants select the explanation or diagram that best fits their beliefs. hardiman, dufresne and mestre, 1989; klein and militello, 2001 self-explanation task (also called \"teach-back\"), in which the user/learner expresses their own understanding. similar to the retrospection/reflection task cañas et al., 2003; ford, cañas, & coffey, 1993; fermbach, et al., 2010; molinaro & garcia-madruga, 2011; van der veer & melguzio, 2003 glitch detector task (also called “accident-error analysis”), in which people identify the things that are wrong in an explanation.  hoffman, coffey, ford & carnot, 2001; taylor, 1988 prediction task, in which users are presented test cases and are asked users to predict the results and then explain why they thought the predicted results would obtain. muramatsu & pratt, 2001 diagramming task (also \"concept mapping\"), in which users create a diagram that lays out their knowledge of processes, events and other relations. cañas, et al., 2003; evans, et al., 2001; hoffman et al., 2017; moon, et al., 2011; novak & gowin, 1984 shadowbox task, in which learners compare their understandings to those of a domain expert. klein & borders, 2016     ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t12\\ttable 5.  methods strengths and weaknesses.  method strength weakness  concurrent think-aloud problem solving can provide rich information about mental models. transcription and protocol analysis can be time consuming, result in a great deal of data, require much analysis. think-aloud task with concurrent question answering enables the researcher to present targeted probes to the user during task performance. highly dependent on the researcher/interviewer’s skill at question design and interviewing. task reflection or retrospection can be conducted as a structured interview, as a questionnaire task, or as a post-task verbalization of a self-explanation. can provide rich information about mental models, or a quick window into mental models. the process of self-explanation itself has learning value. people can overestimate how well they understand complex systems. transcription and protocol analysis can be time consuming, result in a great deal of data, require much analysis. less effort would be required in a questionnaire method, though questionnaire design would be non-trivial. card sorting can provide information about domain concepts and their relations. can provide sparse data about events or processes. primary data consists only of similarity ratings (i.e., semantic nets) nearest neighbor can provide a quick window into mental models. people overestimate how well they understand complex systems. glitch detector can support users to discover and explain aspects of their mental model that are reductive or incorrect. glitches have to be built-in. knowledge shields may inhibit the awareness of reductive tendencies. question-answering/structured interview enables researcher to probe selected aspects of a user’s mental model. highly dependent on the researcher/interviewer’s skill at question design and interviewing. prediction task can provide a quick window into mental models.  the predictions should be accompanied by a confidence rating and an free response elaboration that explains or justifies the predictions. the free responses require content analysis. requires clear rationale for the choice of instances or cases to be the focus of the predictions. diagramming task can provide a rich and thorough representation of the user’s mental model.  relations are not restricted to similarity (see card sorting task, above). can take time to create, although user friendly software systems are readily available.  box or \"shadowbox lite\" task can provide a quick window into mental models. may not result in a thorough expression of the mental model.       ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t13\\t3.4 application to the xai context  what is most desirable for xai is a task that enables the researcher to learn what is good and what is not good about a user\\'s mental model, and enable the learner to learn what is good and what is limited in their understanding. an insight can be thought of as the self-awareness of a \"knowledge shield\" (feltovich, coulson, and spiro, 2001). knowledge shields are arguments that learners make that enable them to preserve their reductive understandings. a focus for instructional design has been to develop methods to get people to recognize when they are employing a knowledge shield that prevents them from developing richer mental models (hilton, 1986, 1996; prietula, feltovich, & marchak, 2000; schaffernicht & groesser, 2011; tullio, dey, chalecki, & fogarty, 2007).  what is most desirable for xai is a method that can elicit mental models quickly, and result in data that can be easily scored, categorized, or analyzed.     it is important that the method provide some sort of structure or “scaffolding” that supports the user in explaining their thoughts and reasoning. one method is cued retrospection. probe questions are presented to participants about their reasoning just after the reasoning task has been performed (see ward, et al, in press). for instance, they might be asked, \"can you describe the major components or steps in the [software system, algorithm].\" the probes can also reference metacognitive processes, for example by asking, \"based on the explanation of the [software, algorithm], can you imagine circumstances or situations in which the [software, algorithm] might lead to error conditions, wrong answers, or bad decisions?\"   instances of explanation are often expressions of what will happen in the future (koehler, 1991; lombrozo and carey, 2006; mitchell, russo & pennington, 1989). prediction tasks have the user predict what the ai will do, such as the classification of images by a deep net. a prediction task might be about \"what do you think will happen next? but it can also be about \"why wouldn\\'t something else happen?\"  explanation and counterfactual reasoning are co-implicative. instances of explanation often are expressions of counterfactual reasoning (byrne, 2017). a prediction task might serve as a frugal method for peering into users\\' mental models, but its application should be accompanied by a confidence rating and a free response elaboration in which the users explain or justify their predictions, or respond to a probe about counterfactuals  diagramming can be an effective way for a user to convey the understanding to the researcher, and it also supports an analytical process in which diagrams are analyzed in terms of their proposition content (cañas, et al., 2003; johnson-laird, 1983 ch. 2). a diagramming task, along with analysis of concepts and relations (including causal connections or state transitions) has been noted in education as a method for comparing the mental models of students to those of experts or their instructor (see novak and gowin, 1984); noted in social studies as a method for comparing individuals\\' mental models of social groups (i.e., individuals and their inter-relations; carley and palmquist, 1992), and in operations research as a method for comparing mental models of dynamical systems (see schaffernicht and groesser, 2011).  explicit explanation improves learning and understanding. this holds for both deliberate self-motivated self-explanation and also self-explanation that is prompted or encouraged by the ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t14\\tinstructor. self-explanation has a significant and positive impact on understanding. self-generated deductions and generalizations help learners refine their knowledge (chi and vanlehn, 1991: chi, et al, 1989, 1994; chi & van lehn, 1991; lombrozo, 2016; molinaro & garcia-madruga, 2011; rittle-johnson, 2006). having learners explain the answers of \"experts\" also enhances the learner\\'s understanding (calin-jagerman & ratner, 2005).  this said, people sometimes overestimate how well they understand complex causal systems. this can be corrected by asking the learner to explicitly express their understanding or reasoning (bjork et al., 2013; chi, et al, 1989; 1991; fernbach, et al., 2012; mills & keil, 2004; o’reilly, symons, & maclatchy-gaudet, 1998; rittle-johnson, 2006; rosenblit & keil, 2002; vanlehn, ball, & kowalski, 1990). \"shadowbox lite\" (presented by permission from devorah klein; see also klein & borders, 2016) is a specific self-explanation task that is applicable to the xai context, and may provide a quick window into user mental models: it avoids the necessity of eliciting and analyzing an extensive recounting of the user’s mental model. in the method, the user is presented a question such as \"how does a car\\'s cruise control work?\" accompanying the question is a proposed explanation. the task for the user is to identify one or more ways in which the explanation is good, and ways in which it is bad. after doing this, the participant is shown a good-bad list that was created a domain expert. the participant\\'s comparison of the lists can lead to insights.   3.5 design considerations  referencing these four kinds of tasks, and the other tasks listed in table 1, it is recommended that the evaluation of user mental models within the xai context should employ more than one method for eliciting mental models. performance on any one type of task might not align with performance at some other task. for instance, adequacy of a user-generated diagram did not match to better performance at a prediction task (see st.-cyr and burns, 2002). performance on a  simulated industrial process control task can be good and yet the operator’s understanding can be limited and even incorrect (see berry and broadbent, 1984).  not all of the participants in a study have to be presented with a mental model elicitation task. indeed, a reasonably sized and representative set of 10 to 12 participants can be presented one or more mental model elicitation tasks. if the analysis of the goodness of the mental models aligns with measures of performance, then subsequent studies might use performance measures as a surrogate for mental model analysis.   3.6  analysis of user mental models  an empirically-derived expression of the content or the ebbs and flows that compose a user’s mental model must permit evaluation of mental model goodness (i.e., correctness, comprehensiveness, coherence, usefulness). for illustrative purposes, table 3 presents a simple example of an evaluation that is usually based on proposition analysis. carley and palmquist (1992) provide illustrative examples of propositional coding for transcripts of interviews of students by their teachers. the user model developed by friedman, forbus and sherin (2017) is ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t15\\tbased on propositional encoding of interview transcripts. in this report we illustrate propositional analysis using the framework of the shadowbox lite task. table 6 presents an \"expert\" explanation, although this might just as easily be thought of as an explanation generated by an xai system.   table 6.  an example of propositional coding using the shadowbox lite task.  the control unit detects the rotation of the drive shaft from a magnet mounted on the drive shaft, and from that can calculate how fast the car is going.  the control unit controls an electric motor that is connected to the accelerator linkage.  the cruise control adjusts the engine speed until it is disengaged.  what is right and helpful about this explanation?  the cruise control unit has to know how fast the car is going.  the cruise control has to control the engine throttle or accelerator. what is problematic or wrong about this explanation?  it seems overly technical, with some concepts left unexplained.  i do not think the cruise control detects the engine speed.  results from a number of elicitation tasks will generally be sets of sentences, which can be recast as propositions, broken out by the concepts — the relations. the products from a diagramming task can also be recast as a set of propositions. the explanation can be decomposed into the component concepts, relations and propositions. in the case of the cruise control example, the expert\\'s explanation has ten concepts (drive shaft rotation, car speed, etc.) seven relations (mounted on, disengage, etc.), and six propositions (e.g., magnet is mounted on the drive shaft, control unit calculates car speed).  the counts for concepts, relations and propositions can be aggregated and analyzed in a number of ways. for instance, one can calculate the percentage of concepts, relations, and propositions that are in the user’s explanation that are also in the expert’s explanation. this could suggest the completeness of the user’s mental model.    3.7 hypothesis testing  based on the model in figure 1, a primary hypothesis for xai is that a measure of performance is simultaneously a measure of the goodness of user mental models. as our discussion (above) of the multi-method approach suggests, this hypothesis is not to be taken for granted. it can be empirically investigated to see if it is confirmed. it may be especially revealing to compare results from participants who perform the best and participants who perform the worst. comparison of their models, and those with an expert model would affirm the hypothesis that a ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t16\\tmeasure of performance can be simultaneously a measure of the goodness of the user mental model.   4. measuring curiosity  4.1 introduction  there are theoretical and empirical reasons why curiosity could be considered an important factor in explainable ai. one of the most important reasons is that the act of seeking an explanation is driven by curiosity. therefore, it is important that the xai systems harness the power of curiosity. explanations may promote curiosity and set the stage for the achievement of insights and the development of better mental models.  on the other hand, explanations can actually suppress curiosity and reinforce flawed mental models.  this can happen in a number of ways:  • an explanation might overwhelm people with details, • the xai system might not allow questions or might make it difficult for the user to pose questions, • explanations might make people feel reticent because of their lack of knowledge, • explanations may include too many open variables and loose ends, and curiosity decreases when confusion and complexity increase.  for these reasons, the assessment of users\\' feelings of curiosity might be informative in the evaluation of xai systems.   4.2 the nature of curiosity  \"epistemic curiosity\" is the general desire for knowledge, a motive to learn new ideas, resolve knowledge gaps, and solve problems, even though this may entail effortful cognitive activity (berlyne, 1960, 1978; loewenstein, 1994; see also litman, 2008; 2010). stimulus novelty, surprisingness, or incongruity, can trigger curiosity. all of these features refer to circumstances when information is noted as being missing or incomplete.   curiosity is also triggered in circumstances where one experiences a \"violated expectation\" (maheswaran & chaiken, 1991). violated expectations essentially reflect the discovery that events anticipated to be comprehensible are instead confusing – more information and some sort of change to one\\'s understanding will be needed to make sense of the event and thus resolve the disparity between expectation and outcome. such situations lead people to engage in effortful processing, and motivates them to seek out additional knowledge in order to gain an insight and resolve the incongruency (loewenstein, 1994).   ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t17\\tthis is directly pertinent to xai. curiosity is stimulated when learner recognizes that there is a gap in their knowledge or understanding. recognizing a knowledge gap, closing that gap, and achieving satisfaction from insight make the likelihood of success from explanations or self-explanations seem feasible. this leads to the question of how to assess or measure curiosity in the xai context, and what to do with the measurements.   figure 2 presents a conceptual model of the explanation process from the perspective of the learner who is using an xai system. this diagram shows the role and place of curiosity, noting that some learners may not feel curious.   \\n  figure 1.  a model of the explanation process in the xai context from the perspective  of the learner, showing the role of curiosity. 4.3 measuring curiosity in the xai context  \\n',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t18\\ta number of psychometric instruments have names that at first glance make them seem pertinent to xai, such as frederick\\'s \"cognitive reflection test\" (2005). but this taps numerical fluency and competence. available scales of curiosity, such as kashdan\\'s \"curiosity exploration inventory\"(kashdan, et al., 2004), the cacioppo \"need for cognition\" scale (cacioppo, petty & kao, 1984), and litman\\'s \"i-type/d-type curiosity scales\" (litman and jimeson, 2004) consider curiosity to be a pervasive style or personality trait. as such, the instruments ask questions such as: i actively seek as much information as i can in a new situation,  i feel stressed or worried about something i do not know,  i like to discover new places to go. such items are barely applicable in the xai context, in which curiosity is situation or task specific, and refers to the workings of computational devices, rather than daily life or experiences.    the above discussion of the knowledge gap theory of curiosity implies that the evaluation of xai systems can benefit from basically asking users to identify the triggers that motivated them to ask for an explanation. as for the other measurement classes we have discussed, it is valuable for the curiosity measurement method to present a \"quick window.\" table 7 presents a simple questionnaire that can be administered to research participants whenever they ask for an explanation.  table 7.  a curiosity checklist.   why have you asked for an explanation?  check all that apply.   i want to know what the ai just did.  i want to know that i understand this ai system correctly.  i want to understand what the ai will do next.   i want to know why the ai did not make some other decision.  i want to know what the ai would have done if something had been different.  i was surprised by the ai’s actions and want to know what i missed.  responses will be informative with regard to these things:  (1). responses may serve as parameters or constraints that the xai system uses to generate explanations.  (2) responses may provide a window into aspects of the ai system\\'s operations that need explaining.  (3). responses may reveal ways in which the ai\\'s explanation method might suppress or inhibit curiosity, and (4). responses may make it possible to use depth of curiosity (i.e., more triggers are checked) as  an independent variable.   \\t\\t\\t',\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t19\\t5 measuring trust in the xai context 5.1 introduction  trust in automation is of concern in computer science and cognitive systems engineering, as well as the popular media (e.g., chancey et al., 2015; hoff and bashir 2015; fitzhugh, hoffman & miller, 2011; hoffman et al., 2009, 2013; huynh et al., 2006; kucala, 2013; lee & see, 2004; merritt and ilgen, 2008; merritt et al. 2013, 2015; naone, 2009; pop et al. 2015; shadbolt, 2002; wickens et al., 2015; woods and hollnagel 2006).   some users may take the computer's assertions (data, claims) as valid and true because they come from a computer. but other users may require some sort of justification ⎯ empirical reasons to believe that the computer's presentations or assertions are valid and true.  just as there are varieties of trusting, there are varieties of negative trusting (mistrust, distrust, etc.). trust in automation can rapidly break down under conditions of time pressure, or when there are conspicuous system faults or errors, or when there is a high false alarm rate (dzindolet et al., 2003; madhavan and wiegmann 2007). the trusting of machines can be hard to reestablish once lost.   however trust is measured, in the xai context, the measurement method must be sensitive to the emergence of negative trusting states. xai systems should enable the user to know whether, when, and why to trust and rely upon the xai system and know whether, when, or why to mistrust the xai and either not rely upon it, or rely on it with caution. people always have some mixture of justified and unjustified trust, and justified and unjustified mistrust in computer systems. a user might feel positive trust toward an ai system with respect to certain tasks and goals and simultaneously feel mistrusting or distrusting when other tasks, goals or situations are involved. indeed, in complex sociotechnical work systems, this is undoubtedly the norm in the human-machine relation (hoffman et al. 2014; sarter et al. 1997),   ideally, with experience the user comes to trust the computer with respect to certain tasks or goals in certain contexts or problem situations and appropriately mistrusts the computer with respect to certain tasks or goals in certain contexts or problem situations. only if this trusting relation is achieved can the user's reliance on the computer be confident (riley, 1996).   5.2 explanation as exploration  trusting of xai systems will always be exploratory. active exploration of trusting–relying relationships cannot and should not be aimed at achieving single stable states or maintaining some decontextualized metrical value, but must be aimed at maintaining an appropriate and context-dependent expectation. active exploration will involve: • verifying the reasons to take the computer's presentations or assertions as true,  • enabling the user to understand and anticipate circumstances in which the machine’s recommendations will not be trustworthy, and the computer's recommendations should not be followed even though they appear trustworthy. \",\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t20\\t• assessing the situational uncertainty that might affect the probability of favorable outcomes. • enabling the user to identify and mitigate unjustiﬁed trusting and unjustiﬁed mistrusting situations. • enabling the user to discover and appreciate indicators to mitigate the impacts and risks of unwarranted reliance, or unwarranted rejection of recommendations, especially in time-pressured or information-challenged (too much, too little, or uncertain) situations. • enabling the user to understand and anticipate circumstances (i.e., unforeseen variations on contextual parameters) in which the xai should not be trusted even if it is working as it should, and perhaps especially if it is working as it should (woods 2011).  there are many possible trajectories in this exploration.  for example, a user who is initially cautions or skeptical may benefit from a good explanation and move into a region of justified trust. subsequent use of the xai system, however, may result in an automation surprise. for example, a deep net might make a misclassification that no human would make. this might swiftly move the user into a state of unjustified mistrust, in which the user is skeptical of any of the classifications that the deep net makes. following that, the xai system may provide additional explanations and the user may explore the performance of the xai, converging in the region of appropriate trust and reliance.   5.3 trust measurement scales  the scientific literature on trust (generally) presents a number of scales for measuring trust. the majority of trust scales have been developed for the context of interpersonal trust. we focus on scales designed for use in the assessment of human trust in automation. a synopsis of representative trust scales is presented in appendix d.  minimally, a trust scale can ask two questions: do you trust the machine's outputs? (trust) and would you follow the machine's advice? (reliance). indeed, these two items comprise the scale developed by adams, et al. (2003). the scale developed by johnson (2007) asks only about reliance and the rareness of errors.   some scales for assessing trust in automation are highly specific to particular application contexts. for example, the scale developed by schaefer (2013) refers specifically to the context of human reliance on a robot, and thus asks does it act as part of a team? and is it friendly? as another example, the trust in automation scale developed by adams, et al. (2003) refers specifically to the evaluation of simulations. it asks only two questions, one about trust (do you trust it?) and one about reliance (are you prepared to rely on it?), although it is noteworthy that this is the only scale that has a free response option associated with the two scale item questions.  to be sure, some research on trust in automation is clearly inapplicable to the xai context.  for example, heerink, et al. (2010) were interested in the acceptance of an assistive/robotic technology by the elderly. the questionnaire they utilized has such items as i feel the robot is nice, and the robot seems to have real feelings.  \",\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t21\\tmontague (2010) presented a study aimed at validating a scale for trust in medical diagnostic instruments, but all of the items actually refer to trust in the health care provider and positive affect about the provider. abstracting from that reference context, the other items ask about reliability, correctness, precision, and trust. thus, we see essential similarity to the items in the cahour-fourzy scale.  some scales for assessing trust in automation are highly specific to particular experimental contexts. hence, the items are not applicable to the xai context, or to any generic trust-in-automation context. for example, the scale by dzindolet, et al. (2003) was created for application in the study of trust in a system for evaluating terrain in aerial photographs, showing  images in which there might be camouflaged soldiers. thus, the hypothetical technology was referred to as a \"contrast detector.\" the experiment was one in which the error rate of the hypothetical detector was a primary independent variable. as a consequence, the scale items refer to trials e.g., how well do you think you will perform during the 200 trials? (not very well-very well), and how many errors do you think you will make during the 200 trials? some of the scale items can be adapted to make them appropriate to the xai context, but the result of this modification is just a few items, which are ones that are already in the cahour-fourzy scale (e.g., can you trust the decisions the [system] will make?)  of those scales that have been subject to psychometric analysis of reliability, results suggest that trust in automation scales can be reliable. of those scales that have been subject to validity analysis, high cronbach alpha results have been obtained. the report by jian, et al. (2000) illustrates these psychometric analyses.   5.4 recommendations  looking across the various scales (see appendix d), there is considerable overlap, and cross-use of the scale items. we have distilled a set of items that might be used in xai research. this is presented in appendix e. most of the items are from the cahour-fourzy scale (some of which are also in the jian et al. scale), but the recommended scale incorporates items from other scales.   none of the scales that have been reviewed treat trust as a process; they treat it as a static quality  or target state, that is measured after the research participants have completed their experimental tasks. in contrast, it is recommended for the xai program that trust measurement be a repeat measure. the scale or selected scale items can be applied after individual trials (e.g., after individual xai categorizations or recommendations; after individual explanations are provided, etc.). the full scale could be completed part way through a series of experimental trials, and at the conclusion of the final experimental trial. multiple measures taken over time could be integrated for overall evaluations of human–machine performance, but episodic measures would be valuable in tracking such things as: how do users maintain trust? what is the trend for desirable movement toward appropriate trust?   \\t\\t',\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t22\\t6 measuring performance  the goal of performance measurement is to determine the degree of success of the human-machine system at effectively conducting the tasks for which the technology is designed. based on the conceptual model in figure 1, the key hypotheses are:  • user performance (including measures of joint user-system performance) will improve as a result of being given satisfying explanations.\\t• user performance will be a function of the qualities of their mental model (e.g., correctness, completeness, etc.) • user performance may be affected by their level of epistemic trust • user performance (that is, reliance) will be appropriate if the user has been able to explore the competence envelop of the ai system.  the evaluation of the performance of an xai system cannot be neatly divorced from the evaluation of the performance of the user, or from the performance of the human-machine system as a whole.    6.1 performance with regard to the primary task goals  the ai system will have some primary task goal. this might be to correctly categorize images, correctly identify certain kinds of actions in videos, or conduct an emergency rescue operation.  performance can be measured in terms of the number of trials on which the user met with success, within some pre-specified time period.  in a search-and-rescue use case, work system performance might be measured in terms of the number of trials that a user has to work in order to reach some pre-determined criterion. basic measures of efficiency can be applied, expressing the ratio of the number of tasks or sub-tasks completed per some period of time.    6.2 performance with regard to the user  a second aspect of performance measurement is the quality of the performance of the user, such as the correctness of the user's predictions of what the ai will do. for these aspects of performance, just like performance with regard to primary ask goals, one can measure response speed and correctness (hits, errors, misses, false alarms), but in this case the user's predictions of the machine outputs. examination can be made for both typical and atypical cases/situations. additionally, one can measure the correctness and completeness of the user's explanation of the machine’s output for cases that are rare, unusual, or anomalous.        \",\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t23\\t6.3  performance with regard to the work system \\t with regard to performance at the work system level, considerations other than raw efficiency come into play (hoffman & hancock, 2017; koopman & hoffman, 2003). for example, an xai system that drives the work efficiency (say, to deal with data overload issues) may not make for a very contented workplace (merritt, 2011). the complexity of performance at the work system level requires analysis based on trade-off functions (woods & hollnagel, 2006).  work system level performance would be reflected when scores on a measure of explanation satisfaction correlate highly with evaluations of the goodness of the users' mental models or with scores on some other performance measure.    at the work system level, appropriate trust and reliance emerge from the user's experience, especially as the user encounters tough cases or cases that fall at the boundary of the work system's competence envelope. appropriateness refers to the fact that mistrust, as well as trust, can be justified. presumably, appropriate reliance (knowing when and when not to rely on the system’s outputs) hinges on appropriate trust.   the analysis of work system level performance may employ some measure of controlability, that is, the extent to which the human can produce an intended set of outcomes based on given inputs or conditions. analysis may employ some measure of correctability. this is a measure of the extent or ease with which the user can correct the machine’s activities so as to make the machine outputs better aligned with either objective states of affairs or the user's judgments of what the machine should be determining.  the analysis of work system level performance can involve comparing the work productivity of the xai-user work system to productivity in current practice (baseline). a related method is to look at learning curves. this involves establishing a metric on a productivity scale, a metric that identifies when performance is satisfactory. how many trials of test cases must a user work successfully in order to reach that learning criterion? is the learning rapid?  why do some people take a long time to reach criterion? the advantage of a trials-to-criterion approach to measurement is that it could put the different xai systems on a “level playing field” by making the primary measure a derivative of task completion time. a variation on this method is to compare performance in this way with performance when the explanation capability of the xai is somehow hobbled.  perhaps the most powerful and direct way of evaluating the performance of a work system that includes an xai is to evaluate how easy or difficult it is to get prospective users (stakeholders) to adopt the xai system. in discussing early medical diagnosis systems, van lent et al (2004) stated, “early on the developers of these systems realized that doctors weren’t willing to accept the expert system’s diagnosis on faith” (p. 904), which led to development of the first explanation-based ai systems.  many users may be satisfied with shallow explanations in that they will be willing to adopt the system that has “xai” or may prefer it over another non-xai system when making adoption decisions. measures of choice behavior were also advocated by adams et al. (2003) as a way of measuring human trust in automation.\\t \",\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t24\\t7. prospects  measurement is the foundation of empirical inquiry. as a form of exploration, one of the purposes of making measurements is to improve the measures.  we do not regard the ideas and methods discussed in this paper as being final.   it was from our own empirical inquiry that emerged our distinction between explanation goodness as an a priori evaluation by researchers versus explanation satisfaction as an a posteriori evaluation by learners.  we look forward to refinements and extensions of all the ideas presented in this article.  also foundational to empirical inquiry is a theoretical foundation. the one on which we have relied is the conceptual model presented in figure 1 (above), which references measures of explanations, user models, and performance. other measurable theoretical concepts might be of value for xai research and development. as our discussion suggests, we advocate for a multi-method approach. such an approach seems mandated by the fact that the human-xai interaction is a complex cognitive system.  an important measurement topic that we have not addressed is that of \"metrics.\" in modern discourse, the word \"metric\" often carries a dual meaning. one is \"measure\" or \"measurement.\"  the other is the notion of some sort of threshold on a measurement scale that is used to make evaluations or decisions. in this article we have discussed measurement, not metrics. a simple example of the measure-metric distinction might clarify this. if a surgeon specializing in carpal tunnel syndrome has a success rate less than 90 percent, he or she might well be in trouble. on the other hand, a specialist in spinal surgery with a 90% success rate would be considered  a miracle worker. the measurement scale in both contexts is surgery success rate. the metric that is laid on that scale depends on the application context (for a fuller discussion, see hoffman, 2010).  certainly xai research needs metrics to accompany its measures. is performance superior, acceptable, or poor? is a mental model rich or impoverished? but metrics for these sorts of decisions do not emerge directly or easily from theoretical concepts being measured, or the operationalzed measures that are being used. the operational definition of a measure tells you how to make measurements, not how to interpret them.  metrics come from policy.  resolution of this metrics challenge may emerge as more xai projects are carried through all the way to performance evaluation.      ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t25\\t8. references  adams, b.d., bruyn, l.e.,  & houde, s. (2003). trust in automated systems. report, ministry of national defence, united kingdom.\\talang, n. (2017, august 31). turns out algorithms are racist. the new republic. retrieved from https://newrepublic.com/article/144644/turns-algorithms-racist?utm_content=buffer7f3ea anderson, j., boyle, c.f., corbett, a.t., and lewis, m.w. (1990). cognitive modeling and intelligent tutoring. in w. j. clancey and e. soloway (eds.) artificial intelligence and learning environments (pp. 7–49). cambridge, ma: bradford books.  ayre, c., & scally, a.j. (2014).  critical values for lawshe’s content validity ratio: revisiting the original methods of calculation. measurement and evaluation in counseling and development, 47, 79-86. bainbridge, l. (1979). verbal reports as evidence of process operator’s knowledge. international journal of man-machine studies, 11, 411-436. bainbridge, l. (1988). types of representation. in i.p. goodstein, h.b. andersen, and s.e. olsen, (eds.) tasks, errors and mental models (pp. 70-91). new york: taylor and francis. beach, l. r. (1992). epistemic strategies on causal thinking in expert and nonexpert judgment. in g. wright & f. bolger (eds.), expertise and decision support (pp. 107-127). new york: plenum. berlyne, d.e. (1960). conflict, arousal, and curiosity. new york: mcgraw-hill. berlyne, d.e. (1978). curiosity and learning. motivation and emotion, 2, 97-175. berry, d. c., and broadbent, d. e. (1988). interactive tasks and the implicit-explicit distinction. british journal of psychology, 79, 251–272. biran, o., & cotton, c. (2017). explanation and justification in machine learning: a survey. ijcai-17 workshop on explainable artificial intelligence (xai). http://home.earthlink.net/~dwaha/research/meetings/ijcai17xai/1.%20(biran%20&%20cotton%20xai-17)%20explanation%20and%20justification%20in%20ml%20-%20a%20survey.pdf bjork, r.a., dunlosky, j., & kornell, n. (2013). self-regulated learning: beliefs, techniques, and illusions. annual review of psychology, 64, 417–444. bogacz, s. and trafton, j.g. (2004). understanding dynamic and static displays: using images to reason dynamically. cognitive systems research, 6, 312-319. bornstein, a.m. (2016, september 1). is artificial intelligence permanently inscrutable? retrieved august 29, 2017, from http://nautil.us/issue/40/learning/is-artificial-intelligence-permanently-inscrutable byrne, r.m. (2017). counterfactual thinking: from logic to morality. current directions in psychological science, 26(4), 314–322. cacioppo, j. t., petty, r. e., & kao, c. f. (1984). the efficient assessment of need for cognition. journal of personality assessment, 48(3), 306-307. ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t26\\tcahour, b., and forzy, j. f. (2009). does projection into use improve trust and exploration? an example with a cruise control system. safety science, 47, 1260-1270. calin-jageman, r. j., & ratner, h. h. (2005). the role of encoding in the self-explanation effect. cognition and instruction, 23, 523-543. cañas, a.j., coffey, j.w., carnot, m.j., feltovich, p., hoffman, r., feltovich, j. and novak, j.d. (2003). a summary of literature pertaining to the use of concept mapping techniques and technologies for education and performance support. report to the chief of naval education and training, prepared by the institute for human and machine cognition, pensacola,  fl. carberry, s. (1990). second international workshop on user modeling. the ai magazine, 11 (5) 57-60. carley, k, and palmquist, m. (1992). extracting, representing and analyzing mental models.  social forces, 70 (3), 601-636 carroll, j.m. (1984). minimalist training. datamation, 1, 125-126. champlin, c., bell, d., & schocken, c. (2017). ai medicine comes to africa’s rural clinics. ieee spectrum, 54(5), 42–48. chancey, e.t., bliss, j.p., proaps, a.b., and madhavan, p. (2015). the role of trust as a mediator between system  characteristics and response behaviors. human  factors, 57, 947–958. chi, m. t. h, feltovich, p. j., and glaser, r. (1981). categorization and representation of physics problems by experts and novices. cognitive science, 5, 121–152. chi, m. t., bassok, m., lewis, m. w., reimann, p., & glaser, r. (1989). self-explanations: how students study and use examples in learning to solve problems. cognitive science, 13(2), 145–182. chi, m.t., leeuw, n., chiu, m.-h., & lavancher, c. (1994). eliciting self-explanations improves understanding. cognitive science, 18(3), 439–477. chi, m.t., & van lehn, k.a. (1991). the content of physics self-explanations. the journal of the learning sciences, 1(1), 69–105. clancey, w.j. (1984). methodology for building an intelligent tutoring system. in kintsch, w., miller, j. r., and polson, p. g. (eds.), method and tactics in cognitive science (pp. 51–83). hillsdale, nj: lawrence erlbaum associates. clancey, w.j. (1986). from guidon to neomycin and heracles in twenty short lessons. ai magazine, 7(3), 40-60. clement, j. (2004). imagistic simulation and physical intuition in expert problem solving. in proceedings of the sixteenth annual conference of the cognitive science society (pp. 201-205). hillsdale, nj: lawrence erlbaum. comrey, a. l. (1988). factor-analytic methods of scale development in personality and clinical psychology. journal of consulting and clinical psychology, 56, 754-761. cortina, j. m. (1993). what is coefficient alpha? an examination of theory and applications. journal of applied psychology, 78, 98-104. ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t27\\tdavis ll. (1992). instrument review: getting the most from a panel of experts. applied nursing research, 5(4),194-7.   de kleer, j., and brown, j.s. (1983). assumptions and ambiguities in mechanistic mental models. in d. gentner and a.l. stevens (eds.) mental models (pp. 155-190). new york: psychology press.  de kleer, j., doyle, j., steele, g.l., and sussman, g.j. (1977). artificial intelligence: an mit perspective. cambridge, ma: mit press.  doyle j.k., ford d.n,. radzicki, m.j., & trees, w.s. (2002). mental models of dynamic systems. in system dynamics and integrated modeling, encyclopedia of life support systems, barlas y(ed.). eolss publishers: oxford. dzindolet, m.t., peterson, s.a., pomranky, r.a., pierce, l.g., and beck, h.p. (2003). the role of trust in automation reliance. international journal of human–computer studies, 58, 697–718. ericcson, k. a., & simon, h. a. (1984). protocol analysis: verbal reports as data. cambridge, ma: mit press. evans, a. w., jentsch, f., hitt, j.m., bowers, c, & salas, e. (2001). mental model assessments: is there convergence among different methods? in proceedings of the human factors and ergonomics society 45th annual meeting (pp. 293-298). santa monica, ca: human factors and ergonomics society.  felten, e. (2017). what does it mean to ask for an “explainable” algorithm? retrieved august 29, 2017, from https://freedom-to-tinker.com/2017/05/31/what-does-it-mean-to-ask-for-an-explainable-algorithm/ feltovich, p. j., coulson, r. l., and spiro, r. j. (2001). learners’(mis) understanding of important and difficult concepts: a challenge to smart machines in education. in k.d. forbus and p.jk. feltovich (eds.), smart machines in education (pp. 349–375). menlo park, ca: aaai/mit press. fernbach, p. m., sloman, s. a., louis, r. s., and shube, j. n. (2012). explanation fiends and foes: how mechanistic detail determines understanding and preference. journal of consumer research, 39(5), 1115–1131. fitzhugh,  e.w.,  hoffman,  r.r.,  and  miller,  j.e.  (2011).  active  trust  management.  in n. stanton (ed.) trust in military teams (pp. 197–218). london: ashgate. forbus, k. d., & feltovich, p. j. (eds.) (2001). smart machines in education. menlo park, ca: aaai/mit press. ford, k.m., cañas, a.j., and coffey, j. (1993). participatory explanation. presented at the flairs 93: sixth florida artificial intelligence research symposium (flairs) (pp. 111–115), pensacola, fl: institute for human and machine cognition. frederick, s. (2005). cognitive reflection and decision making. journal of economic perspectives, 19, 25-42. friedman, s., forbus, k.,  & sherin, b. (2017). representing, running and revising mental models: a computational theory.  cognitive science, 1-36 [https://doi.org/10.111/cogs.12574]. ',\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t28\\tfryer, d. (1939). post quantification of introspective data. american journal of psychology, 52, 367-371. gentner, d. and gentner, d.r. (1983). flowing waters or teem crowds: mental models of electricity. in d. gentner and a.l. stevens (eds.) mental models (pp. 99-129). new york: psychology press. gentner, d. & stevens, a.l. (1983). mental models. new york: psychology press. gilbert, g.e., & prion, s. (2016). making sense of measurement: lawshe's content validity index. clinical simulation in nursing, 12, 530-531. glenberg, a.m., & langston, w.e. (1992). comprehension of illustrated text: pictures help to build mental models.  journal of memory and language, 31, 129-151. goodman, b., & flaxman, s. (2016). european union regulations on algorithmic decision-making and a “right to explanation.” presented at the icml workshop on human interpretability in machine learning, new york, ny. goodstein, i.p., andersen, h.b. and olsen, s. e. (eds.) (1988). tasks, errors and mental models. new york: taylor and francis. greeno, j.g. (1983). conceptual entities. in d. gentner and a.l. stevens (eds.) mental models (pp. 227-252). new york: psychology press. hardiman, p.t., dufresne, r., & mestre, j.p. (1989). the relation between problem categorization and problem solving among experts and novices. memory and cognition, 17, 627-638. harford, t. (2014, march 28). big data: are we making a big mistake? the financial times. harris, s.d., and helander, m.g. (1984). machine intelligence in real systems: some ergonomic issues.  in g. salvendy (ed.), human-computer interaction (pp. 267-277). amsterdam: elsevier science publishers. hawkins, j. (2017). can we copy the brain? what intelligent machines need to learn from the neocortex. ieee spectrum, 54(6), 34–71. heerink, m., kröse, b., evers, v., and wielinga, b. (2010). assessing acceptance of assistive social agent technology by older adults: the almere model. international journal of social robotics, 2(4), 361-375. hilton, d.j. (1996). mental models and causal explanation: judgements of probable cause and explanatory relevance thinking and reasoning, 2(4), 273-308. hilton, d.j., & erb, h.-p. (1996). mental models and causal explanation: judgements of probable cause and explanatory relevance. thinking and reasoning, 2(4), 273–308.  heiser, j., & tversky, b. (2006). arrows comprehending and producing mechanical diagrams, cognitive science, 30, 581-592. hoff, k.a., and bashir, m. (2015). trust in automation: integrating empirical evidence on factors that inﬂuence trust. human factors, 57, 407–434. \",\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t29\\thoffman, r.r. (2017). a taxonomy of emergent trusting in the human–machine relationship. in p. j. smith and r.r. hoffman (eds.), cognitive systems engineering: the future for a changing world (pp. 137-163). boca raton, fl: taylor and francis. hoffman, r. r. (2010). theory → concepts → measures but policies → metrics. in e. patterson and j. miller  (eds.), macrocognition metrics and scenarios: design and evaluation for real-world teams (pp. 3-10). london: ashgate. hoffman, r.r. (1989). whom (or what) do you trust: historical reﬂections on the psychology and sociology of information technology. in proceedings of the fourth annual symposium on human interaction with complex systems (pp. 28–36). new york: ieee computer society. hoffman, r.r., coffey, j.w., ford, k.m. and carnot, m.j. (2001, october) storm-lk: a human-centered knowledge model for weather forecasting. in j.m. flach (ed.), proceedings of the 45th annual meeting of the human factors and ergonomics society (p. 752). santa monica, ca: human factors and ergonomics society. hoffman, r.r., and hancock, p.a. (2017). measuring resilience. human factors, 59, 564-581. hoffman, r.r., johnson, m., bradshaw, j.m., and underbrink, a. (2013, january/february). trust in automation. ieee: intelligent systems, 84–88. hoffman, r.r., klein, g., & mueller, s.t. (2018). literature review and integration of key ideas for explainable ai. report to the darpa xai program. hoffman, r.r., lee, j.d., woods, d.d., shadbolt, n., miller, j. and bradshaw, j.m. (2009, november/december). the dynamics of trust in cyberdomains. ieee intelligent systems, 5–11. huynh, t.d., jennings, n.r., and shadbolt, n.r. (2006). an integrated trust and reputation model for open multi-agent systems. autonomous agents and multi-agent systems, 13, 119–154. jian, j. y., bisantz, a. m., and drury, c. g. (2000). foundations for an empirically determined scale of trust in automated systems. international journal of cognitive ergonomics, 4(1), 53-71. johnson, d.s. (2007). achieving customer value from electronic channels through identity commitment, calculative commitment, and trust in technology. journal of interactive marketing, 21(4), 2-22. johnson-laird, p. n. (1980). mental models in cognitive science. cognitive science, 4, 71-115. johnson-laird, p. n. (1983). mental models: towards a cognitive science of language, inference, and consciousness. cambridge, ma: harvard university press. johnson-laird, p.n. (1989). mental models. in m.i. posner (ed.), foundations of cognitive science (pp. 469-499). cambridge, ma: mit press. kashdan, t.b., rose, p., & fincham, f.d. (2004). curiosity and exploration: facilitating positive subjective experiences and personal growth opportunities. journal of personality assessment, 82, 291-305. kintsch, w., miller, j. r., and polson, p. g. (eds.) (1984). methods and tactics in cognitive science. hillsdale, nj: lawrence erlbaum associates. klein, g., and borders, j. (2016). the shadowbox approach to cognitive skills training: an empirical evaluation.  journal of cognitive engineering and decision making, 10, 268-280. ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t30\\tklein, g. and hoffman, r.r. (2008). macrocognition, mental models, and cognitive task analysis methodology. in j.m. schraagen, l.g.  millitello, t. ormerod and r. lipshitz (eds.), naturalistic decision making and macrocognition  (pp. 57-80). aldershot, england: ashgate. klein, g., & milltello, l.g. (2001). some guidelines for conducting a cognitive task analysis. in e. sales (ed.), human/technology interaction in complex systems, vol 1 (pp. 161-197). oxford: elsevier science ltd. koehler, d. (1991). explanation, imagination , and confidence in judgement. psychological bulletin, 110(3), 499–519. koopman, p., and hoffman, r.r. (november/december 2003). work-arounds, make-work, and kludges. ieee: intelligent systems, 70–75. kuang, c. (2017, 21 november). can a.i. be taught to explain itself? the new york times. retrieved from https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html kucala, d. (2013, june). the truthiness of trustworthiness. chief learning ofﬁcer, 57–59. lawshe, c. h. (1975). a quantitative approach to content validity. personnel psychology, 28, 563–575. lee, j.d., and see, k.a. (2004). trust in automation: designing for appropriate reliance. human factors, 46, 50–80. lesgold, a. m., lajoie, s. p., bunzo, m., and eggan, g. (1992). sherlock: a coached practice environment for an electronics troubleshooting job. in j. larkin and r. chabay (eds.), computer assisted instruction and intelligent tutoring systems: shared issues and complementary approaches (pp. 201-238). hillsdale, nj: lawrence erlbaum associates. lippa, k., klein, h.a. & shalin, v.l. (2008). everyday expertise: cognitive demands in diabetes self-management. human factors, 50, 112-120. litman, j.a. & lunsford, g.d. (2010). incurious motives to seek information about potential threats. european journal of personality, 24, 1–17. litman, j.a., & jimerson, t.l. (2004). the measurement of curiosity as a feeling-of-deprivation. journal of personality assessment, 82, 147-157. loewenstein, g. (1994). the psychology of curiosity: a review and reinterpretation. psychological bulletin, 116, 75-98.  lombrozo, t. (2016). explanatory preferences shape learning and inference. trends in cognitive sciences, 20(10), 748–759.  lombrozo, t., & carey, s. (2006). functional explanation and the function of explanation. cognition, 99, 167–204. https://doi.org/10.1016/j.cognition.2004.12.009 lynn m.r. (1986). determination and quantification of content validity. nursing research, 35 (6), 382-385. madhavan, p., and wiegmann, d.a. (2007). effects of information source, pedigree, and reliability on operator interaction with decision support systems. human factors, 49, 773–785. ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t31\\tmaheswaran, d., and chaiken, s. (1991). promoting systematic processing in low-motivation settings: effect of incongruent information on processing and judgment. journal of personality and social psychology, 61,13-25. may, j., barnard, p.j., and blandford, a. (1993). using structural descriptions of interfaces to automate the modeling of user cognition. user modeling and user-adapted interaction, 3, 27-64. mckeown, k.r., & swartout, w. r. (1987). language generation and explanation. annual review of computer science, 2(1), 401–449. merritt, s. m. (2011). affective processes in human–automation interactions. human factors:, 53(4), 356-370. merritt, s.m., heimbaugh, h., lachapell, j., and lee, d. (2013). i trust it, but don’t know why: effects of implicit attitudes toward automation in trust in an automated system. human factors, 55, 520–534. merritt, s.m., and ilgen, d.r. (2008). not all trust is created equal: dispositional and history-based trust in human–automation interactions. human factors, 50, 194–201. merritt, s.m., lee, d., unnerstall, j.l., and huber, k. (2015). are well-calibrated users effective users? associations between calibration of trust and performance on an automation- aided task. human factors, 57, 34–47. miller, t. (2017). explanation in artificial intelligence: insights from the social sciences. arxiv:1706.07269 [cs]. retrieved from http://arxiv.org/abs/1706.07269 mills, c. m., & keil, f. c. (2004). knowing the limits of one’s understanding: the development of an awareness of an illusion of explanatory depth. journal of experimental child psychology, 87(1), 1–32. mitchell, d., russo, e., & rennington, n. (1989). back to the future: temporal perspective in the explanation of events. journal of behavioral decision making, 2, 25–38.  molinaro, r.i., and garcia-madruga, j.a. (2011). knowledge and question asking. psicothema, 23, 26-30. montague, e. (2010). validation of a trust in medical technology instrument. applied ergonomics, 41(6), 812-821. moon, b.m., hoffman, r.r., cañas, a.j., and novak, j.d. (eds.) (2011). applied concept mapping: capturing, analyzing and organizing knowledge. boca raton, fl: taylor and francis. moore, j. d., & swartout, w. r. (1990). pointing: a way toward explanation dialogue. in proceedings of aaai, 90, 457–464. menlo park, ca: aaai. moray, n. (1987). intelligent aids, mental models, and the theory of machines. international journal of man-machine studies, 7, 619-629. mueller, s.t. and klein, g. (2011, march/april). improving users’ mental models of intelligent software tools. ieee intelligent systems, 77–83. ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t32\\tmuir, b.m. (1987). trust between humans and machines, and the design of decision aids. international journal of man–machine studies, 27, 527–539. muir, b.m. (1994). trust in automation part 1: theoretical issues in the study of trust and human intervention in automated systems. ergonomics, 37, 1905–1922. muir, b.m. and moray, n. (1996). trust in automation. part ii experimental studies of trust and human intervention in a process control simulation. ergonomics, 39, 429–460. muramatsu, j., and pratt, w. (2001). transparent queries: investigation users’ mental models of search engines. in proceedings of the 24th annual international acm sigir conference on research and development in information retrieval (pp. 217–224). new york: association for computing machinery.  naone, e. (4 september 2009). adding trust to wikipedia, and beyond. technology review [http://www.technologyreview.com/web/23355/?a=f]. novak, j. d., and d. b. gowin. (1984). learning how to learn. cambridge: cambridge university press. o’reilly, t., symons, s., & maclatchy-gaudet, h. (1998). a comparison of self-explanation and elaborative interrogation. contemporary educational psychology, 23(4), 434–445. pavlus, j. (2017, september 6). stop pretending you really know what ai is and read this instead. retrieved from https://qz.com/1067123/stop-pretending-you-really-know-what-ai-is-and-read-this-instead/ pinker, s. (2017). uncommon insights into common knowledge. in aps observer, 30. https://www.psychologicalscience.org/observer/uncommon-insights-into-common-knowledge polson, m.c., & richardson, j.j. (eds.). (1988). foundations of intelligent tutoring systems. hillsdale, nj: erlbaum. pop, v.l., shrewsbury, a., and durso, f.t. (2015). individual differences in the calibration of trust in automation. human factors, 57, 545–556. praetorious, n., and duncan, k.d. (1988). verbal reports: a problem in research design. in i.p. goodstein, h.b. andersen, and s.e. olsen, (eds.) tasks, errors and mental models (pp, 293- 324). new york: taylor and francis. prietula, m., feltovich, p., & marchak, f. (2000). factors influencing analysis of complex cognitive tasks: a framework and example from industrial process control. human factors, 42(1), 54–74.  psotka, j., massey, l.d., & mutter, s.a. (1988). intelligent tutoring systems: lessons learned. hillsdale, nj: erlbaum.  qin, y., and simon, h.a. (1992). imagery as a process representation in problem solving.  in proceedings of the fourteenth annual conference of the cognitive science society (pp. 1050-1055).  hillsdale, nj: lawrence erlbaum. rasmussen, j. (1986). information processing and human-machine interaction. amsterdam, north-holland. ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t33\\trasmussen, j., pejtersen, a.m., and goodstein, l.p. (1994). cognitive systems engineering. new york: john wiley. riley, v. (1996). operator reliance on automation: theory and data. in r. parasuraman and m. mouloua (eds.), automation theory and applications (pp. 19–35). mahwah, nj: erlbaum. ritter, f., & feurzeig, w. (1988). teaching real-time tactical thinking. intelligent tutoring systems: lessons learned, 285–301. rittle-johnson, b. (2006). promoting transfer: effects of self-explanation and direct instruction. child development, 77(1), 1–15. rosenblit, l. & kein, f. (2002). the misunderstood limits of folk science: an ilklusion of explanatory depth. cognitive science, 26, 521-562. rungtusanatham, m. (1998, july). let’s not overlook content validity. decision line, pp. 10-13.\\tsamurcay, r., and hoc, j.-m. (1996). causal versus topographical support for diagnosis in a dynamic situation.  le travail humain, 59, 45-68. sarter, n., woods, d.d., and billings, c.e. (1997). automation surprises. in g. salvendy (ed.), handbook of human factors/ergonomics, 2nd ed. (pp. 1926–1943). new york, ny: wiley. schaefer, k. e. (2013). the perception and measurement of human-robot trust. doctoral dissertation, university of central florida orlando, florida. schaffernicht, m., and groesser, s.n. (2011). a comprehensive method for comparing mental models of dynamical systems. european journal of operational research, 210, 57-67.  schwiep, j. (2017, may 3). the state of explainable ai. [https://medium.com/@jschwiep/the-state-of-explainable-ai-e252207dc46b] shadbolt, n. (january/february, 2002). a matter of trust. ieee intelligent systems, 2–3.  sleeman, d., & brown, j. s. (1982). intelligent tutoring systems. london: academic press.  st.-cyr, o., and burns, c.m. (2002). mental models and ecological interface design: an experimental investigation. in proceedings of the human factors and ergonomic society annual meeting (pp. 270-274). santa monica, ca: human factors and ergonomics society. staggers, n., and norcio, a.f. (1993). mental models: concepts for human-computer interaction research. international journal of man-machine studies, 38, 587-605. streiner, d. l. (2003). starting at the beginning: an introduction to coefficient alpha and internal consistency. journal of personality assessment, 80(1), 99-103. taylor, j.r. (1988). using cognitive models to make plants safer: experimental and practical approaches. in i.p. goodstein, h.b. andersen, and s.e. olsen, (eds.) tasks, errors and mental models (pp. 233-239). new york: taylor and francis. tullio, j., dey, a. k., chalecki, j., and fogarty, j. (2007). how it works: a field study of non-technical users interacting with an intelligent system. in proceedings of the sigchi conference on human factors in computing systems (pp. 31–40). new york: association for computing machinery. retrieved from http://dl.acm.org/citation.cfm?id=1240630 ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t34\\tvan der veer, g.c., melguzio, m. (2003). mental models.  in j.a. jacko & a. sears (edfs.), the human-computer interaction handbook (pp. 52-80). hillsdale, nj: lawrence erlbaum. van lehn, k., ball, w., & kowalski, b. (1990). explanation-based learning of correctness: towards a model of the self-explanation effect. report, department of psychology, carnegie mellon university. retrieved from  van lent, m., fisher, w., & mancuso, m. (2004). an explainable artificial intelligence system for small-unit tactical behavior. in proceedings of the 19th national conference on artificial intelligence (pp. 900–907). menlo park, ca: aaai press. voosen, p. (2017). how ai detectives are cracking open the black box of deep learning. science, 357 (no. 6346), 22–27. ward, p. wilson, k, suss, j., woody, w.d., and hoffman, r.r. (in press). an historical perspective on introspection: implications and guidelines fort eliciting verbal and introspective-type reports. to appear in p. ward, j.m. schraagen, t.c. ormerod, and e. roth, (eds), the oxford handbook of expertise. oxford: oxford university press.  weinberger, d. (2017, april 18). our machines now have knowledge we’ll never understand. retrieved from https://www.wired.com/story/our-machines-now-have-knowledge-well-never-understand/ wickens, c.d., clegg, b.a., vieane, a.z., and sebok, a.l. (2015). complacency and automation bias in the use of imperfect automation. human factors, 57, 728–739. williams, m.d., hollan, j.d., and stevens, a.l (1983). human reasoning about a simple physical system. in d. gentner and a.l. stevens (eds.) mental models (pp. 131-154). new york: psychology press. woods, d.d. (2011, september). reﬂections on 30 years of picking up the pieces after explo- sions of technology. presentation at the afrl autonomy workshop, air force research laboratory, wright-patterson air force base, oh. woods, d.d., and hollnagel, e. (2006). joint cognitive systems: patterns in cognitive systems engineering. boca raton, fl: crc press. young, r.m. (1983). surrogates and mappings: two kinds of conceptual models of interactive devices. in d. gentner and a.l. stevens (eds.) mental models (pp. 35-52). new york: psychology press. zhang, kl, & wickens, c.d. (1987). a study of the mental model of a complex dynamic system: the effect of display aiding and contextual system training. in proceedings of the human factors and ergonomics society 31st annual meeting (pp. 102-107). santa monica, ca: human factors and ergonomics society.  \\t ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t35\\tappendix a\\t explanation goodness checklist\\t  this checklist is a list of the features that make explanations good, according to the research literature.  the reference is to the properties of explanations. \\t the intended use context is for researchers or domain experts to provide an independent, a priori evaluation of the goodness of explanations that are generated by other researchers or by xai systems.\\t ---------------------------------------------------------------------------------------\\t the explanation helps me understand how the [software, algorithm, tool] works.  yes\\t no\\t  the explanation of how the [software, algorithm, tool] works is  satisfying.\\t yes\\t no\\t  the explanation of the [software, algorithm, tool] sufficiently detailed. \\t yes\\t no\\t  the explanation of how the [software, algorithm, tool] works is sufficiently complete.\\t yes\\t no\\t  the explanation is actionable, that is, it helps me know how to use the [software, algorithm, tool]\\t yes\\t no\\t  the explanation lets me know how accurate or reliable the [software, algorithm] is.\\t yes\\t no\\t  the explanation lets me know how trustworthy the [software, algorithm, tool] is.\\t yes\\t no\\t  ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t36\\tappendix b\\t materials used in the evaluation of  the discriminant validity \\tof the explanation satisfaction scale\\t  how do cell phones provide directions?  explanation judged a priori to be  relatively \"good\"  cell phones use the global positioning system of satellites to determine the exact location of the phone.   a web-based service (such as google maps, apple maps, etc.) identifies the phone\\'s coordinates along with the desired destination entered by the phone user.   this information is transmitted to a computer, where the map service calculates the best route based on shortest path, but also traffic and other variables.    the instructions are then sent back to the phone.   the map service monitors the phone\\'s location in real-time, and each step is given to the user based on the phone’s proximity to the next step (or checkpoint).   explanation judged a priori to be  relatively \"bad\"  cell phones can provide good directions because they have really accurate maps on them.    the phone downloads the maps from the internet.  the phone knows where it is and it calculates the shortest route.   it tries to give step-by-step directions.     \\t ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t37\\thow does automobile cruise control work?  explanation judged a priori to be  relatively \"good\"  the speed of the car at the moment you turn on the cruise control is stored in a memory circuit.  the cruise control device reads the car’s speed by a speed sensor that is on the car’s drive shaft.  the cruise control is linked to the engine accelerator, and accelerates the car when it falls below the speed you set, such as when you start to go uphill, for example.  it can stop accelerating the car when the car is going downhill, but does not apply the brakes to decelerate the car.  the cruise control also senses when the brake pedal has been depressed, and disengages from the accelerator.  explanation judged a priori to be  relatively \"bad\" the vacuum control unit reads the pulse frequency from a magnet mounted on the drive shaft to figure out how fast the car is going. a bidirectional screw-drive electric motor that is connected to the accelerator linkage receives the control signal and transmits it to the throttle. when you set the cruise control, the engine detects the engine rpm at that point and tries to maintain that engine speed until it is disengaged. the cruise control detects the car gear, which it adjusts to allow the engine to maintain a constant rpm.   \\t ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t38\\thow do computers predict hurricanes?  explanation judged a priori to be  relatively \"good\"  computers have a mathematical model of the atmosphere that divides the world into many small regions, each just a few square kilometers.  each region is defined in terms of its air pressure, temperature, winds, and moisture.  the computer calculates what will happen at the boundaries of each region. for example, strong winds in one region will move air into an adjacent region.   these calculations must be performed for every boundary between all the regions. this allows the prediction of the path a hurricane will take.   explanation judged a priori to be  relatively \"bad\"  the computers have a database of all previous hurricanes and the paths that they followed.  once a hurricane is located, using a satellite image, the computer accesses the database and determines the path that was most frequently taken by hurricanes having that initial location.  this process is repeated once every hour, tracking the hurricane as it moves.  the computers can also tell when the winds and rain will impact the land, and that is when the hurricane warnings are issued.   \\t ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t39\\tappendix c  explanation satisfaction scale   1. from the explanation, i understand how the [software, algorithm, tool] works.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   2.  this explanation of how the [software, algorithm, tool] works is satisfying.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   3. this explanation of how the [software, algorithm, tool] works has sufficient detail.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   4. this explanation of how the [software, algorithm, tool] works seems complete.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   5. this explanation of how the [software, algorithm, tool] works tells me how to use it.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   6. this explanation of how the [software, algorithm, tool] works is useful to my goals.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly  ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t40\\t 7. this explanation of the [software, algorithm, tool] shows me how accurate the [software, algorithm, tool] is.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   8. this explanation lets me judge when i should trust and not trust the [software, algorithm, tool]  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly     \\t ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t41\\tappendix d  synopsis of representative trust scales   cahour-forzy (2009) scale; adams, et al. (2003) scale   trust (and distrust) are defined as a sentiment resulting from knowledge, beliefs, emotions and other aspects of experience, generating positive or negative expectations concerning the reactions of a system and the interaction with it. the scale was developed in the context of  learning to use a cruise control system. trust was analyzed into three factors: reliability, predictability, and efficiency. the scale asks users directly whether they are confident in the xai system, whether the xai system is predictable, reliable, safe, and efficient.  the scale assumes that the participant has had considerable experience using the xai system. hence, these questions would be appropriate for scaling after a period of use, rather than immediately after an explanation has been given and prior to use experience. in the original scale, the items are rated on a bipolar scale going from \"i agree completely\" to \"i do not agree at all.\" the items we present below have been slightly modified to fit the general likert form developed for the xai explanation satisfaction scale. in addition to conforming to psychometric standards, consistency of format will presumably make the ratings tasks easier for participants.    1.  what is your confidence in the [tool]? do you have a feeling of trust in it?  1 2 3 4 5 6 7 i do not trust it at all.      i trust it completely  2.  are the actions of the [tool] predictable?  1 2 3 4 5 6 7 it is not at all predictable.      it is completely predictable.  3.  is the [tool] reliable? do you think it is safe?  1 2 3 4 5 6 7 it is not at      it is ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t42\\tall safe. completely safe.  4.  is the [tool] efficient at what it does?  1 2 3 4 5 6 7 it is not at all efficient.      it is completely efficient.   adams, et al. actually developed two scales.  one was for the evaluation of simulations but the other was generic, intended for the evaluation of any form of automation. apart from the item about liking, the items show overlap with items in the cahour-fourzy scale.  each item is accompanied by a bipolar rating scale (e.g., useful-not useful; reliable-not reliable) on which the participant makes a tick mark on a -5 to +5 delineation. following the likert items, the scale asks participants to rank the importance of the six item factors.  is the automation tool useful? how reliable is it? how accurately does it work? can you understand how it works? do you like using it? how easy is it to use?  jian, et al. scale (2000)   trust is regarded as a trait.  it is analyzed into six factors: fidelity, loyalty, reliability, security, integrity, and familiarity. factors were developed from cluster analysis on trust-related words. this scale is one of the most widely used, especially in the field of human factors.  indeed, a number of other scales have used items, or have adapted scale items, from the jian, et al. scale.  the item referencing \"integrity\" is problematic as the concept that a machine can act with integrity is not explicated.  the final item, about familiarity, would not be relevant in the sai context, since the participants\\' degree of experience with the xai system will be known objectively.  items 1, 2, 3, and 4 all seem to be asking the same thing.  ',\n",
       " \"xai\\tmetrics\\t\\t\\tp.\\t43\\tthe other items items in this scale show considerable overlap with items in the cahour-fourzy scale.  however, item 4 is particularly interesting and is does not have a counterpart in the cahour-fourzy scale.  we are inclined to recommend that the jian, et al., item 4 be incorporated into the xai version of the cahour-fourzy scale.  1. the system is deceptive. 2. the system behaves in an underhanded manner. 3. i am suspicious of the system's intent, action, or outputs. 4. i am wary of the system. 5. the system's actions will have a harmful or injurious outcome. 6. i am confident in the system. 7. the system provides security. 8. the system has integrity. 9. the system is dependable. 10. i can trust the system. 11. i am familiar with the system.  madsen-gregor scale (2000)  trust is defined as being both affective and cognitive. trust was analyzed into five factors: reliability, technical competence, understandability, faith, and personal attachment. their focus was not just trust in a decision aid but trust in an intelligent decision aid. as such, their scale deserves our particular attention. unfortunately, reports on their work are not accompanied by information about the precise method for administering the scale (i.e., whether or not it used a likert method). that said, their results show very high reliabilities (alpha = 0.94) and a factor analysis that accounts for about 70% of the variance.  perceived reliability the system always provides the advice i require to make my decision. the system performs reliably. the system responds the same way under the same conditions at different times. i can rely on the system to function properly. the system analyzes problems consistently. perceived technical competence  the system uses appropriate methods to reach decisions. the system has sound knowledge about this type of problem built into it. the advice the system produces is as good as that which a highly competent person could produce. the system correctly uses the information i enter. the system makes use of all the knowledge and information available to it to produce its solution to the problem. perceived understandability i know what will happen the next time i use the system because i understand how it behaves. \",\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t44\\ti understand how the system will assist me with decisions i have to make. although i may not know exactly how the system works, i know how to use it to make decisions about the problem. it is easy to follow what the system does. i recognize what i should do to get the advice i need from the system the next time i use it. faith  i believe advice from the system even when i don’t know for certain that it is correct. when i am uncertain about a decision i believe the system rather than myself. if i am not sure about a decision, i have faith that the system will provide the best solution. when the system gives unusual advice i am confident that the advice is correct. even if i have no reason to expect the system will be able to solve a difficult problem, i still feel certain that it will. personal attachment i would feel a sense of loss if the system was unavailable and i could not longer use it. i feel a sense of attachment to using the system. i find the system suitable to my style of decision making. i like using the system for decision making. i have a personal preference for making decisions with the system.  it is noteworthy that the scale refers to understandability but does not explicitly reference trust.   upon close examination, it seems that the reliability factor has some redundant items. the factors titled \"perceived technical competence\" and \"perceived understandability\" might be interpreted as referencing the user\\'s mental model of the system. for example, the item even if i have no reason to expect the system will be able to solve a difficult problem, i still feel certain that it will clearly is asking about the user\\'s mental model. indeed, the madsen-gregor scale as a whole can be understood as referring as much to evaluating the user\\'s mental model as it does to trust.  the mere fact that this distinction is fuzzy is a testament to the notion that xai evaluation must have measures of both trust and of mental models, since the two are causally related.  one can question the appropriateness of referring to a \"faith\" factor. items in this factor seem to refer to reliance and uncertainty. one can question the appropriateness of referring to a \"personal attachment\" factor rather than a \"liking\" factor.   as with other scales, multiple interpretations are possible.  for instance, the madsen-gregor item i believe advice from the system even when i don’t know for certain that it is correct asks essentially the same thing as the cahour-fourzy item i am confident in the tool; it works well.  ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t45\\ta number of individual items are of interest, such as \"it is easy to follow what the system does\" and \"i recognize what i should do to get the advice i need from the system.\" these seem to reference usability. up to this point, issues of xai system learnability and usability have not been considered in the xai program.  merritt scale (2011)   trust is regarded as an emotional, attitudinal judgement of the degree to which the user can rely on the automated system to achieve his or her goals under conditions of uncertainty. trust was initially broken into three factors: belief, confidence, and dependability. factor analysis revealed two other factors: propensity to trust and liking. the scale was evaluated in an experiment in which participants conducted a baggage screen task using a fictitious automated weapon detector in a luggage screening task. chronbach’s alpha ranged from a = .87 to a = .92.   items in this scale are all similar to items in the cahour-fourzy scale.  1. i believe the system is a competent performer. 2. i trust the system. 3. i have confidence in the advice given by the system. 4. i can depend on the system. 5. i can rely on the system to behave in consistent ways. 6. i can rely on the system to do its best every time i take its advice.  schaefer scale (2013)  this scale was developed in the context of human-robot collaboration. thus, trust was said to depend on both machine performance and team collaboration. trust was analyzed into two factors: ability and performance. this scale is unique in that it is long and has a format different from all the other scales. specifically the participant is asked to estimate the amount of time that the machine (in the study, a robot) would show each of a number of possible behaviors.  in this scale format, some items are troublesome.  for example, if the machine acts consistently, what is the point of asking about the percentage of time that it asks consistently? many of the items anthropomorphize the machine (robot) and do so in ways that seem inappropriate for the xai application (e.g., \"know the difference between friend and foe,\" \"be supportive,\" \"be responsible,\" \"be conscious\"). for example, the point of xai is to communicate richly and meaningfully with the participant. thus, asking about the percentage of time that the xai \"openly communicates\" or \"clearly communicates\" seems redundant to the evaluation of explanation satisfaction.  in the list below, we place in the left those items that seem appropriate to xai and in the right those that do not. the items in the left align fairly well to items in the cahour-fourzy scale. one of these items\\x00\"perform a task better than a novice human user\"\\x00is particularly interesting and might be added into the cahour-fourzy scale.  ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t46\\twhat percentage of the time will this machine (robot)… act consistently  function successfully  have errors perform a task better than a novice human user  possess adequate decision-making capability  perform exactly as instructed make sensible decisions  tell the truth  perform many functions at one time  follow directions incompetent  dependable  reliable  predictable   protect people  act as part of the team  malfunction  clearly communicate  require frequent maintenance  openly communicate  know the difference between friend and foe  provide feedback  warn people of potential risks in the environment  meet the needs of the mission provide appropriate information communicate with people  work best with a team keep classified information secure  work in close proximity with people  considered part of the team  friendly   pleasant  unresponsive   autonomous   conscious  lifelike  a good teammate led astray by unexpected changes in the environment   singh, et al. scale (1993)  this scale presupposes a context in which the participant is evaluating a device with which they have prior experience or have general familiarity with (atms, medical devices, etc.). trust was defined as an attitude toward commonly encountered automated devices that reflect a potential for complacency.  trust was analyzed into five factors: confidence, reliance, trust,  safety, complacency. since the scale merges trust and reliance, it presupposes prior experience and would not be appropriate for use when a user is first learning to use an xai.  for these reasons, we feel that this scale is not appropriate for use in the xai context. items that might be modified to make them appropriate reference factors that are already covered in the cahour-fourzy scale (i.e., trust, reliance). ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t47\\t factor 1: confidence 1. i think that automated devices used in medicine, such as ct scans and ultrasound, provide very reliable medical diagnosis.  2. automated devices in medicine save time and money in the diagnosis and treatment of disease. 3. if i need to have a tumor in my body removed, i would choose to undergo computer-aided surgery using laser technology because it is more reliable and safer than manual surgery. 4. automated systems used in modern aircraft, such as the automatic landing system, have made air journeys safer. factor 2: reliance 1. atms provide a safeguard against the inappropriate use of an individual\\'s bank account by dishonest people.  2. automated devices used in aviation and banking have made work easier for both employees and customers. 3. even though the automatic cruise control in my car is set at a speed below the speed limit, i worry when i pass a police radar speed trap in case the automatic control is not working properly. factor 3: trust 1. manually sorting through card catalogues is more reliable than computer-aided searches for finding items in a library.  2. i would rather purchase an item using a computer than have to deal with a sales representative on the phone because my order is more likely to be correct using the computer.  3. bank transactions have become safer with the introduction of computer technology for the transfer of funds. factor 4: safety 1. i feel safer depositing my money at an atm than with a human teller.  2. i have to tape an important tv program for a class assignment. to ensure that the correct program is recorded, i would use the automatic programming facility on my vcr rather than manual taping.  wang, et al. scale (2009)  this scale was used to evaluate trust in a hypothetical \"combat identification system\" that participants used in a simulated task. all of the items were taken form or adapted from the jian, et al. scale. the reliability of the decisions generated by the hypothetical decision aid was a primary independent variable, in an effort to study response bias inducted by automation reliability. the scale items are reported in the paper, but not the format for the scale (e.g., was it a likert scale?). some items are context specific (e.g., the aid provides security; the blue light indicates soldiers\").  what is noteworthy about some of the items is that they refer explicitly to ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t48\\tdeception and mistrust. other items in the wang, et al., scale refer to trust and reliability and are covered by items in the cahour-fourzy scale.    the aid is deceptive. the aid behaves in an underhanded (concealed) manner. i am suspicious of the aid’s outputs. i am wary of the aid. the aid’s action will have a harmful or injurious outcome. i am confident in the aid. the aid provides security. the aid is dependable. the aid is reliable. i can trust the aid. i am familiar with the aid. i can trust that blue lights indicate soldiers. i can trust that red lights indicate terrorists.   \\t ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t49\\tappendix e  trust scale recommended for xai   this trust scale asks users directly whether they are confident in the xai system, whether the xai system is predictable, reliable, efficient, and believable.  the scale assumes that the participant has had considerable experience using the xai system. hence, these questions would be appropriate for scaling after a period of use, rather than immediately after an explanation has been given and prior to use experience.  a majority of the items are adapted from the cahour-fourzy scale (2009), just as they have been adapted for use in other scales (e.g., jian, et al.). in the original scale, the items are rated on a bipolar scale going from i agree completely to i do not agree at all. we have modified the items to fit the general likert form developed for the xai explanation satisfaction scale. in addition to conforming to psychometric standards, this consistency of format will presumably make the ratings tasks easier for participants.    item 6 was adapted from the jian, et al. scale, item 7 was adapted from the schaefer scale, and item 8 was adapted from the madsen-gregor scale.  we can assert that the recommended scale is reliable based on these two facts: (1). the majority of the items in this recommended scale essentially overlap with items in the jian, et al. (2000) scale, which was shown empirically to be highly reliable.  (2) items in the recommended scale bear overall semantic similarity to items in the madsen-gregor-scale, and that scale too was also shown to have high reliability coefficients.    we can assume that the recommended scale has content validity given the essential overlap of items in the recommended scale with items in most of the existing scales, we can safely assume that the recommended scale has content validity.  1.  i am confident in the [tool]. i feel that it works well.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   2.  the outputs of the [tool] are very predictable.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   3.  the tool is very reliable.  i can count on it to be correct all the time. ',\n",
       " 'xai\\tmetrics\\t\\t\\tp.\\t50\\t 5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   4. i feel safe that when i rely on the [tool] i will get the right answers.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   5.  the [tool] is efficient in that it works very quickly.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   6. i am wary of the [tool]. (adopted from the jian, et al. scale and the wang, et al. scale)  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   7. the [tool] can perform the task better than a novice human user. (adopted from the schaefer scale)  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly   8. i like using the system for decision making.  5 4 3 2 1 i agree strongly  i agree somewhat i’m neutral about it i disagree somewhat i disagree strongly  \\t',\n",
       " 'racademy of management annals\\n2020, vol. 14, no. 2, 627 –660.\\nhttps://doi.org/10.5465/annals.2018.0057\\nhuman trust in artificial intelligence: review\\nof empirical research\\nella glikson1\\nbar ilan university\\nanita williams woolley\\ncarnegie mellon university\\nartificial intelligence (ai) characterizes a new generation of technologies capable of\\ninteracting with the environment and aiming to simulate human intelligence. the suc-\\ncess of integrating ai into organizations critically depends on workers ’trust in ai\\ntechnology. this review explains how ai differs from other technologies and presentsthe existing empirical research on the determinants of human “trust”in ai, conducted in\\nmultiple disciplines over the last 20 years. based on the reviewed literature, we identify\\nthe form of ai representation (robot, virtual, and embedded) and its level of machineintelligence (i.e., its capabilities) as important antecedents to the development of trust\\nand propose a framework that addresses the elements that shape users ’cognitive and\\nemotional trust. our review reveals the important role of ai ’s tangibility, transparency,\\nreliability, and immediacy behaviors in developing cognitive trust, and the role of ai ’s\\nanthropomorphism specifically for emotional trust. we also note several limitations in\\nthe current evidence base, such as the diversity of trust measures and overreliance onshort-term, small sample, and experimental studies, where the development of trust islikely to be different than in longer-term, higher stakes field environments. based on our\\nreview, we suggest the most promising paths for future research.\\nartificial intelligence (ai) represents a highly capable\\nand complex technology that aims to simulate humanintelligence. ai sits at the core of what has been termedthe“fourth industrial revolution ”(schwab, 2017), dis-\\ntinguished by the shift of agency and control fromhumans to technology, and thus transforms our previous\\nunderstanding of human –technology relations (murray,\\nrhymer, & sirmon, 2020). this revolution and its im-plications highlight new theoretical and empiricalquestions that need to be addressed by organizationalresearchers, as ai has the potential to dramaticallychange the overall workforce structure as well as the way\\norganizations and jobs are designed, decisions are made,and knowledge is managed (brynjolfsson, mitchell, &rock, 2018; danaher, 2017; huang & rust, 2018; kaplan,2015; kellogg, valentine, & christin, 2019; pfeffer, 2018;wirtz et al., 2018; graetz & michaels, 2018). the exact\\nshape of these changes is still to be determined; this\\nleaves room for an open, multidisciplinary dialogue thatshould explore human –ai collaboration and further\\nfacilitate the way ai is developed. the trust that usersdevelop in ai technology will be central to determining\\nits role in organizations moving forward. thus, we re-view the latest empirical research to lay a foundation forunderstanding the ways humans develop trust in ai.\\nas development of trust among humans is highly\\ndependent on the physical appearance of the trustee(cho & hu, 2009; duarte, siegel, & young, 2012), aiembodiment is likely to be an important consideration intrust development between humans and ai. researchershave examined ai in a variety of embodiment forms: asa physical robot, a virtual agent or bot, or in forms that areinvisible to the user, embedded inside of a computer or\\nother tool. in addition to va riance in ai embodiment,\\nresearchers examined human trust in ai under differentlevels of ai machine intelligence, that is, its capabilities.\\nthe work on this article was sponsored by the defense ad-\\nvanced research projects agency and the army research\\noffice, and was accomplished under grant number w911nf-\\n17-1-0104 and w911nf-20-1-0006. the views and conclusionscontained in this paper are those of the authors and should not\\nbe interpreted as representing the official policies, either\\nexpressed or implied, of the defense advanced research pro-jects agency, the army research office, or the u.s. govern-\\nment. the u.s. government is authorized to reproduce and\\ndistribute reprints for government purposes, notwithstandingany copyright notation herein.\\nwe greatly appreciate the constructive and thoughtful\\nfeedback provided by associate editor sharon parker.\\n1corresponding author.\\n627\\ncopyright of the academy of management, all rights reserved. contents may not be copied, emailed, posted to a listserv, or otherwise transmitted with out the copyright holder ’s express\\nwritten permission. users may print, download, or email articles for individual use only.',\n",
       " 'higher machine intelli gence means more complex\\ntechnological abilities, which allow ai to produce more\\nautonomous and complex actions (chen & barnes,2014; hancock, billings, schaefer, chen, de visser, &parasuraman, 2011). users are not always aware of theactual technological sophi stication of ai; while in\\nsome cases highly intelligent machines are acting intheir full capacity, in others the capability may notbe fully manifest in their behavior. for current pur-\\nposes, we focus on the trust of human users, and thus\\naddress the perceived machine intelligence from theusers ’point of view.\\nproceeding from the intersection of research on ai\\nand the extant literature on human trust, we organizeour review of the existing literature by considering thephysical appearance of ai (i.e., its representation),addressing the level of mach ine intelligence, and look-\\ning at the implications of each for the development of\\nboth cognitive and emotional trust (mcallister, 1995). incontrast to the existing reviews and meta-analyses thatfocused on studies from a specific field, such as robotics(hancock et al., 2011) or huma n factors (hoff & bashir,\\n2015; lee & see, 2004), this review integrates researchfrom different disciplines , providing a comprehensive\\noverview. for each ai representation (robotic, virtual,\\nand embedded), we discuss the common dimensions\\nthat emerged from our review as relevant for cognitivetrust (tangibility, transparency, reliability, task charac-teristics, and immediacy be haviors) and for emotional\\ntrust (tangibility, anthropomorphism, and immediacybehaviors).\\nliterature review methodology\\nthis review presents the way trust in ai is cur-\\nrently discussed in the literatures of computer sci-ence, human –computer interaction, human factors,\\ninformation systems, robotics, management, mar-keting, and psychology. focusing on human trust inai, we first used the google scholar platform, search-ing for the following key words: ai, intelligent agents,\\nagent –human interaction, algorithm aversion, robot –\\nhuman interaction, intelligent automation, trust inrobot, and trust in technology. we limited the searchto articles published in the last 20 years (between1999 and 2019) to address the empirical workconcomitant with the recent technological devel-opment of ai. we screened articles based on thecontent, including those relevant to human trust\\nin ai, while excluding descriptions of algorithm/\\narchitecture (without reference to trust), orthose focusing on trust only among humans. we thenfollowed cross-reference techniques to find morerelevant articles. this search revealed approximately\\n200 peer-reviewed articles and conference pro-\\nceedings from the fields of organizational behavior,human –computer interactions, robot –human in-\\nteractions, information systems, information technol-ogy, and engineering. finally, we used threedatabases, business source premier, engineeringvillage, and psycinfo, to complete the literature re-view and, using the same guidelines, added an addi-\\ntional 50 articles based on their content. of the\\nmentioned articles, only about 150 have presentedempirical research that directly or indirectly ad-dresses human trust in ai. we have also includedmost recent published review articles that focus ontrust in technology or in robotics in more generalterms.\\nin proceeding with our review, we first define ai\\nand then discuss the broader perspective of its in-\\ntegration into organizations and review the concept oftrust from a multidisciplinary perspective. we pres-ent the empirical research for the three major types ofai representations and consider the intersection withthe levels of machine intelligence, first for the devel-opment of cognitive and then for emotional trust.next, we discuss the integration of the research, as\\nwell as its implications for organizations, the existing\\nlimitations, and directions for future research.\\nwhat is ai?\\nin management research, ai is defined as a new\\ngeneration of technologies capable of interactingwith the environment by (a) gathering information\\nfrom outside (including from natural language) or\\nfrom other computer systems; (b) interpreting thisinformation, recognizing patterns, inducing rules, orpredicting events; (c) generating results, answeringquestions, or giving instructions to other systems;and (d) evaluating the results of their actions andimproving their decision systems to achieve specificobjectives (ferr `as-hern ´andez, 2018). the interac-\\ntional properties of ai make it capable of learning\\nand changing its behavior based on the cues from theenvironment (frantz, 2003; rahwan et al., 2019). asthe environment in which ai functions is usuallyhighly complex and partially random, ai ’s behavior\\nis not deterministic (danks & london, 2017), and thecomplex multilayered process of ai decision-makingis generally not transparent. this means that ai ’sd e -\\ncisions could be difficult to predict, and the logic be-\\nhind each decision made is often poorly understood.\\nthe futuristic literature assumes ai is a set of algo-\\nrithms able to perform all tasks just as well as, or even628 july academy of management annals',\n",
       " 'better than, humans. however, this type of superintelli-\\ngence, known as strong or general ai, does not yet exist,\\nand thus this review is focused on the weak or narrow aithat is currently in use (raj & seamans, 2019; russell &norvig, 1995). weak ai is based on a variety of tech-nologies that are able to achieve fragments of the sim-ulation of human intelligence , such as face recognition.\\nto better understand how ai d iffers from more tradi-\\ntional technology, it is useful to explain one commonly\\nused component of ai, namely machine learning.\\nmachine learning is the ability of computers to\\nadjust their behavior based on the data to which theyare exposed (samuel, 1959). this means that havinga specific goal, such as minimizing number of mis-ses, and a set of rules that define what is a miss ora hit, will enable computers to adjust their decisionsbased on their experiences. this learning process\\nrequires a large amount of data that can be used for\\ntraining. when properly trained, ai is able to makeaccurate decisions with newly presented similar data,and adjust its behavior when necessary (brynjolfsson& mitchell, 2017). however, the training process mayintroduce unintended bias via the features of thedata, the algorithm, or the data –algorithm interac-\\ntion (danks & london, 2017).\\nthere are two important assumptions in machine\\nlearning: first, while the g oal is being established by\\nthe programmer (for instance, to minimize misses vs.\\nmaximize hits), the specific calculations that leadcomputers to the decision are based on the data and aremostly unknown. second, the computers are able to usedata to a greater extent than humans, and may thereforeachieve better results than humans (brynjolfsson &\\nmitchell, 2017). for example, consider arthur samuel,\\none of the pioneers of machine learning, who taughta computer program to play c heckers (frantz, 2003).\\nhis goal was to teach it to play checkers better thanhimself, which was not som ething he could program\\nexplicitly. samuel used a large number of annotated\\ngames, with the good moves distinguished from the badones, and a guide to checkers to adjust the criteria for\\nchoosing moves, so that the program would choose\\nthose moves thought to be good by checker experts asoften as possible. in 1962, samuel ’s program beat the\\ncheckers champion of the state of connecticut, whowas the fourth in the nation, as it was able to playcheckers better than its programmer (mccarthy &feigenbaum, 1990). even though the program was ap-plying preprogrammed rules, it learned to play better\\nthan its creator, making decisions in a better way than\\nthe programmer could, which is a key difference be-tween prior generations of technology (which werelimited by the knowledge o f the programmer) and ai.considering the unique qualities of ai technology,\\nit is important to address the difference between\\nai and automation, as these terms are often used in-terchangeably (e.g., lee & see, 2004). automationrefers to the situation where computers follow pre-programmed rules to perform repetitive and mono-tonic tasks that were previously performed by humans(parasuraman & riley, 1997). the behavior pro-duced by traditional automation and its outcomes\\nare preprogrammed and well understood. tradi-\\ntional automation is deterministic and does not in-clude any learning processes (e.g., raj & seamans,2019). however, automation can be enabled by ai,which means that machine learning algorithms makethe rules that the automated process follows, andthey also learn and adjust based on experience andfeedback. consequently, automation plays a role in\\ncarrying out the actions determined by an intelligent\\nsystem, and thus this review includes research thatexamines trust in intelligent, ai-enabled automation.the specific, technical details of ai are beyond thescope of this review; our focus is on reviewing exist-ing empirical research related to users ’perceptions\\nand tendencies to trust or not trust ai technology.\\ntrust and integration of ai\\nin organizations\\nearly work on the acceptance and use of new\\ntechnology in organizations tended to focus on userreactions to technological features. for example, thetechnology acceptance model (tam; davis, 1989)emphasizes perceived usefulness (the degree to which\\na potential user believes that technology will help to\\nperform a task) and ease of use (the perceived utilityof the effort to use the new technology) as the maindeterminants of users ’attitudes and behavioral in-\\ntention to use and accept the system (davis, 1989).more recent approaches have further added the con-cept of trust as a predictor of technology acceptance(ghazizadeh, lee, & boyle, 2012; hoff & bashir, 2015;\\nlee & see, 2004; pavlou, 2003).\\na focus on issues of trust allows us to address not only\\nthe disuse (a rejection) of technology but also its misuse(an inappropriate overrelia nce on technology) or its\\nabuse (harmful use to achieve an individual gain;parasuraman & riley, 1997). trust can predict the levelof reliance on technology, whereas the level of corre-spondence between user ’s trust and the technology ’s\\ncapabilities, known as calibration, can influence the\\nactual outcomes of technology use. low trust in highlycapable technology would lead to disuse and high costsin terms of lost time and work efficiency, as well as2020 629 glikson and woolley',\n",
       " 'possible abuse, whereas high trust in incapable tech-\\nnology would lead to over-trust and misuse, which in\\nturn may cause a breach of safety and other undesirableoutcomes (hoff & bashir, 2015; lee & see, 2004).\\none of the most cited definitions of trust was sug-\\ngested by mayer, davis, and schoorman (1995), whoargued that trust is “the willingness of a party to be vul-\\nnerable to the actions of another party based on the ex-pectation that the other will perform a particular action\\nimportant to the trustor, irrespective of the ability to\\nmonitor or control that other party ”(mayer, davis, &\\nschoorman, 1995, p. 712). this definition emphasizesa willingness to be vulnerable and the importance of theactions at stake, and does not limit the concept of trust tohuman –human interaction, allowing us to consider trust\\nwith regard to technology, including ai (wang, qiu,kim, & benbasat, 2016). although definitions in other\\nliteratures incorporate some different assumptions,\\nsuch as socially embedded properties of human orinstitutional relations, the conceptualization of trustas a tendency to take a meaningful risk while believ-ing in a high chance of positive outcome is commonacross different disciplines (hoff & bashir, 2015;rousseau, sitkin, burt, & camerer, 1998).\\ntrust is particularly relevant to the human –ai re-\\nlationships because of the perceived risk embedded in\\nthem, due to the complexity and nondeterminism of aibehaviors, and its future role in the workplace. ai isperceived as technology that slowly will take over dif-ferent types of (currently) human jobs as well as funda-mentally transform the structure of organizations (davis,2019). it is still not clear whether low-skilled and low-cost employees, such as frontline service representa-\\ntives, are at a higher risk of being replaced by ai (huang &\\nrust, 2018; pfeffer, 2018; wirtz et al., 2018) thanknowledge workers and top-level managers whorely on analytical and rational knowledge process-ing, and whose high cost makes their replacementfinancially attractive (ferr `as-hern ´andez, 2018;\\nloebbecke & picot, 2015) . in the present, some “hu-\\nman”tasks are already being performed by ai\\n(brynjolfsson & mitchell, 2017). analyzing tasks across\\nalmost 1,000 occupations, brynjolfsson et al. (2018)found that most occupations in most industries have atleast some tasks that could be replaced by ai (suitablefor machine learning). however, there is no occupationin which all the current tasks could be replaced(brynjolfsson et al., 2018). that being said, there is alsono disagreement that the labor force will go through\\na dramatic change, with some jobs disappearing and\\nnew jobs being created (faraj, pachidi, & sayegh, 2018).\\ntrust is a dynamic concept that is prone to changes\\nbased on the behavior of the trusted agent (crisp &jarvenpaa, 2013; schoorman, mayer, & davis, 2007).\\nhoff and bashir (2015) posited that the way trust in\\ntechnology unfolds differs from the way it develops inhumans because of the common positivity bias towardnew technologies (parasuraman & manzey, 2010). incontrast to the low trust that exists initially betweenunfamiliar humans, new technologies may produceunrealistically optimistic beliefs regarding their abilitiesand functionality (dzindolet, peterson, pomranky,\\npierce, & beck, 2003). thus, although trust in humans\\ngenerally increases with time through frequent in-teractions, trust in technology decreases with time,based on encounters with errors and malfunctions(madhavan & wiegmann, 2007). however, the oppositealso could be true when it comes to ai. pointing out thewidespread skepticism asso ciated with the immaturity\\nof existing ai (hengstler, enkel, & duelli, 2016) and the\\ndifficulties associated with the acceptance of new tech-\\nnologies (leonardi, 2009), some researchers suggestthat low level of trust from an initial encounter mayincrease following a direct interaction (ullman &malle, 2017). in this review, we address the dynamicnature of trust by discussing the trajectory over whichtrust develops for users interacting with different airepresentations. we also examine the ai features that\\nfacilitate the development of trust, such as tangibility,\\ntransparency, reliability, and immediacy behaviors;the context of the task being performed; and the role ofmachine intelligence in moderating the impact ofexperience with ai on human trust.\\nmuch of the extant organizational research has con-\\nsidered trust to be a cognitive construct that involvesrational evaluation of the trustee and situational features\\n(schoorman et al., 2007). however, trust might also be\\ninfluenced by irrational factors, such as emotions andmood (komiak & benbasat, 2006). mcallister (1995) re-\\nferred to the latter as emotion-driven or affect-basedtrust, suggesting that in inte rpersonal relationships,\\npeople develop social connections that provide supportand comfort —in addition to cognitive trust that is based\\non perceptions of trustee reliance and competence. the\\nemotional trust between human coworkers differs from\\ncognitive trust not only in its antecedents but also in itsbehavioral consequences (jones & george, 1998; ng &chua, 2006). recognizing the differences between trustin humans and trust in technology, hoff and bashir(2015) argued that for understanding the adoption ofa complex new technology, it is essential to addressemotion-driven trust. the u se of unknown sophisticated\\ntechnology, such as ai, suggests a need for a “leap of\\nfaith”(hoff & bashir, 2015; lee & see, 2004) and trust in\\nprocesses that cannot be directly observed or cognitivelyunderstood. therefore, in this review, we address630 july academy of management annals',\n",
       " 'empirical research that examined both cognitive and\\nemotional trust in ai.\\nbuilding cognitive trust in ai\\nresearch on human trust attests to the importance\\nof an object ’s representation and tangibility for estab-\\nlishing trust, and the extant research on ai also sup-ports this notion (kr ¨amer, lucas, schmitt, & gratch,\\n2017; lee, jung, kim, & kim, 2006; li, 2015). however,\\nresearch that addresses more than one type of airepresentation (such as physical robot vs.v i r t u a l\\nbot) is rare, as different disciplines tend to focus ona specific type of representation. at the same time,similar representations are often studied by severaldisciplines. for instance, researchers in roboticsand human factors mostly study trust in robots,\\nwhereas researchers in information systems, mar-\\nketing, and human –computer interactions study\\ntrust in recommendation agents. thus, organizinga review by field of study would not be helpful.taking a user-centered approach and embracingthe physical embodiment notion that addresses thephysical representation of ai (lee et al., 2006a), weorganize the review based on the way ai is presented\\nto human users, separating between ai-enabled ro-\\nbots, ai-enabled virtual agents, and embedded ai.reviewing the research across disciplines that arerelevant to each representation, we directly addressthe role of ai representation.\\nas argued previously, trust could be both cogni-\\ntive (based on rational thinking) and emotional(based on affect; mcal lister, 1995), and as these\\ntypes of trust might differ in their antecedents, we\\ndiscuss their development separately.\\n2therefore,\\nwe start by discussing the dimensions influencingcognitive trust within each physical representation,such as tangibility, transparency, and reliability; taskcharacteristics; and immediacy behaviors, with thelatter reflecting the special interactive abilities of ai.in each section, we present an overview of the find-\\nings, the trajectory of trust, and review extant research\\non each dimension relevant to each type of technol-ogy representation (robotic, virtual, or embedded).when researchers examine cognitive trust in ai,\\nthey measure it as a function of whether users are\\nwilling to take factual information or advice and act onit, as well as whether they see the technology as help-ful, competent, or useful. based on prior research thatexamined trust in technology (hancock et al., 2011;hoff & bashir, 2015; lee & see, 2004), we organizethe review of cognitive trust in ai by addressing thedimensions that were found to influence trust. we\\nstart each section by discussing the trajectory of\\ntrust as is evident in the reviewed research and thes p e c i f i cr o l eo fa i tangibility , that is, its capability of\\nbeing perceived or touched, in developing trust. anoverview of our conclusions can be found in table 1and figure 1.\\ntransparency reflects the level to which the un-\\nderlying operating rules and inner logics of the tech-\\nnology are apparent to the users and is considered to\\nbe critical for developing trust in new technology(hoff & bashir, 2015). it is more problematic for aithan other technologies, especially when methodssuch as deep learning are involved. an importantaspect of transparency includes different types ofexplanations regarding how ai works or why a spe-cific decision was made that are understandable to\\nusers, even when they have little technical knowl-\\nedge. the review focuses on the studied implicationsof these explanations for cognitive trust.\\nreliability , or exhibiting the same and expected\\nbehavior over time, is also critical to technologytrustworthiness (hoff & bashir, 2015). in the case ofai, reliability is often difficult to assess, especiallyin the context of high machine intelligence, as learn-\\ning from data can lead technology to exhibit different\\nbehavior, even if the underlying objective functionremains the same. as our review reveals, the relation-ship between ai reliability and trust is less straight-forward in high versus low intelligence technologies\\nand varies across ai representations.\\ntechnologies are believed to be more efficient\\nin some tasks than in others and, therefore, task\\ncharacteristics related to the work the technology\\nis performing, such as whether it deals with largelytechnical or interpersonal judgments, could be animportant antecedent for cognitive trust in ai(hancock et al., 2011). high machine intelligencenot only improves the performance of ai in tradi-tional technology-related tasks but also increasesthe range of tasks that could be performed by tech-\\nnology. as the range of tasks ai can perform keeps\\ngrowing, the role of task characteristics in de-veloping cognitive trust becomes more complexand less stable.\\n2it is important to note that in many cases, researchers\\ndid not make a clear distinction regarding the type of trust\\nin ai they study; we inferred this distinction based on thecontext of the study, trust antecedents, and trust measures.when the studied mechanism was based on affect or\\nemotions, we categorized it as emotional trust, and when it\\nwas based on cognition or rationality, as cognitive trust.2020 631 glikson and woolley',\n",
       " 'high machine intelligence that allows the tech-\\nnology to interact with the environment and be re-\\nsponsive to users has introduced a variety of ai\\nimmediacy behaviors. immediacy has been defined as\\nthe degree of perceived physical and/or psychological\\ncloseness between people (mehrabian, 1967). imme-\\ndiacy behaviors refer to socially oriented gestures\\nintended to increase interpersonal closeness, such as\\nproactivity, active listening, and responsiveness. these\\nbehaviors are perceived as signs of machine intelli-\\ngence and influence cogniti ve trust by raising the ex-\\npectations of high-quality performance and positive\\nexperience during mutual work.cognitive trust in robotic ai\\nai-enabled robots may have a variety of functions\\nand capabilities as well as different mechanical orhuman-like representations; they could be physicallypresent or distantly located and perform mechani-cal or socially oriented tasks. based on the extant re-search, this review focuses on interactions withphysically present robots, addressing remote robotsonly with regard to transparency and task character-\\nistics. the initial trust in robotic ai is relatively low;\\ntherefore, factors such as reliability, transparency, andcharacteristics of the task could play an important rolein developing trust. nevertheless, it seems that a muchtable 1\\nmain effects of dimensions on cognitive trust in ai, organized by representation\\ndimensions robotic ai virtual ai embedded ai\\ntangibility physical presence increases trust:\\nmore trust in robotic ai than invirtual ai.visual presence increases trust:\\nmore trust in virtual ai than inembedded ai.the effect of awareness on the use of\\nai is not clear.\\nselected\\nreferencesbainbridge et al. (2011), lee, peng, jin,\\n& yan (2006), salem et al. (2015),\\nshinozawa et al. (2005)chattaraman et al. (2014), mumm &\\nmutlu (2011)eslami et al. (2015)\\ntransparency transparency might increase trust, but\\nthe empirical research is scant.transparency of ai reliability and\\nexplanations of how algorithmworks increase trust.transparency of how algorithm works\\nincreases trust; especially neededfor highly intelligent managerial\\nsystems.\\nselected\\nreferencessanders et al. (2014) fan et al. (2008), wang & benbasat\\n(2007), wang et al. (2016)alan et al. (2014), chao et al. (2016),\\ndietvorst et al. (2016), dzindoletet al. (2003), kizilcec (2016), lee,\\nkusbit, metsky, & dabbish (2015),\\nm¨ohlmann & zalmanson (2017)\\nreliability low reliability decreases trust, but not\\nalways: when robot is perceived as\\nhaving high machine intelligence,\\npeople tend to follow even a faulty robot.low reliability mostly decreases trust\\nin laboratory and field studies\\nwhere the initial trust was very high.low reliability significantly decreases\\ntrust, and the way to restore trust is\\ndifficult and takes time.\\nselected\\nreferencesbainbridge et al. (2011), desai et al.\\n(2012), freedy et al. (2007), robinette\\net al. (2016), salem et al. (2015)fan et al. (2008); glass et al. (2008);\\nmoran et al. (2013)dietvorst et al. (2015); dzindolet et al.\\n(2003); manzey et al. (2012)\\ntask\\ncharacteristicsin technical tasks the trust is higher\\nthan in tasks that require socialintelligence.in technical tasks that require data\\nanalysis, trust in ai is higher thanin humans.in tasks that require social\\nintelligence, the trust in humansis higher than in ai; high self-confidence moderates the trust in ai.\\nselected\\nreferencesgaudiello et al. (2016), gombolay et al.\\n(2015)ramchurn et al. (2016) dietvorst et al. (2016), logg et al.\\n(2018)\\nimmediacy\\nbehaviorsresponsiveness, adaptiveness, and\\npro-social behaviors increase trust.personalization and use of persuasion\\ntactics increase trust.personalization improves trust;\\nconstant tracking of workers ’\\nbehaviors may decrease trust.\\nselected\\nreferencesbaraglia et al. (2016), de visser &\\nparasuraman (2011), hoffman &breazeal (2007), oistad et al. (2016)andrews (2012), fenster et al. (2012),\\nkomiak & benbasat (2006)dzindolet et al. (2003), lee et al.\\n(2015), matz et al. (2017),m¨ohlmann & zalmanson (2017)632 july academy of management annals',\n",
       " 'more important role is being played by the level of\\nmachine intelligence that allows robots to engage ina variety of behaviors that increase immediacy, suchas responsiveness to users.\\ntrust trajectory\\nextant research addressing the trajectory of human\\ntrust in robotic ai suggests that the initial trust startsat a low level and develops over time, as depicted infigure 1. this means that trust in robotic ai developsin a manner that is similar to trust in humans andincreases following direct interaction (haring, silvera-tawil, watanabe, & velonaki, 2016; ullman & malle,2017). for instance, waytz, heafner, and epley (2014)\\nfound that participants who drove a car that was par-\\ntially autonomous reported higher trust in its abilitiesthan participants without such experience. bartneck,suzuki, kanda, and nomura (2006) noted that a shortinteraction with a robotic pet significantly improvedthe overall attitude toward robots. even for children,a hands-on experience with an automated robot wasfound to increase trust more than other activities, such\\nas watching a video that explained the robot ’s abilities\\n(rossi, holthaus, dautenhahn, koay, & walters, 2018).\\nadditional evidence for low initial trust in robotic\\nai is observed in both laboratory and field studies.for instance, ullman and malle (2017) tested the waypeople trust a small robotic vehicle capable of gener-ating and adjusting its paths. the researchers com-pared a condition in which t he robot was autonomous\\nand performed required adjustments without any hu-\\nman involvement to a condi tion in which, to activate\\nthe adjustment, participants had to push a button. theyfound that participants reported higher cognitive trustin the robot they controlled. furthermore, following\\nthis controlled experience of involvement, partic-ipants expressed signifi cantly higher trust in po-\\ntential future robots (ullman & malle, 2017).\\nin field studies, robots were also treated with great\\nsuspicion and low initial trust. importantly, low initialtrust does not necessarily lead to a lack of use but can\\nbe translated into a misuse of technology, especially in\\nreal-life situations. for example, andrist, bohus, yu,and horvitz (2016) conducted a field study in whichthey analyzed human –robot interactions in a lobby of\\nan office building. the robot ’s goal was to provide\\ndirections to different building areas, such as eleva-tors, in response to users ’requests. analyzing the\\nvideotaped interactions across several days, re-\\nsearchers reported that 81 percent of the interactions\\nwere playful, with no real intent to get directions. inthe next stage, the robot was programmed to respondto a playful approach, such as laughter, with a directquestion regarding the intent of the user. researchersfound that only 15 percent of users admitted to mis-using the robot, whereas others insisted that theywere truly asking for the robot ’s assistance (andrist\\net al., 2016). despite users denying being playful,\\ntheir actual use of a robot has the potential to teachabout its abilities and build trust.\\nas the level of machine intelligence of robotic ai\\nincreases, it becomes capable of engaging in greaterimmediacy behaviors. as a result of the robot ’s en-\\ngagement in such human-like behaviors, users ’ini-\\ntial trust steeply increases and leads to greater\\nuser compliance with the robot ’s directives. al-\\nthough users may perceive this compliance as reci-procity, the observed tendency to cede control toa robot, even when the latter demonstrates erroneousfigure 1\\ntrajectories of trust for robotic, virtual, and embedded ai as reflected by most of the reviewed studies\\ntrust trajectories\\nhigh trust\\nlow trust\\nmoderating effect of the\\nlevel of machine intelligencerobotic ai\\nvirtual ai\\nembedded ai\\nthreshold of use\\ntime 1 time 22020 633 glikson and woolley',\n",
       " 'function, is worrisome. we will discuss the issue of\\ncompliance despite a robot ’s erroneous behavior in\\nthe section on reliability.\\ntangibility\\none of the main factors that is known to influence\\ninitial trust is the robot ’s actual tangible physical\\npresence (for a review, see li, 2015). for instance,\\nbainbridge, hart, kim, and scassellati (2011) com-\\npared a physically present robot and an identical 2dimage presented on a screen. they found that par-ticipants were quicker to respond to the physicalrobot. furthermore, testi ng trust by examining com-\\npliance with an unusual reque st, the researchers found\\nthat participants were more compliant with a physicalrobot than its 2d representation.\\nshinozawa, naya, yamato, and kogure (2005) made\\nsimilar comparisons, using the willingness to accepta robot ’s advice as a behavioral measure of trust. they\\nalso found higher trust in the physically present robot;however, this was only for tasks presented in a physicalspace. when the task was presented on a screen, therewas no difference between the robot and the on-screenimage conditions. these latter findings suggest that the\\nfit between the ai representation and the presentation of\\nthe task may influence human trust, decreasing thepositive impact of physical p resence for tasks that are\\ncompleted online.\\nlooije, neerincx, and cnossen (2010) also com-\\npared a physically present robot and its 2d virtualrepresentation and found that the physically presentrobot was significantly more trusted than its virtual\\nrepresentation. however, problems with the smooth-\\nness of the robot ’s movement harmed its ability to\\nreact to the participants ’voices and drove the partic-\\nipants to perceive the 2d virtual representation ashaving a more social personality —b e i n gm o r ef r i e n d l y\\nand kind. as responsive behavior is more easily cre-ated in an animated virtual agent than in a robot, it isimportant to further evaluate the relative effect of ai ’s\\nphysical presence in comparison to virtual ai re-\\nsponsiveness on trust. based on the existing research,it seems that tangibility is more important to trustthan responsiveness, but in long-term interactions, theprosocial, responsive behaviors could play a moresignificant role.\\nadditional evidence for the positive effect of phys-\\nical presence can be found in a study performed by\\ncormier, young, nakane, newman, and durocher\\n(2013). modeled after milgram ’sc o m p l i a n c ee x p e r i -\\nment, researchers asked participants to perform anextremely boring document-sorting task in thepresence of a robot that was only able to voice such\\nphrases as “please continue doing the task. ”the ro-\\nbot had significantly less effect on participants ’be-\\nhavior than a human facilitator, yet 48 percent ofparticipants followed the robot ’s request and con-\\ntinued the task, while openly voicing their boredomand dissatisfaction.\\nexisting research shows that it is not only the\\nphysical presence that influences cognitive trust but\\nalso a robot ’s physical appearance. for instance, re-\\nsearchers found that robot appearance is ofteninterpreted by users as signaling the level of robotintelligence, and even influences moral judgments,so that human-like robots are expected to make hu-man-like moral decisions, in contrast to robots witha mechanical appearance (malle, scheutz, forlizzi,& voiklis, 2016). interestingly, human-likeness is not\\nalways associated with perceptions of higher in-\\ntelligence. carlson, sweet, rhizor, poston, lucas,and feil-seifer (2015) examined the impact of a co-operation-oriented team activity on perceptions ofa team member robot. they found that the team-building activity improved the perception of the ro-bot’s anthropomorphism but not the perception of\\nthe robot ’s level of intelligence.\\ntransparency\\ndespite an extensive focus on the importance of al-\\ngorithm transparency for cognitive trust, the existingresearch on the role of transparency for trust in roboticai is very limited and mostly relates to robots thatwork in remote locations, focusing on the need for\\nshared awareness (chen & barnes, 2014; stubbs,\\nwettergreen, & hinds, 2007). extant research pro-vides only general support for the positive effect ofconstant information flow on cognitive trust in ro-bots (sanders, wixon, schafer, chen, & hancock,2014). future research must address this gap andtest the effect of transparency for both remote andcollocated robots.\\nreliability\\nan increase in trust following interaction usually\\nsuggests highly reliable performance. interestingly,we could find only a few studies that examined thedirect impact of reliability of ai-enabled robots ontrust. for instance, robinette, howard, and wagner\\n(2017) showed in several studies that in high-risk\\nsituations participants lost trust in the advice ofa robot that made a mistake. however, different fac-tors may significantly moderate the relationship634 july academy of management annals',\n",
       " 'between a robot ’s failure and subsequent human\\ntrust. for instance, desai, kaniarasu, medvedev,\\nsteinfeld, and yanco (2013) examined the moder-ating effect of the timing of a robot ’sf a i l u r e .t h e y\\nfound that early drops in reliability lowered real-time trust more than later drops. freedy, devisser,\\nweltman, and coeyman (2007) reported similar re-sults connecting the early failures to the first impres-sion regarding the robot ’s capabilities. however,\\ncomparing three different levels of the robot ’sr e -\\nliability across several trials, researchers also foundthatexperiencewith a low reliability robot increasedtrust, even though the robot was consistently fail-ing. working with inconsistent reliability (i.e.,a medium level of reliability) was more confusingto the participants, and their trust in this conditionwas lower than in the low reliability condition.\\nsome level of caution should be exercised in gen-\\neralizing these findings, however, as the study hadonly 12 participants. it is important for ongoingresearch to examine whether these results wouldreplicate in a large sample and if reliability is moreimportant for trust in robotic ai than the quality ofits performance.\\na high level of machine intelligence allows ai-\\nenabled robots not only to assist humans in a variety\\nof tasks but also to engage in managerial activities thatexert some control over users ’behavior, such as task\\nallocation, task instructions, or guidance. reviewingstudies in which robots played a semi-managerialrole reveals that a robot ’s reliability could play a less\\nimportant role for human trust and compliance thanpreviously assumed. for instance, salem, lakatos,\\namirabdollahian, and dautenhahn (2015) found that\\npeople followed a human-like robot ’s instructions\\neven when they witnessed its erroneous behavior.the faulty behavior had a significant impact on par-ticipants ’perceptions of reliability and trust; how-\\never, these perceptions did not translate into reducedcompliance. researchers reported that 91 percent ofparticipants followed all robot instructions, even\\nthe unreasonable ones, such as pouring juice on\\na plant and disclosing a personal password. simi-larly, robinette, howard, and wagner (2015) androbinette, li, allen, howard, and wagner (2016)found that people tend to follow a robot ’s lead in an\\nemergency situation, even when its prior behaviorindicates a serious malfunction.\\ndespite the obvious limitations regarding the ex-\\nternal validity of these laboratory-based studies, in-\\ncluding the short-term interactions and low actualrisk involved (even in the emergency scenario it isnot clear to what extent the participant actually feltdanger), the tendency to follow a highly intelligent\\nrobotic ai, even when its ’actions are questionable, is\\nworrisome and requires more research. we will fur-ther discuss the aspects of robots ’erroneous behav-\\nior in the section on emotional trust.\\ntask characteristics\\nlooking into the effect of task characteristics on\\ntrusting behavior, gaudiello , zibetti, lefort, chetouani,\\nand ivaldi (2016) measu red the extent to which\\nparticipants were willin g to change their answers\\nfollowing a robot ’s advice. researchers used functional\\nquestions, such as an evaluation of objects ’weight,\\ncolor, and sound, and questions of a social nature re-garding the importance of different objects in socialscenery, such as a public pool. all cases presented\\nuncertain situations in which any answer could be\\ncorrect, whereas the human-like robot provided ad-vice that was always the opposite of the participant ’s\\nopinion. results indicate that people conform withthe robot more readily on functional issues than onsocial issues; however, the effect size was small, andthe overall rate of accepting the robot ’sa d v i c eo na n y\\nissue was low (significantly lower than 50 percent).\\nin the area of team interpersonal dynamics,\\nmartelaro, jung, and hinds (2015) tested the willing-ness of participants to cooperate with a robot ’si n -\\ntervention into team conflict. the robot was designedto intervene when one of the team members (a con-federate) became very rude. the task of the robot wasto restore appropriate communication and avoid de-terioration of the conflict. the researchers found, in\\ncontrast to what was expected, that the robot ’si n -\\ntervention made the existence of conflict more visi-ble to the team members.\\ngombolay, gutierrez, clarke, sturla, and shah (2015)\\ntested the effects of shared decision-making au-thority in human –robot and human-only teams in\\na manufacturing setting. they found that althoughpeople value human teammates more than robotic\\nteammates, they trusted the robot ’s ability to schedule\\ntasks and manage the workflow. thus, for a task thatrequires complex analysis and optimization to reachan effective flow of actions, participants tend to cedetheir control and authority to the robot, demonstratinghigh trust. as robots gain more capabilities related tofacilitating or even managing team dynamics, it isimportant to note that for human users to trust and\\naccept a robot ’s actions, the task allocated to the robot\\nshould be well matched to its actual abilities.\\nthese studies demonstrate the importance of\\nthe task for developing cognitive trust in a robot,2020 635 glikson and woolley',\n",
       " 'emphasizing the benefits of tasks that involve com-\\nplex calculations and technological abilities versus\\ntasks with social features. these findings are con-sistent with the maba-haba ( “machines are bet-\\nter at vs. humans are better at ”) framework that\\nsignifies the actions in which machines have signif-icant advantages over humans, such as objectivecalculations (bradshaw, feltovich, & johnson, 2011;de winter & dodou, 2014; lee, 2018).\\nnevertheless, as a robot ’s level of machine intelli-\\ngence increases, so does the ability to demonstrateresponsive, prosocial behaviors, which raises theexpectation that robots will be able to fill moresocial roles, such as companionship. strohkorb-sebo, traeger, jung, and sc assellati (2018) exam-\\nined the effect of a robot ’s disclosed vulnerability\\non team dynamics and collaboration. playing the\\nrole of a team facilitator, a humanoid (i.e., human-\\nlike) robot was designed to make comments on theteam ’s progress during task performance. the robot ’s\\ntactical expressions were compared with more emo-tional, encouraging or disappointed expressions.when the robot ’s behavior was more emotional, team\\nm e m b e r sw e r em o r ea c t i v ei nr e d u c i n gt e n s i o nw h e nthey made mistakes and exhibited more trust-building\\nbehaviors. as discussed in the previous section with\\nrespect to pro-social but low reliability robots, as ro-botic ai behavior becomes human-like, it becomeseasier for users to trust and follow them, regardless ofthe exact task (and the level of reliability). future re-search must address the moderating role of task char-acteristics on the effect of machine intelligence andsocial behaviors in building cognitive trust, not only in\\nlaboratory studies but also in field settings. it is pos-\\nsible that at a workplace, in contrast to a laboratory,trust in a highly intelligent robot would still depend onthe nature of the tasks being performed.\\nimmediacy behaviors\\nincorporating higher levels of machine intelligence\\nhas enabled robots to react to human presence and\\nspeech, creating “social-robots, ”interactive assistants\\nthat are able to serve in roles such as an interactivemuseum guide, team member, or social companion(bickmore, pfeifer, & schulman, 2011; hinds, roberts,& jones, 2004; zhang, kaber, zhu, swangnetr, mosaly,& hodge, 2010). interestingly, while paying less at-tention to robots ’reliability, researchers have explored\\nthe effect of different robots ’behaviors on human\\ntrust. overall, the findings indicate that as the level ofmachine intelligence increases, users expect robotsto be more proactive and adaptive. behaviors thatenhance users ’experienced immediacy, such as so-\\ncial gestures, are generally helpful, and their mere\\npresence seems to affect human behavior and bringabout compliance with a robot ’s requests, even when\\nrobots exhibit mistakes in their behavior. faulty be-havior can reduce trust, but, at least in the short term,compliance continues.\\nbaraglia, cakmak, nagai, rao, and asada (2016)\\nexamined two different autonomous forms of robotic\\nbehavior —reactive and proactive. the goal of the\\nrobot was to assist participants in the performance ofa sequence of tasks. the reactive robot providedhelp only after the participant failed in timely taskperformance. the proactive robot detected partici-pants ’movements, was able to anticipate possible\\nfailures, and initiated help before a task was com-pleted. comparing these conditions and a condition\\nin which the robot was used as a tool (i.e., operating\\nat a low level of intelligence and activated by a human ’s\\nrequest for help), researchers found that the partici-pants not only performed better in the proactive thanin the reactive robot condition but also reported thatthey preferred the proactive robot over the one actingas a tool. other studies provided similar results.hoffman and breazeal (2007) compared teamwork\\nwith reactive and proactive robots, where the pro-\\nactive robot was programmed to anticipate specificbehaviors. they found that people liked the proactiverobot more and rated it as a more productive teammember.\\ndirectly examining the perceptions of trust, de\\nvisser and parasuraman (2011) compared stable andadaptive levels of robot autonomy. in the stable con-\\ndition, the robot always provided assistance, needed\\nor not, whereas in the adaptive condition, the helpwas provided only for difficult tasks. the level of in-tervention had no effect on participants ’performance;\\nhowever, participants reported higher trust in theadaptively automated robot. participants appreciatedthe ability of the robotic assistant to initiate helpingbehavior in the appropriate situations and reported\\nhigher levels of self-confidence and lower levels of\\nworkload when working in the adaptive condition. itseems that timing and fit to the situation may facilitatetrust, perhaps because of their connection to per-ceived higher level of robot machine intelligence.\\noistad, sembroski, gates, krupp, fraune, and\\nˇsabanovi ´c (2016) examined the effect of a robot ’s\\nsocial-oriented behaviors on users ’perceptions and\\nphysical proximity to the robot during a box moving\\ntask. they found that robot ’su s e r - o r i e n t e di m m e -\\ndiacy gestures, such as approaching the user andnodding toward him/her when in proximity, had636 july academy of management annals',\n",
       " 'a positive impact on users ’perceptions of robot ’s\\nanthropomorphism. furthermore, social gestures\\ndecreased the sense of physical risk, and partici-pants kept less distance from the higher immediacyrobot than the robot that did not demonstrate thesebehaviors.\\nin addition to immediacy behaviors executed by ro-\\nbots, researchers addressed s ome interveni ng behaviors\\nthat can improve human trust. for instance, carlson\\net al. (2015) demonstrated that a team-building activity\\nincreases trust in a robotic team member. by contrast,you and robert (2019) found that what increasedtrust in a robot was not a stronger sense of a team butan activity in which participants assembled theirrobot. researchers sug gested that the act of robot\\nassembly increased trust and made the participantsidentify more with their robotic team member.\\nhowever, the differences in these experiments\\ncould also be driven by the assumed machine in-telligence of the robots. in the carlson et al. (2015)experiment, the robot was engaged in a complexsearch activity and, thus, had assumed a high ma-chine intelligence; it was in reality operated remotelyin a“wizard of oz ”methodology (i.e., a human was\\nactually controlling the report, unbeknownst to par-\\nticipants), yet participants perceived it as a highly\\nintelligent, autonomously functioning robot. by con-trast, in you and robert ’s (2019) experiment, the robot\\nhad the role of a water carrier, and, thus, its assumedlevel of machine intelligence was low. therefore, itseems that the perceived level of machine intelligencemoderates not only the steepness of the trust trajec-tory but also the activities and psychological percep-\\ntions that lead to cognitive trust.\\ncognitive trust in virtual ai\\nan ai-enabled virtual agent is a representation in\\nwhich ai has no physical presence, but a distinguishedidentity, such as a chatbot or an avatar (ben mimoun,poncin, & garnier, 2012). virtual representation may\\nexist on any electronic device, and may possess fea-\\ntures such as a face, body, vo ice, or the ability to text.\\ndespite being already in commercial use, much of theexisting empirical research focuses on the aspects ofthe interface design, paying less attention to such fac-tors as level of machine intelligence.\\ntrust trajectory\\nthe trust trajectory of virtual ai suggests that high\\ninitial trust decreases following an interaction (hoff& bashir, 2015). this trajectory differs from trustdevelopment in robotic ai (see figure 1) and is evi-\\ndent in both laboratory and field studies. for instance,\\nde visser et al. (2017) found that in an initial stage ofthe experiment, participants trusted the advice ofvirtualai morethanhuman advice, yet withtime(andfollowing decreasing reliability), this trust decreasedmuch more than the trust in a human adviser. exam-ining the field evidence of the effect of virtual agents,ben mimoun et al. (2012) analyzed their use in com-\\nmercial websites and found that despite the initial\\ninterest in their use, over the years their actual use hadsignificantly decreased. based on interviews and thefact that this problem was specific to virtual agents,researchers suggested that the lack of calibration be-tween an agent ’s representation and its actual level of\\nmachine intelligenceled to customers ’frustration and\\nabandonment. human-like representation of ai may\\nlead to users ’expectations of a high-level machine\\nintelligence, which in many cases does not fit thetechnological reality (ben mimoun et al., 2012).\\ninterestingly, this trajectory can be reversed, with\\nsome evidence for low initial trust in virtual ai.similar to observations made with robotic ai in a fieldstudy (andrist et al., 2016), research found that insome cases, the initial trust in field settings could be\\nlow and lead to an agent ’s misuse and negative be-\\nhavior. for example, kopp, gesellensetter, kr ¨amer,\\nand wachsmuth (2005) analyzed the interaction ofmuseum visitors with a virtual guide. examiningmore than 200 conversations, researchers noted thatalthough most of the visitors tended to greet the vir-tual agent and 20 percent tested the system by askingdirect and indirect questions regarding its abilities, 11\\npercent of the interactions were negative, including\\ninsults and abusive and negative language.\\nin addition, there is some evidence of relatively low\\ninitial trust that increases following an interaction.wang et al. (2016), who examined different typesof recommendation agents, found that the firsthandexperience with a reliable recommendation agentincreased participants ’trust in comparison to the\\nthirdhand experience. this suggests that when virtual\\nai has high machine intelligence and is highly func-tional, similar to the case of robotic ai, direct in-teraction can increase the initial trust.\\nto explain the differences of trust trajectories in\\nvirtual ai, researchers suggest addressing the cali-bration between users ’expectations and virtual ai\\nperformance. features of virtual ai, such as visuali-\\nzation, and especially anthropomorphism, may sig-\\nnificantly increase users ’expectations, whereas the\\nactual level of ai machine intelligence moderates thedirection of the trust trajectory. when agents with2020 637 glikson and woolley',\n",
       " 'low machine intelligence are paired with human-\\nlike representations, the users are more likely to start\\nwith high expectations and experience a trust de-crease. by contrast, virtual agents with high machineintelligence can engage in higher immediacy be-haviors, which facilitates a positive trust trajectory.\\ntangibility\\nthe existing research supports the notion that the\\nvisual presence of human-like or animal-like virtualai agents increases initial cognitive trust in com-parison to a lack of visualization. this means thattangibility has a positive effect on cognitive trustin ai, similar to its effect on robotic ai. examiningthe effect of a visually present agent, chattaraman,kwon, gilbert, and li (2014) found that adding an\\navatar ’s picture on a shopping website increased\\nparticipants ’trust and intention to visit the website\\nagain. similarly, mumm and mutlu (2011) found thatwhen feedback for a categorization task was pro-duced by an agent (in the form of a robotic picture),participants reported higher intrinsic motivation incontrast to the condition without explicit visualiza-tion. however, wang et al. (2016) argued that visu-\\nalization mostly influences the emotional trust and\\nnot cognitive trust, as it has less impact on the per-ception of usefulness. in their study, wang et al.(2016) manipulated the presence of a visual agentand the presence of a detailed explanation of theagent ’s recommendation and found that the agent ’s\\ntransparency had a greater effect on cognitive trustthan adding a visual representation.\\ntransparency\\none way to moderate unrealistically high ex-\\npectations from users is to provide an explana-tion regarding virtual ai functionality. exploringthe role of transparency in facilitating trust in ai,pieters (2011) suggested a distinction between\\nexplanation-for-trust and explanation-for-confi-\\ndence. pieters argued that confidence could be seenas a reliance on technology without considering al-ternatives, whereas trust requires comparison be-tween different options. explanation-for-trustaddresses the way the system works, the “how”\\nquestion, by revealing details of its internal opera-tions. by contrast, explanation-for-confidence\\nmakes the user feel comfortable in using the system\\nby providing information about its external com-munications, explaining “why”an algorithm should\\nbe used.in building on this distinction, wang and benbasat\\n(2007) looked at the recommendations of virtual\\nagents and manipulated the transparency of the al-gorithm by providing explanations about why andhow the agent made its decision, and what the al-ternatives were. consistent with pieters (2011), theyfound that the explanation for how a decision wasmade influenced consumers ’beliefs in the compe-\\ntence and benevolence of the virtual agent. the\\ntransparency regarding the choice (i.e., why some-\\nthing was chosen) influenced only the perceptions ofagent benevolence. this is consistent with the extantliterature on the effect of explanations on trust forvirtual ai (see xiao and benbasat, 2007 for review).\\nan additional way in which transparency could be\\nhelpful for establishing trust is when the reliability ofthe virtual agent is transparent. for instance, fan et al.\\n(2008) demonstrated that informing participants re-\\ngarding the actual reliability of a decision-makingagent increased participants ’trust and improved\\nperformance. when the tra nsparent reliability was\\nlow, participants better adjusted their decisions,taking into consideration the agent ’s advice only\\nwhen appropriate. the ability to know when to usethe virtual agent increased the overall trustwor-\\nthiness of the agent.\\nreliability\\nreliability plays an important role in users ’trust\\nand trusting behaviors in virtual ai, which differsfrom robotic ai. moran et al. (2013) examined com-pliance with voiced agent instructions in a street\\nteam-based game and found that compliance was\\nhighly dependent on trust in the agent. when agentreliability was compromised, such as when the in-structions led to no revelation of new cues, trustdecreased, which also decreased the compliance. itseems that experiencing (without advance knowl-edge) a virtual ai agent ’s low reliability significantly\\ndiffers in its effect on trust than simply being aware of\\nthe possibility of low reliability. the actual experi-\\nence decreases the trust, whereas the transparencyregarding ai ’s possible errors may increase the trust.\\nlooking beyond ai reliability, researchers have sug-\\ngested the importance of focusing on the consistency/inconsistency between users ’expectations and the\\nactual ai performance. factoring in the levels of ini-tialtrust allows researchers to better predict the effects\\nof virtual ai behavior. this mechanism was found to\\nexplain users ’trust across different studies (xiao &\\nbenbasat, 2007). glass, mcguinness, and wolverton(2008) interviewed users of an office assistant agent638 july academy of management annals',\n",
       " 'and found that correct expectations regarding the\\nagent ’s performance and capabilities facilitated trust\\nin the agent.\\ntask characteristics\\nvirtual ai is perceived as having benefits with\\nrespect to technical issues, such as analyzing data,which is similar to robotic ai. ramchurn et al. (2016)\\ncompared human compliance with agent versus hu-\\nman instructions in the context of a response to a di-saster and found that under virtual agent instructions,the performance was better because of the agent ’s\\ngreater capabilities of gathering information anda clearer method of wording instructions.\\ntesting compliance with a virtual agent, jiang et al.\\n(2014) found that a virtual agent playing the role of\\ngame instructor was highly trusted, as its orders were\\nusually followed ( 91 percent compliance). however,\\nthis compliance depended on whether the instruc-tions were aligned with team dynamics. when thev i r t u a la ia g e n t ’s orders required a dramatic change of\\nteam dynamic or interfered with accomplishing a dif-ferent task, the compliance decreased to less than 40percent. it is possible that when instructions were\\ninterfering with the way the game was played, the\\nplayers perceived ai as less intelligent and, therefore,less trustworthy.\\nhigh machine intelligence allows virtual ai to be\\nused to influence interaction between humans. for in-stance, de melo, marsella, and gratch (2017) found thathumans represented by virtual agents led people to actmore fairly toward other humans than humans without\\nsuch representation. isbis ter, nakanishi, ishida, and\\nnass (2000) found that the abi lity of an ai-driven agent\\nto match safe vs. unsafe topics for a discussion influ-\\nenced the cultural perceptions of american and japa-nese participants regarding each other and their actual\\nbehavior. safe topics inc luded movies, music, and\\nsports, and ai-driven agents who were “safe”would\\nask questions on the safe topic at any time they would\\na s s e s sal o n gp a u s ei nac o n v e r s a t i o n .a n “unsafe\\nagent ”asked questions on issues like politics, religion,\\nand money. in a “safe agent ”condition, americans felt\\nmore trust in japanese partners and had a more positiveperception about japanese people in general. japanesestudents in the “safe agent ”condition found americans\\nto be more similar to them. kr ¨amer et al. (2017) found\\nthat communication with an interacting agent de-\\ncreases participants ’need to engage in social activities,\\nas they sought less human interaction after using ai.\\nintroducing ai as a team member may also influence\\nthe interaction between people in the team, and evenalter team cognition and team communication pat-\\nterns (demir, mcneese, cook e ,b a l l ,m y e r s ,&f r i e m a n ,\\n2015; demir, mcneese, & cooke, 2017). specifically,demir et al. (2017) found that human members oft e a m sw i t ha na i “peer”(referred to as a “synthetic\\nmember ”) made significantly fewer information ex-\\nchanges than teams with only human members.\\nimmediacy behaviors\\nhigh levels of machine intelligence allow virtual\\nai to enact more immediacy behaviors that increasetrust, such as social responsiveness and personali-zation of the virtual ai agent ’s reactions. pro-social\\nvirtual ai ’s behaviors can be translated to perceptions\\nof the agent ’s personality. andrews (2012) demon-\\ns t r a t e dt h a ta na g e n t ’s pro-social behaviors led partic-\\nipants to perceive a high level of agent agreeableness,\\nwhich was associated with higher trust in the agent.\\nkomiak and benbasat (2006) manipulated the levelof personalization provided by different recom-mendation agents, using eit her personal or general\\nquestions asked by the agent. they found that per-sonalization had a significant positive impact onusers ’cognitive trust.\\na virtual agent ’s persuasion tactics can also be\\nimportant. fenster, zuckerman, and kraus (2012)found that an agent that provided examples was moreinfluential than an agent that provided justificationsand more persuasive than an agent that presented thesubject with both examples and justifications. what isparticularly intriguing about this finding is that itsuggests that the effectiveness of virtual ai persuasion\\ntactics could differ from tactics that typically work\\nwell for humans, where using both examples andjustifications was found to be more effective.\\ncognitive trust in embedded ai\\ncompletely embedded ai is “invisible ”to users,\\nwhich means that it does not have a visual repre-\\nsentation or a distinguished identity. it could be\\nembedded in different types of applications, such asa search engine or a gps map, and users might be notaware of its existence. assuming users are aware ofembedded ai, there is still an important question ofwhat features engender cognitive trust. similar tovirtual ai, cognitive trust in embedded ai differsfrom robotic ai in that it is more driven by its re-\\nliability and transparency. similar to robotic ai, the\\nperceived level of expertise or machine intelligencealso plays an important role in cognitive trust, as wellas the type of task involved, as people believe that2020 639 glikson and woolley',\n",
       " 'algorithms are better at calculation tasks than at so-\\ncial tasks. as the level of machine intelligence in-\\ncreases, the contextual and user-centered factorsbecome more important for cognitive trust becauseit becomes more difficult to assess ai reliability.\\ntrust trajectory\\nresearch assessing the trajectory of cognitive trust\\nin embedded ai has mostly focused on the way trust\\nin ai changes based on the feedback regarding itsaccuracy. many laboratory-based studies have dem-onstrated that people tend to exhibit high initial trustin embedded ai as an algorithmic decision-providingsoftware (de visser et al., 2017; dietvorst, simmons, &massey, 2015; manzey, reichenbach, & onnasch,2012). high initial trust tends to decrease as a result\\nof erroneous ai function, and the process of trust\\nrestoration requires a lot of time.\\nthe few field studies that exist also demonstrate\\nhigh initial trust in embedded ai. for instance, re-searchers examining the effect of wearable algorith-mic sensors on users ’emotions found that users\\ndemonstrated a high level of trust in the sensors andthat their emotions were significantly influenced by\\nthe feedback they received (hollis, pekurovsky, wu,\\n& whittaker, 2018). researchers who studied thecases of uber and lyft drivers also reported highinitial trust. for instance, lee, kusbit, metsky, &dabbish (2015) tested drivers ’experience with an ai-\\nenabled management system and found that theyperceived the passenger –driver rating system as ef-\\nficient in establishing basic trust and service atti-\\ntudes in the ridesharing systems. however, they also\\nfound that low levels of transparency lead drivers tosocial forums, where they could not only make senseof the system but also gain knowledge about ways ofresisting or abusing it. m ¨ohlmann and zalmanson\\n(2017) also found that while they kept using thesystem, uber drivers did not trust its managerialdecisions and engaged in a variety of actions to resist\\nits management, including gaming the system.\\nthere is also evidence of low initial trust in em-\\nbedded ai, especially in field studies, where themistrust could be so high that users may refuse usingthe embedded ai in the first place (christin, 2017).however, field studies that assess trust in embeddedai in organizational settings are scarce. healthcareresearchers examining how algorithmic decision\\naids are being used (or not used) by physicians report\\nsignificant difficulties in acceptance of the tech-nology in medical settings (linkov et al., 2017;panella, marchisio, & di stanislao, 2003). in a fieldexperiment on energy use, alan, costanza, fischer,\\nramchurn, rodden, and jennings (2014) found that\\nparticipants avoided using an algorithm that wasdesigned to help them save on their electricity bills.the refusal to use the technology further prevents thehands-on experience that would increase trust. thiscould explain why commercial companies are eva-sive about their use of embedded ai (e.g., eslamiet al., 2015). future research must consider the role\\nof trust in ai within organizations to better un-\\nderstand the specific difficulties that need to betackled to facilitate its use.\\ntangibility\\nthe embedded nature of ai representation sug-\\ngests that people may not be aware that they are using\\nan algorithm-enabled application. currently, re-\\nsearch of the impact of embedded ai on users ’\\nawareness on trust is very limited. in one study,eslami et al. (2015) surveyed facebook users andfound that more than half of them (62 percent) werenot aware that an algorithm was managing the in-formation that was displayed to them, making de-cisions on what should be hidden. learning about\\nthe algorithm ’s way of working changed users ’at-\\ntributions, perceptions, and behaviors, and overallincreased their sense of control. revealing (or hid-ing) the use of an algorithm may not only raise im-portant ethical questions but also have a significantimpact on users ’long-term trust. however, eslami\\net al. (2015) found that, despite being unpleasantlysurprised or even angry for not being informed about\\nthe use of an algorithm, after learning how it worked,\\nparticipants kept using the platform. future researchneeds to explore the limitations for users ’trust re-\\ncovery in such situations, and the true cost andbenefit of users ’awareness.\\ntransparency\\nlooking for ways to overcome the aversion driven\\nby technology error, researchers have examined therole of transparency on cognitive trust. for instance,mohlemann and zalmanson (2017) focused on uberdrivers and noted that the lack of algorithm trans-parency leads drivers to constantly guess and gamethe system. lee et al. (2015) reached a similarconclusion.\\ndzindolet et al. (2003) used explanations of the ra-\\ntionale behind possible mistakes made by the ma-chine and demonstrated that such explanations hada significant positive effect on trust. supporting the640 july academy of management annals',\n",
       " 'notion of the positive effect of transparency in de-\\nveloping trust in ai, chao, chang, wu, lin, and chen\\n(2016) found in a survey of more than 700 participantsthat understanding the technological capabilities ofai embedded in a search engine positively correlatedwith reliance on the technology and belief in the us-ability and ease of use of the technology. althoughthis study did not directly assess trust in ai, its resultsregarding the perceptions of low risk and high re-\\nliance suggest a positive relationship between ac-\\nknowledgement of ai capabilities and trust.\\nhowever, not all provided information has a simi-\\nlar effect. helldin, falkman, riveiro, and davidsson(2013) showed that when drivers of a simulated au-tonomous vehicle were warned about the situationaluncertainty that would lead an algorithm to err, theyreported lower trust and were quicker to retake man-\\nual control over the car than participants who did not\\nget the warning. kizilcec (2016) investigated trust inan algorithmic peer-reviewing system and found thatwhen participants ’expectations of their outcome\\nwere violated, the explanation regarding how the al-gorithm worked facilitated trust. however, when theexplanation included the raw scores in addition to thealgorithmic action description, the levels of trust went\\ndown. the author suggested that the introduction of\\nadditional data was confusing, which underminedthe positive effect of the algorithm transparency.\\nfollowing pieter ’s framework (2011) that differ-\\nentiates explanations of how algorithms work into“why”versus “how, ”cotter, cho, and rader (2017)\\nexamined the way facebook provided explanationsabout its news feed algorithm. they found that most\\nof the information targeted the question of “why”\\nthis algorithm should be used, rather than “how”it\\nworked, and suggested that such explanation wouldimprove users ’confidence in the system, rather than\\ntheir trust in the system. however, the researchersfocused on the company ’s behavior rather than users ’\\nperceptions, and thus the impact of the explanationon users ’trust is not certain. the importance of un-\\nderstanding “how”the algorithm works is also evi-\\ndent in studies that allowed users to slightly modifythe algorithm (dietvorst, simmons, & massey, 2016).\\nthe embeddedness of ai can also lead to questions\\nregarding who it is intended to benefit, and therebyundermine trust. alan et al. (2014) demonstrated thattransparency about the actual beneficiary of the de-cision aid is another important consideration. in\\na field experiment, participants were asked to test an\\napplication that aimed to reduce their electricityexpenses. however, participants questioned the truerecipients of the benefits of ai: was it them or theelectric company (alan et al., 2014)? these issues are\\nless likely to surface in laboratory studies, as com-\\nmercial interests are less likely to be involved.\\nthe complexity of ai algorithms rarely allows for\\nfull transparency about the basis of its decisions andthe trade-offs it makes (ananny & crawford, 2018).however, communication regarding embedded-airationale and its actual abilities may significantlyimprove the calibration of users ’expectations re-\\ngarding ai performance. better calibration might\\nlower the initial, unrealistically high trust that wasobserved in laboratory studies, while improving therecovery of trust in the case of an erroneous outcome,allowing users to build more effective long-termcollaboration with the technology (hoff & bashir,2015).\\nreliability\\nresearch that tested the levels of trust driven by ai\\naccuracy and failure has revealed a stable pattern,indicating that errors of an embedded-ai are detri-mental to cognitive trust. for instance, dzindoletet al. (2003) tested an automated decision aid andfound that errors significantly decreased trust and\\nreliance on the aid. separating between visibility of\\nan error and performance feedback across many tri-als, researchers have demonstrated that the visibilityof an error effects trust in a way that is difficult torepair. similarly, manzey et al. (2012) found that an\\nerroneous function had a stronger effect on trust thana correct function, and that the trust recovery processwas very long. consequently, researchers have con-\\ncluded that positive and negative feedback loops are\\nnot symmetrical. dietvorst et al. (2015) demon-strated a similar effect of an erroneous function, re-ferring to it as algorithm aversion . across five\\nstudies, researchers found that participants refusedto rely on a forecasting model after seeing it err. par-ticipants preferred to rely on a human forecast and noton an algorithm, even when human errors were more\\nsevere than algorithm errors.\\ntask characteristics\\nalthough ai is assumed to perform better on tasks\\nthat involve mathematical skills, such as workscheduling, this advantage is not always evident inthe empirical studies. for instance, lee (2018) did not\\nfind a significant difference in initial trust between ai\\nand human decision-making for analytical tasks.however, for tasks that involve human skills, such aswork evaluation, participants demonstrated higher2020 641 glikson and woolley',\n",
       " 'trust in human decisions than in algorithmic\\ndecisions.\\nthe subjective value of self-confidence also plays\\nan important role in trust, as people who perceivethemselves as more capable than a machine are lesstrustful and tend to rely less on the technology(lewandowsky, mundy, & tan, 2000). logg, minson,and moore (2018) found that experts used ai-pro-vided advice less than lay participants did, even\\nwhen ignoring it decreased experts ’performance.\\nresearchers explained this finding by referring toevidence of experts being less appreciative of others ’\\nadvice than nonexperts, suggesting that experts tendto rely more on their own opinion.\\nimmediacy behaviors\\nmost of the studies considering immediacy be-\\nhaviors exhibited by robotic and virtual ai that werereviewed indicated a positive impact on trust; how-ever, it seems that such behaviors can highlight theability of embedded ai to constantly monitorworkers and lead to a decrease of trust. in a study ofuber drivers, mohlemann and zalmanson (2017)suggested that constant individual performance\\nevaluation and feedback, only possible through\\nconstant tracking, violates drivers ’sense of auton-\\nomy and decreases their trust. such constant sur-veillance is perceived as micro-management andconveys a lack of trust from those deploying the ai,which leads to low trust among the drivers.\\nlee et al. (2015) suggested an additional explana-\\ntion of the drivers ’decrease of trust. following a set\\nof interviews, they concluded that a lack of person-\\nalization was a key factor that decreased trust. thesystem lacked consideration of many specific cir-cumstances, such as female drivers rejecting malepassengers late at night for safety reasons. highlyintelligent systems should be able to engage in moreimmediacy behaviors, such a s personalization, which\\ncan improve the sense of fairness and trust.\\nadditional support for the effect of personaliza-\\ntion could be found in three field studies conductedby matz, kosinski, nave, a nd stillwell (2017). re-\\nsearchers tested the effects of psychological persuasionon 3.5 million individuals using psychologically tai-lored advertising and found that matching the content\\nof persuasive appe als to individuals ’psychological\\ncharacteristics significan tly altered participants ’be-\\nhavior as measured by clicks and purchases. specifi-\\ncally, they found that persuasive appeals that werematched to peoples ’level of extraversion or open-\\nness-to-experience resulted in up to 40 percent moreclicks and up to 50 percent more purchases than\\ntheir mismatching or nonpersonalized counterparts.\\nembedded ai can also produce immediacy be-\\nhaviors through an activation of nudges or boosts. anudge (e.g., a default option) is a change in the choicearchitecture that shifts human behavior by takingadvantage of basic cognitive processes and biases(e.g., inertia, procrastination, and loss aversion). bycontrast, a boost (e.g., better information) is a change\\nin the choice architecture that shifts behavior by clar-\\nifying the direction an individual should move toachieve personal objectives, which is often accom-plished by enhancing an individual ’s decision-making\\ncompetencies (camilleri, cam, & hoffmann, 2007).analyzing the possible effects of nudges and boostsgenerated by intelligent systems, burr, cristianini,and ladyman (2018) suggested that despite the overall\\nagreement that nudges should be used for benefiting\\nusers, they might function a s coercive and deceptive\\ntools that could redirect user behaviors toward un-\\ndesirable outcomes. the deceptive nature of nudgesrequires further research that reflects not only the effectof nudges on trust but also the ethical aspects of the useof nudges by ai.\\nbuilding emotional trust in ai\\nemotional trust is not commonly addressed in hu-\\nman relations with technology; however, emotionsare known to significantly affect human trusting be-haviors (hoff & bashir, 2015). furthermore, ai de-velopers specifically target human emotions bymanipulating features of ai representations and\\nbehaviors. making a robot or a bot to look or act like\\na human or a living thing is known to affect users ’\\nemotional reactions toward the technology. how-ever, the effect is not always positive, and may alsoresult in negative emotions, such as a sense ofeeriness and fear. even more surprisingly, someresearchers have found that people experiencedmore positive emotions to ward an erroneous than\\na correctly functioning robot ( e.g., mirnig, stollnberger,\\nmiksch, stadler, giuliani, & tscheligi, 2017). there-fore, in addition to understanding users ’cognitive\\ntrust, there is a growing need to understand what andhow such features of the technology affect humanemotions and emotional trust.\\nto organize the review of the empirical research\\non emotional trust in ai, we address the dimensions\\nwhich were studied the most in this regard, specifi-\\ncally the role of tangibility, anthropomorphism, andimmediacy behaviors (see table 2 for an overview).although tangibility and immediacy behaviors were642 july academy of management annals',\n",
       " 'previously discussed with regard to their impact on\\ncognitive trust, anthropomorphism was rarely men-tioned. anthropomorphism , that is, human-likeness,\\nrefers to the perception of technology or an object ashaving human qualities, such as feelings. these per-\\nceptions could be driven by interface features, such as\\nthe human-like form of the robot; by behavioral fea-tures, such as gaze and node; and by intentionalframing, such as giving a robot or bot a human name.\\nemotional trust in robotic ai\\ntangibility. robots are known for evoking a vari-\\nety of emotional reactions in human users, including\\nexcitement, but also fear and a sense of eeriness. incontrast to the overall positive effect of tangibility oncognitive trust, its effect on emotional trust is mixed,and might depend on the attitudes of the user. al-though some people tend to enjoy the physical pres-ence of a robot, others find its tangibility threatening.focusing on the psychological mechanism that ex-\\nplains humans ’predisposition to tr ust robots, nomura,\\nsuzuki, kanda, and kato (20 06), studying japanese\\nstudents, developed a nega tive attitude toward robots\\nscale (nars) that has been used in many hri studies.for instance, in a scenario- based study, tussyadiah,\\nzach, and wang (2019) found a strong negative corre-lation between nars and tr usting beliefs regarding\\nfunctionality, helpfulness , and reliability of serving\\nrobots. bartneck et al. (2006) found that cultural back-\\nground plays an important role in forming attitudes\\ntoward robots, with u.s. participants having the mostpositive perceptions.\\nthe tangibility of a robot can be influenced by its\\nphysical posture. following nomura et al. ’s (2006)\\nsuggestion regarding negative predispositions to-ward autonomous (i.e., ai-enabled) robots, obaid,sandoval, zlotowski, moltchanova, basedow, and\\nbartneck (2016) examined the physical distance\\nbetween a human and human-like robot in a taskthat required physical proximity. the researchersfound that people were more willing to approacha sitting robot than a sta nding one. users inter-\\npreted the posture as a signal of possible physicalrisk that reduced trusting behavior. the emotional\\nsubscale of the nars was significantly correlated\\nwith the kept distance, whereas users with prior\\nexperience were more willing to approach the robot(obaid, salem, ziadee, boukaram, moltchanova, &sakr, 2016).table 2\\nmain effects of dimensions on emotional trust in ai, organized by representation\\ndimensions robotic ai virtual ai embedded ai\\ntangibility physical presence may not only\\nincrease liking but also inducefear.presence of a “persona ”increases liking and\\nemotional trust.being unaware of ai use may\\nevoke anger. positiveemotions could be driven bygood reputation of\\na developing firm.\\nselected\\nreferencesobaid et al. (2016b), shim & arkin\\n(2014)chattaraman et al. (2014), de visser et al. (2017),\\npak et al. (2012), qiu & benbasat (2009)eslami et al. (2015), hengstler\\net al. (2016)\\nanthropomorphism human-likeness mostly increases\\npositive emotions, but can also\\ncause discomfort.mostly increases trust, but also creates high\\nexpectations regarding ai ’s abilities.\\nattractiveness and personalization, such as\\nethnicity or facial similarity to the user,increase trust.\\nselected\\nreferencesappel et al. (2016), jacq et al.\\n(2016), zhang et al. (2010),\\nzłotowski et al. (2016)khan & sutcliffe (2014), obaid et al. (2016a),\\nverberne et al. (2015), von der p ¨utten et al.\\n(2010)\\nimmediacy\\nbehaviorshuman-like behaviors induce\\nhigh emotional trust; erroneous\\nrobots are liked more than\\nflawless ones.human-like behaviors increase trust and\\nliking, yet the effect depends on users ’\\npredispositions.\\nselected\\nreferencesbickmore et al. (2013), birnbaum\\net al. (2016), jung et al. (2013),\\nmirnig et al. (2017), sandoval\\net al. (2016)ben mimoun et al. (2017), dabholkar & sheng\\n(2012), kaptein et al. (2011), matsui &\\nyamada (2019)2020 643 glikson and woolley',\n",
       " 'at the same time, there is also evidence of the\\npositive effect of robotic tangibility. for instance,\\nshim and arkin (2014) showed that elderly partici-pants reported that feedback provided by a robot wasmore enjoyable, motivating, and trustworthy thanone delivered by a computer screen. it seems thatwhen the initial predispositions toward robots are notnegative, such as in the case of u.s. users (bartnecket al., 2006), tangibility may increase emotional trust.\\nthus, the preexisting attitudes of users could be an\\nimportant moderator of the effect of ai agent tangi-bility on the development of emotional trust.\\nanthropomorphism. anthropomorphism, that is,\\nhuman-likeness, is generally thought to have a posi-tive effect on human perceptions and emotions.however, there is also evidence for its negative effect.while examining anthropomorphic robots, some re-\\nsearchers have built on the uncanny valley theory\\n(mori, 1970), which argues that an encounter withan artificial agent that possesses human-like featuresleads to an experience of eeriness or a sense of un-pleasantness that brings to mind thoughts of mortality(ho & macdorman, 2010; z łotowski, yogeeswaran, &\\nbartneck, 2017). research based on these theoriesexamines the negative effects of human-likeness on\\nusers ’perceptions and emotional trust. z łotowski,\\nsumioka, nishio, glas, bartneck, & ishiguro (2016)examined human interactions with machine-like andhuman-like robots and found that the machine-likerobot was perceived as more empathetic and moretrustworthy than the human-like robot, regardless ofits positive or negative attitude (z łotowski et al., 2016).\\nappel, weber, krause, and mara (2016) compared\\nparticipants ’perceptions of a robot based on detailed\\ndescriptions. they found that when a robot wasdescribed as more human-like and having greateragency, it was perceived as uncannier than a less in-telligent robot. in the same vein, z łotowski et al. (2015,\\n2016) found that a human-like robot induced higherlevels of participant anxiety than a machine-like robot.\\ninterestingly, the studies that reported a negative\\neffect of anthropomorphism on human emotions and\\nemotional trust examined mostly the initial trust,based on a short interaction or description. it seemsthat increasing interaction experience with a tangi-ble, human-like robot may decrease a sense of un-pleasantness (z łotowski et al., 2015). it is also possible\\nthat the mismatch between a robot ’s appearance and\\nits machine intelligence is a significant source for\\nnegative impressions. although it is assumed that\\nhuman-level machine intelligence (general ai) mayevoke emotional discomfort and fear, this type ofmachine intelligence currently does not exist. in thecurrent state, low emotional trust could be evoked by\\nan anthropomorphic robot that lacks any intelligence,\\nas in the case of z łotowski et al. ’s (2015) study of\\na human-like robot.\\ndespite some of the research pointing to the neg-\\native effects associated with human-likeness, mostof the empirical research focuses on positive emo-tions, such as excitement, curiosity, and liking,which are the results of interactions with robots.\\nhigh levels of interest an d acceptance of robots\\nare evident across different populations, includingchildren and the elderly (jacq, lemaignan, garcia,dillenbourg, & paiva, 2016; strohkorb, fukuto,warren, taylor, berry, & scassellati, 2016; zhanget al., 2010). for instance, zhang et al. (2010) testeddifferent features of a service robot with elderlyparticipants and found th at more human-like fea-\\ntures of the robot were associated with more emo-\\ntional trust and the pleasantness of the interactionexperience. furthermore, anthropomorphism hada positive impact on users ’physiological parame-\\nters, such as heart rate. the positive power of an-thropomorphism was also demonstrated by waytzet al. (2014), who anthropomorphized an autono-mous vehicle by giving it a name and a voice. the\\nresults indicated that an anthropomorphized car\\nwas more trusted and less blamed for errors thanone that was simply mechanical.\\nimmediacy behaviors. in contrast to the human-\\nlike appearance, human-like behaviors consistentlyinduce high emotional trust and liking in robotic ai.bickmore, vardoulakis, and schulman (2013) testedthe effectiveness of a robot museum guide and found\\nthat its responsiveness had a significant effect on\\nvisitors ’engagement, learning, enjoyment, and trust.\\nbirnbaum, mizrahi, hoffman, reis, finkel, and sass(2016) found that robot responsiveness increasednonverbal approach behaviors such as leaning to-ward the robot, eye contact and participants ’smiling,\\nand their willingness to be accompanied by the ro-bot during stressful events. jung, lee, depalma,\\nadalgeirsson, hinds, & breazeal (2013) focused on\\nback-channeling (i.e., inte ractional cues of active\\nlistening, which are mostly nonverbal, such as nod-ding or moving toward) as an engagement strategyof a robot. they found that this type of behaviordisplayed by a robot lo wered participants ’stress\\nand cognitive load.\\nan intriguing study examined how participants\\nreact to an attempt by a robot to deceive in a re-\\nciprocal game. the robot “bribed ”participants by\\nintentionally letting them win (i.e., changing be-havior to the benefit of the participant) in one task644 july academy of management annals',\n",
       " 'and afterward asked them to help in a task that would\\nbenefit the robot. researchers reported that the ro-\\nbots’deceptive behavior had no effect on partici-\\npants ’behavior, as almost all participants agreed to\\nhelp the robot regardless of its actions. interestingly,participants rated the cheating robot as more likablethan the honest one, perhaps attributing its behaviorto a prosocial intention (sandoval, brandstetter, &bartneck, 2016).\\nusers like not only a “dishonest ”robot, but also an\\nerroneous robot, sometimes even more than they likethe one that does not make any mistakes. mirnig et al.(2017) intentionally designed a robot that makeserroneous explanations and compared users ’liking\\nand perceptions of anthropomorphism and intelli-gence. they found that the erroneous robot was likedmore than a flawless one, and that other perceptions\\nwere not affected (mirnig et al., 2017). similarly,\\nragni, rudenko, kuhnert, and arras (2016) found thatpeople experienced more positive emotions towarda robot that demonstrated less than perfect memoryskills in comparison to a flawless memorizing robot.although ragni et al. (2016) suggested that higherliking could be explained by a lowered sense ofcompetition with an erroneous robot, it is possible\\nthat the uncanny valley theory also provides a valid\\nexplanation, suggesting that a human-like, flawlessrobot could induce higher levels of discomfort thanone that makes mistakes(groom, nass, chen, nielsen,scarborough, & robles, 2009). future research shouldfurther explore the reasons for the positive emotionalreaction toward imperfect functioning anthropomor-phic robots.\\njust as with anthropomorphic behavior, high-im-\\nmediacy animal-like behaviors can also induce emo-tional trust. examining human reactions to a dog-likerobot, lee, park, and song (2005) found that the robot ’s\\nability to improve its responsiveness had a significanteffect on the robot ’s likability and humans ’trust and\\nincreased the willingness to spend more time with it. itseems that behaviors that reflect social intelligence,\\nsuch as social gestures, responsiveness, active listen-\\ning, back-channeling, learning, and even cheating( f o rt h eb e n e f i to ft h eu s e r ) ,h a v em o r ec o n s i s t e n ta n dprofound impact on emotional trust than the featuresrelated to the robot ’s appearance. furthermore, even\\nwhen the initial trust is low, experiencing an in-teraction with a pro-social robot will increase trust.\\nemotional trust in virtual ai\\ntangibility. research suggests that for virtual ai,\\ntangibility has mostly positive effects on emotional trust(de visser et al., 2016; pak, fink, price, bass, & sturre,\\n2012; qiu & benbasat, 2009; waytz et al., 2014).\\nchattaraman et al. (2014) found that the presence ofa“persona ”in a mock retail website significantly re-\\nduced the anxiety of older users, increasing perceivedsocial support. similarly, qiu and benbasat (2009)demonstrated that virtual embodiment of a recommen-dation agent significantly improved users ’enjoyment\\nand trust, increasing perceptions of social presence.\\nit seems that tangibility of virtual agents may even\\ninduce a physiological effect. de visser et al. (2017)found that oxytocin had an impact on human trust inan anthropomorphic agent, leading participants totrust a virtual agent more than an embedded ai (i.e.,ai that has no tangible identity). the connection ofoxytocin to trust in the virtual agent suggests thatpeople tend to perceive such agents as social actors,\\nreacting similarly even on a physiological level.\\nanthropomorphism. by contrast with tangibility,\\nanthropomorphism has more mixed effects on emo-tional trust in virtual ai. culley and madhavan (2013)suggested that anthropomorphic characters are oftendepicted as capable of human qualities, including rea-soning and motivation, which can induce very high ex-pectations and initial trust. because these expectations\\nare unrealistic, however, high expectations of anthro-\\npomorphic characters are designed to fail. ben mimounet al. (2012) su ggested that poor calibration between\\nvirtual agents ’appearance on commercial websites and\\ntheir actual performance drove customers ’distrust\\nand abandonment, which in turn caused the websiteowners to stop using the agents.\\nanthropomorphic features provide the opportu-\\nnity to manipulate virtual ai appearance in different\\nways, making it more attractive and thus increasingits likability (bartneck, kuli ´c, croft, & zoghbi, 2009;\\nbeldad, de jong,& steehouder, 2010; khan& sutcliffe,2014; obaid et al., 2016a; pak et al., 2012; verberne,ham, & midden, 2015). for instance, khan andsutcliffe (2014) found that the visual representationof virtual ai has a significant impact on human\\ncompliance. by comparing agents presented through\\ntwo slightly different female images, the authorsfound that the more visually attractive agent wassignificantly more persuasive for both male andfemale participants. personalization of ai interfacefeatures may also increase likability. researchershave suggested that to be effective in the globalmarket, a virtual agent sh ould conform to different\\ncultural preferences, including language, commu-\\nnication patterns, and facial characteristics such asthose that are associated with an ethnicity (culley &madhavan, 2013). some empirical studies support2020 645 glikson and woolley',\n",
       " 'this notion, demonstrating that when the ethnic\\nfacial features of a virtual agent match a cultural\\ngroup, it increases users ’emotional trust (obaid\\net al., 2016a). relatedly, while examining the per-sonalization of an agent ’sv i s u a li m a g e ,v e r b e r n e\\net al. (2015) found that when an agent was repre-sented by a face whose features were adjusted basedon the face of the user, the users reported higherlevels of trust while using a driving simulation and\\nwere more willing to allow the agent to choose the\\nroute.\\nthe issue of anthropomorphism of a virtual agent\\nleads to an additional question: to what extent doesit matter if the virtual agent represents ai or anotherhuman? the interest in virtual platforms such assecond life has made possible the use of avatars forrepresenting humans in the virtual space in different\\ncontexts, including business interactions. empirical\\nresearch has followed this trend, testing the effect ofsuch representation on human reactions in generaland trust in particular. in a meta-analysis of 32 stud-ies, fox, (grace) ahn, janssen, yeykelis, segovia, &bailenson, 2015 found that when avatars were pre-sented to users as humans, they were more influ-ential than when they were presented as ai-based.\\ninterestingly, the influence was more evident in\\nobjective (behavioral) rather than subjective (self-report) measures. it is important to note that theframing of the avatar as human or as ai had a strongerimpact on participants ’perceptions than the actual\\nlevel of intelligence or control over the character(von der p ¨utten, kr ¨amer, gratch, & kang, 2010).\\nlooking further into the differences between hu-\\nman avatars and intelligent agents activated by ai,\\nresearchers have found that when talking to ai peo-ple tend to engage less in impression managementand to disclose more sensitive personal informationthan when talking to a human (gratch, lucas, king, &morency, 2014; kr ¨amer et al., 2017; lucas, gratch,\\nking, & morency, 2014). this tendency implies thepotential for higher emotional trust in ai than in\\nhumans.\\nimmediacy behaviors. the interactive abilities\\nof virtual ai were mostly found to facilitate users ’\\npositive emotions, emotional trust, and satisfaction.kaptein, markopoulos, de ruyter, and aarts (2011)found that positive feedback about the ongoing con-versation or social praise provided by an ai virtualagent increased its perceived friendliness. dabholkar\\nand sheng (2012) demonstrated that an interac-\\ntional recommendation agent made users get moreinvolved in the process which led to higher satis-faction and trust. matsui and yamada (2019) revealedthat a virtual agent that used hand gestures and ex-\\npressive facial movements led to more positive\\nemotional contagion than a virtual agent that wasless expressive.\\nhowever, the effect of immediacy behaviors on\\nemotional trust might be moderated by users ’char-\\nacteristics, such as need for social interaction. benmimoun, poncin, and garnier (2017) found that forusers with high need for interaction, the use of vi-\\nsually present, interactive virtual ai (compared with\\na present but not interactive agent) had a positiveeffect on perceived system social presence and play-fulness; however, for users with low need for socialinteraction, the use of virtual ai led to no effect onsocial presence and playfulness. personalization ofthe immediacy behaviors to users ’needs and prefer-\\nences could be an important factor for increasing the\\npositive effects of virtual ai.\\nan additional limitation to the effectiveness of\\nimmediacy behaviors was found by groom et al.(2009) who showed that people experience morepositive emotions toward agents whose behavioris not completely realistic. the researchers com-pared a human-like virtual agent with a prerecordedhuman voice recommendation that demonstrated\\ndifferent variations of body- and lip-synchronized\\nmovements. they found that the agent was mostliked when it engaged in only one of the synchro-nized behaviors (either lips or body movement), butnot both. researchers argued that these results areconsistent with the uncanny valley theory (mori,1970), suggesting that when the looks and behaviorof an artificial agent are too human-like, people ex-\\nperience discomfort and a sense of eeriness.\\nemotional trust in embedded ai\\nemotional trust in embedded ai can be built\\nbased on the reputation of the technology and thereputation of the organizations associated with it.for instance, hengstler et al. (2016), in an analysis\\nof eight case studies from the health and transporta-\\ntion industries, examined the way organizations aimto establish users ’trust in ai. using semi-structured\\ninterviews, the researchers concluded that firms pro-mote trust in ai by connecting it to the reputation ofthe developing organization and by making the tech-nology more comprehensible, emphasizing its cur-rent and future usability and benefits. however, this\\nstudy is limited to the perceived organizational in-\\ntentions, without presenting the effectiveness ofsuch tactics. developers ’reputation could be re-\\nlated to the perceived moral standards of the646 july academy of management annals',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4327c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''.join(text)\n",
    "text = re.sub(\",|\\n|@|:\", \"\", text) # 쉼표, \\n, @ 제거\n",
    "text = re.sub(r'\\([^)]*\\)', '', text) # 소괄호 제거\n",
    "text = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995db88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for a_sentence in text:\n",
    "    a_sentence = re.sub(r'\\W',' ',a_sentence)            # 특수 문자는 space로 대체.\n",
    "    a_sentence = re.sub(r'\\d', '', a_sentence)\n",
    "    a_sentence = re.sub(r'\\s+',' ',a_sentence)           # 잉여 space 제거.\n",
    "    t.append(a_sentence)\n",
    "while ' ' in t[:]:\n",
    "    t.remove(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46767ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['special section on deep learningalgorithms for internet of medical thingsreceived april accepted april date of publication may date of current version may digital object identifier access a comprehensive review of thecovid pandemic and the role of iotdrones ai blockchain and g inmanaging its impactvinay chamola vikas hassija vatsal guptaand mohsen guizani department of electrical and electronics engineering birla institute of technology and science pilani indiadepartment of cse and it jaypee institute of information technology noida indiadepartment of computer science and engineering qatar university doha qatarcorresponding author mohsen guizani this work was supported by the qatar national research fund under grant nprp abstract the unprecedented outbreak of the novel coronavirus termed as covid by the worldhealth organization has placed numerous governments around the world in a precarious position the impact of the covid outbreak earlier witnessed by the citizens of china alone has now becomea matter of grave concern for virtually every country in the world ',\n",
       " 'the scarcity of resources to endure thecovid outbreak combined with the fear of overburdened healthcare systems has forced a majority ofthese countries into a state of partial or complete lockdown ',\n",
       " 'the number of laboratory con rmed coronaviruscases has been increasing at an alarming rate throughout the world with reportedly more than millioncon rmed cases as of april adding to these woes numerous false reports misinformation andunsolicited fears in regards to coronavirus are being circulated regularly since the outbreak of the covid ',\n",
       " 'in response to such acts we draw on various reliable sources to present a detailed review of all the majoraspects associated with the covid pandemic ',\n",
       " 'in addition to the direct health implications associatedwith the outbreak of covid this study highlights its impact on the global economy ',\n",
       " 'in drawing thingsto a close we explore the use of technologies such as the internet of things unmanned aerialvehicles blockchain arti cial intelligence and g among others to help mitigate the impactof covid outbreak index terms coronavirus covid pandemic transmission stages global economic impact ua vsfor disaster management blockchain iomt applications iot ai g i ',\n",
       " 'introductionthe covid an acronym for coronavirus disease is a respiratory illness caused by the severe acuterespiratory syndrome coronavirus a con tagious virus belonging to a family of single strandedpositive sense rna viruses known as coronaviridae ',\n",
       " 'muchlike the in uenza virus sars cov attacks the respiratorysystem and causes ailments such as cough fever fatigueand breathlessness ',\n",
       " 'while the exact source of the virus isunknown scientists have mapped the genome sequence of thethe associate editor coordinating the review of this manuscript andapproving it for publication was victor hugo albuquerque sars cov and determined it to be a member of the covgenera of the coronavirus family which typically derives itsgene sources from bats and rodents ',\n",
       " 'the covid was rst reported to affect human life in wuhan city in thehubei province of china in december since then thecovid has spread like wild re throughout the rest of theworld marking its presence in countries and independentterritories ',\n",
       " 'covid statistics for the worst affected coun tries and regions of the world have been presented in fig ',\n",
       " ' according to the who the current global tallyof con rmedcoronavirus cases stands at while the death tollas of april volume this work is licensed under a creative commons attribution license ',\n",
       " 'for more information see https creativecommons org licenses by v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure statistics in regards to the covid has reached ',\n",
       " 'the rapid rise in the number ofcovid incidents worldwide has prompted the need forimmediate countermeasures to curb the catastrophic effects ofthe covid outbreak ',\n",
       " 'to this end this paper evaluates theuse of varied technologies such as iot ua vs ai blockchainand g which could help mitigate the adverse effects of thispandemic and expedite the recovery process ',\n",
       " 'however beforeexploring the potential technological solutions for covid pandemic impact management we provide a comprehensivereview of the covid including its clinical features diag nosis treatment and the impact of its outbreak on the globaleconomy a ',\n",
       " 'backgroundaccording to the who viral infections particularly theones caused by different coronaviruses continue to emergeand pose a severe public health problem ',\n",
       " 'coronavirusesare spherical positive sense rna viruses ranging fromå å in diameter with proteins known as spikesprotruding from its surface which impart a crown like struc ture to them under the electron microscope ',\n",
       " 'the past twodecades have witnessed the emergence of several viral out breaks with different forms of coronavirus at the helmsuch as the sars cov outbreak and themore recent middle east respiratory syndrome coronavirus infection of the sars cov outbreakoriginated in the guandong province of china and laterspread to more than countries worldwide causing over infections and around deaths ',\n",
       " 'the rst case ofmers cov infection was detected in saudi arabia whichinitiated a large scale outbreak in the middle eastern countriesthat ultimately led to fatalities the covid outbreak came to light on decem ber when cases of pneumonia of unknown etiologywere reported at the who s country of ce in china ',\n",
       " 'for theentire timeline of events kindly refer to fig ',\n",
       " 'the epi center of the outbreak was linked to wuhan s wholesale mar ket for seafood and other exotic animals including snakesbats and marmots ',\n",
       " 'a new strain of a highly contagious coronavirus sars cov has been deemed responsiblefor the rapid outbreak of covid ',\n",
       " 'distinguishing charac teristics of the virus include its extremely contagious natureand relatively long incubation period ',\n",
       " 'duringthis period a person can be infected by the virus and notshow any symptoms at all ',\n",
       " 'therefore people infected withthe disease may unknowingly serve as silent carriers ofthe virus contributing to a high basic reproductive num berfor the covid virus ',\n",
       " 'while some studies indicatethat sars cov could be susceptible to heat and ultravio let light there is no speci c treatment or vaccinefor the infection to date and the management protocols forthe disease are evolving as of this writing who de nes basic reproductive number as the number of secondaryinfections caused by a single infected individual volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure a timeline of the covid pandemic b ',\n",
       " 'clinical featurescovid manifests with clinical features ranging fromthe asymptomatic state to acute respiratorydistress syndrome and multiple organ dysfunctionsyndrome ',\n",
       " 'according to the results of a recentstudy conducted by the who in collaboration with chinaof the laboratory con rmed covid cases thatwere examined a majority exhibited clinical characteristicssuch as fever dry cough fatigue and sputum production at the same time only a handful of patients showcasedsymptoms such as sore throat headache myalgia and breath lessness while symptoms such as nausea nasal conges tion hemoptysis diarrhea and conjunctival congestion werefound to be very rare ',\n",
       " 'while most of thecovid patients developed a mild to moderate diseasea few patients were diagnosed with a severe and acritical form of the same ',\n",
       " 'patients with a severeor a critical form of the disease often develop bluish lips faceand are prone to a variety of complications including ardsacute heart injury and secondary infection ',\n",
       " 'according tothe us centers for disease control and prevention the individuals at the highest risk for severe illness from thecovid include older adults and people with existing medical conditions such as diabeteshypertension asthma and cardiovascular disease c ',\n",
       " 'transmission mechanismalthough there are several studies in the direction ofcovid s pathophysiological properties its propagationmechanism remains somewhat elusive ',\n",
       " 'while the initialcovid cases were associated with the direct exposureof individuals to infected animals the rapid outbreak of thedisease has shifted the focus of the research to human to human transmission ',\n",
       " 'an analysis of around cases ofcovid in china has revealed that the covid virus istable list of covid symptoms primarily transmitted between people from the spread of res piratory droplets through sneezing and coughing ',\n",
       " 'theserespiratory droplets have the potential to cover a distanceof up to meters ',\n",
       " 'therefore any person in closecontact with an infected person is at risk of being exposed tothe respiratory droplets and by extension the virus ',\n",
       " 'althoughsymptomatic people have been identi ed to be the primarysource of sars cov transmission there is also a possi bility of transmission via unsymptomatic people ',\n",
       " 'direct andindirect contact with infected surfaces has been identi ed asanother potential cause of covid transmission ',\n",
       " 'evidencesuggests that the virus can survive on plastic and steel sur volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure organization of this work faces for as long as three days on copper for approximately hours and up to hours on cardboard once the virus enters into a healthy body it passes throughthe nasal passage to the mucus membranes present in thethroat and binds itself to the body s cellular receptors ',\n",
       " 'withthe help of the spikes present on its surface the sars cov ruptures the cell membrane and forces the cell into makingmultiple copies of itself ',\n",
       " 'these newly generated copies burstout of the cell and infect other cells in the body ',\n",
       " 'followingthis the virus moves down the bronchial tubes and reachesthe lungs where it severely impairs the host s air sacs d ',\n",
       " 'organizationthe rest of the paper is organized as follows ',\n",
       " 'in section iiwe address the existing works that have reviewed the stateof the covid pandemic ',\n",
       " 'in section iii we present abrief overview of the pandemics that have occurred in thepast century ',\n",
       " 'in section iv we discuss the different stages ofthe covid transmission while in section v the globalimpact of the outbreak on different sectors of the economyhas been evaluated ',\n",
       " 'section v also includes some statisticsproviding valuable insights into the widescale impact ofthe covid pandemic on these sectors ',\n",
       " 'in section viwe discuss the current methods for covid diagnosis section vii examines the efforts being made by variousorganizations and laboratories in the direction of covid vaccine drug development while section viii lists thepreventive measures required to safeguard oneself against thecovid ',\n",
       " 'in the next nine sections we provide a compre hensive review of the use of technologies such as iot ua vsrobots smart wearables ai blockchain and g as a meansto manage the outbreak effectively ',\n",
       " 'finally section xviiiconcludes the paper ',\n",
       " 'the organization of the paper has alsobeen depicted pictorially in fig ',\n",
       " ' ii ',\n",
       " 'related worksthe massive outbreak of the covid has prompted variousscientists researchers laboratories and organizations aroundthe world to conduct large scale research to help develop vac cines and other treatment strategies ',\n",
       " 'in the months followingthe covid outbreak several papers examining differentaspects of the covid have been published to determine the clinical characteristics of the covid dawei wang et al ',\n",
       " 'have studied infected patients inwuhan china ',\n",
       " 'the authors have taken into accountspeci cs such as demographics signs symptoms andmedical history of all the patients to assess their casescarefully ',\n",
       " 'the authors have also presented the laboratory ndings of these patients to demonstrate the effects of thesars cov virus on different vital organs of the body nanshan chen et al ',\n",
       " 'studied patients with the covid of whom had a direct link to the huanan seafood market inwuhan known to be the covid epicenter ',\n",
       " 'their ndingsof the epidemiological clinical and radiological characteris tics of the disease have been published in ',\n",
       " 'in their nd ings they report that among all the patients that were studied developed acute respiratory distress syndrome and among them died of multiple organ dysfunctionsyndrome volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemictable major viral diseases fang jiang et al ',\n",
       " 'have reviewed six published studies rec ognizing the clinical characteristics of the covid ',\n",
       " 'in theirwork they have summarized these studies and in doing soprovided a brief overview of clinical features and treatmentsof the covid ',\n",
       " 'the authors of have reviewed theexisting literature on computed tomography character istics of covid available on platforms such as pubmedgoogle scholar and elsevier among others ',\n",
       " 'the primaryissue with both these works is that they review a small subsetof a much broader subject ',\n",
       " 'to this end the authors of and provide a brief overview of the covid outbreakin terms of its clinical features prevention diagnosis andtreatment ',\n",
       " 'although these surveys shed some light on thecurrent scenario of the covid outbreak they give a verybrief and limited idea about the exact situation despite the abundance of research in the domain ofcovid characteristic analysis and vaccine developmentto the best of our knowledge at the time of this writing thereis no survey that provides a comprehensive review of thecovid outbreak and its potential implications ',\n",
       " 'further more no work in the existing literature attempts to reviewthe role of emerging technologies such as iot ua vs aiblockchain and g in managing the covid pandemic this presents the need for a detailed survey that providesboth the horizontal and the vertical view of the covid interms of its clinical features diagnosis treatment preventionstrategies and the technological solutions being adopted toalleviate the impact of its outbreak ',\n",
       " 'in this work we present acomprehensive review of the covid pandemic that willhelp readers gain a deeper understanding of the current globalsituation due to the covid pandemic ',\n",
       " 'before divulginginto a thorough analysis of the covid pandemic we takea brief look at some of the past pandemics in the sectionbelow iii ',\n",
       " 'pandemics in the past centurythe last century has seen a plethora of outbreaks andepidemics ',\n",
       " 'while coronaviruses such as sars cov mers cov have been responsible for a majority of theseoutbreaks different types of in uenzaviruses such as hn hn and hn have been at thehelm of all the four pandemics in the past years ',\n",
       " 'thehn virus alone has been responsible for two pandemics the spanish flu of and the swine uin while the hn and hn in uenza viruseshave been responsible for the asian flu of andthe hong kong u of respectively ',\n",
       " 'in this sectionwe provide an overview of all these pandemics a ',\n",
       " 'spanish flu pandemic the spanish flu is known by many to be the deadliest pan demic in the history of humankind with the total number offatalities surpassing the million mark ',\n",
       " 'the diseasewas caused by the hn virus which is believed to haveoriginated in birds ',\n",
       " 'unlike most diseases spanish flu hada peculiar characteristic of being extremely lethal againstthe young and healthy populace ',\n",
       " 'this was because the virusattacked hosts by causing cytokine storms in the patient simmune system which often lead to death ',\n",
       " 'since youngpeople had stronger immune systems as compared to olderadults they were more likely to be affected by the virus b ',\n",
       " 'asian flu pandemic the asian u pandemic began in february of in singa pore ',\n",
       " 'it was the second major pandemic of the th centuryafter the spanish flu pandemic of it is believed to havecaused deaths in the us and a total of millionfatalities worldwide ',\n",
       " 'the virus at the root of this diseasewas identi ed to be the type a hn virus which like thehn is believed to be of avian origin ',\n",
       " 'eleven years afterthe outbreak the hn virus subsequently mutated to a strainthat is no longer able to affect human hosts c ',\n",
       " 'hong kong flu pandemic the hong kong flu pandemic was the third major in uenzapandemic of the th century ',\n",
       " 'it was caused by thehn virus which is believed to have evolved fromthe hn virus that caused the asian u pandemic ',\n",
       " 'thehn virus involved a mutated version of the ha antigenpresent in hn but retained the same n antigen ',\n",
       " 'theimpact of the hong kong flu pandemic across the world hasvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure cumulative number of cases of the covid been described as sporadic which is believed to have beendue to the prior immunity developed against the n anti gen on account of the asian flu pandemic ',\n",
       " 'unlike thehn virus behind the spanish flu pandemic the hn viruswas more aggressive towards people above the age of d ',\n",
       " 'swine flu pandemic in the spring of a new strain of the type ahn in uenza virus emerged leading to the swine upandemic ',\n",
       " 'like the spanish flu which was caused by adifferent strain of the same virus the swine u pandemicwas more deadly against people below years of age pre acquired immunity in older people on account of previousexposure to the hn virus was believed to be one of thereasons for the same ',\n",
       " 'the us centers for disease control andprevention estimate that there have been more than million cases hospitalizations and deathsin the us alone due to the virus while the worldwide tally offatalities stands above iv ',\n",
       " 'different stages of covid outbreakaccording to the who the covid pandemic is regardedas having four main classes of transmission that remainconsistent throughout the world to facilitate better com munication and understanding amongst the countries such a categorization makes it simpler for other countries toenforce policies which they think would assist in preventingthe outbreak for example imposing travel bans shuttingdown schools colleges and enforcing partial or completelockdown ',\n",
       " 'for better understanding we have portrayed thewho transmission classes as different stages of the covid outbreak keeping in line with several media reports ',\n",
       " 'theonset of different stages of the covid outbreak in fourcountries namely china spain italy and the usa havebeen mapped in fig ',\n",
       " ' a ',\n",
       " 'stage i imported cases onlythe rst stage of the covid outbreak in a particularnation is characterized by its rst reported incident of the dis ease in this case covid ',\n",
       " 'in this stage the disease doesnot spread locally and the infection is usually limited to thepeople with travel history to an already affected region b ',\n",
       " 'stage ii sporadic cases local transmissionthe second stage of the covid outbreak occurs whenthere are a few sporadic cases of the disease in the country it happens when people who are already infected with thedisease spread it to people with whom they come into contactusually immediate family members friends and colleagues at this stage it is possible to perform contact tracing andlimit the spread of the disease by quarantining the infectedpeople volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure countries in lockdown as of april c ',\n",
       " 'stage iii clusters of casesthe third stage of the covid outbreak in a country ismarked by the presence of several clusters of covid cases i e ',\n",
       " 'when the disease causing virus starts circulatingwithin a geographic location and infects individuals who haveneither a history of travel nor contact with someone who does at this stage it becomes hard to trace the source of the virustransmission and geographical lockdown becomes highlynecessary to prevent the outbreak from reaching stage iv d ',\n",
       " 'stage iv community transmissionthe fourth stage of the covid pandemic in a coun try is associated with community transmission i e ',\n",
       " 'largeroutbreaks of local transmission in a country leading to anextremely high number of reported incidents and deaths at this stage the outbreak gets out of control and ndinga cure or vaccine is the only way to mitigate the impact of thedisease ',\n",
       " 'countries like iran turkey canada and the usa arecurrently in the fourth stage of the covid pandemic v ',\n",
       " 'impact of the covid pandemic on theglobal economyowing to the lack of any concrete treatment strategy socialdistancing has been identi ed as the best possible defensestrategy against the covid pandemic at the time of thiswriting ',\n",
       " 'however the need for social distancing has promptedgovernments around the world to impose lockdowns which has marked a huge dent in the globaleconomy ',\n",
       " 'all non essential services have been forced to shutdown causing virtually all the industrial sectors to face sig ni cant disruptions in the supply chain and consequently putting billions of people at risk of losingtheir jobs ',\n",
       " 'furthermore the rapid outbreak of covid hasforced governments to restrict the trade of a majority of goodsacross country borders leaving international trade ows onthe verge of collapse ',\n",
       " 'according to the projections put forthby jpmorgan chase co the covid pandemic hasthe potential to paralyze the global economy with an esti mated loss of more than trillion us dollars in the next months ',\n",
       " 'in this section we analyze the impactof the covid pandemic on the overall economy by thor oughly dissecting its impact on different economic sectors a ',\n",
       " 'automotive industrythe automotive industry has seen major disruptions in pro duction due to stringent lockdown measures enforced in sev eral countries worldwide as an effort to contain the pandemic as social distancing is enforced and people are required tostay in their homes usage of automobiles including bothpublic private transport has declined across the world ',\n",
       " 'theonly automobiles currently in use are the vehicles associatedwith essential services relevant statistics in china the automobile industry saw an drop insales in year over year sales of january despite containment efforts this number escalated to in february which is the biggest everyoy drop experienced by the chinese automotive indus try in march the yoy sales of passenger vehicles andcommercial vehicles in india saw a decline of andvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemictable industries hit hardest by the covid pandemic respectively as dealers were forced to shut downtheir showrooms following government stipulations tolimit the spread of covid according to the european automobile manufacturersassociation the combined production lossesin the european union and the united king dom amount to more than million vehicles asof april additionally employment of morethan million people has been adversely affected dueto factory shutdowns in the usa the covid outbreak has forced a major ity of automakers including general motors fiat fordand many others to suspend their production activi ties ',\n",
       " 'according to the estimates published by thealliance for automotive innovation on march of all automobile production plants were forced toclose down in the usa following the covid out break b ',\n",
       " 'aviation industrythe covid pandemic has had a massive impact on theaviation industry ',\n",
       " 'affected countries which includes almostall the nations have been forced to impose travel bans on bothinternational and domestic passenger ights ',\n",
       " 'the only activeairways include critical supply routes that support cargo andfreight aircraft relevant statistics as per a recent report published by the internationalair transport association the global air traveldemand increased by just in january which is the lowest yoy increase registered in the lastdecade ',\n",
       " 'the major disruption in travel demandhowever was recorded between and march when the reported number of operational ights plum meted to a sharp decline from ightsreported in the same period in according to the most recent iata estimates the airlineindustry is well on track to lose as much as bil lion us dollars in revenues globally following thecovid crisis as airline services are currently stalled the demand forthe purchase of new aircraft has also dropped ',\n",
       " 'the totalnumber of aircraft orders has decreased from in to in c ',\n",
       " 'tourism industrythe tourism industry has been one of the worst affectedindustries following the outbreak of covid ',\n",
       " 'revenuesgenerated from the tourism sector account for of theworld s gdp ',\n",
       " 'therefore any adversity faced by the tourismsector has the potential to dent the global economy severely relevant statistics according to the world travel tourism coun cil estimations the covid pandemic couldlead to a layoff of about million people associatedwith the tourism industry worldwide as per the gures issued by the united nations worldtourism organisation international visitorarrivals could fall by up to in which cor responds to a loss of billion us dollars ininternational tourism receipts d ',\n",
       " 'oil industrythe shutdown of international and domestic passenger air craft across the world has resulted in a drastic decline in theconsumption of aviation fuel ',\n",
       " 'similarly on the ground allnon essential traf c remains stalled causing a sharp declinein the global oil demand relevant statistics in china the demand for crude oil has fallen by around million barrels a day volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemic the brent crude oil benchmark collapsed over inthe rst quarter of while the west texas intermedi ate benchmark recorded a drop of more than with oil prices plummeting to nearly us dollars boththese benchmarks have recorded their worst ever quarterin history e ',\n",
       " 'construction industryconstruction rms are likely to face severe disruptions anddelays in current projects on account of the covid pan demic ',\n",
       " 'due to a majority of the workforce being unable towork as a result of stringent self quarantine guidelines mostconstruction rms will be required to cease all non essentialoperations until the outbreak is contained ',\n",
       " 'this will likelyresult in the large scale re scheduling of existing projectswhich might lead to severe losses for the industry relevant statistics within just the rst two months of the year xed assetinvestment in china dropped by while the realestate development dropped by the widespread impact of the covid outbreakon the construction sector in china and other leadingeconomies has prompted globaldatato update its esti mate for construction growth in from to f ',\n",
       " 'food industryin comparison to other sectors the impact of the covid pandemic has not been as severe on the food industry ',\n",
       " 'recog nition of food as an essential commodity has allowed supplychains associated with food products to remain operational in fact as per the food and agriculture organization of the united nations packaged food demand has risensigni cantly in the months following the covid out break ',\n",
       " 'however that does not go as far as to say thatthe industry has not been affected at all ',\n",
       " 'while supply chainsfor essential food items are kept open restaurants cafes andother luxury food service providers have been forced to shutdown ',\n",
       " 'furthermore several grocery store owners andsupermarkets are often nding themselves unable to meet therising demands owing to panic buying and stocking up offood supplies by the masses g ',\n",
       " 'healthcare and medical industrythe covid pandemic has had a devastating effect on thehealthcare systems across the world ',\n",
       " 'while most industrialsectors have been economically affected due to the inac tivity caused as a result of lockdown measures travelbans what the healthcare industry is witnessing is far fromstagnation ',\n",
       " 'hospitals across the world are currently facinga shortage of ventilators intensive care units andpersonal protective equipment required to manage thecovid patients ',\n",
       " 'the healthcare systems of even the mosta data analytics and consulting companydeveloped countries in the world are on the brink of col lapse due to the exponentially increasing number of covid patients h ',\n",
       " 'telecommunications industrythe impact of the covid pandemic on the telecom munications industry has been sporadic ',\n",
       " 'various telecom munication service providers and internet serviceproviders have reported witnessing a massive increasein traf c ',\n",
       " 'the large scale consumption of network band width has been attributed to the governments lockdownefforts which have forced the educational institutions to useonline platforms of teaching and companies to allow theiremployees to work from home ',\n",
       " 'however the covid pan demic has not left the telecommunications sector unscathed much like other industrial companies a majority of tsps isps have recorded a massive drop in their share prices overthe past few months ',\n",
       " 'in globaldata s share price analysisof some of the top tsps worldwide it was revealed thatshare prices of telecom behemoths at t china telecomand telefonica plummeted by more than between jan uary and march the large scale implications of the covid pandemic onthe global economy are attributed to the substandard responsesystem adopted following its initial outbreak ',\n",
       " 'although theresponse to the covid pandemic has been more orga nized than the response to previous epidemics and pandemicsa few issues in the current epidemic pandemic response sys tem remain ',\n",
       " 'table lists all the underlying issues with thecurrent response along with the key learning points for futurepublic health emergency management ',\n",
       " 'these lessons arevery relevant not just for other health crises but also in casethere is a second third wave of the covid pandemic inthe future vi ',\n",
       " 'diagnostic testing for the covid given the signi cant spurt in covid cases across theworld in the past few months a carefully devised strategyfor reliable diagnosis is the need of the hour ',\n",
       " 'the onsetof stage ii and stage iii of the covid outbreak hasprompted a majority of the countries worldwide to extendtheir scope of testing beyond individuals with foreign travelhistory ',\n",
       " 'however due to the insuf cient number of test ing kits large scale testing of the covid is infeasible furthermore the inability to distinguish the symptoms ofcovid from the symptoms of common u has made itdif cult for governments across the world to determine xedcriteria required to carry out a test ',\n",
       " 'to this end the cdc hasissued priority based testing criteria to guide the evaluationof covid cases ',\n",
       " 'the criteria assign the highest priorityto healthcare workers hospitalized patients showing symp toms of covid infection while symptomatic patients a above the age of or b having existing medical conditionshave been given the second priority ',\n",
       " 'the entire guidelines forthe testing criteria have been listed on the of cial website ofthe cdc volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemictable lessons drawn from the current response to the covid pandemic a ',\n",
       " 'contact tracingcontact tracing refers to the process of identifying peoplewith a history of exposure to infected individuals ',\n",
       " 'the rela tively long incubation period associated with the covid and the absence of large scale testing has made it extremelychallenging for the authorities to identify the actual numberof infected patients ',\n",
       " 'this leaves the process of contact trac ing as the only viable option ',\n",
       " 'according to the who the process of contact tracing involves three stepsvi identifying individuals with a history of contact with aninfected person ii recording the details of those individuals iii getting those individuals tested as soon as possible adopting the process of contact tracing can be particularlyadvantageous for the countries currently in the rst andthe second stage of the covid outbreak b ',\n",
       " 'clinical tests for covid detectiondeveloping accurate and reliable tests to diagnosesars cov infection in individuals is essential to curb itsrapid transmission ',\n",
       " 'the currently available covid testscan be broadly classi ed into two types molecular teststhe who recommended nucleic acid ampli cationtest has emerged as the most popular test for detect ing an active sars cov infection ',\n",
       " 'these tests involvethe use of the nasopharyngeal swab technique wherein asample comprising a mixture of mucus and saliva is obtainedfrom the back of the throat usinga cotton swab ',\n",
       " 'however in casethe person being tested is suffering from severe respiratoryailments the who recommends obtaining specimens fromhis her lower respiratory tract as well ',\n",
       " 'these samplesare then brought to a specialized laboratory where they areassessed for detecting the presence of viral rna using areal time reverse transcription polymerase chain reaction test ',\n",
       " 'a diagnosis of the covid is onlycon rmed if the test identi es eithervi the presence of two discriminatory targets for thesars cov genome one of which is preferablyexplicit to the sars cov orii the presence of betacoronavirus followed by the iden ti cation of sars cov using partial or completesequencing of the virus genome the viral genes being targeted by the nucleic acid ampli cation tests are the n e s and rdrp genes identi cation of just a single gene in the naat generatesthe need for a repeat test of the patient ',\n",
       " 'in any subsequenttests the who recommends using a different specimen andtarget sequence from the one used in the initial test volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemictable various techniques for coronavirus sample collection table covid candidate vaccines in clinical evaluations while naats have high sensitivity andspeci city one of their drawbacks is thatthey can only diagnose current cases of infection i e ',\n",
       " 'theydo not provide any insights as to whether someone had theinfection earlier serological testsunlike molecular tests that detect the presence of the virusitself serological tests are used to detect the existence ofantibodies in the bloodstream of the person being tested antibodies are proteins formed by the white blood cells tocombat a speci c antigen ',\n",
       " 'by enabling healthcare experts toidentify individuals who have developed an immune responseto the infection serological tests have the potential to play amassive role in the ght against covid ',\n",
       " 'howeverserological tests also have one signi cant shortcoming ',\n",
       " 'theydo not have the ability to detect a disease during its earlydays when the body is still building antibodies against theinfection vii ',\n",
       " 'treatmentcovid caused by the novel sars cov has led theworld into an unprecedented state of severe disarray ',\n",
       " 'at thetime of writing no de nitive treatment or preventive vaccineexists for the coronavirus ',\n",
       " 'as such the treatment of covid is mostly symptomatic i e ',\n",
       " 'the type of treatment admin istered depends on the speci c symptoms exhibited by thepatient most cases of the coronavirus disease have been classi edas mild with patients recovering on their own without theneed for supportive care ',\n",
       " 'therefore it is recommended thatpatients with mild covid symptoms be managed at homevolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicto avoid placing additional strain on the already stressed outhealth systems ',\n",
       " 'however severe and critical cases of covid do tend to require hospitalization ',\n",
       " 'patients experiencinghypoxemiamay require the provision of additional oxygenvia face masks or ventilators ',\n",
       " 'co infections that occur asa result of a weakened immune system due to the virusare treated with necessary antibiotics and antifungals on acase by case basis ',\n",
       " 'as the sars cov virus may affect thekidney as well renal replacement therapy might be requiredin some cases ',\n",
       " 'in any case patients diagnosed with thedisease need to be put under strict isolation irrespective ofthe severity of the symptoms in order to prevent furthertransmission while no de nitive antiviral medicine or preventive vac cine for sars cov is available to date various attemptsare being made to make one available for commercial use assoon as possible ',\n",
       " 'in the following subsections we address theefforts being made to produce potent vaccines and drugs forcovid treatment a ',\n",
       " 'vaccine developmentdeveloping vaccines for viral diseases is particularly chal lenging owing to their capability to mutate from one per son to another ',\n",
       " 'nevertheless the development of reliable potent vaccinations is the only viable way of bringingthe covid pandemic to an end ',\n",
       " 'following the outbreakvarious medical organizations independent laboratories andscientists have been attempting to create a vaccine for thesars cov ',\n",
       " 'according to the who as of april around candidate vaccines are in the pre clinical stagewhile have already entered the clinical evaluations ',\n",
       " 'some of the most signi cant efforts beingmade in the direction of covid vaccine development areas follows moderna s mrna moderna a us based biotech company has put forth avaccine candidate in collaboration with the national insti tute of allergy and infectious diseases ',\n",
       " 'moderna sapproach is based on the injection of mrna a genetic form ofthe virus genome into human cells to allow them to generateproteins required to combat the virus ',\n",
       " 'unlike the methodsadopted in conventional vaccines this approach does notrequire growing large numbers of the virus ',\n",
       " 'althoughthis vaccine has entered the rst phase of clinical trials on march its commercial release is expected to be morethan a year away cansino s ad ncovanother candidate vaccine that is undergoing clinical eval uations is the adenovirus type vector based recombinantcovid vaccine ',\n",
       " 'developed by cansinobiological inc in association with the beijing institute oftechnology ad ncov uses the non replicating virala low level of arterial oxygen supplyfigure covid preventive measures vector as its platform the same as the one used in their ad ebov vaccine for ebola ',\n",
       " 'this vaccine relies on the aden ovirus type vector to stimulate immune responses that workagainst the disease ',\n",
       " 'given the positive response recorded inthe rst phase of clinical trials cansino might move for anexpedited phase ii clinical trial pittcovacc the researchers at the university of pittsburgh school ofmedicine have recently developed a vaccine against thesars cov named pittcovacc ',\n",
       " 'unlike the mrnavaccine candidate developed by moderna pittcovacc adoptsthe more conventional method of building immunity usinglaboratory generated pieces of viral protein ',\n",
       " 'the preliminarytests conducted on mice revealed that pittcovacc triggeredthe development of a large number of antibodies againstsars cov within two weeks of it being administered pending fda s approval phase i of the clinical trials for thisvaccine are slated to commence soon johnson johnson s covid lead vaccinehealthcare conglomerate johnson johnson and thebiomedical advanced research and development authority a subdivision of the us department of health andhuman services have pledged to collectively investmore than billion us dollars in the r d of covid vac cines ',\n",
       " 'on march johnson johnson declared thatit had identi ed its lead candidate vaccine after three monthsof comprehensive research on several vaccine candidates incollaboration with the beth israel deaconess medical center volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemictable promising candidate drugs for the treatment of covid a division of the harvard medical school ',\n",
       " 'johnson johnsonplans to launch the clinical trials of its lead candidate vaccineby september at the latest multiple efforts made by the cepithe coalition for epidemic preparedness innovations a norway based foundation established to expeditethe development of vaccines against emerging infectiousdiseases has initiated collaborations with several organiza tions institutes across the world to aid in the developmentof effective vaccines against the sars cov ',\n",
       " 'cepi andglaxosmithkline announced a new partnership on february which will see gsk make its existingadjuvant technology available to the cepi ',\n",
       " 'on febru ary cepi struck a partnership with the internationalvaccine institute an international organization based inthe republic of korea which shares its vision of a covid free world ',\n",
       " 'under the terms of this partnership the iviwill render its technical expertise in the cepi sponsoredprojects in exchange for which it will receive funding fromthe cepi ',\n",
       " 'in addition to the partnership efforts the cepihas pledged initial funding to various institutes including theuniversity of queensland university of hong kong university of oxford and the pasteur institute to acceleratethe development of effective vaccines against sars cov to date the cepi has invested a sum of million usdollars in the r d of various covid vaccines although researchers around the world are making deter mined attempts to come up with a vaccine for the extirpationof the covid the imminent arrival of an effective vac cine seems implausible ',\n",
       " 'two main reasons for the same arementioned belowvi in the last two coronavirus outbreaks namely sarsand mers it was observed that once the vaccine wasadministered to an individual there was a suddenincrease in his her immune response cytokine bursts often lead to acute respiratory distresssyndrome which is considered to be the leadingcause of death in covid patients ',\n",
       " 'to avoid suchcomplications and to ensure that the vaccines currentlyin development do not prove to be counter effective laterit is necessary to certify that these vaccines have a goodsafety pro le ii sometimes a single dose of vaccine is not suf cient todevelop suf cient antibodies ',\n",
       " 'for example the hepatitisb vaccine is given in doses each of them months apart once identi ed the need for wide scale production ofthe covid vaccine to meet world requirements isanticipated to take much time ',\n",
       " 'adding to that if multipledoses across several months are required it will takean even longer time before we can rely on vaccines forbringing the covid pandemic to an end b ',\n",
       " 'potential drugs for treatmentmany pharmaceutical companies have come up with potentialdrugs as solutions to treat the coronavirus disease ',\n",
       " 'while nodrug is globally approved as of yet several of these drugsare being tried out with some of them in various phases ofclinical trials ',\n",
       " 'as of april morethan clinical trials worldwide are listed on the who sinternational clinical trials registry platform among the drugs being tested remdesivir hydroxychloro quine and arbidol have shown immense promise and arealready undergoing clinical trials at several hospitals acrossthe world ',\n",
       " 'earlier in arbidol was shownto have promising results against the pathogens of thesars cov virus in cellular models ',\n",
       " 'it was also provento be effective against in uenza type a and b viruses as wellas the hepatitis type c virus volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicanother drug that has emerged as a candidate to treat thecovid is the shuang huang lian a well knowntraditional chinese drug used to treat various bacterial andviral infections ',\n",
       " 'chinese researchers have reported that shloral liquid may have inhibitory properties against the sars cov virus due to the presence of baicalin chlorogenic acidand forsythin which are known to have inhibitory effectsagainst multiple pathogenic viruses ',\n",
       " 'it is impor tant to note however that currently there is no conclusiveevidence backing the use of shl oral liquid as a treatmentfor the covid although various attempts are being made to developef cient treatment strategies against the covid a com mercially viable vaccine might not be possible for at leastanother year ',\n",
       " 'therefore the best way to keep the disease fromspreading any further is to limit the exposure of non infectedindividuals to infected individuals ',\n",
       " 'in the following sectionwe discuss the various preventive measures suggested by thewho and the cdc against the covid viii ',\n",
       " 'preventive measuresas the world continues to suffer from the covid healthcrisis it is essential to follow effective preventive measures to minimize the likelihood of becoming anothercasualty ',\n",
       " 'if individuals and communities comply with thepractices mentioned below the world may soon witness a at tened covid curve ',\n",
       " 'flattening the curve implies bringingdown the spread of the covid to the extent where avail able healthcare facilities can suf ciently handle the impact ofthe disease i clean your hands frequently with an alcohol based handsanitizer or wash them thoroughly with soap and water ii practice social distancing seek to keep yourself at adistance of at least meter from others iii stay at home unless absolutely necessary to go out individuals above people with underlying health con ditions and pregnant women are especially advised tostay away from all social interactions iv avoid touching your eyes nose and mouth withoutthoroughly cleansing your hands v frequently touched surfaces such as doorknobs desksphones light switches and laptops should be routinelydisinfected vi cover your coughs sneezes with a cloth handkerchiefor a tissue ',\n",
       " 'if none of these are readily available cough ing sneezing into your elbow pit is advisable vii it is advisable to wear masks around other people ',\n",
       " 'how ever care should be taken to ensure their proper dis posal the rapid outbreak of the covid has placed sincereemphasis on the need to follow good practices in daily lifelike washing hands taking regular baths improving eatinghabits and much more ',\n",
       " 'it is important to note that goodhygiene practices and eating habits should be followed notjust during the covid pandemic but also after it ix ',\n",
       " 'emerging technologies for mitigating theimpact of the covid pandemicas the novel coronavirus continues its onslaught across theglobe the world is reeling under the weight of crashingeconomies and piling casualties ',\n",
       " 'unfortunately billions ofpeople are still under a constant threat of infection with thesituation not likely to get any better in the coming days ',\n",
       " 'how ever a multitude of technological approaches are emerging todeal with the impacts of the covid pandemic ',\n",
       " 'amongthem digital technologies including iot ai blockchainand next generation telecommunication networks like ghave been at the forefront ',\n",
       " 'according to the whoand the cdc digital technologies can play an essentialrole in improving public health response to the covid pandemic ',\n",
       " 'in the following sections we explore theef cacy of the aforementioned technologies in allaying thedisastrous impacts of the covid pandemic x ',\n",
       " 'iot iomtthe internet of medical things also referred to asthe healthcare iot is an amalgamation of medical devicesand software applications offering extensive healthcare ser vices that are connected to the healthcare it systems ',\n",
       " 'in recent times much like the iot iomt haswitnessed a surge in the number of its potential applica tions ',\n",
       " 'this surge is attributed to the fact that anincreasing number of mobile devices are now equipped withnear field communication readers that allow thesedevices to interact with it systems ',\n",
       " 'applications ofiomt include monitoring patients from a remote loca tion tracking medication orders and using wearablesto transmit health information to the concerned health careprofessionals owing to their ability to collect analyze and transmithealth data ef ciently the health care sector has realized thetransformative potential of iomt technologies amid the ongoing covid pandemic several innovatorsmedical organizations and government bodies are lookingto leverage iomt tools in order to reduce the burden on thehealthcare systems ',\n",
       " 'in the following few sections we explorevarious iot iomt technologies that have made a sizablecontribution in monitoring and consequently managing theimpact of the covid pandemic a ',\n",
       " 'smart thermometerseight years ago a us health technology company namedkinsa had launched internet connected thermometers toscreen people for high fevers ',\n",
       " 'although these thermometerswere initially developed to track the common u they arenevertheless proving to be highly useful in identifying thepotential covid clusters throughout the usa ',\n",
       " 'followingthe covid outbreak kinsa health has deployed morethan a million smart thermometers to households in variouscities of the usa ',\n",
       " 'these thermometers are linked to a mobileapplication which allows them to transmit their readingsto the company immediately ',\n",
       " 'once received this data is volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure iomt assimilated by kinsa to generate daily maps showing whichof the us regions are witnessing an increase in high feversthereby allowing the us authorities to identify potentialhotspots ',\n",
       " 'in the past few years kinsa s interactive maps haveproven to be highly accurate in the timely prediction of thespread of u around the us outdoing even the cdc s of cialapp in terms of the promptness of prediction b ',\n",
       " 'iot buttonsto maintain high cleaning standards and limit the numberof hospital acquired infections several hospitals invancouver have installed battery operated iot buttons these buttons named wanda quicktouch were designed forrapid deployment in any facility irrespective of their sizein order to issue prompt alerts to the management warningthem of any sanitation or maintenance issue that may pose arisk to public safety ',\n",
       " 'a remarkable feature of these buttons istheir independence on external infrastructure i e ',\n",
       " 'their abilityto stick to any given surface c ',\n",
       " 'telemedicinethe practice of using iomt technologies to facilitate remotepatient monitoring is called telemedicine ',\n",
       " 'also knownas telehealth this practice allows clinicians to evaluatediagnose and treat patients without needing any physi cal interaction with them ',\n",
       " 'following the outbreakof the highly contagious covid several iomt techand telemedicine platforms have faced a rapid surge intraf c recently jd health an e commerce platform forhealthcare solutions has reported witnessing a considerablerise in demand for online consultations since the outbreakof the covid ',\n",
       " 'in the usa the of ce of civilrights and the centers for medicare and medicaidservices have waived certain medicare rules forallowing doctors to provide their patients with remote med ical expertise via telehealth platforms ',\n",
       " 'following therelaxations in these regulations a texas based multinationaltelemedicine company teladoc health has reported an enor mous increase in demand for its telemedicine solutions ',\n",
       " 'thissurge in demand has prompted its share prices to rise by morethan a in a span of few weeks the bene ts of adopting telehealth techniques have beentwofold it has lessened the burden on the overworkedhospital staff it has reduced the risk of emanation of thevirus from the infected individuals to the healthcare person nel ',\n",
       " 'mentioned below are some ways in which telemedicineplatforms are being used around the world to manage theimpact of covid in the usa the george washington university hospi tal has adopted the use of several telemedicinestrategies including video consultations and live face book webinars to provide remote medical expertise toseveral people another university hospital in the usa the rushuniversity medical center has adopted the use oftelemedicine platforms to facilitate on demand videoconsultations ',\n",
       " 'however the health professionals at therush university medical center are using such consul tations not only to provide medical expertise to peoplebut also to screen them for the covid in india the state governments of andhra pradesh andassam have rolled out telemedicine facilities to enableremote interaction of potential covid patients withmedical experts in israel s largest hospital the sheba medical centerseveral telehealth technologies were used to monitor israeli passengers that were on board the cruiseship quarantined in japan for several weeks ',\n",
       " 'how ever the sheba medical center employed the use oftelemedicine strategies not to treat these passengersremotely but to ensure minimal human contact whiletreating them within the hospital premises ',\n",
       " ' in the past few months several telemedicine tools liketelemedicine carts teleconsultation software and portabletablets have proved their merit in the ght against thecovid pandemic ',\n",
       " 'however the true potential oftelemedicine can only be realized when existing telemedicineplatforms are used in conjunction with other technologiessuch as drones robots smart wearables and next generationg cellular networks ',\n",
       " 'the consolidation of thesetechnologies with existing telehealth platforms can allow fora more dynamic healthcare ecosystem that can enable remotemonitoring and distant clinical care of patients with mildcases of covid the wide range of use cases presented above indicates thepotential of iot iomt in solving the unprecedented chal lenges posed by the covid ',\n",
       " 'however the tools discussedabove form a small subset of the much larger domain that isiot ',\n",
       " 'in the four sections that follow we thoroughly dissectfour prominent technologies linked to iot that have had awide ranging impact in the battle against covid namelydrone technology robots wearables and apps xi ',\n",
       " 'drone technologyduring the times of a public health emergency such as thecovid pandemic ua vs i e ',\n",
       " 'drones can offer manyvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure various technologies enabling telemedicine advantages ',\n",
       " 'not only can they ensure minimized humaninteraction but they can also be used to reach otherwiseinaccessible areas ',\n",
       " 'china the rst country to face the wrathof the covid has made great use of drone technology tocounter the covid outbreak ',\n",
       " 'taking that as inspirationseveral countries around the world have joined forces withnumerous researchers and innovators in an attempt to ndingenious ways of using drones to ght the covid ',\n",
       " 'in this section we explore the numerous bene tsthat drones can provide in terms of managing the covid pandemic or any other future outbreak a ',\n",
       " 'crowd surveillanceto contain the spread of the covid governments aroundthe world are taking all the necessary steps to ensure socialdistancing ',\n",
       " 'to this end many countries around the worldincluding china and india have adopted the drone technol ogy for crowd surveillance micromulticopter a leading industrial drone manufac turer based out of shenzhen in china has deployed over drones in several cities of china in an attempt to sur vey areas and observe crowds ef ciently ',\n",
       " 'the dronesequipped with sky speakers can also be used to give instruc tions to people not in compliance with the guidelines issuedby the chinese government in india a global technology solutions company namedcyient has provided the telangana police with unmannedaerial spectrum monitoring technology to help manage thecovid lockdown ',\n",
       " 'the drones deployed are equippedwith surveillance cameras that can effectively monitor sen sitive areas in the city and allow the police to handle anyunwarranted situation promptly b ',\n",
       " 'public announcementsin addition to crowd surveillance drones can prove to behighly useful for broadcasting important information par ticularly in areas that lack open channels for communica tion ',\n",
       " 'the police authority in madrid spain used a droneequipped with a loudspeaker to inform people of the guide lines put in place regarding the state of emergency that wasimposed ',\n",
       " 'additionally several other european coun tries have regularly used drones to make public announce ments emploring people to practice social distancing normsand taking other necessary precautions to limit the spread ofthe disease c ',\n",
       " 'screening massesfollowing the outbreak of the covid several authoritiesin china committed themselves to detect covid patientsas soon as possible ',\n",
       " 'they employed the use of dronesequipped with infrared cameras to carry out large scale tem perature measurements in several residential areas in india the authorities in new delhi have employedthe use of a multipurpose drone to contain the spread ofthe covid ',\n",
       " 'dubbed the corona combat drone it isequipped with a thermal camera for screening individuals volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure uavs for covid impact management a night vision camera for monitoring the crowd a portablemedical box for carrying essential medical supplies a loud speaker for making announcements and a disinfectanttank with a capacity of liters for sanitizing publicspaces ',\n",
       " 'unlike the infrared thermometers that can mea sure the temperature of one person at a time this dronecan be used to measure the temperature of multiple peoplesimultaneously in addition to these efforts researchers at the universityof south australia in association with the canada basedcommercial ua v manufacturer draganfly are in the processof developing a pandemic drone to remotely observe andidentify people with infectious respiratory in rmities ',\n",
       " 'thesedrones are to be installed with a specialized sensor and com puter vision system that can monitor people s temperatureand heart rates ',\n",
       " 'these drones are also expected tohave the ability to detect people sneezing and coughing inpublic spaces ',\n",
       " 'if successful these drones have the potentialto revolutionize covid diagnostics by early detection ofpotential covid patients d ',\n",
       " 'spraying disinfectantsin the face of the covid pandemic drones can be usedto enter contaminated regions and spray disinfectants ',\n",
       " 'thiscan minimize the risk of further spread of the disease whilealso reducing the exposure of frontline workers to the virus while china and india have routinely used drones for thispractice since the onset of the covid outbreak spainhas become the rst european country to deploy drones forpandemic management ',\n",
       " 'the spanish military has recentlyadopted the use of agricultural drones made by dji a leadingchinese drone manufacturer to spray disinfecting chemicalsover public spaces ',\n",
       " 'as per dji s claims the drones havea load capacity of liters and can disinfect one tenth of akilometer in an hour e ',\n",
       " 'delivery of medical supplies and otheressentialsin september researchers from the national universityof ireland were able to use a ua v to deliver diabetesmedication from galway to a remote location in the aranislands ',\n",
       " 'this was the rst successful beyond visual lineof sight diabetes drone mission and it showedthe world how drones have the capability to carry medicalsupplies reliably ',\n",
       " 'in the current state of crisis this func tionality can prove to be particularly valuable to reduce theburden on the hospitals and health care staff ',\n",
       " 'drones can beused for the rapid delivery of medicines and supplies fromvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicone medical facility to another or from medical centersto the covid patients being cared for in their homes ',\n",
       " 'an example ofthe former was seen in china when a drone was used to movemedical supplies from the disease control center in xinchangcounty to the people s hospital in xinchang county withoutexposing humans to infection marut drones a hyderabad based startup led by a teamof indian institute of technology alumni recentlylaunched an entire line of drones to combat the covid pandemic in india ',\n",
       " 'the company has drones for sanitizingmedicine delivery thermal analysis movement monitoringand crowd surveillance in its arsenal of drones to combatthe covid pandemic ',\n",
       " 'the company claims that theirmedical delivery drones equipped with obstacle avoidanceand advanced navigation technology can cover a distanceof kilometers in merely minutes thereby ensuring med ical deliveries times faster than the conventional meth ods ',\n",
       " 'marut drones has already offered a few dronesto various authorities in telangana to monitor crowds anddisinfect public places ',\n",
       " 'as per the company sestimates their disinfectant drones have already disinfectedareas covering more than km ',\n",
       " 'pending approvalfrom the government of india the company also hopesto deploy its delivery drones soon in the usa following the devastating impact of thecovid various steps are being taken by different usbodies to introduce drone technology in the country ',\n",
       " 'thesmall ua v coalition has led a petition for expeditedfederal aviation administration approvals to allowthe use of drones for delivering medical supplies ',\n",
       " 'fur thermore zipline a medical product delivery companyis planning to establish an active medical supply deliverynetwork ',\n",
       " 'by delivering urgent medication directly to people sdoorsteps zipline hopes to reduce the burden on delivery per sonnel while also promoting the practice of social distancingamong people apart from being a safe way for delivery of medical sup plies drones can facilitate the delivery of groceries as wit nessed in some parts of australia china and the usa in china the e commerce giant jd com has started usinga few of its drones to make last mile deliveries of essen tial goods ',\n",
       " 'meanwhile in the usa google s parentcompany alphabet has recorded a considerable increase inthe number of deliveries made using its autonomous dronedelivery services known as wing f ',\n",
       " 'challengesdespite the numerous bene ts that ua vs can provide inresponse to health crises like the covid pandemicthe use of drone technology is confronted by certain chal lenges and limitations the integration of ua vs in the covid impactresponse system in many countries is limited by the lackof clear government regulatory policies vulnerabilities in drone operations such as gps jamming and hacking make drones an attractiveprospect for malicious users to conduct cyberterrorismand other unlawful activities ',\n",
       " 'in recent times manylaw enforcement agencies have voiced their concernsabout the security risks posed by drones although considerable strides have been made in theadvancement of drone technology in recent yearsbeyond visible line of sight drone opera tions remain somewhat unsafe ',\n",
       " 'there is a growing needfor technological and operational guidelines to warrantthe safe operations of ua vs and consequently to reaptheir comprehensive societal bene ts at present ua vs face several constraints in terms of bat tery life and load capacity which inhibits their capabilityto cover long distances and make multiple deliveries atonce while a few challenges plague the wide scale use of dronetechnology the great promise that it holds in regards tohealthcare support cannot be overlooked ',\n",
       " 'even then manycountries have not yet adopted the use of ua vs in the ghtagainst the covid pandemic ',\n",
       " 'to this end governmentauthorities should carefully collect and assess data in regardsto existing ua v projects and put more effort into ua vresearch and development xii ',\n",
       " 'robots autonomous vehiclesmuch like drone technology other autonomous technologieslike robots and autonomous vehicles have made greatstrides in the ght against the covid pandemic ',\n",
       " 'in thissection we discuss how authorities around the world haveemployed the use of these autonomous technologies to miti gate the impact of the covid pandemic a ',\n",
       " 'robotsas governments and medical organizations around the worldstruggle to contain the spread of the covid robots arebeing deployed to assist in the treatment of patients andconsequently alleviating the stress levels of the healthcareworkers ',\n",
       " 'additionally robot controlled noncontact ultra violet surface disinfection methods are also beingemployed to limit the transfer of the disease via contami nated surfaces ',\n",
       " 'compared to the practice of manual decon tamination which involves the deployment of cleaning staffand subsequently puts them at risk of contracting the virusautonomous disinfection robots ensure rapid and effectivedisinfection of the premises with little to no human con tact ',\n",
       " 'presented below are a few examples of howrobots are being used in hospitals around the world to aid incovid impact management in india a kerala based startup named asimov roboticshas developed a three wheeled robot that can be used toassist patients residing in isolation wards ',\n",
       " 'the robot iscapable of doing tasks like serving food to the patients aswell as giving them medication thereby reducing some volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicburden on the healthcare workers and freeing them fromthe risk of contracting the infection xenex disinfection services a company establishedby two john hopkins educated epidemiologists hasdeveloped an autonomous disinfection robot to helplimit the number of hospital acquired infections xenex asserts that their uv lightstrike germ zappingrobots have the potential to ef ciently obliterate alltypes of germs including various types of viruses andbacteria ',\n",
       " 'xenex has reported witnessing an enor mous surge in demand for its uv germ zapping robotespecially from countries like singapore japan southkorea and italy a danish robotics company uvd robots has devel oped multiple disinfection robots to be delivered inhospitals around the world ',\n",
       " 'to date uvd robots hasdelivered its robots to several provinces in china severalparts of asia and healthcare markets in europe and theunited states ',\n",
       " 'these robots emit powerful uv light thatcan disinfect surfaces by tearing apart strands of virus dna ',\n",
       " 'the danish company claims that their robots canoperate for about hours and disinfect about nine orten rooms on a single charge according to a leading robotics expert from the carnegiemellon university in addition to the tasks mentionedabove robots with the potential to execute tasks like obtainingnasal samples for testing and rendering support to isolatedpatients may also be developed soon b ',\n",
       " 'autonomous vehiclesamid the global health crisis that is the covid pandemica vs could help ease the stress on existing delivery mecha nisms while mitigating the risk of virus transmission china has led the charge in the use of autonomous vehi cles against the pandemic ',\n",
       " 'in fact at the time of writingit is believed to be the only country in the world to deploy a vsfor covid impact management ',\n",
       " 'beijing headquarteredwhite rhino auto company in alliance with unido sinvestment and technology promotion of ce dis patched two autonomous delivery vehicles from beijing tothe guanggu field hospital in the hubei province of china these vehicles have proved to be highly useful for a varietyof tasks such as delivering medical supplies and meals ',\n",
       " 'theuse of a vs not only lessened the workload on the overbur dened hospital staff but it also helped in limiting the risk ofcross infection xiii ',\n",
       " 'wearableswearables are communication enhancing devices worn onthe body that are connected to an internet source ',\n",
       " 'wearablesrange from smartwatches like apple watch tness trackerslike fitbit smart headbands like dreem to personal sensors patches ',\n",
       " 'the ability to monitor people s physical healthalong with their stress levels has made wearables an idealtechnology for adoption in the healthcare sector ',\n",
       " 'in the midstof the current health crisis various organizations have modi ed their existing offerings or rolled out new wearables to aidin covid impact management ',\n",
       " 'some of these technolo gies have been discussed belowa ',\n",
       " 'whoop strap a boston based human performance technology start upwhoop has collaborated with a team of researchers at thecentral queensland university in australiato examine a potential link between alterations in respiratoryrates and the covid symptoms ',\n",
       " 'the primary objectiveof this study is to be able to develop a mechanism that canidentify the covid well during its incubation periodby detecting early signs of abnormal respiratory behaviorin covid patients ',\n",
       " 'with a high reproductive numbera factor that has made the covid outbreak so severethis sort of an early warning system can help slow the globalproliferation of the covid in association with the cleveland clinic the researchers atcquniversity s appleton institute plan to carry out a studyusing physiological data gathered via the wrist mountedwhoop strap from hundreds of whoop memberswho have identi ed themselves as having the covid andvolunteered to be a part of the study ',\n",
       " 'by discerningany deviation in respiratory rates of an individual from theirestablished baseline the strap can notify that individual ofany issues that they might experience ',\n",
       " 'this study will alsocollect data from the whoop journal a recently launchedonline interface accessible from the members smartphonesthat enables them to monitor their daily behavior and makehealthier lifestyle choices although a few watches from garmin and fitbit also havethe functionality to measure respiratory rates whoopclaims to be the only wearable to have its accuracy of mea suring cardiorespiratory variables validated by a third partystudy b ',\n",
       " 'estimote workplace level contact tracingwearableestimote a start up known for its bluetooth location bea cons has recently developed a set of wearable devices toenable contact tracing at the workplace in an attempt toprovide employees with a safer workplace environment ',\n",
       " 'thiswearable device allows organization leaders to monitor thehealth status of their employees remotely and to keep arecord of any case of covid transmission amongst them it empowers an organization s leaders to curb the diseasespread before it spreads rampantly within the organizationor even outside it ',\n",
       " 'when this device is turned onit scans for other wearable devices and records any closeinteractions with them ',\n",
       " 'the devices hardware includes a pas sive gps location tracker in addition to bluetooth poweredproximity sensors ultra wideband connectivity built in lteand a rechargeable battery ',\n",
       " 'furthermore every devicehas led indicators and buttons just like a smartwatch ',\n",
       " 'thepurpose of these buttons is to allow the employees to logvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemictheir real time health status ',\n",
       " 'for example the wearer canupdate his her health status as certi ed healthy symptomaticor veri ed infected ',\n",
       " 'when the wearer updates his her healthstatus it is recorded in a central database that stores theinformation for up to six weeks ',\n",
       " 'there are three variants ofthese devices a pebble like device to be worn around theneck a wrist worn version and a device in the form of a card c ',\n",
       " 'lifesignals biosensor patcha silicon valley start up named lifesignals plans to launch anovel biosensor patch that leverages the cardiovascular moni toring technique to assist early detection of the covid inan individual ',\n",
       " 'this single use showerproof and lightweightwearable named biosensor patchax when af xed on thechest area can record the temperature of the person alongwith his her respiration rate ecg trace and even the heartrate in real time ',\n",
       " 'this data is automatically sent from theuser s patch to an application on the user s smartphoneenabling them to view their data in real time ',\n",
       " 'in casea person using this patch develops covid symptomshis her data can also be sent to a centralized and securecloud platform alerting the healthcare workers of a potentialcovid patient ',\n",
       " 'the patches have been designed insuch a way that it can be worn by an individual for ve daysin one go post which they can be safely disposed to ensurethat the disease does not spread from the patch lifesignals also plans to launch the second version of thepatch biosensor patch a in june ',\n",
       " 'by storing and streamingclinical grade vital signs of a patient the patch will enable thehealthcare workers to monitor covid patients admittedto the intensive care units d ',\n",
       " 'spry health s loop signalspry health is a company that is known for its healthmanagement and telemedicine technologies ',\n",
       " 'this companyhas launched a wearable device called loop signal to limitpatients from visiting hospitals unnecessarily especially dur ing such times ',\n",
       " 'loop signal helps healthcare personnel toremotely manage the health of people who have symptomsof covid ',\n",
       " 'worn on the wrist loop signal tracks theheart rate respiratory rate and pulse oximetry of the patient all these parameters are critical to assess the severity ofthe covid in a patient and can therefore empowerhealthcare professionals to make an in person visit only ifthe patient s condition warrants it ',\n",
       " 'this easy to wear devicehelps in collecting hundreds of data points for a patient on adaily basis ',\n",
       " 'the aggregation of a large number of data pointsprovides a much needed certainty about the present conditionof a patient as opposed to a single data point that may evenbe an error sometimes leading to false alarms e ',\n",
       " 'sphcc with cassia and vivalnkshanghai public health clinical centre hasemployed the use of bluetooth iot gateways developedby cassi network and wearable sensors developed byvivalnk to monitor covid patients with minimalhuman contact ',\n",
       " 'china has been successful in reducing thecount of covid thanks to the advent of such tech nologies ',\n",
       " 'in the mechanism put in place by the sphccvivalnk s wearable sensors constantly supply real time dataabout the changes in the body temperature of the patient ',\n",
       " 'cas sia s gateways then collate this data and transmit it wirelesslyto the healthcare staff s station ',\n",
       " 'this enables rst line health care workers to keep track of their patients health withouthaving to visit them personally ',\n",
       " 'the cassia iot gatewaysallow nearly bluetooth low energy devices tobe paired at the same time thereby facilitating connectivitybetween multiple rooms of the sphcc ',\n",
       " 'the use of thesetechnologies in the sphcc has signi cantly reduced thehealthcare workers risk of exposure to the infection whilealso ensuring reduced workload f ',\n",
       " 'challengesalthough wearables have played a signi cant role in the ght against the covid pandemic it is essential to notethat certain challenges limitations hinder the use of wearablesamid the current health crisis due to lockdowns and interrupted supply chains deliv ery of these wearables is challenging in many parts ofthe words the battery life of smart wearables is usually in question the tedious task of charging wearable devices again andagain often dissuades users from buying these devicesaltogether there are no established guidelines about the use of theprivate data accumulated using these wearables whichgives rise to a multitude of security and privacy con cerns ',\n",
       " 'it is necessary to ensure that the developmentof such wearables is done while keeping in mind thesecurity and privacy preservation of the users xiv ',\n",
       " 'mobile applications other platformsthe use of mobile applications has emerged as a prominent strategy in the ghtagainst the covid ',\n",
       " 'several governments and privateorganizations around the world have already developed cer tain apps and platforms for covid impact managementwhile several others are in the process of doing so ',\n",
       " 'most ofthese modern platforms use a wide variety of technologiesincluding bluetooth global positioning system andgeographic information system ',\n",
       " 'certain apps havealso adopted the use of blockchain an emerging technologythat helps in storing data in the form of immutable blocks table lists the key technologies being used to developcontact tracing applications ',\n",
       " 'in this section we discussa few of the numerous applications that have emerged in thelast few months for combating the covid crisis a ',\n",
       " 'blockchaina blockchain is a continuously expanding record of transac tions between two parties ',\n",
       " 'such records can be used volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure contact tracing applications for covid to verify the claims of a party that a transaction has indeedhappened ',\n",
       " 'blockchain is gaining more and more prominenceeach day thanks to its wide applications in various walksof life ',\n",
       " 'seeing its utility numerous companies andauthorities across the globe have started using blockchain tobuild apps that can help in countering the covid ',\n",
       " 'theseapps aim to address a crucial problem which is the lack ofintegration of veri ed data sources ',\n",
       " 'according to experts oneof the main advantages of using blockchain enabled apps isblockchain s capability of validating continuously changingdata ',\n",
       " 'this feature can prove to be quite valuable in man aging the rapidly escalating covid situation ',\n",
       " 'discussedbelow are two blockchain based applications developed inan attempt to help ght the covid pandemic civitasa canadian start up specializing in blockchain solutions hasrecently launched a safety system in the form of an appknown as civitas that may assist local authorities in variousnations of the world to control the impact of the covid ',\n",
       " 'this app associates people s of cial ids with blockchainrecords to verify whether the person has permission to leavetheir homes or not ',\n",
       " 'this app also determines the ideal timeand day for people exhibiting the covid symptoms togo out and buy essential items thereby minimizing the riskof infecting others ',\n",
       " 'additionally civitas offers a built intelemedicine functionality that allows doctors to keep trackof their patients symptoms and send them notes in regardsto the medicines to be used and healthcare strategies to befollowed ',\n",
       " 'as per the company s claims the app makes surethat people s data remains private and secure mipasamipasa is a data streaming platform built on top of thehyperledger fabric ',\n",
       " 'this platform also draws on the servicesprovided by the ibm blockchain the ibm cloud platformsto facilitate the sharing of veri ed health and location infor mation among individuals authorities and hospitals ',\n",
       " 'thisapplication works by collecting the information provided byvarious medical organizations public health of cials andother individuals ',\n",
       " 'the who recently acknowledged thisapp to be an effective platform for helping the doctors gainaccess to veri able information ',\n",
       " 'the data available on thisplatform can help the hospitals to determine their futureaction plans and to ef ciently allocate their resources toalleviate the impact of the covid outbreak volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicb ',\n",
       " 'geographic information system understanding the geography of the spread of thecovid is crucial to comprehend the severity of the crisisin a particular region and to deploy appropriate measuresto mitigate the impact of the disease in that region ',\n",
       " 'to thisend the gis systems use spatial analytics mapping andlocation intelligence to map the occurrence of the diseasesagainst multiple parameters such as demographics envi ronment and past occurrences ',\n",
       " 'this kind of data will help epidemiologists to understand the origins of the outbreakand governments to identify high risk areas and deployhealthcare facilities accordingly esri arcgis applicationcalifornia based environment systems research insi tute is an international provider of gis softwarewhose product line includes arcgis desktop arcgis proarcgis enterprise among others ',\n",
       " 'following the outbreakof the covid the esri has partnered with several pri vate organizations around the world to launch the esricovid resources and gis hub featuring a compila tion of datasets dashboards applications and other helpfulresources to facilitate adequate planning against the pan demic ',\n",
       " 'additionally esri has joined forces with variousgovernment agencies around the world to help them exploitgis technology for taking proactive measures to manage thecovid spread c ',\n",
       " 'bluetoothbluetooth is one of the most useful technologies used foraccurate proximity calculation ',\n",
       " 'it is also one of the leastinvasive technologies since it does not monitor the exactlocation of a cell user but rather the relative distance betweenhis device and that of another ',\n",
       " 'bluetooth contact tracingapplications generally monitor the proximity between twopeople by calculating the distance between their devices usingthe received signal strength indicator measure ',\n",
       " 'suchapps store records of all of a device s prior bluetooth connec tions including the time for which it maintained a bluetoothconnection with another device ',\n",
       " 'in case a person is diagnosedwith the covid these apps can leverage the bluetoothconnection history of that device to trace all the people whohad exposure to the infected individual ',\n",
       " 'these apps can makeit simpler for the authorities to effectively determine potentialcovid patients and use appropriate measures to quaran tine them ',\n",
       " 'some of the apps that use the bluetooth technologyfor contact tracing are mentioned below tracetogethertracetogether is a contact tracing app launched by the gov ernment of singapore which uses bluetooth technology todetermine the history of exposure of an unaffected indi vidual to an infected one ',\n",
       " 'whenever two people with thismobile application come into close contact with each otheran encrypted code is transferred between their devices andstored in their apps provided that bluetooth is turned on inboth the devices ',\n",
       " 'if a person with this app is later diagnosedwith the covid the authorities can check the recordsstored in his her app to trace all the people who had come intoclose contact with the infected person ',\n",
       " 'this app does not usegps to pinpoint a user s location thereby allaying the fearsof those people who are worried about their privacy ',\n",
       " 'as on april nearly million downloads were recorded forthis app which incidentally is a record for the highest numberof downloads for an application hosted by a governmentwebsite in singapore ',\n",
       " 'however this number is still notconsidered to be enough by the government of singapore asthe reliable functioning of this application requires participa tion from everyone in the country and million correspondsto just one sixth of singapore s entire population apple google s joint contact tracingtechnologyin light of the current health crisis two silicon valley techgiants apple and google have teamed up for a rare joint ven ture to help governments and medical organizations aroundthe world in their ght against the covid ',\n",
       " 'they planto develop a privacy preserving framework that incorporates application programming interfaces and operatingsystem level technology to assist public contact tracingapplications ',\n",
       " 'in a bid to safeguard user s privacythe framework is set to use only the bluetooth technology fortracking the spread of the covid ',\n",
       " 'furthermore the twocompanies claim that data from the user s smartphone willnot be made available to anyone without the user s consent their framework will enable contact tracing applications touse bluetooth low energy technology to log people sinteractions and keep track of whether a smartphone ownerhas come into contact with someone who is later diagnosedto be covid positive ',\n",
       " 'if indeed this scenario takes placethe user is sent an alert stating that he she has come intocontact with someone who is now diagnosed with the dis ease ',\n",
       " 'once alerted such users can then self isolate or getthemselves tested ',\n",
       " 'at present the framework is still in thedevelopment stages with the api expected to be launchedin may while the os level technology to be rolled out inthe following months ',\n",
       " 'the draft technical documentationfor the framework can be found in and the overviewof the api s working can be found in d ',\n",
       " 'gpsglobal positioning system is a satellite navigationsystem owned and maintained by the united states govern ment that provides users with positioning navigation andtiming services ',\n",
       " 'by leveraging this technol ogy government authorities around the world can monitorthe real time location as well as the historical location ofcovid positive patients in their country which can sub sequently enable them to trace other potential covid patients ',\n",
       " 'mentioned below are of cial contact tracing appsof two countries that make use of the gps technology volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemictable challenges associated with the implementation of various technologies in mobile applications aarogya setu appthe national informatics centre a subdivision of india sministry of electronics and it has recently devel oped a contact tracing app called aarogya setu to help curbthe spread of the covid in india ',\n",
       " 'any indian citizen candownload this application for free and register using theirmobile number to use this app s services ',\n",
       " 'on launching thisapplication it asks the user if they are facing any symptomsof the covid or if they have an international travelhistory if not the user is classi ed as belonging to thegreen zone ',\n",
       " 'this application currently supports indian lan guages and is available for both ios and android users unlike tracetogether this app uses the gps location of thecellphone user in addition to the bluetooth technology todetermine if an individual has been exposed to any potentialcovid patient listed in its database ',\n",
       " 'in a scenariothat an individual belonging to the green zone comes incontact with someone who is later marked as belonging to thered zone this app immediately sends an alert to the formernotifying him her of the guidelines that he she should follow additionally this app provides its users with easy access torelevant information ',\n",
       " 'on its release the aarogya setuapp became instantly popular among the indian public ',\n",
       " 'theapp garnered over million downloads in just ve days ofits launch ',\n",
       " 'in response to the privacy concerns surroundingthe app s use of gps technology the government ofindia has assured its citizens that the data which theapp collects is encrypted and will not be used for any purposebesides contact tracing hamagen appa contact tracing app called hamagen launched recently byisrael s health ministry has sparked massive interest fromthe governments of italy australia and germany amongothers ',\n",
       " 'hamagen makes use of the gps technology to deter mine if any app user has come in contact with someonevolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicwho has been tested positive for the disease ',\n",
       " 'quashingthe rumors surrounding the application s privacy pitfallsthe health ministry has issued a statement maintaining thatany user s private data does not leave the phone withouthis her consent ',\n",
       " 'the app s functioning relies heavily on theuser s self reported information regarding their exposure tothe covid ',\n",
       " 'within the rst week of the app launcharound app users claimed that they had adopted themeasure of self isolation e ',\n",
       " 'voice detectionfollowing the covid outbreak several voice detectionapps have been developed for covid screening ',\n",
       " 'voicedetection applications require users to voluntarily provide asample of their voice based on which the app decides whetheror not a person has symptoms of the covid ',\n",
       " 'two promi nent attempts at developing such voice detection platformsfor covid screening have been discussed belowv an automated ai system has been designed by a team ofresearchers from carnegie mellon university to detectthe presence of the covid in an individual basedon his her voice ',\n",
       " 'after logging in to the app a user isasked for his height and weight followed by a requestto cough three times ',\n",
       " 'post this he she is asked to recitean alphabet and a vowel loudly which nally helpsthe app in measuring the lung capacity of the userby comparing it with thousand s of other users dataincluding those who are infected ',\n",
       " 'by the end ofthis brief process the user is given a score out of a higher score indicates that a user s features are highlysimilar to the features exhibited by covid patients the researchers however have added a word of cautionstating that this is not a diagnostic process and can neverbe substituted for tests conducted in the hospitals and thelaboratories a similar mobile application for voice basedcovid diagnosis has also been developed by stu dents of the dy patil institute of bio technology andbio informatics mumbai india ',\n",
       " 'this app iscurrently being tested at the university of tor vergatain rome italy ',\n",
       " 'to use the app one has to speak intothe microphone of his her device following which theapp breaks the sound into multiple parameters includingfrequency and noise distortion ',\n",
       " 'the values of theseparameters are then compared to an average person sparameter values to determine if an individual is poten tially infected with the covid f ',\n",
       " 'challengesalthough many people have hailed the efforts made byvarious governments and organizations in building contacttracing apps a school of thought exists that believesthat contact tracing applications even the ones that claimto respect user s privacy are not secure and can blatantlyabuse the privacy of people ',\n",
       " 'in addition to theprivacy concerns associated with the use of contact tracingapps several issues in terms of accuracy and reliability alsoimpede their performance it has become quite evident that the covid is here tostay unless adequate measures are taken to ght it effectively governments and health of cials alone cannot vanquish thecurrent health crisis ',\n",
       " 'people around the world need to workcollectively with their governments to expedite the end ofthis pandemic and get things back to normalcy ',\n",
       " 'for examplemost of the tools mentioned above require the support ofthe masses to yield fruitful results ',\n",
       " 'the mere presence oftechnologies such as smart thermometers and smart wear ables is meaningless unless people are willing to use themto ght covid ',\n",
       " 'the use of telemedicine platforms isinconsequential unless patients are willing to trust their healthexperts ',\n",
       " 'even the most straightforward contact tracing appsare worthless unless people are willing to use them when theyventure out of their homes ',\n",
       " 'in the coming times the actionstaken not just by the governments but also by the peoplewould in uence the extent of the havoc wreaked by thecovid pandemic xv ',\n",
       " 'artificial intelligencesince its inception ai has proved to be a landmark tech nological advancement ',\n",
       " 'if used properly it stands to be ahighly effective tool against the covid pandemic mentioned below are some of the actual and potential waysin which ai can aid the authorities in effectively combatingthe covid pandemic disease surveillance risk prediction medical diagnosis and screening curative research virus modeling and analysis host identi cation busting fake news enforcing the lockdown measuresin the subsections that follow we review all of the aforemen tioned applications in detail a ',\n",
       " 'disease surveillancethe timely surveillance and forecast of diseases especiallythe ones with the ability to lead the world into a stateof disarray is crucial ',\n",
       " 'to this end a toronto based healthsurveillance company bluedot was successful in reportingan impending outbreak of coronavirus on december nine days before the who ',\n",
       " 'bluedot s ai model lever ages several machine learning and natural languageprocessing tools to look for evidence of emergingdiseases ',\n",
       " 'this model has allowed bluedot to track the spreadof the sars cov and forecast its outbreak well beforeepidemiologists ',\n",
       " 'however that does not go as far as sayingthat no human effort was required to do the same ',\n",
       " 'whiletheir ai model was able to give predictions in regards to the volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure applications of ai for covid pandemic impact mangement outbreak of the disease human interpretation of the model soutput remained central to its working besides bluedot several other organizations have adoptedthe use of ai to estimate the risks associated with emerginginfections ',\n",
       " 'for example a risk analytics company foundedin metabiota has developed an epidemic monitoringplatform that allows it to forecast the spread of diseases metabiota bases its predictions on factors like the infection sclinal features fatality rate and the availability of treat ment ',\n",
       " 'other functionalities of metabiota s epidemic trackerinclude providing detailed information and up to date statis tics on over novel pathogens in addition to these efforts a few scientists have also pro posed the use of such technologies in identifying potentiallyfatal zoonotic viruses well before they cause damage to thehuman population ',\n",
       " 'the global virome project is anexample of one such endeavor ',\n",
       " 'the gvp aims to establish agenetic and ecological database of viruses in various animalspecies that are capable of infecting humans ',\n",
       " 'the large vol ume of data that they collect on viruses could also be used toshape ai technologies to predict which zoonotic viruses havethe potential to cause the most harm to the human species such mechanisms can allow for the proactive developmentof vaccines drugs and preventive measures b ',\n",
       " 'risk predictionone of the possible avenues of application of ai againstcovid is risk prediction ',\n",
       " 'broadlyrisk prediction can be classi ed into the followingcategories predicting the risk of getting infected predicting the risk of developing severe symptoms onceinfected predicting the risk of using a speci c line of treatmenton an infected person typically the risk of getting infected is a function of amyriad of factors ',\n",
       " 'these include age travel history hygienehabits current health status pre existing health conditionsand family medical history ',\n",
       " 'direct mathematical modelingof such factors would not yield fruitful results ',\n",
       " 'howevera comprehensive analysis of these factors integrated with aitechniques can offer a more precise and reliable previsionof individual risk pro les ',\n",
       " 'for example authors in describe an ml based stratagem to build a vulnerability indexfor individuals susceptible to the novel coronavirus once a person is infected ai capabilities can also beused to determine the probability of survival and the require ment of icu treatment for covid patients ',\n",
       " 'to this endphysicians at universities like stanford and the university ofchicago are making attempts at augmenting their existing aisystems to accurately identify the covid patients whosecondition might worsen ',\n",
       " 'earlier these systems have provedtheir mettle in predicting whether or not heart disease patientswill require a transfer to the icu ',\n",
       " 'in another effort bayesianhealth a start up tracing its roots to the john hopkins univer sity has started working on an early warning system for acuterespiratory distress syndrome one of the severesymptoms associated with the covid ',\n",
       " 'the authorsof have also proposed an ai framework that leveragespredictive analysis performed on real covid patientsto support clinical decision making ',\n",
       " 'their ai poweredvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicpredictive model is capable of identifying people with ahigher likelihood of developing severe symptoms like ardsbased on initial presentation ',\n",
       " 'according to their results theirmodel achieved an accuracy of in predicting severecases of the covid in addition to the use cases mentioned above ai tech niques particularly machine learning algorithms can also beused to correlate the patient s data parameters with a speci cdrug s usage ',\n",
       " 'such correlations can be used to predict theeffect of the drug on a speci c group of patients ',\n",
       " 'pre emptiveknowledge of these factors can enable the doctors and medi cal suppliers to be better prepared for the consequences c ',\n",
       " 'medical diagnosis and screeningrapid diagnosis of the covid can allow governments totake effective response measures to limit the disease s furtherspread ',\n",
       " 'the shortage of testing kits worldwide however hasmade it hard for the authorities to carry out large scale diag nostic testing ',\n",
       " 'many existing ai tools are being repurposedwhile some new ones are also being built to solve this prob lem ',\n",
       " 'in this subsection we examine the various ways in whichai is revolutionizing the process of covid screening anddiagnosis face scannersfollowing the covid outbreak various authorities usedir temperature scanners at different public places to screenpeople for a fever ',\n",
       " 'this technology however requires thepresence of frontline personnel to carry out the scan ',\n",
       " 'to limitthe exposure of the frontline staff to potential covid patients several hospitals airports and medical centers haveadopted the use of cameras with ai based multisensory tech nology ',\n",
       " 'these cameras can not only enable the author ities to observe the crowds and identify individuals with highbody temperatures but they can also be used to recognizetheir faces and trace their movements ',\n",
       " 'one of the rst hos pitals to use this technology was the tampa general hospitalin florida usa ',\n",
       " 'the hospital installed an ai enabled cameraat its entrance to screen all the entering patients for elevatedbody temperatures by giving them a thermal face scan ',\n",
       " 'theirai system uses machine learning and ndings of the camerato classify whether or not an individual is manifesting thesymptoms of the covid medical imagingai technology has considerable potential to improveimage based medical diagnosis ',\n",
       " 'according to the researchersat the un global pulse analysis of computed tomogra phy scans and x rays using ai enabled tools can saveradiologists time by offering more timely medical diagno sis than current tests for the covid ',\n",
       " 'to this endmultiple efforts have already been made to employ the use ofai enabled medical imaging to diagnose the covid a beijing based start up that specializes in building anoncology data platform and performing medical dataanalysis linkingmed has put forth an ai based modelfor screening pneumonia through ct scan analysis since pneumonia is one of the most common clini cal features of the covid identifying the presenceof pneumonia can help identify potential covid patients ',\n",
       " 'linkingmed s open source ai model is basedon baidu s parallel distributed deep learning platform paddlepaddle a joint effort between the researchers at the univer sity of waterloo and an ontario based ai start updarwinai has yielded a convolutional neural net work to diagnose covid using chest x rays labeled covid net this ai algorithm has been madeopen source by the research team to facilitate the devel opment of ai tools over their model another ai model for diagnosing the covid usingx rays has been put forth by a few researchers at thedelft university of technology netherlands ',\n",
       " 'namedcadvocid this model is built on top of an ai modeldeveloped at the same university for the diagnosis oftuberculosis although the use of ai powered medical imaging techniqueshas been perceived to have great potential in covid diagnosis several radiologists have voiced some issues con cerning such techniques ',\n",
       " 'firstly the lack of unbiased datahinders the performance of ai models ',\n",
       " 'secondly the use ofmedical imaging techniques can potentially contaminate theequipment used and may well cause the disease to spreadfurther ai powered medical diagnosis in south koreain the republic of korea several ai powered tools havehelped the country in quick examination and identi cationof covid patients ',\n",
       " 'an algorithm to detect unusual obser vations in the patient s chest x rays vuno s chest x rayimage support decision tool has the potential to recog nize the individuals in need of intensive care ',\n",
       " 'to do sothe algorithm studies the patient s x ray images and examineswhether or not there is an issue with the patient s lungs another ai platform named aihub has been developed inthe republic of korea by an ai based medical and securitysolutions company jlk inspection ',\n",
       " 'the platform uses theai and big data capabilities of several imaging devices todiagnose any lung conditions that the patient might have in amatter of seconds ',\n",
       " 'in addition to various covid diagnosisplatforms ai has also played an essential role in acceleratingthe development of testing kits in korea ',\n",
       " 'these testing kitshave been approved by not only the authorities in korea butalso by the european union covid voice detection systemsvoice detection is one of the simplest technologies that canbe employed to identify potential covid patients ',\n",
       " 'duringthese dif cult times when there is a serious dearth of testingkits voice detection platforms can act as a screening measure volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicto decide who needs to be tested ',\n",
       " 'for more details on howvoice detection platforms are currently in use kindly refer tosection xiv e from all the examples presented above it is crucial to notethat ai is better suited to assist the screening of covid patients rather than diagnosing them altogether ',\n",
       " 'to be ableto diagnose any covid patient accurately ai devicesplatforms and algorithms must be suf ciently robust so asto detect all possible mutations of the virus d ',\n",
       " 'curative researchbeing novel one of the major problems with thesars cov is the lack of existing research and treatmentprotocols for the virus ',\n",
       " 'however by analyzing the currentcases of the covid as well as the existing research ondifferent diseases ai can prove to be a bene cial technologyto speed up the process of drug development ',\n",
       " 'several organi zations and research labs have already adopted the use of aito identify potential treatments for the covid ',\n",
       " 'ai can notonly expedite the drug development process but it can alsoaid in the process of discovering existing drugs drug developmentmachine learning a subset of ai has proved its effec tiveness in the process of drug development in the timesof previous health emergencies ',\n",
       " 'for example during theebola epidemic bayesian ml models were used to speedup the process of discovering molecular inhibitors againstthe virus ',\n",
       " 'similarly the authors of adopted theuse of ml assisted virtual screening and scoring to speed upthe process of discovering viral inhibitors against the avianhn virus responsible for recurring in uenza epidemics inchina ',\n",
       " 'in light of the current pandemic ml models similar tosuch models can aid in expediting the process of developingdrugs that can possibly be used to treat the covid repurposing existing drugs compoundsin addition to being able to aid in drug development scientistsare also using ai to help in identifying existing drugs that canbe repurposed to treat the covid a germany based start up named innoplexus ag hasexercised the use of its ai powered drug discoveryplatform to identify a combination of existing drugsthat may prove useful in the treatment of the covid ',\n",
       " 'after extensive analysis of existing data associatedwith the covid their platform has revealed thatchroloquine an anti malaria drug may work better incombination with remdesivir or tocilizumab or pegasys or clarithromycin a similar effort is being made by a british start upnamed exscientia in collaboration with diamondlight source uk and calibr a division of thecalifornia based scripps research institute ',\n",
       " 'exscientiaaims to use its ai drug delivery platform to arrive at acombination of compounds that could prove to be ben e cial in treating the covid ',\n",
       " 'to do so exscientiaintends to screen some clinically ready moleculespresent in calibr s compound library against three keyviral drug targets of the sars cov ',\n",
       " 'earlier thisyear exscientia developed the rst ever ai created drugto enter the clinical trials researchers from the republic of korea and the usaare using deep learning to investigate the effective ness of an existing antiretroviral drug used to treathiv aids named atazanavir in the treatment of thecovid researchers at a uk based ai company benevolentai have identi ed baricitinib as a potential drug totreat the covid ',\n",
       " 'following their research baric itinib has entered a controlled trial with the unitedstates national institute of allergy and infectious dis eases gero ai powered drug discovery and drug repurposingplatform developed by a group of scientists in singa pore has assisted in the identi cation of several existingdrugs including a drug named afatinib that could potentially beused to treat the covid various ml techniques are also being used to iden tify drug candidates by predicting drug target interac tions between the virus s proteins and existingdrugs ',\n",
       " 'the authors of for example built adeep learning deeper feature convolutional neuralnetwork system that can identify classifyprotein ligand interactions with reasonably high accu racy ',\n",
       " 'thus the use of ai can not only help in sug gesting possible candidates for treatments but alsoanalyze their expected effectiveness ',\n",
       " 'another exam ple of this approach is given in where a deeplearning based drug target interaction model moleculetransformer drug target interaction hasbeen developed to identify commercially available drugscapable of acting on sars cov viral proteins although much effort is being put into the discovery ofsuch treatments it is highly unlikely that any of them will beavailable shortly ',\n",
       " 'these candidate treatments have to undergoextensive scienti c checks and clinical trials before they areapproved for commercial use e ',\n",
       " 'virus modeling and analysisthe key to developing a successful treatment againstcovid is to understand the virus itself ',\n",
       " 'since virusescannot reproduce by themselves they rely on host cells tomanufacture copies of their dna ',\n",
       " 'to do this a virus typicallyinfects a host cell by binding itself to the host s receptors via alock and key mechanism ',\n",
       " 'the working mechanism for mostinhibitor based agents is to prevent this from happening byvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure debunking myths surrounding the covid blocking the receptors of the target cells ',\n",
       " 'thus the design ofeffective inhibitors requires scientists to model the bindingmechanism ',\n",
       " 'machine learning happens to be one of the mostuseful tools in the scientist s arsenal for building such models in the past ml models trained with protein data haveproved to be successful in predicting protein protein interac tions between the hn virus and human body cellsthereby eliminating the need to model the entire virus hostinteractome ',\n",
       " 'machine learning can also be used tomodel various protein folding mechanisms that the virususes to sustain itself ',\n",
       " 'reference for example employsdeep learning algorithms to predict the structure of a pro tein from its amino acid sequence ',\n",
       " 'knowing a protein sthree dimensional structure is of great importance as its func tioning is strongly correlated to its structure amid the current covid health crisis deepmindgoogle s ai company has adopted the use of its alphafoldsystem to predict the structure of the proteins associatedwith the sars cov ',\n",
       " 'these predictions can aid scientistsin better understanding the overall structure of the virus andconsequently in developing a new drug to treat the covid ',\n",
       " 'it is important to note however that deepmind hasmade it clear that these predictions have not been experimen tally veri ed f ',\n",
       " 'host identificationthe sars cov is a member of the betacov genera of thecoronaviridae family ',\n",
       " 'typically genomes of such viruses area mix of bat and rodent genomes ',\n",
       " 'to date the mammalianhost that facilitated the transmission of the covid tohuman beings is an unknown variable ',\n",
       " 'to this end ml mod els can be used to effectively compare the viral genome withknown genomes and identify similarities between them ',\n",
       " 'sucha database of known genomes is available in ',\n",
       " 'in the authors have proposed the use of a random forest algo rithm to identify the hosts for the in uenza a virus ',\n",
       " 'anotherexample of such an approach is given in ',\n",
       " 'such modelscan be extended to include the sars cov as well g ',\n",
       " 'busting fake newsthe uncertain times following the outbreak of the covid have bred several myths and conspiracy theories ',\n",
       " 'much misinformation has been making the roundson social media platforms ',\n",
       " 'to curb the propagation of thesefake news and provide veri ed information technology com panies like google youtube and facebook have employedthe use of ai techniques ',\n",
       " 'all these platforms have made aneffort to screen content for the presence of even the slight est bit of misinformation ',\n",
       " 'youtube in particular has placedstringent measures to take down any video propagating fakenews h ',\n",
       " 'enforcing the lockdown measuresmany countries around the world including china indiathe usa and the uk are adopting the use of ai to enforcesocial distancing and lockdown measures ',\n",
       " 'in china baiduone of the largest ai and internet companies in the world hasdeveloped computer vision powered infrared camerasto scan public places ',\n",
       " 'these cameras can not only identify volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicpeople with high body temperatures but via the use of theirinbuilt facial recognition system they can also recognize citi zens who are not following the lockdown measures ',\n",
       " 'a similarcv camera system has been deployed in oxford englandto monitor if the crowds are following the social distancingmeasures ',\n",
       " 'an ai based start up in the usa landing aihelmed by one of the most renowned ai experts in the world andrew ng has also developed a social distancing detectiontool that monitors crowds and alerts the authorities wheneversocial distancing guidelines are breached i ',\n",
       " 'challengesarti cial intelligence can conceivably play an essential rolein mitigating the impact of the covid pandemic ',\n",
       " 'how ever at present ai systems are still in the prefatory stages the several challenges and limitations hindering the applica tion of ai in covid impact management are as followsvi to yield reliable and accurate results ai models requirea substantial amount of training data ',\n",
       " 'however owingto the unprecedented nature of the pandemic there isa dearth of historical data on which to train ai mod els which has consequently rendered several ai modelsinef cient ii it is not only the absence of open data that has impededthe performance of ai models too much noisy andoutlier data has also presented a challenge to the ef cientuse of ai technologies ',\n",
       " 'google flu trends failed initia tive sheds light on the fact that a deluge of data hubriscan potentially inundate ai algorithms and inhibit theirfunctioning iii another limitation faced by ai systems particularlymachine learning models is their inherent assumptionthat all possible contingencies in any given situation arethe same as the ones exhibited in the dataset they havebeen trained on iv the use of ai techniques for crowd surveillance is seenby many as a breach of privacy ',\n",
       " 'although at present peo ple have apprehended the fact that public health concernsare more important than data privacy concerns the pri vacy pitfalls associated with the use of ai have instilleda sense of fear among the public that governments maycontinue to monitor them even after the pandemic isover v another limitation of ai in its current form is its depen dence on human knowledge ',\n",
       " 'human expertise is fun damental to guide the implementation of ai techniquesand make a signi cant difference in the ght against thecovid pandemic despite the several challenges facing the ai systemstheir contribution to the ght against the covid pan demic cannot be overlooked ',\n",
       " 'in recent years ai technol ogy has made stunning advances in the elds of nlp mldeep learning data analytics among others ',\n",
       " 'such develop ments serve to prove the potential of ai in assisting thecovid pandemic management system xvi ',\n",
       " 'blockchainblockchain technology has been under extensive delib eration amongst researchers and industrialists in recenttimes especially since the onset of blockchain blockchain ',\n",
       " 'gradually this technology is extend ing its presence to almost all the major domains includ ing the insurance sector the transportation industry dronecommunication technologies and even the healthcaresector ',\n",
       " 'the current health crisis brought bythe covid is neither localized nor independent ',\n",
       " 'thecovid pandemic has left no space for seclusion andpeople all around the globe need to stand united to get throughthis crisis ',\n",
       " 'the nature of the pandemic itself is distributedin nature ',\n",
       " 'therefore distributed ledger technologies such asblockchain can be highly bene cial in regards to dealing withthis situation ',\n",
       " 'blockchain technology enables individuals andorganizations from any corner of the world to become a partof a single interconnected network that facilitates the securesharing of data ',\n",
       " 'the tamper proof feature of blockchainmakes it resistant to unauthorized changes and the use ofconsensus algorithms and smart contracts minimizes thepotential of the dissemination of bogus data and fraudulentinformation ',\n",
       " 'blockchain based applications can be employedto monitor and manage the covid patients digitallythereby relieving some burden on the hospital staff and otherhealthcare personnel ',\n",
       " 'mentioned below aresome of the signi cant ways in which blockchain technologycan help in the ght against the covid facilitating increased testing and reporting recording the details of the covid patients managing the lockdown implementation preventing the circulation of fake news enabling an incentive based volunteer participationplatform enabling a secure donation platform for supporters limiting supply chain disruptionswe dissect each one of these ways in the subsections thatfollow a ',\n",
       " 'increased testing and reportingvarious countries such as china germany and the republicof korea have emphasized the need for extensive testing ofindividuals as the eventual means to curb the spread of thevirus ',\n",
       " 'however in order to ensure ef ciency tests must becarried out intelligently and accurate data in regards to thenumber of tests performed needs to be maintained ',\n",
       " 'to thisend blockchain technology can help in setting up distributedcheck up points for testing the patients who are showingsymptoms related to covid ',\n",
       " 'the coordinators of all thesecheck up points can act as nodes of the same distributedblockchain network ',\n",
       " 'these nodes can continuously updatedata regarding the number of tests performed and the numberof laboratory con rmed cases in their local check up point onthis network ',\n",
       " 'this can help in getting an accurate report onthe number of tests being conducting and the number ofvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure blockchain based dlt architecture for covid impact management positive cases recorded in each area ',\n",
       " 'these reports can furtherhelp the authorities and healthcare of cials to strategize aplan to combat the spread of disease in the areas reportinga high number of covid positive patients ',\n",
       " 'the sharedblockchain network can act as a single source for all the usersto update and retrieve the data ',\n",
       " 'due to blockchain s inherentfeature of being immutable data stored in the network willbe tamper proof and can therefore be trusted by all thehealthcare professionals and government authorities b ',\n",
       " 'recording covid patient detailsapart from securely storing the test reports the blockchain based distributed platforms can also act as a promising solu tion for recording covid patient details ',\n",
       " 'as soon as aperson tests positive for the covid all of his her detailsincluding sex age medical history underlying health condi tions the severity of the disease the symptoms developedand the recommended line of treatment can be securelyadded on the network ',\n",
       " 'a platform with up to date data onthe covid patients can help facilitate the study of thedisease s clinical characteristics and help all the health cen ters that are part of the network better understand better thedisease s growth pattern ',\n",
       " 'in the near future any health centerdealing with a con rmed case of the covid can refer tothese studies to anticipate the kind of facilities and medicinesrequired to deal with the situation at hand c ',\n",
       " 'managing the lockdown implementationliving under lockdown conditions is an unprecedented sit uation for a majority of the people around the world ',\n",
       " 'theessential needs of the public have to be met to empower themto stay at home and follow the lockdown restrictions strictly people from the police department healthcare departmentnon governmental organizations and other volun teers need to work in sync with the government authoritiesto achieve the intended results of the lockdown success fully ',\n",
       " 'following the implementation of lockdown measuresmultiple reports have surfaced claiming that people residingin easily accessible areas are utilizing extra services whilepeople living in remote areas are kept bereft of even the fun damental necessities ',\n",
       " 'to this end blockchain technology canaid the government and non government bodies to overseethe requirements of people in different regions of the countryand ef ciently manage the lockdown implementation ',\n",
       " 'all theauthorized groups or individuals associated with enforcingthe lockdown can act as nodes in the blockchain network andcan register the needs of the residents in their designated areaon the network ',\n",
       " 'all the participating nodes in the blockchainnetwork are allowed to check for the requirements listed bythe nodes of different areas following which the intendedgroups may take appropriate actions to satisfy those needs this will help to limit the imbalance in the supply of servicesin different areas and consequently result in a more stringentlockdown implementation d ',\n",
       " 'preventing the circulation of fake newsfollowing the outbreak of the covid one of the majorconcerns for governments worldwide has been to limit thespread of misinformation ',\n",
       " 'various unsolicited messages arebeing forwarded giving rise to feelings of unrest amongst thecitizens ',\n",
       " 'besides spreading rumors and fake news some mes sages are particularly in ammatory and instill the feelingsof xenophobia amongst the readers ',\n",
       " 'however since severalsocial platforms are currently in use it becomes dif cult forthe authorities to monitor the authenticity of the informationbeing shared in each of these platforms ',\n",
       " 'moreover even if the volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicauthorities are able to detect an unfactual message it becomesdif cult for them to track the original initiator of the message to this end the use of a public blockchain network forinformation sharing can be a highly promising solution tocurb the spread of rumors conspiracy theories fake news andin ammatory remarks ',\n",
       " 'by forcing all message initiators tosign their message with a digital signature the authorities cankeep track of who shared which message ',\n",
       " 'although the useof consensus algorithms will ensure that no misinformationmakes it into the network in the rst place even if it doesthe authorities can quickly determine the message initiatorbased on his her digital signature ',\n",
       " 'such a platform will pre vent people from falling prey to fraudulent information e ',\n",
       " 'incentive based volunteer participationthe general behavior of the individuals is that they tend torespond quickly to the incentives offered ',\n",
       " 'incentives may besimple words of appreciation a monetary bene t a smallgift or a certi cate acknowledging his her work ',\n",
       " 'blockchaintechnology makes use of a robust consensus mechanism thatcan be used to facilitate the secure distribution of incentivesin different ways to the deserving candidates in the current state of crisis that is scaling up at a rapidpace it becomes crucial for countries to prompt their citi zens to share vital data and also to involve them in impactmanagement activities ',\n",
       " 'to this end a blockchain basedincentive mechanism such as the ones proposed in and can prove to be highly useful in motivating alarge number of citizens to act as volunteers for the covid crisis management ',\n",
       " 'volunteers can help by distributingfood masks and other essential products ',\n",
       " 'furthermore theycan also help by reporting the identities of people breakingsocial distancing protocols hoarding items of daily useand misusing the current state of panic among people tocharge them extra for even the most fundamental necessi ties ',\n",
       " 'all the participants in the blockchain network can berewarded with some tokens or certi cates of appreciation toacknowledge their work done and motivate them to partici pate with even more enthusiasm f ',\n",
       " 'secure donation platformfollowing the massive impact of the covid pandemicglobally especially on those belonging to the underpriv ileged class several people and organizations around theworld are coming forward to help the ones less fortunatethan themselves ',\n",
       " 'since in these dire times not everyonecannot go out and personally help the needy people havechosen to donate in several international and national relieffunds ',\n",
       " 'however the reports of fraudulent bank accountsand relief funds have instilled a feeling of insecurity amongthe people who were otherwise willing to donate ',\n",
       " 'recentlyin india a group of fraudsters was caught collecting dona tions by creating a fake bank account under the same nameas the one initiated by the indian prime minister to this end a secure and transparent donation platform isrequired to quash the skepticism surrounding the validityand transparency of existing donation platforms and con sequently enable more citizens to extend monetary help various blockchain based crowdfunding platforms have beenproposed in recent times ',\n",
       " 'blockchain basedplatforms can ensure a secure collection of money whilealso warranting transparency in regards to where the donatedmoney is being used g ',\n",
       " 'limiting supply chain distruptionsthe onset of the covid has been particularly trouble some for international trade and supply chains ',\n",
       " 'amid thelockdown measures currently imposed in several countriesmost organizations around the world are experiencing con siderable dif culties in maintaining the ow of goods andservices ',\n",
       " 'supply chain disruptions further exacerbatedby trade restrictions have caused a majority of suppliers tohalt production and several logistic partners to postpone thetransport of goods ',\n",
       " 'technologies such as blockchain arebeing hailed as the key to reforming the trade networks andmaking the supply chain more tolerant of such emergenciesin the future the past few years have seen several attempts made byorganizations around the world to incorporate blockchain intheir supply chains in a bid to increase supply chain visibilitylack of which is cited as the primary reason for supply chaindisruptions ',\n",
       " 'in existing systems even if the manufacturers arefamiliar with any dif culties being faced by their immediatesuppliers they might be oblivious to the challenges faced bytheir supplier s partners ',\n",
       " 'knowledge of such challenges canallow manufacturers to arrange for temporary solutions todeter supply chain problems ',\n",
       " 'however owing to theinsecurities of losing a competitive edge suppliers may beleery of disseminating their partner s details ',\n",
       " 'to this end per mission blockchains can make it feasible for the supplier toshare data without actually disclosing their partner s identity h ',\n",
       " 'challengesa few technical and non technical challenges hinder theapplication of blockchain in the covid impact manage ment ',\n",
       " 'before blockchain based solutions can be implementedin the current situation these issues must be adequatelyaddressed i the rst non technical challenge to blockchain imple mentation is the lack of awareness about blockchain andits potential ',\n",
       " 'furthermore several people have reserva tions regarding the use of blockchain since they associateblockchain only with cryptocurrencies and fraudulentactivities ii although non technical challenges can be handledby increased awareness the main challenges toblockchain implementation are the technical ones blockchain based platforms often suffer from their lackof scalability ',\n",
       " 'the current crisis necessitates the use ofa highly scalable solution since it is affecting almostall people around the world ',\n",
       " 'currently only a fewvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicblockchain based platforms are available and almost allof them have inherent scalability constraints iii the response to the current pandemic requires the con solidation of various emerging and legacy technologies since blockchain technology is relatively new and imma ture it becomes dif cult to integrate blockchain applica tions with legacy systemsiv one of the signi cant advantages of blockchainthe absence of any central authority may some times back re ',\n",
       " 'to ensure the proper functioning ofblockchain based applications it is essential to properlyenforce government regulations and standards in thedesign and development of such applications although blockchain technology is relatively new and itsentire potential is yet to be explored the disastrous impactof the covid pandemic has warranted the use ofblockchain based transparency solutions for enhanced impactmanagement techniques ',\n",
       " 'in the coming times due to theseveral bene ts that it offers blockchain technology has thepotential to become an indispensable part of the healthcareindustry and the rapid response system xvii ',\n",
       " 'g network technologyg refers to the fth generation of wireless communica tion technology supporting mobile networks globally in comparison to g g is expected to have better per formance in terms of higher speed lower latency widerrange increased availability and more reliability ',\n",
       " 'togetherwith other concomitant technologies like iot and ai gnetwork technology has the potential to revolutionize thehealthcare sector ',\n",
       " 'the commercialization of g technologyin china has already transformed its response mechanism tothe covid pandemic by providing better assistance tothe frontline staff and facilitating improved virus trackingpatient monitoring data collection and analysis ',\n",
       " 'citingchina as an example in this section we discuss the variousways in which countries can adopt g to help improve theef ciency of their efforts in resisting the covid healthcrisis a ',\n",
       " 'gc telemedicineas de ned in section x c telemedicine refers to the practiceof remotely monitoring the patients ',\n",
       " 'although the use ofdrones smart wearables and mobile applications can aug ment the functionalities of the telemedicine sector g net work technology is a necessity to realize those functional ities ',\n",
       " 'due to its limited bandwidth and data transfer speedthe existing g networks cannot support real time high quality video conferencing which is an essential requirementfor seamless consultation teleconferencing ',\n",
       " 'further more g lte networks often hinder the connection of iomtdevices to cloud platforms consequently rendering theminef cient ',\n",
       " 'to this end g with its features like ultra lowlatency and high speed data transmission can enable mobilenetworks to address these issues ',\n",
       " 'furthermore g canenable immersive virtual and augmented reality applications which can conceivably lead to an interactiveexperience in telemedicine and equip caregivers to provideimmediate expertise in regards to possible complications andtreatment strategies china where the g technology was commerciallyunveiled in early november last year has already drawn onsome of the features that g networks bring to telemedicine various hospitals and medical centers in china have launchedgc telemedicine platforms for covid patients ',\n",
       " 'forexamplev west china hospital has launched a covid gcteleconsultation platform with assistance from chinatelecom a hospital af liated to the kunming medical univer sity has launched a g based online platform for freecovid diagnosis and treatment an emergency facility in wuhan huoshenshan hospi tal has launched a gc remote consultation platform this consultation platform has enabled a more ef cientdiagnosis and treatment of the covid patients inthe hospital by equipping the healthcare profession als in beijing to work with the medical team of thehospital b ',\n",
       " 'gc medical imagingrecent years have seen medical imaging techniques like pic ture archiving and communication systems becomean indispensable part of diagnosis and treatment ',\n",
       " 'in tandemwith the next generation cellular networks and technologieslike ai and big data analytics pacs can offer enhanceddata analysis management while requiring minimal humaneffort ',\n",
       " 'in a specialist eld hospital in wuhan leishenshanhospital g enabled medical imaging platforms allowedfor real time diagnosis of covid patients and in doingso relieved some of the load on the hospital s medicalstaff c ',\n",
       " 'gc thermal imagingthermal imaging technology initially developed foranti aircraft defense has now found its way into severaldomains including healthcare where it has proved to beparticularly propitious ',\n",
       " 'the establishment of g networks hasfacilitated the development of g enabled thermal imagingsystems that can have several applications in defense andhealthcare ',\n",
       " 'a gc ir thermal imaging monitoring systemcan enable the real time temperature of moving bodies withhigh accuracy and precision ',\n",
       " 'the data accumulated by thesystems can then be transmitted to the central monitoringsystem with ultra low latency using g networks ',\n",
       " 'for thecovid outbreak this functionality can mean around the clock public temperature monitoring ',\n",
       " 'in china several gcthermal imaging systems have already been consolidated inrobots and ua vs which have been deployed in public spacesof several cities to reduce the spread of the covid volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicfigure ',\n",
       " 'g epidemic monitoring platform d ',\n",
       " 'gc robotsfollowing the covid outbreak several attempts havebeen made around the globe to develop and deploy robots toease the burden on the rst line of cials ',\n",
       " 'although some ofthese attempts have already been discussed in section xii athis section focuses mainly on g powered robots ',\n",
       " 'in addi tion to having more functionalities g enabled robots areoften more ef cient in performing the assigned tasks g robots deployed by ais in thailandin thailand advanced info services the country slargest phone operator has leveraged g technology in var ious ways to ght the outbreak of the covid ',\n",
       " 'ais hasinstalled g networks at hospitals and deployed several grobots to aid the hospitals in augmenting their telemedicinefacilities ',\n",
       " 'apart from serving as a means of communicationbetween the medics and the patients these robots have theability to perform thermal scans china mobile s g robots in shanghaias part of its effort to contain the spread of covid a chinese telecommunications operator china mobile hasprovided six g enabled intelligent robots to the shanghaipublic health clinical center ',\n",
       " 'these robots can perform amultitude of operations such as sanitizing the health centerpremises and delivering medicines to the patients to name afew ',\n",
       " 'in addition to the robots telecom operators in shanghaihave deployed smart devices such as g thermal imagingcameras and g health monitors in their bid to combat thecovid crisis cloudminds g robots in wuhana eld hospital staffed with several g enabled smart robotswas recently opened in wuhan china ',\n",
       " 'these robots pro vided by a beijing based company called cloudminds canclean and disinfect the premises deliver medicine to thepatients and measure their temperature ',\n",
       " 'this facility com monly referred to as the smart field hospital also employedthe use of various other iot devices to ease the burden on thehospital staff ',\n",
       " 'patients at the facility wore smart bracelets andrings that synced with cloudminds ai platform to enable thehealth workers to continually track their patients vital signsincluding their temperature heart rate and blood oxygenlevels without requiring to be physically present with themat all times patrol robots in multiple cities of chinaa local robotics company based out of guangzhou chinahas recently designed g police patrol robots on top of theadvantech developed edge computer mic ',\n",
       " 'these smartrobots born at the intersection of ai iot g and cloudcomputing technologies are equipped with ve infrared ther mometers high resolution cameras that allow them tomeasure the body temperatures of up to people at once furthermore by employing the use of environmental sensingthese robots can also determine if someone is wearing a maskvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemicor not ',\n",
       " 'anytime the robot encounters someone who is notwearing a mask or has high body temperature it immediatelysends an alert to the local authorities ',\n",
       " 'these robots havebeen deployed in public places of multiple cities in chinaincluding shanghai guangzhou and guiyang e ',\n",
       " 'challengessince the outbreak of the covid several technologi cal solutions have been proposed for mitigating its impact among them iot drone technology and ai have been at theforefront ',\n",
       " 'however to realize the transformative potential ofthese technologies there is a need for a cellular network thatcan overcome the bandwidth latency and exibility issuesinherent to the current network technology ',\n",
       " 'the responsibilityfor this rests with the next generation g cellular networks the integration of tools like ua vs robots and telemedicineplatforms with g supported features like high speed datatransmission ultra low latency and advanced data analyticscan allow for an ef cient system for monitoring the crowdsdetecting infected individuals and providing treatment tothem all without the need for any physical human contact ',\n",
       " 'in the future such an epidemic controlsystem also has the potential to be one of the building blocksfor the development of a more dynamic smart city manage ment model ',\n",
       " 'however at present the implementationof g networks faces several challenges some of which arementioned belowvi since the deployment of g networks is still in nascentstages one of its pitfalls is the lack of infrastructureto support their working ',\n",
       " 'furthermore the high costsassociated with the installation and maintenance of gnetworks have made its wide scale deployment dif cultfor governments and telecom operators ii on their own g networks cannot revolutionize thehealthcare sector ',\n",
       " 'they can prove to be effective onlywhen used in tandem with other emerging technologieslike iot ai and cloud computing iii at present there are no established guidelines that reg ulate the use of a patient s con dential data collectedusing g healthcare systems ',\n",
       " 'besides data con dential ity several other security issues associated with the useof g are yet to be resolved although the wide scale deployment of g networks in thehealthcare industry is likely to take a few years an increasingnumber of medical centers are already contemplating theuse of g enabled healthcare systems to enhance the qualityof medical service and patient experience reduce the costof medical care and minimize the burden on healthcarepersonnel xviii ',\n",
       " 'conclusionwhile the world continues to grapple with the impact ofthe covid pandemic complementary efforts of variousemerging technologies such as iot ua vs ai blockchainand g are endeavoring to alleviate its impact ',\n",
       " 'keepingthat as the foundation of this work we offer some of thelatest insights on the covid pandemic ',\n",
       " 'we begin thispaper with a comprehensive review of the covid itselfin which we explore its clinical features transmission mech anism and diagnosis procedures ',\n",
       " 'following this we discussthe stages the disease goes through in the course of its spread we also list the various treatment efforts being made toput an end to the pandemic and the preventive measures tobe followed till the time that is possible ',\n",
       " 'to calibrate thedisastrous impact of the covid we also take a broadlook at the state of the global economy following its out break ',\n",
       " 'in the thorough discussion post this we dissect thevarious technological interventions made in the direction ofcovid impact management ',\n",
       " 'primarily our discussionfocuses on the use of emerging technologies such as iotdrones ai blockchain and g in mitigating the impact ofthe covid pandemic ',\n",
       " 'till the time a cure for this diseasesurfaces the responsibility to manage and limit its impactrests largely with these technologies acknowledgmentthe statements made herein are solely the responsibility ofthe authors references m cascella m rajnik a cuomo s c dulebohn and r di napoli features evaluation and treatment coronavirus updated apr in statpearls internet ',\n",
       " 'treasure islandfl usa statpearls publishing jan ',\n",
       " ' online ',\n",
       " 'available https www ncbi nlm nih gov books nbk world health organization ',\n",
       " 'coronavirus disease pandemic ',\n",
       " 'accessed apr ',\n",
       " ' online ',\n",
       " 'available https www who int emergencies diseases novel coronavirus who ',\n",
       " ' online ',\n",
       " 'availablehttps www who int docs default source coronaviruse situation reports sitrep covid pdf sfvrsn bae_ t singhal a review of coronavirus disease indianj ',\n",
       " 'pediatrics vol ',\n",
       " ' no ',\n",
       " ' pp ',\n",
       " ' apr ',\n",
       " ' m chan yeung and r xu sars epidemiology respirology vol ',\n",
       " 'pp ',\n",
       " 's s ',\n",
       " ' sars basics fact sheet ',\n",
       " 'centers for disease control pre vention online ',\n",
       " 'available https www cdc gov sars about fs sars html world health organization ',\n",
       " 'middle east respiratory syndrome coro navirus ',\n",
       " 'accessed apr ',\n",
       " ' online ',\n",
       " 'availablehttps www who int emergencies mers cov en world health organization ',\n",
       " 'middle east respiratorysyndrome coronavirus the kingdom of saudi arabia online ',\n",
       " 'available https www who int csr don april mers saudi arabia en freepik ',\n",
       " 'timeline flat design infographic designed by freepik accessed apr ',\n",
       " ' online ',\n",
       " 'available https www freepik com free vector timeline at design inforaphic_ htm query timeline position c sohrabi z alsa n o neill m khan a kerwan a al jabirc ',\n",
       " 'iosi dis and r agha world health organization declares globalemergency a review of the novel coronavirus int j ',\n",
       " 'surgery vol ',\n",
       " ' pp ',\n",
       " ' apr ',\n",
       " ' who ',\n",
       " 'report who china joint missioncoronavirus disease ',\n",
       " ' online ',\n",
       " 'availablehttps www who int docs default source coronaviruse who china joint mi ssion on covid nal report pdf people who are at higher risk for severe illness ',\n",
       " ' centers for disease control prevention ',\n",
       " ' online available https www cdc gov coronavirus ncov need extra precautions people at higher risk html volume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemic world health organization ',\n",
       " 'modes of transmission of virus causingcovid implications for ipc precaution recommendations accessed apr ',\n",
       " ' online ',\n",
       " 'available https www who int news room commentaries detail modes of transmission of virus causing covid implications for ipc precaution recommendations national institutes health ',\n",
       " 'study suggests newcoronavirus may remain on surfaces for days ',\n",
       " ' online ',\n",
       " 'availablehttps www nih gov news events nih research matters study suggests new coronavirus may remain surfaces days p belluck what does the coronavirus do to the body ',\n",
       " 'the new yorktimes mar ',\n",
       " ' online ',\n",
       " 'available https www nytimes com article coronavirus body symptoms html searchre sultposition l fang g karakiulakis and m roth are patients with hypertensionand diabetes mellitus at increased risk for covid infection ',\n",
       " 'lancet respiratory med ',\n",
       " 'vol ',\n",
       " ' no ',\n",
       " ' p e ',\n",
       " ' s h wong r n s lui and j j y sung covid and the digestivesystem j gastroenterol ',\n",
       " 'hepatol ',\n",
       " ' r baldwin and e tomiura thinking ahead about the trade impact ofcovid economics in the time covid p ',\n",
       " ' v surveillances the epidemiological characteristics of an outbreak of novel coronavirus diseases china china cdcweekly vol ',\n",
       " ' no ',\n",
       " ' pp ',\n",
       " ' h chen j guo c wang f luo x yu w zhang j lid ',\n",
       " 'zhao d xu q gong j liao h yang w hou and y zhang clinical characteristics and intrauterine vertical transmission poten tial of covid infection in nine pregnant women a retrospectivereview of medical records lancet vol ',\n",
       " ' no ',\n",
       " ' pp ',\n",
       " ' mar ',\n",
       " ' d wang b hu c hu f zhu x liu j zhang b wang h xiangz ',\n",
       " 'cheng y xiong y zhao y li x wang and z peng clinicalcharacteristics of hospitalized patients with novel coronavirus infected pneumonia in wuhan china j amer ',\n",
       " 'med ',\n",
       " 'assoc ',\n",
       " 'vol ',\n",
       " 'no ',\n",
       " ' p mar ',\n",
       " ' n chen m zhou x dong j qu f gong y han y qiu j wangy ',\n",
       " 'liu y wei j xia t yu x zhang and l zhang epidemiolog ical and clinical characteristics of cases of novel coronaviruspneumonia in wuhan china a descriptive study lancet vol ',\n",
       " 'no ',\n",
       " ' pp ',\n",
       " ' feb ',\n",
       " ' f jiang l deng l zhang y cai c w cheung and z xia reviewof the clinical characteristics of coronavirus disease j gen internal med ',\n",
       " 'vol ',\n",
       " ' pp ',\n",
       " ' mar ',\n",
       " ' doi s w s salehi a abedi s balakrishnan and a gholamrezanezhad coro navirus disease a systematic review of imaging nd ings in patients amer ',\n",
       " 'j roentgenol ',\n",
       " 'pp ',\n",
       " ' mar ',\n",
       " ' doi ajr ',\n",
       " ' pandemic ',\n",
       " 'centers for disease controlprevention ',\n",
       " 'accessed apr ',\n",
       " ' online ',\n",
       " 'availablehttps www cdc gov u pandemic resources pandemic hn html e d kilbourne in uenza pandemics of the th century emerg infectious diseases vol ',\n",
       " ' no ',\n",
       " ' pp ',\n",
       " ' pandemic ',\n",
       " 'centers for disease controlprevention ',\n",
       " 'accessed apr ',\n",
       " ' online ',\n",
       " 'availablehttps www cdc gov u pandemic resources pandemic html hn pandemic ',\n",
       " 'centers for disease con trol prevention ',\n",
       " 'accessed apr ',\n",
       " ' online ',\n",
       " 'availablehttps www cdc gov u pandemic resources hn pandemic html who ',\n",
       " 'coronavirus disease situationreport ',\n",
       " ' online ',\n",
       " 'available https www who int docs default source coronaviruse situation reports sitrep covid pdf sfvrsn a_ who ',\n",
       " 'coronavirus disease situationreport ',\n",
       " ' online ',\n",
       " 'available https www who int docs default source coronaviruse situation reports sitrep covid pdf sfvrsn b_ m frackowiak j darlak a kobylinska and t lund ',\n",
       " 'factbox europebegins easing coronavirus lockdowns ',\n",
       " 'reuters ',\n",
       " 'apr ',\n",
       " ' online available https www reuters com article us health coronavirus europe factbox fa ctbox europe begins easing coronavirus lockdowns iduskbnzp m godin ',\n",
       " 'these european countries are slowly lifting coronaviruslockdowns ',\n",
       " 'here s what that looks like ',\n",
       " 'time ',\n",
       " 'apr ',\n",
       " ' online available https time com countries lifting coronavirus restrictions eur ope r martin ',\n",
       " 'what countries are still in lockdown and how manyweeks has it been for them ',\n",
       " 'metro ',\n",
       " 'apr ',\n",
       " ' online ',\n",
       " 'availablehttps metro co uk countries still lockdown many weeks r staff here s what lockdown looks like around the world world economic forum apr ',\n",
       " ' online ',\n",
       " 'available https www weforum org agenda coronavirus lockdowns global a brzozowski ',\n",
       " 'belgium extends covid lockdownuntil may but relaxes some measures ',\n",
       " ' online ',\n",
       " 'availablehttps www euractiv com section coronavirus news belgium extends covid lockdown until may but relaxes some measures d cheng ',\n",
       " 'covid coronavirus latest case numbers arewe ready to lift lockdown ',\n",
       " 'nz herald ',\n",
       " 'apr ',\n",
       " ' online available https www nzherald co nz nz news article cfm c_id objectid d dunford b dale n stylianou e lowther m ahmedand i d l t arenas coronavirus the world in lockdown inmaps and charts bbc news apr ',\n",
       " ' online ',\n",
       " 'availablehttps www bbc com news world ',\n",
       " 'trudeau says canada s lockdown will last manymore weeks online ',\n",
       " 'available https www deccanherald com international world news politics trudeau says canadas lockdown will last many more weeks html d adhikari nepal extends coronavirus lockdown until april aanews apr ',\n",
       " ' online ',\n",
       " 'available https www aa com tr en latest on coronavirus outbreak nepal extends c oronavirus lockdown until april arab news ',\n",
       " 'iran begins lifting restrictions aftervirus lockdown ',\n",
       " ' online ',\n",
       " 'available https www arabnews com node middle east p kuras germany is cautiously starting to ease its lockdown but it sharder than it looks the guardian apr ',\n",
       " ' online ',\n",
       " 'availablehttps www theguardian com commentisfree apr germany ease lock down harder j lockett australia admits coronavirus lockdown may last a yeardespite having just deaths the sun apr ',\n",
       " ' online ',\n",
       " 'availablehttps www thesun co uk news australia coronavirus lockdown y ear extension m sa j otte and o holmes ',\n",
       " 'the guardian ',\n",
       " 'israeland south korea to ease coronavirus lockdowns ',\n",
       " ' online ',\n",
       " 'avail able https www theguardian com world apr israel and south korea to ease coronavirus lockdowns a timsit ',\n",
       " 'the psychology behind france s decision to announcean end date for lockdown ',\n",
       " 'quartz apr ',\n",
       " ' online ',\n",
       " 'availablehttps qz com why france announced its coronavirus lockdown wi ll end on may s upal ',\n",
       " 'which countries are on coronavirus lockdown ',\n",
       " 'thesun ',\n",
       " 'apr ',\n",
       " ' online ',\n",
       " 'available https www thesun co uk news which countries are on coronavir us lockdown spain italy j shannon and l reyes ',\n",
       " 'us reopening what states are relaxingsocial distancing restrictions and moving away from lockdowns usa today apr ',\n",
       " ' online ',\n",
       " 'available https www msn com en us news us us reopening what states are relaxing social distancing restrictions and moving away from lockdowns ar bbssy p whiteside ',\n",
       " 'coronavirus lockdowns unlocked which countriesare easing restrictions ',\n",
       " 'sky news ',\n",
       " 'apr ',\n",
       " ' online ',\n",
       " 'availablehttps news sky com story coronavirus lockdowns unlocked which countri es are easing restrictions d soguel and d hruby how european countries are trying to safelyend lockdowns the christian science monitor apr ',\n",
       " ' online available https www csmonitor com world europe how european countries are trying to safely end lockdowns d goodman ',\n",
       " 'world economy faces trillion hit that s likelosing japan ',\n",
       " 'bloombergquint apr ',\n",
       " ' online ',\n",
       " 'availablehttps www bloombergquint com global economics world economy faces t rillion hit that is like losing japan y sun b goh and h sarkar ',\n",
       " 'china s feb auto sales plunge biggest monthly drop ever ',\n",
       " 'cnbc mar ',\n",
       " ' online ',\n",
       " 'availablehttps www cnbc com reuters america chinas feb auto sales p lunge percent biggest monthly drop ever html a panday virus outbreak drives down automobile salesin march livemint apr ',\n",
       " ' online ',\n",
       " 'availablehttps www livemint com companies news automakers hit hard by covid march sales decline over htmlvolume v ',\n",
       " 'chamola et al ',\n",
       " 'comprehensive review of the covid pandemic a panday amid covid crisis commercial vehicle salescrash in march livemint apr ',\n",
       " ' online ',\n",
       " 'availablehttps www livemint com companies news amid covid crisis commercial vehicle sales crash in march html acea ',\n",
       " 'interactive map production impact ofcovid on the european auto industry ',\n",
       " ' online ',\n",
       " 'availablehttps www acea be news article interactive map production impact of c ovid on the european auto industry s szymkowski ',\n",
       " 'covid shut down of all usauto production ',\n",
       " 'roadshow apr ',\n",
       " ' online ',\n",
       " 'availablehttps www cnet com roadshow news covid shut down us auto productio n coronavirus alliance for automotive innovation covid press release north american assembly facility operating status ',\n",
       " ' online ',\n",
       " 'available https www autosinnovate org covid north american assembly facility operating status iata ',\n",
       " 'air passenger market analysis passenger growth slows as covid impacts theindustry ',\n",
       " ' online ',\n",
       " 'available https www iata org en iata repository publications economic reports a ir passenger market analysis jan m ovaska r levinson and b simon the toll on travel reutersapr ',\n",
       " ' online ',\n",
       " 'available https graphics reuters com health corona virus flights qzjvqeqrvxm iata ',\n",
       " 'covid puts over half of passengerrevenues at risk ',\n",
       " ' online ',\n",
       " 'available https www iata org en pressroom pr j kenkel ',\n",
       " 'cyient ',\n",
       " 'the impact of covid on thea d industry and its recovery and regrowth ',\n",
       " ' online ',\n",
       " 'availablehttps www cyient com blog aerospace defense the impact of covid on the ad industry and its recovery and regrowth j faus this is how coronavirus could affect the travel and tourismindustry world economic forum ad ',\n",
       " ' online ',\n",
       " 'availablehttps www weforum org agenda world travel coronavirus covid jobs pandemic tourism aviation unwto ',\n",
       " 'impact assessment of the covid outbreak on international tourism ',\n",
       " ' online ',\n",
       " 'availablehttps www unwto org impact assessment of the covid outbreak on int ernational tourism a cang j blas and s cho ',\n",
       " 'china oil demand has plunged because of the virus lockdown ',\n",
       " 'bloomberg com ',\n",
       " 'feb ',\n",
       " ' online available https www bloomberg com news articles china oil demand is said to have plunged on virus lockdown s meredith ',\n",
       " 'oil prices could soon turn negative as the world runsout of places to store crude analysts warn ',\n",
       " 'cnbc apr ',\n",
       " ' online ',\n",
       " 'available https www cnbc com coronavirus oil prices could turn negat ive as storage nears capacity html china property investment falls sales plunge by ',\n",
       " 'the business times mar ',\n",
       " ' online ',\n",
       " 'availablehttps www businesstimes com sg real estate china property investment falls sales plunge by globaldata ',\n",
       " 'globaldata sharply revises down forecastfor construction output growth globally to just in ',\n",
       " ' online available https www globaldata com globaldata sharply revises down forecast for construction output growth globally to just in food and agriculture organization of the united nations ',\n",
       " 'q a covid pandemic impact on food and agriculture ',\n",
       " 'accessed apr ',\n",
       " ' online ',\n",
       " 'available http www fao org ncov q and a impact on food and agriculture en researchandmarkets com ',\n",
       " 'global food beveragesindustry and the effects of covid analysis of regionalregulations and other government policies researchandmarkets com online ',\n",
       " 'available https www businesswire com news home en global food be verages industry effects covid i almeida m dorning and m g perez ',\n",
       " 'food makers get shot ofreality now that panic buying has waned ',\n",
       " 'bloomberg com ',\n",
       " 'apr ',\n",
       " ' online ',\n",
       " 'available https www bloomberg com news articles with panic buying wa ning big food sees life without restaurants v bekiempis ',\n",
       " 'could you buy a little less please ',\n",
       " 'panic buyingdisrupts food distribution ',\n",
       " 'the guardian mar ',\n",
       " ' online ',\n",
       " 'avail able https www theguardian com world mar us coronavirus panic buyi ng food coronavirus how do i get a food parcel ',\n",
       " 'bbc news apr ',\n",
       " ' online ',\n",
       " 'available https www bbc com news business m v beusekom doctors covid pushing italian icus towardcollapse univ ',\n",
       " 'minnesota mar ',\n",
       " ' online ',\n",
       " 'availablehttps www cidrap umn edu news perspective doctors covid pu shing italian icus toward collapse j hockaday ',\n",
       " 'spain s healthcare system on verge ofcollapse as another die of coronavirus ',\n",
       " ' online ',\n",
       " 'availablehttps metro co uk spains healthcare system verge collapse another die coronavirus m yamaguchi and y kageyama coronavirus japan s medical sys tem on verge of collapse doctors say global news apr ',\n",
       " ' online ',\n",
       " 'available https globalnews ca news coronavirus japan medical system w feuer who of cials warn health systems are collapsing undercoronavirus this isn t just a bad u season cnbc mar ',\n",
       " ' online ',\n",
       " 'available https www cnbc com coronavirus who says health systems col lapsing this isnt just a bad u season html deloitte ',\n",
       " 'understanding covid s impact on the telecom sector accessed apr ',\n",
       " ' online ',\n",
       " 'available https www deloitte com global en pages about deloitte articles covid understanding covid impact on the telecom sector html globaldata ',\n",
       " 'telecom sector will shine inpost covid era says globaldata ',\n",
       " ' online ',\n",
       " 'availablehttps www globaldata com telecom sector will shine in post covid e ra says globaldata evaluating and testing persons for coronavirus disease ',\n",
       " 'centers for disease control prevention accessed apr ',\n",
       " ' online ',\n",
       " 'available https www cdc gov coronavirus ncov hcp clinical criteria html world health organization ',\n",
       " 'contact tracing ',\n",
       " ' online available https www who int features qa contact tracing en u siddiqui ',\n",
       " 'coronavirus testing methods what you needto know ',\n",
       " 'news al jazeera apr ',\n",
       " ' online ',\n",
       " 'availablehttps www aljazeera com news coronavirus testing methods html world health organization ',\n",
       " 'laboratorytesting for coronavirus disease insuspected human cases ',\n",
       " ' online ',\n",
       " 'available https apps who int iris rest bitstreams retrieve s pfefferle s reucher d nörz and m lütgehetmann evaluation of aquantitative rt pcr assay for the detection of the emerging coronavirussars cov using a high throughput system eurosurveillance vol ',\n",
       " 'no ',\n",
       " ' art ',\n",
       " 'no ',\n",
       " ' t heikkinen j marttila a a salmi and o ruuskanen nasalswab versus nasopharyngeal aspirate for isolation of respiratory viruses j ',\n",
       " 'clin ',\n",
       " 'microbiol ',\n",
       " 'vol ',\n",
       " ' no ',\n",
       " ' pp ',\n",
       " ' world health organization ',\n",
       " 'core medical equipment information ',\n",
       " 'accessed apr ',\n",
       " ' online ',\n",
       " 'available https www who int medical_devices innovation bronchoscope pdf ua narayana health care ',\n",
       " 'coronavirus testing how totest for coronavirus different types of tests ',\n",
       " ' online ',\n",
       " 'availablehttps www narayanahealth org blog coronavirus testing how to test s m hahn ',\n",
       " 'coronavirus update serological tests u s ',\n",
       " 'food and drug administration ',\n",
       " 'apr ',\n",
       " ' online ',\n",
       " 'availablehttps www fda gov news events press announcements coronavirus covid update serological tests world health organization ',\n",
       " 'apr ',\n",
       " ' draft landscape of covid candidate vaccines ',\n",
       " ' online ',\n",
       " 'available https www who int docs default source coronaviruse novel coronavirus landscape ncov pdf a park ',\n",
       " 'as the first coronavirus vaccine human tri als begin manufacturer is already preparing to scale productionto millions ',\n",
       " ' online ',\n",
       " 'available https time com coronavirus vaccine moderna moderna ',\n",
       " 'moderna s work on a potential vaccine againstcovid ',\n",
       " ' online ',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = t\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62b1b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>special section on deep learningalgorithms for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the scarcity of resources to endure thecovid o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the number of laboratory con rmed coronavirusc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in response to such acts we draw on various re...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in addition to the direct health implications ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80240</th>\n",
       "      <td>intangible assets and growth ac counting evid...</td>\n",
       "      <td>80240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80241</th>\n",
       "      <td>it is beautifully written extremely interestin...</td>\n",
       "      <td>80241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80242</th>\n",
       "      <td>the authors make two central claims</td>\n",
       "      <td>80242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80243</th>\n",
       "      <td>the ﬁ rst is that ai rebecca henderson is the ...</td>\n",
       "      <td>80243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80244</th>\n",
       "      <td>unauthorized posting copying or distributing o...</td>\n",
       "      <td>80244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80245 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence    num\n",
       "0      special section on deep learningalgorithms for...      0\n",
       "1      the scarcity of resources to endure thecovid o...      1\n",
       "2      the number of laboratory con rmed coronavirusc...      2\n",
       "3      in response to such acts we draw on various re...      3\n",
       "4      in addition to the direct health implications ...      4\n",
       "...                                                  ...    ...\n",
       "80240   intangible assets and growth ac counting evid...  80240\n",
       "80241  it is beautifully written extremely interestin...  80241\n",
       "80242               the authors make two central claims   80242\n",
       "80243  the ﬁ rst is that ai rebecca henderson is the ...  80243\n",
       "80244  unauthorized posting copying or distributing o...  80244\n",
       "\n",
       "[80245 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame({'sentence':text})\n",
    "test['num'] = pd.DataFrame(range(len(test)))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f2cf591",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    if len(test['sentence'][i])< 80:\n",
    "        test.drop([i], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49082b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5f3ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>num</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>special section on deep learningalgorithms for...</td>\n",
       "      <td>0</td>\n",
       "      <td>[special, section, on, deep, learningalgorithm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the scarcity of resources to endure thecovid o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[the, scarcity, of, resources, to, endure, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the number of laboratory con rmed coronavirusc...</td>\n",
       "      <td>2</td>\n",
       "      <td>[the, number, of, laboratory, con, rmed, coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in response to such acts we draw on various re...</td>\n",
       "      <td>3</td>\n",
       "      <td>[in, response, to, such, acts, we, draw, on, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in addition to the direct health implications ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[in, addition, to, the, direct, health, implic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80239</th>\n",
       "      <td>challenges to mismeasurement explanations for...</td>\n",
       "      <td>80239</td>\n",
       "      <td>[challenges, to, mismeasurement, explanations,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80240</th>\n",
       "      <td>intangible assets and growth ac counting evid...</td>\n",
       "      <td>80240</td>\n",
       "      <td>[intangible, assets, and, growth, ac, counting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80241</th>\n",
       "      <td>it is beautifully written extremely interestin...</td>\n",
       "      <td>80241</td>\n",
       "      <td>[it, is, beautifully, written, extremely, inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80243</th>\n",
       "      <td>the ﬁ rst is that ai rebecca henderson is the ...</td>\n",
       "      <td>80243</td>\n",
       "      <td>[the, ﬁ, rst, is, that, ai, rebecca, henderson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80244</th>\n",
       "      <td>unauthorized posting copying or distributing o...</td>\n",
       "      <td>80244</td>\n",
       "      <td>[unauthorized, posting, copying, or, distribut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47485 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence    num                                              words\n",
       "0      special section on deep learningalgorithms for...      0  [special, section, on, deep, learningalgorithm...\n",
       "1      the scarcity of resources to endure thecovid o...      1  [the, scarcity, of, resources, to, endure, the...\n",
       "2      the number of laboratory con rmed coronavirusc...      2  [the, number, of, laboratory, con, rmed, coron...\n",
       "3      in response to such acts we draw on various re...      3  [in, response, to, such, acts, we, draw, on, v...\n",
       "4      in addition to the direct health implications ...      4  [in, addition, to, the, direct, health, implic...\n",
       "...                                                  ...    ...                                                ...\n",
       "80239   challenges to mismeasurement explanations for...  80239  [challenges, to, mismeasurement, explanations,...\n",
       "80240   intangible assets and growth ac counting evid...  80240  [intangible, assets, and, growth, ac, counting...\n",
       "80241  it is beautifully written extremely interestin...  80241  [it, is, beautifully, written, extremely, inte...\n",
       "80243  the ﬁ rst is that ai rebecca henderson is the ...  80243  [the, ﬁ, rst, is, that, ai, rebecca, henderson...\n",
       "80244  unauthorized posting copying or distributing o...  80244  [unauthorized, posting, copying, or, distribut...\n",
       "\n",
       "[47485 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nltk_tokenizer(_wd):\n",
    "    return RegexpTokenizer(r'\\w+').tokenize(_wd.lower())\n",
    "\n",
    "test['words'] = test['sentence'].apply(nltk_tokenizer)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b7d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽어온 파일 csv로 저장 (나중에 실행할 때 이 파일만 불러오면 됨)\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1649a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431078\n",
      "91320\n"
     ]
    }
   ],
   "source": [
    "tokens = [ t for d in test['words'] for t in d]\n",
    "text = nltk.Text(tokens, name='AI_assay')\n",
    "print(len(text.tokens))\n",
    "print(len(set(text.tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b45f7877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 72364), ('of', 48799), ('and', 42843), ('to', 32648), ('in', 28501), ('a', 27257), ('for', 16310), ('is', 15148), ('that', 13429), ('ai', 12011)]\n"
     ]
    }
   ],
   "source": [
    "# 최다 빈도 단어 확인\n",
    "print(text.vocab().most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17727f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 빈도 수 확인\n",
    "text.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b3ea6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mcarthur', 1), ('natty', 1), ('beautifully', 1), ('fabulous', 1), ('guvenen', 1), ('bloombergview', 1), ('dimitriadis', 1), ('audhkhasi', 1), ('sercu', 1), ('kurata', 1), ('saon', 1), ('improvising', 1), ('orlikowski', 1), ('frbp', 1), ('milgrom', 1), ('dewhurst', 1), ('willmott', 1), ('katy', 1), ('populism', 1), ('levitt', 1), ('visuomotor', 1), ('kendrick', 1), ('durlauf', 1), ('boyan', 1), ('tug', 1), ('hortaçsu', 1), ('microeconomics', 1), ('switchover', 1), ('photolithographic', 1), ('underinvestment', 1), ('hatzius', 1), ('ruhl', 1), ('rassier', 1), ('mataloni', 1), ('syversonguvenen', 1), ('grangier', 1), ('auli', 1), ('gehring', 1), ('centennial', 1), ('vlad', 1), ('menick', 1), ('piot', 1), ('bilal', 1), ('azar', 1), ('gheshlaghi', 1), ('meire', 1), ('bk', 1), ('feldstein', 1), ('dynamo', 1), ('imf', 1), ('lusine', 1), ('hbswk', 1), ('bpea', 1), ('villones', 1), ('lal', 1), ('bridgman', 1), ('robocalypse', 1), ('salomons', 1), ('syversoneconomy', 1), ('curvetime', 1), ('inventive', 1), ('complementari', 1), ('pugsley', 1), ('alloway', 1), ('referencesabramovitz', 1), ('appendixyou', 1), ('allowednewey', 1), ('gibles', 1), ('intan', 1), ('underrated', 1), ('depress', 1), ('portend', 1), ('foretell', 1), ('leaderboard', 1), ('titans', 1), ('declin', 1), ('statisticians', 1), ('sociologists', 1), ('mists', 1), ('conclusionthere', 1), ('erentiate', 1), ('transferrable', 1), ('syversonmists', 1), ('capitalyou', 1), ('outstrip', 1), ('rkygkziygi', 1), ('rkydkkziydii', 1), ('ˆss', 1), ('ziydiiwhere', 1), ('dyyrkydkkwlydllrkydkk', 1), ('dyyrkydkkwlydlland', 1), ('fldl', 1), ('fada', 1), ('zdi', 1), ('fakkl', 1), ('syversonunmeasured', 1), ('overestimation', 1), ('mismeasure', 1), ('quadrupled', 1), ('tripled', 1), ('undercounted', 1), ('misattribute', 1), ('booked', 1), ('capitalregardless', 1), ('idiosyn', 1), ('syversonand', 1), ('amusing', 1), ('depreciate', 1), ('accelerationto', 1), ('reaccelerate', 1), ('erasyou', 1), ('circa', 1), ('technologieswe', 1), ('syversonwhen', 1), ('miniscule', 1), ('reckon', 1), ('supercenters', 1), ('guration', 1), ('lechatelier', 1), ('economize', 1), ('preneurs', 1), ('distri', 1), ('brynjolfs', 1), ('peaking', 1), ('syversonviding', 1), ('traffi', 1), ('polyphase', 1), ('unelectri', 1), ('eponymous', 1), ('nonresidential', 1), ('growthhaving', 1), ('nontransport', 1), ('ignite', 1), ('fodder', 1), ('syversonalso', 1), ('coinventions', 1), ('railroads', 1), ('steamships', 1), ('coal', 1), ('spurring', 1), ('trajtenberg', 1), ('technologyas', 1), ('imitationfromobservation', 1), ('shehabi', 1), ('arman', 1), ('koomey', 1), ('lyzed', 1), ('nonmarket', 1), ('almonds', 1), ('chores', 1), ('sensorimotor', 1), ('syversonteam', 1), ('siteselectiongroup', 1), ('optimismsimply', 1), ('syversonespecially', 1), ('scatterplotfig', 1), ('niﬁ', 1), ('decadeten', 1), ('errorsnewey', 1), ('decadeyou', 1), ('autocorrelation', 1), ('econometrician', 1), ('explanationimplicit', 1), ('enon', 1), ('phenom', 1), ('arduous', 1), ('coinven', 1), ('inven', 1), ('downturns', 1), ('optimis', 1), ('halves', 1), ('discordance', 1), ('lagseach', 1), ('dispositive', 1), ('stantial', 1), ('ciaries', 1), ('scoped', 1), ('syversonone', 1), ('dissipationa', 1), ('soloveichik', 1), ('facie', 1), ('mismeasurementanother', 1), ('circumspect', 1), ('overoptimism', 1), ('aero', 1), ('kittyhawk', 1), ('supersonic', 1), ('jets', 1), ('cernan', 1), ('beckon', 1), ('credence', 1), ('doldrums', 1), ('escapes', 1), ('hopesthe', 1), ('dissipa', 1), ('paradoxthere', 1), ('nordhaus', 1), ('syversonthat', 1), ('databasetm', 1), ('regionsource', 1), ('cowen', 1), ('noneconomic', 1), ('swath', 1), ('realityalthough', 1), ('nasdaq', 1), ('syversonperformance', 1), ('owers', 1), ('certiﬁ', 1), ('victories', 1), ('ilsvrc', 1), ('viva', 1), ('alphabets', 1), ('_singularity', 1), ('_the', 1), ('_kurzweil', 1), ('_ray', 1), ('_by', 1), ('_made', 1), ('brin', 1), ('khoslaventures', 1), ('doublings', 1), ('vinod', 1), ('scarily', 1), ('polman', 1), ('optimismpaul', 1), ('measurers', 1), ('forecasters', 1), ('undergoes', 1), ('pessimistically', 1), ('tratjenberg', 1), ('goolsbee', 1), ('austan', 1), ('benzell', 1), ('abrams', 1), ('riet', 1), ('syversonerik', 1), ('statisticserik', 1), ('paradoxa', 1), ('astonishing', 1), ('syversonchapter', 1), ('statisticschapter', 1), ('antoniofoundation', 1), ('childrens', 1), ('softwaresan', 1), ('openstack', 1), ('startupshigh', 1), ('hasadvised', 1), ('amazonmicrosoft', 1), ('productcitations', 1), ('awardtop', 1), ('mentoringemployees', 1), ('ofengineering', 1), ('hewas', 1), ('polytechnicthe', 1), ('laband', 1), ('founderand', 1), ('oncyber', 1), ('peyman', 1), ('intelligencecomputer', 1), ('neurotypicaldisabilities', 1), ('grantin', 1), ('brainhealth', 1), ('utsa', 1), ('txusa', 1), ('cochin', 1), ('opencloud', 1), ('researchfellow', 1), ('europeanconference', 1), ('basisdecomposition', 1), ('muelly', 1), ('attributionfor', 1), ('bilmes', 1), ('pechenizkiy', 1), ('ipenburg', 1), ('weerts', 1), ('isfragile', 1), ('abid', 1), ('forinterpretable', 1), ('bischl', 1), ('casalicchio', 1), ('molnar', 1), ('scientiﬁcadvancements', 1), ('xsede', 1), ('cloudenvironment', 1), ('provisioned', 1), ('jetstream', 1), ('attributefunctions', 1), ('withself', 1), ('placesa', 1), ('incontext', 1), ('relativefeature', 1), ('unstlicheintelligenz', 1), ('carrington', 1), ('inhealthcare', 1), ('sakr', 1), ('sherif', 1), ('interpretablemachine', 1), ('atopic', 1), ('seltzer', 1), ('inlecture', 1), ('pﬁster', 1), ('ravikumar', 1), ('forno', 1), ('aznarte', 1), ('vega', 1), ('predictionswhen', 1), ('løland', 1), ('jullum', 1), ('najmi', 1), ('detectedby', 1), ('sciencereview', 1), ('smu', 1), ('lohia', 1), ('tieu', 1), ('aideddiagnosis', 1), ('dlime', 1), ('mefraz', 1), ('ullerand', 1), ('seegerer', 1), ('yeom', 1), ('acomputational', 1), ('schiebinger', 1), ('taxonomiesopportunities', 1), ('sirbikyt', 1), ('grigien', 1), ('ˇcerka', 1), ('threatsand', 1), ('everson', 1), ('forfmri', 1), ('knutson', 1), ('grosenick', 1), ('rechercheoperationnelle', 1), ('dinformatique', 1), ('generativeapproach', 1), ('pajdlab', 1), ('andhospital', 1), ('interpretableclassiﬁers', 1), ('springenberg', 1), ('modelpredictions', 1), ('viagradient', 1), ('adel', 1), ('betterunderstanding', 1), ('oztireli', 1), ('ceolini', 1), ('quantitativetesting', 1), ('sayres', 1), ('bmvc', 1), ('visionconference', 1), ('onapplications', 1), ('modelsvia', 1), ('tansey', 1), ('thomason', 1), ('onlayer', 1), ('paisley', 1), ('louie', 1), ('automaticconcept', 1), ('causalconcept', 1), ('neuraladditive', 1), ('frosst', 1), ('whatmachines', 1), ('unmasking', 1), ('aldchen', 1), ('defaultprediction', 1), ('aste', 1), ('turiel', 1), ('accountingand', 1), ('intelligencetools', 1), ('riskprediction', 1), ('raaij', 1), ('associationsin', 1), ('radiogenomic', 1), ('mazurowski', 1), ('harowicz', 1), ('albadawy', 1), ('smartworld', 1), ('gurram', 1), ('braines', 1), ('julier', 1), ('microelectronicsmipro', 1), ('hlupic', 1), ('brcic', 1), ('highstakes', 1), ('forsystematic', 1), ('sokol', 1), ('harnessingadversarial', 1), ('tolias', 1), ('bethge', 1), ('reimer', 1), ('pitkow', 1), ('sinz', 1), ('atanasova', 1), ('tsaneva', 1), ('gompels', 1), ('dud', 1), ('kurtzman', 1), ('koes', 1), ('andtrustthe', 1), ('ﬁnancialsector', 1), ('regaining', 1), ('augmentedintelligence', 1), ('intelligibleintelligence', 1), ('dataimplementing', 1), ('stahl', 1), ('keskinbora', 1), ('euorpean', 1), ('andwireless', 1), ('haddadi', 1), ('patras', 1), ('thannu', 1), ('devicesanalysis', 1), ('ruminski', 1), ('withartiﬁcial', 1), ('poison', 1), ('chacon', 1), ('detectinginternet', 1), ('beebe', 1), ('parra', 1), ('roopaei', 1), ('voiceprintauthentication', 1), ('actionperformance', 1), ('prevost', 1), ('ebadi', 1), ('bendre', 1), ('productionby', 1), ('jamshidi', 1), ('sahba', 1), ('intelligenttransportation', 1), ('drivingdatasets', 1), ('modalobject', 1), ('dietmayer', 1), ('wiesbeck', 1), ('timm', 1), ('fieldrobotics', 1), ('macesanu', 1), ('cocias', 1), ('trasnea', 1), ('grigorescu', 1), ('tsiotras', 1), ('filev', 1), ('traversalsusing', 1), ('alaeddini', 1), ('neuroimage', 1), ('meneguzzi', 1), ('wearablesensors', 1), ('stereotypical', 1), ('furlanello', 1), ('marchiori', 1), ('venuti', 1), ('jurman', 1), ('screeningmultiple', 1), ('teleophthalmology', 1), ('lish', 1), ('nouhi', 1), ('fordiabetic', 1), ('leeet', 1), ('gefter', 1), ('schiebler', 1), ('claussen', 1), ('ogel', 1), ('usingsecure', 1), ('aboutalebi', 1), ('showspromising', 1), ('explanationscould', 1), ('illustratesthat', 1), ('andpose', 1), ('theirshortcomings', 1), ('inputfeature', 1), ('surrogatemodels', 1), ('additionallythere', 1), ('algorithmsdue', 1), ('isfocused', 1), ('seminalalgorithms', 1), ('explainingdeep', 1), ('importantseveral', 1), ('inﬂuenceof', 1), ('onclusionblindly', 1), ('correspondingoutput', 1), ('wisebackprojection', 1), ('nattribution', 1), ('togradient', 1), ('eachconcepts', 1), ('conceptexplanations', 1), ('explanationbased', 1), ('explanationby', 1), ('haveadditional', 1), ('explainingwith', 1), ('generatesome', 1), ('methodsfailed', 1), ('sanitychecks', 1), ('aninput', 1), ('datarandomization', 1), ('randomizationtest', 1), ('testand', 1), ('forgradient', 1), ('constantvector', 1), ('thatmost', 1), ('hyperparameterinstead', 1), ('ofnetworks', 1), ('havehigh', 1), ('wanget', 1), ('bypopular', 1), ('threw', 1), ('examplesthus', 1), ('thatpopular', 1), ('inputinstance', 1), ('areexplained', 1), ('deﬁnitionsof', 1), ('moreconstraints', 1), ('mapsby', 1), ('explanationsas', 1), ('explanationmap', 1), ('causeslow', 1), ('someattributions', 1), ('sawmore', 1), ('improvedby', 1), ('inimproving', 1), ('presentingexplanations', 1), ('movingforward', 1), ('reconsidered', 1), ('formission', 1), ('ofcompleteness', 1), ('xaivisualizations', 1), ('generatedare', 1), ('onprimarily', 1), ('maximizedthe', 1), ('aslime', 1), ('muchemphasis', 1), ('focusedprimarily', 1), ('visualizationswhere', 1), ('involvea', 1), ('outputbecause', 1), ('bluefig', 1), ('verifythat', 1), ('priorgradient', 1), ('theimprovements', 1), ('variousxai', 1), ('leafbeetle', 1), ('anincorrect', 1), ('indicatesa', 1), ('ownindividual', 1), ('visualizationsfor', 1), ('ﬁgureare', 1), ('valuesincrease', 1), ('negativevalues', 1), ('howevershap', 1), ('basedtechniques', 1), ('hereeach', 1), ('thedecisions', 1), ('mapsin', 1), ('paribus', 1), ('ceteris', 1), ('severalmodel', 1), ('modeloriented', 1), ('drwhy', 1), ('marcoancona', 1), ('gradientinputintegrated', 1), ('anconaauthor', 1), ('expectationplots', 1), ('molnarauthor', 1), ('createdusing', 1), ('beetle', 1), ('importancein', 1), ('understandfeature', 1), ('ris', 1), ('regressionshap', 1), ('linearlogistic', 1), ('boostingdecision', 1), ('softwarepackages', 1), ('reproducibleresearch', 1), ('packagesopensource', 1), ('nullify', 1), ('explainablealgorithms', 1), ('weightedexplanation', 1), ('manuallyannotate', 1), ('imagenetdataset', 1), ('seni', 1), ('mosh', 1), ('theincreasing', 1), ('oreffect', 1), ('themonotonicity', 1), ('authorsintroduce', 1), ('theinterpreter', 1), ('predictingon', 1), ('byincrementally', 1), ('performanceeffect', 1), ('faithfullness', 1), ('describeda', 1), ('monotonicity', 1), ('regionrwith', 1), ('grrfor', 1), ('imageswhose', 1), ('betweendifference', 1), ('simplynot', 1), ('pasted', 1), ('henceattribution', 1), ('shouldignore', 1), ('tabulartab', 1), ('imgglobal', 1), ('schetinin', 1), ('orspeciﬁcdomainbayesian', 1), ('preprintversion', 1), ('vsummary', 1), ('iftable', 1), ('miniplaces', 1), ('pasting', 1), ('mscoco', 1), ('objectcategories', 1), ('pixelgroups', 1), ('thecorrectness', 1), ('preprintpublication', 1), ('risktool', 1), ('framingham', 1), ('scs', 1), ('scenariowhere', 1), ('oftendomain', 1), ('systemcausability', 1), ('whichdoes', 1), ('tractionfrom', 1), ('schemesseveral', 1), ('bedetectable', 1), ('differencescloser', 1), ('populationsmust', 1), ('magniﬁes', 1), ('onefeature', 1), ('cmust', 1), ('mustproduce', 1), ('worldsetting', 1), ('humanunderstandability', 1), ('wesummarize', 1), ('withprimary', 1), ('evaluationtechniques', 1), ('proposedalgorithms', 1), ('fundamentalchallenge', 1), ('worksdiscussed', 1), ('futuredirectionsso', 1), ('madeexplainable', 1), ('thatfis', 1), ('fsuch', 1), ('sacriﬁcing', 1), ('alreadytrained', 1), ('mostpost', 1), ('existingaccurate', 1), ('operationsand', 1), ('boxmeans', 1), ('hocexplaining', 1), ('accelerateinherently', 1), ('setmodel', 1), ('improveinterpretability', 1), ('architecturesand', 1), ('restrictionsto', 1), ('functionalmagnetic', 1), ('discriminantanalysis', 1), ('textualcategories', 1), ('bayesiannon', 1), ('provideaccurate', 1), ('modelsgams', 1), ('pairwiseinteractions', 1), ('tunedlanguage', 1), ('followsthe', 1), ('bayesiantechniques', 1), ('tosimplify', 1), ('moreif', 1), ('elseif', 1), ('ifelse', 1), ('decisionlists', 1), ('globallyexplainable', 1), ('inherentlyinterpretable', 1), ('naturallyexplainable', 1), ('fitself', 1), ('granularexplanations', 1), ('byfollowing', 1), ('intothem', 1), ('intrinsicon', 1), ('raisesvarious', 1), ('weightsaandbrespectively', 1), ('fandfwith', 1), ('weightedsum', 1), ('thatf', 1), ('networkmodelsfandfsuch', 1), ('modelfwhich', 1), ('fforthe', 1), ('attributionsbased', 1), ('patternat', 1), ('basednmt', 1), ('instancegooglenetlstm', 1), ('asaliency', 1), ('vggresnet', 1), ('describingnegative', 1), ('speciﬁcquery', 1), ('methodshave', 1), ('offgradient', 1), ('kicked', 1), ('alexnetgooglenetresnetvgga', 1), ('discussionssaliency', 1), ('ivsummary', 1), ('aretable', 1), ('discretegradients', 1), ('usediscrete', 1), ('andlrp', 1), ('functionallyequivalent', 1), ('attributionmethods', 1), ('inputsdespite', 1), ('anattribution', 1), ('orequal', 1), ('saturates', 1), ('differingfeature', 1), ('desirablequalities', 1), ('activationmaps', 1), ('thateg', 1), ('asexpectations', 1), ('reformulate', 1), ('isintractable', 1), ('xsince', 1), ('followingall', 1), ('ofbaseline', 1), ('andeg', 1), ('introducedin', 1), ('featureattributions', 1), ('howeverchoosing', 1), ('summationinstead', 1), ('integralin', 1), ('gradientis', 1), ('wherejdescribes', 1), ('xjd', 1), ('thatigj', 1), ('xtox', 1), ('pointsof', 1), ('modelfcan', 1), ('xon', 1), ('baselineinstancexrn', 1), ('havespeciﬁc', 1), ('wiserelevance', 1), ('generatingan', 1), ('correspondingto', 1), ('attentionfunctionreturnsrmap', 1), ('multiscalesaliencysrmap', 1), ('generatesrmaps', 1), ('mapflrp', 1), ('factorroutput', 1), ('anattention', 1), ('rarefound', 1), ('colorspace', 1), ('adissimilarity', 1), ('contextaware', 1), ('globalidea', 1), ('arefig', 1), ('oflrp', 1), ('superim', 1), ('todifferentiate', 1), ('otherpixel', 1), ('saliencyvalue', 1), ('mapalgorithm', 1), ('salience', 1), ('saliencemap', 1), ('proposedsalient', 1), ('anotherexample', 1), ('gradcamto', 1), ('classiﬁcationimage', 1), ('issuccessfully', 1), ('whichnegatively', 1), ('allowsclass', 1), ('forlocalizing', 1), ('cnnsand', 1), ('modiﬁedglobal', 1), ('maxpooling', 1), ('poolingoperations', 1), ('backpropagationmethods', 1), ('cnnswould', 1), ('linearunit', 1), ('importancegiven', 1), ('perturbationmethod', 1), ('visualexplanations', 1), ('followingsubsections', 1), ('inputxtowards', 1), ('vbert', 1), ('importanceinception', 1), ('studyfeature', 1), ('ofinputsresnetvgg', 1), ('bypetsiuk', 1), ('fromvarious', 1), ('variousmodels', 1), ('relevancevalue', 1), ('featurestowards', 1), ('alexnetgooglenetvggone', 1), ('fromx', 1), ('studyingfremoving', 1), ('differenceanalysis', 1), ('improveﬁnal', 1), ('ingenerating', 1), ('studiesargue', 1), ('thatshap', 1), ('pointof', 1), ('byﬁnding', 1), ('indataset', 1), ('deconvnetsalexnet', 1), ('occlud', 1), ('discussionsdeconv', 1), ('iiisummary', 1), ('contrastutilize', 1), ('outputclassc', 1), ('ftowards', 1), ('basedperturbation', 1), ('performancedue', 1), ('incounterfactual', 1), ('interestingway', 1), ('pothesis', 1), ('uninformativecounterfactuals', 1), ('discoveringimportant', 1), ('interpretabilityrandomization', 1), ('blackboxprediction', 1), ('heatmapfor', 1), ('weightedaverage', 1), ('mapscorresponding', 1), ('themasked', 1), ('featuresexceptx', 1), ('xnidenotes', 1), ('hiddenfeatures', 1), ('inmodel', 1), ('itsfeature', 1), ('featuresto', 1), ('summarizethe', 1), ('samplingbased', 1), ('granularstudy', 1), ('mapscould', 1), ('visualizationof', 1), ('mapsback', 1), ('renderopposite', 1), ('unpooling', 1), ('arecnns', 1), ('deconvnets', 1), ('visualizationsusing', 1), ('differentsegments', 1), ('occluding', 1), ('individuallayers', 1), ('visualizationszeiler', 1), ('furthersummarized', 1), ('basedxai', 1), ('anyinput', 1), ('methodstrying', 1), ('similarmethod', 1), ('byiteratively', 1), ('superpixelsof', 1), ('blurringshifting', 1), ('pickingone', 1), ('certainfeatures', 1), ('theseperturbations', 1), ('inputsgenerally', 1), ('trainedmachine', 1), ('basedexplanations', 1), ('asperturbation', 1), ('oneswhich', 1), ('methodologybased', 1), ('anoutput', 1), ('generateexact', 1), ('featuresas', 1), ('modelprovides', 1), ('distributionnwithx', 1), ('aweight', 1), ('andbarethe', 1), ('wherexw', 1), ('calculatedash', 1), ('exu', 1), ('infeatures', 1), ('withstandard', 1), ('sourcepaper', 1), ('asumming', 1), ('fiis', 1), ('featuresxi', 1), ('fiwith', 1), ('parameterizing', 1), ('thetarget', 1), ('xkis', 1), ('fkwherefiis', 1), ('formg', 1), ('cannotlearn', 1), ('andfeature', 1), ('togeneralized', 1), ('networkattend', 1), ('subpopulationgranularity', 1), ('explanationsamong', 1), ('globalattribution', 1), ('byminimizing', 1), ('ﬁndsa', 1), ('weightedconjoined', 1), ('welldeﬁned', 1), ('eigenmapanalysisreturnclusters', 1), ('scclusters', 1), ('forreshapefsprayclusters', 1), ('samplesforxxdofspray', 1), ('attributionsinput', 1), ('optionallyvisualized', 1), ('eigengap', 1), ('ﬁndrelevant', 1), ('eigenmap', 1), ('spectralcluster', 1), ('improvecomputation', 1), ('relevancemaps', 1), ('xxusing', 1), ('startby', 1), ('identiﬁesnormal', 1), ('frequentlyoccurring', 1), ('aspectral', 1), ('techniqueby', 1), ('utilizingshapley', 1), ('cmgby', 1), ('mconcept', 1), ('individualconcepts', 1), ('howeverconceptshap', 1), ('consistentlyclustered', 1), ('discoveredconcept', 1), ('arebiases', 1), ('experimentalresults', 1)]\n"
     ]
    }
   ],
   "source": [
    "lower_cnt = int(len(set(text.tokens)) * 0.01) * -1\n",
    "print(text.vocab().most_common()[:lower_cnt:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88523ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_test = test[['num','words']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b5d89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[uid]) for uid, _d in doc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14c3cc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['special', 'section', 'on', 'deep', 'learningalgorithms', 'for', 'internet', 'of', 'medical', 'thingsreceived', 'april', 'accepted', 'april', 'date', 'of', 'publication', 'may', 'date', 'of', 'current', 'version', 'may', 'digital', 'object', 'identifier', 'access', 'a', 'comprehensive', 'review', 'of', 'thecovid', 'pandemic', 'and', 'the', 'role', 'of', 'iotdrones', 'ai', 'blockchain', 'and', 'g', 'inmanaging', 'its', 'impactvinay', 'chamola', 'vikas', 'hassija', 'vatsal', 'guptaand', 'mohsen', 'guizani', 'department', 'of', 'electrical', 'and', 'electronics', 'engineering', 'birla', 'institute', 'of', 'technology', 'and', 'science', 'pilani', 'indiadepartment', 'of', 'cse', 'and', 'it', 'jaypee', 'institute', 'of', 'information', 'technology', 'noida', 'indiadepartment', 'of', 'computer', 'science', 'and', 'engineering', 'qatar', 'university', 'doha', 'qatarcorresponding', 'author', 'mohsen', 'guizani', 'this', 'work', 'was', 'supported', 'by', 'the', 'qatar', 'national', 'research', 'fund', 'under', 'grant', 'nprp', 'abstract', 'the', 'unprecedented', 'outbreak', 'of', 'the', 'novel', 'coronavirus', 'termed', 'as', 'covid', 'by', 'the', 'worldhealth', 'organization', 'has', 'placed', 'numerous', 'governments', 'around', 'the', 'world', 'in', 'a', 'precarious', 'position', 'the', 'impact', 'of', 'the', 'covid', 'outbreak', 'earlier', 'witnessed', 'by', 'the', 'citizens', 'of', 'china', 'alone', 'has', 'now', 'becomea', 'matter', 'of', 'grave', 'concern', 'for', 'virtually', 'every', 'country', 'in', 'the', 'world'], tags=[0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc4ea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# doc2vec 하이퍼 파라미터 튜닝\n",
    "max_epochs = 11\n",
    "\n",
    "model = Doc2Vec(\n",
    "    window=5,                # 문맥을 고려하는 단어의 최대 거리\n",
    "    vector_size=130,         # 벡터 크기\n",
    "    alpha=0.025,             # 모델의 학습속도\n",
    "    min_alpha=0.025,\n",
    "    workers = 8,             # 학습을 병렬화하기 위한 스레드 수\n",
    "    min_count=3,             # 최소 단어 빈도\n",
    "    dm =0,                   # dm = '0': DBOW // dm = '1': DM\n",
    "    negative = 6,            # 음수 에제의 수를 결정\n",
    "    seed = 9999)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "    model.alpha -= 0.002     # 학습 속도 점차 감소시킴\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86b509f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dubai', 0.3454352617263794),\n",
       " ('israel', 0.34018829464912415),\n",
       " ('hero', 0.33700981736183167),\n",
       " ('thealgorithms', 0.32803624868392944),\n",
       " ('mutate', 0.32234182953834534),\n",
       " ('labo', 0.31641167402267456),\n",
       " ('ofknowledge', 0.31562456488609314),\n",
       " ('strained', 0.3100779056549072),\n",
       " ('finnis', 0.30814531445503235),\n",
       " ('hca', 0.3062429130077362)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비슷한 단어 테스트\n",
    "model.wv.most_similar('korea',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ea90e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " 'the past twodecades have witnessed the emergence of several viral out breaks with different forms of coronavirus at the helmsuch as the sars cov outbreak and themore recent middle east respiratory syndrome coronavirus infection of the sars cov outbreakoriginated in the guandong province of china and laterspread to more than countries worldwide causing over infections and around deaths ')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 문장 출력\n",
    "test_id = 20\n",
    "test['num'][test_id], test['sentence'][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcad51af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.9361479878425598 \n",
      " the past twodecades have witnessed the emergence of several viral out breaks with different forms of coronavirus at the helmsuch as the sars cov outbreak and themore recent middle east respiratory syndrome coronavirus infection of the sars cov outbreakoriginated in the guandong province of china and laterspread to more than countries worldwide causing over infections and around deaths  \n",
      "\n",
      "449 0.6491448283195496 \n",
      " voice detectionfollowing the covid outbreak several voice detectionapps have been developed for covid screening  \n",
      "\n",
      "289 0.6453151702880859 \n",
      " screening massesfollowing the outbreak of the covid several authoritiesin china committed themselves to detect covid patientsas soon as possible  \n",
      "\n",
      "109 0.622896671295166 \n",
      " comprehensive review of the covid pandemicfigure countries in lockdown as of april c  \n",
      "\n",
      "79 0.6227855682373047 \n",
      " while coronaviruses such as sars cov mers cov have been responsible for a majority of theseoutbreaks different types of in uenzaviruses such as hn hn and hn have been at thehelm of all the four pandemics in the past years  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1104-10\\AppData\\Local\\Temp\\ipykernel_15912\\3435780723.py:6: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  return_docs = model.docvecs.most_similar(positive=[inferred_vector],topn=5)\n"
     ]
    }
   ],
   "source": [
    "# 특정 문장에 대한 유사한 문장 출력\n",
    "model.random.seed(9999)\n",
    "\n",
    "doc_list = test['words'][test_id]\n",
    "\n",
    "inferred_vector = model.infer_vector(doc_list)\n",
    "return_docs = model.docvecs.most_similar(positive=[inferred_vector],topn=5)\n",
    "\n",
    "for rd in return_docs:\n",
    "    for des in test[test['num'] == rd[0]]['sentence']:\n",
    "        print (rd[0],rd[1],'\\n',des,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2c2ae6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12533 0.7482085227966309 \n",
      " on the interpretations illustrations and implications of artificial intelligence business horizons  \n",
      "\n",
      "10802 0.7280052900314331 \n",
      " strategic council for ai technology artificial intelligence technology strategy  \n",
      "\n",
      "7007 0.7255040407180786 \n",
      " hbr org the big idea artificial intelligence for real erik brynjolfsson and andrew mcafeesolving for  \n",
      "\n",
      "52828 0.7233378291130066 \n",
      "  executive office of the president artificial intelligence automation and the economy  \n",
      "\n",
      "54237 0.71969074010849 \n",
      " developing an artificial intelligence capability a theoretical framework for business value  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 직접 입력한 문장과 유사한 문장 출력\n",
    "model.random.seed(9999)\n",
    "\n",
    "doc_list = 'the business of artificial intelligence'.split(' ')\n",
    "\n",
    "inferred_vector = model.infer_vector(doc_list)\n",
    "return_docs = model.dv.most_similar(positive=[inferred_vector],topn=5)\n",
    "\n",
    "for rd in return_docs:\n",
    "    for des in test[test['num'] == rd[0]]['sentence']:\n",
    "        print (rd[0],rd[1],'\\n',des,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
